{"title": "Compute Engine - Network bandwidths and GPUs", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Network bandwidths and GPUs\nHigher network bandwidths can improve the performance of your distributed workloads running on Compute Engine virtual machine (VM) instances.\n", "content": "## Overview\nThe maximum network bandwidth that is available for VMs with attached GPUs on Compute Engine is as follows:\n- For N1 general-purpose VMs that have P100, P4, and K80 GPUs attached, a maximum network bandwidth of 32\u00a0Gbps is available. This is similar to the maximum rate available to N1 VMs that don't have GPUs attached. For more information about network bandwidths, see [maximum egress data rate](/vpc/docs/quota#per_instance) .\n- For N1 general-purpose VMs that have T4 and V100 GPUs attached, you can get a maximum network bandwidth of up to 100\u00a0Gbps, based on the combination of GPU and vCPU count.\n- For A2 and G2 accelerator-optimized VMs, you can get a maximum network bandwidth of up to 100\u00a0Gbps, based on the machine type.\n- For A3 accelerator-optimized VMs, you can get a maximum network bandwidth of up 1,000\u00a0Gbps (1\u00a0Tbps).## Network bandwidth and Google Virtual NIC (gVNIC)\nTo get the higher network bandwidth rates (50\u00a0Gbps or higher) applied to your GPU VMs, it is recommended that you use Google Virtual NIC (gVNIC). For more information about creating GPU VMs that use gVNIC, see [Creating GPU VMs that use higher bandwidths](/compute/docs/gpus/optimize-gpus#create-high-bandwidth-vm) .\n## Accelerator-optimized VMs\nThis section outlines the maximum network bandwidth available for A3, A2, and G2 [accelerator-optimized VMs](/compute/docs/accelerator-optimized-machines) .\n### A3 VMs\nEach A3 machine type has a fixed number of NVIDIA H100 80GB GPUs attached. Each machine type also has a fixed vCPU count and memory size.\n`a3-highgpu-8g`\n| Machine type | GPU count | vCPUs | Memory | Maximum network bandwidth |\n|:---------------|------------:|--------:|:---------|:----------------------------|\n| a3-highgpu-8g |   8 |  208 | 1872 GB | 1,000\u00a0Gbps     |\n### A2 VMs\nEach A2 machine type has a fixed number of NVIDIA A100 40GB or NVIDIA A100 80 GB GPUs attached. Each machine type also has a fixed vCPU count and memory size.\n| Machine type | GPU count | vCPUs | Memory | Maximum network bandwidth |\n|:---------------|------------:|--------:|:---------|:----------------------------|\n| a2-highgpu-1g |   1 |  12 | 85 GB | 24\u00a0Gbps      |\n| a2-highgpu-2g |   2 |  24 | 170 GB | 32\u00a0Gbps      |\n| a2-highgpu-4g |   4 |  48 | 340 GB | 50\u00a0Gbps      |\n| a2-highgpu-8g |   8 |  96 | 680 GB | 100\u00a0Gbps     |\n| a2-highgpu-16g |   16 |  96 | 1360 GB | 100\u00a0Gbps     || Machine type | GPU count | vCPUs | Memory | Maximum network bandwidth |\n|:---------------|------------:|--------:|:---------|:----------------------------|\n| a2-ultragpu-1g |   1 |  12 | 170 GB | 24\u00a0Gbps      |\n| a2-ultragpu-2g |   2 |  24 | 340 GB | 32\u00a0Gbps      |\n| a2-ultragpu-4g |   4 |  48 | 680 GB | 50\u00a0Gbps      |\n| a2-ultragpu-8g |   8 |  96 | 1360 GB | 100\u00a0Gbps     |\n### G2 VM configuration\nEach G2 machine type has a fixed number of [NVIDIA L4 GPUs](/compute/docs/gpus#l4-gpus) and vCPUs attached. Each G2 machine type also has a default memory and a custom memory range. The custom memory range defines the amount of memory that you can allocate to your VM for each machine type. You can specify your custom memory during VM creation.\n| Machine type | GPU count | vCPUs | Default memory | Custom memory range | Maximum network bandwidth |\n|:---------------|------------:|:---------|:-----------------|:----------------------|:----------------------------|\n| g2-standard-4 |   1 | 4 vCPUs | 16 GB   | 16 - 32 GB   | 10\u00a0Gbps      |\n| g2-standard-8 |   1 | 8 vCPUs | 32 GB   | 32 - 54 GB   | 16\u00a0Gbps      |\n| g2-standard-12 |   1 | 12 vCPUs | 48 GB   | 48 - 54 GB   | 16\u00a0Gbps      |\n| g2-standard-16 |   1 | 16 vCPUs | 64 GB   | 54 - 64 GB   | 32\u00a0Gbps      |\n| g2-standard-24 |   2 | 24 vCPUs | 96 GB   | 96 - 108 GB   | 32\u00a0Gbps      |\n| g2-standard-32 |   1 | 32 vCPUs | 128 GB   | 96 - 128 GB   | 32\u00a0Gbps      |\n| g2-standard-48 |   4 | 48 vCPUs | 192 GB   | 192 - 216 GB   | 50\u00a0Gbps      |\n| g2-standard-96 |   8 | 96 vCPUs | 384 GB   | 384 - 432 GB   | 100\u00a0Gbps     |\n## N1 GPU VMs\nFor N1 general-purpose VMs that have T4 and V100 GPUs attached, you can get a maximum network bandwidth of up to 100\u00a0Gbps, based on the combination of GPU and vCPU count. For all other N1 GPU VMs, see [Overview](#overview) .\nReview the following section to calculate the maximum network bandwidth that is available for your T4 and V100 VMs based on the GPU model, vCPU, and GPU count.\nFor T4 and V100 VMs that have 5 vCPUs or less, a maximum network bandwidth of 10\u00a0Gbps is available.\nFor T4 and V100 VMs that have more than 5 vCPUs, maximum network bandwidth is calculated based on the number of vCPUs and GPUs for that VM.\n| GPU model | Number of GPUs | Maximum network bandwidth calculation |\n|:------------|-----------------:|:----------------------------------------|\n| NVIDIA V100 |    1 | min(vcpu_count * 2, 32)     |\n| NVIDIA V100 |    2 | min(vcpu_count * 2, 32)     |\n| NVIDIA V100 |    4 | min(vcpu_count * 2, 50)     |\n| NVIDIA V100 |    8 | min(vcpu_count * 2, 100)    |\n| NVIDIA T4 |    1 | min(vcpu_count * 2, 32)     |\n| NVIDIA T4 |    2 | min(vcpu_count * 2, 50)     |\n| NVIDIA T4 |    4 | min(vcpu_count * 2, 100)    |\n## Create high bandwidth VMs\nTo create VMs that use higher network bandwidths, see [Use higher network bandwidth](/compute/docs/gpus/optimize-gpus#overview) .\nTo test or verify the bandwidth speed for any configuration, you can use the benchmarking test. For more information, see [Checking network bandwidth](/compute/docs/gpus/optimize-gpus#check-bandwidth) .\n## What's next?\n- Learn more about [GPU platforms](/compute/docs/gpus) .\n- Learn how to [create VMs with attached GPUs](/compute/docs/gpus/create-vm-with-gpus) .\n- Learn about [Use higher network bandwidth](/compute/docs/gpus/optimize-gpus) .\n- Learn about [GPU pricing](/compute/gpus-pricing) .", "guide": "Compute Engine"}