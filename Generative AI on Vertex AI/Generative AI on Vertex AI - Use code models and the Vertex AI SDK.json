{"title": "Generative AI on Vertex AI - Use code models and the Vertex AI SDK", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/sdk-for-llm/sdk-use-code-models", "abstract": "# Generative AI on Vertex AI - Use code models and the Vertex AI SDK\nThere are three generative AI code foundation models in Vertex AI. The three models are a code generation model, a code completion model, and a code chat model.\n- The code generation model name is `code-bison` and its class in the Vertex AI SDK is [CodeGenerationModel](/python/docs/reference/aiplatform/latest/vertexai.language_models.CodeGenerationModel) .\n- The code completion model name is `code-gecko` and its class in the Vertex AI SDK is the same class used for code generation, [CodeGenerationModel](/python/docs/reference/aiplatform/latest/vertexai.language_models.CodeGenerationModel) .\n- The code chat model name is `codechat-bison` and its class in the Vertex AI SDK is [CodeChatModel](/python/docs/reference/aiplatform/latest/vertexai.language_models.CodeChatModel) .\nThe following topics show you how to use these classes and the Vertex AI SDK to perform some common code-related generative AI tasks.\n#", "content": "## Generate a code function\nThe use cases for the code generation foundation model include designing unit tests, writing a function, and creating a class. To generate code, use the same class that's used to create code completion, [CodeGenerationModel](/python/docs/reference/aiplatform/latest/vertexai.language_models.CodeGenerationModel) . To create a solution that generates code, pass in the name of a version of the code generation model, such as `code-bison@002` . To learn more about the code generation foundation model, see [Create prompts to generate code](/vertex-ai/generative-ai/docs/code/code-generation-prompts) and [Test code generation prompts](/vertex-ai/generative-ai/docs/code/test-code-generation-prompts) .\nThe following code sample writes a function that detects if a year is a leap year.\n```\nfrom vertexai.language_models import CodeGenerationModelcode_generation_model = CodeGenerationModel.from_pretrained(\"code-bison@001\")print(code_generation_model.predict(\u00a0 \u00a0 prefix=\"Write a function that checks if a year is a leap year.\",\u00a0 \u00a0 # The following parameters are optional:\u00a0 \u00a0 # max_output_tokens=1024,\u00a0 \u00a0 # temperature=0.0,))\n```\nThe output might be similar to the following:\n```\nI will write a function to check if a year is a leap year.**The function will take a year as input and return a boolean value**.**The function will first check if the year is divisible by 4.****If the year is divisible by 4, the function will then check if the year is divisible by 100.****If the year is divisible by 100, the function will then check if the year is divisible by 400.****If the year is divisible by 400, the function will ...\n```\n## Generate code for code completion\nCode completion is code that's predicted to complete code as it's written. The generated prediction appears as you type. If you want to create a code completion solution, use the [CodeGenerationModel](/python/docs/reference/aiplatform/latest/vertexai.language_models.CodeGenerationModel) class. This is the same class used to generate code, such as a function. To generate code that's predicted to complete code as it's written, call `CodeGenerationModel.from_pretrained` and pass in the name of a version of the code completion model. To learn more about the code completion foundation model, see [Create prompts for code completion](/vertex-ai/generative-ai/docs/code/code-completion-prompts) and [Test code completion prompts](/vertex-ai/generative-ai/docs/code/test-code-completion-prompts) .\nThe following sample code uses the most recent [stable version](/vertex-ai/generative-ai/docs/learn/model-versioning#stable-version) of `code-gecko` to return code that's predicted to complete the start of a function that reverses a string.\n```\nfrom vertexai.language_models import CodeGenerationModelcode_completion_model = CodeGenerationModel.from_pretrained(\"code-gecko@001\")print(code_completion_model.predict(\u00a0 \u00a0 prefix=\"def reverse_string(s):\",\u00a0 \u00a0 # Optional:\u00a0 \u00a0 suffix=\" \u00a0 \u00a0return reversed_str\",\u00a0 \u00a0 max_output_tokens=64,\u00a0 \u00a0 # temperature=0.0,))\n```\nThe output is similar to the following:\n```\n\"\"\":type s: str:rtype: str\"\"\"reversed_str = \"\"for i in range(len(s) - 1, -1, -1):\u00a0 \u00a0 reversed_str += s[i]\n```\n## Create a code chat\nYou might want to create a chat session that is specifically about code. For example, you might want to use chat to learn about a coding language or syntax. To create a code chat session with the Vertex AI SDK, use the `start_chat` method on an instance of a `CodeChatModel` . Unlike a text chat, a code chat created with the Vertex AI SDK doesn't use the [InputOutputTextPair](/python/docs/reference/aiplatform/latest/vertexai.language_models.InputOutputTextPair) class. To learn more about the code chat foundation model, see [Create prompts for code chat](/vertex-ai/generative-ai/docs/code/code-chat-prompts) and [Test code chat prompts](/vertex-ai/generative-ai/docs/code/test-code-chat-prompts) .\nThe following uses code chat to request information about how to write a function.\n```\nfrom vertexai.language_models import CodeChatModelcode_chat_model = CodeChatModel.from_pretrained(\"codechat-bison@002\")code_chat = code_chat_model.start_chat()print(code_chat.send_message(\"Please help write a function that prints its own source code\"))\n```\nThe output might be similar to the following:\n```\nSure, here is a function that prints its own source code:```def print_source_code():\u00a0 \"\"\"Prints the source code of this function.\"\"\"\u00a0 # Get the source code of this function.\u00a0 source_code = inspect.getsource(print_source_code)\u00a0 # Print the source code.\u00a0 print(source_code)```This function works by first getting the source code of the function using the`inspect.getsource()` function. Then, it prints the source code to the console.\n```\n## Stream code model responses\nYou might want to receive responses from the code generation and code chat models as they're generated. Receiving responses from a foundation model as the responses are generated is known as streaming. When code generation and code chat model responses are streamed, the output tokens are sent when they're generated. To stream code generation, use the `CodeGenerationModel.predict_streaming` method. To stream code chat, use the `CodeChatModel.predict_streaming` method. To learn more about streaming from foundation models, see [Stream responses from Generative AI models](/vertex-ai/generative-ai/docs/learn/streaming) .\n### Stream code generation\nThe following sample code streams code that checks if a year is a leap year. It also outputs the time before and the time after `from_pretrained` is called to demonstrate how long it takes to stream the output.\n```\nimport datetimefrom vertexai.language_models import CodeGenerationModelcode_generation_model = CodeGenerationModel.from_pretrained(\"code-bison@001\")print(\"Start: \", datetime.datetime.now())for response in code_generation_model.predict_streaming(\u00a0 \u00a0 prefix=\"Write a function that checks if a year is a leap year.\",\u00a0 \u00a0 # Optional:\u00a0 \u00a0 # max_output_tokens=1024,\u00a0 \u00a0 # temperature=0.0,):\u00a0 \u00a0 print(datetime.datetime.now(), \"|\", response)print(\"End: \", datetime.datetime.now())\n```\nThe response might be similar to the following:\n```\nStart: \u00a0YYYY-MM-DD 06:31:45.759810YYYY-MM-DD 06:31:46.536173 | To check if a year is a leap year, we can use the following stepYYYY-MM-DD 06:31:46.611856 | s:1. **Check if the year is divisible by 4.** If it is not, thYYYY-MM-DD 06:31:46.667330 | en it is not a leap year.2. **Check if the year is divisible byYYYY-MM-DD 06:31:46.805714 | \u00a0100.** If it is, then it is not a leap year unless it is also dYYYY-MM-DD 06:31:46.940925 | ivisible by 400.3. **If the year is divisible by 4 but not by 1YYYY-MM-DD 06:31:47.033529 | 00, then it is a leap year.**For example, the year 2020 is divYYYY-MM-DD 06:31:47.110856 | isible byEnd: \u00a0YYYY-MM-DD 06:31:47.112951\n```\n### Stream code chat\nThe following sample code streams code chat that is in response to a chatbot request to write a function that prints its own source code. The code sample also outputs the time before and the time after `from_pretrained` is called to demonstrate how long it takes to stream the output.\n```\nimport datetimefrom vertexai.language_models import CodeChatModelcode_chat_model = CodeChatModel.from_pretrained(\"codechat-bison@001\")code_chat = chat_model.start_chat()print(\"Start: \", datetime.datetime.now())for response in code_chat.send_message_streaming(\u00a0 \u00a0 message=\"Please help write a function that prints its own source code\",\u00a0 \u00a0 # Optional:\u00a0 \u00a0 max_output_tokens=1024,):\u00a0 \u00a0 #print(datetime.datetime.now(), \"|\", response)\u00a0 \u00a0 print(\">>>\")\u00a0 \u00a0 print(response)print(\"End: \", datetime.datetime.now())\n```\nThe response might be similar to the following:\n```\n```Start: \u00a0YYYY-MM-DD 06:32:10.733415>>>```pythondef print_source(func):\u00a0 \u00a0 with open(func.__file__, '>>>r') as f:\u00a0 \u00a0 \u00a0 \u00a0 source = f.read()\u00a0 \u00a0 print(source)```End: \u00a0YYYY-MM-DD 06:32:11.764794```\n```\n## What's next\n- Learn how to [use text model classes and the Vertex AI SDK](/vertex-ai/generative-ai/docs/sdk-for-llm/sdk-use-text-models) .\n- Learn how to [use the Vertex AI SDK to tune foundation models](/vertex-ai/generative-ai/docs/sdk-for-llm/sdk-tune-models) .\n- Learn about [Vertex AI SDK classes not related to generative AI](/vertex-ai/docs/python-sdk/python-sdk-class-overview) .", "guide": "Generative AI on Vertex AI"}