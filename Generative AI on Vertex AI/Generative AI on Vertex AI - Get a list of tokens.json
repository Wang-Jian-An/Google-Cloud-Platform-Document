{"title": "Generative AI on Vertex AI - Get a list of tokens", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/compute-token", "abstract": "# Generative AI on Vertex AI - Get a list of tokens\nThis page shows you how to compute tokens for a given prompt. A token is a way to represent a common sequence of characters found in a text input. When you create a token, a Large Language Model (LLM) can compute the statistical relationships between tokens and produces the next most likely token in a sequence of tokens.\n", "content": "## Supported models\nThe following foundation models support getting a list of tokens and token IDs:\n- `text-bison`\n- `chat-bison`\n- `textembedding-gecko`\n- `code-bison`\n- `codechat-bison`\n- `code-gecko`## Get a list of tokens and token IDs for a prompt\nYou can get a list of tokens and token IDs by using the Vertex AI API.\n**Important:** The input format for `ComputeTokens` is the same for all the models, which is different from `CountTokens` , where each model matches the input format for `predict` .\nTo get a list of tokens and token IDs for a prompt using the Vertex AI API, send a POST request to the publisher model endpoint.\nBefore using any of the request data, make the following replacements:- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : The name of the model for which you want to  compute tokens for your prompt. The foundation model options are:- `text-bison`\n- `chat-bison`\n- `textembedding-gecko`\n- `code-bison`\n- `codechat-bison`\n- `code-gecko`\nYou can specify a [stable version](/vertex-ai/generative-ai/docs/learn/model-versioning#stable-version) by appending a version number to the model name, such as`@001`to the model name.  You can also specify a [latest version](/vertex-ai/generative-ai/docs/learn/model-versioning#latest-version) by not appending a version number to the model name. To learn which *stable* model versions are  available, see [Available stable model versions](/vertex-ai/generative-ai/docs/learn/model-versioning#stable-versions-available) .\n- : The prompt to compute the tokens for. (Don't add quotes around the prompt here.)\nHTTP method and URL:\n```\nPOST https://us-central1-aiplatform.googleapis.com/v1beta1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:computeTokens\n```\nRequest JSON body:\n```\n{\n \"instances\": [ { \"prompt\": \"PROMPT\"}\n ],\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` .  Run the following command in the terminal to create or overwrite  this file in the current directory:\n```\ncat > request.json << 'EOF'\n{\n \"instances\": [ { \"prompt\": \"PROMPT\"}\n ],\n}\nEOF\n```\nThen execute the following command to send your REST request:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:computeTokens\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` .  Run the following command in the terminal to create or overwrite  this file in the current directory:\n```\n@'\n{\n \"instances\": [ { \"prompt\": \"PROMPT\"}\n ],\n}\n'@ | Out-File -FilePath request.json -Encoding utf8\n```\nThen execute the following command to send your REST request:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://us-central1-aiplatform.googleapis.com/v1beta1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:computeTokens\" | Select-Object -Expand Content\n```\nThe output tokens are represented in base64 string. For improved readability, you can convert the output back to regular string. Here is an example:\n```\n {\n \"tokensInfo\": [  {\n  \"tokens\": [   \"IFByb3ZpZGU=\",\n   \"IGE=\",\n   \"IHN1bW1hcnk=\",\n   \"IG9m\"\n  ],\n  \"tokenIds\": [   \"45895\",\n   \"1016\",\n   \"14292\",\n   \"1024\"\n  ]\n  }\n ]\n }\n```\n```\nMODEL_ID=\"text-bison\"PROJECT_ID=\"my-project\"PROMPT=\"Provide a summary with about two sentences for the following article.\"curl \\-X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\https://us-central1-aiplatform.googleapis.com/v1beta1/projects/${PROJECT_ID}/locations/us-central1/publishers/google/models/${MODEL_ID}:computeTokens -d \\$'{\u00a0 \"instances\": [\u00a0 \u00a0 { \"prompt\": \"'\"$PROMPT\"'\"}\u00a0 ],}'\n```\n## Pricing and quota\nThere is no charge for using the `ComputeTokens` API. There is a quota restriction of 3000 requests per minute, the same quota for the `CountTokens` API.\n## What's next\n- Learn how to [count tokens](/vertex-ai/generative-ai/docs/get-token-count) .\n- Learn how to [test chat prompts](/vertex-ai/generative-ai/docs/chat/test-chat-prompts) .\n- Learn how to [test text prompts](/vertex-ai/generative-ai/docs/text/test-text-prompts) .\n- Learn how to [get text embeddings](/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings) .", "guide": "Generative AI on Vertex AI"}