{"title": "Generative AI on Vertex AI - \u591a\u6a21\u614b\u5d4c\u5165", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-embeddings?hl=zh-cn", "abstract": "# Generative AI on Vertex AI - \u591a\u6a21\u614b\u5d4c\u5165\nEmbeddings for Multimodal ( `multimodalembedding` ) \u6a21\u578b\u6703\u6839\u64da\u60a8\u63d0\u4f9b\u7684\u8f38\u5165\u751f\u6210\u7dad\u5ea6\u5411\u91cf\uff08128\u3001256\u3001512 \u6216 1408 \u7dad\u5ea6\uff09\u3002\u6b64\u8f38\u5165\u53ef\u5305\u62ec\u4efb\u4f55\u6587\u672c\u3001\u5716\u7247\u6216\u8996\u983b\u7684\u7d44\u5408\u3002\u7136\u5f8c\uff0c\u5d4c\u5165\u5411\u91cf\u53ef\u7528\u65bc\u5176\u4ed6\u5f8c\u7e8c\u4efb\u52d9\uff0c\u4f8b\u5982\u5716\u7247\u5206\u985e\u6216\u5167\u5bb9\u5be9\u8988\u3002\n\u6587\u672c\u3001\u5716\u7247\u548c\u8996\u983b\u5d4c\u5165\u5411\u91cf\u4f4d\u65bc\u540c\u4e00\u8a9e\u7fa9\u7a7a\u9593\u4e2d\uff0c\u4e26\u4e14\u5177\u6709\u76f8\u540c\u7684\u7dad\u5ea6\u3002\u56e0\u6b64\uff0c\u9019\u4e9b\u5411\u91cf\u53ef\u4ee5\u4e92\u63db\u7528\u65bc\u61c9\u7528\u5834\u666f\uff0c\u4f8b\u5982\u6309\u6587\u672c\u641c\u7d22\u5716\u7247\u6216\u6309\u5716\u7247\u641c\u7d22\u8996\u983b\u3002\n", "content": "## \u4f7f\u7528\u5834\u666f\n\u591a\u6a21\u614b\u5d4c\u5165\u7684\u4e00\u4e9b\u5e38\u898b\u61c9\u7528\u5834\u666f\u5305\u62ec\uff1a\n- **\u5716\u7247\u6216\u8996\u983b\u5206\u985e** \uff1a\u5c07\u5716\u7247\u6216\u8996\u983b\u4f5c\u7232\u8f38\u5165\uff0c\u4e26\u9810\u6e2c\u4e00\u500b\u6216\u591a\u500b\u985e\u5225\uff08\u6a19\u7c64\uff09\u3002\n- **\u5716\u7247\u641c\u7d22** \uff1a\u641c\u7d22\u76f8\u95dc\u6216\u985e\u4f3c\u7684\u5716\u7247\u3002\n- **\u8996\u983b\u5167\u5bb9\u641c\u7d22** - **\u4f7f\u7528\u8a9e\u7fa9\u641c\u7d22** \uff1a\u5c07\u6587\u672c\u4f5c\u7232\u8f38\u5165\uff0c\u4e26\u8fd4\u56de\u4e00\u7d44\u8207\u67e5\u8a62\u5339\u914d\u7684\u5df2\u6392\u5e8f\u5e40\u3002\n- **\u4f7f\u7528\u76f8\u4f3c\u5ea6\u641c\u7d22\u529f\u80fd** \uff1a- \u5c07\u8996\u983b\u4f5c\u7232\u8f38\u5165\uff0c\u4e26\u8fd4\u56de\u4e00\u7d44\u8207\u67e5\u8a62\u5339\u914d\u7684\u8996\u983b\u3002\n- \u5c07\u4e00\u5f35\u5716\u7247\u4f5c\u7232\u8f38\u5165\uff0c\u4e26\u8fd4\u56de\u4e00\u7d44\u8207\u67e5\u8a62\u5339\u914d\u7684\u8996\u983b\u3002\n- **\u63a8\u85a6** \uff1a\u6839\u64da\u5716\u7247\u6216\u8996\u983b\u751f\u6210\u7522\u54c1\u6216\u5ee3\u544a\u63a8\u85a6\uff08\u76f8\u4f3c\u5ea6\u641c\u7d22\uff09\u3002\n\u5982\u9700\u5728\u63a7\u5236\u6aaf\u4e2d\u63a2\u7d22\u6b64\u6a21\u578b\uff0c\u8acb\u53c3\u95b1 Model Garden \u4e2d\u7684 **Embeddings for Multimodal** \u6a21\u578b\u5361\u7247\u3002\n<a{: class=\"button button-primary\" l10n-attrs-original-order=\"href,target,class,track-name,track-type\" l10n-encrypted-href=\"SAHUNDUxy6reWq97H1UtVltigmNHgUGOXn/QVSGplOi71dheYhG9dKuv3S+0ajmQkfzB9oP/Mo2x7xIe1klR5WMcFGqgYIW2vdvnDTxO1+88jFCqaIV0kUsj2YehOF0AqvP4zdF86Pqj1NbCoHpRoQ==\" target=\"console\" track-name=\"consoleLink\" track-type=\"tasks\" }=\"\">\u524d\u5f80 Model Garden</a{:>\n## HTTP \u8acb\u6c42\n```\nPOST https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT}/locations/us-central1/publishers/google/models/multimodalembedding:predict\n```\n## \u8acb\u6c42\u6b63\u6587\n```\n{\u00a0 \"instances\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"text\": string,\u00a0 \u00a0 \u00a0 \"image\": {\u00a0 \u00a0 \u00a0 \u00a0 // Union field can be only one of the following:\u00a0 \u00a0 \u00a0 \u00a0 \"bytesBase64Encoded\": string,\u00a0 \u00a0 \u00a0 \u00a0 \"gcsUri\": string,\u00a0 \u00a0 \u00a0 \u00a0 // End of list of possible types for union field.\u00a0 \u00a0 \u00a0 \u00a0 \"mimeType\": string\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \"video\": {\u00a0 \u00a0 \u00a0 \u00a0 // Union field can be only one of the following:\u00a0 \u00a0 \u00a0 \u00a0 \"bytesBase64Encoded\": string,\u00a0 \u00a0 \u00a0 \u00a0 \"gcsUri\": string,\u00a0 \u00a0 \u00a0 \u00a0 // End of list of possible types for union field.\u00a0 \u00a0 \u00a0 \u00a0 \"videoSegmentConfig\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"startOffsetSec\": integer,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"endOffsetSec\": integer,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"intervalSec\": integer\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \"parameters\": {\u00a0 \u00a0 \u00a0 \u00a0 \"dimension\": integer\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 ]}\n```\n\u5c0d\u591a\u6a21\u614b\u751f\u6210\u6a21\u578b `multimodal embeddings` \u4f7f\u7528\u4ee5\u4e0b\u53c3\u6578\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7372\u53d6\u591a\u6a21\u614b\u5d4c\u5165](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings?hl=zh-cn) \u3002\n| \u53c3\u6578        | \u8aaa\u660e                                                                                                    | \u53ef\u63a5\u53d7\u7684\u503c                     |\n|:----------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------|\n| instances       | \u4e00\u500b\u6578\u7d44\uff0c\u5176\u4e2d\u5305\u542b\u5177\u6709\u8981\u7372\u53d6\u5176\u76f8\u95dc\u4fe1\u606f\u7684\u6578\u64da\uff08\u6587\u672c\u3001\u5716\u7247\u548c\u8996\u983b\uff09\u7684\u5c0d\u8c61\u3002                                                                                   | \u6578\u7d44\uff08\u5141\u8a31 1 \u500b\u5c0d\u8c61\uff09                  |\n| text        | \u8981\u7232\u5176\u5275\u5efa\u5d4c\u5165\u7684\u8f38\u5165\u6587\u672c\u3002                                                                                              | \u5b57\u7b26\u4e32\uff08\u6700\u591a 32 \u500b\u8a5e\u5143\uff09                  |\n| image.bytesBase64Encoded   | \u8981\u7372\u53d6\u5176\u5d4c\u5165\u7684\u5716\u7247\u3002\u5982\u679c\u60a8\u6307\u5b9a\u4e86 image.bytesBase64Encoded\uff0c\u5247\u7121\u6cd5\u8a2d\u7f6e image.gcsUri\u3002                                                                                | Base64 \u7de8\u78bc\u7684\u5716\u7247\u5b57\u7b26\u4e32\uff08BMP\u3001GIF\u3001JPG \u6216 PNG \u6587\u4ef6\uff0c\u6700\u5927 20\u00a0MB\uff09        |\n| image.gcsUri      | \u8981\u7372\u53d6\u5176\u5d4c\u5165\u7684\u5716\u7247\u7684 Cloud Storage URI\u3002\u5982\u679c\u60a8\u6307\u5b9a\u4e86 image.gcsUri\uff0c\u5247\u7121\u6cd5\u8a2d\u7f6e image.bytesBase64Encoded\u3002                                                                           | Cloud Storage \u4e2d\u5716\u7247\u6587\u4ef6\u7684\u5b57\u7b26\u4e32 URI\uff08BMP\u3001GIF\u3001JPG \u6216 PNG \u6587\u4ef6\uff0c\u6700\u5927 20\u00a0MB\uff09    |\n| image.mimeType     | \u53ef\u9078\u3002\u60a8\u6307\u5b9a\u7684\u5716\u7247\u7684 MIME \u985e\u578b\u3002                                                                                             | \u5b57\u7b26\u4e32\uff08image/bmp\u3001image/gif\u3001image/jpeg \u6216 image/png\uff09          |\n| video.bytesBase64Encoded   | \u8981\u7372\u53d6\u5176\u5d4c\u5165\u7684\u8996\u983b\u3002\u5982\u679c\u60a8\u6307\u5b9a\u4e86 video.bytesBase64Encoded\uff0c\u5247\u7121\u6cd5\u8a2d\u7f6e video.gcsUri\u3002                                                                                | Base64 \u7de8\u78bc\u7684\u8996\u983b\u5b57\u7b26\u4e32\uff08AVI\u3001FLV\u3001MKV\u3001MOV\u3001MP4\u3001MPEG\u3001MPG\u3001WEBM \u6216 WMV \u6587\u4ef6\uff09    |\n| video.gcsUri      | \u8981\u7372\u53d6\u5176\u5d4c\u5165\u7684\u8996\u983b\u7684 Cloud Storage URI\u3002\u5982\u679c\u60a8\u6307\u5b9a\u4e86 video.gcsUri\uff0c\u5247\u7121\u6cd5\u8a2d\u7f6e video.bytesBase64Encoded\u3002                                                                           | Cloud Storage \u4e2d\u8996\u983b\u6587\u4ef6\u7684\u5b57\u7b26\u4e32 URI\uff08AVI\u3001FLV\u3001MKV\u3001MOV\u3001MP4\u3001MPEG\u3001MPG\u3001WEBM \u6216 WMV \u6587\u4ef6\uff09 |\n| videoSegmentConfig.startOffsetSec | \u53ef\u9078\u3002\u6a21\u578b\u958b\u59cb\u5d4c\u5165\u6aa2\u6e2c\u7684\u6642\u9593\uff08\u4ee5\u79d2\u7232\u55ae\u4f4d\uff09\u3002\u9ed8\u8a8d\u503c\uff1a0                                                                                       | \u6574\u6578                       |\n| videoSegmentConfig.endOffsetSec | \u53ef\u9078\u3002\u6a21\u578b\u7d50\u675f\u5d4c\u5165\u6aa2\u6e2c\u7684\u6642\u9593\uff08\u4ee5\u79d2\u7232\u55ae\u4f4d\uff09\u3002\u9ed8\u8a8d\u503c\uff1a120                                                                                       | \u6574\u6578                       |\n| videoSegmentConfig.intervalSec | \u53ef\u9078\u3002\u7232\u5176\u751f\u6210\u5d4c\u5165\u7684\u8996\u983b\u6578\u64da\u7247\u6bb5\u7684\u6642\u9593\uff08\u4ee5\u79d2\u7232\u55ae\u4f4d\uff09\u3002\u6b64\u503c\u5c0d\u61c9\u65bc\u8996\u983b\u5d4c\u5165\u6a21\u5f0f\uff08\u57fa\u672c\u3001\u6a19\u6e96\u6216 Plus\uff09\uff0c\u8a72\u6a21\u5f0f\u6703\u5f71\u97ff\u529f\u80fdpricing\u3002 \u57fa\u672c\u6a21\u5f0f (intervalSec >= 15)\uff1a\u7232\u5176\u751f\u6210\u5d4c\u5165\u7684\u8996\u983b\u7247\u6bb5\u6700\u5c11\u3002\u6700\u4f4e\u8cbb\u7528\u9078\u9805\u3002 \u6a19\u6e96\u5c64\u7d1a (8 <= intervalSec < 15)\uff1a\u7232\u5176\u751f\u6210\u5d4c\u5165\u7684\u8996\u983b\u7247\u6bb5\u591a\u65bc\u57fa\u672c\u6a21\u5f0f\uff0c\u4f46\u5c11\u65bc Plus \u6a21\u5f0f\u3002\u4e2d\u9593\u8cbb\u7528\u9078\u9805\u3002 Plus \u6a21\u5f0f (4 <= intervalSec < 8)\uff1a\u7232\u5176\u751f\u6210\u5d4c\u5165\u7684\u8996\u983b\u7247\u6bb5\u6700\u591a\u3002\u6700\u9ad8\u8cbb\u7528\u9078\u9805\u3002 \u9ed8\u8a8d\u503c\uff1a16\uff08\u57fa\u672c\u6a21\u5f0f\uff09 | \u6574\u6578\uff08\u6700\u5c0f\u503c\uff1a4\uff09                   |\n| parameters.dimension    | \u53ef\u9078\u3002\u8981\u7232\u5176\u751f\u6210\u5d4c\u5165\u7684\u5411\u91cf\u7dad\u5ea6\uff08\u50c5\u9650\u6587\u672c\u6216\u5716\u7247\uff09\u3002\u5982\u679c\u672a\u8a2d\u7f6e\uff0c\u5247\u7cfb\u7d71\u6703\u4f7f\u7528\u9ed8\u8a8d\u503c 1408\u3002                                                                               | \u6574\u6578\uff08128\u3001256\u3001512 \u6216 1408 [\u9ed8\u8a8d\u503c]\uff09              |\n## \u793a\u4f8b\u8acb\u6c42\n\u4ee5\u4e0b\u793a\u4f8b\u4f7f\u7528\u5716\u7247\u3001\u6587\u672c\u548c\u8996\u983b\u6578\u64da\u3002\u60a8\u53ef\u4ee5\u5728\u8acb\u6c42\u6b63\u6587\u4e2d\u4f7f\u7528\u9019\u4e9b\u6578\u64da\u985e\u578b\u7684\u4efb\u610f\u7d44\u5408\u3002\n\u6b64\u5916\uff0c\u6b64\u793a\u4f8b\u9084\u6703\u4f7f\u7528 Cloud Storage \u4e2d\u7684\u8996\u983b\u3002\u60a8\u9084\u53ef\u4ee5\u4f7f\u7528 `video.bytesBase64Encoded` \u5b57\u6bb5\u63d0\u4f9b\u8996\u983b\u7684 [base64 \u7de8\u78bc](https://cloud.google.com/vertex-ai/generative-ai/docs/image/base64-encode?hl=zh-cn) \u5b57\u7b26\u4e32\u8868\u793a\u5f62\u5f0f\u3002\n\u5728\u4f7f\u7528\u4efb\u4f55\u8acb\u6c42\u6578\u64da\u4e4b\u524d\uff0c\u8acb\u5148\u9032\u884c\u4ee5\u4e0b\u66ff\u63db\uff1a- \uff1a\u60a8\u7684\u9805\u76ee\u7684\u5340\u57df\u3002 \u4f8b\u5982`us-central1`\u3001`europe-west2`\u6216`asia-northeast3`\u3002\u5982\u9700\u67e5\u770b\u53ef\u7528\u5340\u57df\u7684\u5217\u8868\uff0c\u8acb\u53c3\u95b1 [Vertex AI \u4e0a\u7684\u751f\u6210\u5f0f AI \u4f4d\u7f6e](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations-genai?hl=zh-cn) \u3002\n- \uff1a\u60a8\u7684 Google Cloud [\u9805\u76ee ID](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#identifiers) \u3002\n- \uff1a\u8981\u7372\u53d6\u5d4c\u5165\u7684\u76ee\u6a19\u6587\u672c\u3002\u4f8b\u5982\uff1a`a cat`\u3002\n- \uff1a\u8981\u7232\u5176\u7372\u53d6\u5d4c\u5165\u7684\u76ee\u6a19\u8996\u983b\u7684 Cloud Storage URI\u3002 \u4f8b\u5982`gs://my-bucket/embeddings/supermarket-img.png`\u3002\n- \uff1a\u8981\u7232\u5176\u7372\u53d6\u5d4c\u5165\u7684\u76ee\u6a19\u8996\u983b\u7684 Cloud Storage URI\u3002 \u4f8b\u5982`gs://my-bucket/embeddings/supermarket-video.mp4`\u3002\n- `videoSegmentConfig`\uff08\u3001\u3001\uff09\u3002\u53ef\u9078\u3002\u7232\u5176\u751f\u6210\u5d4c\u5165\u7684\u7279\u5b9a\u8996\u983b\u7247\u6bb5\uff08\u4ee5\u79d2\u7232\u55ae\u4f4d\uff09\u3002\u60a8\u7232`videoSegmentConfig.intervalSec`\u8a2d\u7f6e\u7684\u503c\u6703\u5f71\u97ff\u6536\u8cbb\u7684\u50f9\u683c\u5c64\u7d1a\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u8996\u983b\u5d4c\u5165\u6a21\u5f0f](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings?hl=zh-cn#video-modes) \u90e8\u5206\u548c [pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing?hl=zh-cn) \u9801\u9762\u3002\u4f8b\u5982\uff1a```\n[...]\n\"videoSegmentConfig\": {\n \"startOffsetSec\": 10,\n \"endOffsetSec\": 60,\n \"intervalSec\": 10\n}\n[...]\n```\u4f7f\u7528\u6b64\u914d\u7f6e\u53ef\u6307\u5b9a\u5f9e 10 \u79d2\u5230 60 \u79d2\u7684\u8996\u983b\u6578\u64da\uff0c\u4f75\u7232\u4ee5\u4e0b 10 \u79d2\u7684\u8996\u983b\u9593\u9694\u751f\u6210\u5d4c\u5165\uff1a[10, 20), [20, 30), [30, 40), [40, 50), [50, 60)\u3002  \u6b64\u8996\u983b\u9593\u9694 ( `\"intervalSec\": 10` ) \u5c6c\u65bc [\u6a19\u6e96\u8996\u983b\u5d4c\u5165\u6a21\u5f0f](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings?hl=zh-cn#video-modes) \uff0c\u7528\u6236\u6309 [\u6a19\u6e96\u6a21\u5f0f\u50f9\u683c\u8cbb\u7387](https://cloud.google.com/vertex-ai/generative-ai/pricing?hl=zh-cn) \u8a08\u8cbb\u3002\u5982\u679c\u7701\u7565 `videoSegmentConfig` \uff0c\u5247\u670d\u52d9\u4f7f\u7528\u4ee5\u4e0b\u9ed8\u8a8d\u503c\uff1a `\"videoSegmentConfig\": { \"startOffsetSec\": 0, \"endOffsetSec\": 120, \"intervalSec\": 16 }` \u3002  \u6b64\u8996\u983b\u9593\u9694 ( `\"intervalSec\": 16` ) \u5c6c\u65bc [\u57fa\u672c\u8996\u983b\u5d4c\u5165\u6a21\u5f0f](https://cloud.google.com/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings?hl=zh-cn#video-modes) \uff0c\u7528\u6236\u6309 [\u57fa\u672c\u6a21\u5f0f\u50f9\u683c\u8cbb\u7387](https://cloud.google.com/vertex-ai/generative-ai/pricing?hl=zh-cn) \u8a08\u8cbb\u3002\nHTTP \u65b9\u6cd5\u548c\u7db2\u5740\uff1a\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/multimodalembedding@001:predict\n```\n\u8acb\u6c42 JSON \u6b63\u6587\uff1a\n```\n{\n \"instances\": [ {\n  \"text\": \"TEXT\",\n  \"image\": {\n  \"gcsUri\": \"IMAGE_URI\"\n  },\n  \"video\": {\n  \"gcsUri\": \"VIDEO_URI\",\n  \"videoSegmentConfig\": {\n   \"startOffsetSec\": START_SECOND,\n   \"endOffsetSec\": END_SECOND,\n   \"intervalSec\": INTERVAL_SECONDS\n  }\n  }\n }\n ]\n}\n```\n\u5982\u9700\u767c\u9001\u8acb\u6c42\uff0c\u8acb\u9078\u64c7\u4ee5\u4e0b\u65b9\u5f0f\u4e4b\u4e00\uff1a\n **\u6ce8\u610f** \uff1a\u4ee5\u4e0b\u547d\u4ee4\u5047\u5b9a\u60a8\u5df2\u4f7f\u7528\u60a8\u7684\u7528\u6236\u8cec\u865f\u901a\u904e\u904b\u884c [gcloud init](https://cloud.google.com/sdk/gcloud/reference/init?hl=zh-cn) \u6216 [gcloud auth login](https://cloud.google.com/sdk/gcloud/reference/auth/login?hl=zh-cn) \u767b\u9304`gcloud`CLI\uff0c\u6216\u8005\u4f7f\u7528\u4e86 [Cloud Shell](https://cloud.google.com/shell/docs?hl=zh-cn) \uff0c\u9019\u6703\u4f7f\u60a8\u81ea\u52d5\u767b\u9304`gcloud`CLI\u3002\u60a8\u53ef\u4ee5\u904b\u884c [gcloud auth list](https://cloud.google.com/sdk/gcloud/reference/auth/list?hl=zh-cn) \u4f86\u6aa2\u67e5\u7576\u524d\u6d3b\u8e8d\u7684\u8cec\u865f\u3002\n\u5c07\u8acb\u6c42\u6b63\u6587\u4fdd\u5b58\u5728\u540d\u7232 `request.json` \u7684\u6587\u4ef6\u4e2d\uff0c\u7136\u5f8c\u57f7\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/multimodalembedding@001:predict\"\n``` **\u6ce8\u610f** \uff1a\u4ee5\u4e0b\u547d\u4ee4\u5047\u5b9a\u60a8\u5df2\u4f7f\u7528\u60a8\u7684\u7528\u6236\u8cec\u865f\u901a\u904e\u904b\u884c [gcloud init](https://cloud.google.com/sdk/gcloud/reference/init?hl=zh-cn) \u6216 [gcloud auth login](https://cloud.google.com/sdk/gcloud/reference/auth/login?hl=zh-cn) \u767b\u9304`gcloud`CLI\uff0c\u6216\u8005\u4f7f\u7528\u4e86 [Cloud Shell](https://cloud.google.com/shell/docs?hl=zh-cn) \uff0c\u9019\u6703\u4f7f\u60a8\u81ea\u52d5\u767b\u9304`gcloud`CLI\u3002\u60a8\u53ef\u4ee5\u904b\u884c [gcloud auth list](https://cloud.google.com/sdk/gcloud/reference/auth/list?hl=zh-cn) \u4f86\u6aa2\u67e5\u7576\u524d\u6d3b\u8e8d\u7684\u8cec\u865f\u3002\n\u5c07\u8acb\u6c42\u6b63\u6587\u4fdd\u5b58\u5728\u540d\u7232 `request.json` \u7684\u6587\u4ef6\u4e2d\uff0c\u7136\u5f8c\u57f7\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/multimodalembedding@001:predict\" | Select-Object -Expand Content\n```\u6a21\u578b\u8fd4\u56de\u7684\u5d4c\u5165\u662f 1408 \u500b\u6d6e\u9ede\u77e2\u91cf\u3002\u4ee5\u4e0b\u793a\u4f8b\u97ff\u61c9\u6703\u7e2e\u77ed\u3002\n```\n{\n \"predictions\": [ {\n  \"textEmbedding\": [  0.0105433334,\n  -0.00302835181,\n  0.00656806398,\n  0.00603460241,\n  [...]\n  0.00445805816,\n  0.0139605571,\n  -0.00170318608,\n  -0.00490092579\n  ],\n  \"videoEmbeddings\": [  {\n   \"startOffsetSec\": 0,\n   \"endOffsetSec\": 7,\n   \"embedding\": [   -0.00673126569,\n   0.0248149596,\n   0.0128901172,\n   0.0107588246,\n   [...]\n   -0.00180952181,\n   -0.0054573305,\n   0.0117037306,\n   0.0169312079\n   ]\n  }\n  ],\n  \"imageEmbedding\": [  -0.00728622358,\n  0.031021487,\n  -0.00206603738,\n  0.0273937676,\n  [...]\n  -0.00204976718,\n  0.00321615417,\n  0.0121978866,\n  0.0193375275\n  ]\n }\n ],\n \"deployedModelId\": \"DEPLOYED_MODEL_ID\"\n}\n```\n\u5982\u9700\u77ad\u89e3\u5982\u4f55\u5b89\u88dd\u6216\u66f4\u65b0 Python\uff0c\u8acb\u53c3\u95b1 [\u5b89\u88dd Python \u7248 Vertex AI SDK](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk?hl=zh-cn) \u3002   \u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [   Python API \u53c3\u8003\u6587\u6a94](https://cloud.google.com/python/docs/reference/aiplatform/latest?hl=zh-cn) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/generative_ai/multimodal_embedding_image_video_text.py) \n```\nfrom typing import Optionalimport vertexaifrom vertexai.vision_models import (\u00a0 \u00a0 Image,\u00a0 \u00a0 MultiModalEmbeddingModel,\u00a0 \u00a0 MultiModalEmbeddingResponse,\u00a0 \u00a0 Video,\u00a0 \u00a0 VideoSegmentConfig,)def get_image_video_text_embeddings(\u00a0 \u00a0 project_id: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 image_path: str,\u00a0 \u00a0 video_path: str,\u00a0 \u00a0 contextual_text: Optional[str] = None,\u00a0 \u00a0 dimension: Optional[int] = 1408,\u00a0 \u00a0 video_segment_config: Optional[VideoSegmentConfig] = None,) -> MultiModalEmbeddingResponse:\u00a0 \u00a0 \"\"\"Example of how to generate multimodal embeddings from image, video, and text.\u00a0 \u00a0 Args:\u00a0 \u00a0 \u00a0 \u00a0 project_id: Google Cloud Project ID, used to initialize vertexai\u00a0 \u00a0 \u00a0 \u00a0 location: Google Cloud Region, used to initialize vertexai\u00a0 \u00a0 \u00a0 \u00a0 image_path: Path to image (local or Google Cloud Storage) to generate embeddings for.\u00a0 \u00a0 \u00a0 \u00a0 video_path: Path to video (local or Google Cloud Storage) to generate embeddings for.\u00a0 \u00a0 \u00a0 \u00a0 contextual_text: Text to generate embeddings for.\u00a0 \u00a0 \u00a0 \u00a0 dimension: Dimension for the returned embeddings.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-multimodal-embeddings#low-dimension\u00a0 \u00a0 \u00a0 \u00a0 video_segment_config: Define specific segments to generate embeddings for.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-multimodal-embeddings#video-best-practices\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 vertexai.init(project=project_id, location=location)\u00a0 \u00a0 model = MultiModalEmbeddingModel.from_pretrained(\"multimodalembedding\")\u00a0 \u00a0 image = Image.load_from_file(image_path)\u00a0 \u00a0 video = Video.load_from_file(video_path)\u00a0 \u00a0 embeddings = model.get_embeddings(\u00a0 \u00a0 \u00a0 \u00a0 image=image,\u00a0 \u00a0 \u00a0 \u00a0 video=video,\u00a0 \u00a0 \u00a0 \u00a0 video_segment_config=video_segment_config,\u00a0 \u00a0 \u00a0 \u00a0 contextual_text=contextual_text,\u00a0 \u00a0 \u00a0 \u00a0 dimension=dimension,\u00a0 \u00a0 )\u00a0 \u00a0 print(f\"Image Embedding: {embeddings.image_embedding}\")\u00a0 \u00a0 # Video Embeddings are segmented based on the video_segment_config.\u00a0 \u00a0 print(\"Video Embeddings:\")\u00a0 \u00a0 for video_embedding in embeddings.video_embeddings:\u00a0 \u00a0 \u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 f\"Video Segment: {video_embedding.start_offset_sec} - {video_embedding.end_offset_sec}\"\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Embedding: {video_embedding.embedding}\")\u00a0 \u00a0 print(f\"Text Embedding: {embeddings.text_embedding}\")\n```\u5728\u5617\u8a66\u6b64\u793a\u4f8b\u4e4b\u524d\uff0c\u8acb\u6309\u7167 [\u300a\u751f\u6210\u5f0f AI \u5feb\u901f\u5165\u9580\uff1a\u4f7f\u7528\u5ba2\u6236\u7aef\u5eab\u300b](https://cloud.google.com/vertex-ai/docs/start/client-libraries?hl=zh-cn) \u4e2d\u7684 Node.js \u8a2d\u7f6e\u8aaa\u660e\u57f7\u884c\u64cd\u4f5c\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u751f\u6210\u5f0f AI Node.js API \u53c3\u8003\u6587\u6a94](https://cloud.google.com/nodejs/docs/reference/aiplatform/latest?hl=zh-cn) \u3002\n\u5982\u9700\u5411\u751f\u6210\u5f0f AI \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/predict-image-from-image-and-text.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\\\u00a0* (Not necessary if passing values as arguments)\u00a0*/// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';// const bastImagePath = \"YOUR_BASED_IMAGE_PATH\"// const textPrompt = 'YOUR_TEXT_PROMPT';const aiplatform = require('@google-cloud/aiplatform');// Imports the Google Cloud Prediction service clientconst {PredictionServiceClient} = aiplatform.v1;// Import the helper module for converting arbitrary protobuf.Value objects.const {helpers} = aiplatform;// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};const publisher = 'google';const model = 'multimodalembedding@001';// Instantiates a clientconst predictionServiceClient = new PredictionServiceClient(clientOptions);async function predictImageFromImageAndText() {\u00a0 // Configure the parent resource\u00a0 const endpoint = `projects/${project}/locations/${location}/publishers/${publisher}/models/${model}`;\u00a0 const fs = require('fs');\u00a0 const imageFile = fs.readFileSync(baseImagePath);\u00a0 // Convert the image data to a Buffer and base64 encode it.\u00a0 const encodedImage = Buffer.from(imageFile).toString('base64');\u00a0 const prompt = {\u00a0 \u00a0 text: textPrompt,\u00a0 \u00a0 image: {\u00a0 \u00a0 \u00a0 bytesBase64Encoded: encodedImage,\u00a0 \u00a0 },\u00a0 };\u00a0 const instanceValue = helpers.toValue(prompt);\u00a0 const instances = [instanceValue];\u00a0 const parameter = {\u00a0 \u00a0 sampleCount: 1,\u00a0 };\u00a0 const parameters = helpers.toValue(parameter);\u00a0 const request = {\u00a0 \u00a0 endpoint,\u00a0 \u00a0 instances,\u00a0 \u00a0 parameters,\u00a0 };\u00a0 // Predict request\u00a0 const [response] = await predictionServiceClient.predict(request);\u00a0 console.log('Get image embedding response');\u00a0 const predictions = response.predictions;\u00a0 console.log('\\tPredictions :');\u00a0 for (const prediction of predictions) {\u00a0 \u00a0 console.log(`\\t\\tPrediction : ${JSON.stringify(prediction)}`);\u00a0 }}await predictImageFromImageAndText();\n```\u5728\u5617\u8a66\u6b64\u793a\u4f8b\u4e4b\u524d\uff0c\u8acb\u6309\u7167 [\u300a\u751f\u6210\u5f0f AI \u5feb\u901f\u5165\u9580\uff1a\u4f7f\u7528\u5ba2\u6236\u7aef\u5eab\u300b](https://cloud.google.com/vertex-ai/docs/start/client-libraries?hl=zh-cn) \u4e2d\u7684 Java \u8a2d\u7f6e\u8aaa\u660e\u57f7\u884c\u64cd\u4f5c\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u751f\u6210\u5f0f AI Java API \u53c3\u8003\u6587\u6a94](https://cloud.google.com/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1?hl=zh-cn) \u3002\n\u5982\u9700\u5411\u751f\u6210\u5f0f AI \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/PredictImageFromImageAndTextSample.java) \n```\nimport com.google.cloud.aiplatform.v1beta1.EndpointName;import com.google.cloud.aiplatform.v1beta1.PredictResponse;import com.google.cloud.aiplatform.v1beta1.PredictionServiceClient;import com.google.cloud.aiplatform.v1beta1.PredictionServiceSettings;import com.google.gson.Gson;import com.google.gson.JsonObject;import com.google.protobuf.InvalidProtocolBufferException;import com.google.protobuf.Value;import com.google.protobuf.util.JsonFormat;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.nio.file.Files;import java.nio.file.Paths;import java.util.ArrayList;import java.util.Base64;import java.util.HashMap;import java.util.List;import java.util.Map;public class PredictImageFromImageAndTextSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace this variable before running the sample.\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String textPrompt = \"YOUR_TEXT_PROMPT\";\u00a0 \u00a0 String baseImagePath = \"YOUR_BASE_IMAGE_PATH\";\u00a0 \u00a0 // Learn how to use text prompts to update an image:\u00a0 \u00a0 // https://cloud.google.com/vertex-ai/docs/generative-ai/image/edit-images\u00a0 \u00a0 Map<String, Object> parameters = new HashMap<String, Object>();\u00a0 \u00a0 parameters.put(\"sampleCount\", 1);\u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 String publisher = \"google\";\u00a0 \u00a0 String model = \"multimodalembedding@001\";\u00a0 \u00a0 predictImageFromImageAndText(\u00a0 \u00a0 \u00a0 \u00a0 project, location, publisher, model, textPrompt, baseImagePath, parameters);\u00a0 }\u00a0 // Update images using text prompts\u00a0 public static void predictImageFromImageAndText(\u00a0 \u00a0 \u00a0 String project,\u00a0 \u00a0 \u00a0 String location,\u00a0 \u00a0 \u00a0 String publisher,\u00a0 \u00a0 \u00a0 String model,\u00a0 \u00a0 \u00a0 String textPrompt,\u00a0 \u00a0 \u00a0 String baseImagePath,\u00a0 \u00a0 \u00a0 Map<String, Object> parameters)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 final String endpoint = String.format(\"%s-aiplatform.googleapis.com:443\", location);\u00a0 \u00a0 final PredictionServiceSettings predictionServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 PredictionServiceSettings.newBuilder().setEndpoint(endpoint).build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests.\u00a0 \u00a0 try (PredictionServiceClient predictionServiceClient =\u00a0 \u00a0 \u00a0 \u00a0 PredictionServiceClient.create(predictionServiceSettings)) {\u00a0 \u00a0 \u00a0 final EndpointName endpointName =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 EndpointName.ofProjectLocationPublisherModelName(project, location, publisher, model);\u00a0 \u00a0 \u00a0 // Convert the image to Base64\u00a0 \u00a0 \u00a0 byte[] imageData = Base64.getEncoder().encode(Files.readAllBytes(Paths.get(baseImagePath)));\u00a0 \u00a0 \u00a0 String encodedImage = new String(imageData, StandardCharsets.UTF_8);\u00a0 \u00a0 \u00a0 JsonObject jsonInstance = new JsonObject();\u00a0 \u00a0 \u00a0 jsonInstance.addProperty(\"text\", textPrompt);\u00a0 \u00a0 \u00a0 JsonObject jsonImage = new JsonObject();\u00a0 \u00a0 \u00a0 jsonImage.addProperty(\"bytesBase64Encoded\", encodedImage);\u00a0 \u00a0 \u00a0 jsonInstance.add(\"image\", jsonImage);\u00a0 \u00a0 \u00a0 Value instanceValue = stringToValue(jsonInstance.toString());\u00a0 \u00a0 \u00a0 List<Value> instances = new ArrayList<>();\u00a0 \u00a0 \u00a0 instances.add(instanceValue);\u00a0 \u00a0 \u00a0 Gson gson = new Gson();\u00a0 \u00a0 \u00a0 String gsonString = gson.toJson(parameters);\u00a0 \u00a0 \u00a0 Value parameterValue = stringToValue(gsonString);\u00a0 \u00a0 \u00a0 PredictResponse predictResponse =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 predictionServiceClient.predict(endpointName, instances, parameterValue);\u00a0 \u00a0 \u00a0 System.out.println(\"Predict Response\");\u00a0 \u00a0 \u00a0 System.out.println(predictResponse);\u00a0 \u00a0 \u00a0 for (Value prediction : predictResponse.getPredictionsList()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\tPrediction: %s\\n\", prediction);\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }\u00a0 // Convert a Json string to a protobuf.Value\u00a0 static Value stringToValue(String value) throws InvalidProtocolBufferException {\u00a0 \u00a0 Value.Builder builder = Value.newBuilder();\u00a0 \u00a0 JsonFormat.parser().merge(value, builder);\u00a0 \u00a0 return builder.build();\u00a0 }}\n```\n## \u97ff\u61c9\u6b63\u6587\n```\n{\u00a0 \"predictions\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"textEmbedding\": [\u00a0 \u00a0 \u00a0 \u00a0 float,\u00a0 \u00a0 \u00a0 \u00a0 // array of 128, 256, 512, or 1408 float values\u00a0 \u00a0 \u00a0 \u00a0 float\u00a0 \u00a0 \u00a0 ],\u00a0 \u00a0 \u00a0 \"imageEmbedding\": [\u00a0 \u00a0 \u00a0 \u00a0 float,\u00a0 \u00a0 \u00a0 \u00a0 // array of 128, 256, 512, or 1408 float values\u00a0 \u00a0 \u00a0 \u00a0 float\u00a0 \u00a0 \u00a0 ],\u00a0 \u00a0 \u00a0 \"videoEmbeddings\": [\u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"startOffsetSec\": integer,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"endOffsetSec\": integer,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"embedding\": [\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // array of 1408 float values\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ]\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 ]\u00a0 \u00a0 }\u00a0 ],\u00a0 \"deployedModelId\": string}\n```\n| \u97ff\u61c9\u5143\u7d20  | \u8aaa\u660e                    |\n|:----------------|:----------------------------------------------------------------------------------|\n| imageEmbedding | \u5c3a\u5bf8\u7232 128\u3001256\u3001512 \u6216 1408 \u7684\u6d6e\u9ede\u6578\u5217\u8868\u3002          |\n| textEmbedding | \u5c3a\u5bf8\u7232 128\u3001256\u3001512 \u6216 1408 \u7684\u6d6e\u9ede\u6578\u5217\u8868\u3002          |\n| videoEmbeddings | 1408 \u7dad\u5ea6\u7684\u6d6e\u9ede\u6578\u5217\u8868\uff0c\u5176\u4e2d\u5305\u542b\u751f\u6210\u5d4c\u5165\u7684\u8996\u983b\u7247\u6bb5\u7684\u958b\u59cb\u548c\u7d50\u675f\u6642\u9593\uff08\u4ee5\u79d2\u7232\u55ae\u4f4d\uff09\u3002 |", "guide": "Generative AI on Vertex AI"}