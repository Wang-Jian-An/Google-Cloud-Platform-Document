{"title": "Generative AI on Vertex AI - Overview of Generative AI on Vertex AI", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Generative AI on Vertex AI - Overview of Generative AI on Vertex AI\nGenerative AI on Vertex AI (also known as or ) gives you access to Google's large generative AI models so you can test, tune, and deploy them for use in your AI-powered applications. This page gives you an overview of the generative AI workflow on Vertex AI, the features and models available, and directs you to resources for getting started.\n", "content": "## Generative AI workflow\nThe following diagram shows a high level overview of the generative AI workflow.| 0 | 1                                                                                                          |\n|----:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | The generative AI workflow typically starts with prompting. A prompt is a natural language request sent to a language model to elicit a response back. Writing a prompt to get the desired response from the model is a practice called prompt design. While prompt design is a process of trial and error, there are prompt design principles and strategies that you can use to nudge the model to behave in the desired way. || 0 | 1                                                                                                                                                                     |\n|----:|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | Prompts are sent to a model for response generation. Vertex AI has a variety of generative AI foundation models that are accessible through an API, including the following: Gemini API: Advanced reasoning, multiturn chat, code generation, and multimodal prompts. PaLM API: Natural language tasks, text embeddings, and multiturn chat. Codey APIs: Code generation, code completion, and code chat. Imagen API: Image generation, image editing, and visual captioning. MedLM: Medical question answering and summarization. (Private GA) The models differ in size, modality, and cost. You can explore Google's proprietary models and OSS models in Model Garden. || 0 | 1                                                                                                                                             |\n|----:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | You can customize the default behavior of Google's foundation models so that they consistently generate the desired results without using complex prompts. This customization process is called model tuning. Model tuning helps you reduce the cost and latency of your requests by allowing you to simplify your prompts. Vertex AI also offers model evaluation tools to help you evaluate the performance of your tuned model. After your tuned model is production-ready, you can deploy it to an endpoint and monitor performance like in standard MLOps workflows. || 0 | 1                                                                  |\n|----:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | If you need model responses to be grounded on a source of truth, such as your own data corpus, you can use grounding in Vertex AI. Grounding helps reduce model hallucinations, especially on unknown topics, and also gives the model access to new information. || 0 | 1                                                                |\n|----:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | After the response is generated, Vertex AI checks whether citations need to be included with the response. If a significant amount of the text in the response comes from a particular source, that source is added to the citation metadata in the response. || 0 | 1                                                                                        |\n|----:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | The last layer of checks that the prompt and response go through before being returned is the safety filters. Vertex AI checks both the prompt and response for how much the prompt or response belongs to a safety category. If the threshold is exceed for one or more categories, the response is blocked and Vertex AI returns a fallback response. || 0 | 1                                                          |\n|----:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | If the prompt and response passes the safety filter checks, the response is returned. Typically, the response is returned all at once. However, you can also receive responses progressively as it generates by enabling streaming. |\n## Generative AI APIs and models\nThe generative AI models available in Vertex AI, also called foundation models, are categorized by the type of content that it's designed to generate. This content includes text, chat, image, code, video, multimodal data, and embeddings. Each model is exposed through a publisher endpoint that's specific to your Google Cloud project so there's no need to deploy the foundation model unless you need to tune it for a specific use case.\n### Gemini API offerings\nThe [Vertex AI Gemini API](/vertex-ai/generative-ai/docs/multimodal/overview) contains the publisher endpoints for the Gemini models developed by Google DeepMind.\n- **Gemini 1.0 Pro** is designed to handle  natural language tasks, multiturn text and code chat, and code  generation.\n- **Gemini 1.0 Pro Vision** supports multimodal  prompts. You can include text, images, and video in your prompt requests and  get text or code responses.\n### PaLM API offerings\nThe Vertex AI PaLM API contains the publisher endpoints for Google's Pathways Language Model 2 (PaLM 2), which are large language models (LLMs) that generate text and code in response to natural language prompts.\n- **PaLM API for text** is fine-tuned for language tasks such  as classification, summarization, and entity extraction.\n- **PaLM API for chat** is fine-tuned for multi-turn chat,  where the model keeps track of previous messages in the chat and uses it as  context for generating new responses.\n### Other Generative AI offerings\n- The **Codey APIs** generate code. The Codey APIs include three models that generate code, suggest code for code completion, and let developers chat to get help with code-related questions. For more information, see [Code models overview](/vertex-ai/generative-ai/docs/code/code-models-overview) .\n- The **Text Embedding API** generates vector embeddings for input text. You can use embeddings for tasks like semantic search, recommendation, classification, and outlier detection.\n- **Multimodal embeddings** generates embedding vectors based on image and text inputs. These embeddings can later be used for other subsequent tasks like image classification or content recommendations. For more information, see the [multimodal embeddings](/vertex-ai/generative-ai/docs/embeddings/get-multimodal-embeddings) page.\n- **Imagen** , our text-to-image foundation model, lets organizations generate and customize studio-grade images at scale for any business need. For more information, see the [Imagen on Vertex AI overview](/vertex-ai/generative-ai/docs/image/overview) .\n- **MedLM** is a family of foundation models fine-tuned for the healthcare industry. For more information, see the [MedLM models overview](/vertex-ai/generative-ai/docs/medlm/overview) .## Vertex AI Studio\nVertex AI Studio is a Google Cloud console tool for rapidly prototyping and testing generative AI models. You can test sample prompts, design your own prompts, and customize foundation models to handle tasks that meet your application's needs. This page introduces the different tasks that you can perform in Vertex AI Studio, including the following:\n- Test models using prompt samples.\n- Design and save your own prompts.\n- Tune a foundation model.\n- Convert between speech and text.\n### Test models using prompt samples\nPrompt Gallery, in the **Language** section of Vertex AI Studio, contains a variety of sample prompts that are predesigned to help demonstrate model capabilities. The sample prompts are categorized by the task type, such as summarization, classification, and extraction. Each prompt is preconfigured with a specified model and parameter values so you can just open the sample prompt and click **Submit** to get the model to generate a response.### Design and save your own prompts\nPrompt design is the process of manually creating prompts that elicit the desired response from a language model. By carefully crafting prompts, you can nudge the model to generate a desired result. Prompt design can be an efficient way to experiment with adapting a language model for a specific use case.\nYou can create and save your own prompts in Vertex AI Studio. When creating a new prompt, you enter the prompt text, specify the model to use, configure parameter values, and test the prompt by generating a response. You can iterate on the prompt and its configurations until you get the desired results. When you are done designing the prompt, you can save it in Vertex AI Studio.\n### Response citations\nIf you are using a text model in Vertex AI Studio like `text-bison` , you receive text responses based on your input. Our features are intended to produce original content and not replicate existing content at length. If Vertex AI Studio quotes at length from a web page, it cites that page in the output.\nYou can change the quality of responses by tweaking the temperature (output randomness), and experimenting with other response parameters in Vertex AI Studio.\nCitations are available in Vertex AI Studio and are available in the API. To learn more about Responsible AI and citations, see [Citation metadata](/vertex-ai/generative-ai/docs/learn/responsible-ai#citation_metadata) .\n### Explore generative AI models in Model Garden\nModel Garden is a platform that helps you discover, test, customize, and deploy Google proprietary and select OSS models and assets. To explore the generative AI models and APIs that are available on Vertex AI, go to Model Garden in the Google Cloud console.\n[Go to Model Garden](https://console.cloud.google.com/vertex-ai/model-garden)\nTo learn more about Model Garden, including available models and capabilities, see [Explore AI models in Model Garden](/vertex-ai/docs/start/explore-models) .\n### Tune a foundation model\nWhile prompt design is great for quick experimentation, if training data is available, higher quality can be achieved by tuning the model itself. Tuning a model lets you customize the model's response based on examples of the task that you want the model to perform.\nTo learn how to tune a foundation model, see [Tune foundation models](/vertex-ai/generative-ai/docs/models/tune-models) .\n### Convert between speech and text\nIn the speech tool of Vertex AI Studio, you can take a snippet of text and convert it into a speech audio file that you can playback and download. You can select from several voices and adjust the speaking rate.\nConversely, if you have an audio file of speech, you can also upload it to Vertex AI Studio and get it transcribed into text.\nTo learn more, see the following pages:\n- [Text-to-speech](/vertex-ai/generative-ai/docs/speech/text-to-speech) \n- [Speech-to-text](/vertex-ai/generative-ai/docs/speech/speech-to-text) \n### Try Vertex AI Studio\nVertex AI Studio is in the Vertex AI page of the Google Cloud console.\n[Go to Vertex AI Studio](https://console.cloud.google.com/vertex-ai/generative)\n## Certifications and security controls\nVertex AI supports CMEK, VPC Service Controls, Data Residency, and Access Transparency. There are some limitations for Generative AI features. For more information, see [Generative AI security controls](/vertex-ai/generative-ai/docs/genai-security-controls) .\n## Get started\n- Try a quickstart tutorial using [Vertex AI Studio](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart) or the [Vertex AI API](/vertex-ai/generative-ai/docs/start/quickstarts/api-quickstart) .\n- Explore pretrained models in [Model Garden](/vertex-ai/docs/start/explore-models) .\n- Learn how to [tune a foundation model](/vertex-ai/generative-ai/docs/models/tune-models) .\n- Learn about [responsible AI best practices and Vertex AI's safety filters](/vertex-ai/generative-ai/docs/learn/responsible-ai) .\n- Learn about [quotas and limits](/vertex-ai/generative-ai/docs/quotas) .\n- Learn about [pricing](/vertex-ai/pricing#generative_ai_models) .", "guide": "Generative AI on Vertex AI"}