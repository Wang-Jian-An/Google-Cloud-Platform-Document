{"title": "Generative AI on Vertex AI - Overview of model tuning", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/models/tune-models", "abstract": "# Generative AI on Vertex AI - Overview of model tuning\nTuning a foundation model can improve its performance. Foundation models are trained for general purposes and sometimes don't perform tasks as well as you'd like them to. This might be because the tasks you want the model to perform are specialized tasks that are difficult to teach a model by using only prompt design. In these cases, you can use model tuning to improve the performance of a model for specific tasks. Model tuning can also help it adhere to specific output requirements when instructions aren't sufficient. This page provides an overview of model tuning, describes the tuning options available on Vertex AI, and helps you determine when each tuning option should be used.\n", "content": "## Model tuning overview\nModel tuning works by providing a model with a training dataset that contains many examples of a unique task. For unique or niche tasks, you can get significant improvements in model performance by tuning the model on a modest number of examples. After you tune a model, fewer examples are required in its prompts.\nVertex AI supports the following methods to tune foundation models:\n- [Supervised tuning](/vertex-ai/generative-ai/docs/tuning/supervised-tuning) - Supervised tuning of a text model is a good option when the output of your model isn't complex and is relatively easy to define. Supervised tuning is recommended for classification, sentiment analysis, entity extraction, summarization of content that's not complex, and writing domain-specific queries. For code models, supervised tuning is the only option.\n- [Reinforcement learning from human feedback (RLHF) tuning](/vertex-ai/generative-ai/docs/tuning/rlhf-tuning) - RLHF tuning is a good option when the output of your model is complex and isn't easily achieved with supervised tuning. RLHF tuning is recommended for question answering, summarization of complex content, and content creation, such as a rewrite. RLHF tuning isn't supported by code models.\n- [Model distillation](/vertex-ai/generative-ai/docs/tuning/model-distillation) - Distillation is a good option if you have a large model that you want to make smaller without degrading its ability to do what you want. The process of a model creates a new, smaller trained model that costs less to use and has lower latency than the original model.## Quota\nEach Google Cloud project should have enough default quota to run one tuning job. However, if your project doesn't have enough quota for one tuning job, or if you want to run multiple concurrent tuning jobs in your project, you need to [request additional quota](/docs/quotas/view-manage#requesting_higher_quota) .\nThe following table shows the type and amount of quota to request depending on the region where you specified for tuning to take place:\n| Region  | Resource quota            | Amount per concurrent job |\n|:-------------|:-----------------------------------------------------------|----------------------------:|\n| us-central1 | Restricted image training Nvidia A100 80GB GPUs per region |       8 |\n| us-central1 | Restricted image training CPUs for A2 CPU types per region |       96 |\n| europe-west4 | Restricted image training TPU V3 pod cores per region  |       64 |\n## Pricing\nWhen you tune or distill a foundation model, you pay the cost to run the tuning or distillation pipeline. When you deploy a tuned or distilled foundation model to a Vertex AI endpoint, you aren't charged for hosting. For serving predictions, you pay the same price as you pay when serving predictions using an untuned foundation model (for tuning) or the student model (for distilling). To learn which foundation models can be tuned and distilled, see [Foundation models](/vertex-ai/generative-ai/docs/learn/models#foundation_models) . For pricing details, see [Pricing for Generative AI on Vertex AI](/vertex-ai/generative-ai/pricing) .\n## What's next\n- Learn about [supervised tuning](/vertex-ai/generative-ai/docs/tuning/supervised-tuning) .\n- Learn about [RLHF tuning](/vertex-ai/generative-ai/docs/tuning/rlhf-tuning) .\n- Learn about [model distillation](/vertex-ai/generative-ai/docs/tuning/model-distillation) .", "guide": "Generative AI on Vertex AI"}