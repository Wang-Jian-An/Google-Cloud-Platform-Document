{"title": "Generative AI on Vertex AI - MedLM models overview", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/medlm/overview", "abstract": "# Generative AI on Vertex AI - MedLM models overview\n**Disclaimer:** MedLM on Vertex AI is available to allow listed customers. This allow listed GA release (US-only GA) focuses on Medical Q&A and Medical Summarization use. By using the MedLM API, you agree to the [GenerativeAI Prohibited Use Policy](https://policies.google.com/terms/generative-ai/use-policy) and the Google Cloud Platform [Service-Specific Terms](/terms/service-terms) , and you agree to notify and coordinate with Google in good faith to address any regulatory inquiries regarding your use of MedLM. For this product, you can process personal data as outlined in the Data Processing Security Terms, subject to the restrictions described in the Google Cloud Platform Terms of Service. For more information, see the [launch stagedescriptions](/products#product-launch-stages) . Provided that you enter into a Business Associate Agreement with Google that covers your use of Google Cloud Platform Services, MedLM API can be used to process Protected Health Information subject to the Health Insurance Portability and Accountability Act (HIPAA) of 1996 and/or any amendments or regulations under HIPAA.\n**Caution:** - Before activating Production use for MedLM, customers must reach out to Google Product Team to discuss usage.\n- MedLM has not been designed or developed to be used as a medical device. Any output should be verified by a Healthcare Professional (HCP), and no direct diagnosis should be claimed.\n- The generated output may not always be completely reliable. Due to the nature of LLMs and Generative AI, outputs may have incorrect or biased (for example, stereotypes or other harmful content) information and should be reviewed. All summaries or answers should be considered draft and not final.\n- If Vertex AI detects content that violates our policies, including [Google Cloud Platform Acceptable Use Policy](/terms/aup) and [Generative AI Prohibited Use Policy](https://policies.google.com/terms/generative-ai/use-policy) , a response is not returned.\n- When used by HCPs for Q&A purposes, MedLM is only intended for use as an educational tool for medical training or to reinforce the HCP's prior training.\n- LLM output may not follow the exact format laid out in the prompt. The prompt design to extract information for each field should take into account that the format may deviate from the original (for example, dashes in field names, exact capitalization of letters).\n", "content": "## Background\nMedLM is a family of foundation models fine-tuned for the healthcare industry. [Med-PaLM 2](https://sites.research.google/med-palm/) is one of the text-based models developed by Google Research that powers MedLM, and was the first AI system to reach human expert level on answering US Medical Licensing Examination (USMLE)-style questions. The development of these models has been informed by specific customer needs such as answering medical questions and drafting summaries.\n## MedLM model card\nThe MedLM model card outlines the model details, such as MedLM's intended use, data overview, and safety information. Click the following link to download a PDF version of the MedLM model card:\n[Download the MedLM model card](/static/vertex-ai/generative-ai/docs/medlm/MedLM-model-card.pdf)\n## Regulatory information\n### MedLM intended use\nMedLM is based on Google Research's medically-tuned large language model, Med-PaLM 2. It is intended to be used for question answering and creating draft summaries from existing documentation -- to be reviewed, edited, and approved by the user before use. MedLM is also used for educational purposes for a Healthcare Professional (HCP) to engage in medical questioning and answering to help support the HCP.\n**Caution:** The output of the model(s) is not considered final, and gives only a draft response which the HCP should review. MedLM must not be used for any diagnostic or therapeutic purpose, and is not to be used in direct patient care.\n### Conditions of use and out-of-scope applications\n- MedLM customers and users must abide by the [Generative AI Prohibited Use Policy](https://policies.google.com/terms/generative-ai/use-policy) , Google Cloud Platform [Service Specific Terms](/terms/service-terms) , [Terms of Service](/terms) , [Acceptable Use Policy](/terms/aup) , [User Guide](/vertex-ai/generative-ai/docs/medlm/overview) , and other product documentation.\n- As part of [Service Specific Terms](/terms/service-terms) , customers may not use MedLM for clinical purposes (for clarity, non-clinical research, scheduling, and other administrative tasks are not restricted), to provide medical advice, or in any manner that is overseen by or requires clearance or approval from a medical device regulatory agency.- Direct patient use is prohibited. The product functions as an assistive tool for a clinician, HCP, or knowledge worker with a high degree of expertise, education, or experience in the healthcare and life sciences industry.\n- Use of MedLM as a Software as a Medical Device is prohibited.\n- The intended use for MedLM is to draft documents and responses that would be reviewed by a \"human in the loop\" before usage.\n- We recommend usage of MedLM solely for Medical Q&A and Summarization use cases at this stage:- Long form Q&A\n- Multiple choice Q&A\n- Summarizations, such as creation of After Visit Summaries or History and Physical Examination notes\n- Examples of medical device uses that are not permitted include (but are not limited to):- Analysis of patient records, prescription patterns, geographical data, and so forth to identify patients with possible diagnosis of opioid addiction.\n- Analysis of patient-specific medical information to detect a life-threatening condition, such as stroke or sepsis, and generate an alarm or an alert to notify a HCP.\n- Analysis of patient-specific medical information found in the medical records, including the most recent mammography report findings, to provide a list of follow-up actions or treatment options.\n- Analyzing prioritized list of FDA-authorized depression treatment options to an HCP based on an analysis of reported outcomes in a database of clinical studies using medical information (for example, diagnosis and demographics) from the patient's medical record.MedLM is currently only available to allow-listed customers in the US.\nMedLM is not intended to be used as a medical device. Customer use cases must be consistent with the intended use and conditions of use. Q&A should only be used for educational purposes and summarization outputs must always be independently reviewed and verified by the user based on their clinical judgment.\n## MedLM versus PaLM\nUsage of MedLM is similar to that of PaLM. However, unlike PaLM, MedLM has been tuned for specific medical tasks, such as select forms of summarization and medical question-answering.\nAs with most new applications of LLMs, however, we encourage performing careful validation and/or tuning your usage of MedLM to ensure good performance on these tasks. For tasks that don't require specialized medical expertise (for example, general NLP tasks or tasks which operate on medical data but don't require expertise), we expect that MedLM may perform similar to more generic models such as PaLM, and encourage experimenting with both on the specific use-case. See also the [Med-PaLM paper](https://www.nature.com/articles/s41586-023-06291-2) for more details on the Q&A tasks that MedLM has been trained and validated on. Capabilities like grounding of the responses in authoritative medical sources or accounting for the time-varying nature of medical consensus are not built into the model, as called out in the publication.\nAs per our [Generative AI Service-Specific Terms](/terms/service-terms) , customers may not use MedLM for clinical purposes (for clarity, non-clinical research, scheduling, or other administrative tasks is not restricted), to provide medical advice, or in any manner that is overseen by or requires clearance or approval from a medical device regulatory agency.\n## MedLM models\nIn the current MedLM release, two models are being made available:\n- MedLM-medium\n- MedLM-large\nMedLM-medium and MedLM-large have separate endpoints and provide customers with additional flexibility for their use cases. MedLM-medium provides customers with better throughputs and includes more recent data. MedLM-large is the same model from the preview phase. Both models will continue to be refreshed over the product lifecycle. In this page, \"MedLM\" refers to both models.\n## Customer responsibilities\nMedLM has been developed with trained and licensed healthcare practitioner users in mind. Google Cloud customers and end users should understand that LLMs and Generative AI are inherently probabilistic and may not always be accurate. Without adequate consideration or controls by customers, use of Generative AI models in healthcare may constitute a hazard to patients due to inaccurate content, missing content, or misleading, biased content.\n- Customers should implement appropriate hazard mitigations for all MedLM uses, such as adequate practitioner education, training, assessment of equity, and appropriate technical controls.\n- Customers must also perform their own evaluations for performance and safety to ensure prevention of harm for their use cases.\nMedLM may produce less accurate results for some groups compared to others depending on the question and how it is posed. Customers should be aware that differing performance of outputs of the model across demographic groups has the potential to exacerbate health inequities and perpetuate harmful biases. and often stem from multiple factors, such as existing social and structural inequities, medical misconceptions, negative stereotypes, and lack of diversity in training data.\n- Customers should consider implementing equity-focused evaluations and mitigations. This includes assessing model performance and behavior for intended use cases within various populations (for example, race/ethnicity, socioeconomic status (SES), geography, gender identity, sexual orientation, age, language preference, caste, and so forth); obtaining feedback on performance; engaging interdisciplinary experts and external partners that specialize in defining and addressing social and structural aspects of health; and conducting continuous monitoring efforts to assess and address issues of bias.## Request access\nAccess to the MedLM models is restricted. To request access, contact your Google Cloud account team.\n## Provide feedback\nYour feedback throughout your experience will help us improve future model versions and ensure that we continue to deliver the best possible experience for our users. Contact [medlm-feedback@google.com](mailto:medlm-feedback@google.com) and copy your Google Cloud account team and Google Cloud Customer Engineer (CE).\nEmail responses will be used as Feedback under the terms of your Agreement for Google Cloud Services and will be collected in accordance with the Google Cloud Privacy Notice. Do not include any personal information (names, email addresses) in this feedback form or other data that is sensitive or confidential. Note that data may be reviewed using both human reviewed and automated processing.\n## Report abuse\nYou can report suspected abuse of the MedLM API, any generated output that contains inappropriate material, or inaccurate information in [Report suspected abuse on Google Cloud](https://support.google.com/code/contact/cloud_platform_report) . In the **Google Cloud Platform Service** list, select **Cloud AI** .\n## Pricing\nAccess to the MedLM pricing is restricted. To request access, contact your Google Cloud account team. If you have access, see [MedLM pricing](/vertex-ai/generative-ai/docs/medlm/pricing) .\n## What's next\n- See examples of how to [create MedLM prompts](/vertex-ai/generative-ai/docs/medlm/medlm-prompts) .", "guide": "Generative AI on Vertex AI"}