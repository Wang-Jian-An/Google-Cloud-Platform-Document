{"title": "Generative AI on Vertex AI - Introduction to multimodal classes in the Vertex AI SDK", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/sdk-for-gemini/gemini-sdk-overview-reference", "abstract": "# Generative AI on Vertex AI - Introduction to multimodal classes in the Vertex AI SDK\nYou can use the [Vertex AI SDK for Python](/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) to programmatically create solutions using [Geminimodel](/vertex-ai/generative-ai/docs/multimodal/overview) classes. You can use the Vertex AI SDK to load one of the multimodal models, and . After you load a model, you can use it to generate text from a text prompt, an image, or a text prompt and an image. For more details about Gemini models, see [Gemini API models](/vertex-ai/generative-ai/docs/learn/models) .\nThe Gemini model classes represented in the Vertex AI SDK are in addition to classes that help you create Vertex AI solutions that aren't related to generative AI and language models. For information about how to use the Vertex AI SDK to automate data ingestion, train models, and get predictions on Vertex AI, see [Introduction to theVertex AI SDK for Python](/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) .\n", "content": "## Install the Vertex AI SDK\nTo install the Vertex AI SDK for Python, run the following command:\n```\npip install --upgrade google-cloud-aiplatform\n```\nFor more information, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/install-sdk) . To view the language model section in the [Vertex AI SDK reference guide](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform) , see [Package language models](/python/docs/reference/aiplatform/latest/vertexai.language_models) .\n## Authenticate the Vertex AI SDK\nAfter you install the Vertex AI SDK for Python, you need to authenticate. The following topics explain how to authenticate with the Vertex AI SDK if you're working locally and if you're working in Colaboratory:\n- If you're developing locally, do the following to set up [Application Default Credentials (ADC)](/docs/authentication/application-default-credentials) in your local environment:- [Install](/sdk/docs/install) the Google Cloud CLI, then [initialize](/sdk/docs/initializing) it by running the following command:```\ngcloud init\n```\n- Create local authentication credentials for your Google Account:```\ngcloud auth application-default login\n```A login screen is displayed. After you sign in, your credentials are stored in the local credential file used by ADC. For more information about working with ADC in a local environment, see [Local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n- If you're working in Colaboratory, run the following command in a Colab cell to authenticate:```\nfrom google.colab import authauth.authenticate_user()\n```This command opens a window where you can complete the authentication.## Load a Gemini model\nTo use the Vertex AI SDK to reference a multimodal model, you import `GenerativeModel` from `vertexai.preview.generative_models` , then use `GenerativeModel` to load the model. The following sample code shows you how to load the Gemini Pro and the Gemini Pro Vision models:\n```\nfrom vertexai.preview.generative_models import GenerativeModel# Load Gemini Progemini_pro_model = GenerativeModel(\"gemini-1.0-pro\")# Load Gemini Pro Visiongemini_pro_vision_model = GenerativeModel(\"gemini-1.0-pro-vision\")\n```\n## GenerativeModel class code samples\nThe `GenerativeModel` class represents a Gemini model. You can use it to load the Gemini Pro or Gemini Pro Vision model. The `GenerativeModel` class includes methods to help you generate content from text, images, and video. The following code samples demonstrate how to use the `GenerativeModel` class.\n- [Generate content using a text prompt](#generate-content-from-text) \n- [Generate content using more than one text prompt](#generate-content-from-multiple-text-prompts) \n- [Generate a description of an image](#generate-content-from-image) \n- [Generate content from text and an image](#generate-content-from-text-and-image) \n- [Generate content from a video](#generate-content-from-video) \n### Generate content using a text prompt\nThe following code sample uses the Gemini Pro multimodal model to generate text about roses:\n```\nfrom vertexai.preview.generative_models import GenerativeModelgemini_pro_model = GenerativeModel(\"gemini-1.0-pro\")model_response = gemini_pro_model.generate_content(\"Why do cars have four wheels?\")print(\"model_response\\n\",model_response)\n```\nThe response to this sample code might be similar to the following. The returned text is truncated for brevity.\n```\ncandidates {\u00a0 content {\u00a0 \u00a0 parts {\u00a0 \u00a0 \u00a0 text: \"1. **Stability:** Four wheels provide a wider base of support,\u00a0 \u00a0 \u00a0 \u00a0 which increases the vehicle\\'s stability. This is especially important\u00a0 \u00a0 \u00a0 \u00a0 when cornering or driving on uneven surfaces.\\n\\n2....\"\u00a0 \u00a0 }\u00a0 }}usage_metadata {\u00a0 prompt_token_count: 7\u00a0 candidates_token_count: 323\u00a0 total_token_count: 330}\n```\n### Generate content using more than one text prompt\nThe following code sample uses the Gemini Pro multimodal model to generate text using more than one text prompt:\n```\nfrom vertexai.preview.generative_models import GenerativeModelgemini_pro_model = GenerativeModel(\"gemini-1.0-pro\")model_response = gemini_pro_model.generate_content([\"What is x multiplied by 2?\", \"x = 42\"])print(\"model_response\\n\",model_response)\n```\nThe response to this sample code might be similar to the following:\n```\ncandidates {\u00a0 content {\u00a0 \u00a0 parts {\u00a0 \u00a0 \u00a0 text: \"84\"\u00a0 \u00a0 }\u00a0 }}usage_metadata {\u00a0 prompt_token_count: 13\u00a0 candidates_token_count: 2\u00a0 total_token_count: 15}\n```\n### Generate a description of an image\nThe following code sample uses the Gemini Pro Vision multimodal model to generate text that describes a flower:\n```\nfrom vertexai.preview.generative_models import GenerativeModelfrom vertexai.preview.generative_models import Partgemini_pro_vision_model = GenerativeModel(\"gemini-1.0-pro-vision\")image = Part.from_uri(\"gs://cloud-samples-data/ai-platform/flowers/daisy/10559679065_50d2b16f6d.jpg\", mime_type=\"image/jpeg\")model_response = gemini_pro_vision_model.generate_content([\"what is this image?\", image])print(\"model_response\\n\",model_response)\n```\nThe response to this sample code might be similar to the following:\n```\ncandidates {\u00a0 content {\u00a0 \u00a0 role: \"model\"\u00a0 \u00a0 parts {\u00a0 \u00a0 \u00a0 text: \" The image is a photograph of a daisy flower in a field of fallen leaves.\"\u00a0 \u00a0 }\u00a0 }\u00a0 finish_reason: STOP\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_HARASSMENT\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_HATE_SPEECH\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_SEXUALLY_EXPLICIT\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_DANGEROUS_CONTENT\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }}usage_metadata {\u00a0 prompt_token_count: 263\u00a0 candidates_token_count: 16\u00a0 total_token_count: 279}\n```\n### Generate content from text and an image\nThe following code sample uses the Gemini Pro Vision multimodal model to generate content using a text prompt and a picture of a flower:\n```\nfrom vertexai import generative_modelsfrom vertexai.generative_models import GenerativeModelimage = generative_models.Part.from_uri(\"gs://cloud-samples-data/ai-platform/flowers/daisy/10559679065_50d2b16f6d.jpg\", mime_type=\"image/jpeg\")gemini_pro_vision_model = GenerativeModel(\"gemini-1.0-pro-vision\")model_response = gemini_pro_vision_model.generate_content([\"What is shown in this image?\", image])print(\"model_response\\n\",model_response)\n```\nThe response to this sample code might be similar to the following:\n```\ncandidates {\u00a0 content {\u00a0 \u00a0 role: \"model\"\u00a0 \u00a0 parts {\u00a0 \u00a0 \u00a0 text: \" This is an image of a white daisy growing in a pile of brown, dead leaves.\"\u00a0 \u00a0 }\u00a0 }\u00a0 finish_reason: STOP\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_HARASSMENT\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_HATE_SPEECH\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_SEXUALLY_EXPLICIT\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }\u00a0 safety_ratings {\u00a0 \u00a0 category: HARM_CATEGORY_DANGEROUS_CONTENT\u00a0 \u00a0 probability: NEGLIGIBLE\u00a0 }}usage_metadata {\u00a0 prompt_token_count: 265\u00a0 candidates_token_count: 18\u00a0 total_token_count: 283}\n```\n### Generate content from a video\nYou can use streaming to generate content using a video. Gemini models support streaming for only video content. The following code sample uses the Gemini Pro Vision multimodal model to generate content using a text prompt and a video of an advertisement for a movie.\n```\nfrom vertexai import generative_modelsfrom vertexai.generative_models import GenerativeModelgemini_pro_vision_model = GenerativeModel(\"gemini-1.0-pro-vision\")response = gemini_pro_vision_model.generate_content([\u00a0 \"What is in the video? \",\u00a0 generative_models.Part.from_uri(\"gs://cloud-samples-data/video/animals.mp4\", mime_type=\"video/mp4\"),], stream=True)for chunk in response :\u00a0 print(chunk.text)\n```\nThe response to this sample code might be similar to the following:\n```\nThe video is an advertisement for the movie Zootopia. It features a tiger, an\notter, and a sloth. The tiger is shown looking at the camera , while the otter\nand the sloth are shown swimming in a pool. The video is set to the song \"Try\nEverything\" by Shakira.\"\n```\n## What's next\n- Learn about [foundation model classes and the Vertex AI SDK](/vertex-ai/generative-ai/docs/sdk-for-llm/llm-sdk-overview) .\n- Learn how to [use text model classes and the Vertex AI SDK](/vertex-ai/generative-ai/docs/sdk-for-llm/sdk-use-text-models) .\n- Learn about [use code model classes and the Vertex AI SDK](/vertex-ai/generative-ai/docs/sdk-for-llm/sdk-use-code-models) .", "guide": "Generative AI on Vertex AI"}