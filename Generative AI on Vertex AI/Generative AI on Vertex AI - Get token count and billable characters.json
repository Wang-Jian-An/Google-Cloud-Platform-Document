{"title": "Generative AI on Vertex AI - Get token count and billable characters", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/get-token-count", "abstract": "# Generative AI on Vertex AI - Get token count and billable characters\nThis page shows you how to get the token count and the number of billable characters for a prompt.\n", "content": "## Supported models\nThe following multimodal models support getting prompt token counts:\n- `gemini-1.0-pro`\n- `gemini-1.0-pro-vision`## Get the token count for a prompt\nYou can get the token count and the number of billable characters for a prompt by using the Vertex AI API.\n**Important:** The input format for `CountTokens` depends on the model you use. Each input format is the same as the `Predict` input format.\nTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/generative_ai/gemini_count_token_example.py) \n```\nimport vertexaifrom vertexai.generative_models import GenerativeModeldef generate_text(project_id: str, location: str) -> str:\u00a0 \u00a0 # Initialize Vertex AI\u00a0 \u00a0 vertexai.init(project=project_id, location=location)\u00a0 \u00a0 # Load the model\u00a0 \u00a0 model = GenerativeModel(\"gemini-1.0-pro\")\u00a0 \u00a0 # prompt tokens count\u00a0 \u00a0 print(model.count_tokens(\"why is sky blue?\"))\u00a0 \u00a0 # Load example images\u00a0 \u00a0 response = model.generate_content(\"why is sky blue?\")\u00a0 \u00a0 # response tokens count\u00a0 \u00a0 print(response._raw_response.usage_metadata)\u00a0 \u00a0 return response.text\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/generative-ai/snippets/countTokens.js) \n```\nconst {VertexAI} = require('@google-cloud/vertexai');/**\u00a0* TODO(developer): Update these variables before running the sample.\u00a0*/async function countTokens(\u00a0 projectId = 'PROJECT_ID',\u00a0 location = 'us-central1',\u00a0 model = 'gemini-1.0-pro') {\u00a0 // Initialize Vertex with your Cloud project and location\u00a0 const vertexAI = new VertexAI({project: projectId, location: location});\u00a0 // Instantiate the model\u00a0 const generativeModel = vertexAI.getGenerativeModel({\u00a0 \u00a0 model: model,\u00a0 });\u00a0 const req = {\u00a0 \u00a0 contents: [{role: 'user', parts: [{text: 'How are you doing today?'}]}],\u00a0 };\u00a0 const countTokensResp = await generativeModel.countTokens(req);\u00a0 console.log('count tokens response: ', countTokensResp);}\n```To get the token count and the number of billable characters for a prompt by using the Vertex AI API, send a POST request to the publisher model endpoint.\nBefore using any of the request data, make the following replacements:- : The region to process the request. Available options include the following:\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : The model ID of the multimodal model  that you want to use. The options are:- `gemini-1.0-pro-vision`\n- `gemini-1.0-pro`\n- : The role in a conversation associated with the content. Specifying a role is required even in singleturn use cases. Acceptable values include the following:- `USER`: Specifies content that's sent by you.- : The text instructions to include in the prompt.\n- : A sequence of bytes instead of characters.\n- : The Cloud Storage URI of the image or video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify.\n- : The media type of the image or video specified in the`data`or`fileUri`fields. Acceptable values include the following:\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/MODEL_ID:countTokens\n```\nRequest JSON body:\n```\n{\n \"contents\": {\n \"role\": \"ROLE\",\n \"parts\": [  {\n  \"inlineData\": {\n   \"mimeType\": \"MIME_TYPE\",\n   \"data\": \"IMAGE_BYTES\"\n  }\n  },\n  {\n  \"fileData\": {\n   \"mimeType\": \"MIME_TYPE\",\n   \"fileUri\": \"FILE_URI\"\n  }\n  },\n  {\n  \"text\": \"TEXT\"\n  }\n ]\n },\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/MODEL_ID:countTokens\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/MODEL_ID:countTokens\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following.\n```\nMODEL_ID=\"gemini-1.0-pro-vision\"PROJECT_ID=\"my-project\"PROMPT=\"Provide a summary with about two sentences for the following article.\"curl \\-X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:computeTokens-d \\$'{\u00a0 \"contents\": [\u00a0 \u00a0 { \"prompt\": \"'\"$PROMPT\"'\" }\u00a0 \u00a0 { \"inlineData\": {\"'\"$MIME_TYPE\"'\": \"image/jpeg\", \"data\": \"'\"$IMAGE_BYTES\"'\" } },\u00a0 \u00a0 { \"fileData\": {\"mimeType\": \"video/avi\", \"fileUri\":\"'\"$FILE_URI\"'\" } } ] }}\n```\n```\nMODEL_ID=\"gemini-1.0-pro-vision\"PROJECT_ID=\"my-project\"PROMPT=\"Provide a summary with about two sentences for the following article.\"curl \\-X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/MODEL_ID:computeTokens-d \\$'{\u00a0 \"contents\": [\u00a0 \u00a0 { \"prompt\": \"'\"$PROMPT\"'\"}\u00a0 ],}'\n```\n## Pricing and quota\nThere is no charge or quota restriction for using the `CountTokens` API. The maximum quota for the `CountTokens` API and the `ComputeTokens` API is 3000 requests per minute.\n## What's next\n- Learn how to [test chat prompts](/vertex-ai/generative-ai/docs/chat/test-chat-prompts) .\n- Learn how to [test text prompts](/vertex-ai/generative-ai/docs/text/test-text-prompts) .", "guide": "Generative AI on Vertex AI"}