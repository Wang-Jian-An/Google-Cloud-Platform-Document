{"title": "Generative AI on Vertex AI - Model information", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models", "abstract": "# Generative AI on Vertex AI - Model information\nVertex AI features a growing list of foundation models that you can test, deploy, and customize for use in your AI-based applications. Foundation models are fine-tuned for specific use cases and offered at different price points. This page summarizes the models that are available in the various APIs and gives you guidance on which models to choose by use case.\nTo learn more about all AI models and APIs on Vertex AI, see [Explore AImodels and APIs](/vertex-ai/docs/start/explore-models) .\n", "content": "## Foundation model APIs\nVertex AI has the following foundation model APIs:\n- Gemini API (Multimodal data, text, code, and chat)\n- PaLM API (Text, chat, and embeddings)\n- Codey APIs (Code generation, code chat, and code completion)\n- Imagen API (Image generation, image editing, image captioning, visual question answering, and multimodal embedding)\n### Gemini API models\nThe following table summarizes the models available in the [Gemini API](/vertex-ai/generative-ai/docs/multimodal/overview) :\n| Model name         | Description                                                      | Model properties                                                 | Tuning support        |\n|:----------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------|\n| Gemini 1.0 Pro (gemini-1.0-pro)    | Designed to handle natural language tasks, multiturn text and code chat, and code generation. Use Gemini 1.0 Pro for prompts that only contain text.                   | Max total tokens (input and output): 32,760 Max output tokens: 8,192 Training data: Up to Feb 2023                            | Supervised: No RLHF: No Distillation: No |\n| Gemini 1.0 Pro Vision (gemini-1.0-pro-vision) | Multimodal model that supports adding image and video in text or chat prompts for a text or code response. Use Gemini 1.0 Pro Vision multimodal prompts.                  | Max total tokens (input and output): 16,384 Max output tokens: 2,048 Max image size: No limit Max images per prompt: 16 Max video length: 2 minutes Max videos per prompt: 1 Training data: Up to Feb 2023 | Supervised: No RLHF: No Distillation: No |\n| Gemini 1.0 Ultra (GA with allow list)   | Google's most capable multimodal model, optimized for complex tasks including instruction, code, and reasoning, with support for multiple languages. Gemini 1.0 Ultra is generally available (GA) to a select set of customers. | Max tokens input: 8,192 Max tokens output: 2,048                                        | Supervised: No RLHF: No Distillation: No |\n| Gemini 1.0 Ultra Vision (GA with allow list) | Google's most capable multimodal vision model, optimized to support text, images, videos, and multi-turn chat. Gemini 1.0 Ultra Vision is generally available (GA) to a select set of customers.        | Max tokens input: 8,192 Max tokens output: 2,048                                        | Supervised: No RLHF: No Distillation: No |\n| Gemini 1.5 Pro (private preview)    | Google's mid-size multimodal model, optimized for scaling across a wide-range of tasks. Gemini 1.5 Pro supports long-context understanding with up to 1 million tokens.               | Max tokens input: 1,000,000 Max tokens output: 8,192 Max images: 300 Max video frames: 3,800                             | Supervised: No RLHF: No Distillation: No |\n### PaLM API models\nThe following table summarizes the models available in the PaLM API:\n| Model name               | Description                                     | Model properties                        | Tuning support           |\n|:--------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|\n| PaLM 2 for Text (text-bison)          | Fine-tuned to follow natural language instructions and is suitable for a variety of language tasks, such as classification, summarization, and extraction. | Maximum input tokens: 8192 Maximum output tokens: 1024 Training data: Up to Feb 2023       | Supervised: Yes RLHF: Yes (Preview) Distillation: No |\n| PaLM 2 for Text (text-unicorn)          | The most advanced text model in the PaLM family of models for use with complex natural language tasks.              | Maximum input tokens: 8192 Maximum output tokens: 1024 Training data: Up to Feb 2023       | Supervised: No RLHF: No Distillation: Yes (Preview) |\n| PaLM 2 for Text 32k (text-bison-32k)        | Fine-tuned to follow natural language instructions and is suitable for a variety of language tasks.               | Max tokens (input + output): 32,768 Max output tokens: 8,192 Training data: Up to Aug 2023     | Supervised: Yes RLHF: No Distillation: No    |\n| PaLM 2 for Chat (chat-bison)          | Fine-tuned for multi-turn conversation use cases.                           | Maximum input tokens: 8192 Maximum output tokens: 2048 Training data: Up to Feb 2023 Maximum turns : 2500 | Supervised: Yes RLHF: No Distillation: No    |\n| PaLM 2 for Chat 32k (chat-bison-32k)        | Fine-tuned for multi-turn conversation use cases.                           | Max tokens (input + output): 32,768 Max output tokens: 8,192 Training data: Up to Aug 2023 Max turns : 2500 | Supervised: Yes RLHF: No Distillation: No    |\n| Embeddings for Text (textembedding-gecko)       | Returns model embeddings for text inputs.                             | 3072 input tokens and outputs 768-dimensional vector embeddings.            | Supervised: Yes RLHF: No Distillation: No    |\n| Embeddings for Text multilingual (textembedding-gecko-multilingual) | Returns model embeddings for text inputs which support over 100 languages                     | 3072 input tokens and outputs 768-dimensional vector embeddings.            | Supervised: Yes (Preview) RLHF: No Distillation: No |\n### Codey APIs models\nThe following table summarizes the models available in the Codey APIs:\n| Model name          | Description                                    | Model properties            | Tuning support        |\n|:-----------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------|:--------------------------------------------|\n| Codey for Code Generation (code-bison)   | A model fine-tuned to generate code based on a natural language description of the desired code. For example, it can generate a unit test for a function. | Maximum input tokens: 6144 Maximum output tokens: 1024  | Supervised: Yes RLHF: No Distillation: No |\n| Codey for Code Generation 32k (code-bison-32k) | A model fine-tuned to generate code based on a natural language description of the desired code. For example, it can generate a unit test for a function. | Max tokens (input + output): 32,768 Max output tokens: 8,192 | Supervised: Yes RLHF: No Distillation: No |\n| Codey for Code Chat (codechat-bison)   | A model fine-tuned for chatbot conversations that help with code-related questions.                  | Maximum input tokens: 6144 Maximum output tokens: 1024  | Supervised: Yes RLHF: No Distillation: No |\n| Codey for Code Chat 32k (codechat-bison-32k) | A model fine-tuned for chatbot conversations that help with code-related questions.                  | Max tokens (input + output): 32,768 Max output tokens: 8,192 | Supervised: Yes RLHF: No Distillation: No |\n| Codey for Code Completion (code-gecko)   | A model fine-tuned to suggest code completion based on the context in code that's written.                | Maximum input tokens: 2048 Maximum output tokens: 64   | Supervised: No RLHF: No Distillation: No |\n### Imagen API models\nThe following table summarizes the models available in the Imagen API:\n| Model name          | Description                                 | Model properties                                     | Tuning support   |\n|:------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------|\n| Imagen for Image Generation (imagegeneration) | This model supports image generation and can create high quality visual assets in seconds.             | Maximum requests per minute per project: 100 Maximum images generated: 8 Maximum base image (editing/upscaling): 10\u00a0MB Generated image resolution: 1024x1024 pixels | Supervised: No RLHF: No |\n| Embeddings for Multimodal (multimodalembedding) | This model generates vectors based on the input you provide, which can include a combination of image and text.       | Maximum requests per minute per project: 120 Maximum text length: 32 tokens Language: English Maximum image size: 20\u00a0MB           | Supervised: No RLHF: No |\n| Image captioning (imagetext)     | The model that supports image captioning. This model generates a caption from an image you provide based on the language that you specify. | Maximum requests per minute per project: 500 Languages: English, French, German, Italian, Spanish Maximum image size: 10\u00a0MB Maximum number of captions: 3  | Supervised: No RLHF: No |\n| Visual Question Answering - VQA (imagetext)  | A model which supports image question and answering.                      | Maximum requests per minute per project: 500 Languages: English Maximum image size: 10\u00a0MB Maximum number of answers: 3           | Supervised: No RLHF: No |\n### MedLM API models\nThe following table summarizes the models available in the MedLM API:\n| Model name     | Description                                                     | Model properties                 | Tuning support   |\n|:----------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------|:-------------------------|\n| MedLM-medium (medlm-medium) | A HIPAA-compliant suite of medically tuned models and APIs powered by Google Research. These models help healthcare practitioners with medical question and answering (Q&A) and summarizing healthcare and medical documents. | Max tokens (input + output): 32,768 Max output tokens: 8,192 Languages: English | Supervised: No RLHF: No |\n| MedLM-large (medlm-large) | A HIPAA-compliant suite of medically tuned models and APIs powered by Google Research. These models help healthcare practitioners with medical question and answering (Q&A) and summarizing healthcare and medical documents. | Max input tokens: 8,192 Max output tokens: 1,024 Languages: English    | Supervised: No RLHF: No |\n**Note:** Access to the MedLM API models is restricted. For more information, see [Request access](/vertex-ai/generative-ai/docs/medlm/overview#request-access) .\n## Language support\n[Vertex AI PaLM API](/vertex-ai/generative-ai/docs/model-reference/text) and [Vertex AI Gemini API](/vertex-ai/generative-ai/docs/model-reference/gemini) are [Generally Available (GA)](/products#product-launch-stages) for the following languages:\n- Arabic (`ar`)\n- Bengali (`bn`)\n- Bulgarian (`bg`)\n- Chinese simplified and traditional (`zh`)\n- Croatian (`hr`)\n- Czech (`cs`)\n- Danish (`da`)\n- Dutch (`nl`)\n- English (`en`)\n- Estonian (`et`)\n- Finnish (`fi`)\n- French (`fr`)\n- German (`de`)\n- Greek (`el`)\n- Hebrew (`iw`)\n- Hindi (`hi`)\n- Hungarian (`hu`)\n- Indonesian (`id`)\n- Italian (`it`)\n- Japanese (`ja`)\n- Korean (`ko`)\n- Latvian (`lv`)\n- Lithuanian (`lt`)\n- Norwegian (`no`)\n- Polish (`pl`)\n- Portuguese (`pt`)\n- Romanian (`ro`)\n- Russian (`ru`)\n- Serbian (`sr`)\n- Slovak (`sk`)\n- Slovenian (`sl`)\n- Spanish (`es`)\n- Swahili (`sw`)\n- Swedish (`sv`)\n- Thai (`th`)\n- Turkish (`tr`)\n- Ukrainian (`uk`)\n- Vietnamese (`vi`)\nFor access to other languages, contact your Google Cloud representative.\n## Explore all models in Model Garden\nModel Garden is a platform that helps you discover, test, customize, and deploy Google proprietary and select OSS models and assets. To explore the generative AI models and APIs that are available on Vertex AI, go to Model Garden in the Google Cloud console.\n[Go to Model Garden](https://console.cloud.google.com/vertex-ai/model-garden)\nTo learn more about Model Garden, including available models and capabilities, see [Explore AI models in Model Garden](/vertex-ai/docs/start/explore-models) .\n## What's next\n- Try a quickstart tutorial using [Vertex AI Studio](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart) or the [Vertex AI API](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal) .\n- Learn how to [test text prompts](/vertex-ai/generative-ai/docs/text/test-text-prompts) .\n- Learn how to [test chat prompts](/vertex-ai/generative-ai/docs/chat/test-chat-prompts) .\n- Explore pretrained models in [Model Garden](/vertex-ai/docs/start/explore-models) .\n- Learn how to [tune a foundationmodel](/vertex-ai/generative-ai/docs/models/tune-models) .\n- Learn about [responsible AI best practices and Vertex AI's safetyfilters](/vertex-ai/generative-ai/docs/learn/responsible-ai) .", "guide": "Generative AI on Vertex AI"}