{"title": "Generative AI on Vertex AI - Try the text embedding API", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-text-embeddings", "abstract": "# Generative AI on Vertex AI - Try the text embedding API\nUse Vertex AI to send text embedding requests to Google's PaLM 2 Large Language Model (LLM) and to receive a response. Test and customize prompts to meet the needs of your application.\n", "content": "## Before you begin\nBefore you can try the chat prompts, you must do the following:\n- [Set up a project and a development environment](/vertex-ai/docs/start/cloud-environment) . The project ID is needed to run the sample code.\n- Familiarize yourself with the [text embedding parameters](/vertex-ai/generative-ai/docs/model-reference/text-embeddings#request_body) that you must replace before running the sample code.\n- Review the [text embedding use cases](/vertex-ai/generative-ai/docs/model-reference/text-embeddings#use_cases) to help you identify which type of sample to create.## Try text embedding requests\nThe Vertex AI PaLM Embedding API performs online (real-time) predictions, which use text embedding requests as input to the model. The API accepts 3,072 input tokens and outputs 768-dimensional vector embeddings.\nSelect a tab, and follow the instructions to run the sample.\nTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/generative_ai/embedding.py) \n```\nfrom vertexai.language_models import TextEmbeddingModeldef text_embedding() -> list:\u00a0 \u00a0 \"\"\"Text embedding with a Large Language Model.\"\"\"\u00a0 \u00a0 model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")\u00a0 \u00a0 embeddings = model.get_embeddings([\"What is life?\"])\u00a0 \u00a0 for embedding in embeddings:\u00a0 \u00a0 \u00a0 \u00a0 vector = embedding.values\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Length of Embedding Vector: {len(vector)}\")\u00a0 \u00a0 return vector\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/predict-text-embeddings.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\\\u00a0* (Not necessary if passing values as arguments)\u00a0*/// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';const aiplatform = require('@google-cloud/aiplatform');// Imports the Google Cloud Prediction service clientconst {PredictionServiceClient} = aiplatform.v1;// Import the helper module for converting arbitrary protobuf.Value objects.const {helpers} = aiplatform;// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};const publisher = 'google';const model = 'textembedding-gecko@001';// Instantiates a clientconst predictionServiceClient = new PredictionServiceClient(clientOptions);async function callPredict() {\u00a0 // Configure the parent resource\u00a0 const endpoint = `projects/${project}/locations/${location}/publishers/${publisher}/models/${model}`;\u00a0 const instance = {\u00a0 \u00a0 content: 'What is life?',\u00a0 };\u00a0 const instanceValue = helpers.toValue(instance);\u00a0 const instances = [instanceValue];\u00a0 const parameter = {\u00a0 \u00a0 temperature: 0,\u00a0 \u00a0 maxOutputTokens: 256,\u00a0 \u00a0 topP: 0,\u00a0 \u00a0 topK: 1,\u00a0 };\u00a0 const parameters = helpers.toValue(parameter);\u00a0 const request = {\u00a0 \u00a0 endpoint,\u00a0 \u00a0 instances,\u00a0 \u00a0 parameters,\u00a0 };\u00a0 // Predict request\u00a0 const [response] = await predictionServiceClient.predict(request);\u00a0 console.log('Get text embeddings response');\u00a0 const predictions = response.predictions;\u00a0 console.log('\\tPredictions :');\u00a0 for (const prediction of predictions) {\u00a0 \u00a0 console.log(`\\t\\tPrediction : ${JSON.stringify(prediction)}`);\u00a0 }}callPredict();\n```Before trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/PredictTextEmbeddingsSample.java) \n```\nimport com.google.cloud.aiplatform.util.ValueConverter;import com.google.cloud.aiplatform.v1beta1.EndpointName;import com.google.cloud.aiplatform.v1beta1.PredictResponse;import com.google.cloud.aiplatform.v1beta1.PredictionServiceClient;import com.google.cloud.aiplatform.v1beta1.PredictionServiceSettings;import com.google.protobuf.Value;import com.google.protobuf.util.JsonFormat;import java.io.IOException;import java.util.ArrayList;import java.util.List;public class PredictTextEmbeddingsSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 // Details about text embedding request structure and supported models are available in:\u00a0 \u00a0 // https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings/get-text-embeddings\u00a0 \u00a0 String instance = \"{ \\\"content\\\": \\\"What is life?\\\"}\";\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 String publisher = \"google\";\u00a0 \u00a0 String model = \"textembedding-gecko@001\";\u00a0 \u00a0 predictTextEmbeddings(instance, project, location, publisher, model);\u00a0 }\u00a0 // Get text embeddings from a supported embedding model\u00a0 public static void predictTextEmbeddings(\u00a0 \u00a0 \u00a0 String instance, String project, String location, String publisher, String model)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 String endpoint = String.format(\"%s-aiplatform.googleapis.com:443\", location);\u00a0 \u00a0 PredictionServiceSettings predictionServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 PredictionServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(endpoint)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests.\u00a0 \u00a0 try (PredictionServiceClient predictionServiceClient =\u00a0 \u00a0 \u00a0 \u00a0 PredictionServiceClient.create(predictionServiceSettings)) {\u00a0 \u00a0 \u00a0 EndpointName endpointName =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 EndpointName.ofProjectLocationPublisherModelName(project, location, publisher, model);\u00a0 \u00a0 \u00a0 // Use Value.Builder to convert instance to a dynamically typed value that can be\u00a0 \u00a0 \u00a0 // processed by the service.\u00a0 \u00a0 \u00a0 Value.Builder instanceValue = Value.newBuilder();\u00a0 \u00a0 \u00a0 JsonFormat.parser().merge(instance, instanceValue);\u00a0 \u00a0 \u00a0 List<Value> instances = new ArrayList<>();\u00a0 \u00a0 \u00a0 instances.add(instanceValue.build());\u00a0 \u00a0 \u00a0 PredictResponse predictResponse =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 predictionServiceClient.predict(endpointName, instances, ValueConverter.EMPTY_VALUE);\u00a0 \u00a0 \u00a0 System.out.println(\"Predict Response\");\u00a0 \u00a0 \u00a0 for (Value prediction : predictResponse.getPredictionsList()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\tPrediction: %s\\n\", prediction);\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the C# setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI C# API reference documentation](/dotnet/docs/reference/Google.Cloud.AIPlatform.V1/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/dotnet-docs-samples/blob/HEAD/aiplatform/api/AIPlatform.Samples/PredictTextEmbeddingsSample.cs) \n```\nusing Google.Cloud.AIPlatform.V1;using System;using System.Collections.Generic;using System.Linq;using Value = Google.Protobuf.WellKnownTypes.Value;public class PredictTextEmbeddingsSample{\u00a0 \u00a0 public int PredictTextEmbeddings(\u00a0 \u00a0 \u00a0 \u00a0 string projectId = \"your-project-id\",\u00a0 \u00a0 \u00a0 \u00a0 string locationId = \"us-central1\",\u00a0 \u00a0 \u00a0 \u00a0 string publisher = \"google\",\u00a0 \u00a0 \u00a0 \u00a0 string model = \"textembedding-gecko@001\"\u00a0 \u00a0 )\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 // Initialize client that will be used to send requests.\u00a0 \u00a0 \u00a0 \u00a0 // This client only needs to be created once,\u00a0 \u00a0 \u00a0 \u00a0 // and can be reused for multiple requests.\u00a0 \u00a0 \u00a0 \u00a0 var client = new PredictionServiceClientBuilder\u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Endpoint = $\"{locationId}-aiplatform.googleapis.com\"\u00a0 \u00a0 \u00a0 \u00a0 }.Build();\u00a0 \u00a0 \u00a0 \u00a0 // Configure the parent resource.\u00a0 \u00a0 \u00a0 \u00a0 var endpoint = EndpointName.FromProjectLocationPublisherModel(projectId, locationId, publisher, model);\u00a0 \u00a0 \u00a0 \u00a0 // Initialize request argument(s).\u00a0 \u00a0 \u00a0 \u00a0 var instances = new List<Value>\u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Value.ForStruct(new()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Fields =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [\"content\"] = Value.ForString(\"What is life?\"),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 })\u00a0 \u00a0 \u00a0 \u00a0 };\u00a0 \u00a0 \u00a0 \u00a0 // Make the request.\u00a0 \u00a0 \u00a0 \u00a0 var response = client.Predict(endpoint, instances, null);\u00a0 \u00a0 \u00a0 \u00a0 // Parse and return the embedding vector count.\u00a0 \u00a0 \u00a0 \u00a0 var values = response.Predictions.First().StructValue.Fields[\"embeddings\"].StructValue.Fields[\"values\"].ListValue.Values;\u00a0 \u00a0 \u00a0 \u00a0 Console.WriteLine($\"Length of embedding vector: {values.Count}\");\u00a0 \u00a0 \u00a0 \u00a0 return values.Count;\u00a0 \u00a0 }}\n```To try a text embedding request by using the Google Cloud console,   do the following:- Open the Cloud Shell terminal in the Google Cloud console. [Go to Cloud Shell](https://console.cloud.google.com/?cloudshell=true) \n- Edit the placeholders in the sample code, and copy    to the console.```\nMODEL_ID=\"textembedding-gecko\"PROJECT_ID=PROJECT_IDcurl \\\u00a0 -X POST \\\u00a0 -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\u00a0 -H \"Content-Type: application/json\" \\\u00a0 https://us-central1-aiplatform.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/publishers/google/models/${MODEL_ID}:predict -d \\\u00a0 $'{\u00a0 \u00a0 \"instances\": [\u00a0 \u00a0 \u00a0 { \"content\": \"What is life?\"}\u00a0 \u00a0 ],\u00a0 }'\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \n```## What's next\n- Learn about [designing text prompts](/vertex-ai/generative-ai/docs/text/text-prompts) . and [text chat prompts](/vertex-ai/generative-ai/docs/chat/chat-prompts) .\n- Learn how to test prompts in [Vertex AI Studio](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart) .\n- Learn about [text embeddings](/vertex-ai/generative-ai/docs/embeddings/get-text-embeddings) .\n- Try to [tune a language foundation model](/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-tuning) .\n- Learn about [responsible AI best practices](/vertex-ai/generative-ai/docs/learn/responsible-ai#recommended_practices) and [Vertex AI's safety filters](/vertex-ai/generative-ai/docs/learn/responsible-ai#safety_filters_and_attributes) .", "guide": "Generative AI on Vertex AI"}