{"title": "Generative AI on Vertex AI - Image captions", "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/image-captioning", "abstract": "# Generative AI on Vertex AI - Image captions\n`imagetext` is the name of the model that supports image captioning. `imagetext` generates a caption from an image you provide based on the language that you specify. The model supports the following languages: English ( `en` ), German ( `de` ), French ( `fr` ), Spanish ( `es` ) and Italian ( `it` ).\nTo explore this model in the console, see the `Image Captioning` model card in the Model Garden.\n[Go to the Model Garden](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/imagetext)\n", "content": "## Use cases\nSome common use cases for image captioning include:\n- Creators can generate captions for uploaded images and videos (for example, a short description of a video sequence)\n- Generate captions to describe products\n- Integrate captioning with an app using the API to create new experiences## HTTP request\n```\nPOST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/publishers/google/models/imagetext:predict\n```\n## Request body\n```\n{\u00a0 \"instances\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"image\": {\u00a0 \u00a0 \u00a0 \u00a0 // Union field can be only one of the following:\u00a0 \u00a0 \u00a0 \u00a0 \"bytesBase64Encoded\": string,\u00a0 \u00a0 \u00a0 \u00a0 \"gcsUri\": string,\u00a0 \u00a0 \u00a0 \u00a0 // End of list of possible types for union field.\u00a0 \u00a0 \u00a0 \u00a0 \"mimeType\": string\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 ],\u00a0 \"parameters\": {\u00a0 \u00a0 \"sampleCount\": integer,\u00a0 \u00a0 \"storageUri\": string,\u00a0 \u00a0 \"language\": string,\u00a0 \u00a0 \"seed\": integer\u00a0 }}\n```\nUse the following parameters for the Imagen model `imagetext` . For more information, see [Get image descriptions using visual captioning](/vertex-ai/generative-ai/docs/image/image-captioning) .\n| Parameter   | Description                                   | Acceptable values              |\n|:-------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------|\n| instances   | An array that contains the object with image details to get information about.                  | array (1 image object allowed)           |\n| bytesBase64Encoded | The image to caption.                                | Base64-encoded image string (PNG or JPEG, 20\u00a0MB max)     |\n| gcsUri    | The Cloud Storage URI of the image to caption.                          | string URI of the image file in Cloud Storage (PNG or JPEG, 20\u00a0MB max) |\n| mimeType   | Optional. The MIME type of the image you specify.                         | string (image/jpeg or image/png)          |\n| sampleCount  | Number of generated text strings.                             | Int value: 1-3               |\n| seed    | Optional. The seed for random number generator (RNG). If RNG seed is the same for requests with the inputs, the prediction results will be the same. | integer                |\n| storageUri   | Optional. The Cloud Storage location to save the generated text responses.                   | string                 |\n| language   | Optional. The text prompt for guiding the response.                         | string: en (default), de, fr, it, es         |\n## Sample request\nTo test a text prompt by using the Vertex AI API, send a POST request to the publisher model endpoint.\nBefore using any of the request data, make the following replacements:- : Your Google Cloud [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : Your project's region. For example,`us-central1`,`europe-west2`, or`asia-northeast3`. For a list of available regions, see [Generative AI on Vertex AI locations](/vertex-ai/generative-ai/docs/learn/locations-genai) .\n- : The image to get captions for. The image must be  specified as a [base64-encoded](/vertex-ai/generative-ai/docs/image/base64-encode) byte string. Size limit:  10 MB.\n- : The number of image captions you want to generate. Accepted integer values: 1-3.\n- : One of the supported language codes. Languages supported:- English (`en`)\n- French (`fr`)\n- German (`de`)\n- Italian (`it`)\n- Spanish (`es`)\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/imagetext:predict\n```\nRequest JSON body:\n```\n{\n \"instances\": [ {\n  \"image\": {\n   \"bytesBase64Encoded\": \"B64_IMAGE\"\n  }\n }\n ],\n \"parameters\": {\n \"sampleCount\": RESPONSE_COUNT,\n \"language\": \"LANGUAGE_CODE\"\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/imagetext:predict\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/publishers/google/models/imagetext:predict\" | Select-Object -Expand Content\n```The following sample responses are for a request with\n`\"sampleCount\": 2`\n. The response returns two prediction strings.\n **English (en):** \n```\n{\n \"predictions\": [ \"a yellow mug with a sheep on it sits next to a slice of cake\",\n \"a cup of coffee with a heart shaped latte art next to a slice of cake\"\n ],\n \"deployedModelId\": \"DEPLOYED_MODEL_ID\",\n \"model\": \"projects/PROJECT_ID/locations/LOCATION/models/MODEL_ID\",\n \"modelDisplayName\": \"MODEL_DISPLAYNAME\",\n \"modelVersionId\": \"1\"\n}\n```\n **Spanish (es):** \n```\n{\n \"predictions\": [ \"una taza de caf\u00e9 junto a un plato de pastel de chocolate\",\n \"una taza de caf\u00e9 con una forma de coraz\u00f3n en la espuma\"\n ],\n \"deployedModelId\": \"DEPLOYED_MODEL_ID\",\n \"model\": \"projects/PROJECT_ID/locations/LOCATION/models/MODEL_ID\",\n \"modelDisplayName\": \"MODEL_DISPLAYNAME\",\n \"modelVersionId\": \"1\"\n}\n```\n## Response body\n```\n{\u00a0 \"predictions\": [ string ]}\n```\n| Response element | Description              |\n|:-------------------|:------------------------------------------------------------------|\n| predictions  | List of text strings representing captions, sorted by confidence. |\n## Sample response\n```\n{\u00a0 \"predictions\": [\u00a0 \u00a0 \"text1\",\u00a0 \u00a0 \"text2\"\u00a0 ]}\n```", "guide": "Generative AI on Vertex AI"}