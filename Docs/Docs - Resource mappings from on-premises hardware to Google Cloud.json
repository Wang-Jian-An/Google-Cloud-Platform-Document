{"title": "Docs - Resource mappings from on-premises hardware to Google Cloud", "url": "https://cloud.google.com/architecture/resource-mappings-from-on-premises-hardware-to-gcp", "abstract": "# Docs - Resource mappings from on-premises hardware to Google Cloud\nThis document shows you how to find the right resource mappings from on-premises hardware to Google Cloud. In a scenario where your applications are running on bare-metal servers and you want to migrate them to Google Cloud, you might consider the following questions:\n- How do physical cores (pCPUs) map to virtual CPUs (vCPUs) on Google Cloud? For example, how do you map 4 physical cores of bare-metal [Xeon E5](https://ark.intel.com/content/www/us/en/ark/products/47923/intel-xeon-processor-e5640-12m-cache-2-66-ghz-5-86-gt-s-intel-qpi.html) to vCPUs in Google Cloud?\n- How do you account for performance differences between different CPU platforms and processor generations? For example, is a 3.0 GHz [Sandy Bridge](https://wikipedia.org/wiki/Sandy_Bridge) 1.5 times faster than a 2.0 GHz [Skylake](https://wikipedia.org/wiki/Skylake_(microarchitecture)) ?\n- How do you right-size resources based on your workloads? For example, how can you optimize a memory-intensive, single-threaded application that's running on a multi-core server?\n**Note:** Most of the topics discussed in this document are active areas of academic and industry research. This document provides a high-level overview of these topics. We recommend that you exercise diligence based on the nature of your migration.\n", "content": "## Sockets, CPUs, cores, and threads\nThe terms , , , and are often used interchangeably, which can cause confusion when you are migrating between different environments.\nSimply put, a server can have one or more sockets. A [socket](https://wikipedia.org/wiki/CPU_socket) (also called a or ) is the connector on the motherboard that houses a CPU chip and provides physical connections between the CPU and the [circuit board](https://wikipedia.org/wiki/Printed_circuit_board) .\nA CPU refers to the actual [integrated circuit](https://wikipedia.org/wiki/Integrated_circuit) (IC). The fundamental operation of a CPU is to execute a sequence of stored [instructions](https://wikipedia.org/wiki/Instruction_(computing)) . At a high level, CPUs follow the fetch, decode, and execute steps, which are collectively known as the [instruction cycle](https://wikipedia.org/wiki/Instruction_cycle) . In more complex CPUs, multiple instructions can be fetched, decoded, and executed simultaneously.\nEach CPU chip can have one or more cores. A core essentially consists of an [execution unit](https://wikipedia.org/wiki/Execution_unit) that receives instructions and performs actions based on those instructions. In a [hyper-threaded system](https://wikipedia.org/wiki/Hyper-threading) , a physical processor core allows its resources to be allocated as multiple logical processors. In other words, each physical processor core is presented as two virtual (or logical) cores to the operating system.\nThe following diagram shows a high-level view of a quad-core CPU with hyper-threading enabled.\nIn Google Cloud, each [vCPU](/compute/docs/faq#virtualcpu) is implemented as a single hyper-thread on one of the available [CPU platforms](/compute/docs/cpu-platforms) .\nTo find the total number of vCPUs (logical CPUs) in your system, you can use the following formula:\n= \u00d7 \u00d7\nThe [lscpu](https://linux.die.net/man/1/lscpu) command gathers information that includes the number of sockets, CPUs, cores, and threads. It also includes information about the CPU caches and cache sharing, family, model, and [BogoMips](https://wikipedia.org/wiki/BogoMips) . Here's some typical output:\n```\n...\nArchitecture:   x86_64\nCPU(s):     1\nOn-line CPU(s) list: 0\nThread(s) per core:  1\nCore(s) per socket:  1\nSocket(s):    1\nCPU MHz:    2200.000\nBogoMIPS:    4400.00\n...\n```\nWhen you map CPU resources between your existing environment and Google Cloud, make sure that you know how many physical or virtual cores your server has. For more information, see the [Mapping resources](#map_resources) section.\n## CPU clock rate\nFor a program to execute, it must be broken down into a set of instructions that the processor understands. Consider the following C program that adds two numbers and displays the result:\n```\n#include <stdio.h>int main(){\u00a0 \u00a0 \u00a0 \u00a0 int a = 11, b = 8;\u00a0 \u00a0 \u00a0 \u00a0 printf(\"%d \\n\", a+b);}\n```\nOn compilation, the program is converted into the following [assembly code](https://wikipedia.org/wiki/Assembly_language) :\n```\n...main:.LFB0:\u00a0 \u00a0 \u00a0 \u00a0 .cfi_startproc\u00a0 \u00a0 \u00a0 \u00a0 pushq \u00a0 %rbp\u00a0 \u00a0 \u00a0 \u00a0 .cfi_def_cfa_offset 16\u00a0 \u00a0 \u00a0 \u00a0 .cfi_offset 6, -16\u00a0 \u00a0 \u00a0 \u00a0 movq \u00a0 \u00a0%rsp, %rbp\u00a0 \u00a0 \u00a0 \u00a0 .cfi_def_cfa_register 6\u00a0 \u00a0 \u00a0 \u00a0 subq \u00a0 \u00a0$16, %rsp\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0$11, -8(%rbp)\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0$8, -4(%rbp)\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0-8(%rbp), %edx\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0-4(%rbp), %eax\u00a0 \u00a0 \u00a0 \u00a0 addl \u00a0 \u00a0%edx, %eax\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0%eax, %esi\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0$.LC0, %edi\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0$0, %eax\u00a0 \u00a0 \u00a0 \u00a0 call \u00a0 \u00a0printf\u00a0 \u00a0 \u00a0 \u00a0 movl \u00a0 \u00a0$0, %eax\u00a0 \u00a0 \u00a0 \u00a0 leave\u00a0 \u00a0 \u00a0 \u00a0 .cfi_def_cfa 7, 8\u00a0 \u00a0 \u00a0 \u00a0 ret\u00a0 \u00a0 \u00a0 \u00a0 .cfi_endproc...\n```\nEach assembly instruction in the preceding output corresponds to a single machine instruction. For example, the `pushq` instruction indicates that the contents of the [RBP register](https://wikipedia.org/wiki/X86#Purpose) should be pushed onto the program stack. During each CPU cycle, a CPU can perform a basic operation such as fetching an instruction, accessing the content of a register, or writing data. To step through each stage of the cycle for adding two numbers, see this [CPU simulator](https://tools.withcode.uk/cpu/?ram=913f911f920000000000000000000000) .\nNote that each CPU instruction might require multiple clock cycles to execute. The average number of clock cycles required per instruction for a program is defined by [cycles per instruction](https://wikipedia.org/wiki/Cycles_per_instruction) (CPI), like so:\n= /\nMost modern CPUs can execute multiple instructions per clock cycle through [instruction pipelining](https://wikipedia.org/wiki/Instruction_pipeline) . The average number of instructions executed per cycle is defined by [instructions per cycle](https://wikipedia.org/wiki/Instructions_per_cycle) (IPC), like so:\n= /\nThe CPU clock rate defines the number of clock cycles that the processor can execute per second. For example, a 3.0 GHz processor can execute 3 billion clock cycles per second. This means that every clock cycle takes ~0.3 nanoseconds to execute. During each clock cycle, a CPU can perform 1 or more instructions as defined by IPC.\nClock rates are commonly used to compare processor performances. Going by their literal definition (number of cycles executed per second), you might conclude that a higher number of clock cycles would mean that the CPU can do more work and hence perform better. This conclusion might be valid when comparing CPUs in the same processor generation. However, clock rates should not be used as a sole performance indicator when comparing CPUs across different processor families. A new-generation CPU might provide better performance even when it runs at a lower clock rate than prior-generation CPUs.\n## Clock rates and system performance\nTo better understand a processor's performance, it's important to look not just at the number of clock cycles but also at the amount of work a CPU can do per cycle. The total execution time of a CPU-bound program is not only dependent on the clock rate but also on other factors such as number of instructions to be executed, cycles per instruction or instructions per cycle, [instruction set architecture](https://wikipedia.org/wiki/Instruction_set_architecture) , [scheduling](https://wikipedia.org/wiki/Scheduling_(computing)) and [dispatching](https://wikipedia.org/wiki/Scheduling_(computing)#Dispatcher) algorithms, and programming language used. These factors can vary significantly from one processor generation to another.\nTo understand how CPU execution can vary across two different implementations, consider the example of a simple [factorial](https://wikipedia.org/wiki/Factorial) program. One of the following programs is written in C and another in Python. [Perf](https://perf.wiki.kernel.org/index.php/Tutorial) (a profiling tool for Linux) is used to capture some of the CPU and kernel metrics.\n**C program**\n```\n#include <stdio.h>\nint main()\n{\n int n=7, i;\n unsigned int factorial = 1;\n for(i=1; i<=n; ++i){\n   factorial *= i;\n }\n printf(\"Factorial of %d = %d\", n, factorial);\n}\nPerformance counter stats for './factorial':\n...\n0    context-switches  # 0.000 K/sec\n0    cpu-migrations   # 0.000 K/sec\n45   page-faults   # 0.065 M/sec\n1,562,075  cycles     # 1.28 GHz\n1,764,632  instructions   # 1.13 insns per cycle\n314,855  branches    # 257.907 M/sec\n8,144   branch-misses   # 2.59% of all branches\n...\n0.001835982 seconds time elapsed\n```\n**Python program**\n```\nnum = 7\nfactorial = 1\nfor i in range(1,num + 1):\n factorial = factorial*i\nprint(\"The factorial of\",num,\"is\",factorial)\nPerformance counter stats for 'python3 factorial.py':\n...\n7    context-switches  # 0.249 K/sec\n0    cpu-migrations  # 0.000 K/sec\n908   page-faults   # 0.032 M/sec\n144,404,306 cycles    # 2.816 GHz\n158,878,795 instructions   # 1.10 insns per cycle\n38,254,589  branches    # 746.125 M/sec\n945,615  branch-misses   # 2.47% of all branches\n...\n0.029577164 seconds time elapsed\n```\nThe highlighted output shows the total time taken to execute each program. The program written in C executed ~15 times faster than the program written in Python (1.8 milliseconds vs. 30 milliseconds). Here are some additional comparisons:\n- **Context switches** . When the system scheduler needs to run another program or when an interrupt triggers an on-going execution, the operating system saves the running program's CPU register contents and sets them up for the new program execution. No context switches occurred during the C program's execution, but 7 context switches occurred during the Python program's execution.\n- **CPU migrations** . The operating system tries to maintain [workload balance](https://wikipedia.org/wiki/Scheduling_(computing)) among the available CPUs in multi-processor systems. This balancing is done periodically and every time a [CPU run queue](https://wikipedia.org/wiki/Run_queue) is empty. During the test, no CPU migration was observed.\n- **Instructions** . The C program resulted in 1.7 million instructions that were executed in 1.5 million CPU cycles (IPC = 1.13, CPI = 0.88), whereas the Python program resulted in 158 million instructions that were executed in 144 million cycles (IPC = 1.10, CPI = 0.91). Both programs filled up the pipeline, allowing the CPU to run more than 1 instruction per cycle. But compared to C, the number of instructions generated for Python is ~90 times greater.\n- **Page faults** . Each program has a slice of [virtual memory](https://wikipedia.org/wiki/Virtual_memory) that contains all of its instructions and data. Usually, it's not efficient to copy all of these instructions in the [main memory](https://wikipedia.org/wiki/Random-access_memory) at once. A [page fault](https://wikipedia.org/wiki/Page_fault) happens each time a program needs part of its virtual memory's content to be copied in the main memory. A page fault is signaled by the CPU through an [interrupt](https://wikipedia.org/wiki/Interrupt) .Because the [interpreter](https://wikipedia.org/wiki/Interpreted_language) executable for Python is much bigger than for C, the additional overhead is evident both in terms of CPU cycles (1.5M for C, 144M for Python) and page faults (45 for C, 908 for Python).\n- **Branches and branch-misses** . For conditional instructions, the CPU tries to predict the execution path even before evaluating the branching condition. Such a step is useful to keep the instruction pipeline filled. This process is called [speculative execution](https://wikipedia.org/wiki/Speculative_execution) . The speculative execution was quite successful in the preceding executions: the branch predictor was wrong only 2.59% of the time for the program in C, and 2.47% of the time for the program in Python.## Factors other than CPU\nSo far, you've looked at various aspects of CPUs and their impact on performance. However, it's rare for an application to have sustained on-CPU execution 100% of the time. As a simple example, consider the following `tar` command that creates an archive from a user's `home` directory in Linux:\n```\n$ time tar cf archive.tar /home/\"$(whoami)\"\n```\nThe output looks like this:\n```\nreal 0m35.798s\nuser 0m1.146s\nsys 0m6.256s\n```\nThese output values are defined as follows:\nIn the preceding example, the user time is 1.0 second, while the system time is 6.3 seconds. The ~28 seconds difference between `real` time and `user` + `sys` time points to the spent by the `tar` command.\nA high off-CPU time for an execution indicates that the process is not CPU bound. Computation is said to be bound by something when that resource is the bottleneck for achieving the expected performance. When you plan a migration, it's important to have a holistic view of the application and to consider all the factors that can have a meaningful impact on performance.\n## Role of target workload in migration\nIn order to find a reasonable starting point for the migration, it's important to benchmark the underlying resources. You can do performance benchmarking in various ways:\n- **Actual target workload** : Deploy the application in the target environment and benchmark performance of the [key performance indicators](https://wikipedia.org/wiki/Performance_indicator) (KPIs). For example, KPIs for a web application can include the following:- Application load time\n- End-user latencies for end-to-end transactions\n- Dropped connections\n- Number of serving instances for low, average, and peak traffic\n- Resource (CPU, RAM, disk, network) utilization of serving instances\nHowever, deploying a full (or a subset of) target application can be complex and time consuming. For preliminary benchmarking, program-based benchmarks are generally preferred.\n- **Program-based benchmarks** : Program-based benchmarks focus on individual components of the application rather than the end-to-end application flow. These benchmarks run a mix of test profiles, where each profile is targeted toward one component of the application. For example, test profiles for a [LAMP stack](https://wikipedia.org/wiki/LAMP_(software_bundle)) deployment can include [Apache Bench](https://httpd.apache.org/docs/2.4/programs/ab.html) , which is used to benchmark the web server performance, and [Sysbench](https://github.com/akopytov/sysbench) , which is used to benchmark MySQL. These tests are generally easier to set up than actual target workloads and are highly portable across different operating systems and environments.\n- **Kernel or synthetic benchmarks** : To test key computationally intensive aspects from real programs, you can use synthetic benchmarks such as [matrix factorization](https://wikipedia.org/wiki/Non-negative_matrix_factorization) or [FFT](http://www.fftw.org/speed/) . You typically run these tests during the early application design phase. They are best suited for benchmarking only certain aspects of a machine such as VM and drive stress, I/O syncs, and cache thrashing.## Understanding your application\nMany applications are bound by CPU, memory, disk I/O, and network I/O, or a combination of these factors. For example, if an application is experiencing slowness due to contention on disks, providing more cores to the servers might not improve performance.\nNote that maintaining observability for applications over large, complex environments can be nontrivial. There are specialized monitoring systems that can keep track of all distributed, system-wide resources. For example, on Google Cloud you can use [Cloud Monitoring](/monitoring) to get full visibility across your code, applications, and infrastructure. A Cloud Monitoring example is discussed later in this section, but first it's a good idea to understand monitoring of typical system resources on a standalone server.\nMany utilities such as [top](https://wikipedia.org/wiki/Top_(software)) , [IOStat](https://wikipedia.org/wiki/Iostat) , [VMStat](https://wikipedia.org/wiki/Vmstat) , and [iPerf](https://wikipedia.org/wiki/Iperf) can provide a high-level view of a system's resources. For example, running `top` on a Linux system produces an output like this:\n```\ntop - 13:20:42 up 22 days, 5:25,   18 users,  load average: 3.93 2.77,3.37\nTasks: 818 total,  1 running,  760 sleeping, 0 stopped,  0 zombie\nCpu(s): 88.2%us,   0.0%sy,   0.0%ni,   0.3%id,   0.0%wa, 0.0%hi, 0.0%si, 0.0%st\nMem: 49375504k total, 6675048k used, 42700456k free, 276332k buffers\nSwap: 68157432k total, 0k used,  68157432k free, 5163564k cached\n```\nIf the system has a high load and the wait-time percentage is high, you likely have an I/O-bound application. If either or both of user-percentage time or system-percentage time are very high, you likely have a CPU-bound application.\nIn the previous example, the load averages (for a 4 vCPU VM) in the last 5 minutes, 10 minutes, and 15 minutes are 3.93, 2.77, and 3.37 respectively. If you combine these averages with the high percentage of user time (88.2%), low idle time (0.3%), and no wait time (0.0%), you can conclude that the system is CPU bound.\nAlthough these tools work well for standalone systems, they are typically not designed to monitor large, distributed environments. To monitor production systems, tools such as [Cloud Monitoring](/monitoring) , [Nagios](https://www.nagios.org/) , [Prometheus](https://prometheus.io/) , and [Sysdig](https://sysdig.com/) can provide in-depth analysis of resource consumption against your applications.\n[Performance monitoring](https://wikipedia.org/wiki/Application_performance_management) your application over a sufficient period of time lets you collect data across multiple metrics such as CPU utilization, memory usage, disk I/O, network I/O, roundtrip times, latencies, error rates, and throughput. For example, the following [Cloud Monitoring](/monitoring) graphs show CPU loads and utilization levels along with memory and disk usage for all servers running in a [Google Cloud managed instance group](/compute/docs/instance-groups) . To learn more about this setup, see the [Cloud Monitoring agent overview](/monitoring/agent) .\nFor analysis, the data-collection period should be long enough to show the peak and trough utilization of resources. You can then analyze the collected data to provide a starting point for capacity planning in the new target environment.\n## Map resources\nThis section walks through how to establish resource sizing on Google Cloud. First, you make an initial sizing assessment based on existing resource utilization levels. Then you run application-specific performance benchmarking tests.\n### Usage-based sizing\nFollow these steps to map the existing core count of a server to vCPUs in Google Cloud.\n- **Find the current core count** . Refer to the `lscpu` command in the [earlier section](#sockets-cpus-cores-and-threads) \n- **Find the CPU utilization of the server** . CPU usage refers to the time that the CPU takes when it is in [user mode](https://wikipedia.org/wiki/User-mode_Linux) ( `%us` ) or [kernel mode](https://wikipedia.org/wiki/Kernel_(operating_system)) ( `%sy` ). [Nice processes](https://wikipedia.org/wiki/Nice_(Unix)) ( `%ni` ) also belong to user mode, whereas software interrupts ( `%si` ) and hardware [interrupts](https://wikipedia.org/wiki/Interrupt) ( `%hi` ) are handled in kernel mode. If the CPU isn't doing any of these, then either it's idle or waiting for I/O to complete. When a process is waiting for I/O to complete, it doesn't contribute to CPU cycles.To calculate the current CPU usage of a server, you run the following `top` command:```\n...Cpu(s): 88.2%us, \u00a00.0%sy, \u00a00.0%ni, \u00a00.3%id, \u00a00.0%wa, \u00a00.0%hi, \u00a00.0%si, 0.0%st...\n```CPU usage is defined as follows:```\nCPU Usage = %us + %sy + %ni + %hi + %si\n```Alternatively, you can use any monitoring tool like Cloud Monitoring that can collect the required CPU inventory and utilization. For application deployments that are non-autoscaling (that is, run with one or more fixed number of servers), we recommend that you consider using peak utilization for CPU sizing. This approach safeguards application resources against disruptions when workloads are at peak utilization. For autoscaling deployments ( [based on CPU usage](/compute/docs/autoscaler/scaling-cpu#scaling_based_on_cpu_utilization) ), average CPU utilization is a safe baseline to consider for sizing. In that case, you handle traffic spikes by scaling out the number of servers for the duration of the spike.\n- **Allocate sufficient buffer to accommodate any spikes** . When you are CPU sizing, include a sufficient buffer to accommodate any unscheduled processing that might cause unexpected spikes. For example, you can plan for CPU capacity such that there's additional headroom of 10\u201315% over expected peak usage, and the overall maximum CPU utilization doesn't exceed 70%.\n- **Use the following formula to calculate the expected core count on GCP** : = 2 \u00d7 **CEILING** [( \u00d7 ) / (2 \u00d7 )]These values are defined as follows:- : The existing core count (as calculated in step 1).\n- : The CPU utilization of the server (as calculated in step 2).\n- : The maximum CPU usage allowed on the server after taking into account sufficient headroom (as calculated in step 3).For a concrete example, consider a scenario where you have to map the core count of a bare-metal [4-core Xeon E5640](https://ark.intel.com/content/www/us/en/ark/products/47923/intel-xeon-processor-e5640-12m-cache-2-66-ghz-5-86-gt-s-intel-qpi.html) server running on-premises to vCPUs in Google Cloud. Xeon E5640 specs are available [publicly](https://ark.intel.com/content/www/us/en/ark/products/47923/intel-xeon-processor-e5640-12m-cache-2-66-ghz-5-86-gt-s-intel-qpi.html) , but you can also confirm this by running a command like `lscpu` on the system. The numbers look like the following:\n- =(1) \u00d7(4) \u00d7(2) = **8** .\n- Suppose that the CPU utilization () observed during peak traffic is 40%.\n- There's a provision for an additional buffer of 30%; that is, maximum CPU utilization () should not exceed 70%.\n- = 2 \u00d7 **CEILING** [(8 \u00d7 0.4)/(2 \u00d7 0.7)] = **6 vCPUs** (that is, 2 \u00d7 **CEILING** [3.2/1.4] = 2 \u00d7 **CEILING** [2.28] = 2 \u00d7 3 = **6** )\nYou can do similar assessments for RAM, disk, network I/O, and other system resources.\n**Important:** The preceding conversion is based solely on resource utilization levels. The conversion doesn't take into account any platform differences between source and target environments.\n### Performance-based sizing\nThe previous section covered details of mapping pCPUs to vCPUs based on current and expected levels of CPU use. This section considers the application that's running on the server.\nIn this section, you run a standard, canonical set of tests (program-based benchmarks) in order to benchmark performance. Continuing with the example scenario, consider that you are running a MySQL server on the Xeon E5 machine. In this case, you can use [Sysbench OLTP](https://github.com/akopytov/sysbench) to benchmark the database performance.\nA simple read-write test on MySQL using Sysbench produces the following output:\n```\nOLTP test statistics:\n queries performed:\n read:    520982\n write:    186058\n other:    74424\n total:    781464\n transactions:  37211 (620.12 per sec.)\n deadlocks:   2 (0.03 per sec.)\n read/write requests: 707040 (11782.80 per sec.)\n other operations: 74424 (1240.27 per sec.)\nTest execution summary:\n total time:   60.0061s\n total number of events: 37211\n total time taken by event execution: 359.8158\n per-request statistics:\n min:   2.77ms\n avg:   9.67ms\n max:   50.81ms\n approx. 95 percentile: 14.63ms\nThread fairness:\n events (avg/stddev):   6201.8333/31.78\n execution time (avg/stddev): 59.9693/0.00\n```\nRunning this benchmark lets you compare performance in terms of number of transactions per second, total reads/writes per second, and end-to-end execution time between your current environment and Google Cloud. We recommend that you run multiple iterations of these tests in order to rule out any outliers. To observe performance differences under varying load and traffic patterns, you can also repeat these tests with different parameters, such as concurrency levels, duration of tests, and number of simulated users or varying hatch rates.\nThe performance numbers between the current environment and Google Cloud will help further rationalize your initial capacity assessment. If the benchmarking tests on Google Cloud yield similar or better results than the existing environment, then you can further adjust the scale of resources based on the performance gains. On the other hand, if benchmarks on your existing environment are better than on Google Cloud, you should do the following:\n- Revisit the initial capacity assessment.\n- Monitor system resources.\n- Find possible areas of contention (for example, bottlenecks identified on CPU and RAM).\n- Resize resources accordingly.\nAfter you're done, rerun your application-specific benchmark tests.\n### End-to-end performance benchmarking\nSo far, you've looked at a simplistic scenario that compared just the MySQL performance between on-premises and Google Cloud. In this section, you consider the following distributed 3-tier application.\nAs the diagram shows, you've likely run multiple benchmarks to reach a reasonable assessment of your current environment and Google Cloud. However, it can be challenging to establish which subset of benchmarks estimates your application performance most accurately. Furthermore, it can be a tedious task to manage the test process from dependency management to test installation, execution, and result aggregation across different cloud or non-cloud environments. For such scenarios, you can use [PerfKitBenchmarker](https://github.com/GoogleCloudPlatform/PerfKitBenchmarker) . PerfKit contains various sets of benchmarks to measure and compare different offerings across [multiple clouds](https://wikipedia.org/wiki/PerfKitBenchmarker#General) . It can also run certain benchmarks on-premises through [static machines](https://github.com/GoogleCloudPlatform/PerfKitBenchmarker/wiki/Can-I-run-PerfKitBenchmarker-on-my-local-machine-or-data-center%3F) .\nSuppose that for the 3-tier application in the preceding diagram, you want to run tests to benchmark cluster boot time, CPU, and network performance of VMs on Google Cloud. Using PerfKitBenchmarker, you can run multiple iterations of [relevant test profiles](https://github.com/GoogleCloudPlatform/PerfKitBenchmarker/blob/master/tools/demos/demo_config.yml) , which produce the following results:\n- [Cluster boot time](https://github.com/GoogleCloudPlatform/PerfKitBenchmarker/blob/master/perfkitbenchmarker/linux_benchmarks/cluster_boot_benchmark.py) : Provides a view of VM boot time. This is particularly important if the application is elastic and expects instances to be added or removed as part of autoscaling. The following graph shows that the boot times of an [n1-standard-4](/compute/docs/machine-types#general_purpose)  [Compute Engine](/compute) instance stay fairly consistent (up to the 99th percentile) at 40\u201345 seconds. \n- [Stress-ng](https://wiki.ubuntu.com/Kernel/Reference/stress-ng) : Measures and compares compute-intensive performance by stressing a system's processor, memory subsystem, and compiler. In the following example, `stress-ng` runs multiple stress tests such as [bsearch](https://wikipedia.org/wiki/Binary_search_algorithm) , [malloc](https://wikipedia.org/wiki/Memory_management#Dynamic_memory_allocation) , [matrix](https://wikipedia.org/wiki/Non-negative_matrix_factorization) , [mergesort](https://wikipedia.org/wiki/Merge_sort) , and [zlib](https://wikipedia.org/wiki/Zlib) on an `n1-standard-4` Compute Engine instance. `Stress-ng` measures stress-test throughput using [bogus operations (bogo ops) per second](https://wikipedia.org/wiki/BogoMips) . If you normalize bogo ops across different stress test results, you get the following output, which shows the geometric mean of operations executed per second. In this example, bogo ops range from ~8,000 per second at the 50th percentile to ~10,000 per second at the 95th percentile. Note that bogo ops are generally used to benchmark only standalone CPU performance. These operations might not be representative of your application. \n- [Netperf](https://github.com/HewlettPackard/netperf) : Measures latency with request and response tests. Request and response tests run at the [application layer](https://wikipedia.org/wiki/Internet_protocol_suite#Application_layer) of the network stack. This method of latency testing involves all of the layers of the stack and is preferred over [ping tests](https://wikipedia.org/wiki/Ping_(networking_utility)) to measure VM-to-VM latency. The following graph shows the TCP request and response (TCP_RR) latencies between a client and server that are running in the same [Google Cloud zone](/compute/docs/regions-zones) . TCP_RR values range from ~70 microseconds at the 50th percentile to ~130 microseconds at the 90th percentile. \nGiven the nature of the target workload, you can run other test profiles by using PerfKit. For details, see [supported benchmarks in PerfKit](https://github.com/GoogleCloudPlatform/PerfKitBenchmarker) .\n**Important:** PerfKit default settings are not tuned for any platform and can vary based on the selected instance type. When you compare results across different environments, make sure that you run all tests by using the same parameters (for example, test duration, number of threads, concurrent requests, and packet size).\n## Best practices on Google Cloud\nBefore you set up and execute a migration plan on Google Cloud, we recommend that you follow the migration best practices. These practices are only a starting point. You might need to consider many other aspects of your application\u2014such as decoupling dependencies, introducing fault tolerance, and ensuring scale-up and scale-down based on component workload\u2014and how each of those aspects map to Google Cloud.\n- **Know Google Cloud limits and quotas** . Before formally starting with capacity assessment, understand some important considerations for resource planning on Google Cloud\u2014for example:- [Per-instance network quotas](/vpc/docs/quota#per_instance) \n- [Disk performance on Google Cloud](/compute/docs/disks/performance) \n- [Available CPU platforms on Google Cloud](/compute/docs/instances/specify-min-cpu-platform) \nList the [infrastructure as a service (IaaS) and platform as a service (PaaS) components](/solutions/best-practices-migrating-vm-to-compute-engine#designing_the_migration) that would be required during the migration and clearly understand any quotas and limits and any fine-tuning adjustments available with each of the services.\n- **Monitor resources continuously** . Continuous resource monitoring can help you identify patterns and trends in system and application performance. Monitoring not only helps establish baseline performance but also demonstrates the need for hardware upgrades and downgrades over time. Google Cloud provides various options to deploy end-to-end monitoring solutions:- [Full stack monitoring through Cloud Monitoring](/monitoring/docs) \n- [Application profiling](/profiler/docs) \n- [Distributed tracing](/trace/docs) \n- **Right-size your VMs** . Identify when a VM is under-provisioned or over-provisioned. Setting up basic monitoring [as discussed earlier](#understanding-your-application) should easily provide these insights. Google Cloud also provides [right-sizing recommendations](/compute/docs/instances/apply-sizing-recommendations-for-instances#how_sizing_recommendations_work) based on an instance's historical usage. Furthermore, based on the nature of the workload, if predefined machine types don't meet your needs, you can create an instance with [custom virtualized hardware settings](/compute/docs/instances/creating-instance-with-custom-machine-type) .\n- **Use the right tools** . For large-scale environments, deploy automated tools to minimize manual effort\u2014for example:- [StratoZone](https://www.stratozone.com/) and [CloudPhysics](https://www.cloudphysics.com/) for application discovery and existing inventory data collection.\n- [Migrate to Virtual Machines](/migrate/compute-engine) to migrate VMs to Google Cloud and for [built-in testing](/migrate/compute-engine/docs/4.5/how-to/using-test-clones/creating-a-test-clone) to validate in-cloud performance, SLAs, and cost.\n- [Database Migration Service](/database-migration) to migrate data and databases to Google Cloud.\n- [Cloud Deployment Manager](/deployment-manager) to provision cloud infrastructure resources as code (IaC).\n## Takeaways\nMigrating resources from one environment to another requires careful planning. It's important to not look at hardware resources in isolation but to take an end-to-end view of your application. For example, instead of solely focusing on whether a 3.0 GHz Sandy Bridge processor is going to be twice as fast as a 1.5 GHz Skylake processor, focus instead on how your application's key performance indicators change from one computing platform to another.\nWhen you assess resource mapping requirements across different environments, consider the following:\n- System resources that your application is constrained by (for example, CPU, memory, disk, or network).\n- Impact of the underlying infrastructure (for example, processor generation, clock speed, HDD or SSD) on the performance of your application.\n- Impact of software and architectural design choices (for example, single or multithreaded workloads, fixed or autoscaling deployments) on the performance of the application.\n- Current and expected utilization levels of compute, storage, and network resources.\n- Most appropriate performance tests that are representative of your application.\nCollecting data against these metrics through continuous monitoring helps you determine an [initial capacity plan](#usage-based-sizing) . You can follow up by doing appropriate performance [benchmarking](#performance-based-sizing) to fine-tune your initial sizing estimates.\n## What's next\n- Learn more about [best practices for migrating VMs to Google Cloud](/solutions/best-practices-migrating-vm-to-compute-engine) .\n- Read about Google Cloud's [migration center](/migration-center) .\n- Learn more about the [Cloud Foundation Toolkit](/foundation-toolkit) .\n- Learn more about [how to get started with Google Cloud migration](/solutions/migration-to-gcp-getting-started) .\n- Learn more about how [Google Cloud compares with other cloud platforms](/docs/compare) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Docs"}