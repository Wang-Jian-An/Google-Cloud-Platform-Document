{"title": "Docs - Deploy your migration with Istio mesh expansion", "url": "https://cloud.google.com/architecture/migrate-with-istio-mesh-expansion/deployment", "abstract": "# Docs - Deploy your migration with Istio mesh expansion\nLast reviewed 2023-11-02 UTC\nThis document describes how to initialize and configure a [service mesh](https://istio.io/docs/concepts/what-is-istio/) to support a feature-by-feature migration from an on-premises data center to Google Cloud. It assumes that you're familiar with the associated [reference architecture](/architecture/migrate-with-istio-mesh-expansion) . It's intended for administrators, developers, and engineers who want to use a service mesh that dynamically routes traffic either to the source environment or to Google Cloud.\nThis deployment guide is intended to help you migrate from a non-Google Cloud environment (such as on-premises or another cloud provider) to Google Cloud. Such migrations have a layer of network complexity because you have to set up a [secure communication channel](/hybrid-connectivity) between the non-Google Cloud environment and the Google Cloud environment.\n", "content": "## Architecture\nThe following diagram shows how you can use a service mesh to route traffic either to microservices running in the source environment or to Google Cloud:\nIn the diagram, Istio Gateway provides a service mesh that links the microservices of an application. Google Kubernetes Engine (GKE) acts as a container to define the boundaries of each microservice. For more information, see [Support your migration with Istio mesh expansion](/architecture/migrate-with-istio-mesh-expansion) .\nIn this deployment, you use the following software:\n- [Ubuntu Server](https://www.ubuntu.com/server) and [Container-Optimized OS](/container-optimized-os/docs) : Operating systems used in this deployment.\n- [Docker Engine](https://docs.docker.com/engine/) : Platform to run containerized workloads.\n- [Docker Compose](https://docs.docker.com/compose/) : A tool for defining and running Docker apps.\n- [Istio](https://istio.io/) : An open source service mesh.\n- [Kiali](https://www.kiali.io/) : A tool to visualize Istio service meshes.\n- [Envoy](https://www.envoyproxy.io/) : A sidecar proxy used by Istio to include services in the mesh.## The example workload\nIn this deployment, you use the [Bookinfo](https://istio.io/docs/examples/bookinfo/) app, which is a 4-tier, [polyglot](https://en.wikipedia.org/wiki/Polyglot_(computing)) microservices app that shows information about books. This app is designed to run on Kubernetes, but you deploy it on a Compute Engine instance by using Docker and Docker Compose. With Docker Compose, you describe multi-container apps using YAML [descriptors](https://docs.docker.com/compose/compose-file) . You can then start the app by executing a single command.\nAlthough this example workload is already containerized, this approach also applies to non-containerized services. In such cases, you can add a modernization phase where you containerize services that you intend to migrate.\nThe Bookinfo app has four microservice components:\n- `productpage`: Calls the`details`,`ratings`, and`reviews`microservices to populate the book information page\n- `details`: Serves information about books\n- `reviews`: Contains book reviews\n- `ratings`: Returns book ranking information to accompany a book review\nTo demonstrate Istio and its features, the authors and maintainers of the Bookinfo app have implemented multiple versions of some of these components. In this deployment, you deploy only one version of each component.\n## Objectives\n- Initialize an environment that simulates the on-premises data center.\n- Deploy and test example workloads on the on-premises data center.\n- Configure the target environment on Google Cloud.\n- Migrate the workload from the on-premises data center to the target environment.\n- Test the workloads running in the target environment.\n- Retire the on-premises data center.## Costs\nIn this document, you use the following billable components of Google Cloud:\n- [Compute Engine](/compute) \n- [Google Kubernetes Engine (GKE)](/kubernetes-engine) \n- [Persistent Disk](/persistent-disk) \n- [Networking](/vpc) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) .\n## Prepare your environment\nYou perform most of the steps for this deployment in [Cloud Shell](/shell) .\n- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.\n- In Cloud Shell, check the amount of free space that you have:```\ndf -h\n```To complete this deployment, you need about 200 MB of free space.\n- Change the working directory to the `${HOME}` directory:```\ncd \"${HOME}\"\n```\n- Clone the Git repository, which contains the scripts and the manifest files to deploy and configure the example workload:```\ngit clone https://github.com/GoogleCloudPlatform/solutions-istio-mesh-expansion-migration\n```\n- Authenticate with [Application Default Credentials (ADC)](https://developers.google.com/identity/protocols/application-default-credentials) :```\ngcloud auth application-default login\n```The output shows the path to the `Application Default Credentials` file:```\nCredentials saved to file:[/tmp/tmp.T5Qae7XwAO/application_default_credentials.json]\n```Make a note of the path to the `Application Default Credentials` file. These credentials will be used by any library that requests ADC.\n- Initialize the environment variables:```\nAPPLICATION_DEFAULT_CREDENTIALS_PATH=APPLICATION_DEFAULT_CREDENTIALS_PATHBILLING_ACCOUNT_ID=BILLING_ACCOUNT_IDDEFAULT_FOLDER=DEFAULT_FOLDERDEFAULT_PROJECT=DEFAULT_PROJECTDEFAULT_REGION=DEFAULT_REGIONDEFAULT_ZONE=DEFAULT_ZONEGKE_CLUSTER_NAME=istio-migrationDEPLOYMENT_DIRECTORY_PATH=\"$(pwd)\"/solutions-istio-mesh-expansion-migrationORGANIZATION_ID=ORGANIZATION_ID\n```Replace the following:- ``: the path to the ADC file from the previous step.\n- ``: the ID of the billing account to use.\n- ``: the ID of the Google Cloud [folder](/resource-manager/docs/cloud-platform-resource-hierarchy#folders) to create the Google Cloud project in. If you want Terraform to create the Google Cloud project directly under the Google Cloud [organization](/resource-manager/docs/cloud-platform-resource-hierarchy#organizations) , leave this string empty.\n- ``: the ID of the Google Cloud project to provision the resources to complete this deployment. Terraform creates this project for you when it provisions the environment.\n- ``: the default [region](/compute/docs/regions-zones) where resources are provisioned.\n- ``: the default [zone](/compute/docs/regions-zones) where resources are provisioned.\n- ``: the ID of your Google Cloud [organization](/resource-manager/docs/cloud-platform-resource-hierarchy#organizations) .\n## Provision your environments\nIn this section, you provision the following environments for this deployment:\n- An environment that simulates the source on-premises data center.\n- An environment that simulates the migration target.\nIn this deployment, both environments run in Google Cloud. This approach helps to simplify the setup process because there is only one bootstrapping phase. You automatically provision the source and target environments using Terraform.\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Initialize the Terraform backend configuration:```\nscripts/init.sh \\--application-credentials \"${APPLICATION_DEFAULT_CREDENTIALS_PATH}\" \\--billing-account-id \"${BILLING_ACCOUNT_ID}\" \\--default-folder \"${DEFAULT_FOLDER}\" \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\" \\--organization-id \"${ORGANIZATION_ID}\"\n```The `init.sh` script does the following:- Generates the descriptors to configure the [Terraform backend](https://www.terraform.io/docs/language/settings/backends/index.html) .\n- Initializes the Terraform working directory.\n- Change the working directory to the `terraform` directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"/terraform\n```\n- Apply the changes with Terraform:```\nterraform apply\n```\n- When prompted, review the proposed changes and confirm by entering `yes` .The output is similar to the following:```\nApply complete! Resources: 27 added, 0 changed, 0 destroyed\n```\nBy applying the proposed changes with Terraform, you automate the following tasks:\n- [Creating firewall rules](/vpc/docs/using-firewalls#creating_firewall_rules) to allow external access to the microservices and to the database and inter-node communications.\n- [Creating and enabling a service account](/compute/docs/access/create-enable-service-accounts-for-instances) for the Compute Engine instances to use. We recommend that you limit the service account to only the roles and access permissions that are required to run the app. For this deployment, the service account for Compute Engine instances only requires the [Compute Viewer role](/compute/docs/access/iam#compute.viewer) (`roles/compute.viewer`). This role provides read-only access to Compute Engine resources.\n- Provisioning and configuring a Compute Engine instance to host the workloads to migrate, as a source environment. When you configure the Compute Engine instance, you provide a startup script that installs Docker, Docker Compose, and [Dnsmasq](https://thekelleys.org.uk/dnsmasq/doc.html) .\n- Creating and enabling a service account for the GKE cluster to host the workloads as a target environment. In this deployment, you create a service account that the GKE cluster nodes use. We recommend that you limit the service account to just the roles and access permissions that are required in order to run the app. For this deployment, the roles required for the service account for GKE cluster nodes are as follows:- [Monitoring Viewer](/monitoring/access-control#mon_roles_desc) (`roles/monitoring.viewer`)\n- [Monitoring Metric Writer](/monitoring/access-control#mon_roles_desc) (`roles/monitoring.metricWriter`)\n- [Logs Writer](/logging/docs/access-control#permissions_and_roles) (`roles/logging.logWriter`), as described in [Hardening your cluster's security](/kubernetes-engine/docs/how-to/hardening-your-cluster#use_least_privilege_sa) \n- Provisioning and configuring a GKE cluster to host the workloads, as a target environment. To provision the GKE clusters, Terraform uses the [kubernetes-engine Terraform module](https://registry.terraform.io/modules/terraform-google-modules/kubernetes-engine) .## Deploy the workload in the source environment\nIn this deployment, you deploy the Istio Bookinfo App as the workload to migrate. The following diagram shows the architecture of the source environment:\nIn the diagram, clients access the example workload that's running on Compute Engine. To reduce complexity in this example, clients connect directly to a single Compute Engine instance. In a production environment, this direct connection is unlikely because you need a load-balancing layer to run multiple instances of a workload.\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Deploy the workloads in the Compute Engine instances:```\nscripts/workloads.sh \\--deploy-with \"COMPOSE\" \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\"\n```The `workloads.sh` script does the following:- Configures the default project, region, and zone.\n- Copies the Docker Compose descriptors to the Compute Engine instances.\n- Deploys the example workload using Docker Compose.\nIf you didn't previously create an SSH key file to authenticate with Compute Engine instances, the gcloud CLI prompts you to generate one.In the output, you see a confirmation of the deployment and how you can access it. The output is similar to the following:```\nYou can access the workload by loading http://COMPUTE_ENGINE_PRODUCTPAGE_EXTERNAL_IP:9080/productpage\n```In the output, `` is the IP address where the workload is served. Make a note of the IP address, because you use it in a later step.## Test your deployment in the source environment\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://COMPUTE_ENGINE_PRODUCTPAGE_EXTERNAL_IP:9080/productpage\n```\nA Bookinfo page is displayed with details about books and relevant ratings.\n## Configure Istio\nIn this section, you configure the target environment in Google Cloud by installing Istio, and then you use Istio to expose the example workload. The following diagram shows the architecture of the target environment:\nIn the diagram, Istio exposes the workload that's running in Compute Engine.\n### Install Istio\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Install Istio:```\nscripts/install-istio.sh \\--cluster-name \"${GKE_CLUSTER_NAME}\" \\--google-cloud-project \"${DEFAULT_PROJECT}\" \\--cluster-region \"${DEFAULT_REGION}\"\n```The `install-istio.sh` script does the following:- Downloads the Istio distribution.\n- Installs Istio in the target environment GKE cluster.\n- Deploys a [Gateway](https://istio.io/latest/docs/reference/config/networking/gateway/) to expose the services in the service mesh.\n- Configures Istio to allow the [expansion of the service mesh](https://istio.io/latest/docs/setup/install/virtual-machine/) to the Compute Engine instances that are simulating the source environment.\n- Installs service mesh monitoring and visualization tools, such as Kiali.\nWhen this command finishes running, the console shows a confirmation of installation. The output is similar to the following:```\n\u2714 Istio core installed\n\u2714 Istiod installed\n\u2714 Ingress gateways installed\n\u2714 Egress gateways installed\n\u2714 Installation complete\n```\n### Configure Istio mesh expansion\nIn this section, you connect the Compute Engine instance that simulates the source environment to the service mesh. The service mesh handles connecting the microservices in the legacy environment that will be migrated to the target environment. In this phase, the service mesh is empty, waiting for services to be registered. The service mesh isn't receiving any production traffic yet.\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Install and configure Istio on the Compute Engine instance:```\nscripts/compute-engine-mesh-expansion-setup.sh \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\"\n```The `compute-engine-mesh-expansion-setup.sh` script does the following:- Installs Istio on the source environment Compute Engine instances.\n- Starts the Istio service on the Compute Engine instances.\n### Expose the workload\nIn this section, you register the workloads that are running in the Compute Engine instance and simulating the source environment to the Istio service mesh.\nThe `workloads.sh` script that you run in this section sets up routing rules to split production traffic between services running in the legacy environment and services running in the target environment, using the service mesh. Because traffic routing inside the service mesh is transparent to clients, they won't know that the routing configuration has changed.\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Expose the workloads:```\nscripts/workloads.sh \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\" \\--expose-with \"ISTIO_COMPUTE_ENGINE\"\n```\n- The `workloads.sh` script does the following:- Configures the default project, region, and zone.\n- Enables [automatic sidecar injection](https://istio.io/latest/docs/setup/additional-setup/sidecar-injection/#automatic-sidecar-injection) to avoid manual edits to your deployment descriptors.\n- Registers the workloads running in the Compute Engine instance to the mesh by configuring the [WorkloadEntry](https://istio.io/latest/docs/reference/config/networking/workload-entry/) endpoints and the corresponding Services.\n- Deploys the [ServiceEntries](https://istio.io/latest/docs/reference/config/networking/service-entry/) to allow traffic to the [Compute Engine metadata server](/compute/docs/storing-retrieving-metadata) and to [Cloud APIs](/apis) .\n- Deploys the [Virtual Services](https://istio.io/latest/docs/reference/config/networking/virtual-service/) to route traffic from the Istio Gateway to the`productpage`instance running in the Compute Engine instance.\nIn the output, you see a confirmation of the deployment and how you can access it. The output is similar to the following:```\nYou can access the workload by loading http://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/productpage\n```In the output, `` is the IP address where the workload is served. Make a note of the IP address because you use it in a later step.\n### Test the Istio mesh expansion\nIn this section, you test the example workload that's running in the Compute Engine instance that you used Istio to expose.\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/productpage\n```\nThe source environment entry point (which connects to the Compute Engine instance) is still available at this stage. When you migrate a production environment, we recommend that you gradually redirect traffic to the target environment by updating the configuration of the load-balancing layer.\n### Visualize the service mesh\nIn this section, you use Kiali to show a visual representation of the service mesh.\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/kiali/console/graph/namespaces/?edges=requestDistribution&graphType=versionedApp&namespaces=default%2Cistio-system&idleNodes=false&duration=60&refresh=15000&operationNodes=false&idleEdges=false&injectServiceNodes=true&layout=dagre\n```The Kiali service dashboard is displayed.\n- In Cloud Shell, run a request multiple times for the main page of the example workload:```\nISTIO_INGRESS_GATEWAY_EXTERNAL_IP=\"$(kubectl get svc istio-ingressgateway -n istio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\"for i in {1..10000}; do curl -s -o /dev/null -w \"$(date --iso-8601=ns) - %{http_code}\\n\" \u00a0http://\"${ISTIO_INGRESS_GATEWAY_EXTERNAL_IP}\"/productpage; done\n```The request generates traffic to the Bookinfo app. The output shows a list of the timestamps for each HTTP request to the `productpage` service, and the HTTP return code of each request ( `200` in this case).The output is similar to the following:```\n2021-06-09T10:16:15,355323181+00:00 - 200\n2021-06-09T10:16:15,355323182+00:00 - 200\n2021-06-09T10:16:15,355323183+00:00 - 200\n[...]\n```The request takes time to complete, so you can leave it running and proceed to the next step.\n- In the Kiali service dashboard, you see a diagram of the current mesh, with traffic routed to services running in Compute Engine. All of the traffic is routed from the `istio-ingressgateway` to the `productpage` microservice that runs on the Compute Engine instance with the `compute-engine` version label, and to the `kiali` service to visualize the service mesh.You don't see the other services in the graph ( `details` , `reviews` , and `ratings` ) because the `productpage` microservice that runs in Compute Engine connects directly to the other microservices running in Compute Engine. The `productpage` microservice does not go through the service mesh.If you want all the traffic to go through the service mesh, you need to reconfigure the workloads running in Compute Engine to point to the services in the service mesh, instead of connecting to them directly.If you don't see the following diagram on the Kiali dashboard, refresh the page.The diagram on the Kiali dashboard shows that traffic is routed to services that are running in Compute Engine.\n- In Cloud Shell, to stop the traffic generation command, press `Control+C` .## Migrate the workload\nIn this section, you migrate the components of the example workload from the Compute Engine instances to the GKE cluster. For each microservice of the example workload, you do the following:\n- Deploy an instance of the microservice in the GKE cluster.\n- Start routing traffic to both the microservice instances running in Compute Engine and running in GKE.\nThe following diagram shows the architecture of the system for this section:\nIn the diagram, Cloud Load Balancing routes traffic to Istio Gateway, and then Istio either routes the traffic to services that are running in Compute Engine, or to services running in GKE.\nTo migrate the components of the example workload, do the following:\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Deploy the workloads in the target environment:```\nscripts/workloads.sh \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\" \\--deploy-with \"GKE\"\n```The `workloads.sh` script does the following:- Enables [automatic sidecar injection](https://istio.io/latest/docs/setup/additional-setup/sidecar-injection/#automatic-sidecar-injection) to avoid manual edits to your deployment descriptors.\n- Deploys the [ServiceAccounts](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/) and the [Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) to run the example workloads in the GKE cluster.\nYou see a confirmation of the deployment, and how you can access it. The output is similar to the following:```\nYou can access the workload by loading http://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/productpage\n```\nThe service mesh routes traffic to both the example workloads running in the Compute Engine instances and the ones running in the GKE cluster.\n### Test the workload running in Compute Engine and GKE\nIn this section, you test the example workload that you deployed in Compute Engine and GKE.\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/productpage\n```A Bookinfo page is displayed with information about books and relevant ratings.\nBecause you deployed the same version of the example workload in the Compute Engine and in the GKE cluster, the output is the same as the [previous test](#test-istio-mesh-expansion) .\n### Visualize the service mesh\nIn this section, you use Kiali to show a visual representation of the service mesh.\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/kiali/console/graph/namespaces/?edges=requestDistribution&graphType=versionedApp&namespaces=default%2Cistio-system&idleNodes=false&duration=60&refresh=15000&operationNodes=false&idleEdges=false&injectServiceNodes=true&layout=dagre\n```\n- In Cloud Shell, run a request multiple times for the main page of the example workload:```\nISTIO_INGRESS_GATEWAY_EXTERNAL_IP=\"$(kubectl get svc istio-ingressgateway -n istio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\"for i in {1..10000}; do curl -s -o /dev/null -w \"$(date --iso-8601=ns) - %{http_code}\\n\" \u00a0http://\"${ISTIO_INGRESS_GATEWAY_EXTERNAL_IP}\"/productpage; done\n```The command generates traffic to the Bookinfo app. The expected output is a list of the dates of the HTTP requests to the `productpage` service, and the HTTP return code of each request ( `200 OK` in this case). The output is similar to the following:```\n2021-06-09T10:16:15,355323181+00:00 - 200\n2021-06-09T10:16:15,355323182+00:00 - 200\n2021-06-09T10:16:15,355323183+00:00 - 200\n[...]\n```\n- In the Kiali service dashboard, you see a diagram of the current mesh, with traffic routed to services that are running in Compute Engine and GKE.Each instance of a microservice has a label to explain its revision:- Instances that are running in Compute Engine have a label of`compute-engine`.\n- Instances that are running in GKE have an extra string, for example,`v1`or`v3`.\nInstances that are running in Compute Engine connect directly to the other instances in Compute Engine without going through the service mesh. Therefore, you don't see the traffic that goes from the instances running in Compute Engine to other instances.If you don't see the following diagram on the Kiali dashboard, refresh the page.The diagram on the Kiali dashboard shows the traffic that's routed to services that are running in Compute Engine and to services running in GKE.\n- In Cloud Shell, to stop the traffic generation command, press `Control+C` .## Route traffic to the GKE cluster only\nIn this section, you route traffic to the workload service instances that are running in the GKE cluster only. For each service of the example workload, you delete the `WorkloadEntry` reference that points to the service running in Compute Engine. The deletion causes the service to only select the microservice instances that are running in the GKE cluster, and traffic is routed only to the GKE cluster. The following diagram shows the architecture of the system for this section:- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Expose the workloads in the target environment only:```\nscripts/workloads.sh \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\" \\--expose-with \"GKE_ONLY\"\n```The `workloads.sh` script deletes the `WorkloadEntry` references that point to the microservice instances that are running in Compute Engine from the GKE cluster.You see a confirmation of the deployment and how you can access it. The output is similar to the following:```\nYou can access the workload by loading http://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/productpage\n```\nThe service entry uses [workloadSelector](https://istio.io/latest/docs/reference/config/networking/service-entry/) to automatically select the example workload that's running in the GKE cluster.\n### Test the workload running in GKE\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/productpage\n```A Bookinfo page is displayed with information about books and relevant ratings.\n### Visualize the service mesh\nIn this section, you use Kiali to show a visual representation of the service mesh.\n- Open a browser and go to the following URL, where `` is the IP address from the previous step:```\nhttp://ISTIO_INGRESS_GATEWAY_EXTERNAL_IP/kiali/console/graph/namespaces/?edges=requestDistribution&graphType=versionedApp&namespaces=default%2Cistio-system&idleNodes=false&duration=60&refresh=15000&operationNodes=false&idleEdges=false&injectServiceNodes=true&layout=dagre\n```\n- In Cloud Shell, run a request multiple times for the main page of the example workload:```\nISTIO_INGRESS_GATEWAY_EXTERNAL_IP=\"$(kubectl get svc istio-ingressgateway -n istio-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\"for i in {1..10000}; do curl -s -o /dev/null -w \"$(date --iso-8601=ns) - %{http_code}\\n\" \u00a0http://\"${ISTIO_INGRESS_GATEWAY_EXTERNAL_IP}\"/productpage; done\n```This command generates traffic to the Bookinfo app. The expected output is a list of the dates of the HTTP requests to the `productpage` service, and the HTTP return code of each request ( `200 OK` in this case). The output is similar to the following:```\n2021-06-09T10:16:15,355323181+00:00 - 200\n2021-06-09T10:16:15,355323182+00:00 - 200\n2021-06-09T10:16:15,355323183+00:00 - 200\n[...]\n```\n- The Kiali service dashboard shows a diagram of the current mesh with traffic routed to services that are running in GKE. You deployed two instances of each microservice: one runs in the Compute Engine instance, and the other runs in the GKE cluster. However, because you removed the `WorkloadEntry` references that point to the microservice instances that run in Compute Engine, the services only select the microservice instances that are running in the GKE cluster.If you don't see the following diagram on the Kiali dashboard, refresh the page:The diagram on the Kiali dashboard shows the traffic that's routed to services that are running in GKE.\n- In Cloud Shell, to stop the traffic generation command, press `Control+C` .## Retire the source environment\nBecause all the traffic is now routed to the GKE cluster, you can stop the instances of the workload that are running in Compute Engine.\nDuring a production migration, keep the source data center ready for your rollback strategy. We recommend that you start retiring the source data center only when you're sure that the new solution is working as expected and that all backup and fault-tolerance mechanisms are in place.\nThe following diagram shows the architecture of the system for this section:\nIn the diagram, Istio routes traffic to services that are running in GKE only, and the workloads that are running in Compute Engine are retired.\nTo retire the source environment, do the following:\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"\n```\n- Expose the workloads in the target environment only:```\nscripts/workloads.sh \\--default-project \"${DEFAULT_PROJECT}\" \\--default-region \"${DEFAULT_REGION}\" \\--default-zone \"${DEFAULT_ZONE}\" \\--deploy-with \"GKE_ONLY\"\n```The `workloads.sh` script stops the containers running in the Compute Engine instances.## Clean up\nTo avoid incurring charges to your Google Cloud account for the resources used in this deployment, either delete the project that contains the resources, or keep the project and delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.### Delete the individual resources\n- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${DEPLOYMENT_DIRECTORY_PATH}\"/terraform\n```\n- Delete the resources that you provisioned:```\nterraform destroy -auto-approve\n```## What's next\n- Read about [GKE](/kubernetes-engine) .\n- Read about [Istio](https://istio.io/) .\n- For more reference architectures, diagrams, and best practices, explore the [Cloud Architecture Center](/architecture) .", "guide": "Docs"}