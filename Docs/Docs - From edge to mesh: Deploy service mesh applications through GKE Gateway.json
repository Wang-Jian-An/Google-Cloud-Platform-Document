{"title": "Docs - From edge to mesh: Deploy service mesh applications through GKE Gateway", "url": "https://cloud.google.com/architecture/exposing-service-mesh-apps-through-gke-ingress/deployment", "abstract": "# Docs - From edge to mesh: Deploy service mesh applications through GKE Gateway\nLast reviewed 2024-01-31 UTC\nThis deployment shows how to combine [Anthos Service Mesh](/service-mesh/docs/overview) with [Cloud Load Balancing](/load-balancing/docs/load-balancing-overview) to expose applications in a service mesh to internet clients.\nYou can expose an application to clients in many ways, depending on where the client is. This deployment shows you how to expose an application to clients by combining Cloud Load Balancing with Anthos Service Mesh to integrate load balancers with a service mesh. This deployment is intended for advanced practitioners who run Anthos Service Mesh, but it works for Istio on Google Kubernetes Engine too.\n", "content": "## Architecture\nThe following diagram shows how you can use mesh ingress gateways to integrate load balancers with a service mesh:\n**Note:** For applications in Anthos Service Mesh, deployment of the external TCP/UDP load balancer is the default exposure type. You deploy the load balancer through the Kubernetes Service, which selects the Pods of the mesh ingress proxies.\nIn the topology of the preceding diagram, the cloud ingress layer, which is programed through GKE Gateway, sources traffic from outside of the service mesh and directs that traffic to the mesh ingress layer. The mesh ingress layer then directs traffic to the mesh-hosted application backends.\nThe preceding topology has the following considerations:\n- **Cloud ingress:** In this reference architecture, you configure the Google Cloud load balancer through GKE Gateway to check the health of the mesh ingress proxies on their exposed health-check ports.\n- **Mesh ingress:** In the mesh application, you perform health checks on the backends directly so that you can run load balancing and traffic management locally.The preceding diagram illustrates HTTPS encryption from the client to the Google Cloud load balancer, from the load balancer to the mesh ingress proxy, and from the ingress proxy to the sidecar proxy.\n## Objectives\n- Deploy a Google Kubernetes Engine (GKE) cluster on Google Cloud.\n- Deploy an Istio-based Anthos Service Mesh on your GKE cluster.\n- Configure GKE Gateway to terminate public HTTPS traffic and direct that traffic to service mesh-hosted applications.\n- Deploy the Online Boutique application on the GKE cluster that you expose to clients on the internet.## Cost optimization\nIn this document, you use the following billable components of Google Cloud:\n- [Google Kubernetes Engine](/kubernetes-engine/pricing) \n- [Compute Engine](/compute/all-pricing%22) \n- [Cloud Load Balancing](/vpc/network-pricing#lb) \n- [Certificate Manager](/certificate-manager/pricing) \n- [Anthos Service Mesh](/service-mesh/pricing) \n- [Google Cloud Armor](/armor/pricing) \n- [Cloud Endpoints](/endpoints/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) .\nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .\n## Before you begin\n- In the Google Cloud console, on the project selector page,   select or [create a Google Cloud project](/resource-manager/docs/creating-managing-projects) . **Note** : If you don't plan to keep the  resources that you create in this procedure, create a project instead of  selecting an existing project. After you finish these steps, you can  delete the project, removing all resources associated with the project. [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\n- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) You run all of the terminal commands for this deployment from Cloud Shell.\n- Upgrade to the latest version of the Google Cloud CLI:```\ngcloud components update\n```\n- Set your default Google Cloud project:```\nexport PROJECT=PROJECTexport PROJECT_NUMBER=$(gcloud projects describe ${PROJECT} --format=\"value(projectNumber)\")gcloud config set project ${PROJECT}\n```Replace `` with the project ID that you want to use for this deployment.\n- Create a working directory:```\nmkdir -p ${HOME}/edge-to-meshcd ${HOME}/edge-to-meshexport WORKDIR=`pwd`\n```After you finish this deployment, you can delete the working directory.## Create GKE clusters\nThe features that are described in this deployment require a GKE cluster version 1.16 or later.\n- In Cloud Shell, create a new `kubeconfig` file. This step ensures that you don't create a conflict with your existing (default) `kubeconfig` file.```\ntouch edge2mesh_kubeconfigexport KUBECONFIG=${WORKDIR}/edge2mesh_kubeconfig\n```\n- Define environment variables for the GKE cluster:```\nexport CLUSTER_NAME=edge-to-meshexport CLUSTER_LOCATION=us-central1\n```\n- Enable the Google Kubernetes Engine API:```\ngcloud services enable container.googleapis.com\n```\n- Create a GKE [Autopilot cluster](/kubernetes-engine/docs/concepts/autopilot-overview) :```\ngcloud container --project ${PROJECT} clusters create-auto ${CLUSTER_NAME} --region ${CLUSTER_LOCATION} --release-channel rapid\n```\n- Ensure that the cluster is running:```\ngcloud container clusters list\n```The output is similar to the following:```\nNAME   LOCATION MASTER_VERSION MASTER_IP  MACHINE_TYPE NODE_VERSION  NUM_NODES STATUS\nedge-to-mesh us-central1 1.27.3-gke.1700 34.122.84.52 e2-medium 1.27.3-gke.1700 3   RUNNING\n```## Install a service mesh\nIn this section, you configure the [managed Anthos Service Mesh with fleet API](/service-mesh/docs/managed/auto-control-plane-with-fleet) .\n- In Cloud Shell, enable the required APIs:```\ngcloud services enable mesh.googleapis.com\n```\n- Enable Anthos Service Mesh on the fleet:```\ngcloud container fleet mesh enable\n```\n- Register the cluster to the fleet:```\ngcloud container fleet memberships register ${CLUSTER_NAME} \\\u00a0 --gke-cluster ${CLUSTER_LOCATION}/${CLUSTER_NAME\n```\n- Apply the `mesh_id` label to the `edge-to-mesh` cluster:```\ngcloud container clusters update ${CLUSTER_NAME} --project ${PROJECT} --region ${CLUSTER_LOCATION} --update-labels mesh_id=proj-${PROJECT_NUMBER}\n```\n- Enable automatic control plane management and managed data plane:```\ngcloud container fleet mesh update \\\u00a0 --management automatic \\\u00a0 --memberships ${CLUSTER_NAME}\n```\n- After a few minutes, verify that the control plane status is `ACTIVE` :```\ngcloud container fleet mesh describe\n```The output is similar to the following:```\n...\nmembershipSpecs:\n projects/892585880385/locations/us-central1/memberships/edge-to-mesh:\n mesh:\n  management: MANAGEMENT_AUTOMATIC\nmembershipStates:\n projects/892585880385/locations/us-central1/memberships/edge-to-mesh:\n servicemesh:\n  controlPlaneManagement:\n  details:\n  - code: REVISION_READY\n   details: 'Ready: asm-managed-rapid'\n  state: ACTIVE\n  dataPlaneManagement:\n  details:\n  - code: OK\n   details: Service is running.\n  state: ACTIVE\n state:\n  code: OK\n  description: 'Revision(s) ready for use: asm-managed-rapid.'\n  updateTime: '2023-08-04T02:54:39.495937877Z'\nname: projects/e2m-doc-01/locations/global/features/servicemesh\nresourceState:\n state: ACTIVE\n...\n```## Deploy GKE Gateway\nIn the following steps, you deploy the external Application Load Balancer through the GKE Gateway controller. The GKE Gateway resource automates the provisioning of the load balancer and backend health checking. Additionally, you use Certificate Manager to provision and manage a TLS certificate, and Endpoints to automatically provision a public DNS name for the application.\n### Install a service mesh ingress gateway\nAs a security best practice, we recommend that you deploy the ingress gateway in a different namespace from the control plane.\n- In Cloud Shell, create a dedicated `asm-ingress` namespace:```\nkubectl create namespace asm-ingress\n```\n- Add a namespace label to the `asm-ingress` namespace:```\nkubectl label namespace asm-ingress istio-injection=enabled\n```The output is similar to the following:```\nnamespace/asm-ingress labeled\n```Labeling the `asm-ingress` namespace with `istio-injection=enabled` instructs Anthos Service Mesh to automatically inject Envoy sidecar proxies when an application is deployed.\n- Create a self-signed certificate used by the ingress gateway to terminate TLS connections between the Google Cloud load balancer (to be configured later through the GKE Gateway controller) and the ingress gateway, and store the self-signed certificate as a Kubernetes secret:```\nopenssl req -new -newkey rsa:4096 -days 365 -nodes -x509 \\\u00a0-subj \"/CN=frontend.endpoints.${PROJECT}.cloud.goog/O=Edge2Mesh Inc\" \\\u00a0-keyout frontend.endpoints.${PROJECT}.cloud.goog.key \\\u00a0-out frontend.endpoints.${PROJECT}.cloud.goog.crtkubectl -n asm-ingress create secret tls edge2mesh-credential \\\u00a0--key=frontend.endpoints.${PROJECT}.cloud.goog.key \\\u00a0--cert=frontend.endpoints.${PROJECT}.cloud.goog.crt\n```For more details about the requirements for the ingress gateway certificate, see the [secure backend protocol considerations guide](/load-balancing/docs/ssl-certificates/encryption-to-the-backends#secure_backend_protocol_considerations) .\n- Run the following commands to create the ingress gateway resource YAML:```\nmkdir -p ${WORKDIR}/asm-ig/basecat <<EOF > ${WORKDIR}/asm-ig/base/kustomization.yamlresources:\u00a0 - github.com/GoogleCloudPlatform/anthos-service-mesh-samples/docs/ingress-gateway-asm-manifests/baseEOFmkdir ${WORKDIR}/asm-ig/variantcat <<EOF > ${WORKDIR}/asm-ig/variant/role.yamlapiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata:\u00a0 name: asm-ingressgateway\u00a0 namespace: asm-ingressrules:- apiGroups: [\"\"]\u00a0 resources: [\"secrets\"]\u00a0 verbs: [\"get\", \"watch\", \"list\"]EOFcat <<EOF > ${WORKDIR}/asm-ig/variant/rolebinding.yamlapiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata:\u00a0 name: asm-ingressgateway\u00a0 namespace: asm-ingressroleRef:\u00a0 apiGroup: rbac.authorization.k8s.io\u00a0 kind: Role\u00a0 name: asm-ingressgatewaysubjects:\u00a0 - kind: ServiceAccount\u00a0 \u00a0 name: asm-ingressgatewayEOFcat <<EOF > ${WORKDIR}/asm-ig/variant/service-proto-type.yamlapiVersion: v1kind: Servicemetadata:\u00a0 name: asm-ingressgatewayspec:\u00a0 ports:\u00a0 - name: status-port\u00a0 \u00a0 port: 15021\u00a0 \u00a0 protocol: TCP\u00a0 \u00a0 targetPort: 15021\u00a0 - name: http\u00a0 \u00a0 port: 80\u00a0 \u00a0 targetPort: 8080\u00a0 - name: https\u00a0 \u00a0 port: 443\u00a0 \u00a0 targetPort: 8443\u00a0 \u00a0 appProtocol: HTTP2\u00a0 type: ClusterIPEOFcat <<EOF > ${WORKDIR}/asm-ig/variant/gateway.yamlapiVersion: networking.istio.io/v1beta1kind: Gatewaymetadata:\u00a0 name: asm-ingressgatewayspec:\u00a0 servers:\u00a0 - port:\u00a0 \u00a0 \u00a0 number: 443\u00a0 \u00a0 \u00a0 name: https\u00a0 \u00a0 \u00a0 protocol: HTTPS\u00a0 \u00a0 hosts:\u00a0 \u00a0 - \"*\" # IMPORTANT: Must use wildcard here when using SSL, see note below\u00a0 \u00a0 tls:\u00a0 \u00a0 \u00a0 mode: SIMPLE\u00a0 \u00a0 \u00a0 credentialName: edge2mesh-credentialEOFcat <<EOF > ${WORKDIR}/asm-ig/variant/kustomization.yamlnamespace: asm-ingressresources:- ../base- role.yaml- rolebinding.yamlpatches:- path: service-proto-type.yaml\u00a0 target:\u00a0 \u00a0 kind: Service- path: gateway.yaml\u00a0 target:\u00a0 \u00a0 kind: GatewayEOF\n```\n- Apply the ingress gateway CRDs:```\nkubectl apply -k ${WORKDIR}/asm-ig/variant\n```\n- Ensure that all deployments are up and running:```\nkubectl wait --for=condition=available --timeout=600s deployment --all -n asm-ingress\n```The output is similar to the following:```\ndeployment.apps/asm-ingressgateway condition met\n```\n### Apply a service mesh ingress gateway health check\nWhen integrating a service mesh ingress gateway to a Google Cloud application load balancer, the application load balancer must be configured to perform health checks against the ingress gateway Pods. The `HealthCheckPolicy` CRD provides an API to configure that health check.\n- In Cloud Shell, create the `HealthCheckPolicy.yaml` file:```\ncat <<EOF >${WORKDIR}/ingress-gateway-healthcheck.yamlapiVersion: networking.gke.io/v1kind: HealthCheckPolicymetadata:\u00a0 name: ingress-gateway-healthcheck\u00a0 namespace: asm-ingressspec:\u00a0 default:\u00a0 \u00a0 checkIntervalSec: 20\u00a0 \u00a0 timeoutSec: 5\u00a0 \u00a0 #healthyThreshold: HEALTHY_THRESHOLD\u00a0 \u00a0 #unhealthyThreshold: UNHEALTHY_THRESHOLD\u00a0 \u00a0 logConfig:\u00a0 \u00a0 \u00a0 enabled: True\u00a0 \u00a0 config:\u00a0 \u00a0 \u00a0 type: HTTP\u00a0 \u00a0 \u00a0 httpHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 #portSpecification: USE_NAMED_PORT\u00a0 \u00a0 \u00a0 \u00a0 port: 15021\u00a0 \u00a0 \u00a0 \u00a0 portName: status-port\u00a0 \u00a0 \u00a0 \u00a0 #host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: /healthz/ready\u00a0 \u00a0 \u00a0 \u00a0 #response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 #proxyHeader: PROXY_HEADER\u00a0 \u00a0 #requestPath: /healthz/ready\u00a0 \u00a0 #port: 15021\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: asm-ingressgatewayEOF\n```\n- Apply the `HealthCheckPolicy:````\nkubectl apply -f ${WORKDIR}/ingress-gateway-healthcheck.yaml\n```\n### Define security policies\n[Google Cloud Armor](/armor) provides DDoS defense and [customizable security policies](/armor/docs/configure-security-policies) that you can attach to a load balancer through Ingress resources. In the following steps, you create a security policy that uses [preconfigured rules](/armor/docs/rule-tuning#preconfigured_rules) to block cross-site scripting (XSS) attacks. This rule helps block traffic that matches known attack signatures but allows all other traffic. Your environment might use different rules depending on your workload.\n- In Cloud Shell, create a security policy that is called `edge-fw-policy` :```\ngcloud compute security-policies create edge-fw-policy \\\u00a0 --description \"Block XSS attacks\"\n```\n- Create a security policy rule that uses the preconfigured XSS filters:```\ngcloud compute security-policies rules create 1000 \\\u00a0 \u00a0 --security-policy edge-fw-policy \\\u00a0 \u00a0 --expression \"evaluatePreconfiguredExpr('xss-stable')\" \\\u00a0 \u00a0 --action \"deny-403\" \\\u00a0 \u00a0 --description \"XSS attack filtering\"\n```\n- Create the `GCPBackendPolicy.yaml` file to attach to the ingress gateway service:```\ncat <<EOF > ${WORKDIR}/cloud-armor-backendpolicy.yamlapiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: cloud-armor-backendpolicy\u00a0 namespace: asm-ingressspec:\u00a0 default:\u00a0 \u00a0 securityPolicy: edge-fw-policy\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: asm-ingressgatewayEOF\n```\n- Apply the `GCPBackendPolicy.yaml` file:```\nkubectl apply -f ${WORKDIR}/cloud-armor-backendpolicy.yaml\n```\n### Configure IP addressing and DNS\n- In Cloud Shell, create a global static IP address for the Google Cloud load balancer:```\ngcloud compute addresses create e2m-gclb-ip --global\n```This static IP address is used by the GKE Gateway resource and allows the IP address to remain the same, even if the external load balancer changes.\n- Get the static IP address:```\nexport GCLB_IP=$(gcloud compute addresses describe e2m-gclb-ip --global --format \"value(address)\")echo ${GCLB_IP}\n```To create a stable, human-friendly mapping to the static IP address of your application load balancer, you must have a public DNS record. You can use any DNS provider and automation that you want. This deployment uses [Endpoints](/endpoints/docs) instead of creating a managed DNS zone. Endpoints provides a free [Google-managed DNS record](/endpoints/docs/openapi/cloud-goog-dns-configure) for a public IP address.\n- Run the following command to create the YAML specification file named `dns-spec.yaml` :```\ncat <<EOF > ${WORKDIR}/dns-spec.yamlswagger: \"2.0\"info:\u00a0 description: \"Cloud Endpoints DNS\"\u00a0 title: \"Cloud Endpoints DNS\"\u00a0 version: \"1.0.0\"paths: {}host: \"frontend.endpoints.${PROJECT}.cloud.goog\"x-google-endpoints:- name: \"frontend.endpoints.${PROJECT}.cloud.goog\"\u00a0 target: \"${GCLB_IP}\"EOF\n```The YAML specification defines the public DNS record in the form of `frontend.endpoints.${PROJECT}.cloud.goog` , where `${PROJECT}` is your unique project identifier.\n- Deploy the `dns-spec.yaml` file in your Google Cloud project:```\ngcloud endpoints services deploy ${WORKDIR}/dns-spec.yaml\n```The output is similar to the following:```\nproject [e2m-doc-01]...\nOperation \"operations/acat.p2-892585880385-fb4a01ad-821d-4e22-bfa1-a0df6e0bf589\" finished successfully.\nService Configuration [2023-08-04r0] uploaded for service [frontend.endpoints.e2m-doc-01.cloud.goog]\n```Now that the IP address and DNS are configured, you can generate a public certificate to secure the frontend. To integrate with GKE Gateway, you use [Certificate Manager](/certificate-manager/docs/overview) TLS certificates.\n### Provision a TLS certificate\nIn this section, you create a TLS certificate using [Certificate Manager](/certificate-manager/docs/overview) , and associate it with a [certificate map](/certificate-manager/docs/how-it-works) through a certificate map entry. The application load balancer, configured through GKE Gateway, uses the certificate to provide secure communications between the client and Google Cloud. After it's created, the certificate map entry is referenced by the GKE Gateway resource.\n- In Cloud Shell, enable the Certificate Manager API:```\ngcloud services enable certificatemanager.googleapis.com --project=${PROJECT}\n```\n- Create the TLS certificate:```\ngcloud --project=${PROJECT} certificate-manager certificates create edge2mesh-cert \\\u00a0 \u00a0 --domains=\"frontend.endpoints.${PROJECT}.cloud.goog\"\n```\n- Create the certificate map:```\ngcloud --project=${PROJECT} certificate-manager maps create edge2mesh-cert-map\n```\n- Attach the certificate to the certificate map with a certificate map entry:```\ngcloud --project=${PROJECT} certificate-manager maps entries create edge2mesh-cert-map-entry \\\u00a0 \u00a0 --map=\"edge2mesh-cert-map\" \\\u00a0 \u00a0 --certificates=\"edge2mesh-cert\" \\\u00a0 \u00a0 --hostname=\"frontend.endpoints.${PROJECT}.cloud.goog\"\n```\n### Deploy the GKE Gateway and HTTPRoute resources\nIn this section, you configure the GKE Gateway resource that provisions the Google Cloud application load balancer using the `gke-l7-global-external-managed` [gatewayClass](/kubernetes-engine/docs/concepts/gateway-api#gatewayclass) . Additionally, you configure [HTTPRoute](/kubernetes-engine/docs/concepts/gateway-api#httproute) resources that both route requests to the application and perform HTTP to HTTP(S) redirects.\n- In Cloud Shell, run the following command to create the `Gateway` manifest as `gke-gateway.yaml` :```\ncat <<EOF > ${WORKDIR}/gke-gateway.yamlkind: GatewayapiVersion: gateway.networking.k8s.io/v1beta1metadata:\u00a0 name: external-http\u00a0 namespace: asm-ingress\u00a0 annotations:\u00a0 \u00a0 networking.gke.io/certmap: edge2mesh-cert-mapspec:\u00a0 gatewayClassName: gke-l7-global-external-managed # gke-l7-gxlb\u00a0 listeners:\u00a0 - name: http # list the port only so we can redirect any incoming http requests to https\u00a0 \u00a0 protocol: HTTP\u00a0 \u00a0 port: 80\u00a0 - name: https\u00a0 \u00a0 protocol: HTTPS\u00a0 \u00a0 port: 443\u00a0 addresses:\u00a0 - type: NamedAddress\u00a0 \u00a0 value: e2m-gclb-ip # reference the static IP created earlierEOF\n```\n- Apply the `Gateway` manifest to create a `Gateway` called `external-http` :```\nkubectl apply -f ${WORKDIR}/gke-gateway.yaml\n```\n- Create the default `HTTPRoute.yaml` file:```\ncat << EOF > ${WORKDIR}/default-httproute.yamlapiVersion: gateway.networking.k8s.io/v1beta1kind: HTTPRoutemetadata:\u00a0 name: default-httproute\u00a0 namespace: asm-ingressspec:\u00a0 parentRefs:\u00a0 - name: external-http\u00a0 \u00a0 namespace: asm-ingress\u00a0 \u00a0 sectionName: https\u00a0 rules:\u00a0 - matches:\u00a0 \u00a0 - path:\u00a0 \u00a0 \u00a0 \u00a0 value: /\u00a0 \u00a0 backendRefs:\u00a0 \u00a0 - name: asm-ingressgateway\u00a0 \u00a0 \u00a0 port: 443EOF\n```\n- Apply the default `HTTPRoute` :```\nkubectl apply -f ${WORKDIR}/default-httproute.yaml\n```\n- Create an additional `HTTPRoute.yaml` file to perform HTTP to HTTP(S) redirects:```\ncat << EOF > ${WORKDIR}/default-httproute-redirect.yamlkind: HTTPRouteapiVersion: gateway.networking.k8s.io/v1beta1metadata:\u00a0 name: http-to-https-redirect-httproute\u00a0 namespace: asm-ingressspec:\u00a0 parentRefs:\u00a0 - name: external-http\u00a0 \u00a0 namespace: asm-ingress\u00a0 \u00a0 sectionName: http\u00a0 rules:\u00a0 - filters:\u00a0 \u00a0 - type: RequestRedirect\u00a0 \u00a0 \u00a0 requestRedirect:\u00a0 \u00a0 \u00a0 \u00a0 scheme: https\u00a0 \u00a0 \u00a0 \u00a0 statusCode: 301EOF\n```\n- Apply the redirect `HTTPRoute` :```\nkubectl apply -f ${WORKDIR}/default-httproute-redirect.yaml\n```Reconciliation takes time. Use the following command until `programmed=true` :```\nkubectl get gateway external-http -n asm-ingress -w\n```## Install the Online Boutique sample app\n- In Cloud Shell, create a dedicated `onlineboutique` namespace:```\nkubectl create namespace onlineboutique\n```\n- Add a label to the `onlineboutique` namespace:```\nkubectl label namespace onlineboutique istio-injection=enabled\n```Labeling the `onlineboutique` namespace with `istio-injection=enabled` instructs Anthos Service Mesh to automatically inject Envoy sidecar proxies when an application is deployed.\n- Download the Kubernetes YAML files for the Online Boutique sample app:```\ncurl -LO \\https://raw.githubusercontent.com/GoogleCloudPlatform/microservices-demo/main/release/kubernetes-manifests.yaml\n```\n- Deploy the Online Boutique app:```\nkubectl apply -f kubernetes-manifests.yaml -n onlineboutique\n```The output is similar to the following (including warnings about GKE Autopilot [setting default resource requests and limits](/kubernetes-engine/docs/concepts/autopilot-resource-requests#defaults) ):```\nWarning: autopilot-default-resources-mutator:Autopilot updated Deployment onlineboutique/emailservice: adjusted resources to meet requirements for containers [server] (see http://g.co/gke/autopilot-resources)deployment.apps/emailservice createdservice/emailservice createdWarning: autopilot-default-resources-mutator:Autopilot updated Deployment onlineboutique/checkoutservice: adjusted resources to meet requirements for containers [server] (see http://g.co/gke/autopilot-resources)deployment.apps/checkoutservice createdservice/checkoutservice createdWarning: autopilot-default-resources-mutator:Autopilot updated Deployment onlineboutique/recommendationservice: adjusted resources to meet requirements for containers [server] (see http://g.co/gke/autopilot-resources)deployment.apps/recommendationservice createdservice/recommendationservice created...\n```\n- Ensure that all deployments are up and running:```\nkubectl get pods -n onlineboutique\n```The output is similar to the following:```\nNAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 READY \u00a0 STATUS \u00a0 \u00a0RESTARTS \u00a0 AGEadservice-64d8dbcf59-krrj9 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 2/2 \u00a0 \u00a0 Running \u00a0 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02m59scartservice-6b77b89c9b-9qptn \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 2/2 \u00a0 \u00a0 Running \u00a0 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02m59scheckoutservice-7668b7fc99-5bnd9 \u00a0 \u00a0 \u00a0 \u00a0 2/2 \u00a0 \u00a0 Running \u00a0 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02m58s...\n```Wait a few minutes for the GKE Autopilot cluster to provision the necessary compute infrastructure to support the application.\n- Run the following command to create the `VirtualService` manifest as `frontend-virtualservice.yaml` :```\ncat <<EOF > frontend-virtualservice.yamlapiVersion: networking.istio.io/v1beta1kind: VirtualServicemetadata:\u00a0 name: frontend-ingress\u00a0 namespace: onlineboutiquespec:\u00a0 hosts:\u00a0 - \"frontend.endpoints.${PROJECT}.cloud.goog\"\u00a0 gateways:\u00a0 - asm-ingress/asm-ingressgateway\u00a0 http:\u00a0 - route:\u00a0 \u00a0 - destination:\u00a0 \u00a0 \u00a0 \u00a0 host: frontend\u00a0 \u00a0 \u00a0 \u00a0 port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 number: 80EOF\n````VirtualService` is created in the application namespace ( `onlineboutique` ). Typically, the application owner decides and configures how and what traffic gets routed to the `frontend` application, so `VirtualService` is deployed by the app owner.\n- Deploy `frontend-virtualservice.yaml` in your cluster:```\nkubectl apply -f frontend-virtualservice.yaml\n```\n- Access the following link:```\necho \"https://frontend.endpoints.${PROJECT}.cloud.goog\"\n```Your Online Boutique frontend is displayed. **Note:** You might get an `ERR_SSL_VERSION_OR_CIPHER_MISMATCH` error. This error occurs when certificates have not yet propagated to all of the Google Front Ends (GFEs) globally. Wait a few minutes, and then try the link again.\n- To display the details of your certificate, click lock **View site information** in your browser's address bar, and then click **Certificate (Valid)** .The certificate viewer displays details for the managed certificate, including the expiration date and who issued the certificate.\nYou now have a global HTTPS load balancer serving as a frontend to your service mesh-hosted application.\n## Clean up\nAfter you've finished the deployment, you can clean up the resources you created on Google Cloud so you won't be billed for them in the future. You can either delete the project entirely or delete cluster resources and then delete the cluster.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.### Delete the individual resources\nIf you want to keep the Google Cloud project you used in this deployment, delete the individual resources:\n- In Cloud Shell, delete the `HTTPRoute` resources:```\nkubectl delete -f ${WORKDIR}/default-httproute-redirect.yamlkubectl delete -f ${WORKDIR}/default-httproute.yaml\n```\n- Delete the GKE Gateway resource:```\nkubectl delete -f ${WORKDIR}/gke-gateway.yaml\n```\n- Delete the TLS certificate resources (including the certificate map entry and its parent certificate map):```\ngcloud --project=${PROJECT} certificate-manager maps entries delete edge2mesh-cert-map-entry --map=\"edge2mesh-cert-map\" --quietgcloud --project=${PROJECT} certificate-manager maps delete edge2mesh-cert-map --quietgcloud --project=${PROJECT} certificate-manager certificates delete edge2mesh-cert --quiet\n```\n- Delete the Endpoints DNS entry:```\ngcloud endpoints services delete \"frontend.endpoints.${PROJECT}.cloud.goog\"\n```The output is similar to the following:```\nAre you sure? This will set the service configuration to be deleted, along\nwith all of the associated consumer information. Note: This does not\nimmediately delete the service configuration or data and can be undone using\nthe undelete command for 30 days. Only after 30 days will the service be\npurged from the system.\n```\n- When you are prompted to continue, enter .The output is similar to the following:```\nWaiting for async operation operations/services.frontend.endpoints.edge2mesh.cloud.goog-5 to complete...\nOperation finished successfully. The following command can describe the Operation details:\n gcloud endpoints operations describe operations/services.frontend.endpoints.edge2mesh.cloud.goog-5\n```\n- Delete the static IP address:```\ngcloud compute addresses delete ingress-ip --global\n```The output is similar to the following:```\nThe following global addresses will be deleted:\n - [ingress-ip]\n```\n- When you are prompted to continue, enter .The output is similar to the following:```\nDeleted\n[https://www.googleapis.com/compute/v1/projects/edge2mesh/global/addresses/ingress-ip].\n```\n- Delete the GKE cluster:```\ngcloud container clusters delete $CLUSTER_NAME --zone $CLUSTER_LOCATION\n```The output is similar to the following:```\nThe following clusters will be deleted.- [edge-to-mesh] in [us-central1]\n```\n- When you are prompted to continue, enter .After a few minutes, the output is similar to the following:```\nDeleting cluster edge-to-mesh...done.Deleted[https://container.googleapis.com/v1/projects/e2m-doc-01/zones/us-central1/clusters/edge-to-mesh].\n```## What's next\n- Learn about [more features offered by GKE Ingress that you can use with your service mesh](/kubernetes-engine/docs/how-to/ingress-configuration) .\n- Learn about [the different types of cloud load balancing available for GKE](/blog/products/containers-kubernetes/exposing-services-on-gke) .\n- Learn about [the features and functionality offered by Anthos Service Mesh](/service-mesh/docs/overview) .\n- See how to [deploy Ingress across multiple GKE clusters for multi-regional load balancing](/kubernetes-engine/docs/concepts/ingress-for-anthos) .\n- For more reference architectures, diagrams, and best practices, explore the [Cloud Architecture Center](/architecture) .", "guide": "Docs"}