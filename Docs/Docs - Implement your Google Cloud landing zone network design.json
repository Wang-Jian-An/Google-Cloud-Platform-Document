{"title": "Docs - Implement your Google Cloud landing zone network design", "url": "https://cloud.google.com/architecture/landing-zones/implement-network-design", "abstract": "# Docs - Implement your Google Cloud landing zone network design\nLast reviewed 2023-09-11 UTC\nThis document provides steps and guidance to implement your chosen network design after you review [Decide the network design for your Google Cloud landing zone](/architecture/landing-zones/decide-network-design) . If you have not already done so, review [Landing zone design in Google Cloud](/architecture/landing-zones) before you choose an option.\nThese instructions are intended for network engineers, architects, and technical practitioners who are involved in creating the network design for your organization's landing zone.\n", "content": "## Network design options\nBased on your chosen network design, complete one of the following:\n- [Create option 1: Shared VPC network for each environment](#option-1-shared-vpc-network-for-each-environment) \n- [Create option 2: Hub-and-spoke topology with centralized appliances](#option-2-hub-and-spoke-topology-with-centralized-appliances) \n- [Create option 3: Hub-and-spoke topology without appliances](#option-3-hub-and-spoke-topology-without-appliances) \n- [Create option 4: Expose services in a consumer-producer model with Private Service Connect](#option-4-psc) ## Create option 1: Shared VPC network for each environment\nIf you have chosen to create the [Shared VPC network for each environment](/architecture/landing-zones/decide-network-design#option-1) in \"Decide the network design for your Google Cloud landing zone\", follow this procedure.\nThe following steps create a single instance of a landing zone. If you need more than one landing zone, perhaps one for development and one for production, repeat the steps for each landing zone.\n### Limit external access by using an organization policy\nWe recommend that you limit direct access to the internet to only the resources that need it. Resources without external addresses can still access many Google APIs and services through Private Google Access. Private Google Access is enabled at the subnet level and lets resources interact with key Google services, while isolating them from the public internet.\nFor usability, the default functionality of Google Cloud lets users create resources in all projects, as long as they have the correct IAM permissions. For improved security, we recommend that you restrict the default permissions for resource types that can cause unintended internet access. You can then authorize specific projects only to allow the creation of these resources. Use the instructions at [Creating and managing organization policies](/resource-manager/docs/organization-policy/creating-managing-policies) to set the following constraints.\nProtocol forwarding establishes a forwarding rule resource with an external IP address and lets you direct the traffic to a VM.\nThe **Restrict Protocol Forwarding Based on type of IP Address** constraint prevents the creation of forwarding rules with external IP addresses for the entire organization. For projects authorized to use external forwarding rules, you can modify the constraint at the folder or project level.\nSet the following values to configure this constraint:\n- Customize\n- Replace\n- Custom\n- Deny\n- `IS:EXTERNAL`By default, individual VM instances can acquire external IP addresses, which allows both outbound and inbound connectivity with the internet.\nEnforcing the **Define allowed external IPs for VM instances** constraint prevents the use of external IP addresses with VM instances. For workloads that require external IP addresses on individual VM instances, modify the constraint at a folder or project level to specify the individual VM instances. Or, override the constraint for the relevant projects.\n- Customize\n- Replace\n- Deny AllThe **Disable VPC External IPv6 usage** constraint, when set to `True` , prevents the configuration of VPC subnets with external IPv6 addresses for VM instances.\n- Customize\n- OnWhen a new project is created, a default VPC is automatically created. This is useful for quick experiments that don't require specific network configuration or integration with a larger enterprise networking environment.\nConfigure the **Skip default network creation** constraint to disable default VPC creation for new projects. You can manually create the default network within a project, if needed.\n- Customize\n- On\n### Design firewall rules\nFirewall rules let you allow or deny traffic to or from your VMs based on a configuration you define. [Hierarchical firewall policies](/vpc/docs/firewall-policies) are implemented at the organization and folder levels, and network firewall policies are implemented at the VPC network level in the resource hierarchy. Together, these provide an important capability to help secure your workloads.\nRegardless of where the firewall policies are applied, use the following guidelines when designing and evaluating your firewall rules:\n- Implement least-privilege (also referred to as microsegmentation) principles. Block all traffic by default and only allow the specific traffic you need. This includes limiting the rules to only the protocols and ports you need for each workload.\n- Enable firewall rules logging for visibility into firewall behavior and to use Firewall Insights.\n- Define a numbering methodology for allocating firewall rule priorities. For example, it's best practice to reserve a range of low numbers in each policy for rules needed during incident response. We also recommend that you prioritize more specific rules higher than more general rules, to ensure that the specific rules aren't shadowed by the general rules. The following example shows a possible approach for firewall rule priorities:\n| Firewall rule priority range | Purpose      |\n|:-------------------------------|:-------------------------------|\n| 0-999       | Reserved for incident response |\n| 1000-1999      | Always blocked traffic   |\n| 2000-1999999999    | Workload-specific rules  |\n| 2000000000-2100000000   | Catch-all rules    |\n| 2100000001-2147483643   | Reserved      |\n[Hierarchical firewall policies](/vpc/docs/firewall-policies) let you create and enforce a consistent firewall policy across your organization. For examples of using hierarchical firewall policies, see [Hierarchical firewall policy examples](/vpc/docs/firewall-policies-examples) .\nDefine hierarchical firewall policies to implement the following network access controls:\n- **Identity-Aware Proxy (IAP) for TCP forwarding.** IAP for TCP forwarding is allowed through a security policy that permits ingress traffic from IP range 35.235.240.0/20 for TCP ports 22 and 3389.\n- **Health checks for Cloud Load Balancing.** The well-known ranges that are used for health checks are allowed.- For most Cloud Load Balancing instances (including Internal TCP/UDP Load Balancing, Internal HTTP(S) Load Balancing, External TCP Proxy Load Balancing, External SSL Proxy Load Balancing, and HTTP(S) Load Balancing), a security policy is defined that allows ingress traffic from the IP ranges 35.191.0.0/16 and 130.211.0.0/22 for ports 80 and 443.\n- For Network Load Balancing, a security policy is defined that enables legacy health checks by allowing ingress traffic from IP ranges 35.191.0.0/16, 209.85.152.0/22, and 209.85.204.0/22 for ports 80 and 443.\n### Configure your Shared VPC environment\nBefore implementing a Shared VPC design, decide how to share subnets with service projects. You attach a service project to a host project. To determine which subnets are available for the service project, you assign IAM permissions to the host project or individual subnets. For example, you can choose to dedicate a different subnet to each service project, or share the same subnets between service projects.\n- [Create a new project](/resource-manager/docs/creating-managing-projects) for the Shared VPC. Later in this process, this project becomes the host project and contains the networks and networking resources to be shared with the service projects.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the host project.\n- [Configure Shared VPC](/vpc/docs/provisioning-shared-vpc) for the project.\n- Create the [custom-mode VPC network](/vpc/docs/create-modify-vpc-networks#creating_networks) in the host project.\n- [Create subnets](/vpc/docs/create-modify-vpc-networks#subnet-rules) in the regions where you plan to deploy workloads. For each subnet, enable Private Google Access to allow VM instances without external IP addresses to reach Google services.\n### Configure Cloud NAT\nFollow these steps if the workloads in specific regions require outbound internet access\u2014for example, to download software packages or updates.\n- [Create a Cloud NAT gateway](/nat/docs/set-up-manage-network-address-translation) in the regions where workloads require outbound internet access. You can customize the Cloud NAT configuration to only allow outbound connectivity from specific subnets, if needed.\n- At a minimum, [enable Cloud NAT logging](/nat/docs/monitoring) for the gateway to log`ERRORS_ONLY`. To include logs for translations performed by Cloud NAT, configure each gateway to log`ALL`.\n### Configure hybrid connectivity- If you're using Dedicated Interconnect, do the following. If you're using Partner Interconnect or Cloud VPN, you can skip these steps.- Create a [separate project for the physical interconnect ports](/network-connectivity/docs/interconnect/concepts/best-practices#provision_physical_interconnect_connections_in_a_separate_project) .\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Create Dedicated Interconnect connections](/network-connectivity/docs/interconnect/how-to/dedicated/provisioning-overview) .\n- For each region where you're terminating hybrid connectivity in the VPC network, do the following:- Create two Dedicated or Partner [VLAN attachments](/network-connectivity/docs/interconnect/how-to/dedicated/creating-vlan-attachments) , one for each edge availability zone. As part of this process, you select Cloud Routers and create BGP sessions.\n- Configure the peer network (on-premises or other cloud) routers.\n### Configure workload projects\nCreate a separate service project for each workload:\n- [Create a new project](/resource-manager/docs/creating-managing-projects) to function as one of the service projects for the Shared VPC.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the service project.\n- [Attach the project to the host project](/vpc/docs/provisioning-shared-vpc#create-shared) .\n- Configure access to [all subnets in the host project](/vpc/docs/provisioning-shared-vpc#networkuseratproject) or [some subnets in the host project](/vpc/docs/provisioning-shared-vpc#networkuseratsubnet) .\n### Configure observability\nNetwork Intelligence Center provides a cohesive way to monitor, troubleshoot, and visualize your cloud networking environment. Use it to ensure that your design functions with the desired intent.\nThe following configurations support the analysis of logging and metrics enabled.\n- You must [enable the Network Management API](/network-intelligence-center/docs/connectivity-tests/concepts/overview) before you can run Connectivity Tests. Enabling the API is required to use the API directly, the Google Cloud CLI, or the Google Cloud console.\n- You must [enable the Firewall Insights API](/network-intelligence-center/docs/firewall-insights/how-to/enable-api-features) before you can perform any tasks using Firewall Insights.\n### Next steps\nThe initial configuration for this network design option is now complete. You can now either repeat these steps to configure an additional instance of the landing zone environment, such as a staging or production environment, or continue to [Decide the security for your Google Cloud landing zone](/architecture/landing-zones/decide-security) .\n## Create option 2: Hub-and-spoke topology with centralized appliances\nIf you have chosen to create the [hub-and-spoke topology with centralized appliances](/architecture/landing-zones/decide-network-design#option-2) in \"Decide the network design for your Google Cloud landing zone\", follow this procedure.\nThe following steps create a single instance of a landing zone. If you need more than one landing zone, perhaps one for development and one for production, repeat the steps for each landing zone.\n### Limit external access by using an organization policy\nWe recommend that you limit direct access to the internet to only the resources that need it. Resources without external addresses can still access many Google APIs and services through Private Google Access. Private Google Access is enabled at the subnet level and lets resources interact with key Google services, while isolating them from the public internet.\nFor usability, the default functionality of Google Cloud lets users create resources in all projects, as long as they have the correct IAM permissions. For improved security, we recommend that you restrict the default permissions for resource types that can cause unintended internet access. You can then authorize specific projects only to allow the creation of these resources. Use the instructions at [Creating and managing organization policies](/resource-manager/docs/organization-policy/creating-managing-policies) to set the following constraints.\nProtocol forwarding establishes a forwarding rule resource with an external IP address and lets you direct the traffic to a VM.\nThe **Restrict Protocol Forwarding Based on type of IP Address** constraint prevents the creation of forwarding rules with external IP addresses for the entire organization. For projects authorized to use external forwarding rules, you can modify the constraint at the folder or project level.\nSet the following values to configure this constraint:\n- Customize\n- Replace\n- Custom\n- Deny\n- `IS:EXTERNAL`By default, individual VM instances can acquire external IP addresses, which allows both outbound and inbound connectivity with the internet.\nEnforcing the **Define allowed external IPs for VM instances** constraint prevents the use of external IP addresses with VM instances. For workloads that require external IP addresses on individual VM instances, modify the constraint at a folder or project level to specify the individual VM instances. Or, override the constraint for the relevant projects.\n- Customize\n- Replace\n- Deny AllThe **Disable VPC External IPv6 usage** constraint, when set to `True` , prevents the configuration of VPC subnets with external IPv6 addresses for VM instances.\n- Customize\n- OnWhen a new project is created, a default VPC is automatically created. This is useful for quick experiments that don't require specific network configuration or integration with a larger enterprise networking environment.\nConfigure the **Skip default network creation** constraint to disable default VPC creation for new projects. You can manually create the default network within a project, if needed.\n- Customize\n- On\n### Design firewall rules\nFirewall rules let you allow or deny traffic to or from your VMs based on a configuration you define. [Hierarchical firewall policies](/vpc/docs/firewall-policies) are implemented at the organization and folder levels, and network firewall policies are implemented at the VPC network level in the resource hierarchy. Together, these provide an important capability to help secure your workloads.\nRegardless of where the firewall policies are applied, use the following guidelines when designing and evaluating your firewall rules:\n- Implement least-privilege (also referred to as microsegmentation) principles. Block all traffic by default and only allow the specific traffic you need. This includes limiting the rules to only the protocols and ports you need for each workload.\n- Enable firewall rules logging for visibility into firewall behavior and to use Firewall Insights.\n- Define a numbering methodology for allocating firewall rule priorities. For example, it's best practice to reserve a range of low numbers in each policy for rules needed during incident response. We also recommend that you prioritize more specific rules higher than more general rules, to ensure that the specific rules aren't shadowed by the general rules. The following example shows a possible approach for firewall rule priorities:\n| Firewall rule priority range | Purpose      |\n|:-------------------------------|:-------------------------------|\n| 0-999       | Reserved for incident response |\n| 1000-1999      | Always blocked traffic   |\n| 2000-1999999999    | Workload-specific rules  |\n| 2000000000-2100000000   | Catch-all rules    |\n| 2100000001-2147483643   | Reserved      |\n[Hierarchical firewall policies](/vpc/docs/firewall-policies) let you create and enforce a consistent firewall policy across your organization. For examples of using hierarchical firewall policies, see [Hierarchical firewall policy examples](/vpc/docs/firewall-policies-examples) .\nDefine hierarchical firewall policies to implement the following network access controls:\n- **Identity-Aware Proxy (IAP) for TCP forwarding.** IAP for TCP forwarding is allowed through a security policy that permits ingress traffic from IP range 35.235.240.0/20 for TCP ports 22 and 3389.\n- **Health checks for Cloud Load Balancing.** The well-known ranges that are used for health checks are allowed.- For most Cloud Load Balancing instances (including Internal TCP/UDP Load Balancing, Internal HTTP(S) Load Balancing, External TCP Proxy Load Balancing, External SSL Proxy Load Balancing, and HTTP(S) Load Balancing), a security policy is defined that allows ingress traffic from the IP ranges 35.191.0.0/16 and 130.211.0.0/22 for ports 80 and 443.\n- For Network Load Balancing, a security policy is defined that enables legacy health checks by allowing ingress traffic from IP ranges 35.191.0.0/16, 209.85.152.0/22, and 209.85.204.0/22 for ports 80 and 443.\n### Configure your VPC environment\nThe transit and hub VPC networks provide the networking resources to enable connectivity between workload spoke VPC networks and on-premises or multi-cloud networks.\n- [Create a new project](/resource-manager/docs/creating-managing-projects) for transit and hub VPC networks. Both VPC networks are part of the same project to support connectivity through the virtual network appliances.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Create the transit custom mode VPC network](/vpc/docs/create-modify-vpc-networks#creating_networks) .\n- In the transit VPC network, [create a subnet](/vpc/docs/create-modify-vpc-networks#subnet-rules) in the regions where you plan to deploy the virtual network appliances.\n- [Create the hub custom mode VPC network](/vpc/docs/create-modify-vpc-networks#creating_networks) .\n- In the hub VPC network, [create a subnet](/vpc/docs/create-modify-vpc-networks#subnet-rules) in the regions where you plan to deploy the virtual network appliances.\n- Configure [global or regional network firewall policies](/vpc/docs/firewall-policies-overview) to allow ingress and egress traffic for the network virtual appliances.\n- [Create a managed instance group](/compute/docs/instance-groups/creating-groups-of-managed-instances) for the virtual network appliances.\n- [Configure the internal TCP/UDP load balancing resources](/load-balancing/docs/internal/setting-up-internal) for the transit VPC. This load balancer is used for routing traffic from the transit VPC to the hub VPC through the virtual network appliances.\n- [Configure the internal TCP/UDP load balancing resources](/load-balancing/docs/internal/setting-up-ilb-next-hop) for the hub VPC. This load balancer is used for routing traffic from the hub VPC to the transit VPC through the virtual network appliances.\n- [Configure Private Service Connect for Google APIs](/vpc/docs/configure-private-service-connect-apis) for the hub VPC.\n- [Modify VPC routes](/vpc/docs/using-routes#adding_and_removing_routes) to send all traffic through the network virtual appliances:- Delete the`0.0.0.0/0`route with next-hop`default-internet-gateway`from the hub VPC.\n- Configure a new route with destination`0.0.0.0/0`and a next-hop of the forwarding rule for the load balancer in the hub VPC.\n### Configure Cloud NAT\nFollow these steps if the workloads in specific regions require outbound internet access\u2014for example, to download software packages or updates.\n- [Create a Cloud NAT gateway](/nat/docs/set-up-manage-network-address-translation) in the regions where workloads require outbound internet access. You can customize the Cloud NAT configuration to only allow outbound connectivity from specific subnets, if needed.\n- At a minimum, [enable Cloud NAT logging](/nat/docs/monitoring) for the gateway to log`ERRORS_ONLY`. To include logs for translations performed by Cloud NAT, configure each gateway to log`ALL`.\n### Configure hybrid connectivity- If you're using Dedicated Interconnect, do the following. If you're using Partner Interconnect or Cloud VPN, you can skip these steps.- Create a [separate project for the physical interconnect ports](/network-connectivity/docs/interconnect/concepts/best-practices#provision_physical_interconnect_connections_in_a_separate_project) .\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Create Dedicated Interconnect connections](/network-connectivity/docs/interconnect/how-to/dedicated/provisioning-overview) .\n- For each region where you're terminating hybrid connectivity in the VPC network, do the following:- Create two Dedicated or Partner [VLAN attachments](/network-connectivity/docs/interconnect/how-to/dedicated/creating-vlan-attachments) , one for each edge availability zone. As part of this process, you select Cloud Routers and create BGP sessions.\n- Configure the peer network (on-premises or other cloud) routers.\n- Configure custom route advertisements in the Cloud Routers for the subnet ranges in the hub and workload VPCs.\n### Configure workload projects\nCreate a separate spoke VPC for each workload:\n- [Create a new project](/resource-manager/docs/creating-managing-projects) to host your workload.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Configure VPC Network Peering](/vpc/docs/using-vpc-peering) between the workload spoke VPC and hub VPC with the following settings:- Enable custom route export on the hub VPC.\n- Enable custom route import on the workload spoke VPC.\n- [Create subnets](/vpc/docs/create-modify-vpc-networks#subnet-rules) in the regions where you plan to deploy workloads. For each subnet, enable Private Google Access to allow VM instances withinternal IP addresses to reach Google services.\n- [Configure Private Service Connect for Google APIs](/vpc/docs/configure-private-service-connect-apis) .\n- To route all traffic through the virtual network appliances in the hub VPC, delete the`0.0.0.0/0`route with next-hop`default-internet-gateway`from the workload spoke VPC.\n- Configure [global or regional network firewall policies](/vpc/docs/firewall-policies-overview) to allow ingress and egress traffic for your workload.\n### Configure observability\nNetwork Intelligence Center provides a cohesive way to monitor, troubleshoot, and visualize your cloud networking environment. Use it to ensure that your design functions with the desired intent.\nThe following configurations support the analysis of logging and metrics enabled.\n- You must [enable the Network Management API](/network-intelligence-center/docs/connectivity-tests/concepts/overview) before you can run Connectivity Tests. Enabling the API is required to use the API directly, the Google Cloud CLI, or the Google Cloud console.\n- You must [enable the Firewall Insights API](/network-intelligence-center/docs/firewall-insights/how-to/enable-api-features) before you can perform any tasks using Firewall Insights.\n### Next steps\nThe initial configuration for this network design option is now complete. You can now either repeat these steps to configure an additional instance of the landing zone environment, such as a staging or production environment, or continue to [Decide the security for your Google Cloud landing zone](/architecture/landing-zones/decide-security) .\n## Create option 3: Hub-and-spoke topology without appliances es\nIf you have chosen to create the [hub-and-spoke topology without appliances](/architecture/landing-zones/decide-network-design#option-3) in \"Decide the network design for your Google Cloud landing zone\", follow this procedure.\nThe following steps create a single instance of a landing zone. If you need more than one landing zone, perhaps one for development and one for production, repeat the steps for each landing zone.\n### Limit external access by using an organization policy\nWe recommend that you limit direct access to the internet to only the resources that need it. Resources without external addresses can still access many Google APIs and services through Private Google Access. Private Google Access is enabled at the subnet level and lets resources interact with key Google services, while isolating them from the public internet.\nFor usability, the default functionality of Google Cloud lets users create resources in all projects, as long as they have the correct IAM permissions. For improved security, we recommend that you restrict the default permissions for resource types that can cause unintended internet access. You can then authorize specific projects only to allow the creation of these resources. Use the instructions at [Creating and managing organization policies](/resource-manager/docs/organization-policy/creating-managing-policies) to set the following constraints.\nProtocol forwarding establishes a forwarding rule resource with an external IP address and lets you direct the traffic to a VM.\nThe **Restrict Protocol Forwarding Based on type of IP Address** constraint prevents the creation of forwarding rules with external IP addresses for the entire organization. For projects authorized to use external forwarding rules, you can modify the constraint at the folder or project level.\nSet the following values to configure this constraint:\n- Customize\n- Replace\n- Custom\n- Deny\n- `IS:EXTERNAL`By default, individual VM instances can acquire external IP addresses, which allows both outbound and inbound connectivity with the internet.\nEnforcing the **Define allowed external IPs for VM instances** constraint prevents the use of external IP addresses with VM instances. For workloads that require external IP addresses on individual VM instances, modify the constraint at a folder or project level to specify the individual VM instances. Or, override the constraint for the relevant projects.\n- Customize\n- Replace\n- Deny AllThe **Disable VPC External IPv6 usage** constraint, when set to `True` , prevents the configuration of VPC subnets with external IPv6 addresses for VM instances.\n- Customize\n- OnWhen a new project is created, a default VPC is automatically created. This is useful for quick experiments that don't require specific network configuration or integration with a larger enterprise networking environment.\nConfigure the **Skip default network creation** constraint to disable default VPC creation for new projects. You can manually create the default network within a project, if needed.\n- Customize\n- On\n### Design firewall rules\nFirewall rules let you allow or deny traffic to or from your VMs based on a configuration you define. [Hierarchical firewall policies](/vpc/docs/firewall-policies) are implemented at the organization and folder levels, and network firewall policies are implemented at the VPC network level in the resource hierarchy. Together, these provide an important capability to help secure your workloads.\nRegardless of where the firewall policies are applied, use the following guidelines when designing and evaluating your firewall rules:\n- Implement least-privilege (also referred to as microsegmentation) principles. Block all traffic by default and only allow the specific traffic you need. This includes limiting the rules to only the protocols and ports you need for each workload.\n- Enable firewall rules logging for visibility into firewall behavior and to use Firewall Insights.\n- Define a numbering methodology for allocating firewall rule priorities. For example, it's best practice to reserve a range of low numbers in each policy for rules needed during incident response. We also recommend that you prioritize more specific rules higher than more general rules, to ensure that the specific rules aren't shadowed by the general rules. The following example shows a possible approach for firewall rule priorities:\n| Firewall rule priority range | Purpose      |\n|:-------------------------------|:-------------------------------|\n| 0-999       | Reserved for incident response |\n| 1000-1999      | Always blocked traffic   |\n| 2000-1999999999    | Workload-specific rules  |\n| 2000000000-2100000000   | Catch-all rules    |\n| 2100000001-2147483643   | Reserved      |\n[Hierarchical firewall policies](/vpc/docs/firewall-policies) let you create and enforce a consistent firewall policy across your organization. For examples of using hierarchical firewall policies, see [Hierarchical firewall policy examples](/vpc/docs/firewall-policies-examples) .\nDefine hierarchical firewall policies to implement the following network access controls:\n- **Identity-Aware Proxy (IAP) for TCP forwarding.** IAP for TCP forwarding is allowed through a security policy that permits ingress traffic from IP range 35.235.240.0/20 for TCP ports 22 and 3389.\n- **Health checks for Cloud Load Balancing.** The well-known ranges that are used for health checks are allowed.- For most Cloud Load Balancing instances (including Internal TCP/UDP Load Balancing, Internal HTTP(S) Load Balancing, External TCP Proxy Load Balancing, External SSL Proxy Load Balancing, and HTTP(S) Load Balancing), a security policy is defined that allows ingress traffic from the IP ranges 35.191.0.0/16 and 130.211.0.0/22 for ports 80 and 443.\n- For Network Load Balancing, a security policy is defined that enables legacy health checks by allowing ingress traffic from IP ranges 35.191.0.0/16, 209.85.152.0/22, and 209.85.204.0/22 for ports 80 and 443.\n### Configure the hub VPC environment\nThe hub VPC provides the networking resources to enable connectivity between workload spoke VPC networks and on-premises or multi-cloud networks.\n- [Create a new project](/resource-manager/docs/creating-managing-projects) for the hub VPC network.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- Create the hub [custom mode VPC network](/vpc/docs/create-modify-vpc-networks#creating_networks) .\n- [Configure Private Service Connect for Google APIs](/vpc/docs/configure-private-service-connect-apis) for the hub VPC.\n### Configure hybrid connectivity- If you're using Dedicated Interconnect, do the following. If you're using Partner Interconnect or Cloud VPN, you can skip these steps.- Create a [separate project for the physical interconnect ports](/network-connectivity/docs/interconnect/concepts/best-practices#provision_physical_interconnect_connections_in_a_separate_project) .\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Create Dedicated Interconnect connections](/network-connectivity/docs/interconnect/how-to/dedicated/provisioning-overview) .\n- For each region where you're terminating hybrid connectivity in the VPC network, do the following:- Create two Dedicated or Partner [VLAN attachments](/network-connectivity/docs/interconnect/how-to/dedicated/creating-vlan-attachments) , one for each edge availability zone. As part of this process, you select Cloud Routers and create BGP sessions.\n- Configure the peer network (on-premises or other cloud) routers.\n- Configure custom route advertisements in the Cloud Routers for the subnet ranges in the hub and workload VPCs.\n### Configure workload projects\nCreate a separate spoke VPC for each workload:\n- [Create a new project](/resource-manager/docs/creating-managing-projects) to host your workload.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Configure VPC Network Peering](/vpc/docs/using-vpc-peering) between the workload spoke VPC and hub VPC, with the following settings:- Enable custom route export on the hub VPC.\n- Enable custom route import on the workload spoke VPC.\n- [Create subnets](/vpc/docs/create-modify-vpc-networks#subnet-rules) in the regions where you plan to deploy workloads. For each subnet, enable Private Google Access to allow VM instances withinternal IP addresses to reach Google services.\n- [Configure Private Service Connect for Google APIs](/vpc/docs/configure-private-service-connect-apis) .\n### Configure Cloud NAT\nFollow these steps if the workloads in specific regions require outbound internet access\u2014for example, to download software packages or updates.\n- [Create a Cloud NAT gateway](/nat/docs/set-up-manage-network-address-translation) in the regions where workloads require outbound internet access. You can customize the Cloud NAT configuration to only allow outbound connectivity from specific subnets, if needed.\n- At a minimum, [enable Cloud NAT logging](/nat/docs/monitoring) for the gateway to log`ERRORS_ONLY`. To include logs for translations performed by Cloud NAT, configure each gateway to log`ALL`.\n### Configure observability\nNetwork Intelligence Center provides a cohesive way to monitor, troubleshoot, and visualize your cloud networking environment. Use it to ensure that your design functions with the desired intent.\nThe following configurations support the analysis of logging and metrics enabled.\n- You must [enable the Network Management API](/network-intelligence-center/docs/connectivity-tests/concepts/overview) before you can run Connectivity Tests. Enabling the API is required to use the API directly, the Google Cloud CLI, or the Google Cloud console.\n- You must [enable the Firewall Insights API](/network-intelligence-center/docs/firewall-insights/how-to/enable-api-features) before you can perform any tasks using Firewall Insights.\n### Next steps\nThe initial configuration for this network design option is now complete. You can now either repeat these steps to configure an additional instance of the landing zone environment, such as a staging or production environment, or continue to [Decide the security for your Google Cloud landing zone](/architecture/landing-zones/decide-security) .\n## Create option 4: Expose services in a consumer-producer model with Private Service Connect\nIf you have chosen to [expose services in a consumer-producer model with Private Service Connect](/architecture/landing-zones/decide-network-design#option-4) for your landing zone, as described in \"Decide the network design for your Google Cloud landing zone\", follow this procedure.\nThe following steps create a single instance of a landing zone. If you need more than one landing zone, perhaps one for development and one for production, repeat the steps for each landing zone.\n### Limit external access by using an organization policy\nWe recommend that you limit direct access to the internet to only the resources that need it. Resources without external addresses can still access many Google APIs and services through Private Google Access. Private Google Access is enabled at the subnet level and lets resources interact with key Google services, while isolating them from the public internet.\nFor usability, the default functionality of Google Cloud lets users create resources in all projects, as long as they have the correct IAM permissions. For improved security, we recommend that you restrict the default permissions for resource types that can cause unintended internet access. You can then authorize specific projects only to allow the creation of these resources. Use the instructions at [Creating and managing organization policies](/resource-manager/docs/organization-policy/creating-managing-policies) to set the following constraints.\nProtocol forwarding establishes a forwarding rule resource with an external IP address and lets you direct the traffic to a VM.\nThe **Restrict Protocol Forwarding Based on type of IP Address** constraint prevents the creation of forwarding rules with external IP addresses for the entire organization. For projects authorized to use external forwarding rules, you can modify the constraint at the folder or project level.\nSet the following values to configure this constraint:\n- Customize\n- Replace\n- Custom\n- Deny\n- `IS:EXTERNAL`By default, individual VM instances can acquire external IP addresses, which allows both outbound and inbound connectivity with the internet.\nEnforcing the **Define allowed external IPs for VM instances** constraint prevents the use of external IP addresses with VM instances. For workloads that require external IP addresses on individual VM instances, modify the constraint at a folder or project level to specify the individual VM instances. Or, override the constraint for the relevant projects.\n- Customize\n- Replace\n- Deny AllThe **Disable VPC External IPv6 usage** constraint, when set to `True` , prevents the configuration of VPC subnets with external IPv6 addresses for VM instances.\n- Customize\n- OnWhen a new project is created, a default VPC is automatically created. This is useful for quick experiments that don't require specific network configuration or integration with a larger enterprise networking environment.\nConfigure the **Skip default network creation** constraint to disable default VPC creation for new projects. You can manually create the default network within a project, if needed.\n- Customize\n- On\n### Design firewall rules\nFirewall rules let you allow or deny traffic to or from your VMs based on a configuration you define. [Hierarchical firewall policies](/vpc/docs/firewall-policies) are implemented at the organization and folder levels, and network firewall policies are implemented at the VPC network level in the resource hierarchy. Together, these provide an important capability to help secure your workloads.\nRegardless of where the firewall policies are applied, use the following guidelines when designing and evaluating your firewall rules:\n- Implement least-privilege (also referred to as microsegmentation) principles. Block all traffic by default and only allow the specific traffic you need. This includes limiting the rules to only the protocols and ports you need for each workload.\n- Enable firewall rules logging for visibility into firewall behavior and to use Firewall Insights.\n- Define a numbering methodology for allocating firewall rule priorities. For example, it's best practice to reserve a range of low numbers in each policy for rules needed during incident response. We also recommend that you prioritize more specific rules higher than more general rules, to ensure that the specific rules aren't shadowed by the general rules. The following example shows a possible approach for firewall rule priorities:\n| Firewall rule priority range | Purpose      |\n|:-------------------------------|:-------------------------------|\n| 0-999       | Reserved for incident response |\n| 1000-1999      | Always blocked traffic   |\n| 2000-1999999999    | Workload-specific rules  |\n| 2000000000-2100000000   | Catch-all rules    |\n| 2100000001-2147483643   | Reserved      |\n[Hierarchical firewall policies](/vpc/docs/firewall-policies) let you create and enforce a consistent firewall policy across your organization. For examples of using hierarchical firewall policies, see [Hierarchical firewall policy examples](/vpc/docs/firewall-policies-examples) .\nDefine hierarchical firewall policies to implement the following network access controls:\n- **Identity-Aware Proxy (IAP) for TCP forwarding.** IAP for TCP forwarding is allowed through a security policy that permits ingress traffic from IP range 35.235.240.0/20 for TCP ports 22 and 3389.\n- **Health checks for Cloud Load Balancing.** The well-known ranges that are used for health checks are allowed.- For most Cloud Load Balancing instances (including Internal TCP/UDP Load Balancing, Internal HTTP(S) Load Balancing, External TCP Proxy Load Balancing, External SSL Proxy Load Balancing, and HTTP(S) Load Balancing), a security policy is defined that allows ingress traffic from the IP ranges 35.191.0.0/16 and 130.211.0.0/22 for ports 80 and 443.\n- For Network Load Balancing, a security policy is defined that enables legacy health checks by allowing ingress traffic from IP ranges 35.191.0.0/16, 209.85.152.0/22, and 209.85.204.0/22 for ports 80 and 443.\n### Configure the VPC environment\nThe transit VPC provides the networking resources to enable connectivity between workload spoke VPC networks and on-premises or multi-cloud networks.\n- [Create a new project](/resource-manager/docs/creating-managing-projects) for the transit VPC network.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- Create the transit [custom mode VPC network](/vpc/docs/create-modify-vpc-networks#creating_networks) .\n- [Create a Private Service Connect subnet ](/vpc/docs/configure-private-service-connect-producer#add-subnet-psc) in each region where you plan to publish services running in your hub VPC or on-premises environment. Consider [Private Service Connect subnet sizing](/vpc/docs/private-service-connect#psc-subnets) when deciding your IP addressing plan.\n- For each on-premises service you want to expose to workloads running in Google Cloud, create an internal HTTP(S) or TCP proxy load balancer and [expose the services using Private Service Connect](/load-balancing/docs/tcp/set-up-int-tcp-proxy-hybrid#publish) .\n- [Configure Private Service Connect for Google APIs](/vpc/docs/configure-private-service-connect-apis) for the transit VPC.\n### Configure hybrid connectivity- If you're using Dedicated Interconnect, do the following. If you're using Partner Interconnect or Cloud VPN, you can skip these steps.- Create a [separate project for the physical interconnect ports](/network-connectivity/docs/interconnect/concepts/best-practices#provision_physical_interconnect_connections_in_a_separate_project) .\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- [Create Dedicated Interconnect connections](/network-connectivity/docs/interconnect/how-to/dedicated/provisioning-overview) .\n- For each region where you're terminating hybrid connectivity in the VPC network, do the following:- Create two Dedicated or Partner [VLAN attachments](/network-connectivity/docs/interconnect/how-to/dedicated/creating-vlan-attachments) , one for each edge availability zone. As part of this process, you select Cloud Routers and create BGP sessions.\n- Configure the peer network (on-premises or other cloud) routers.\n### Configure workload projects\nCreate a separate VPC for each workload:\n- [Create a new project](/resource-manager/docs/creating-managing-projects) to host your workload.\n- [Enable the Compute Engine API](/endpoints/docs/openapi/enable-api) for the project.\n- Create a [custom-mode VPC network](/vpc/docs/create-modify-vpc-networks#creating_networks) .\n- [Create subnets](/vpc/docs/create-modify-vpc-networks#subnet-rules) in the regions where you plan to deploy workloads. For each subnet, enable Private Google Access to allow VM instances withinternal IP addresses to reach Google services.\n- [Configure Private Service Connect for Google APIs](/vpc/docs/configure-private-service-connect-apis) .\n- For each workload you're consuming from a different VPC or your on-premises environment, [create a Private Service Connect consumer endpoint](/vpc/docs/configure-private-service-connect-services) .\n- For each workload you're producing for a different VPC or your on-premises environment, [create an internal load balancer and service attachment for the service](/vpc/docs/configure-private-service-connect-producer) . Consider [Private Service Connect subnet sizing](/vpc/docs/private-service-connect#psc-subnets) when deciding your IP addressing plan.\n- If the service should be reachable from your on-premises environment, [create a Private Service Connect consumer endpoint](/vpc/docs/configure-private-service-connect-services) in the transit VPC.\n### Configure Cloud NAT\nFollow these steps if the workloads in specific regions require outbound internet access\u2014for example, to download software packages or updates.\n- [Create a Cloud NAT gateway](/nat/docs/set-up-manage-network-address-translation) in the regions where workloads require outbound internet access. You can customize the Cloud NAT configuration to only allow outbound connectivity from specific subnets, if needed.\n- At a minimum, [enable Cloud NAT logging](/nat/docs/monitoring) for the gateway to log`ERRORS_ONLY`. To include logs for translations performed by Cloud NAT, configure each gateway to log`ALL`.\n### Configure observability\nNetwork Intelligence Center provides a cohesive way to monitor, troubleshoot, and visualize your cloud networking environment. Use it to ensure that your design functions with the desired intent.\nThe following configurations support the analysis of logging and metrics enabled.\n- You must [enable the Network Management API](/network-intelligence-center/docs/connectivity-tests/concepts/overview) before you can run Connectivity Tests. Enabling the API is required to use the API directly, the Google Cloud CLI, or the Google Cloud console.\n- You must [enable the Firewall Insights API](/network-intelligence-center/docs/firewall-insights/how-to/enable-api-features) before you can perform any tasks using Firewall Insights.\n### Next steps\nThe initial configuration for this network design option is now complete. You can now either repeat these steps to configure an additional instance of the landing zone environment, such as a staging or production environment, or continue to [Decide the security for your Google Cloud landing zone](/architecture/landing-zones/decide-security) .\n## What's next\n- [Decide the security for your Google Cloud landing zone](/architecture/landing-zones/decide-security) (next document in this series).\n- Read [Best practices for VPC network design](/solutions/best-practices-vpc-design) .\n- Learn how to use [Centralized network appliances on Google Cloud](/architecture/architecture-centralized-network-appliances-on-google-cloud) .\n- Read more about [Private Service Connect](/vpc/docs/private-service-connect) .", "guide": "Docs"}