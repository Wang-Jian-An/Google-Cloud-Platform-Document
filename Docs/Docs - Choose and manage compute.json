{"title": "Docs - Choose and manage compute", "url": "https://cloud.google.com/architecture/framework/system-design/compute", "abstract": "# Docs - Choose and manage compute\nLast reviewed 2023-10-03 UTC\nThis document in the [Google Cloud Architecture Framework](/architecture/framework) provides best practices to deploy your system based on compute requirements. You learn how to choose a compute platform and a migration approach, design and scale workloads, and manage operations and VM migrations.\nComputation is at the core of many workloads, whether it refers to the execution of custom business logic or the application of complex computational algorithms against datasets. Most solutions use compute resources in some form, and it's critical that you select the right compute resources for your application needs.\nGoogle Cloud provides several options for using time on a CPU. Options are based on CPU types, performance, and how your code is scheduled to run, including usage billing.\nGoogle Cloud compute options include the following:\n- Virtual machines (VM) with cloud-specific benefits like live migration.\n- Bin-packing of containers on cluster-machines that can share CPUs.\n- Functions and serverless approaches, where your use of CPU time can be metered to the work performed during a single HTTP request.", "content": "## Choosing compute\nThis section provides best practices for choosing and migrating to a compute platform.\n### Choose a compute platform\nWhen you choose a compute platform for your workload, consider the technical requirements of the workload, lifecycle automation processes, regionalization, and security.\nEvaluate the nature of CPU usage by your app and the entire supporting system, including how your code is packaged and deployed, distributed, and invoked. While some scenarios might be compatible with multiple platform options, a portable workload should be capable and performant on a range of compute options.\nThe following table provides an overview of the recommended Google Cloud compute services for various use cases:\n| Compute platform  | Use cases                                        | Recommended products                                                                                                                                  |\n|:-----------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Serverless    | Deploy your first app. Focus on data and processing logic and on app development, rather than maintaining infrastructure operations.         | Cloud Run: Put your business logic in containers by using this fully managed serverless option. Cloud Run is designed for workloads that are compute intensive, but not always on. Scale cost effectively from 0 (no traffic) and define the CPU and RAM of your tasks and services. Deploy with a single command and Google automatically provisions the right amount of resources. Cloud Functions: Separate your code into flexible pieces of business logic without the infrastructure concerns of load balancing, updates, authentication, or scaling. |\n| Kubernetes    | Build complex microservice architectures that need additional services like Istio to manage service mesh control.              | Google Kubernetes Engine: An open source container-orchestration engine that automates deploying, scaling, and managing containerized apps.                                                                                                     |\n| Virtual machines (VMs) | Create and run VMs from predefined and customizable VM families that support your application and workload requirements, as well as third-party software and services. | Compute Engine: Add graphics processing units (GPUs) to your VM instances. You can use these GPUs to accelerate specific workloads on your instances like machine learning and data processing. To select appropriate machine types based on your requirements, see Recommendations for machine families.                                                             |\nFor more information, see [Choosing compute options](/docs/choosing-a-compute-option) .\n### Choose a compute migration approach\nIf you're migrating your existing applications from another cloud or from on-premises, use one of the following Google Cloud products to help you optimize for performance, scale, cost, and security.\n| Migration goal  | Use case                     | Recommended product   |\n|:----------------------|:-----------------------------------------------------------------------------------------|:----------------------------|\n| Lift and shift  | Migrate or extend your VMware workloads to Google Cloud in minutes.      | Google Cloud VMware Engine |\n| Lift and shift  | Move your VM-based applications to Compute Engine.          | Migrate to Virtual Machines |\n| Upgrade to containers | Modernize traditional applications into built-in containers on Google Kubernetes Engine. | Migrate to Containers  |\nTo learn how to migrate your workloads while aligning internal teams, see [VM Migration lifecycle](/migrate/compute-engine/docs/5.0/concepts/lifecycle) and [Building a Large Scale Migration Program with Google Cloud](https://inthecloud.withgoogle.com/building-a-large-scale-migration-20/dl-cd.html) .\n## Designing workloads\nThis section provides best practices for designing workloads to support your system.\n### Evaluate serverless options for simple logic\nis a type of compute that doesn't require specialized hardware or machine types like CPU-optimized machines. Before you invest in [Google Kubernetes Engine (GKE)](/kubernetes-engine/docs) or [Compute Engine](/compute/docs) implementations to abstract operational overhead and optimize for cost and performance, evaluate [serverless options](#platform) for lightweight logic.\n### Decouple your applications to be stateless\nWhere possible, decouple your applications to be stateless to maximize use of [serverless computing](/serverless) options. This approach lets you use managed compute offerings, scale applications based on demand, and optimize for cost and performance. For more information about decoupling your application to design for scale and high availability, see [Design for scale and high availability](/architecture/framework/reliability/design-scale-high-availability) .\n### Use caching logic when you decouple architectures\nIf your application is designed to be stateful, use caching logic to decouple and make your workload scalable. For more information, see [Database best practices](/architecture/framework/system-design/databases#caching) .\n### Use live migrations to facilitate upgrades\nTo facilitate Google maintenance upgrades, use live migration by setting instance availability policies. For more information, see [Set VM host maintenance policy](/compute/docs/instances/host-maintenance-options) .\n## Scaling workloads\nThis section provides best practices for scaling workloads to support your system.\n### Use startup and shutdown scripts\nFor stateful applications, use [startup](/compute/docs/instances/startup-scripts) and [shutdown](/compute/docs/shutdownscript) scripts where possible to start and stop your application state gracefully. A is when a computer is turned on by a software function and the operating system is allowed to perform its tasks of safely starting processes and opening connections.\nGraceful startups and shutdowns are important because stateful applications depend on immediate availability to the data that sits close to the compute, usually on local or persistent disks, or in RAM. To avoid running application data from the beginning for each startup, use a startup script to reload the last saved data and run the process from where it previously stopped on shutdown. To save the application memory state to avoid losing progress on shutdown, use a shutdown script. For example, use a shutdown script when a VM is scheduled to be shut down due to downscaling or Google maintenance events.\n### Use MIGs to support VM management\nWhen you use [Compute Engine VMs](/compute/docs/quickstarts) , [managed instance groups](/compute/docs/instance-groups/creating-groups-of-managed-instances) (MIGs) support features like autohealing, load balancing, autoscaling, auto updating, and [stateful workloads](/compute/docs/instance-groups/stateful-migs) . You can create zonal or [regional MIGs](/compute/docs/instance-groups/regional-migs) based on your availability goals. You can use MIGs for stateless serving or batch workloads and for stateful applications that need to preserve each VM's unique state.\n### Use pod autoscalers to scale your GKE workloads\nUse [horizontal](/kubernetes-engine/docs/concepts/horizontalpodautoscaler) and [vertical Pod autoscalers](/kubernetes-engine/docs/concepts/verticalpodautoscaler) to scale your workloads, and use [node auto-provisioning](/kubernetes-engine/docs/how-to/node-auto-provisioning) to scale underlying compute resources.\n### Distribute application traffic\nTo scale your applications globally, use [Cloud Load Balancing](/load-balancing) to distribute your application instances across more than one region or zone. Load balancers optimize packet routing from Google Cloud [edge networks](/vpc/docs/edge-locations) to the nearest zone, which increases serving traffic efficiency and minimizes serving costs. To optimize for end-user latency, use [Cloud CDN](/cdn/docs) to cache static content where possible.\n### Automate compute creation and management\nMinimize human-induced errors in your production environment by automating compute creation and management.\n## Managing operations\nThis section provides best practices for managing operations to support your system.\n### Use Google-supplied public images\nUse public images supplied by Google Cloud. The Google Cloud public images are regularly updated. For more information, see [List of public images available on Compute Engine](/compute/docs/images#list_of_public_images_available_on) .\nYou can also [create your own images](/compute/docs/images/create-delete-deprecate-private-images) with specific configurations and settings. Where possible, automate and centralize image creation in a separate project that you can share with authorized users within your organization. Creating and curating a custom image in a separate project lets you update, patch, and create a VM using your own configurations. You can then share the curated VM image with relevant projects.\n### Use snapshots for instance backups\nSnapshots let you create backups for your instances. Snapshots are especially useful for stateful applications, which aren't flexible enough to maintain state or save progress when they experience abrupt shutdowns. If you frequently use snapshots to create new instances, you can optimize your backup process by creating a base image from that snapshot.\n### Use a machine image to enable VM instance creation\nAlthough a snapshot only captures an image of the data inside a machine, a machine image captures machine configurations and settings, in addition to the data. Use a [machine image](/compute/docs/machine-images/create-machine-images) to store all of the configurations, metadata, permissions, and data from one or more disks that are needed to create a VM instance.\nWhen you create a machine from a snapshot, you must configure instance settings on the new VM instances, which requires a lot of work. Using machine images lets you copy those known settings to new machines, reducing overhead. For more information, see [When to use a machine image](/compute/docs/machine-images#when-to-use) .\n## Capacity, reservations, and isolation\nThis section provides best practices for managing capacity, reservations, and isolation to support your system.\n### Use committed-use discounts to reduce costs\nYou can reduce your operational expenditure (OPEX) cost for workloads that are always on by using [committed use discounts](/compute/vm-instance-pricing#committed_use) . For more information, see the [Costoptimization category](/architecture/framework/cost-optimization) .\n### Choose machine types to support cost and performance\nGoogle Cloud offers machine types that let you choose compute based on cost and performance parameters. You can choose a low-performance offering to optimize for cost or choose a high-performance compute option at higher cost. For more information, see the [Costoptimization category](/architecture/framework/cost-optimization) .\n### Use sole-tenant nodes to support compliance needs\nare physical Compute Engine servers that are dedicated to hosting only your project's VMs. Sole-tenant nodes can help you to meet compliance requirements for physical isolation, including the following:\n- Keep your VMs physically separated from VMs in other projects.\n- Group your VMs together on the same host hardware.\n- Isolate payments processing workloads.\nFor more information, see [Sole-tenant nodes](/compute/docs/nodes/sole-tenant-nodes) .\n### Use reservations to ensure resource availability\nGoogle Cloud lets you define [reservations](/compute/docs/instances/reserving-zonal-resources) for your workloads to ensure those resources are always available. There is no additional charge to create reservations, but you pay for the reserved resources even if you don't use them. For more information, see [Consuming and managing reservations](/compute/docs/instances/reserving-zonal-resources) .\n## VM migration\nThis section provides best practices for migrating VMs to support your system.\n### Evaluate built-in migration tools\nEvaluate built-in migration tools to move your workloads from another cloud or from on-premises. For more information, see [Migration to Google Cloud](/architecture/migration-to-gcp-getting-started) . Google Cloud offers tools and services to help you migrate your workloads and optimize for cost and performance. To receive a free migration cost assessment based on your current IT landscape, see [Google Cloud Rapid Assessment & Migration Program](/solutions/cloud-migration-program) .\n### Use virtual disk import for customized operating systems\nTo import customized [supported operating systems](/compute/docs/images/os-details#import) , see [Importing virtual disks](/compute/docs/import/importing-virtual-disks) . Sole-tenant nodes can help you meet your hardware bring-your-own-license requirements for per-core or per-processor licenses. For more information, see [Bringing your own licenses](/compute/docs/nodes/bringing-your-own-licenses) .\n## Recommendations\nTo apply the guidance in the Architecture Framework to your own environment, we recommend that you do following:\n- Review [Google Cloud Marketplace](/marketplace) offerings to evaluate whether your application is listed under a supported vendor. Google Cloud supports running various open source systems and various [third-party software](/compute/docs/infrastructure-software) .\n- Consider [Migrate to Containers and GKE](/migrate/anthos/docs/getting-started) to extract and package your VM-based application as a containerized application running on GKE.\n- Use [Compute Engine](/compute/docs) to run your applications on Google Cloud. If you have legacy dependencies running in a VM-based application, verify whether they meet your vendor requirements.\n- Evaluate using a Google Cloud internal passthrough Network Load Balancer to scale your decoupled architecture. For more information, see [Internal passthrough Network Load Balancer overview](/load-balancing/docs/internal) .\n- Evaluate your options for switching from traditional on-premises use cases like HA-Proxy usage. For more information, see [best practice for floating IP address](/solutions/best-practices-floating-ip-addresses) .\n- Use [VM Manager](/compute/docs/vm-manager) to manage operating systems for your large VM fleets running windows or Linux on Compute Engine, and apply consistent configuration policies.\n- Consider using [GKE Autopilot ](/kubernetes-engine/docs/concepts/autopilot-overview) and let Google SRE fully manage your clusters.\n- Use [Policy Controller](/anthos-config-management/docs/concepts/policy-controller) and [Config Sync](/anthos-config-management/docs/config-sync-overview) for policy and configuration management across your GKE clusters.\n- Ensure availability and scalability of machines in specific regions and zones. Google Cloud can scale to support your compute needs. However, if you need a lot of specific machine types in a specific region or zone, work with your account teams to ensure availability. For more information, see [Reservations for Compute Engine](https://cloud.google.com/compute/docs/instances/reservations-overview) .## What's next\nLearn [networking design principles](/architecture/framework/system-design/networking#core) , including the following:\n- Design [workload VPC architectures](/architecture/framework/system-design/networking#workload) .\n- Design [inter-VPC connectivity](/architecture/framework/system-design/networking#connectivity) .\nExplore other categories in the [Architecture Framework](/architecture/framework) such as reliability, operational excellence, and security, privacy, and compliance.", "guide": "Docs"}