{"title": "Docs - Federated learning on Google Cloud", "url": "https://cloud.google.com/architecture/federated-learning-google-cloud", "abstract": "# Docs - Federated learning on Google Cloud\nLast reviewed 2022-06-08 UTC\nThis document describes an implementation for a [federated learning](https://wikipedia.org/wiki/Federated_learning) use case. The document takes into account the security and isolation considerations that you need to make for both multicloud and hybrid environments. It's intended for IT administrators, IT architects, and data scientists who are interested in implementing a federated learning system.\n", "content": "## Federated learning\nFederated learning is a machine learning (ML) technique that enables a group of organizations, or groups within the same organization, to collaboratively and iteratively train and improve a shared, global ML model. In this approach, no data is shared outside individual devices or groups. The participating organizations form a federation which can be made up of diverse configurations, such as geographic regions and timezones, or across business units within the same organization.\nIn federated learning, the focus is on training ML models with homogeneous and identically distributed data, or with data that's non-independent, and potentially not identically distributed. No unique data is exchanged between the organizations that participate in the federation. Federated learning enables the implementation of ML in industries and use cases where it's generally difficult to share data between organizations due to privacy, regulatory, or technical constraints. An example use case would be a group of hospitals around the world that are participating in the same clinical trial. Typically, the data that an individual hospital collects about patients can't leave its control or the hospital environment. As a result, hospitals can't transfer patient data to a third party. Federated learning lets affiliated hospitals train shared ML models, while still retaining control of patient data within each hospital.\n## Implement a federated learning use case\nTo implement a federated learning use case in Google Cloud, you must put in place the following minimum prerequisites, which are explained in more detail in the following section:\n- [Establish a federated learning consortium](#establish_a_federated_learning_consortium) .\n- [Determine the collaboration model for the federated learning consortium](#determine_a_collaboration_model_for_the_federated_learning_consortium) to implement and decide the responsibilities for each participant in the consortium.\nIn addition to these prerequisites, there are other actions that the federation owner must take which are outside the scope of this document, such as the following:\n- Management of the federated learning consortium.\n- Design and implementation of a collaboration model.\n- Preparation, management, and operation of the model training data and the model that the federation owner intends to train.\n- Creation, containerization, and orchestration of federated learning workflows.\n- Deployment and management of federated learning workloads.\n- Set up the communication channels for the participant organizations to securely transfer data.## Establish a federated learning consortium\nThe group of organizations that participate in a federated learning effort establish a . Organizations share the parameters of the ML models only, and those parameters can be encrypted to increase privacy. If the federated learning consortium allows the practice, organizations can also aggregate data that don't contain personally identifiable information (PII).\n## Determine a collaboration model for the federated learning consortium\nThe federated learning consortium can implement different collaboration models, such as the following:\n- Athat consists of a single coordinating organization, called theor, and a set ofor.\n- Athat consists of organizations that coordinate as a group.\n- Athat consists of a consortium of diverse participating organizations, all of which bring different resources to the consortium.\nIn this document, it's assumed that the collaboration model is a centralized model.\n### Determine the responsibilities of the participant organizations\nAfter choosing a collaboration model for the federated learning, the federation owner must determine the responsibilities for the participant organizations.\nThe federation owner must also do the following when they begin to build a federated learning consortium:\n- Coordinate the federated learning effort.\n- Design and implement the global ML model and the ML models to share with the participant organizations.\n- Define the\u2014the approach for the iteration of the ML training process.\n- Select the participant organizations that contribute to any given federated learning round. This selection is called a.\n- Design and implement a consortium membership verification procedure for the participant organizations.\n- Update the global ML model and the ML models to share with the participant organizations.\n- Provide the participant organizations with the tools to validate that the federated learning consortium meets their privacy, security, and regulatory requirements.\n- Provide the participant organizations with secure and encrypted communication channels.\n- Provide the participant organizations with all the necessary non-confidential, aggregated data that they need to complete each federated learning round.\nThe participant organizations have the following responsibilities:\n- Provide and maintain a secure, isolated environment (a). The silo is where participant organizations store their own data, and where ML model training is implemented.\n- Train the models supplied by the federation owner using their own computing infrastructure and their own local data.\n- Share model training results with the federation owner in the form of aggregated data, after removing any PII.\nThe federation owner and the participant organizations refine the ML model training until it meets their requirements.\n## Implement federated learning on Google Cloud\nAfter establishing the federated learning consortium and determining how it will collaborate, we recommend that participant organizations do the following:\n- Provision and configure the necessary infrastructure for the federated learning consortium.\n- Implement the collaboration model.\n- Start the federated learning effort.\n### Provision and configure the infrastructure for the federated learning consortium\nWhen provisioning and configuring the infrastructure for the federated learning consortium, it's the responsibility of the federation owner to create and distribute the workloads that train the federated ML models to the participant organizations. Because a third party (the federation owner) created and provided the workloads, the participant organizations must take precautions when deploying those workloads in their runtime environments.\nParticipant organizations must configure their environments according to their individual security best practices, and apply controls that limit the scope and the permissions granted to each workload. In addition to following their individual security best practices, we recommend that the federation owner and the participant organizations consider [threat vectors that are specific to federated learning](#security_considerations) .\nTo help implement a secure runtime environment that lets you control access and isolation between your federated learning workloads on Google Cloud, we recommend that all participating organizations use [Google Kubernetes Engine (GKE)](/kubernetes-engine/docs) .\nTo learn how to provision and configure a GKE cluster to provide all the features and security controls that you need for federated learning, see [Preparing a GKE cluster for apps distributed by a third party](/architecture/preparing-gke-cluster-apps-distributed-third-party) . In this approach, you use a [multi-tenant](/kubernetes-engine/docs/concepts/multitenancy-overview) architecture, and the workloads that train the federated model are treated as tenants within the GKE cluster. Tenants are grouped in dedicated [Kubernetes Namespaces](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) , and Namespaces are isolated from each other on dedicated GKE cluster nodes. With this approach, you can apply security controls and policies to the nodes and Namespaces that host the tenant workloads.\n### Implement the collaboration model\nAfter the federated learning consortium infrastructure is prepared, the federation owner designs and implements the mechanisms that let the participant organizations interact with each other. The approach follows the collaboration model that the federation owner chose for the federated learning consortium.\nThe design and the implementation of the different collaboration models are out of the scope of this document.\n### Start the federated learning effort\nAfter implementing the collaboration model, the federation owner implements the global ML model to train, and the ML models to share with the participant organization. After those ML models are ready, the federation owner starts the first round of the federated learning effort. During each round of the federated learning effort, the federation owner does the following:\n- Pre-processes training data to share with the participants organization to avoid revealing any PII.\n- Distributes the ML models to share with the participant organizations, along with the necessary training data.\n- Waits for the participant organizations to deliver the results of the training of the ML models that the federation owner shared.\n- Collects and processes the training results that the participant organizations produced.\n- Updates the global ML model when they receive appropriate training results from participating organizations.\n- Updates the ML models to share with the other members of the consortium when applicable.\n- Prepares the training data for the next round of federated learning.\n- Starts the next round of federated learning.## Security considerations\nDespite its strict data sharing model, federated learning isn't inherently secure against all targeted attacks. There's also the risk of unintended information leaks about ML models or model training data. For example, an attacker might intentionally compromise the global ML model or rounds of the federated learning effort, or they might execute a [timing attack (a type of side-channel attack)](https://en.wikipedia.org/wiki/Timing_attack) to gather information about the size of the training datasets.\nThe most common threats against a federated learning implementation are as follows:\n- **Intentional or unintentional training data memorization** . Your federated learning implementation or an attacker might intentionally or unintentionally store data in ways that might be difficult to work with. An attacker might be able to gather information about the global ML model or past rounds of the federated learning effort by reverse engineering the stored data.\n- **Extract information from updates to the global ML model** . An attacker might reverse engineer the updates to the global ML model that the federation owner collects from participant organizations during a round of the federated learning effort.\n- **The federation owner might compromise rounds** . A compromised federation owner might control a rogue silo and start a round of the federated learning effort. At the end of the round, the compromised federation owner might be able to gather information about the updates that it collects from legitimate participant organizations by comparing those updates to the one that the rogue silo produced.\n- **Participant organizations might compromise the global ML model** . An organization might attempt to maliciously affect the performance, the quality, or the integrity of the global ML model by producing rogue or inconsequential updates during a round of the federated learning effort.\nTo help mitigate the impact of the threats described in this section, we recommend that everyone in the consortium does the following:\n- Tune training data memorization, reducing it to the minimum.\n- Implement privacy-preserving mechanisms.\n- Regularly audit the global ML model, the ML models that you intend to share, the training data, and infrastructure that you implemented to realize federated learning.\n- Implement a [secure aggregation](https://research.google/pubs/pub45808/) algorithm to process the training results that participant organizations produce.\n- Securely generate and distribute data encryption keys using a [public key infrastructure](https://wikipedia.org/wiki/Public_key_infrastructure) .\n- Deploy your infrastructure on a [trusted computing](https://wikipedia.org/wiki/Trusted_Computing) platform.\nFederation owners must also take the following additional steps:\n- Verify the identity of each participant organization and the integrity of each silo.\n- Limit the scope of the updates to the global ML model that participant organizations can produce.## What's next\n- Read about how to [prepare a GKE cluster for apps distributed by a third party](/architecture/preparing-gke-cluster-apps-distributed-third-party) .\n- Explore how you can implement your federated learning algorithms on the [TensorFlow Federated platform](https://www.tensorflow.org/federated/get_started) .\n- Read about [advances and open problems in federated learning](https://arxiv.org/abs/1912.04977) .\n- Read about [federated learning on the Google AI Blog](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html) .\n- Watch how [Google uses federated learning using de-identified, aggregated information to improve ML models in a privacy-preserving way](https://www.youtube.com/watch?v=gbRJPa9d-VU) .\n- [Set up a HIPAA-Aligned workload using the Data Protection Toolkit](https://services.google.com/fh/files/misc/hipaa_technical_solution_guide.pdf) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Docs"}