{"title": "Docs - Build a smart API to predict customer propensity to purchase by using Apigee, BigQuery ML, and Spanner", "url": "https://cloud.google.com/architecture/build-smart-api-predict-customer-purchase-apigee-bigquery-ml-cloud-spanner/deployment", "abstract": "# Docs - Build a smart API to predict customer propensity to purchase by using Apigee, BigQuery ML, and Spanner\nLast reviewed 2023-06-20 UTC\nThis document describes how you build the architecture described in [Smart API to predict customer propensity to purchase by using Apigee, BigQuery ML, and Spanner](/architecture/build-smart-api-predict-customer-purchase-apigee-bigquery-ml-cloud-spanner) . In that architecture, you use these products to deploy an API that can predict how likely a customer is to make a purchase.\nThese instructions are intended for API developers and data specialists who want to generate more revenue through omni-channel and ecommerce platforms by providing a more personalized experience to users. It assumes that you're familiar with Apigee, BigQuery ML, Spanner, the Google Cloud CLI, and [Apache Maven](https://maven.apache.org/) .\n", "content": "## Architecture\nThe following diagram shows the architecture and process used in this solution:\nFor details, see [Smart API to predict customer propensity to purchase by using Apigee, BigQuery ML, and Spanner](/architecture/build-smart-api-predict-customer-purchase-apigee-bigquery-ml-cloud-spanner) .\n## Objectives\n- Create a customer purchase propensity dataset in BigQuery.\n- Import product catalog data to the Spanner database.\n- Import and deploy an Apigee API proxy.\n- Integrate customer purchase propensity data from BigQuery with the product catalog and pricing information from the Spanner database.\n- Create an aggregated view of product recommendations.## Costs\nIn this document, you use the following billable components of Google Cloud:\n- BigQuery and BigQuery ML Flex Slots\n- Spanner\n- Apigee\nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) .\n## Before you begin\n- In the Google Cloud console, on the project selector page,   select or [create a Google Cloud project](/resource-manager/docs/creating-managing-projects) . [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\n- Enable the AI Platform Training & Prediction, BigQuery, BigQuery Reservation, BigQuery Storage, Cloud Spanner, Cloud Storage, Cloud Storage API, Dataflow, Google Cloud, Cloud Storage JSON, Service Management, Service Usage APIs. [Enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,bigquery.googleapis.com,bigqueryreservation.googleapis.com,bigquerystorage.googleapis.com,spanner.googleapis.com,storage-component.googleapis.com,storage.googleapis.com,dataflow.googleapis.com,cloudapis.googleapis.com,storage-api.googleapis.com,servicemanagement.googleapis.com,serviceusage.googleapis.com) \n- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.\n- Grant roles to your Google Account. Run the following command once for each of the following   IAM roles: \n- `roles/apigee.admin`\n- `roles/bigquery.user`\n- `roles/bigquery.dataViewer`\n- `roles/spanner.admin`\n- `roles/spanner.databaseAdmin`\n- `roles/resourcemanager.projectIamAdmin`\n- `roles/serviceusage.serviceUsageConsumer`\n```\ngcloud projects add-iam-policy-binding PROJECT_ID --member=\"user:EMAIL_ADDRESS\" --role=ROLE\n```- Replace``with your project ID.\n- Replace``with your email address.\n- Replace``with each individual role.\n- If you don't already have an Apigee account, [set up Apigee](https://apigee.google.com/setup?pli=1) to provision an Apigee instance. Provisioning can take up  to an hour.\n- Configure your Apigee organization to allow [external access](/apigee/docs/api-platform/get-started/eval-orgs#access-routing) .\nIf you complete this procedure and decide not to keep the deployment, you can avoid continued billing by deleting the resources you created. For more information, see [Clean up](#clean-up) .\n## Create an ecommerce recommendation dataset using BigQuery ML\nIn this section, you use standard SQL queries in BigQuery ML to create an ML model, train it on customer data in BigQuery, and then deploy it.\nThe customer data that you use is from the Google Analytics Sample dataset, which is hosted publicly on BigQuery. This dataset provides 12 months (August 2016 to August 2017) of obfuscated Analytics 360 data from the Google Merchandise Store, a real ecommerce store that sells Google-branded merchandise.\nYou don't have to export your data or build a model training and deployment pipeline. BigQuery autoscales to handle any compute resources that you need.\nThe ML model that you create for this solution uses [matrix factorization](https://developers.google.com/machine-learning/recommendation/collaborative/matrix) , a common and effective method of creating a recommendation system based on user preference data.\n### Process the sample data\nWhen you use matrix factorization, you evaluate explicit or implicit user feedback to determine customer preferences. To use explicit feedback, the dataset must contain data about user product preferences, like star ratings between 1 and 5. If there isn't explicit feedback available, you must use other behavioral metrics to infer customer preferences, like looking at the total time a user spends on a product detail page. This solution uses session duration data to infer customer preferences.\nTo train the matrix factorization model, you need a table with columns that identify the customer, the item being rated, and the implicit rating. In this section, you create such a table with the `userid` , `itemId` , and `session_duration` columns. The `session_duration` column contains the duration of the user's session on the product page of the given item.\nTo create the table using data from the Analytics Sample dataset, do the following:\n- In the Google Cloud Marketplace, go to the [Analytics Sample](https://console.cloud.google.com/marketplace/details/obfuscated-ga360-data/obfuscated-ga360-data?filter=solution-type:dataset) page. [Go to Analytics Sample](https://console.cloud.google.com/marketplace/details/obfuscated-ga360-data/obfuscated-ga360-data?filter=solution-type:dataset) \n- Click **View Dataset** . The BigQuery SQL workspace page opens with the Analytics Sample dataset selected.\n- In the **Explorer** section, next to your project, click more_vert **View actions** , and then click **Create dataset** .\n- In the **Create dataset** dialog that appears, do the following:- In the **Dataset ID** field, enter`bqml`.\n- In the **Data location** list, select **us (multiple regions in\nUnited States)** .\n- Click **Create dataset** .\n- Click **Go to dataset** , and then click **Compose New Query** .\n- In the **Query Editor** , create a table that contains the training data by running the following SQL statement:```\nCREATE OR REPLACE TABLE bqml.aggregate_web_stats AS (\u00a0 WITH\u00a0 \u00a0 durations AS (\u00a0 \u00a0 \u00a0 --calculate pageview durations\u00a0 \u00a0 \u00a0 SELECT\u00a0 \u00a0 \u00a0 \u00a0 CONCAT(fullVisitorId,'-',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0CAST(visitNumber AS STRING),'-',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0CAST(hitNumber AS STRING) ) AS visitorId_session_hit,\u00a0 \u00a0 \u00a0 \u00a0 LEAD(time, 1) OVER (\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 PARTITION BY CONCAT(fullVisitorId,'-',CAST(visitNumber AS STRING))\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ORDER BY\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 time ASC ) - time AS pageview_duration\u00a0 \u00a0 \u00a0 FROM\u00a0 \u00a0 \u00a0 \u00a0 `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`,\u00a0 \u00a0 \u00a0 \u00a0 UNNEST(hits) AS hit\u00a0 \u00a0 ),\u00a0 \u00a0 prodview_durations AS (\u00a0 \u00a0 \u00a0 --filter for product detail pages only\u00a0 \u00a0 \u00a0SELECT\u00a0 \u00a0 \u00a0 \u00a0 CONCAT(fullVisitorId,'-',CAST(visitNumber AS STRING)) AS userId,\u00a0 \u00a0 \u00a0 \u00a0 productSKU AS itemId,\u00a0 \u00a0 \u00a0 \u00a0 IFNULL(dur.pageview_duration,\u00a0 \u00a0 \u00a0 \u00a0 \u00a01) AS pageview_duration,\u00a0 \u00a0 \u00a0 FROM\u00a0 \u00a0 \u00a0 \u00a0 `bigquery-public-data.google_analytics_sample.ga_sessions_2017*` t,\u00a0 \u00a0 \u00a0 \u00a0 UNNEST(hits) AS hits,\u00a0 \u00a0 \u00a0 \u00a0 UNNEST(hits.product) AS hits_product\u00a0 \u00a0 \u00a0 JOIN\u00a0 \u00a0 \u00a0 \u00a0 durations dur\u00a0 \u00a0 \u00a0 ON\u00a0 \u00a0 \u00a0 \u00a0 CONCAT(fullVisitorId,'-',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0CAST(visitNumber AS STRING),'-',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0CAST(hitNumber AS STRING)) = dur.visitorId_session_hit\u00a0 \u00a0 \u00a0 WHERE\u00a0 \u00a0 \u00a0 eCommerceAction.action_type = \"2\"\u00a0 \u00a0 ),\u00a0 \u00a0 aggregate_web_stats AS(\u00a0 \u00a0 \u00a0 --sum pageview durations by userId, itemId\u00a0 \u00a0 \u00a0 SELECT\u00a0 \u00a0 \u00a0 \u00a0 userId,\u00a0 \u00a0 \u00a0 \u00a0 itemId,\u00a0 \u00a0 \u00a0 \u00a0 SUM(pageview_duration) AS session_duration\u00a0 \u00a0 \u00a0 FROM\u00a0 \u00a0 \u00a0 \u00a0 prodview_durations\u00a0 \u00a0 \u00a0 GROUP BY\u00a0 \u00a0 \u00a0 \u00a0 userId,\u00a0 \u00a0 \u00a0 \u00a0 itemId )\u00a0 \u00a0 SELECT\u00a0 \u00a0 *\u00a0 \u00a0FROM\u00a0 \u00a0 \u00a0 aggregate_web_stats);\n```The `bqml.aggregate_web_stats` table is created and populated with training data.\n- To see a sample of the data, in the **Query Editor** run the following SQL statement:```\nSELECT*FROM\u00a0 bqml.aggregate_web_statsLIMIT\u00a0 10;\n```\nThe output shows a table that has a row for each user ID that includes the item ID that the user viewed, and the duration of their session. The output is similar to the following:\n| Row | userId    | itemId  | session_duration |\n|------:|:----------------------|:-------------|-------------------:|\n|  1 | 6703373209489429228-1 | GGOEAXXX0808 |    19523 |\n|  2 | 868731560082458910-1 | GGOEAXXX0808 |    8312 |\n|  3 | 4805474958539278422-1 | GGOEAXXX0808 |    62892 |\n|  4 | 8353360074725418910-3 | GGOEAXXX0808 |    4883 |\n|  5 | 8253742246691621007-2 | GGOEAXXX0808 |     10 |\n|  6 | 7211254729136975568-1 | GGOEAXXX0808 |    96090 |\n|  7 | 66777488032155805-1 | GGOEAXXX0808 |    3893 |\n|  8 | 0804312527321649470-1 | GGOEAXXX0808 |    7539 |\n|  9 | 2965429397557124425-1 | GGOEAXXX0808 |    21776 |\n| 10 | 8459600677575627508-1 | GGOEAXXX0808 |    6265 |\n### Purchase flex slots\nIf you use [on-demand pricing](/bigquery/pricing#on_demand_pricing) for BigQuery, in order to train a matrix factorization model, you must purchase flex slots and then create reservations and assignments for them. If you use flat-rate pricing with BigQuery, you can skip this section and go to [Create, train, and deploy the model](#create-train-and-deploy-the-model) .\nTo purchase flex slots, you must have an IAM role that includes the `bigquery.reservations.create` permission. This permission is granted to the project owner, and it's included in the BigQuery Admin ( `roles/bigquery.admin` ) and BigQuery Resource Admin ( `roles/bigquery.resourceAdmin` ) IAM roles.\n- In the Google Cloud console, go to the **BigQuery** page: [Go to BigQuery](https://console.cloud.google.com/bigquery) \n- Click **Capacity management** , and then click **Reservations** .\n- If you're redirected to the **BigQuery Reservation API** page to enable the API, click **Enable** . Otherwise, proceed to the next step.\n- In the **Reservations** tab, click **Buy Slots** .\n- In the **Buy Slots** page, do the following:- In the **Commitment duration** list, select **Flex** .\n- In the **Location** list, select **us (multiple regions in\nUnited States)** \n- In the **Number of slots** list, select **500** .\n- Click **Next** .\n- In the **Purchase confirmation** field, type `CONFIRM` and then click **Purchase** . **Note:** the console displays an estimated monthly cost of $14,600.00. After you complete the deployment, you can delete the unused slots, so you only pay for the slots that you used to train the model. Training the model takes approximately 10 minutes.\n- Click **View Slot Commitments** .Wait up to 20 minutes for the capacity to be provisioned. After the capacity is provisioned, the slot commitment **Status** column shows check_circle .\n- Click **Create Reservation** , and then set the following options:- In **Reservation name** , enter`model`.\n- In the **Location** list, select **us (multiple regions in\nUnited States)** \n- In **Number of slots** , enter`500`.\n- Click **Save** . This returns you to the **Reservations** page.\n- Next to the `model` reservation, in the **Actions** column, select **Create Assignment** .\n- In **Select an organization, folder, or project** , click **Browse** .\n- Enter the name of the project that you used for this solution, or select it from the list.\n- Click **Select** , and then click **Create** .\n### Create, train, and deploy the model\nTo create, train, and deploy the matrix factorization model, do the following:\n- In the Google Cloud console BigQuery page, clickadd_box **Compose new query** .\n- Run the [CREATE MODEL](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-matrix-factorization) SQL statement:```\nCREATE OR REPLACE MODEL bqml.retail_recommender`\u00a0 OPTIONS(model_type='matrix_factorization',\u00a0 \u00a0 \u00a0 \u00a0 user_col='userId',\u00a0 \u00a0 \u00a0 \u00a0 item_col='itemId',\u00a0 \u00a0 \u00a0 \u00a0 rating_col='session_duration',\u00a0 \u00a0 \u00a0 \u00a0 feedback_type='implicit'\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 AS\u00a0 SELECT * FROM bqml.aggregate_web_stats;\n```\nAfter training completes, the trained model is deployed as the `bqml.retail_recommender` model.\n### Use the trained model to make predictions\nIn this section, to get predictions from the deployed `bqml.retail_recommender` model, you use the [ML.RECOMMEND](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-recommend) SQL function.\n- In the Google Cloud console BigQuery page, compose a query and get predictions that represent the top 5 recommendations for a specified userId:```\nDECLARE MY_USERID STRING DEFAULT \"0824461277962362623-1\";SELECT\u00a0*FROM\u00a0 ML.RECOMMEND(MODEL `bqml.retail_recommender`,\u00a0 (SELECT MY_USERID as userID)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )ORDER BY predicted_session_duration_confidence DESCLIMIT 5;\n```The output displays a row for the predicted session duration confidence (higher is better), the associated user ID, and the item ID that the user viewed. The output is similar to the following:| Row | predicted_session_duration_confidence | userId    | itemId   |\n|------:|----------------------------------------:|:----------------------|:---------------|\n|  1 |         29011.1 | 0824461277962362623-1 | GGOEGAAX0574 |\n|  2 |         28213 | 0824461277962362623-1 | GGOEGDHQ015399 |\n|  3 |         28126.8 | 0824461277962362623-1 | GGOEGETR014599 |\n|  4 |         27303.6 | 0824461277962362623-1 | GGOEGAAX0338 |\n|  5 |         25692.4 | 0824461277962362623-1 | GGOEGEFR024199 |\n- To get the top 5 predictions for all users, run the following SQL statement. The statement generates many rows, so the output is written to a table and then the first ten records are retrieved so that you can see an example of the data.```\n-- Create output table of top 5 predictionsCREATE OR REPLACE TABLE bqml.prod_recommendations AS (WITH predictions AS (\u00a0 \u00a0 SELECT\u00a0 \u00a0 \u00a0 userId,\u00a0 \u00a0 \u00a0 ARRAY_AGG(STRUCT(itemId,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0predicted_session_duration_confidence)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ORDER BY\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 predicted_session_duration_confidence DESC\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 LIMIT 5) as recommended\u00a0 \u00a0 FROM ML.RECOMMEND(MODEL bqml.retail_recommender)\u00a0 \u00a0 GROUP BY userId)SELECT\u00a0 userId,\u00a0 itemId,\u00a0 predicted_session_duration_confidenceFROM\u00a0 predictions p,\u00a0 UNNEST(recommended));-- Show tableSELECT*FROM\u00a0 bqml.prod_recommendationsORDER BY\u00a0 userIdLIMIT\u00a0 10;\n```The output shows multiple user IDs, the item ID that the user viewed, and the predicted session duration confidence. The output is similar to the following:| Row | userId    | itemId   | predicted_session_duration_confidence |\n|------:|:---------------------|:---------------|----------------------------------------:|\n|  1 | 000170187170673177-6 | GGOEGDHQ015399 |         15931.2 |\n|  2 | 000170187170673177-6 | GGOEGAAX0574 |         20178.6 |\n|  3 | 000170187170673177-6 | GGOEGAAX0338 |         20247.3 |\n|  4 | 000170187170673177-6 | GGOEGETR014599 |         15524.4 |\n|  5 | 000170187170673177-6 | GGOEGEFR024199 |         16443.3 |\n|  6 | 000338059556124978-1 | GGOEGAAX0338 |         18143.1 |\n|  7 | 000338059556124978-1 | GGOEGAAX0279 |         16531.7 |\n|  8 | 000338059556124978-1 | GGOEGAAX0574 |         20916.7 |\n|  9 | 000338059556124978-1 | GGOEGETR014599 |         16155.7 |\n| 10 | 000338059556124978-1 | GGOEGEFR024199 |         18417.2 |\n### Set up Spanner data\nIn the following sections, you use the [gcloud CLI](/sdk/gcloud) and [Maven](https://maven.apache.org/) . You run commands for both tools from Cloud Shell. No installation is required to use the tools.\n- In Cloud Shell, clone the [product recommendations GitHut repository](https://github.com/apigee/devrel/tree/main/references/product-recommendations) that contains the product-recommendations API proxy bundle and scripts for setting up the data in a Spanner database:```\ngit clone https://github.com/apigee/devrel/tree/main/references/product-recommendationscd product-recommendations-v1\n```\n- Create the `datareader` service account and assign IAM roles to it. The service account is used to access the data in BigQuery and the Spanner database from the API proxy.```\ngcloud iam service-accounts create datareader --display-name=\"Data reader for BigQuery and Spanner Demo\"gcloud iam service-accounts list | grep datareadergcloud iam service-accounts create datareader --display-name=\"Data reader for Apigee, BigQuery, and Spanner Demo\"gcloud projects add-iam-policy-binding $PROJECT_ID --member=\"serviceAccount:$SA\" --role=\"roles/spanner.databaseUser\" --quietgcloud projects add-iam-policy-binding $PROJECT_ID --member=\"serviceAccount:$SA\" --role=\"roles/spanner.databaseReader\" --quietgcloud projects add-iam-policy-binding $PROJECT_ID --member=\"serviceAccount:$SA\" --role=\"roles/bigquery.dataViewer\" --quietgcloud projects add-iam-policy-binding $PROJECT_ID --member=\"serviceAccount:$SA\" --role=\"roles/bigquery.user\" --quiet\n```\n- Set environment variables:```\n# For Apigeeexport PROJECT_ID=APIGEE_PROJECTexport ORG=$PROJECT_IDexport ENV=evalexport ENVGROUP_HOSTNAME=API_DOMAIN_NAMEexport SA=datareader@$PROJECT_ID.iam.gserviceaccount.com# For Cloud Spannerexport SPANNER_INSTANCE=product-catalogexport SPANNER_DATABASE=product-catalog-v1export REGION=regional-us-east1\n```Replace the following:- ``: the name of your Apigee project.\n- ``: the hostname configured in the Admin>Environments>Groups page in the Apigee UI.\n- In the Google Cloud console BigQuery page, select the **prod_recommendations** table, and then click the **Preview** tab to view the results.- Copy any **userId** value.\n- In Cloud Shell, set an environment variable:```\nexport CUSTOMER_USERID=USER_ID\n```Replace `` with the `userId` value that you copied in the preceding step.\n- In Cloud Shell, display the ordered product recommendation results for the specified `CUSTOMER_USERID` value:```\nbq query --nouse_legacy_sql \\\u00a0 \u00a0 \"SELECT * FROM \\`$PROJECT_ID.bqml.prod_recommendations\\` AS A where A.userid = \\\"$CUSTOMER_USERID\\\"\" \\\u00a0 \u00a0 ORDER BY A.predicted_session_duration_confidence DESC\n```The output shows an individual user ID, the item ID that the user viewed, and the predicted session duration confidence. The output is similar to the following:```\n+-----------------------+----------------+--------------------------------------------+\n|  userId   |  itemId  |  predicted_session_duration_confidence |\n+-----------------------+----------------+--------------------------------------------+\n| 6929470170340317899-1 | GGOEGAAX0037 |       40161.10446942589 |\n| 6929470170340317899-1 | GGOEYDHJ056099 |       27642.28480729123 |\n| 6929470170340317899-1 | GGOEGAAX0351 |       27204.111219270915 |\n| 6929470170340317899-1 | GGOEGDWC020199 |       25863.861349754334 |\n| 6929470170340317899-1 | GGOEGAAX0318 |       24585.509088154067 |\n+-----------------------+----------------+--------------------------------------------+\n```\n### Create a Spanner database and import product catalog data\n- In Cloud Shell, create a Spanner instance in the specified region, create the product catalog database, and import the data:```\n./setup_spanner.sh\n```The script uses the `CUSTOMER_USERID` environment variable and it displays the entries that were created.The Spanner product catalog only contains the items that were used in the BigQuery training step for a specific user. Therefore, if you change the `CUSTOMER_USERID` environment variable after you create the product catalog data in the Spanner database, you must rerun the `setup_spanner.sh` shell script to repopulate the data.\n- Verify the data in the Spanner database:```\ngcloud spanner databases execute-sql $SPANNER_DATABASE --sql='SELECT * FROM products'\n```The output shows the product IDs and the descriptive information from the Spanner product catalog, including price and image path. The output is similar to the following:```\nproductid  name    description    price discount image\nGGOEGAAX0037 Aviator Sunglasses The ultimate sunglasses 42.42 0   products_Images/sunglasses.jpg\nGGOEGAAX0318 Bamboo glass jar Bamboo glass jar   19.99 0   products_Images/bamboo-glass-jar.jpg\nGGOEGAAX0351 Loafers    Most comfortable loafers 38.99 0   products_Images/loafers.jpg\nGGOEGDWC020199 Hair dryer   Hottest hair dryer   84.99 0   products_Images/hairdryer.jpg\nGGOEYDHJ056099 Coffee Mug   Best Coffee Mug   4.2 0   products_Images/mug.jpg\n```\n### Deploy Apigee proxy\nIn this section, you run a Maven command to create the following resources:\n- A proxy named`product-recommendations-v1`\n- An API product named`product-recommendations-v1-$ENV`\n- An app developer user named`demo@any.com`\n- An app named`product-recommendations-v1-app-$ENV`\nTo create the resources, Maven uses the `pom.xml` file from the GitHub repository. The file contains the installation instructions and steps.\nThe profile section of the `pom.xml` file contains values for `apigee.org` , `apigee.env` , `api.northbound.domain` , `gcp.projectid` , `googletoken.email` , and `api.userid` . These values vary by project and they are set by using the command line. The following example shows the section of the `pom.xml` file that contains the values:\n```\n<profile>\u00a0 <id>eval</id>\u00a0 <properties>\u00a0 \u00a0 <apigee.profile>eval</apigee.profile>\u00a0 \u00a0 <apigee.org>${apigeeOrg}</apigee.org>\u00a0 \u00a0 <apigee.env>${apigeeEnv}</apigee.env>\u00a0 \u00a0 <api.northbound.domain>${envGroupHostname}</api.northbound.domain>\u00a0 \u00a0 <gcp.projectid>${gcpProjectId}</gcp.projectid><apigee.googletoken.email>${googleTokenEmail}</apigee.googletoken.email>\u00a0 \u00a0 <api.userid>${customerUserId}</api.userid>\u00a0 </properties></profile>\n```\nYou set these values earlier when you [set up the Spanner data](#set-up-cloud-spanner-data) .\nTo deploy the proxy, do the following:\n- In Cloud Shell, install the proxy and its associated artifacts and then test the API:```\nmvn -P eval clean install -Dbearer=$(gcloud auth print-access-token) \\\u00a0 \u00a0 -DapigeeOrg=$ORG \\\u00a0 \u00a0 -DapigeeEnv=$ENV \\\u00a0 \u00a0 -DenvGroupHostname=$ENVGROUP_HOSTNAME \\\u00a0 \u00a0 -DgcpProjectId=$PROJECT_ID \\\u00a0 \u00a0 -DgoogleTokenEmail=$SA \\\u00a0 \u00a0 -DcustomerUserId=$CUSTOMER_USERID\n```The output shows the execution of the installation steps and the results of the integration test API calls. There's one call to the `/openapi` endpoint and another to the `/products` endpoint. The test results verify that the API proxy was installed, deployed, and is operational. The output also displays the app credentials, which you can use for subsequent API test calls.\n### Test the recommendations API\n- In Cloud Shell, set an environment variable for the API Key of the app by making a curl call to the Apigee API:```\nAPIKEY=$(curl -s -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\https://apigee.googleapis.com/v1/organizations/$ORG/developers/demo@any.com/apps/product-recommendations-v1-app-$ENV \\\u00a0 \u00a0 | jq -r .credentials[0].consumerKey)\n```Make a note of the `APIKEY` value, you need this information if you optionally [create an AppSheet app](#optional-create-an-appsheet-app) later.\n- To get the results for the `CUSTOMER_USERID` value that you specified when you installed the API proxy, make a test call:```\ncurl -s https://$ENVGROUP_HOSTNAME/v1/recommendations/products \\-H \"x-apikey:$APIKEY\" | jq\n```\nThe API that's defined by the OpenAPI Specification (OAS) lets the request specify the following headers:\n- `x-apikey`: The app consumer key from the security scheme.\n- `x-userid`: The user identifier making the request. If not provided, this value defaults to the`CUSTOMER_USERID`value that's configured in the proxy.\n- `cache-control`: The amount of time to cache the response. This header lets you cache the response for 300 seconds or override by specifying`no-cache`.\nTo change the `CUSTOMER_USERID` value or to control caching, you can set the header values as shown in the following example call:\n```\ncurl -s \"https://$ENVGROUP_HOSTNAME/v1/recommendations/products\" \\-H \"x-apikey:$APIKEY\" \\-H \"x-userid:$CUSTOMER_USERID\" \\-H \"Cache-Control:no-cache\" | jq\n```\nThe response to the example call is similar to the following:\n```\n{\n \"products\": [ {\n  \"productid\": \"GGOEGAAX0037\",\n  \"name\": \"Aviator Sunglasses\",\n  \"description\": \"The ultimate sunglasses\",\n  \"price\": \"42.42\",\n  \"image\": \"products_Images/sunglasses.jpg\"\n },\n {\n  \"productid\": \"GGOEYDHJ056099\",\n  \"name\": \"Coffee Mug\",\n  \"description\": \"Best Coffee Mug\",\n  \"price\": \"4.2\",\n  \"image\": \"products_Images/mug.jpg\"\n },\n {\n  \"productid\": \"GGOEGAAX0351\",\n  \"name\": \"Loafers\",\n  \"description\": \"Most comfortable loafers\",\n  \"price\": \"38.99\",\n  \"image\": \"products_Images/loafers.jpg\"\n },\n {\n  \"productid\": \"GGOEGDWC020199\",\n  \"name\": \"Hairdryer\",\n  \"description\": \"Hotest hairdryer\",\n  \"price\": \"84.99\",\n  \"image\": \"products_Images/hairdryer.jpg\"\n },\n {\n  \"productid\": \"GGOEGAAX0318\",\n  \"name\": \"Bamboo glass jar\",\n  \"description\": \"Bamboo glass jar\",\n  \"price\": \"19.99\",\n  \"image\": \"products_Images/bamboo-glass-jar.jpg\"\n }\n ]\n}\n```\n### Apigee policies\nThe Apigee policies that are listed in the following sections are used in the [API proxy bundle](#deploy-apigee-proxy) .\n## Optional: Create an AppSheet app using Apigee as a data source\nTo show product recommendations to ecommerce website end users and to business users, you can create an AppSheet app as shown in this section.\n### Create an AppSheet account\nCreate an [AppSheet](https://www.appsheet.com/) account using your email address.\n### Create a data source\nAppSheet uses the API proxy as the data source for your new app. To create a data source, do the following:\n- Sign in to [AppSheet](https://www.appsheet.com/) .\n- In the **My Account** page, click **Sources > New Data Source** .\n- In the **Add a new data source** dialog, enter the name of the proxy`product-recommendations-v1`, and then click **Apigee** .\n- In the **Add Apigee API connection information** dialog, set the following options:- Select **Manual** .\n- In the **Apigee API Key** field, enter the API key for your app, which you used to test the proxy. If you don't have the API key, get it in Cloud Shell by running`echo $APIKEY.`\n- In the **Apigee API Base Path field** , enter the following:```\nhttps://ENVGROUP_HOSTNAME/v1/recommendations\n```Replace with the hostname configured in the Apigee UI for Admin > Environments > Groups.\n- In the **API Resource Paths** field, enter the path suffix `products` .\n- Click **Test** .\n- After the tests complete successfully, click **Authorize Access** .After you authorize access, the AppSheet console shows a new tile for **product-recommendations-v1** .\n### Create the app\n- Go to the AppSheet [products-template app](https://www.appsheet.com/templates/sample?appGuidString=73c381a3-a8da-431e-83eb-d492a2682e24) page.\n- Click **Copy and Customize** . The **Clone your App** dialog is displayed.\n- In the **App name** field, enter the name of the proxy,`product-recommendations-v1`, and then click **Copy app** . Wait a few moments for your app to be created.\n- In the **Welcome to your app** page, click **Customize app** . By default, the app uses a sample data source in a Google Sheet.\n- Change the data source to match the Apigee data source that you created earlier:- Click **+ New Table** , and then click **product recommendations v1** .\n- In the **Choose a Sheet/Table** dialog, select **products** .\n- In the **Create a new table** dialog, click **Read-Only** , and then click **Add This Table** .\nThe app is displayed with a **products 2** tab and a different data view. The new data view has different values for the description and price of each item. Notice that the order of the items is not the same as the order of the predictions.\n- Change the order in which items are returned from the data source by removing the AppSheet default sorting:- In the side navigation menu, select **UX** .\n- In the **Primary Views** section, select **products 2** .\n- In the **View Options** section, next to **Sort by** , delete the entry for **name, Ascending** . Observe that the order displayed in AppSheet is now the same as the result of the API call, with the last item from the response at the bottom.\n- Save the app.\nYou can optionally delete the original Product table and UX, and rename the \"products 2\" table and view to \"Product Recommendations\".\n## Clean up\nTo avoid incurring charges to your Google Cloud account for the resources used in this procedure, either delete the project that contains the resources, or keep the project and delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.### Delete the individual resources\nTo avoid recurring costs, delete the BigQuery Flex Slot reservations, the BigQuery dataset, and AI Platform model.- In the Google Cloud console BigQuery page, select **Capacity management** , and then click the **Reservations** tab.\n- Open the **model** entry.\n- Next to the **reservation** , clickmore_vert **View actions** , and then click **Delete** .\n- Next to the **model** entry, clickmore_vert **View actions** , and then click **Delete** .\n- In Cloud Shell, delete the deployment, the proxy, and its associated artifacts:```\nmvn -P eval process-resources -Dbearer=$(gcloud auth print-access-token) \\\u00a0 \u00a0 -DapigeeOrg=$ORG -DapigeeEnv=$ENV -Dskip.integration=true \\\u00a0 \u00a0 apigee-config:apps apigee-config:apiproducts apigee-config:developers -Dapigee.config.options=delete \\\u00a0 \u00a0 apigee-enterprise:deploy -Dapigee.options=clean\n```\n- Remove the Spanner resources:```\n./cleanup_spanner.sh\n```- In the Google Cloud console BigQuery page, in the **Resources** section, expand the project that you used for this solution.\n- Select the **bqml** dataset, and then click **Delete dataset** .\n- In the overlay window that appears, enter`bqml`and then click **Delete** .- In the Google Cloud console, go to the [AI Platform Models](https://console.cloud.google.com/ai-platform/models) page. [Go to AI Platform Models](https://console.cloud.google.com/ai-platform/models) \n- In the models list, click **rpm_bqml_model** .\n- In the **Model Details** page, select the checkbox for the **V_1(default)** version.\n- Click **More** , and then click **Delete** .\n- After the version has finished deleting, click **Back** to return to the models list.\n- Select the checkbox for the **rpm_bqml_model** model.\n- Click **More** , then click **Delete** .\n- In Cloud Shell, delete the service account:```\ngcloud iam service-accounts delete $SA\n```## What's next\n- Learn how to [invoke Google Cloud services from Apigee API proxies](/apigee/docs/api-platform/security/google-auth/overview) .\n- For more reference architectures, diagrams, and best practices, explore the [Cloud Architecture Center](/architecture) .", "guide": "Docs"}