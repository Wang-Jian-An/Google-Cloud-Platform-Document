{"title": "Docs - Building multi-architecture container images for IoT devices", "url": "https://cloud.google.com/architecture/building-multi-architecture-container-images-iot-devices-tutorial", "abstract": "# Docs - Building multi-architecture container images for IoT devices\nThis tutorial is the second part of a series that discusses building an automated [continuous integration (CI)](https://wikipedia.org/wiki/Continuous_integration) pipeline to build multi-architecture [container](https://wikipedia.org/wiki/OS-level_virtualization) images on Google Cloud.\nIn this tutorial, you implement a pipeline for building multi-architecture container images by using [Cloud Build](/build) and [Container Registry](/container-registry) . This tutorial exemplifies the multi-architecture build strategy described in the [Implementing a multi-architecture container images building pipeline](/solutions/building-multi-architecture-container-images-iot-devices#implementing_a_pipeline_for_building_multi-architecture_container_images) section in part 1 of this series.\nFor example, suppose you maintain a fleet of Internet of Things (IoT) devices. As new requirements for your IoT solution emerge, you need new hardware devices. If the new devices have a different hardware architecture than your existing ones, you need to modify your build pipeline to support the new architecture.\nThis tutorial is intended for IT professionals who want to simplify and streamline complex pipelines for building container images, or to extend those pipelines to build multi-architecture images.\nThis tutorial assumes that you have a basic knowledge of the following:- [Terraform](https://www.terraform.io/intro/index.html) , for creating infrastructure on Google Cloud.\n- [Google Cloud CLI](/sdk#documentation) , for performing platform tasks on Google Cloud.\n- [Cloud Shell](/shell/docs/features) , for running commands in this tutorial. All the tools used in this tutorial are preinstalled in Cloud Shell.\n- [Cloud Build](/build) , for setting up a CI pipeline.\n- [Docker](https://www.docker.com/) , as a container management platform.\n- [Container Registry](/container-registry) , for storing the container images that the build process produces.\nIn this tutorial, you use Terraform to set up the resources that you need in order to provision and configure the pipeline for building container images.", "content": "## ArchitectureThe following diagram illustrates the workflow for the pipeline that you create in this tutorial for building container images.Changes made to the source code of the container image trigger Cloud Build to build a multi-architecture container image. When the build is completed, the multi-architecture container image is stored in Container Registry.## Objectives\n- Use Terraform to provision the pipeline for building container images on Google Cloud.\n- Modify the source code of the container image to trigger a new build.\n- Inspect the container image that is stored in Container Registry.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Cloud Source Repositories](/source-repositories/pricing) \n- [Cloud Build](/build/pricing) \n- [Container Registry](/container-registry/pricing) \n- [Pub/Sub](/pubsub/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . ## Before you begin\n- In the Google Cloud console, on the project selector page,   select or [create a Google Cloud project](/resource-manager/docs/creating-managing-projects) . **Note** : If you don't plan to keep the  resources that you create in this procedure, create a project instead of  selecting an existing project. After you finish these steps, you can  delete the project, removing all resources associated with the project. [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Preparing your environmentIn this tutorial, you run all commands in Cloud Shell.- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.\n- Clone the sample code repository:```\ncd \"$HOME\"git clone \\https://github.com/GoogleCloudPlatform/solutions-build-multi-architecture-images-tutorial.git\n```\n- Generate [application default credentials](/sdk/gcloud/reference/auth/application-default) :```\ngcloud auth application-default login --quiet\n```The output is similar to the following:```\nGo to the following link in your browser:\n https://accounts.google.com/o/oauth2/auth?code_challenge=...\nEnter verification code:\n```\n- In a browser window, open the URL that is displayed in the output from generating the application default credentials (the preceding step).\n- Select **Allow** to continue.\n- Copy the code on the screen and enter it into Cloud Shell.The output is similar to the following:```\n/tmp/tmp.xxxxxxxxxx/application_default_credentials.json\n```Note the path to the `application_default_credentials.json` file. You use this path to set an environment variable in the next section.\n## Setting environment variablesBefore you can provision the necessary infrastructure for this tutorial, you need to initialize and export the following environment variables:- In Cloud Shell, create an environment variable that stores the [Google Cloud service account](/iam/docs/understanding-service-accounts) name that Terraform uses to provision resources:```\nexport TF_SERVICE_ACCOUNT_NAME=tf-service-account\n```\n- Create an environment variable that stores the Google Cloud project ID that Terraform uses to store the [state](https://www.terraform.io/docs/state/index.html) :```\nexport TF_STATE_PROJECT=${DEVSHELL_PROJECT_ID}\n```\n- Create an environment variable that stores the Cloud Storage bucket that Terraform uses to save the state files:```\nexport TF_STATE_BUCKET=tf-state-bucket-${TF_STATE_PROJECT}\n```\n- Create an environment variable that stores the Google Cloud project ID that contains the resources for the container image build pipeline:```\nexport GOOGLE_CLOUD_PROJECT=${DEVSHELL_PROJECT_ID}\n```\n- Create an environment variable that stores path to the default Google Cloud application default credentials, which is the value you noted in the preceding section:```\nexport GOOGLE_APPLICATION_CREDENTIALS=PATH\n```Replace the following:- ``: path to the`application_default_credentials.json`file## Provisioning the environmentYou need to run the `generate-tf-backend.sh` shell script that generates the [Terraform backend configuration](https://www.terraform.io/docs/backends/index.html) , the necessary Google Cloud service accounts, and the Cloud Storage bucket to store information about the [Terraform remote state](https://www.terraform.io/docs/state/remote.html) .- In Cloud Shell, provision your build environment:```\ncd $HOME/solutions-build-multi-architecture-images-tutorial/./generate-tf-backend.sh\n```The script is idempotent and safe to run multiple times.After you run the script successfully for the first time, the output is similar to the following:```\nGenerating the descriptor to hold backend data in terraform/backend.tf\nterraform {\n backend \"gcs\" {\n  bucket = \"tf-state-bucket-project-id\"\n  prefix = \"terraform/state\"\n }\n}\n```\n## Creating the build pipelineThe Terraform template file `terraform/main.tf` defines the resources that are created for this tutorial. By running Terraform with that descriptor, you create the following Google Cloud resources:- A Cloud Source Repositories code repository to store the [container image descriptor](https://docs.docker.com/engine/reference/builder/) and the [Cloud Build build configuration file](/build/docs/configuring-builds/create-basic-configuration) .\n- A Pub/Sub [topic](/pubsub/docs/overview#data_model) where Cloud Build publishes messages on each source code change.\n- A Cloud Build build that builds the multi-architecture container image.\n- A Container Registry repository to store container images.\nIn Cloud Shell, do the following:- To initialize the Terraform working directory, run the [terraform init](https://www.terraform.io/docs/commands/init.html) command:```\ncd terraformterraform init\n```\n- (Optional) To review the changes that Terraform is going to apply, run the [terraform plan](https://www.terraform.io/docs/commands/plan.html) command:```\nterraform plan\n```The output is a list of all actions that Terraform is expected to perform to provision resources in the Google Cloud environment. The summary of all actions is similar to the following:```\nPlan: 8 to add, 0 to change, 0 to destroy.\n```The total number of add actions is 8, with no changes and no deletions.\n- Run the [terraform apply](https://www.terraform.io/docs/commands/apply.html) command to create the resources in your Google Cloud project:```\nterraform apply\n```\n- To continue with running the command, enter `yes` .\n## Pushing the source files to Cloud Source RepositoriesIn order for the build pipeline to execute the build, the Dockerfile and the Cloud Build configuration files need to be stored in a Cloud Source Repositories source code repository.- In Cloud Shell, clone the source repository:```\ncd $HOMEgcloud source repos clone cross-build\n```\n- Copy the Dockerfile and the Cloud Build configuration file into the source code repository:```\ncp -r \"$HOME\"/solutions-build-multi-architecture-images-tutorial/terraform/cloud-build/. \"$HOME\"/cross-build\n```\n- Commit and push the files in the source code repository:```\ncd \"$HOME\"/cross-buildgit add .git commit -m \"Initial commit\"git push\n```\n## Inspecting the resultsWhile the Cloud Build job is running and after its completion, you can inspect the execution of each build step on the Cloud Build [Build history](https://console.cloud.google.com/cloud-build/builds) page.\n \n### Cloud Build buildIn the **Build history** page, you get an overview of the build steps, together with the time it took to run each step, as the following illustration shows.\n \nIf you open a build step, you see the output for that step. For example, the build details of the **buildx inspect** step in the preceding diagram show the different target platform architecture that the platform supports:\n```\n12 Name:  mybuilder0\n13 Endpoint: unix:///var/run/docker.sock\n14 Status: running\n15 Platforms: linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6\n```\nThe build details for the fourth step show the output from the build for each target architecture:\n```\n#8 0.268 I am running on linux/amd64, building for linux/amd64\n#12 0.628 I am running on linux/amd64, building for linux/arm/v7\n#10 0.279 I am running on linux/amd64, building for linux/arm/v6\n#14 0.252 I am running on linux/amd64, building for linux/arm64\n```\n### Image manifest in Container RegistryAfter the build has completed, you can inspect the image manifest on the Container Registry [Images page](https://console.cloud.google.com/gcr) in the Google Cloud console, as the following illustration shows.\n \nIf you open the **test** repository in the repository list, you see all the container image versions that belong to the **test** repository, as the following illustration shows.\n \nYou can open the image that is tagged **latest** to open to the **Digestdetails** page to see detailed information about the image, as the following illustration shows.\n \nIn the **Digest details** page, you can expand the **Manifest** section and verify all the target architecture created by the build is stated in the file, as the following example shows:\n```\n{\n \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n \"schemaVersion\": 2,\n \"manifests\": [  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:839024acb1038509e3bc66f3744857840951d0d512be54fd6670ea1e8babdcb6\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"amd64\",\n   \"os\": \"linux\"\n  }\n  },\n  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:33489767c29efb805e446a61d91cc55e042d3cfadcd186d9a1c8698f2f12309d\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"arm64\",\n   \"os\": \"linux\"\n  }\n  },\n  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:f1958815778ca8c83d324bad3fc68a9e3e9d5ea48b5bb27a8aca7d8da20cf8d4\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"arm\",\n   \"os\": \"linux\",\n   \"variant\": \"v7\"\n  }\n  }\n ]\n}\n```\nYou can also view the image manifest directly from Cloud Shell.- In Cloud Shell, display the image manifest:```\nDOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect gcr.io/\"${DEVSHELL_PROJECT_ID}\"/test:latest\n```The output is the same as the manifest file that you can expand on the **Digest details** page.\n## Configuring continuous deployment from the build pipelineTo build the container image for the new hardware architecture, you modify the build configuration file by adding the new target architecture. After you commit and push the change to the source repository in Cloud Source Repositories, Cloud Build starts a new build. The build produces a new version of the multi-architecture container image, including the support for the newly added hardware architecture.- In Cloud Shell, add the new target platform to the build configuration file:```\ncd \"$HOME\"/cross-buildsed -i -e 's/linux\\/arm\\/v7/linux\\/arm\\/v7,linux\\/386/g' build-docker-image-trigger.yaml\n```\n- Commit and push the change to the source code repository:```\ngit add .git commit -m \"add a new target platform\"git push\n```\n- View the latest manifest to verify the new target platform is part of the latest container image:```\nDOCKER_CLI_EXPERIMENTAL=enabled docker manifest inspect gcr.io/${DEVSHELL_PROJECT_ID}/test:latest\n```\n- Verify the newly added target platform is in the manifest file, similar to the following output:```\n{\n \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n \"schemaVersion\": 2,\n \"manifests\": [  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:bc80d063fccb4c370df9b505cbf4f8a814a366d99644de09ebee98af2ef0ff63\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"amd64\",\n   \"os\": \"linux\"\n  }\n  },\n  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:be10e4f01f529149815ebad7eb09edaa84ebef5b7d70d51f7d1acb5ceb1f61cd\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"arm64\",\n   \"os\": \"linux\"\n  }\n  },\n  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:f6ba5d5d3bc1ea0177e669517ea15a0d4fb97c06c7eca338afa43734d87af779\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"arm\",\n   \"os\": \"linux\",\n   \"variant\": \"v7\"\n  }\n  },\n  {\n  \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n  \"digest\": \"sha256:a3c34621cca10974026f8ad0782af78539cd7bb0ebfa0082a27b2c3ed4418ca0\",\n  \"size\": 735,\n  \"platform\": {\n   \"architecture\": \"386\",\n   \"os\": \"linux\"\n  }\n  }\n ]\n}\n```\n## Clean upThe easiest way to eliminate billing is to delete the Google Cloud project you created for the tutorial. Alternatively, you can delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n### Delete the individual resourcesIf you want to keep the project that you used in this tutorial, perform the following steps to delete the resources that you created in this tutorial.- In Cloud Shell, delete the container images:```\ngcloud container images delete gcr.io/${DEVSHELL_PROJECT_ID}/test --quiet\n```\n- Delete the resources you provisioned using Terraform:```\ncd $HOME/solutions-build-multi-architecture-images-tutorial/terraformterraform destroy\n```\n- Enter `yes` to confirm the deletion.\n## What's next\n- Read [Multi-architecture container images for IoT devices](/architecture/building-multi-architecture-container-images-iot-devices) .\n- Learn more about [managing infrastructure as code with Terraform, Cloud Build, and GitOps](/solutions/managing-infrastructure-as-code) .\n- Get more information about DevOps on the [DevOps page](/devops) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Docs"}