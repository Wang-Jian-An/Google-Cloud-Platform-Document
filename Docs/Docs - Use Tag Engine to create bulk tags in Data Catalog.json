{"title": "Docs - Use Tag Engine to create bulk tags in Data Catalog", "url": "https://cloud.google.com/architecture/tag-engine-and-data-catalog", "abstract": "# Docs - Use Tag Engine to create bulk tags in Data Catalog\nLast reviewed 2022-11-17 UTC\nThis guide shows you how to use Tag Engine to create bulk tags in [Data Catalog](/data-catalog) . Bulk tags are a collection of similar tags which are created and updated together as a unit. Creating tags in bulk can reduce the time and effort required to tag your organization's data assets. This document introduces Tag Engine and shows you how to use it to tag a collection of assets when those assets have common metadata attributes.\nTag Engine is an open source tool that helps you create metadata for [BigQuery](/bigquery) and [Cloud Storage](/storage) assets. The tool supports populating tags that have static metadata or dynamic metadata. Tag Engine also supports the autotagging of new assets and the refreshing of existing tags as the underlying data changes.\nThis document is intended for data stewards who are responsible for creating metadata that accurately describes their organization's data assets.\nThis document walks through the initial setup of Tag Engine, which includes running some [Terraform](https://www.terraform.io/) scripts. It uses two examples to illustrate bulk tagging for BigQuery assets. Both examples start by creating a small dataset in BigQuery. A subsequent document illustrates similar concepts for Cloud Storage.\n", "content": "## Tag Engine architecture\nTag Engine is deployed under the following configurations:\n- Deployed into the same project as Data Catalog and BigQuery, which is suitable for proof-of-concept and development environments.\n- Shared with a Data Catalog project, but in a different BigQuery project, which is suitable for higher-level environments, like production.\n- Deployed into its own project, which is also suitable for higher-level environments.The preceding diagram illustrates the shared deployment pattern, which is the pattern this document uses.\n## Objectives\n- Create bulk metadata for your BigQuery assets with Tag Engine, as a data steward.\n- Create bulk metadata for your BigQuery assets with the Tag Engine API, as a data engineer.\n- Createtag configurations using the Tag Engine UI or its API.\n- Createtag configurations using the Tag Engine UI or its API.\n- Keep the change history of your tags in BigQuery.\n- Publish real-time tag updates to Pub/Sub and alert on critical changes.\n- Review your data estate with the Tag Engine coverage report and prioritize tagging tasks.## Costs\n- [App Engine](/appengine/pricing) \n- [Firestore](/firestore/pricing) \n- [BigQuery](/bigquery/pricing) \n- [Data Catalog](/data-catalog/pricing) \n- [Pub/Sub (optional)](/pubsub/pricing) ## Before you begin\n- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.This document introduces two Google Cloud projects, one for running Tag Engine and another for storing data in BigQuery. For the remainder of this document, the first Google Cloud project is called the Tag Engine project. The second Google Cloud project is called the BigQuery project.\nIf you don't plan to keep the resources that you create in this document, create two projects instead of selecting existing ones.\n## Deploy and configure Tag Engine\nIn this section, you deploy Tag Engine on Google Cloud. First, you create the Tag Engine database on Firestore and use Google Cloud CLI commands to deploy the Tag Engine application on App Engine. Then, you use Terraform to configure Tag Engine.\n**Note:** Tag Engine comes in two flavors. Tag Engine v1 is hosted on App Engine, which is the focus of this tutorial. Tag Engine v2 is hosted on Cloud Run and can be found in the `cloud-run` branch of the code repository.\nDownload and install [Terraform](https://learn.hashicorp.com/tutorials/terraform/install-cli) before deploying Tag Engine on Google Cloud. The Terraform scripts grant IAM permissions, create database indexes, and configure the cloud task and scheduler entries.\n- In Cloud Shell, set the required environment variables:```\nexport TAG_ENGINE_PROJECT=PROJECT_ID1export TAG_ENGINE_REGION=us-centralexport TAG_ENGINE_SUB_REGION=us-central1export BQ_PROJECT=PROJECT_ID2export BQ_REGION=us-central1export TAG_ENGINE_SA=${TAG_ENGINE_PROJECT}@appspot.gserviceaccount.comgcloud config set project ${TAG_ENGINE_PROJECT}\n```Replace the following variables:- = the ID of your Tag Engine project\n- = the ID of your BigQuery project\n- Clone the GitHub Tag Engine code repository:```\ngit clone https://github.com/GoogleCloudPlatform/datacatalog-tag-engine.git\n```\n- Set the Terraform variables by creating a `variables.tfvars` file:```\ncd datacatalog-tag-enginecat > deploy/variables.tfvars << EOLtag_engine_project=\"${TAG_ENGINE_PROJECT}\"bigquery_project=\"${BQ_PROJECT}\"app_engine_region=\"${TAG_ENGINE_REGION}\"app_engine_subregion=\"${TAG_ENGINE_SUB_REGION}\"EOL\n```\n- Create the Tag Engine configuration file ( `tagengine.ini` ):```\ncat > tagengine.ini << EOL\\[DEFAULT]\\TAG_ENGINE_PROJECT = ${TAG_ENGINE_PROJECT}\\QUEUE_REGION = ${TAG_ENGINE_SUB_REGION}\\INJECTOR_QUEUE = tag-engine-injector-queue\\WORK_QUEUE = tag-engine-work-queue\\BIGQUERY_REGION = ${BQ_REGION}\\EOL\n```\n- Create an App Engine application for Tag Engine:```\ngcloud app create \\\u00a0 --project=${TAG_ENGINE_PROJECT} \\\u00a0 --region=${TAG_ENGINE_REGION}\n```\n- Create the database:```\ngcloud firestore databases create \\\u00a0 --project=${TAG_ENGINE_PROJECT} \\\u00a0 --region=${TAG_ENGINE_REGION}\n```\n- Deploy Tag Engine with the default App Engine service account:```\ngcloud app deploy app.yaml\n```Make sure that your service account is assigned the Editor role on the Tag Engine project.\n- (Optional) Deploy Tag Engine with a user-managed service account:```\nexport TAG_ENGINE_SA=SERVICE_ACCOUNTgcloud beta app deploy --service-account=$TAG_ENGINE_SA app.yaml\n```Replace the following variable:- = the email of your user-managed service account\nAssign your user-managed service account the Editor role on the Tag Engine project.\n- Secure App Engine using firewall rules:```\ngcloud app firewall-rules create 100 --action ALLOW --source-range[IP_RANGE]gcloud app firewall-rules update default --action deny\n```By default, App Engine allows traffic from the public internet. Use App Engine [firewall rules](/appengine/docs/flexible/go/application-security#app_engine_firewall) to restrict network traffic to a range of IP addresses.Alternatively, you can manage access with IAM using [Identity-Aware Proxy (IAP)](/iap/docs/concepts-overview) .To set up IAP to access Tag Engine, [configure OAuth and IAP access](/iap/docs/authenticate-users-google-accounts) .\n- Run the following Terraform commands. Enter `yes` when prompted.```\ncd deployterraform initterraform apply -var-file variables.tfvars\n```\n- Launch Tag Engine in your browser:```\ngcloud app browse\n```\nThe Tag Engine browser interface is primarily how data stewards create bulk metadata tags. To create all metadata tags, Tag Engine uses tag configurations.\n## Create a sample dataset\nIn this scenario, the sample dataset used in both examples contains three tables. The tables hold publicly available service request records for the cities of Austin, New York, and San Francisco from the non-emergency municipal services [311](https://en.wikipedia.org/wiki/3-1-1) telephone number for each city. The tables are located in the `us` region and we would like to query them from the `us-central1` region. To do so, we export them to Cloud Storage and then import them into the correct region in BigQuery.\n- In Cloud Shell, create a bucket in Cloud Storage in the `us-central1` region:```\nexport BUCKET=cities-311gsutil mb -l ${BQ_REGION} gs://${BUCKET}\n```\n- Export the three `311_service_requests` tables into the Cloud Storage bucket:```\nbq extract --destination_format=AVRO \\\u00a0 bigquery-public-data:austin_311.311_service_requests \\\u00a0 gs://${BUCKET}/austin/311_service_requests*.avrobq extract --destination_format=AVRO \\\u00a0 bigquery-public-data:new_york_311.311_service_requests \\\u00a0 gs://${BUCKET}/new_york/311_service_requests*.avrobq extract --destination_format=AVRO \\\u00a0 bigquery-public-data:san_francisco_311.311_service_requests \\\u00a0 gs://${BUCKET}/san_francisco/311_service_requests*.avro\n```\n- In Cloud Shell, create the sample dataset:```\nbq --location=${BQ_REGION} mk --dataset ${BQ_PROJECT}:cities_311\n```\n- Load the files into BigQuery:```\n\u00a0bq load --source_format=AVRO ${BQ_PROJECT}:cities_311.austin_311_service_requests \\\u00a0 \u00a0gs://${BUCKET}/austin/*.avro\u00a0bq load --source_format=AVRO ${BQ_PROJECT}:cities_311.new_york_311_service_requests \\\u00a0 \u00a0gs://${BUCKET}/new_york/*.avro\u00a0bq load --source_format=AVRO ${BQ_PROJECT}:cities_311.san_francisco_311_service_requests \\\u00a0 \u00a0gs://${BUCKET}/san_francisco/*.avro\u00a0```\n```\n- Delete the cities 311 files and bucket from Cloud Storage:```\ngsutil -m rm -r gs://${BUCKET}\n```## Create Data Catalog tag templates\nBefore you can create the tag configurations in Tag Engine, you must first create one or more Data Catalog [tag templates](/data-catalog/docs/tags-and-tag-templates#tag-templates) . A tag template is a Data Catalog concept that defines the schema of one or more tags of the same type. The schema specifies a collection of field names, their data types, and their sequence in the template. Every Data Catalog tag is instantiated from a tag template.\nTo annotate each 311 service request table using key performance metrics, create a tag template:\n- In Cloud Shell, clone the GitHub `datacatalog-templates.git` repository and change into the `datacatalog-templates` folder:```\ngit clone https://github.com/GoogleCloudPlatform/datacatalog-templates.gitcd datacatalog-templates\n```\n- Create and activate a virtual environment, and install the Python dependencies:```\npython -m venv venvsource venv/bin/activatepip install -r requirements.txt\n```\n- Create the `cities_311` tag template:```\npython create_template.py $TAG_ENGINE_PROJECT $TAG_ENGINE_SUB_REGION \\\u00a0 cities_311.yaml\n```The `create_template.py` script creates a tag template based on the contents of the `cities_311.yaml` file. The `cities_311` tag template contains 11 fields, 2 of which are required. You must provide both required fields when you create tags from this tag template.| Field name     | Field type | Required field |\n|:---------------------------|:-------------|:-----------------|\n| avg_daily_total_requests | double  | False   |\n| avg_daily_open_requests | double  | False   |\n| avg_daily_closed_requests | double  | False   |\n| avg_daily_unknown_requests | double  | False   |\n| sum_total_requests   | double  | True    |\n| unique_total_requests  | double  | False   |\n| closed_total_requests  | double  | False   |\n| open_total_requests  | double  | False   |\n| unknown_total_requests  | double  | False   |\n| unique_total_complaints | double  | False   |\n| tag_snapshot_time   | datetime  | True    |\n- Open [Data Catalog](https://console.cloud.google.com/datacatalog/templates) in Google Cloud console to view the **Cities 311 Service Requests** tag template. It should look similar to the following screenshot: \n- Create the `data_governance` tag template:```\npython create_template.py ${TAG_ENGINE_PROJECT} ${TAG_ENGINE_SUB_REGION} \\\u00a0 \u00a0 data_governance.yaml\n```The `data_governance` template also contains 11 fields, 2 of which are required. You must provide both of the required fields when you create tags from this template.| Field name    | Type  | Required |\n|:-------------------------|:---------|:-----------|\n| data_domain    | enum  | True  |\n| broad_data_category  | enum  | True  |\n| environment    | enum  | False  |\n| data_origin    | enum  | False  |\n| data_creation   | datetime | False  |\n| data_ownership   | string | False  |\n| data_asset_owner   | string | False  |\n| data_asset_expert  | string | False  |\n| data_confidentiality  | enum  | False  |\n| data_retention   | enum  | False  |\n| data_asset_documentation | string | False  |\n- In Google Cloud console, open [Data Catalog](https://console.cloud.google.com/datacatalog/templates) to view the `data_governance` tag template. It should look similar to the following screenshot: ## Tag Engine preferences\nTag Engine gives you the option to save a default tag template for convenience. There are also options to save a copy of each tag to BigQuery and to Pub/Sub. Each of these topics is detailed in this section. Although you can start tagging without setting these options, you can't copy those tags to BigQuery or publish them to Pub/Sub. If you want to skip these options, you can go directly to the [Tagging overview](#tagging_overview) section.\n### Save a default tag template\nTo avoid entering the tag template ID, project ID, and region each time you create or edit your tags, Tag Engine lets you save a default tag template.\nFollow these steps to set your default tag template:\n- Click the **Set Default Tag Template** link from the Tag Engine home page.\n- Enter the following details:- **Template ID:** `cities_311`\n- **Template Project:** \n- **Template Region:** `us-central1`\nReplace with the ID of your Tag Engine project.\n- Click **Save Settings** .The parameters on the home page are now pre-populated with your default tag template details.\n### Select a tag history option\nThrough the tag history option, you can save a copy of every tag that Tag Engine creates to a BigQuery table. This action lets you keep a change history of all of your tags. Every tag is written as a new table record in BigQuery with all tag values from one tag template stored in the same table. The table schema includes the creation time of the tag, the asset name, and every field from the tag template. The tag history table for the `cities_311` template is created with the following fields:\n| Field name     | Field type | Description                          |\n|:---------------------------|:-------------|:-------------------------------------------------------------------------------------------------------------------|\n| event_time     | datetime  | Timestamp of the tagging operation                     |\n| asset_name     | string  | Name of the asset in BigQuery\u2014for example, warehouse-337221/dataset/cities_311/table/new_york_311_service_requests |\n| avg_daily_total_requests | numeric  | Value for the field avg_daily_total_requests                  |\n| avg_daily_open_requests | numeric  | Value for the field avg_daily_open_requests                  |\n| avg_daily_closed_requests | numeric  | Value for the field avg_daily_closed_requests                  |\n| avg_daily_unknown_requests | numeric  | Value for the field avg_daily_unknown_requests                  |\n| sum_total_requests   | numeric  | Value for the field sum_total_requests                    |\n| unique_total_requests  | numeric  | Value for the field unique_total_requests                   |\n| closed_total_requests  | numeric  | Value for the field closed_total_requests                   |\n| open_total_requests  | numeric  | Value for the field open_total_requests                   |\n| unknown_total_requests  | numeric  | Value for the field unknown_total_requests                   |\n| unique_total_complaints | numeric  | Value for the field unique_total_complaints                  |\n| tag_snapshot_time   | datetime  | Value for the field tag_snapshot_time                    |\nThis tag history table is named `tag_history.cities_311` . The dataset in which you store your tag history tables is identified by `tag_history` .\n- To enable the tag history feature, create a BigQuery dataset for storing your tag history tables:```\nbq mk --project_id ${BQ_PROJECT} tag_history\n```\n- Grant the Tag Engine service account edit permissions on the dataset:```\n\u00a0bq query --nouse_legacy_sql \\\"GRANT \\`roles/bigquery.dataEditor\\` ON SCHEMA \\`${BQ_PROJECT}.tag_history\\`TO 'serviceAccount:${TAG_ENGINE_PROJECT}@appspot.gserviceaccount.com'\"\n```\n- In Tag Engine, click **Turn on/off Tag History** on the home page. Enter the following details:- **Enable Tag History:** On\n- **BigQuery Project ID:** \n- **BigQuery Region:** `us-central1`\n- **BigQuery Dataset:** `tag_history`\nReplace the following variable: - = the ID of your BigQuery project.\n- Click **Save Settings** . **Note:** Tag Engine doesn't create the BigQuery dataset for hosting your tag history tables. You must create it outside of Tag Engine before enabling tag history.\n- (Optional) To turn off this feature, go to the **Tag History Settings** page and choose **Enable tag history: Off** and save your changes.\n### Select a tag stream option\nThrough the tag stream option, Tag Engine publishes a copy of every tag you create into a Pub/Sub topic. This action lets you subscribe and react to changes in your tag values.\n- In Cloud Shell, create a Pub/Sub topic:```\ngcloud pubsub topics create tag-stream \\\u00a0 --project=${BQ_PROJECT}\n```\n- Create a subscription on a Pub/Sub topic:```\ngcloud pubsub subscriptions create tag-stream-sub \\\u00a0 --topic=tag-stream \\\u00a0 --topic-project=${BQ_PROJECT}\n```\n- Grant permissions to the Tag Engine service account on the Pub/Sub topic:```\ngcloud pubsub topics add-iam-policy-binding tag-stream \\\u00a0 --project=${BQ_PROJECT} \\\u00a0 --member=\"serviceAccount:${TAG_ENGINE_PROJECT}@appspot.gserviceaccount.com\" \\\u00a0 \u00a0--role=\"roles/editor\"\n```\n- Click the **Turn on/off Tag Stream** link on the Tag Stream home page. Enter the following details:- **Enable Tag Stream:** On\n- **Pub/Sub Project ID:** \n- **Pub/Sub Topic:** `tag-stream`\nReplace with the ID of your BigQuery project.\n- Click **Save Settings** .\n- (Optional) To turn off tag streaming, select **Off** from the **EnableTag Stream** menu and save your changes.## Tagging overview\nThere are two primary tag configurations in Tag Engine: and .\nA dynamic configuration assigns a query expression for each tag template field. The query expressions are provided in SQL with the use of some special variables. The dynamic configuration also includes information on when and how to update the tags. You use dynamic configurations to populate tags with metadata attributes sourced from BigQuery, such as operational metadata. There are two types of dynamic configurations that you can use: a that tags tables and views in BigQuery, or a that tags fields in BigQuery.\nA static configuration assigns constant values to each of the tag template fields in the tag. You use static configurations to tag assets with seldom-changing, descriptive metadata, such as data ownership and data domain information. The assets can either be BigQuery datasets, tables, and views or Cloud Storage buckets, folders, and files. This configuration comes in only one option, .\nTag Engine lets you create configurations through either a web interface or an API. Data stewards normally prefer using the web interface. By using the web interface, data stewards don't need to write data pipelines. Also the web interface gives them the autonomy and agility to develop new tags with SQL. Data engineers normally prefer using APIs, especially in a production environment. Using APIs lets them integrate the tagging tasks into their data pipelines and gives them more control on the timing of the tag updates.\nWhen you create configurations, choose the method (either the web interface or API) that is appropriate for your use case and team. The following sections provide details on how to use both methods, starting with how to use the web interface.\n## Create dynamic tag configurations\nA dynamic configuration produces a collection of Data Catalog tags. Each tag is associated with a unique tag template and a BigQuery resource combination. It's called because the contents of the tags are populated from the results of the query expressions.\nAs mentioned earlier, a dynamic configuration produces either table-level tags or column-level tags, but not both. To create table-level tags, choose the dynamic table configuration type. To create column-level tags, should the dynamic column configuration type.\nRegardless of which type you choose, a dynamic configuration contains the following three sections:\n- **Query expressions:** Specifies how to generate the value for one or more tag template fields\n- **URI expressions:** Specifies a path to one or more BigQuery resources (tables, views, datasets)\n- **Scheduling settings:** Specifies how often to update the Data Catalog tags associated with the current configuration\nThe required fields of the tag template are auto-selected, for example, `sum_total_requests` and `tag_snapshot_time` . Next to each tag template field, enter a query expression. The expected type for each field is listed in parentheses. In BigQuery, The query expression must be a valid `SELECT` statement. The `SELECT` clause is required. The `FROM` and `WHERE` clauses are optional, although frequently used. Other clauses in the `SELECT` statement, like `JOIN` and `GROUP BY` , are also allowed.\nWithin the various clauses of the `SELECT` statement, the query expression can reference a few variables, like `$table` and `$column` . The following list contains all the variables you can reference:\n- `$project`: The project ID of the BigQuery resource being tagged.\n- `$dataset`: The dataset name of the BigQuery resource being tagged.\n- `$table`: The table name of the BigQuery resource being tagged. When used in the`FROM`clause of the query expression, it resolves to the fully qualified path to the table being tagged. For example,`warehouse-337221.cities_311.austin_311_service_requests`. When used in the`WHERE`clause of the query expression, it resolves to the table name\u2014for example,`austin_311_service_requests`.\n- `$column`: The column name of the BigQuery resource being tagged. Note that this variable is only available when creating column-level tags.\nIn addition to referencing these special variables, a query expression can also reference any built-in BigQuery functions, like `round` , `cast` , `extract` , and so on.\n### Create a dynamic table configuration using the cities_311 tag template\nIn this section, you use the `cities_311` tag template to create a dynamic table configuration.\n- On the Tag Engine home page, enter your tag template ID, project ID, and region if they aren't already set and click **Search Template** .\n- On the **Tag template details** page, click **Create Dynamic Table Tags** . The query expression section of the configuration now appears on the **Config for creating dynamic table tags** page. Notice on the page that the required fields (in this case, `sum_total_requests` and `tag_snapshot_time` ) of the tag template are auto-selected. The required fields of the tag template are auto-selected, in this case, `sum_total_requests` and `tag_snapshot_time` .\n- Next to each tag template field, enter a query expression in the text field.The query expression must be a valid `SELECT` statement in BigQuery. The `SELECT` clause is required. The FROM and `WHERE` clauses are optional, although frequently used. Other clauses in the `SELECT` statement, such as `JOIN` and `GROUP BY` , are also allowed.Each query expression must return a value that is compatible with its corresponding tag template field type. For example, the expression associated with the `sum_total_requests` field must return a `numeric` value. The expression associated with the `tag_snapshot_time` field must return a `datetime` value. The expected type for each field is listed.Within the various clauses of the `SELECT` statement, the query expression can reference a few special variables, like `$table` and `$column` . The following list contains all the variables you can reference:- `$project`: The project ID of the BigQuery resource being tagged.\n- `$dataset`: The dataset name of the BigQuery resource being tagged.\n- `$table`: The table name of the BigQuery resource being tagged. When used in the FROM clause of the query expression,`$table`resolves to the fully qualified path to the table being tagged. For example,`warehouse-337221.cities_311.austin_311_service_requests`. When used in the`WHERE`clause of the query expression, it resolves to the table name\u2014for example,`austin_311_service_requests`.\n- `$column`: The column name of the BigQuery resource being tagged. Note that this variable is only available for column-level tags and does not apply to this cities_311 example.\nIn addition to referencing these special variables, a query expression can also reference any built-in BigQuery functions, like `round` , `cast` , `extract` , and so on.\n- Enter the following queries into the appropriate fields:| Field name     | Query expression                                                              |\n|:---------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| avg_daily_total_requests | select ifnull(round(avg(daily_requests), 2), 0) from (select date_created, count(*) as daily_requests from (select extract(date from timestamp_micros(created_date)) as date_created from $table) group by date_created)           |\n| avg_daily_open_requests | select ifnull(round(avg(daily_requests), 2), 0) from (select date_created, count(*) as daily_requests from (select extract(date from timestamp_micros(created_date)) as date_created from $table where status = 'Open') group by date_created)     |\n| avg_daily_closed_requests | select ifnull(round(avg(daily_requests), 2), 0) from (select date_created, count(*) as daily_requests from (select extract(date from timestamp_micros(created_date)) as date_created from $table where status = 'Closed') group by date_created)    |\n| avg_daily_unknown_requests | select ifnull(round(avg(daily_requests), 2), 0) from (select date_created, count(*) as daily_requests from (select extract(date from timestamp_micros(created_date)) as date_created from $table where status not in ('Open', 'Closed')) group by date_created) |\n| sum_total_requests   | select count(*) from $table                                                           |\n| unique_total_requests  | select count(distinct unique_key) from $table                                                      |\n| closed_total_requests  | select count(*) from $table where status = 'Closed'                                                     |\n| open_total_requests  | select count(*) from $table where status = 'Open'                                                     |\n| unknown_total_requests  | select count(*) from $table where status not in ('Closed', 'Open')                                                 |\n| unique_total_complaints | select count(distinct complaint_type) from $table                                                     |\n| tag_snapshot_time   | select current_datetime                                                            | **Note:** The indentation in the query expressions is for readability. Tag Engine doesn't require you to indent your code.\n- Select the checkboxes to include all fields from the tag template. \n### Finalize the configuration file\nThe next section of the configuration file describes the URIs to your BigQuery resources. This section consists of the following two parts:\n- The first part is the **Included Tables URIs** field. This field contains one or more paths to your BigQuery resources. Every tag configuration requires at least one Included Tables URI path.The URIs in the **Included Tables URIs** field follow this format: `bigquery/project/{project}/dataset/{dataset}/{table}/{column}` .The first four components of the URI up to and including `{dataset}` are required. The remaining components are optional.To tag an entire project, use `bigquery/project/{project}/*;` . To tag an entire dataset, use `bigquery/project/{project}/dataset/{dataset}/*` . Wildcards are allowed in the dataset and table names. For example, `bigquery/project/warehouse-337221/dataset/cities_311/austin*` matches on every table and view in the `cities_311` dataset, beginning with the string `austin*` .\n- The second part is the **Excluded Tables URIs** field. This optional field lets you exclude resources that match one or more of the Included Tables URI paths. You can use the **Excluded Tables URIs** field to exclude temporary tables and staging tables from being tagged. This field follows the same formatting rules as the **Included Tables URIs** field.\n**Note:** A dynamic column configuration has one additional parameter, a column query expression, which supplies a list of BigQuery fields to be tagged. Although this guide doesn't show a dynamic column configuration, you can view some examples of this type of configuration in the `/examples` folder of the code repository.\nTo finalize the configuration file, perform the following steps:\n- Enter the following value in the **Included Tables URIs** field: `bigquery/project/` `` `/dataset/cities_311/*`Replace with the ID of your BigQuery project.\n- Leave the **Excluded Tables URIs** field blank. \n- Schedule the tag refresh rate by selecting **Auto** . The following refresh mode selections are available:- **Auto:** Indicates that Tag Engine should trigger updates to the tags based on the refresh frequency that you choose.\n- **On-demand:** Deactivates Tag Engine automatic updates. Choose on-demand when updates depend on other data processing tasks and you want to trigger those updates through the API.\n \n- (Optional) Set the tag history and tag stream options. Accept the default values by leaving both boxes selected.These options only appear if you enabled the tag history and stream options before creating the dynamic table configuration. The tag history option saves a copy of each new and updated tag from this configuration to a BigQuery table. The tag stream option publishes a copy of each new and updated tag from this configuration to a Pub/Sub topic. The tag history records are organized by tag template. Tag stream messages are placed in the same topic. \n- Click **Submit Tag Config** .A confirmation page appears indicating that Tag Engine is processing the dynamic table configuration. \n- To refresh the status of the configuration page, click the provided link.To see the **View configurations** page where the status of the configuration is shown, click the **here** link.The following configuration statuses are available:- **Pending:** The configuration has been submitted and the bulk tag job is being created.\n- **Running:** The bulk tag job is running. The completion percentage also appears.\n- **Active:** The bulk tag job is complete and the configuration is active.\n- **Error:** The bulk tag job has produced one or more errors. Check the App Engine logs for more details.\n- When the status turns to for the `cities_311` configuration file, open the [Data Catalog](https://console.cloud.google.com/datacatalog) UI.\n- In the Data Catalog UI, click on the **Tag Templates** page and select the `cities_311` template.\n- On the template details page, click on **search for entries matching the template** .There should be three entries in the search results, one per city.\n- Click any of the three entries to see a `cities_311` tag containing the tag template fields and results from the query expressions. The dataset refreshes daily. \n### Verify scheduled tag updates\nThere are three ways to verify that Tag Engine is automatically updating all the tags produced by dynamic configurations.\nThe first method is to include a field in the tag template that records the last modified time of a tag. In the `cities_311` example, the `tag_snapshot_time` field, which is set to `select current_datetime` , serves this function. After creating a dynamic config, you wait one full refresh cycle\u2014which in the `cities_311` example is 24 hours\u2014and then check the tags in Data Catalog. The value of the `tag_snapshot_time` field should increase by one day. If this value is behind by more than 24 hours, the updates aren't working as intended. Review the App Engine logs for further details.\nThe second method is to query the tag history tables in BigQuery. This method requires turning on the tag history option in your configurations. The following screenshot shows that the `cities_311` tags were last updated on February 20, 2022.\nThe third method is to inspect the Tag Engine configuration store by searching for the configuration document in Firestore. Use the following steps to inspect the Tag Engine configuration store:\n- Open [Firestore](https://console.cloud.google.com/firestore) and look in the `dynamic_table_configs` collection for the configuration document.If your collection contains more than a handful of documents, you can filter the documents by `config_status = ACTIVE` or `config_type = DYNAMIC_TABLE_TAG` .\n- In the document that contains the configuration, find the scheduling section and look for the following fields:\n- `next_run` : Indicates the earliest time that Tag Engine is allowed to update the tags\n- `scheduling_status` : Indicates if the configuration is ready for updates\n- `version` : Indicates the number of updates that have occurred\n- To ensure that the update runs, set the `scheduling_status` field to Ready and ensure that the `next_run` field is a timestamp.## Create static tag configurations\nUnlike dynamic tag configurations, static tag configurations are intended for populating metadata attributes that rarely change, like the owner of a data asset or the domain of a data asset. Just like a dynamic configuration, a static tag configuration produces multiple Data Catalog tags. Each tag is linked to a unique BigQuery or Cloud Storage resource, like a dataset, table, view, bucket, folder, or file. Unlike dynamic configurations, a static configuration assigns a constant value to each template field that is included in the tag. Therefore, all tags produced by a static tag configuration contain the identical metadata values. To create a static configuration to tag the three `cities_311` tables, complete the following steps:\n- On the Tag Engine landing page, enter the following `data_governance` tag template details:- **Tag template ID:** `data_governance`\n- **Google Cloud project ID:** \n- **Google Cloud region:** `us-central1`\nReplace with the ID of your Tag Engine project. \n- Click **Search Template** . The **data_governance tag template details** page appears.\n- On the **data_governance tag template details** page, click **Create Static Asset Tags** . \n- On the **Config for creating static asset tags** page, enter the following details into the **Template Field Values** section:- **data_domain (enum):** `GOVERNMENT`\n- **broad_data_category (enum):** `CONTENT`\n- **environment (enum):** `DEV`\n- **data_origin (enum):** `OPEN_DATA`\n- **data_creation (datetime):** `2022-11-08 20:40:50`\n- **data_ownership (enum):** `PUBLIC_DOMAIN`\n- **data_asset_owner (string):** `Emily Doe`\n- **data_asset_expert (string):** `John Smith`\n- **data_confidentiality (enum):** `PUBLIC`\n- **data_retention (enum):** `30_DAYS`\n- **data_asset_documentation (string):** [https://support.datasf.org/help/311-case-data-faq](https://support.datasf.org/help/311-case-data-faq) \n **Note:** The value for the **data_creation** field defaults to the current date and time. \n- In the BigQuery or Google Cloud Storage Assets section of the page, enter the following values:- **Included Assets URIs:** `bigquery/project/` `` `/dataset/cities_311/*`\nReplace with the ID of your BigQuery project.- **Excluded Assets URIs:** leave this field blank. There are no tables to exclude.\n \n- In the **Update Options** section, enter the following values:- **Refresh mode:** `AUTO`\n- **Refresh frequency:** `24 hours`\n **Note:** The update options for static configurations have different semantics from the dynamic configs. A refresh mode of `AUTO` for static configurations means means that Tag Engine tags any new assets that match the Included Assets URIs at the specified refresh frequency. A refresh mode of `ON-DEMAND` means that you trigger the updates from the API at a convenient time. In either case, assets that have already been tagged through this configuration won't be retagged during updates.\n- Accept the default values for **Tag History** and **Tag Stream** by leaving both boxes selected.\n- Click **Submit Tag Config** to submit your static tag configuration. A confirmation page appears and indicates that the request is processing.To view the status of the configuration, click the **here** link. The status should change to `ACTIVE` within a few seconds when the tagging is complete. Larger jobs take longer. The status of a job appears as `PENDING` and `PROCESSING` while it is initializing and running.\n- Open the [Data Catalog](https://console.cloud.google.com/datacatalog) UI to verify the resulting tags.\n- Search for entries using `tag:data_governance` .The three `cities_311` tables show up in the results. Each entry contains a `data_governance` tag with the field name and values you assigned in the static configuration. Your results should look similar to the following screenshot: ## Create configurations and trigger tag updates through the API\nTag Engine provides various API methods for creating static and dynamic configurations and triggering tag updates. The `/examples` folder of the code repository has various examples for each method. The `static_asset_configs` examples are based on the `data_governance` tag template and the `dynamic_table_configs` examples are based on the `cities_311` tag template.\n- `static_asset_tags` : Creates a static asset configuration based on a configuration request formatted in JSON. Returns a job identifier. [Example request](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/blob/main/examples/static_asset_configs/static_asset_create_auto_bq.json) .\n- `dynamic_table_tags` : Creates a dynamic table configuration based on a configuration request formatted in JSON. Returns a job identifier. [Example request](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/tree/main/examples/dynamic_table_configs) .\n- `dynamic_column_tags` : Creates a dynamic column configuration based on a configuration request formatted in JSON. Returns a job identifier. [Example request](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/blob/main/examples/dynamic_column_configs/dynamic_column_create_auto.json) .\n- `ondemand_updates` : Triggers an update request. The request either updates the contents of the tags (dynamic configuration) or creates tags for any new assets (static configuration). Requires a static or dynamic configuration with a refresh_mode set to `ON_DEMAND` . Request is formatted in JSON. Returns a job identifier. [Example request.](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/blob/main/examples/dynamic_table_configs/dynamic_table_update_ondemand.json) \n- `get_job_status` : Returns the following statuses for a create or update job. Requires a job identifier.- `job_status`\n- `success`\n- `task_count`\n- `tasks_completed`\n- `tasks_failed`\n- `tasks_ran`\n### Create a dynamic table configuration\nThe following steps show how to call the `dynamic_table_tags` method using one of the provided configuration requests for the `cities_311` tag template.\n- In Cloud Shell, edit the [examples/dynamic_table_configs/dynamic_table_create_ondemand.json](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/blob/main/examples/dynamic_table_configs/dynamic_table_create_ondemand.json) file. Replace the values for the `template_project` , `template_region` , and `included_tables_uris` fields with your Tag Engine project, Tag Engine region, and BigQuery project.\n- Make an API call to create the dynamic tag configuration:```\nexport TAG_ENGINE_URL=https://${TAG_ENGINE_PROJECT}.uc.r.appspot.comRESPONSE_JSON=$(curl -X POST ${TAG_ENGINE_URL}/dynamic_create -d @examples/dynamic_table_configs/dynamic_table_create_ondemand.json)JOB_ID=$(echo ${RESPONSE_JSON} | jq -r \".job_uuid\")echo \"Job ID: ${JOB_ID}\"\n```If the request was successful, the API method returns a job identifier. If the request wasn't successful, the output details the error. Additional details can also be found in the App Engine logs by running: `gcloud app logs tail -s default`\n- To request the status of the job, use the job identifier from the previous step:```\ncurl -X POST ${TAG_ENGINE_URL}/get_job_status \\-d \"{\\\"job_uuid\\\":\\\"${JOB_ID}\\\"}\"\n```The output resembles the following:```\n{\"job_status\":\"COMPLETED\",\"success\":true,\"task_count\":3,\"tasks_completed\":3,\"tasks_failed\":0,\"tasks_ran\":3}\n```Once the job is finished, it returns a status of `COMPLETED` . To view the resulting tags, go to Data Catalog.\n### Trigger tag updates through the API\nBecause you created this configuration with on-demand scheduling ( `refresh_mode: ON_DEMAND` ), you can also use the API to trigger its tag updates. On-demand scheduling is useful in situations when the update schedule of a tag varies. In these circumstances, don't use the automatic scheduling mode. Instead, you should set your configuration to on-demand scheduling and trigger the tag updates using the `ondemand_updates` method.\n### Create a dynamic table update\n- Edit the file [examples/dynamic_table_configs/dynamic_table_update_ondemand.json](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/blob/main/examples/dynamic_table_configs/dynamic_table_update_ondemand.json) . Replace the following values:- `template_project`: Your Tag Engine project ID\n- `template_region`:`us-central1`\n- `included_tables_uris`: The BigQuery project URIs\n- Run the following command:```\nRESPONSE_JSON=$(curl -X POST ${TAG_ENGINE_URL}/ondemand_updates -d @examples/dynamic_table_configs/dynamic_table_update_ondemand.json)JOB_ID=$(echo ${RESPONSE_JSON} | jq -r \".job_uuid\")echo \"Job ID: ${JOB_ID}\"\n```If the request was successful, this method returns a job identifier.\n- To fetch the status of the job, call the `get_job_status` method:```\ncurl -X POST ${TAG_ENGINE_URL}/get_job_status \\-d \"{\\\"job_uuid\\\":\\\"${JOB_ID}\\\"}\"\n```\n### Create a static tag configuration and trigger an update\nTag Engine provides the API method `static_asset_tags` for creating static asset configurations. This method takes a JSON object as input and returns a job identifier. The following steps show how to create a static configuration with the data governance tag template.\n- In Cloud Shell, Edit the file [examples/static_asset_configs/static_asset_create_ondemand_bq.json](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/blob/main/examples/static_asset_configs/static_asset_create_ondemand_bq.json) . Replace the following values:- `template_project`: Your Tag Engine project ID\n- `template_region`:`us-central1`\n- `included_assets_uris`: The BigQuery project URIs\n- Make an API call to create a static configuration:```\nRESPONSE_JSON=$(curl -X POST ${TAG_ENGINE_URL}/static_asset_tags -d @examples/static_asset_configs/static_asset_create_ondemand_bq.json)JOB_ID=$(echo ${RESPONSE_JSON} | jq -r \".job_uuid\")echo \"Job ID: ${JOB_ID}\"\n```\nIf the request was successful, the API method returns a job identifier. If the request wasn't successful, the output details the error.\n- (Optional) Find additional details in the App Engine logs by running the following command:```\ngcloud app logs tail -s default\n```\n- To request the status of the job, use the job identifier from the previous step:```\ncurl -X POST ${TAG_ENGINE_URL}/get_job_status \\-d \"{\\\"job_uuid\\\":\\\"${JOB_ID}\\\"}\"\n```The output resembles the following:```\n {\"job_status\":\"RUNNING\",\"success\":true,\"task_count\":3,\"tasks_completed\":0,\"tasks_failed\":0,\"tasks_ran\":0}\n```## Perform load testing\nTag Engine provides various utilities and examples for load testing its bulk tagging capabilities. The `load_testing` folder contains Python scripts for cloning and loading BigQuery tables. The `*_standalone.py` scripts in this folder run on a single machine and create BigQuery tables in sequential order. The `*_distributed.py` scripts in the same folder create BigQuery tables in parallel, using Cloud Tasks and Cloud Functions. There's also a `check_tags.py` script which verifies the number of tagged assets in a BigQuery dataset.\nIn the `examples` directory, there are configuration request files in JSON for various batch sizes, both for static and dynamic types. The configs are based on the `cities_311` and `data_governance` tag templates used in this guide.\nThe following table provides a summary of the static example configs along with their average runtime:\n| Batch size   | Config file   | Runtime (HH:MM) |\n|:-------------------|:--------------------|:------------------|\n| 500 tag writes  | static create 500 | 00:01    |\n| 5000 tag writes | static create 5k | 00:06    |\n| 50,000 tag writes | static create 50k | 01:02    |\n| 500,000 tag writes | static create 500k | 14:17    |\nBecause of the additional processing involved when querying BigQuery, dynamic configurations generally have both a greater runtime and higher cost than static configurations for the same batch size.\n## Create a coverage report\nTag Engine provides a report that summarizes the Data Catalog tags across your data estate. The report displays a listing of each data asset and the number of tags on it. You can configure the report to include multiple projects. You can also configure the report to exclude certain datasets and tables from a project. Use the following steps to configure a coverage report.\n- On the Tag Engine home page, click **Configure Coverage Report** .By default, all datasets within a project are included in the report. If you would like to exclude certain datasets and tables from the report, specify them in the corresponding field. Save the coverage report settings.\n- Fill out the project details in the **Coverage Report Settings** page and then click **Save** .\n- Click **Coverage Report** . The report changes to reflect the number of tags on each asset.For example, if you created the dynamic table configuration on the `cities_311` template and the static asset configuration on the `data_governance` template, you see two tags on each of the three BigQuery tables, as shown in the following screenshot: ## What's next\n- [Tag Engine code repo](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine) \n- [Tag Engine on Cloud Run](https://github.com/GoogleCloudPlatform/datacatalog-tag-engine/tree/cloud-run) \n- [View sample tag templates](https://github.com/GoogleCloudPlatform/datacatalog-templates) \n- [Create tag templates](https://github.com/GoogleCloudPlatform/datacatalog-templates/blob/master/create_template.py) \n- [Evolve tag templates](https://github.com/GoogleCloudPlatform/datacatalog-templates/blob/master/evolve_template.py)", "guide": "Docs"}