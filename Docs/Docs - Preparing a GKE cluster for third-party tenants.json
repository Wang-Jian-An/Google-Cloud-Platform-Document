{"title": "Docs - Preparing a GKE cluster for third-party tenants", "url": "https://cloud.google.com/architecture/preparing-gke-cluster-apps-distributed-third-party", "abstract": "# Docs - Preparing a GKE cluster for third-party tenants\nLast reviewed 2022-02-10 UTC\nThis document suggests controls that you can use to help configure and secure [Google Kubernetes Engine (GKE)](/kubernetes-engine) clusters that host custom apps distributed by third-party tenants. It's part of a blueprint solution which is made up of the following:\n- A guide to the controls that you implement (this document).\n- A [GitHub repository](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint) that contains the following directories:- [terraform](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint/blob/main/terraform) : contains the Terraform code that you use to create the project-level infrastructure and resources. This code also installs GKE Enterprise components into the cluster.\n- [configsync](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint/blob/main/configsync) : contains the cluster-level resources and configurations that are applied to your GKE cluster.\n- [tenant-config-pkg](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint/blob/main/tenant-config-pkg) : a [kpt](https://kpt.dev/?id=overview) package that you can use as a template to configure new tenants in the GKE cluster.This document is intended for teams that administer GKE clusters. It assumes that you are familiar with GKE and [Kubernetes](https://kubernetes.io/) .\nThis document assumes that you have already configured a foundational set of security controls to protect your cloud infrastructure, such as the controls described in the [Google Cloud enterprise foundations blueprint](/architecture/security-foundations) . The blueprint helps you layer additional controls onto your existing security controls to help to protect your GKE clusters.\n", "content": "## Architecture\nThe following diagram describes the architecture that you create with this blueprint:\nAs shown in the preceding diagram, the blueprint helps you to create and configure the following infrastructure components:\n- A [Virtual Private Cloud (VPC) network](/vpc/docs/vpc) and subnet.\n- A [private GKE cluster](/kubernetes-engine/docs/concepts/private-cluster-concept) . The cluster nodes are isolated from the internet.\n- Two GKE [node pools](/kubernetes-engine/docs/concepts/node-pools) . You create a dedicated node pool to exclusively host tenant apps and resources. Other cluster resources are hosted in the default node pool.\n- [VPC firewall rules](/vpc/docs/firewalls) . You create baseline rules that apply to all nodes in the cluster. You create additional rules that apply only to the nodes in the tenant node-pool. These firewall rules limit egress from the tenant nodes.\n- [Cloud NAT](/nat/docs/overview) to allow egress from the cluster nodes to the internet.\n- [Cloud DNS](/dns/docs/overview) rules configured to enable [Private Google Access](/vpc/docs/private-google-access) such that apps within the cluster can access Google APIs without traversing the internet.\n- [Service Accounts](/iam/docs/understanding-service-accounts) used by the cluster nodes and apps.\n### Applications\nThe following diagram shows the cluster-level resources that you create and configure with the blueprint.\nAs shown in the preceding diagram, in the blueprint, you use the following to create and configure the cluster-level resources:\n- [Config Sync](/anthos-config-management/docs/config-sync-overview) to sync cluster configuration and policies from a Git repository.\n- [Policy Controller](/anthos-config-management/docs/concepts/policy-controller) to enforce policies on resources in the cluster.\n- [Anthos Service Mesh](/service-mesh/docs/overview) to control and help secure network traffic.\n- A dedicated namespace for tenant apps and resources.\n- Policies and controls applied to the tenant namespace, including network policies and service mesh policies.## Understanding the security controls that you need\nThis section discusses the controls that you apply with the blueprint to help you secure your GKE cluster.\n### Enhanced security of GKE clusters\nThe blueprint helps you create a GKE cluster which implements the following security settings:\n- Limit exposure of your cluster nodes and control plane to the internet by creating a [private GKE cluster](/kubernetes-engine/docs/concepts/private-cluster-concept) with [authorized networks](/kubernetes-engine/docs/concepts/private-cluster-concept#overview) .\n- Use [shielded nodes](/kubernetes-engine/docs/how-to/shielded-gke-nodes) that use a hardened node image with the [containerd](/kubernetes-engine/docs/concepts/using-containerd) runtime.\n- Increased isolation of tenant workloads using [GKE Sandbox](/kubernetes-engine/docs/concepts/sandbox-pods) .\n- [Encrypt cluster secrets](/kubernetes-engine/docs/how-to/encrypting-secrets) at the application layer.\nFor more information about GKE security settings, refer to [Hardening your cluster's security](/kubernetes-engine/docs/how-to/hardening-your-cluster) .\n### VPC firewall rules\n[Virtual Private Cloud (VPC) firewall rules](/vpc/docs/firewalls) govern which traffic is allowed to or from Compute Engine VMs. The rules let you filter traffic at VM granularity, depending on [Layer 4](https://wikipedia.org/wiki/Transport_layer) attributes.\nYou create a GKE cluster with the [default GKE cluster firewall rules](/kubernetes-engine/docs/concepts/firewall-rules#cluster-fws) . These firewall rules enable communication between the cluster nodes and GKE control plane, and between nodes and Pods in the cluster.\nYou apply additional firewall rules to the nodes in the tenant node pool. These firewall rules restrict egress traffic from the tenant nodes. This approach lets you increase the isolation of the tenant nodes. By default, all egress traffic from the tenant nodes is denied. Any required egress must be explicitly configured. For example, you use the blueprint to create firewall rules to allow egress from the tenant nodes to the GKE control plane, and to Google APIs using [Private Google Access](/vpc/docs/private-google-access) . The firewall rules are targeted to the tenant nodes using the tenant node pool [service account](/vpc/docs/firewalls#service-accounts-vs-tags) .\n### Namespaces\nNamespaces let you provide a scope for related resources within a cluster\u2014for example, Pods, Services, and replication controllers. By using namespaces, you can delegate administration responsibility for the related resources as a unit. Therefore, namespaces are integral to most security patterns.\nNamespaces are an important feature for control plane isolation. However, they don't provide node isolation, data plane isolation, or network isolation.\nA common approach is to create namespaces for individual applications. For example, you might create the namespace `myapp-frontend` for the UI component of an application.\nThe blueprint helps you create a dedicated namespace to host the third-party apps. The namespace and its resources are treated as a tenant within your cluster. You apply policies and controls to the namespace to limit the scope of resources in the namespace.\n### Network policies\n[Network policies](https://kubernetes.io/docs/concepts/services-networking/network-policies/) enforce Layer 4 network traffic flows by using Pod-level firewall rules. Network policies are [scoped to a namespace](/anthos-config-management/docs/how-to/configs#network-policy-config) .\nIn the blueprint, you apply network policies to the tenant namespace that hosts the third-party apps. By default, the network policy denies all traffic to and from pods in the namespace. Any required traffic must be explicitly allowlisted. For example, the network policies in the blueprint explicitly allow traffic to required cluster services, such as the cluster internal DNS and the Anthos Service Mesh control plane.\n### Config Sync\n[Config Sync](/anthos-config-management/docs/config-sync-overview) keeps your GKE clusters in sync with configs stored in a Git [repository](/anthos-config-management/docs/how-to/repo) . The Git repository acts as the single source of truth for your cluster configuration and policies. Config Sync is declarative. It continuously checks cluster state and applies the state declared in the configuration file in order to enforce policies, which helps to prevent [configuration drift](/anthos-config-management/docs/how-to/prevent-config-drift) .\nYou install Config Sync into your GKE cluster. You configure Config Sync to sync cluster configurations and policies from the GitHub repository associated with the blueprint. The synced resources include the following:\n- Cluster-level Anthos Service Mesh configuration\n- Cluster-level security policies\n- Tenant namespace-level configuration and policy including network policies, service accounts, RBAC rules, and Anthos Service Mesh configuration\n### Policy Controller\n[GKE Enterprise Policy Controller](/anthos-config-management/docs/concepts/policy-controller) is a [dynamic admission controller](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/) for Kubernetes that enforces [CustomResourceDefinition-based (CRD-based)](https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/) policies that are executed by the [Open Policy Agent (OPA)](https://www.openpolicyagent.org/) .\n[Admission controllers](https://kubernetes.io/blog/2019/03/21/a-guide-to-kubernetes-admission-controllers/) are Kubernetes plugins that intercept requests to the Kubernetes API server before an object is persisted, but after the request is authenticated and authorized. You can use admission controllers to limit how a cluster is used.\nYou install Policy Controller into your GKE cluster. The blueprint includes example policies to help secure your cluster. You automatically apply the policies to your cluster using Config Sync. You apply the following policies:\n- Selected policies to help [enforce Pod security](/anthos-config-management/docs/how-to/using-constraints-to-enforce-pod-security) . For example, you apply policies that prevent pods [running privileged containers](/anthos-config-management/docs/how-to/using-constraints-to-enforce-pod-security#prevent-privileged-containers) and that require a [read-only root file system](/anthos-config-management/docs/how-to/using-constraints-to-enforce-pod-security#require-readonly-rootfs) .\n- Policies from the Policy Controller [template library](/anthos-config-management/docs/latest/reference/constraint-template-library) . For example, you apply a policy that [disallows services with type NodePort](/anthos-config-management/docs/latest/reference/constraint-template-library#k8sblocknodeport) .\n### Anthos Service Mesh\n[Anthos Service Mesh](/service-mesh/docs/overview) helps you monitor and manage an [Istio](https://istio.io/docs/concepts/what-is-istio/) -based service mesh. A service mesh is an infrastructure layer that helps create managed, observable, and secure communication across your services.\nAnthos Service Mesh helps simplify the management of secure communications across services in the following ways:\n- Managing authentication and encryption of traffic ( [supported protocols](/service-mesh/docs/supported-features#protocol_support) within the cluster using [mutual Transport Layer Communication (mTLS)](/service-mesh/docs/security-overview#mutual_tls) ). Anthos Service Mesh manages the provisioning and rotation of mTLS keys and certificates for GKE Enterprise workloads without disrupting communications. Regularly rotating mTLS keys is a security best practice that helps reduce exposure in the event of an attack.\n- Letting you configure network security policies based on service identity rather than on the IP address of a peers on the network. Anthos Service Mesh is used to configure identity-aware access control (firewall) policies that let you create security policies that are independent of the network location of the workload. This approach simplifies the process of setting up service-to-service communications policies.\n- Letting you configure policies that permit access from certain clients.\nThe blueprint guides you to install Anthos Service Mesh in your cluster. You configure the tenant namespace for [automatic sidecar proxy injection](/service-mesh/docs/proxy-injection) . This approach ensures that apps in the tenant namespace are part of the mesh. You automatically configure Anthos Service Mesh using Config Sync. You configure the mesh to do the following:\n- Enforce [mTLS communication](/service-mesh/docs/security/configuring-mtls#enforcing_mesh-wide_mtls) between services in the mesh.\n- Limit outbound traffic from the mesh to only known hosts.\n- Limit [authorized communication](/service-mesh/docs/security/authorization-policy-overview) between services in the mesh. For example, apps in the tenant namespace are only allowed to communicate with apps in the same namespace, or with a set of known external hosts.\n- Route all outbound traffic through a mesh gateway where you can apply further traffic controls.\n### Node taints and affinities\n[Node taints](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/) and [node affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity) are Kubernetes mechanisms that let you influence how pods are scheduled onto cluster nodes.\nTainted nodes repel pods. Kubernetes will not schedule a Pod onto a tainted node unless the Pod has a for the taint. You can use node taints to reserve nodes for use only by certain workloads or tenants. Taints and tolerations are often used in multi-tenant clusters. See the [dedicated nodes with taints and tolerations](/kubernetes-engine/docs/concepts/multitenancy-overview#dedicated_nodes_with_taints_and_tolerations) documentation for more information.\nNode affinity lets you constrain pods to nodes with particular labels. If a pod has a node affinity requirement, Kubernetes will not schedule the Pod onto a node unless the node has a label that matches the affinity requirement. You can use node affinity to ensure that pods are scheduled onto appropriate nodes.\nYou can use node taints and node affinity together to ensure tenant workload pods are scheduled exclusively onto nodes reserved for the tenant.\nThe blueprint helps you control the scheduling of the tenant apps in the following ways:\n- Creating a GKE node pool dedicated to the tenant. Each node in the pool has a taint related to the tenant name.\n- Automatically applying the appropriate toleration and node affinity to any Pod targeting the tenant namespace. You apply the toleration and affinity using [PolicyController mutations](/anthos-config-management/docs/how-to/mutation) .\n### Least privilege\nIt is a security best practice to adopt a principle of least privilege for your Google Cloud projects and resources like GKE clusters. This way, the apps that run inside your cluster, and the developers and operators that use the cluster, have only the minimum set of permissions required.\nThe blueprint helps you use least privilege service accounts in the following ways:\n- Each GKE node pool receives its own service account. For example, the nodes in the tenant node pool use a service account dedicated to those nodes. The node service accounts are configured with the [minimum required permissions](/kubernetes-engine/docs/how-to/hardening-your-cluster#use_least_privilege_sa) .\n- The cluster uses [Workload Identity](/kubernetes-engine/docs/how-to/workload-identity) to associate Kubernetes service accounts with Google service accounts. This way, the tenant apps can be granted limited access to any required Google APIs without downloading and storing a service account key. For example, you can grant the service account permissions to read data from a Cloud Storage bucket.\nThe blueprint helps you [restrict access to cluster resources](/kubernetes-engine/docs/how-to/hardening-your-cluster#use_namespaces_and_rbac_to_restrict_access_to_cluster_resources) in the following ways:\n- You create a sample Kubernetes RBAC role with limited permissions to manage apps. You can grant this role to the users and groups who operate the apps in the tenant namespace. This way, those users only have permissions to modify app resources in the tenant namespace. They do not have permissions to modify cluster-level resources or sensitive security settings like Anthos Service Mesh policies.## Bringing it all together\nTo implement the [architecture](#architecture) described in this document, do the following:\n- Determine whether you will deploy the blueprint in tandem with the enterprise foundations blueprint, or without it. If you choose not to deploy the enterprise foundations blueprint, ensure that your environment has a similar security baseline in place.\n- Review the [Readme](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint/blob/main/README.md) for the blueprint and ensure that you meet all the prerequisites.\n- In your testing environment, deploy one instance of this architecture. As part of your testing process, do the following:- [Deploy an example tenant service and verify the configuration of the cluster](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint/tree/main/testing) .\n- [Add another tenant to the cluster](https://github.com/GoogleCloudPlatform/gke-securing-third-party-apps-blueprint#add-another-tenant) .\n- Deploy the blueprint into your production environment.\n- Add more tenants to the cluster.## What's next\n- Read the [Google Cloud enterprise foundations blueprint](/architecture/security-foundations) \n- Read the [GKE hardening guide](/kubernetes-engine/docs/how-to/hardening-your-cluster) \n- Read about [Federated learning on Google Cloud](/architecture/federated-learning-google-cloud) \n- Learn about [best practices for using Anthos Service Mesh egress gateways on GKE](/service-mesh/docs/security/egress-gateways-best-practices)", "guide": "Docs"}