{"title": "Docs - Optimize database performance", "url": "https://cloud.google.com/architecture/framework/performance-optimization/databases", "abstract": "# Docs - Optimize database performance\nLast reviewed 2023-08-06 UTC\nThis document in the [Google Cloud Architecture Framework](/architecture/framework) provides recommendations to help you optimize the performance of your databases in Google Cloud.\n", "content": "## Cloud SQL\nThe following recommendations help you to optimize the performance of your [Cloud SQL](/sql) instances running SQL Server, MySQL, and PostgreSQL databases.\n- For SQL Server databases, Google recommends that you [modify certain parameters](/sql/docs/sqlserver/best-practices#sqlserver_settings_modify) and [retain the default values for some parameters](/sql/docs/sqlserver/best-practices#sqlserver_settings_retain) .\n- When you choose the storage type for MySQL or PostgreSQL databases, consider the [cost-performance tradeoff between SSD and HDD storage](/sql/docs/mysql/choosing-ssd-hdd) .\n- To identify and analyze performance issues with PostgreSQL databases, use the [Cloud SQL Insights](/sql/docs/postgres/using-query-insights) dashboard.\n- To diagnose poor performance when running SQL queries, use the [EXPLAIN](/sql/docs/mysql/diagnose-issues#tips) statement.\nFor more information, see the following documentation:\n- [Optimize performance: SQL Server](/sql/docs/sqlserver/diagnose-issues#performance) \n- [Optimize performance: MySQL](/sql/docs/mysql/diagnose-issues#performance) \n- [Optimize performance: PostgreSQL](/sql/docs/postgres/diagnose-issues#performance) ## Bigtable\nThis section provides recommendations to help you optimize the performance of your [Bigtable](/bigtable/docs/overview) instances.\n### Plan capacity based on performance requirements\nYou can use Bigtable in a broad spectrum of applications, each with a different optimization goal. For example, for batch data-processing jobs, throughput might be more important than latency. For an online service that serves user requests, you might need to prioritize lower latency over throughput. When you plan capacity for your Bigtable clusters, consider the tradeoffs between throughput and latency. For more information, see [Plan your Bigtable capacity](/bigtable/docs/performance#planning-your-capacity) .\n### Follow schema-design best practices\nYour tables can scale to billions of rows and thousands of columns, enabling you to store petabytes of data. When you design the schema for your Bigtable tables, consider the [schema design best practices](/bigtable/docs/schema-design) .\n### Monitor performance and make adjustments\n[Monitor](/bigtable/docs/monitoring-instance) the CPU and disk usage for your instances, analyze the performance of each cluster, and review the sizing recommendations that are shown in the monitoring charts.\n## Spanner\nThis section provides recommendations to help you optimize the performance of your [Spanner](/spanner) instances.\n### Choose a primary key that prevents a hotspot\nA hotspot is a single server that is forced to handle many requests. When you choose the primary key for your database, follow the [schema design best practices](/spanner/docs/schema-design) to prevent a hotspot.\n### Follow best practices for SQL coding\nThe SQL compiler in Spanner converts each declarative SQL statement that you write into an imperative [query execution plan](/spanner/docs/query-execution-plans) . Spanner uses the execution plan to run the SQL statement. When you construct SQL statements, follow [SQL best practices](/spanner/docs/sql-best-practices) to make sure that Spanner uses execution plans that yield optimal performance.\n### Use query options to manage the SQL query optimizer\nSpanner uses a [SQL query optimizer](/spanner/docs/query-optimizer/overview) to transform SQL statements into efficient query execution plans. The query execution plan that the optimizer produces might change slightly when the query optimizer itself evolves, or when the database statistics are updated. You can minimize the potential for performance regression when the query optimizer or the database statistics change by using [query options](/spanner/docs/query-optimizer/manage-query-optimizer) .\n### Visualize and tune the structure of query execution plans\nTo analyze query performance issues, you can visualize and tune the structure of the query execution plans by using the [query plan visualizer](/spanner/docs/tune-query-with-visualizer) .\n### Use operations APIs to manage long-running operations\nFor certain method calls, Spanner creates long-running operations, which might take a substantial amount of time to complete. For example, when you [restore a database](/spanner/docs/reference/rest/v1/projects.instances.databases/restore) , Spanner creates a long-running operation to track restore progress. To help you monitor and manage long-running operations, Spanner provides operations APIs. For more information, see [Managing long-running operations](/spanner/docs/manage-long-running-operations) .\n### Follow best practices for bulk loading\nSpanner supports several options for loading large amounts of data in bulk. The performance of a bulk-load operation depends on factors such as partitioning, the number of write requests, and the size of each request. To load large amounts of data efficiently, follow [bulk-loading best practices](/spanner/docs/bulk-loading) .\n### Monitor and control CPU utilization\nThe CPU utilization of your Spanner instance can affect request latencies. An overloaded backend server can cause higher request latencies. Spanner provides [CPU utilization metrics](/spanner/docs/cpu-utilization) to help you [investigate high CPU utilization](/spanner/docs/introspection/investigate-cpu-utilization) . For performance-sensitive applications, you might need to r [educe CPU utilization by increasing the compute capacity](/spanner/docs/cpu-utilization#reduce) .\n### Analyze and solve latency issues\nWhen a client makes a remote procedure call to Spanner, the API request is first prepared by the client libraries. The request then passes through the [Google Front End](/docs/security/infrastructure/design#google-frontend-service) and the Cloud Spanner API frontend before it reaches the Spanner database. To analyze and solve latency issues, you must [measure and analyze the latency](/spanner/docs/latency-metrics) for each segment of the path that the API request traverses. For more information, see [Spanner end-to-end latency guide](/spanner/docs/latency-guide) .\n### Launch applications after the database reaches the warm state\nAs your Spanner database grows, it divides the key space of your data into [splits](/spanner/docs/schema-and-data-model#database-splits) . Each split is a range of rows that contains a subset of your table. To balance the overall load on the database, Spanner dynamically moves individual splits independently and assigns them to different servers. When the splits are distributed across multiple servers, the database is considered to be in a state. A database that's warm can maximize parallelism and deliver improved performance. Before you launch your applications, we recommend that you [warm up your database](/spanner/docs/pre-warm-database) with test data loads.\n## What's next\nReview the best practices for optimizing the performance of your compute, storage, networking, and analytics resources:\n- [Optimize compute performance](/architecture/framework/performance-optimization/compute) .\n- [Optimize storage performance](/architecture/framework/performance-optimization/storage) .\n- [Optimize networking performance](/architecture/framework/performance-optimization/networking) .\n- [Optimize analytics performance](/architecture/framework/performance-optimization/analytics) .", "guide": "Docs"}