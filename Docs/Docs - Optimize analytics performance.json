{"title": "Docs - Optimize analytics performance", "url": "https://cloud.google.com/architecture/framework/performance-optimization/analytics", "abstract": "# Docs - Optimize analytics performance\nLast reviewed 2023-08-04 UTC\nThis document in the [Google Cloud Architecture Framework](/architecture/framework) provides recommendations to help you optimize the performance of your analytics workloads in Google Cloud.\n", "content": "## BigQuery\nThis section provides recommendations to help you optimize the performance of queries in [BigQuery](/bigquery) .\n### Optimize query design\nQuery performance depends on factors like the number of bytes that your queries read and write, and the volume of data that's passed between [slots](/bigquery/docs/slots) . To optimize the performance of your queries in BigQuery, apply the best practices that are described in the following documentation:\n- [Introduction to optimizing query performance](/bigquery/docs/best-practices-performance-overview) \n- [Managing input data and data sources](/bigquery/docs/best-practices-performance-input) \n- [Optimizing communication between slots](/bigquery/docs/best-practices-performance-communication) \n- [Optimize query computation](/bigquery/docs/best-practices-performance-compute) \n- [Manage query outputs](/bigquery/docs/best-practices-performance-output) \n- [Avoiding SQL anti-patterns](/bigquery/docs/best-practices-performance-patterns) \n### Define and use materialized views efficiently\nTo improve the performance of workloads that use common and repeated queries, you can use [materialized views](/bigquery/docs/materialized-views-intro) . There are [limits](/bigquery/docs/materialized-views-intro#limitations) to the number of materialized views that you can create. Don't create a separate materialized view for every permutation of a query. Instead, define materialized views that you can use for multiple patterns of queries.\n### Improve JOIN performance\nYou can use [materialized views](/bigquery/docs/materialized-views-intro) to reduce the cost and latency of a query that performs aggregation on top of a [JOIN](/bigquery/docs/reference/standard-sql/query-syntax#join_types) . Consider a case where you join a large fact table with a few small dimension tables, and then perform an [aggregation](/bigquery/docs/reference/standard-sql/aggregate-function-calls) on top of the join. It might be practical to rewrite the query to first perform the aggregation on top of the fact table with foreign keys as grouping keys. Then, join the result with the dimension tables. Finally, perform a post-aggregation.\n## Dataflow\nThis section provides recommendations to help you optimize query performance of your [Dataflow](/dataflow) pipelines.\nWhen you create and deploy pipelines, you can configure execution parameters, like the Compute Engine machine type that should be used for the Dataflow worker VMs. For more information, see [Pipeline options](/dataflow/docs/reference/pipeline-options) .\nAfter you deploy pipelines, Dataflow manages the Compute Engine and Cloud Storage resources that are necessary to run your jobs. In addition, the following features of Dataflow help optimize the performance of the pipelines:\n- **Parallelization** : Dataflow automatically partitions your data and distributes your worker code to Compute Engine instances for parallel processing. For more information, see [parallelization and distribution](/dataflow/docs/guides/deploying-a-pipeline#parallelization-and-distribution) .\n- **Optimization** : Dataflow uses your pipeline code to create an execution graph that represents [PCollection](https://beam.apache.org/documentation/programming-guide/#pcollections) objects and [transforms](https://beam.apache.org/documentation/programming-guide/#transforms) in the pipeline. It then optimizes the graph for the most efficient performance and resource usage. Dataflow also automatically optimizes potentially costly operations, such as data aggregations. For more information, see [Fusion optimization](/dataflow/docs/guides/deploying-a-pipeline#fusion-optimization) and [Combine optimization](/dataflow/docs/guides/deploying-a-pipeline#combine-optimization) .\n- **Automatic tuning** : Dataflow dynamically optimizes jobs while they are running by using [Horizontal Autoscaling](/dataflow/docs/guides/deploying-a-pipeline#horizontal-autoscaling) , [Vertical Autoscaling](/dataflow/docs/guides/deploying-a-pipeline#vertical-autoscaling) , and [Dynamic Work Rebalancing](/dataflow/docs/guides/deploying-a-pipeline#dynamic-work-rebalancing) .\nYou can monitor the performance of Dataflow pipelines by using the web-based [monitoring interface](/dataflow/docs/guides/using-monitoring-intf) or the [Dataflow gcloud CLI](/dataflow/docs/guides/using-command-line-intf) .\n**Note:** You can also use Cloud Profiler to identify the parts of the pipeline code that consume the most resources. For more information, see [Monitoring pipeline performance](/dataflow/docs/guides/profiling-a-pipeline) .\n## Dataproc\nThis section describes best practices to optimize the performance of your [Dataproc](/dataproc) clusters.\n### Autoscale clusters\nTo ensure that your Dataproc clusters deliver predictable performance, you can enable autoscaling. Dataproc uses [Hadoop YARN memory metrics](/dataproc/docs/concepts/configuring-clusters/autoscaling#hadoop_yarn_metrics) and an autoscaling policy that you define to automatically adjust the number of worker VMs in a cluster. For more information about how to use and configure autoscaling, see [Autoscaling clusters](/dataproc/docs/concepts/configuring-clusters/autoscaling) .\n### Provision appropriate storage\nChoose an appropriate storage option for your Dataproc cluster based on your performance and cost requirements:\n- If you need a low-cost Hadoop-compatible file system (HCFS) that Hadoop and Spark jobs can read from and write to with minimal changes, use Cloud Storage. The data stored in Cloud Storage is persistent, and can be accessed by other Dataproc clusters and other products such as BigQuery.\n- If you need a low-latency [Hadoop Distributed File System (HDFS)](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html) for your Dataproc cluster, use Compute Engine persistent disks attached to the worker nodes. The data stored in HDFS storage is transient, and the storage cost is higher than the Cloud Storage option.\n- To get the performance advantage of Compute Engine persistent disks and the cost and durability benefits of Cloud Storage, you can combine both of the storage options. For example, you can store your source and final datasets in Cloud Storage, and provision limited HDFS capacity for the intermediate datasets. When you decide on the size and type of the disks for HDFS storage, consider the recommendations in the [Persistent disks and local SSDs](/architecture/framework/performance-optimization/storage#persistent-disks-and-local-ssds) section.\n### Reduce latency when using Cloud Storage\nTo reduce latency when you access data that's stored in Cloud Storage, we recommend the following:\n- Create your Cloud Storage bucket in the same region as the Dataproc cluster.\n- Disable`auto.purge`for Apache Hive-managed tables stored in Cloud Storage.\n- When using Spark SQL, consider creating Dataproc clusters with the latest versions of available [images](/dataproc/docs/concepts/versioning) . By using the latest version, you can avoid performance issues that might remain in older versions, such as [slow INSERT OVERWRITE performance](https://issues.apache.org/jira/browse/SPARK-18107) in Spark 2.x.\n- To minimize the possibility of writing many files with varying or small sizes to Cloud Storage, you can configure the [Spark SQL parameters](/dataproc/docs/concepts/configuring-clusters/flex#advanced_configuration) `spark.sql.shuffle.partitions`and`spark.default.parallelism`or the Hadoop parameter`mapreduce.job.reduces`.\n### Monitor and adjust storage load and capacity\nThe persistent disks attached to the worker nodes in a Dataproc cluster hold [shuffle](/dataproc/docs/support/spark-job-tuning#configure_partitioning_and_shuffling) data. To perform optimally, the worker nodes need sufficient disk space. If the nodes don't have sufficient disk space, the nodes are marked as `UNHEALTHY` in the [YARN NodeManager](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/NodeManager.html) log. If this issue occurs, either increase the disk size for the affected nodes, or run fewer jobs concurrently.\n### Enable EFM\nWhen worker nodes are removed from a running Dataproc cluster, such as due to downscaling or preemption, shuffle data might be lost. To minimize job delays in such scenarios, we recommend that you enable [Enhanced Flexibility Mode (EFM)](/dataproc/docs/concepts/configuring-clusters/flex) for clusters that use [preemptible VMs](/dataproc/docs/concepts/compute/preemptible-vms) or that only autoscale the secondary worker group.\n## What's next\nReview the best practices for optimizing the performance of your compute, storage, networking, and database resources:\n- [Optimize compute performance](/architecture/framework/performance-optimization/compute) .\n- [Optimize storage performance](/architecture/framework/performance-optimization/storage) .\n- [Optimize networking performance](/architecture/framework/performance-optimization/networking) .\n- [Optimize database performance](/architecture/framework/performance-optimization/databases) .", "guide": "Docs"}