{"title": "Docs - Geospatial analytics architecture", "url": "https://cloud.google.com/architecture/geospatial-analytics-architecture", "abstract": "# Docs - Geospatial analytics architecture\nLast reviewed 2021-10-18 UTC\nThis document helps you understand Google Cloud geospatial capabilities and how you can use these capabilities in your geospatial analytics applications. This document is intended for geographic information systems (GIS) professionals, data scientists, and application developers who want to learn how to use the products and services available in Google Cloud to deliver geospatial insights to business stakeholders.\n", "content": "## Overview\nGoogle Cloud provides a comprehensive suite of geospatial analytics and machine learning capabilities that can help you develop insights to understand more about the world, your environment, and your business. Geospatial insights that you get from these Google Cloud capabilities can help you make more accurate and sustainable business decisions without the complexity and expense of managing traditional GIS infrastructure.\n## Geospatial analytics use cases\nMany critical business decisions revolve around location data. Insights gleaned from geospatial analytics are applicable across a number of industries, businesses, and markets, as described in the following examples:\n- **Assessing environmental risk.** Understand the risks posed by environmental conditions by predicting natural disasters like flooding and wildfires, which can help you more effectively anticipate risk and plan for it.\n- **Optimizing site selection.** Combine proprietary site metrics with publicly available data like traffic patterns and geographic mobility, and then use geospatial analytics to find the optimum locations for your business and to predict financial outcomes.\n- **Planning logistics and transport.** Better manage fleet operations such as last-mile logistics, analyze data from autonomous vehicles, manage precision railroading, and improve mobility planning by incorporating geospatial data into business decision-making.\n- **Understanding and improving soil health and yield.** Analyze millions of acres of land to understand soil characteristics and help farmers analyze the interactions among variables that affect crop production.\n- **Managing sustainable development.** Map economic, environmental, and social conditions to determine focus areas for protecting and preserving the environment.## Geospatial cloud building blocks\nYour geospatial analytics architecture can consist of one or more geospatial cloud components, depending on your use case and requirements. Each component provides different capabilities, and these components work together to form a unified, scalable geospatial cloud analytics architecture.\nData is the raw material for delivering geospatial insights. Quality geospatial data is available from a number of public and proprietary sources. Public data sources include [BigQuery public datasets](/bigquery/public-data) , the [Earth Engine catalog](https://developers.google.com/earth-engine/datasets) , and the [United States Geological Survey (USGS)](https://www.usgs.gov/products/data) . Proprietary data sources include internal systems such as SAP and Oracle, and internal GIS tooling such as [Esri ArcGIS Server](https://enterprise.arcgis.com/en/server/) , Carto, and QGIS. You can aggregate data from multiple business systems, such as inventory management, marketing analytics, and supply chain logistics, and then combine that data with geospatial source data and send the results to your geospatial data warehouse.\nDepending on a source's data type and destination, you might be able to load geospatial data sources directly into your analytics data warehouse. For example, BigQuery has [built-in support for loading newline-delimited GeoJSON files](/bigquery/docs/geospatial-data#geojson-files) , and Earth Engine has an [integrated data catalog](https://developers.google.com/earth-engine/datasets) with a comprehensive collection of analysis-ready datasets. You can load other data in other formats through a geospatial data pipeline that preprocesses the geospatial data and loads it into your enterprise data warehouse in Google Cloud. You can [build production-ready data pipelines using Dataflow](/architecture/building-production-ready-data-pipelines-using-dataflow-deploying) . Alternatively, you can use a partner solution such as [FME Spatial ETL](https://www.safe.com/fme/key-capabilities/spatial-etl/) .\nThe enterprise data warehouse is the core of your geospatial analytics platform. After geospatial data is loaded into your data warehouse, you can start building geospatial applications and insights by using some of the following capabilities:\n- The machine learning capabilities that are available in [BigQuery ML](/bigquery-ml/docs) and [Vertex AI](/vertex-ai) .\n- Reporting and business intelligence tools like [BigQuery GeoViz](/bigquery/docs/geospatial-visualize#geo_viz) , [Looker Studio](/bigquery/docs/geospatial-visualize#data_studio) , and [Looker](https://docs.looker.com/exploring-data/visualizing-query-results/interactive-map-options) .\n- The API services that are available in Google Cloud such as Apigee.\n- The [geospatial query and analysis capabilities available in BigQuery](/bigquery/docs/geospatial-data) .\n- The [SQL geography functions in BigQuery](/bigquery/docs/reference/standard-sql/geography_functions) , which let you perform geospatial computations and queries.\n- The [machine learning capabilities built into Earth Engine](https://developers.google.com/earth-engine/guides/machine-learning) .\nYour architecture then serves as a single system that you can use to store, process, and manage data at scale. The architecture also lets you build and deploy advanced analytics solutions that can produce insights that are not feasible on systems that don't include these features.\n## Geospatial data types, formats, and coordinate systems\nTo aggregate your geospatial data into a data warehouse like BigQuery, you must understand the geospatial data formats that you're likely to encounter in internal systems and from public sources.\n### Data types\nGeospatial data types fall into two categories: vector and raster.\nVector data is composed of vertices and line segments, as shown in the following diagram.\nExamples of vector data include parcel boundaries, public rights-of-way (roads), and asset locations. Because vector data can be stored in a tabular (row and column) format, geospatial databases such as BigQuery and [PostGIS in Cloud SQL](/sql/docs/postgres/extensions#postgis) excel at storing, indexing, and analyzing vector data.\nRaster data is composed of grids of pixels. Examples of raster data include atmospheric measurements and satellite imagery, as shown in the following examples.\nEarth Engine is designed for planetary-scale storage and analysis of raster data. Earth Engine includes the [ability to vectorize rasters](https://developers.google.com/earth-engine/guides/reducers_reduce_to_vectors) , which can help you classify regions and understand patterns in raster data. For example, by analyzing atmospheric raster data over time, you can extract vectors that represent prevailing wind currents. You can load each individual raster pixel into BigQuery by using a process called [polygonization](https://github.com/GoogleCloudPlatform/dataflow-geobeam#polygonize-raster) , which converts each pixel directly to a vector shape.\nGeospatial cloud applications often combine both types of data to produce holistic insights that leverage the strengths of data sources from each category. For example, a real-estate application that helps identify new development sites might combine vector data such as parcel boundaries with raster data such as elevation data to minimize flood risk and insurance costs.\n### Data formats\nThe following table lists popular geospatial data formats and ways in which they can be used in your analytics platform.\n| Data source format | Description                          | Examples            |\n|:---------------------|:-----------------------------------------------------------------------------------------------------------------|:--------------------------------------------------------|\n| Shapefile   | A vector data format that was developed by Esri. It lets you store geometric locations and associate attributes. | Census tract geometries, building footprints   |\n| WKT     | A human-readable vector data format that's published by OGC. Support for this format is built into BigQuery.  | Representation of geometries in CSV files    |\n| WKB     | A storage-efficient binary equivalent of WKT. Support for this format is built into BigQuery.     | Representation of geometries in CSV files and databases |\n| KML     | An XML-compatible vector format used by Google Earth and other desktop tools. The format is published by OGC. | 3D building shapes, roads, land features    |\n| Geojson    | An open vector data format that's based on JSON.                 | Features in web browsers and mobile applications  |\n| GeoTIFF    | A widely used raster data format. This format lets you map pixels in a TIFF image to geographic coordinates.  | Digital elevation models, Landsat      |\n### Coordinate reference systems\nAll geospatial data, regardless of type and format, includes a [coordinate reference system](https://wikipedia.org/wiki/Spatial_reference_system) that lets geospatial analytics tools such as BigQuery and Earth Engine associate coordinates with a physical location on the earth's surface. There are two basic types of coordinate reference systems: [geodesic and planar](https://developers.google.com/earth-engine/guides/geometries_planar_geodesic) .\nGeodesic data takes the curvature of the earth into account, and uses a coordinate system based on geographic coordinates (longitude and latitude). Geodesic shapes are commonly referred to as . The [WGS\u00a084](https://gisgeography.com/wgs84-world-geodetic-system/) coordinate reference system that's used by BigQuery is a geodesic coordinate system.\nPlanar data is based on a map projection such as [Mercator](https://wikipedia.org/wiki/Mercator_projection) that maps geographic coordinates to a two-dimensional plane. To load planar data into BigQuery, you need to reproject planar data into the WGS\u00a084 coordinate system. You can do this reprojection manually by using your existing GIS tooling, or by using a geospatial cloud data pipeline (see the next section).\n## Considerations for building a geospatial cloud data pipeline\nAs noted, you can load some geospatial data directly into BigQuery and Earth Engine, depending on data type. BigQuery [lets you load vector data](/bigquery/docs/geospatial-data#loading_geospatial_data) in the WKT, WKB, and GeoJSON file formats if the data [uses the WGS\u00a084 reference system](/bigquery/docs/geospatial-data#coordinate_systems_and_edges) . Earth Engine integrates directly with the data that's available in the Earth Engine catalog and [supports loading raster images directly](https://developers.google.com/earth-engine/guides/image_upload#geotiff) in the GeoTIFF file format.\nYou might encounter geospatial data that's stored in other formats and that can't be loaded directly into BigQuery. Or the data might be in a coordinate reference system that you must first reproject into the WGS\u00a084 reference system. Similarly, you might encounter data that needs to be preprocessed, simplified, and corrected for errors.\nYou can load preprocessed geospatial data into BigQuery by building geospatial data pipelines using [Dataflow](/dataflow) . Dataflow is a managed analytics service that supports streaming and batch processing of data at scale.\nYou can use the [geobeam](https://github.com/GoogleCloudPlatform/dataflow-geobeam) Python library that extends Apache Beam and adds geospatial processing capabilities to Dataflow. The library lets you read geospatial data from a variety of sources. The library also helps you process and transform the data and load it into BigQuery to use as your geospatial cloud data warehouse. The `geobeam` library is open source, so you can modify and extend it to support additional formats and preprocessing tasks.\nUsing Dataflow and the `geobeam` library, you can ingest and analyze massive amounts of geospatial data in parallel. The `geobeam` library works by implementing custom I/O connectors. The `geobeam` library includes [GDAL](https://gdal.org/) , [PROJ](https://proj.org/) , and other related libraries to make it easier to process geospatial data. For example, `geobeam` automatically reprojects all input geometries to the [WGS84 coordinate system used by BigQuery](/bigquery/docs/gis-data#coordinate_systems_and_edges) to store, cluster, and process spatial data.\nThe `geobeam` library follows Apache Beam design patterns, so your spatial pipelines work similar to non-spatial pipelines. The difference is that you use the `geobeam` custom [FileBasedSource](https://beam.apache.org/releases/pydoc/2.27.0/apache_beam.io.filebasedsource.html) classes to read from spatial source files. You can also use the built-in `geobeam` [transform functions](https://beam.apache.org/documentation/programming-guide/#applying-transforms) to process your spatial data and to implement your own functions.\nThe following example shows how you can create a pipeline that reads a raster file, [polygonizes the raster](https://gdal.org/programs/gdal_polygonize.html) , reprojects it to WGS\u00a084, and writes the polygons to BigQuery.\n```\nwith beam.Pipeline(options=pipeline_options) as p:\n (p\n | beam.io.Read(GeotiffSource(known_args.gcs_url))\n | 'MakeValid' >> beam.Map(geobeam.fn.make_valid)\n | 'FilterInvalid' >> beam.Filter(geobeam.fn.filter_invalid)\n | 'FormatRecords' >> beam.Map(geobeam.fn.format_record,\n  known_args.band_column, known_args.band_type)\n | 'WriteToBigQuery' >> beam.io.WriteToBigQuery('DATASET.TABLE'))\n```\n## Geospatial data analysis in BigQuery\nWhen the data is in BigQuery, you can transform, analyze, and model the data. For example, you can query the average elevation of a land parcel by [computing the intersection of those geographies](/bigquery/docs/reference/standard-sql/geography_functions#st_intersects) and joining the tables using [standard SQL](/bigquery/docs/reference/standard-sql/functions-and-operators) . BigQuery offers many [functions](/bigquery/docs/reference/standard-sql/geography_functions) that let you construct new geography values, compute the measurements of geographies, explore the relationship between two geographies, and more. You can do hierarchical geospatial indexing with S2 grid cells using BigQuery S2 functions. In addition, you can use the machine learning features of BigQuery ML to identify patterns in the data, such as [creating a k-means machine learning model to cluster geospatial data](/bigquery-ml/docs/kmeans-tutorial) .\n## Geospatial visualization, reports, and deployment\nGoogle Cloud provides several options for visualizing and reporting your spatial data and insights in order to deliver them to users and applications. The methods you use to represent your spatial insights depend on your business requirements and objectives. Not all spatial insights are represented graphically. Many insights are best delivered through an API service like [Apigee](/apigee) , or by saving them into an application database like [Firestore](https://firebase.google.com/) so that the insights can power features in your user-facing applications.\nWhile you're testing and prototyping your geospatial analyses, you can use [BigQuery GeoViz](/bigquery/docs/gis-visualize#geo_viz) as a way to validate your queries and to generate a visual output from BigQuery. For business intelligence reporting, you can use [Looker Studio](https://lookerstudio.google.com/c/u/0/) or [Looker](https://looker.com/) to connect to BigQuery and combine your geospatial visualizations with a wide variety of other report types in order to present a unified view of the insights you need.\nYou can also build applications that let your users interact with geospatial data and insights and incorporate those insights into your business applications. For example, by using the [Google Maps Platform](/maps-platform) , you can combine geospatial analytics, machine learning, and data from the [Maps API](https://developers.google.com/maps/documentation) into a single map-based application. By using open source libraries like [deck.gl](https://deck.gl/) , you can include [high-performance visualizations and animations](/blog/products/maps-platform/high-performance-data-visualizations-google-maps-platform-and-deckgl) to tell map-based stories and better represent your data.\nGoogle also has a robust and growing ecosystem of partner offerings that can help you make the most of your geospatial insights. [Carto](https://carto.com/) , [NGIS](https://ngis.com.au/) , [Climate Engine](http://climateengine.org/) , and others each have specialized capabilities and offerings that you can customize to your industry and business.\n## Reference architecture\nThe following diagram shows a reference architecture that illustrates how the geospatial cloud components interact. The architecture has two key components: the geospatial data pipeline and the geospatial analytics platform.\nAs the diagram shows, geospatial source data is loaded into Cloud Storage and Earth Engine. From either of these products, the data can be loaded through a Dataflow pipeline using `geobeam` to perform common preprocessing operations such as feature validation and geometry reprojection. Dataflow writes the pipeline output into BigQuery. When the data is in BigQuery, it can be analyzed in place using BigQuery analytics and machine learning, or it can be accessed by other services such as Looker Studio, Looker, Vertex AI, and Apigee.\n## What's next\n- [Getting started with geospatial analytics](/bigquery/docs/geospatial-intro) \n- [BigQuery geospatial tutorials](/bigquery/docs/geospatial-tutorial-hurricane) \n- [Earth Engine tutorials](https://developers.google.com/earth-engine/tutorials/tutorials) \n- [Geospatial analytics and AI](/solutions/geospatial)", "guide": "Docs"}