{"title": "Docs - Propensity modeling for gaming applications", "url": "https://cloud.google.com/architecture/propensity-modeling-gaming", "abstract": "# Docs - Propensity modeling for gaming applications\nLearn how to use BigQuery ML to train, evaluate, and get predictions from several different types of propensity models. Propensity models can help you to determine the likelihood of specific users returning to your app, so you can use that information in marketing decisions.\n", "content": "## Overview\nIf you are a mobile game developer, user retention is probably one of your challenges. According to the [Mobile Gaming Industry Analysis in 2019](https://gameanalytics.com/reports/mobile-gaming-industry-analysis-h1-2019) , most mobile games only see a 25% retention rate for users after the first day. To retain a larger percentage of users after that, you can take steps to motivate and incentivize those users who are most likely to return. But to target those users, you need to identify the propensity of any specific user returning after the first 24 hours. If you develop other types of online application that prioritize reducing audience churn, this approach should also work for you.\nTo implement the approach described in this article, use this [notebook](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/gaming/propensity-model/bqml/bqml_ga4_gaming_propensity_to_churn.ipynb) .\nThis article discusses a high-level approach to propensity modeling, including:\n- Preparing gaming data so it can be used to train a machine learning (ML) model\n- Choosing what type of propensity model to use\n- Training and evaluating the model\n- Getting predictions from the model\n- Exporting prediction data for use in marketing campaigns\n### Audience\nThe solution is intended for online application developers, especially mobile game developers. It assumes that you have basic knowledge of the following:\n- Machine learning concepts\n- Standard SQL## Sample dataset\nThe solution uses the public [firebase-public-project.analytics_153293282.events_20181003](https://console.cloud.google.com/bigquery?p=firebase-public-project&d=analytics_153293282&t=events_20181003&page=table) dataset. This dataset contains Google Analytics 4 (GA4) data from a real mobile game app called \"Flood It!\". This dataset contains 5.7 million events from over 15 thousand users.\nGA4 uses an [event-based](https://support.google.com/analytics/answer/9322688) measurement model. Each row in this dataset is a unique event, which contains nested fields for event parameters. To learn more about the structure of the data, see the [Schema for BigQuery Export](https://support.google.com/analytics/answer/7029846) .\n## Exporting Google Analytics data to BigQuery\nIf instead of the sample data, you want to use your own data from a GA4 property, you can follow the instructions in [(GA4) Set up BigQuery Export](https://support.google.com/analytics/answer/9823238) to export your data.\n## Processing the data\nYou must process the event data to get it into the right shape and format to use as training data. Processing the data accomplishes the following goals:\n- Filters out users who are unlikely to return to the app\n- Creates features for user demographic data\n- Creates features for user behavioral data\nHaving a combination of both demographic data and behavioral data helps to create a more predictive model.\nOnce processed, each row the training data represents the data for a unique user, identified by the `user_pseudo_id` column.\n### Labeling users\nTo process the data, start by labeling records to identify users who seem unlikely to return to the app. In this solution, you label records to categorize then based on the their interaction with the application.\nFirst, you filter out users who spent less than 10 mins using the app during their first visit. You label these users as **bounced** .\nYou then label the remaining users as either **churned** if they have no event data for the user after 24 hours of first [engaging](https://support.google.com/analytics/answer/9355853?hl=en) with the application, or as **returned** if they have at least one event record after 24 hours of first engaging with the app. The model uses these labels during training to learn how to identify the likelihood that a user will fall into one category or the other. You can then use the trained model to predict that likelihood for specific users.\nIf you have a different use case, you can use different criteria to identify bounced or churned customers. If you want to predict something other than audience churn, you can consider, for example:\n- Whether a user is likely to spend money on in-game currency\n- The likelihood of the user completinggame levels\n- The likelihood of the user spendingamount of time in-game\n### Processing demographic features\nThe next step in processing the data is to add features for user demographics. This solution uses the following fields as demographic features:\n- `geo.country`\n- `device.operating_system`\n- `device.language`\nHowever, you can choose different fields if those work better for your use case.\nA user might have multiple unique values in these fields. For example, if a user used the app from two different devices. To simplify, this solution uses the values from the first user engagement event.\n### Processing behavioral features\nThe final step in processing the data is to add features for user behavior.\nTo extract user behavior from the data, the solution analyzes each user's activities in the first 24 hours of user engagement. In addition to the [events automatically collected](https://support.google.com/analytics/answer/6317485) by Analytics, there are also the [recommended events for games](https://support.google.com/analytics/answer/9267565) that you can explore to understand user behavior. To predict user churn in this case, the solution counts the number of times the following events are collected for each user within 24 hours of first user engagement:\n- `user_engagement`\n- `level_start_quickplay`\n- `level_end_quickplay`\n- `level_complete_quickplay`\n- `level_reset_quickplay`\n- `post_score`\n- `spend_virtual_currency`\n- `ad_reward`\n- `challenge_a_friend`\n- `completed_5_levels`\n- `use_extra_steps`\nYou can use different sets of events if your use case is different from the one described here. To view list of available events, use the following query:\n```\nSELECT\u00a0 \u00a0 event_name,\u00a0 \u00a0 COUNT(event_name) as event_countFROM\u00a0 \u00a0 firebase-public-project.analytics_153293282.events_*GROUP BY 1ORDER BY\u00a0 \u00a0event_count DESC\n```\n## Choosing a model\nOnce the training data is prepared, you are ready to create an ML model. You can choose from a number of classification algorithms for the model. The following table lists the model types and their pros and cons:\n| Model    | model_type    | Advantages                    | Disadvantages                 |\n|:---------------------|:------------------------|:---------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------|\n| Logistic regression | LOGISTIC_REG   | Faster to train than other model types.            | Might not have the highest performance.           |\n| XGBoost    | BOOSTED_TREE_CLASSIFIER | Higher performance than a LOGISTIC_REG model. Allows inspection of feature importance. | Slower to train than a LOGISTIC_REG model.          |\n| Deep neural networks | DNN_CLASSIFIER   | Higher performance than a LOGISTIC_REG model.           | Slower to train than a LOGISTIC_REG model.          |\n| AutoML Tables  | AUTOML_CLASSIFIER  | Higher performance than a LOGISTIC_REG model.           | Might take longer to train than other model types. Limited model explainability. |\nThis solution defaults to using a logistic regression model because it is the fastest to train, but in the [notebook](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/gaming/propensity-model/bqml/bqml_ga4_gaming_propensity_to_churn.ipynb) , you can can choose to use one of the other model types if you prefer.\n## Training the model\nTrain the classification model by using BigQuery ML. The trained model outputs a propensity score that indicates the probability of a user churning. A 100% probability of churning is indicated by `churned` =1 and a 100% probability of returning is indicated by `churned` =0, with most results falling between these boundaries.\nWhen you use the `CREATE MODEL` statement, BigQuery ML automatically [splits](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#data_split_method) the training data into a training set and a test set. This lets you evaluate the model after training is complete so you can see how accurate it is.\nThe query below shows the `CREATE OR REPLACE MODEL` statement for training the model:\n```\nCREATE OR REPLACE MODEL bqmlga4.churn_logregTRANSFORM(\u00a0 EXTRACT(MONTH from user_first_engagement) as month,\u00a0 EXTRACT(DAYOFYEAR from user_first_engagement) as julianday,\u00a0 EXTRACT(DAYOFWEEK from user_first_engagement) as dayofweek,\u00a0 EXTRACT(HOUR from user_first_engagement) as hour,\u00a0 * EXCEPT(user_first_engagement, user_pseudo_id))OPTIONS(\u00a0 MODEL_TYPE=\"LOGISTIC_REG\",\u00a0 INPUT_LABEL_COLS=[\"churned\"]) ASSELECT\u00a0*FROM\u00a0 Bqmlga4.train\n```\nThis query extracts `month` , `julianday` , and `dayofweek` values from `datetime` and `timestamp` columns, as one example of additional feature preprocessing that you can do before training. The [TRANSFORM()](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create#transform) function in your `CREATE MODEL` query allows the model to retain the extracted values. That way, when you are using this model to make predictions later on, these values won't have to be extracted again.\nView the [notebook](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/gaming/propensity-model/bqml/bqml_ga4_gaming_propensity_to_churn.ipynb) to see examples of how to train XGBoost, deep neural network, and AutoML Tables models.\n## Evaluating the model\nOnce the model finished training, evaluate the model to see how it performed.\nThis solution uses the [ML.EVALUATE](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate) statement to generate [precision](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall) , [recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall) , [accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy) and [f1_score](https://en.wikipedia.org/wiki/F-score) metrics for the model. Training multiple models and then comparing their evaluation metrics can help you decide which model works best with your data.\nThis solution also uses a [confusion matrix](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative) to inspect how well the model predicted the labels, compared to the actual labels. The confusion matrix is created using the default threshold of 0.5, which you may want to adjust to optimize for recall, precision, or a balance of the two. You can use the optional [THRESHOLD](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate#eval_threshold) parameter to modify the default threshold.\n## Getting predictions\nOnce the model is trained and evaluated, you can use it to get predictions.\nThe solution uses the [ML.PREDICT](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict) statement to request predictions from the model.\nFor propensity modeling, the prediction output is the probability of a behavior occurring. The closer the predicted probability is to 1, the more likely the user is to return. The closer the predicted probability is to 0, the more likely the user is to churn.\n## Exporting predictions\nOnce you have predictions from the model, you can use this data for marketing activation. Common ways to do this are to export the data for use in Analytics or Firebase.\n### Using predictions in Google Analytics\nYou can use prediction data for marketing campaigns in Analytics. You can import the model predictions back into Analytics as a user attribute by using the [Data Import feature](https://support.google.com/analytics/answer/10071301) for Google Analytics 4. Based on the prediction values you can [Create and edit audiences](https://support.google.com/analytics/answer/2611404) and also do [Audience targeting](https://support.google.com/optimize/answer/6283435) For example, you can define an audience based on users with prediction probabilities between 0.4 and 0.7, which are those that might not return on their own but could be incentivized to do so.\n### Using predictions in Firebase\nFor Firebase applications, you can use the [Import segments](https://firebase.google.com/docs/projects/import-segments) feature to import prediction data. With this data, you can tailor the user experience by targeting your identified users through Firebase services such as [Remote Config](https://firebase.google.com/docs/remote-config) , [Cloud Messaging](https://firebase.google.com/docs/cloud-messaging) , and [In-App Messaging](https://firebase.google.com/docs/in-app-messaging) . This allows you to do things like send notifications to users, configure the app for users, and follow user journeys across devices.\n## Continuous model evaluation\nAs more data is generated from your users, you might want to regularly evaluate your model on fresh data and re-train the model if you notice that the model quality is declining.\nThis process of ensuring a production machine learning model is still performing well on new data is called continuous evaluation, and it is an essential part of any ML workflow. Performing continuous evaluation can help you catch model drift, a phenomenon that occurs when the data used to train your model no longer reflects the data you are using to request predictions.\nTo learn more about how to do continuous model evaluation, see [Continuous model evaluation with BigQuery ML, Stored Procedures, and Cloud Scheduler](/blog/topics/developers-practitioners/continuous-model-evaluation-bigquery-ml-stored-procedures-and-cloud-scheduler) .\n### What's next\n- Get started with the solution [notebook](https://github.com/GoogleCloudPlatform/analytics-componentized-patterns/blob/master/gaming/propensity-model/bqml/bqml_ga4_gaming_propensity_to_churn.ipynb) .\n- Learn about [BigQuery export of Google Analytics data](https://support.google.com/analytics/answer/9358801) .\n- Review the [events automatically collected by Google Analytics 4](https://support.google.com/analytics/answer/9234069) .\n- Learn [how to build demand forecasting models with BigQuery ML](/blog/topics/developers-practitioners/how-build-demand-forecasting-models-bigquery-ml) .\n- Learn [how to build a recommendation system on e-commerce data using BigQuery ML](https://medium.com/google-cloud/how-to-build-a-recommendation-system-on-e-commerce-data-using-bigquery-ml-df9af2b8c110) .", "guide": "Docs"}