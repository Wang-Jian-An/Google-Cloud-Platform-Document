{"title": "Docs - Optimize compute performance", "url": "https://cloud.google.com/architecture/framework/performance-optimization/compute", "abstract": "# Docs - Optimize compute performance\nLast reviewed 2023-08-05 UTC\nThis document in the [Google Cloud Architecture Framework](/architecture/framework) provides recommendations to help you optimize the performance of your Compute Engine, Google Kubernetes Engine (GKE), and serverless resources.\n", "content": "## Compute Engine\nThis section provides guidance to help you optimize the performance of your [Compute Engine](/compute) resources.\n### Autoscale resources\n[Managed instance groups (MIGs)](/compute/docs/instance-groups) let you scale your stateless apps deployed on Compute Engine VMs efficiently. Autoscaling helps your apps continue to deliver predictable performance when the load increases. In a MIG, a group of Compute Engine VMs is launched based on a template that you define. In the template, you configure an autoscaling policy, which specifies one or more signals that the autoscaler uses to scale the group. The autoscaling signals can be schedule-based, like start time or duration, or based on target metrics such as average CPU utilization. For more information, see [Autoscaling groups of instances](/compute/docs/autoscaler) .\n### Disable SMT\nEach virtual CPU (vCPU) that you allocate to a Compute Engine VM is implemented as a single hardware multithread. By default, two vCPUs share a physical CPU core. This architecture is called [simultaneous multi-threading (SMT)](https://wikipedia.org/wiki/Simultaneous_multithreading) .\nFor workloads that are highly parallel or that perform floating point calculations (such as transcoding, Monte Carlo simulations, genetic sequence analysis, and financial risk modeling), you can improve performance by disabling SMT. For more information, see [Set the number of threads per core](/compute/docs/instances/set-threads-per-core) .\n### Use GPUs\nFor workloads such as machine learning and visualization, you can add [graphics processing units (GPUs)](/compute/docs/gpus) to your VMs. Compute Engine provides NVIDIA GPUs in passthrough mode so that your VMs have direct control over the GPUs and the associated memory. For graphics-intensive workloads such as 3D visualization, you can use NVIDIA RTX virtual workstations. After you deploy the workloads, [monitor the GPU usage](/compute/docs/gpus/monitor-gpus) and review the options for [optimizing GPU performance](/compute/docs/gpus/optimize-gpus) .\n### Use compute-optimized machine types\nWorkloads like gaming, media transcoding, and high performance computing (HPC) require consistently high performance per CPU core. Google recommends that you use [compute-optimized machine types](/compute/docs/compute-optimized-machines) for the VMs that run such workloads. Compute-optimized VMs are built on an architecture that uses features like [non-uniform memory access (NUMA)](https://www.kernel.org/doc/html/latest/mm/numa.html) for optimal and reliable performance.\nTightly coupled HPC workloads have a unique set of requirements for achieving peak efficiency in performance. For more information, see the following documentation:\n- [Parallel file systems for HPC workloads](/architecture/parallel-file-systems-for-hpc) \n- [Architecture: Lustre file system in Google Cloud using DDN EXAScaler](/architecture/lustre-architecture) \n### Choose appropriate storage\nGoogle Cloud offers a wide range of [storage options](/compute/docs/disks) for Compute Engine VMs: Persistent disks, local solid-state drive (SSD) disks, Filestore, and Cloud Storage. For design recommendations and best practices to optimize the performance of each of these storage options, see [Optimize storage performance](/architecture/framework/performance-optimization/storage) .\n## Google Kubernetes Engine\nThis section provides guidance to help you optimize the performance of your [Google Kubernetes Engine (GKE)](/kubernetes-engine) resources.\n### Autoscale resources\nYou can automatically resize the node pools in a GKE cluster to match the current load by using the [cluster autoscaler](/kubernetes-engine/docs/concepts/cluster-autoscaler) feature. Autoscaling helps your apps continue to deliver predictable performance when the load increases. The cluster autoscaler resizes node pools automatically based on the resource requests (rather than actual resource utilization) of the Pods running on the nodes. When you use autoscaling, there can be a trade-off between performance and cost. Review the best practices for configuring [cluster autoscaling](/architecture/best-practices-for-running-cost-effective-kubernetes-applications-on-gke#cluster_autoscaler) efficiently.\n**Note:** With [Autopilot clusters](/kubernetes-engine/docs/concepts/autopilot-overview) , you don't need to worry about provisioning nodes or managing node pools. The node pools are automatically provisioned and scaled based on the requirements of your workloads.\n### Use C2D VMs\nYou can improve the performance of compute-intensive containerized workloads by using [C2D machine types](/compute/docs/compute-optimized-machines#c2d_machine_types) . You can add C2D nodes to your GKE clusters by choosing a C2D machine type in your node pools.\n### Disable SMT\n[Simultaneous multi-threading (SMT)](https://wikipedia.org/wiki/Simultaneous_multithreading) can increase application throughput significantly for general computing tasks and for workloads that need high I/O. But for workloads in which both the virtual cores are compute-bound, SMT can cause inconsistent performance. To get better and more predictable performance, you can [disable SMT](/kubernetes-engine/docs/how-to/configure-smt#configure-smt) for your GKE nodes by setting the number of vCPUs per core to 1.\n### Use GPUs\nFor compute-intensive workloads like image recognition and video transcoding, you can accelerate performance by creating node pools that use GPUs. For more information, see [Running GPUs](/kubernetes-engine/docs/how-to/gpus) .\n### Use container-native load balancing\n[Container-native load balancing](/kubernetes-engine/docs/concepts/container-native-load-balancing) enables load balancers to distribute traffic directly and evenly to Pods. This approach provides better network performance and improved visibility into network latency between the load balancer and the Pods. Because of these benefits, container-native load balancing is the recommended solution for load balancing through [Ingress](/kubernetes-engine/docs/concepts/ingress) .\n### Define a compact placement policy\nTightly coupled batch workloads need low network latency between the nodes in the GKE node pool. \u200b\u200bYou can deploy such workloads to [single-zone node pools](/kubernetes-engine/docs/how-to/creating-a-regional-cluster#create-regional-single-zone-nodepool) , and ensure that the nodes are physically close to each other by defining a compact placement policy. For more information, see [Define compact placement for GKE nodes](/kubernetes-engine/docs/how-to/compact-placement) .\n## Serverless compute services\nThis section provides guidance to help you optimize the performance of your serverless compute services in Google Cloud: [Cloud Run](/run) and [Cloud Functions](/functions) . These services provide autoscaling capabilities, where the underlying infrastructure handles scaling automatically. By using these serverless services, you can reduce the effort to scale your microservices and functions, and focus on optimizing performance at the application level.\nFor more information, see the following documentation:\n- [Optimizing performance for Cloud Run services ](/run/docs/tips/general#optimizing_performance) \n- [Optimizing Java applications for Cloud Run](/run/docs/tips/java) \n- [Optimizing performance in Cloud Functions](/functions/docs/bestpractices/tips#performance) ## What's next\nReview the best practices for optimizing the performance of your storage, networking, database, and analytics resources:\n- [Optimize storage performance](/architecture/framework/performance-optimization/storage) .\n- [Optimize networking performance](/architecture/framework/performance-optimization/networking) .\n- [Optimize database performance](/architecture/framework/performance-optimization/databases) .\n- [Optimize analytics performance](/architecture/framework/performance-optimization/analytics) .", "guide": "Docs"}