{"title": "Docs - MLOps with Intelligent Products Essentials", "url": "https://cloud.google.com/architecture/mlops-intelligent-products-essentials", "abstract": "# Docs - MLOps with Intelligent Products Essentials\nLast reviewed 2022-06-28 UTC\nThis document describes a reference architecture for implementing MLOps using [Intelligent Products Essentials ](/solutions/intelligent-products) and [Vertex AI](/vertex-ai) . These tools can help manufacturers to continuously improve their products by doing the following:\n- Adding intelligent capabilities to more effectively meet customer needs.\n- Monetize new product features.\nWith these objectives in mind, this document is intended for data scientists, machine learning (ML) engineers, and solution architects who want to learn about a MLOps solution architecture for connected products.\n", "content": "## MLOps\nAs described in [Hidden technical debt in ML systems](https://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf) , the ML code is only a small part of mature ML systems. In addition to the ML code and high-quality data, you need a way to put your ML processes into operation.\n[MLOps](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning) is a practice which helps companies to build, deploy and put your ML system into operation in a rapid, repeatable, and reliable manner. MLOps is an application of [DevOps](/devops) principles to ML systems. MLOps is an engineering culture and practice that's intended to unify ML system development (Dev) and ML system operation (Ops). The objective of MLOps is to provide a set of standardized processes and technology capabilities for building, deploying, and putting ML systems into operation rapidly and reliably.\nThe following sections discuss how MLOps can be implemented with Intelligent Products Essentials and Vertex AI.\n### MLOps personas\nThe preceding diagram shows the following component and core MLOps user personas:\n- **Intelligent Products Essentials:** stores customer data, device data, device telemetry, and ownership data across [BigQuery](/architecture/intelligent-products-essentials-architecture#component_3_analytics_and_business_intelligence) and [Cloud Storage](/storage) .\n- **Data scientists:** responsible for analyzing data stored in Intelligent Products Essentials , feature engineering, model development, model evaluation, and building a ML pipeline.\n- **ML engineers:** responsible for orchestrating and hosting model deployment at scale.\nThe following sections describe the MLOps architecture from the perspective of data scientists and ML engineers.\n### Data scientists\nFor any ML problems, the objective of data scientists is to apply advanced analytical and ML techniques to identify patterns in data and output predictions. Because data is the foundation of ML, data scientists need easy access to datasets and a flexible development environment for data analysis.\nThe following diagram shows the MLOps architecture of Intelligent Products Essentials from the perspective of data scientists.\nThe preceding diagram shows the following MLOps components for data scientists:\n- [Vertex AI Workbench](/vertex-ai/docs/workbench/introduction) : offers a Jupyter-based, fully managed, scalable, enterprise-ready compute infrastructure to connect to all the Google Cloud data in the organization. Data scientists can use this infrastructure as their development environment.\n- [Vertex AI Feature Store](/vertex-ai/docs/featurestore/overview) : provides a centralized repository for organizing, storing, and serving ML features. Data scientists can use Vertex AI Feature Store to store and share features across their organization.\n- [Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/introduction/) : lets data scientists build and deploy portable, scalable ML workflows based on Docker containers. After the data scientists produce a ML model, the data scientists can package their training procedures into a ML pipeline using [Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/introduction/) .\n- [Vertex AI Pipelines](/vertex-ai/docs/pipelines/introduction) : provides an execution environment for ML pipelines built using the [Kubeflow Pipelines SDK or TensorFlow Extended](/vertex-ai/docs/pipelines/build-pipeline#sdk) . For Intelligent Products Essentials, we recommend that you use Kubeflow Pipelines SDK. When you use Kubeflow Pipelines SDK, there are also  prebuilt components such as the [Google Cloud Pipeline Components](/vertex-ai/docs/pipelines/components-introduction) for simple and rapid deployment. For the full list of prebuilt components,  see the [Google Cloud Pipeline Components list](/vertex-ai/docs/pipelines/gcpc-list) .\n- [Cloud Source Repositories](/source-repositories) : are fully featured, private Git repositories hosted on Google Cloud. After data scientists define their continuous training ML pipeline, they can store the pipeline definition in a source repository, like Cloud Source Repositories. This approach triggers the continuous integration and continuous deployment (CI/CD) pipeline to run.\n### ML engineers\nIntelligent Products Essentials helps ML engineers to automate the operation of ML models in a timely and reliable fashion. ML engineers manage the CI/CD pipelines that support the deployment of the ML pipeline, model, and in some cases, the prediction service.\nThe following diagram shows the MLOps architecture of Intelligent Products Essentials from the perspective of ML engineers.\nThe preceding diagram shows the following MLOps components for machine learning engineers:\n- [A CI pipeline](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#continuous_integration) : builds, tests, and packages the components of the ML pipeline.\n- [A CD pipeline](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#continuous_delivery) : deploys the ML pipeline to appropriate environments, like staging or production environments.\n- ML pipeline: prepares training data and trains ML models. It includes the following steps:- Data extraction: pulls [training datasets](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#Training_data_set) from predefined data sources.\n- Data validation: identifies anomalies in the data schema and in the distribution of data values.\n- Data preparation: involves data cleaning, data transformation, and feature engineering.\n- Model training: creates trained models using training data and other ML techniques, such as hyperparameter optimization.\n- Model evaluation: assesses the performance of the trained model (from the previous model training step) on the [test dataset](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets#Test_data_set) .\n- Model validation: confirms whether the trained model meets the predictive performance benchmark for deployment.\n- [ML pipeline triggers](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#ml_pipeline_triggers) : events published to [Pub/Sub](/pubsub) that trigger the ML pipeline for [continuous training](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning#data_and_model_validation) .\n- [Vertex AI Model Registry](/vertex-ai/docs/model-registry/introduction) : stores different versions of trained models and their associated metadata.\n- [Batch prediction](/vertex-ai/docs/predictions/batch-predictions) : applies predictions in batches on input data stored in Cloud Storage or BigQuery (available with AutoML Tables). The batch prediction operation can output the prediction results to Cloud Storage or BigQuery (available with AutoML Tables) for downstream systems to consume.## What's next\n- Learn more about [Vertex AI](/vertex-ai) .\n- Learn more about [ML problem framing](https://developers.google.com/machine-learning/problem-framing) .\n- Read about [continuous delivery and automation pipelines in ML](/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning) \n- Read about [MLOps for practitioners](/resources/mlops-whitepaper) .\n- For more reference architectures, diagrams, and best practices, explore the [Cloud Architecture Center](/architecture) .", "guide": "Docs"}