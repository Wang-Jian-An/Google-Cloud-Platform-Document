{"title": "Dataflow - Use Dataflow Prime", "url": "https://cloud.google.com/dataflow/docs/guides/enable-dataflow-prime", "abstract": "# Dataflow - Use Dataflow Prime\nDataflow Prime is a serverless data processing platform for Apache Beam pipelines. Based on Dataflow, Dataflow Prime uses a compute and state-separated architecture. In the following cases, Dataflow Prime might improve pipeline efficiency:\n- Your pipeline would benefit from [Vertical Autoscaling](/dataflow/docs/vertical-autoscaling) .\n- Your pipeline uses [GPUs](/dataflow/docs/gpu/use-gpus) with [right fitting](/dataflow/docs/guides/right-fitting) .\nDataflow Prime supports both batch and streaming pipelines. By default, Dataflow Prime uses [Dataflow Shuffle](/dataflow/docs/shuffle-for-batch) and [Dataflow Runner V2](/dataflow/docs/runner-v2) for batch pipelines.\n", "content": "## SDK version support\nDataflow Prime supports the following Apache Beam SDKs:\n- Apache Beam Python SDK version 2.21.0 or later\n- Apache Beam Java SDK version 2.30.0 or later\n- Apache Beam Go SDK version 2.44.0 or later\nTo download the SDK package or to read the Release Notes, see [Apache Beam Downloads](https://beam.apache.org/get-started/downloads/) .\n## Dataflow Prime features\nThe following is the list of supported Dataflow Prime features for different kinds of pipelines:\n- **Vertical Autoscaling (memory).** Supports streaming pipelines in Python, Java, and Go.\n- **Right Fitting (Dataflow Prime resource hints).** Supports batch pipelines in Python and Java.\n- **Job Visualizer.** Supports batch pipelines in Python and Java.\n- **Smart Recommendations.** Supports both streaming and batch pipelines in Python and Java.\n- **Data Pipelines.** Supports both streaming and batch pipelines in Python and Java.\nThe features Job Visualizer, Smart Recommendations, and Data Pipelines are also supported for non-Dataflow Prime jobs.\n### Vertical Autoscaling\nThis feature automatically adjusts the memory available to the Dataflow worker VMs to fit the needs of the pipeline and help prevent out-of-memory errors. In Dataflow Prime, Vertical Autoscaling works alongside Horizontal Autoscaling to scale resources dynamically.\nFor more information, see [Vertical Autoscaling](/dataflow/docs/vertical-autoscaling) .\n### Right Fitting\nThis feature uses [resource hints](https://beam.apache.org/documentation/runtime/resource-hints/) , a feature of Apache Beam. By using resource hints, you can specify resource requirements either for the entire pipeline or for specific steps of the pipeline. This feature lets you create customized workers for different steps of a pipeline. Right fitting lets you specify pipeline resources to maximize efficiency, lower operational cost, and avoid out-of-memory and other resource errors. It supports memory and GPU resource hints.\nRight fitting requires [Apache Beam 2.30.0](https://beam.apache.org/blog/beam-2.30.0/) or later.\nFor more information, see [Configuring Dataflow Prime Right Fitting](/dataflow/docs/guides/right-fitting) .\n### Job Visualizer\nThis feature lets you see the performance of a Dataflow job and optimize the performance of the job by finding inefficient code, including parallelization bottlenecks. In the Google Cloud console, you can click any Dataflow job in the **Jobs** page to view details about the job. You can also see the list of steps associated with each stage of the pipeline.\nFor more information, see [Execution details](/dataflow/docs/concepts/execution-details) .\n### Smart Recommendations\nThis feature lets you optimize and troubleshoot the pipeline based on the recommendations provided in the **Diagnostics** tab of the job details page. In the Google Cloud console, you can click any Dataflow job in the **Jobs** page to view details about the job.\nFor more information, see [Recommendations and diagnostics](/dataflow/docs/guides/monitoring-overview#recommendations-and-diagnostics) .\n### Data Pipelines\nThis feature lets you schedule jobs, observe resource utilizations, track data freshness objectives for streaming data, and optimize pipelines.\nFor more information, see [Working with Data Pipelines](/dataflow/docs/guides/data-pipelines) .\n## Quota and limit requirements\nQuotas and limits are the same for Dataflow and Dataflow Prime. For more information, see [Quotas and limits](https://cloud.google.com/dataflow/quotas) .\nIf you opt for Data Pipelines, there are additional implications for [quotas and regions](/dataflow/docs/guides/data-pipelines#overview) .\n## Unsupported features\nDataflow Prime does not support the following:\n- Resource hints for cross-language transforms. For more information about this limitation, see the [Apache Beam](https://issues.apache.org/jira/browse/BEAM-12082) documentation.\n- Designating specific VM types by using the flag `--worker_machine_type` or `--machine_type` for Python pipelines and `--workerMachineType` for Java pipelines.\n- Viewing or using SSH to log into worker VMs.\n- The classes `MapState` and `OrderedListState` for Java pipelines.\n- [Custom window](https://beam.apache.org/documentation/patterns/custom-windows/) types.\n- [Flexible Resource Scheduling (FlexRS)](/dataflow/docs/guides/flexrs) .\n- Using [VPC Service Controls](/vpc-service-controls/docs/overview) with Vertical Autoscaling. If you enable Dataflow Prime and launch a new job within a VPC Service Controls perimeter, the job uses Dataflow Prime without Vertical Autoscaling.\n- [NVIDIA Multi-Process Service (MPS)](/dataflow/docs/gpu/use-nvidia-mps) .\nAll [pipeline options](/dataflow/docs/reference/pipeline-options) not explicitly mentioned previously or in the [feature comparison table](#feature-comparison) work the same for Dataflow and Dataflow Prime.\n## Before using Dataflow Prime\nTo use Dataflow Prime, you can reuse your existing pipeline code and also enable the Dataflow Prime option either through Cloud Shell or programmatically.\nDataflow Prime is backward compatible with batch jobs that use Dataflow Shuffle and streaming jobs that use Streaming Engine. However, we recommend testing your pipelines with Dataflow Prime before you use them in a production environment.\nIf your streaming pipeline is running in production, to use Dataflow Prime, perform the following steps:\n- [Stop](/dataflow/docs/guides/stopping-a-pipeline) the pipeline.\n- Enable [Dataflow Prime](#enable-prime) .\n- Rerun the pipeline.## Enable Dataflow Prime\nTo enable Dataflow Prime for a pipeline:\n- Enable the Cloud Autoscaling API. [Enable the API](https://console.cloud.google.com/flows/enableapi?apiid=autoscaling.googleapis.com) Dataflow Prime uses the Cloud Autoscaling API to dynamically adjust memory.\n- Enable Prime in your pipeline options.You can set the [pipeline options](/dataflow/docs/guides/setting-pipeline-options) either programmatically or by using the command line. For [supported Apache Beam SDK versions](/dataflow/docs/guides/enable-dataflow-prime#sdk_version_support) , enable the following flag:\n```\n--dataflowServiceOptions=enable_prime\n```\nApache Beam Python SDK version 2.29.0 or later:\n```\n--dataflow_service_options=enable_prime\n```\nApache Beam Python SDK version 2.21.0 to 2.28.0:\n```\n--experiments=enable_prime\n```\n```\n--dataflow_service_options=enable_prime\n```\n## Use Dataflow Prime with templates\nIf you're using Dataflow templates, you can choose to enable Dataflow Prime in one of the following ways:\n- For jobs launched from the **Create job from template** page:- Go to the **Create job from template** page. [Go to Create job from template](https://console.cloud.google.com/dataflow/createjob) \n- In the **Additional experiment** field, enter `enable_prime` .\n- For jobs launched from a template through the command line interface, pass the `--additional-experiments=enable_prime` flag.\n- To enable Dataflow Prime when you create a template, set the `--experiments=enable_prime` flag.## Use Dataflow Prime in Apache Beam notebooks\nIf you're using an [Apache Beam notebook](/dataflow/docs/guides/interactive-pipeline-development) , you can enable Dataflow Prime [programmatically](/dataflow/docs/guides/setting-pipeline-options#setting_pipeline_options_programmatically) using `PipelineOptions` :\n```\noptions = pipeline_options.PipelineOptions(\u00a0 \u00a0 flags=[],\u00a0 \u00a0 dataflow_service_options=['enable_prime'],)\n```\nTo learn more about setting Dataflow options in a notebook, see [Launch Dataflow jobs from a pipeline created in your notebook](/dataflow/docs/guides/interactive-pipeline-development#launch-jobs-from-pipeline) .\n## Feature comparison between Dataflow and Dataflow Prime\nThe following table compares the available features for both variants of Dataflow.\n| Feature        | Dataflow Prime                   | Dataflow                  |\n|:------------------------------------|:------------------------------------------------------------------------------------------|:--------------------------------------------------------------------------------|\n| Runner V2       | Default feature with no option to turn off for batch jobs and optional for streaming jobs | Optional feature                |\n| Dataflow Shuffle for batch jobs  | Default feature with no option to turn off            | Default feature with an option to turn off          |\n| Streaming Engine for streaming jobs | Optional feature for Java pipelines and always on for Python pipelines     | Optional feature for Java pipelines and option to turn off for Python pipelines |\n| Horizontal Autoscaling    | Default feature with option to turn off             | Default feature with option to turn off           |\n| Vertical Autoscaling    | Default feature with option to turn off             | Not applicable                 |\n| Right Fitting      | Optional feature                   | Not applicable                 |\n| Billing        | Serverless billing                  | Standard billing                |\n## What's next\n- Read about Dataflow [quotas](https://cloud.google.com/dataflow/quotas) .\n- Learn how to set [pipeline options](/dataflow/docs/guides/setting-pipeline-options) .\n- See available [pipeline options](/dataflow/docs/reference/pipeline-options#worker-level_options) for Java and Python pipelines.\n- Learn more about [autotuning features](/dataflow/docs/guides/deploying-a-pipeline#autotuning-features) for Dataflow Prime.\n- Learn more about Dataflow [GPUs](/dataflow/docs/gpu) .", "guide": "Dataflow"}