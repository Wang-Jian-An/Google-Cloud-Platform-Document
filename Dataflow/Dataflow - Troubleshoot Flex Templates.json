{"title": "Dataflow - Troubleshoot Flex Templates", "url": "https://cloud.google.com/dataflow/docs/guides/troubleshoot-templates", "abstract": "# Dataflow - Troubleshoot Flex Templates\nThis page provides troubleshooting tips and debugging strategies that you might find helpful if you're using Dataflow Flex Templates. This information can help you detect a polling timeout, determine the reason behind the timeout, and correct the problem.\n", "content": "## Troubleshoot polling timeouts\nThis section provides steps for identifying the cause of polling timeouts.\n### Polling timeouts\nYour Flex Template job might return the following error message:\n```\nTimeout in polling result file: ${file_path}.\nService account: ${service_account_email}\nImage URL: ${image_url}\nTroubleshooting guide at https://cloud.google.com/dataflow/docs/guides/common-errors#timeout-polling\n```\nThis error can occur for the following reasons:\n- [The base Docker image was overridden.](#docker-entrypoint) \n- [The service account that fills in ${service_account_email} does not havesome necessary permissions.](#service-account) \n- [External IP addresses are disabled, and VMs can't connect to the set ofexternal IP addresses used by Google APIs and services.](#private-access) \n- [The program that creates the graph takes too long to finish.](#launcher) \n- [Pipeline options are being overwritten.](#required-options) \n- [(Python only) There is a problem with the requirements.txt file.](#python-requirements) \n- There was a transient error.\nTo resolve this issue, first check for transient errors by checking the job logs and retrying. If those steps don't resolve the issue, try the following troubleshooting steps.\nTry this step if you're running a template from a custom Docker image rather than using one of the provided templates.\nCheck for the container entrypoint using the following command:\n```\ndocker inspect $TEMPLATE_IMAGE\n```\nThe following output is expected:\n`/opt/google/dataflow/java_template_launcher`\n `/opt/google/dataflow/python_template_launcher`\nIf you get a different output, then the entrypoint of your Docker container is overridden. Restore `$TEMPLATE_IMAGE` to the default.\nCheck that the service account mentioned in the message has the following permissions:\n- It must be able read and write the Cloud Storage path that fills in`${file_path}`in the message.\n- It must be able to read the Docker image that fills in`${image_url}`in the message.If external IP addresses are disabled, you need to allow Compute Engine VMs to connect to the set of external IP addresses used by [Google APIs and services](https://developers.google.com/apis-explorer/) . Enable Private Google Access on the subnet used by the network interface of the VM.\nFor configuration details, see [Configuring Private Google Access](/vpc/docs/configure-private-google-access) .\nBy default, when a Compute Engine VM lacks an external IP address assigned to its network interface, it can only send packets to other internal IP address destinations.\nThe program that constructs the pipeline must finish before the pipeline can be launched. The polling error could indicate that it took too long to do so.\nSome things you can do to locate the cause in code are:\n- Check job logs and see if any operation appears to take a long time to complete. An example would be a request for an external resource.\n- Make sure no threads are blocking the program from exiting. Some clients might create their own threads, and if these clients are not shut down, the program waits forever for these threads to be joined.\nPipelines launched directly that don't use a template don't have these limitations. Therefore, if the pipeline worked directly but not as a template, then the use of a template might be the root cause. Finding the issue in the template and fixing the template might resolve the issue.\nWhen using Flex Templates, you can configure some but not all pipeline options during pipeline initialization. For more information, see the [Failed to read the job file](#read-job-file) section in this document.\nIf your Dockerfile includes a `requirements.txt` with `apache-beam[gcp]` , remove it from the file and install it separately. The following command demonstrates how to complete this step:\n```\nRUN pip install apache-beam[gcp]\nRUN pip install -U -r ./requirements.txt\n```\nPutting Apache Beam in the requirements file can cause long launch times, often resulting in a timeout.\n### Polling timeouts when using Python\nIf you're running a Dataflow job by using a Flex Template and Python, your job might queue for a period, fail to run, and then display the following error:\n```\nTimeout in polling\n```\nThe `requirements.txt` file that's used to install the required dependencies causes the error. When you launch a Dataflow job, all of the dependencies are staged first to make these files accessible to the worker VMs. This process involves downloading and compiling every direct and indirect dependency in the `requirements.txt` file. Some dependencies might take several minutes to compile. Notably [PyArrow](https://issues.apache.org/jira/browse/ARROW-8983) might take time to compile. PyArrow is an indirect dependency that's used by Apache Beam and most Cloud Client Libraries.\nTo optimize your job's performance, use a Dockerfile or a custom container to prepackage the dependencies. For more information, see [Package dependencies](/dataflow/docs/guides/templates/configuring-flex-templates#dependencies) in \"Configure Flex Templates.\"\n## Job launch failures\nThe following section contains common errors that lead to job launch failures and steps for resolving or troubleshooting the errors.\n### Early startup issues\nWhen the template launching process fails in an early stage, regular Flex Template logs might not be available. To investigate startup issues, enable [serial port logging](/compute/docs/troubleshooting/viewing-serial-port-output) for the templates launcher VM.\nTo enable logging for Java templates, set the `enableLauncherVmSerialPortLogging` option to `true` . To enable logging for Python and Go templates, set the `enable_launcher_vm_serial_port_logging` option to `true` . In the Google Cloud console, the parameter is listed in **Optional parameters** as **Enable Launcher VM Serial Port Logging** .\nYou can view the serial port output logs of the templates launcher VM in Cloud Logging. To find the logs for a particular launcher VM, use the query `resource.type=\"gce_instance\" \"launcher-` `` `\"` where starts with the current date in the format `YYYMMDD` .\n[Your organization policy](/compute/docs/troubleshooting/viewing-serial-port-output#setting_an_organization_policy) might prohibit you from enabling serial port outputs logging.\n### Failed to read the job file\nWhen you try to run a job from a Flex Template, your job might fail with one of the following errors:\n```\nFailed to read the job file : gs://dataflow-staging-REGION-PROJECT_ID/staging/template_launches/TIMESTAMP/job_object with error message: ...: Unable to open template file\n```\nOr:\n```\nFailed to read the result file : gs://BUCKET_NAME with error message: (ERROR_NUMBER): Unable to open template file: gs://BUCKET_NAME\n```\nThis error occurs when the necessary pipeline initialization options are overwritten. When using Flex Templates, you can configure some but not all pipeline options during pipeline initialization. If the command line arguments required by the Flex Template are overwritten, the job might ignore, override, or discard the pipeline options passed by the template launcher. The job might fail to launch, or a job that doesn't use the Flex Template might launch.\nTo avoid this issue, during pipeline initialization, don't change the following [pipeline options](/dataflow/docs/reference/pipeline-options) in user code or in the `metadata.json` file:\n- `runner`\n- `project`\n- `jobName`\n- `templateLocation`\n- `region`\n- `runner`\n- `project`\n- `job_name`\n- `template_location`\n- `region`\n- `runner`\n- `project`\n- `job_name`\n- `template_location`\n- `region`\n### Permission denied on resource\nWhen you try to run a job from a Flex Template, your job might fail with the following error:\n```\nPermission \"MISSING_PERMISSION\" denied on resource \"projects/PROJECT_ID/locations/REGION/repositories/REPOSITORY_NAME\" (or it may not exist).\n```\nThis error occurs when the used service account does not have permissions to access necessary resources to run a Flex Template.\nTo avoid this issue, verify that the service account has the [required permissions](/dataflow/docs/guides/templates/configuring-flex-templates#permissions_to_run_a_flex_template) . Adjust the service account permissions as needed.\n### Flag provided but not defined\nWhen you try to run a Go Flex Template with the `worker_machine_type` pipeline option, the pipeline fails with the following error:\n```\nflag provided but not defined: -machine_type\n```\nThis error is caused by a known issue in the Apache Beam Go SDK versions 2.47.0 and earlier. To resolve this issue, upgrade to Apache Beam Go version 2.48.0 or later.\n## Flex Template launcher delay\nWhen you submit a Flex Template job, the job request goes into a Spanner queue. The template launcher picks up the job from the Spanner queue and then runs the template. When Spanner has a message backlog, a significant delay might occur between the time you submit the job and the time the job launches.\nTo work around this issue, launch your Flex Template from a different region.\n## The template parameters are invalid\nWhen you try to use the gcloud CLI to run a job that uses a [Google-provided template](/dataflow/docs/guides/templates/provided-templates) , the following error occurs:\n```\nERROR: (gcloud.beta.dataflow.flex-template.run) INVALID_ARGUMENT: The template\nparameters are invalid. Details: defaultSdkHarnessLogLevel: Unrecognized\nparameter defaultWorkerLogLevel: Unrecognized parameter\n```\nThis error occurs because some Google-provided templates don't support the `defaultSdkHarnessLog` and `defaultWorkerLog` options.\nAs a workaround, copy the template specification file to a Cloud Storage bucket. Add the following additional parameters to the file.\n```\n\"metadata\": {\u00a0 \u00a0 ...\u00a0 \u00a0 \"parameters\": [\u00a0 \u00a0 \u00a0 ...,\u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \"name\": \"defaultSdkHarnessLogLevel\",\u00a0 \u00a0 \u00a0 \u00a0 \"isOptional\": true,\u00a0 \u00a0 \u00a0 \u00a0 \"paramType\": \"TEXT\"\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \"name\": \"defaultWorkerLogLevel\",\u00a0 \u00a0 \u00a0 \u00a0 \"isOptional\": true,\u00a0 \u00a0 \u00a0 \u00a0 \"paramType\": \"TEXT\"\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 ]\u00a0 }\n```\nAfter you make this change to the template file, use the following command to run the template.\n```\n--template-file-gcs-location=gs://BUCKET_NAME/FILENAME\n```\nReplace the following values:\n- ``: the name of your Cloud Storage bucket\n- ``: the name of your template specification file## Flex Template launcher logs show wrong severity\nWhen a [custom Flex Template](/dataflow/docs/guides/templates/using-flex-templates) launch fails, the following message appears in the log files with the severity `ERROR` :\n```\nERROR: Error occurred in the launcher container: Template launch failed. See console logs.\n```\nThe root cause of the launch failure usually appears in the logs prior to this message with the severity `INFO` . Although this log level may be incorrect, it is expected, because the Flex template launcher has no way to extract severity details from the log messages produced by the Apache Beam application.\nIf you want to see the correct severity for every message in the launcher log, configure your template to generate logs in the JSON format instead of in plain text. This configuration allows the template launcher to extract the correct log message severity. Use the following message structure:\n```\n{\u00a0 \"message\": \"The original log message\",\u00a0 \"severity\": \"DEBUG/INFO/WARN/ERROR\"}\n```\nIn Java, you can use [Logback logger](https://logback.qos.ch/documentation.html) with a custom JSON [appender](https://logback.qos.ch/manual/appenders.html) implementation. For more information, see the [Logback example configuration](https://github.com/GoogleCloudPlatform/DataflowTemplates/blob/f0029e203fbcfd3ea32b1632c70add1d6088ed38/structured-logging/src/main/resources/logback.xml) and the [JSON appender example code](https://github.com/GoogleCloudPlatform/DataflowTemplates/blob/ae826040fe19c3d1cb4c80763403dd4f257711db/structured-logging/src/main/java/com/google/cloud/teleport/v2/logging/JsonAppender.java#L28) in GitHub.\nThis issue only impacts the logs generated by the Flex Template launcher when the pipeline is launching. When the launch succeeds and the pipeline is running, the logs produced by Dataflow workers have the proper severity.\n[Google-provided templates](/dataflow/docs/guides/templates/provided-templates) show the correct severity during job launch, because the Google-provided templates use this JSON logging approach.", "guide": "Dataflow"}