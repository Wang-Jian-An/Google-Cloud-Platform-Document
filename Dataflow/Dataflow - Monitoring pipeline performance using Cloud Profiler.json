{"title": "Dataflow - Monitoring pipeline performance using Cloud Profiler", "url": "https://cloud.google.com/dataflow/docs/guides/profiling-a-pipeline", "abstract": "# Dataflow - Monitoring pipeline performance using Cloud Profiler\nCloud Profiler is a statistical, low-overhead profiler that continuously gathers CPU usage and memory allocation information from your production applications. For more details, see [Profiling concepts](/profiler/docs/concepts-profiling) . To troubleshoot or monitor pipeline performance, use Dataflow integration with Cloud Profiler to identify the parts of the pipeline code consuming the most resources.\nFor troubleshooting tips and debugging strategies for building or running your Dataflow pipeline, see [Troubleshooting and debugging pipelines](/dataflow/docs/guides/troubleshooting-your-pipeline) .\n", "content": "## Before you begin\nUnderstand [profiling concepts](/profiler/docs/concepts-profiling) and familiarize yourself with the Profiler interface. For information about how to get started with the Profiler interface, see [Select the profiles to analyze](/profiler/docs/selecting-profiles) .\nThe Cloud Profiler API must be enabled for your project before your job is started. It is enabled automatically the first time you [visit the Profilerpage](/profiler/docs/measure-app-performance#before_you_begin) . Alternatively, you can enable the Cloud Profiler API by using the [Google Cloud CLI](/profiler/docs/profiling-python#enabling-profiler) `gcloud` command-line tool or the Google Cloud console.\nTo use Cloud Profiler, your project must have enough [quota](/profiler/quotas) . In addition, the [worker service account](/dataflow/docs/concepts/security-and-permissions#worker-service-account) for the Dataflow job must have appropriate permissions for Profiler. For example, to create profiles, the worker service account must have the `cloudprofiler.profiles.create` permission, which is included in the Cloud Profiler Agent ( `roles/cloudprofiler.agent` ) IAM role. For more information, see [Access control with IAM](/profiler/docs/iam) .\n## Enable Cloud Profiler for Dataflow pipelines\nCloud Profiler is available for Dataflow pipelines written in Apache Beam SDK for Java and Python, version 2.33.0 or later. Python pipelines must use Dataflow Runner v2. Cloud Profiler can be enabled at pipeline start time. The amortized CPU and memory overhead is expected to be less than 1% for your pipelines.\nTo enable CPU profiling, start the pipeline with the following option.\n `--dataflowServiceOptions=enable_google_cloud_profiler` \nTo enable heap profiling, start the pipeline with the following options. Heap profiling requires Java 11 or higher.\n`--dataflowServiceOptions=enable_google_cloud_profiler`\n`--dataflowServiceOptions=enable_google_cloud_heap_sampling`\nNote: The pipeline option `--dataflowServiceOptions` is the  Dataflow preferred way to enable Dataflow  features. Alternatively, you can use `--experiments` .To use Cloud Profiler, your Python pipeline must run with Dataflow [Runner v2](/dataflow/docs/runner-v2) .\nTo enable CPU profiling, start the pipeline with the following option. Heap profiling is not yet supported for Python.\n`--dataflow_service_options=enable_google_cloud_profiler`\nNote: The pipeline option `--dataflow_service_options` is  the Dataflow preferred way to enable Dataflow  features. Alternatively, you can use `--experiments` .To enable CPU and heap profiling, start the pipeline with the following option.\n`--dataflow_service_options=enable_google_cloud_profiler`\nNote: The pipeline option `--dataflow_service_options` is  the Dataflow preferred way to enable Dataflow  features. Alternatively, you can use `--experiments` .\nIf you deploy your pipelines from [Dataflow templates](/dataflow/docs/concepts/dataflow-templates) and want to enable Cloud Profiler, specify the `enable_google_cloud_profiler` and `enable_google_cloud_heap_sampling` flags as additional experiments.\nIf you use a [ Google-providedtemplate](/dataflow/docs/guides/templates/provided-templates) , you can specify the flags on the Dataflow **Createjob from template** page in the **Additional experiments** field.If you use the Google Cloud CLI to run templates, either [gclouddataflow jobs run](/sdk/gcloud/reference/dataflow/jobs/run) or [gcloud dataflow flex-template run](/sdk/gcloud/reference/dataflow/flex-template/run) , depending on the template type, use the `--additional-experiments` option to specify the flags.\nIf you use the REST API to run templates, depending on the template type, specify the flags using the `additionalExperiments` field of the runtime environment, either [RuntimeEnvironment](/dataflow/docs/reference/rest/v1b3/RuntimeEnvironment) or [FlexTemplateRuntimeEnvironment](/dataflow/docs/reference/rest/v1b3/projects.locations.flexTemplates/launch#FlexTemplateRuntimeEnvironment) .\n## View the profiling data\nIf Cloud Profiler is enabled, a link to the Profiler page is shown on the job page.\nOn the Profiler page, you can also find the profiling data for your Dataflow pipeline. The **Service** is your job name and the **Version** is your job ID.\n## Using the Cloud Profiler\nThe Profiler page contains a [flame graph](/profiler/docs/concepts-flame) which displays statistics for each frame running on a worker. In the horizontal direction, you can see how long each frame took to execute in terms of CPU time. In the vertical direction, you can see stack traces and code running in parallel. The stack traces are dominated by runner infrastructure code. For debugging purposes we are usually interested in user code execution, which is typically found near the bottom tips of the graph. User code can be identified by looking for **marker frames** , which represent runner code that is known to only call into user code. In the case of the Beam ParDo runner, a dynamic adapter layer is created to invoke the user-supplied DoFn method signature. This layer can be identified as a frame with the **invokeProcessElement** suffix. The following image shows a demonstration of finding a **marker frame** .\nAfter clicking on an interesting marker frame, the flame graph focuses on that stack trace, giving a good sense of long running user code. The slowest operations can indicate where bottlenecks have formed and present opportunities for optimization. In the following example, it is possible to see that Global Windowing is being used with a ByteArrayCoder. In this case, the coder might be a good area for optimization because it is taking up significant CPU time compared to the ArrayList and HashMap operations.\n**Note:** The following filter can be applied to quickly find and isolate all marker frames: `Show from frame: invokeProcessElement` .\n## Troubleshoot Cloud Profiler\nIf you enable Cloud Profiler and your pipeline doesn't generate profiling data, one of the following conditions might be the cause.\n- Your pipeline uses an older Apache Beam SDK version. To use Cloud Profiler, you need to use Apache Beam SDK version 2.33.0 or later. You can view your pipeline's Apache Beam SDK version on the job page. If your job is created from Dataflow templates, the templates must use the [supported SDK versions](/dataflow/docs/support/sdk-version-support-status) .\n- Your project is running out of Cloud Profiler quota. You can view the quota usage from your project's quota page. An error such as `Failed to collect and upload profile whose profile type is WALL` can occur if the Cloud Profiler quota is exceeded. The Cloud Profiler service rejects the profiling data if you've reached your quota. For more information about Cloud Profiler quotas, see [Quotas and Limits](/profiler/quotas) .\nThe Cloud Profiler agent is installed during Dataflow worker startup. Log messages generated by Cloud Profiler are available in the log type `dataflow.googleapis.com/worker-startup` .\nSometimes, profiling data exists but Cloud Profiler does not display any output. The Profiler displays a message similar to, `There were profiles collected for the specified time range, but none match the current filters` .\nTo resolve this issue, try the following troubleshooting steps.\n- Make sure that the timespan and end time in the Profiler are inclusive of the job's elapsed time.\n- Confirm that the correct job is selected in the Profiler. The **Service** is your job name.\n- Confirm that the `job_name` pipeline option has the same value as the job name on the Dataflow job page.\n- If you specified a [service-name argument](/profiler/docs/profiling-python#svc-name-and-version) when you loaded the Profiler agent, confirm that the service name is configured correctly.", "guide": "Dataflow"}