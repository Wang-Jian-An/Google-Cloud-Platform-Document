{"title": "Dataflow - Apache Beam RunInference with TensorFlow and TensorFlow Hub", "url": "https://cloud.google.com/dataflow/docs/notebooks/run_inference_with_tensorflow_hub?hl=zh-cn", "abstract": "# Dataflow - Apache Beam RunInference with TensorFlow and TensorFlow Hub\n| 0     | 1      |\n|:--------------------|:----------------------|\n| Run in Google Colab | View source on GitHub |\nThis notebook shows how to use the Apache Beam [RunInference](https://beam.apache.org/releases/pydoc/current/apache_beam.ml.inference.base.html#apache_beam.ml.inference.base.RunInference) transform for [TensorFlow](https://www.tensorflow.org/) with a trained model from [TensorFlow Hub](https://www.tensorflow.org/hub) . Apache Beam includes built-in support for two TensorFlow model handlers: [TFModelHandlerNumpy](https://github.com/apache/beam/blob/ca0787642a6b3804a742326147281c99ae8d08d2/sdks/python/apache_beam/ml/inference/tensorflow_inference.py#L91) and [TFModelHandlerTensor](https://github.com/apache/beam/blob/ca0787642a6b3804a742326147281c99ae8d08d2/sdks/python/apache_beam/ml/inference/tensorflow_inference.py#L184) .\n- Use`TFModelHandlerNumpy`to run inference on models that expect a NumPy array as an input.\n- Use`TFModelHandlerTensor`to run inference on models expecting a tensor as an input.\nFor more information about using RunInference, see [Get started with AI/ML pipelines](https://beam.apache.org/documentation/ml/overview/) in the Apache Beam documentation.\n**Note:** The image used for prediction is licensed in CC-BY. The creator is listed in the [LICENSE.txt](https://storage.googleapis.com/apache-beam-samples/image_captioning/LICENSE.txt) file.\n", "content": "## Before you begin\nFirst, import `tensorflow` . To use RunInference with the TensorFlow model handler, install Apache Beam version 2.46 or later.\n```\npip install tensorflowpip install apache_beam==2.46.0\n```\n## Use TensorFlow Hub's trained model URL\nTo use TensorFlow Hub's trained model URL, pass the model URL to the `model_uri` field of `TFModelHandler` class.\n**Note:** Only models that you save in the [TF2 format](https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model) are compatible with `TFModelHandler` . To see TF2 models, go to the [TF2 section of the TensorFlow Hub](https://tfhub.dev/s?subtype=module,placeholder&tf-version=tf2) .\n```\nimport tensorflow as tfimport tensorflow_hub as hubimport apache_beam as beam\n```\n```\n# URL of the trained model from TensorFlow HubCLASSIFIER_URL =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n```\n```\nimport numpy as npimport PIL.Image as ImageIMAGE_RES = 224img = tf.keras.utils.get_file(origin='https://storage.googleapis.com/apache-beam-samples/image_captioning/Cat-with-beanie.jpg')img = Image.open(img).resize((IMAGE_RES, IMAGE_RES))img\n```\n```\nDownloading data from https://storage.googleapis.com/apache-beam-samples/image_captioning/Cat-with-beanie.jpg\n1812110/1812110 [==============================] - 0s 0us/step\n```\n```\n# Convert the input image to the type and dimensions required by the model.img = np.array(img)/255.0img_tensor = tf.cast(tf.convert_to_tensor(img[...]), dtype=tf.float32)\n```\n```\nfrom apache_beam.ml.inference.tensorflow_inference import TFModelHandlerTensorfrom apache_beam.ml.inference.base import PredictionResultfrom apache_beam.ml.inference.base import RunInferencefrom typing import Iterablemodel_handler = TFModelHandlerTensor(model_uri=CLASSIFIER_URL)class PostProcessor(beam.DoFn):\u00a0 \"\"\"Process the PredictionResult to get the predicted label.\u00a0 Returns predicted label.\u00a0 \"\"\"\u00a0 def setup(self):\u00a0 \u00a0 labels_path = tf.keras.utils.get_file(\u00a0 \u00a0 \u00a0 \u00a0 'ImageNetLabels.txt',\u00a0 \u00a0 \u00a0 \u00a0 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\u00a0 \u00a0 )\u00a0 \u00a0 self._imagenet_labels = np.array(open(labels_path).read().splitlines())\u00a0 def process(self, element: PredictionResult) -> Iterable[str]:\u00a0 \u00a0 predicted_class = np.argmax(element.inference)\u00a0 \u00a0 predicted_class_name = self._imagenet_labels[predicted_class]\u00a0 \u00a0 yield \"Predicted Label: {}\".format(predicted_class_name.title())with beam.Pipeline() as p:\u00a0 _ = (p\u00a0 \u00a0 | \"Create PCollection\" >> beam.Create([img_tensor])\u00a0 \u00a0 | \"Perform inference\" >> RunInference(model_handler)\u00a0 \u00a0 | \"Post Processing\" >> beam.ParDo(PostProcessor())\u00a0 \u00a0 | \"Print\" >> beam.Map(print))\n```\n```\nPredicted Label: Tiger Cat\n```", "guide": "Dataflow"}