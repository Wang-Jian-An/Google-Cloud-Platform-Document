{"title": "Dataflow - Use the Dataflow job monitoring interface", "url": "https://cloud.google.com/dataflow/docs/guides/monitoring-overview", "abstract": "# Dataflow - Use the Dataflow job monitoring interface\nWhen you run your pipeline using the [Dataflow-managed service](/dataflow/service/dataflow-service-desc) , you can view that job and any others by using the web-based monitoring interface of Dataflow. The monitoring interface lets you see and interact with your Dataflow jobs.\n**Note:** If you prefer to view and interact with your Dataflow jobs using the command-line interface, use the [Dataflow command-line interface](/dataflow/pipelines/dataflow-command-line-intf) .\nYou can access the Dataflow monitoring interface by using the [Google Cloud console](https://console.cloud.google.com/) . The monitoring interface can show you:\n- A list of all running Dataflow jobs and all jobs run within the last 30 days.\n- A graphical representation of each pipeline.\n- Details about the status of your job, type, and SDK version.\n- Links to information about the Google Cloud services running your pipeline, such as [Compute Engine](/compute) and [Cloud Storage](/storage) .\n- Any errors or warnings that occur during a job.\n- Additional diagnostics for a job.\nYou can view job visualizers within the Dataflow monitoring interface. These charts display metrics over the duration of a pipeline job and include the following information:\n- Step-level visibility to help identify which steps might be causing pipeline lag.\n- Statistical information that can surface anomalous behavior.\n- I/O metrics that can help identify bottlenecks in your sources and sinks.\n**Note:** Sometimes job data is intermittently unavailable. When data is missing, gaps appear in the job monitoring charts.\n", "content": "## Access the Dataflow monitoring interface\nTo access the Dataflow monitoring interface, follow these steps:\n- [Sign in](https://console.cloud.google.com/) to the Google Cloud console.\n- Select your Google Cloud project.\n- Open the navigation menu.\n- In **Analytics** , click **Dataflow** .\nA list of Dataflow jobs appears along with their status. If you don't see any jobs, you need to run a new job. To learn how to run a job, see the [Java quickstart](/dataflow/docs/quickstarts/create-pipeline-java) , [Python quickstart](/dataflow/docs/quickstarts/create-pipeline-python) , or [Go quickstart](/dataflow/docs/quickstarts/create-pipeline-go) .A job can have the following statuses:\n- **\u2014** : the monitoring interface has not yet received a status from the Dataflow service.\n- **Running** : the job is running.\n- **Starting...** : the job is created, but the system needs some time to prepare before launching.\n- **Queued** : either a [FlexRS job](/dataflow/docs/guides/flexrs#delayed_scheduling) is queued or a [Flex template](/dataflow/docs/guides/templates/using-flex-templates) job is being launched (which might take several minutes).\n- **Canceling...** : the job is [being canceled](/dataflow/docs/guides/stopping-a-pipeline#cancel) .\n- **Canceled** : the job is canceled.\n- **Draining...** : the job is [being drained](/dataflow/docs/guides/stopping-a-pipeline#drain) .\n- **Drained** : the job is drained.\n- **Updating...** : the job is [being updated](/dataflow/docs/guides/updating-a-pipeline) .\n- **Updated** : the job is updated.\n- **Succeeded** : the job has finished successfully.\n- **Failed** : the job failed to complete.\nFor more information about a pipeline, click the name of the job.\n## Access job visualizers\nTo access charts for monitoring your job, click the job name within the Dataflow monitoring interface. The **Job details** page is displayed, which contains the following information:\n- **Job graph** : visual representation of your pipeline\n- **Execution details** : tool to optimize your pipeline performance\n- **Job metrics** : metrics about the running of your job\n- **Cost** : metrics about the estimated cost of your job\n- **Autoscaling** : metrics related to streaming job autoscaling events\n- **Job info** panel: descriptive information about your pipeline\n- **Job logs** : logs generated by the Dataflow service at the job level\n- **Worker logs** : logs generated by the Dataflow service at the worker level\n- **Diagnostics** : table showing where errors occurred along the chosen timeline and possible recommendations for your pipeline\n- **Data sampling** : tool that lets you observe the data at each step of a pipeline. See [Use data sampling to observe pipeline data](/dataflow/docs/guides/data-sampling) .\nWithin the **Job details** page, you can switch your job view with the **Job graph** , **Execution details** , **Job metrics** , **Cost** , and **Autoscaling** tabs.\n## Job graphs\nWhen you select a specific Dataflow job, the monitoring interface provides a graphical representation of your pipeline: the **job graph** . The job graph page in the console also provides a job summary, a job log, and information about each step in the pipeline. For more details about job graphs, see [Dataflow job graph](/dataflow/docs/guides/job-graph) .\n## Job metrics\nYou can view charts in the `Job metrics` tab of the Dataflow web interface. Each metric is organized into the following dashboards:\nOverview metrics\n- [Autoscaling](/dataflow/docs/guides/using-monitoring-intf#autoscaling) \n- [Throughput](/dataflow/docs/guides/using-monitoring-intf#throughput) \n- [Worker error log count](/dataflow/docs/guides/using-monitoring-intf#worker-error-logs) \nStreaming metrics (streaming pipelines only)\n- [Data freshness (with and without Streaming Engine)](/dataflow/docs/guides/using-monitoring-intf#data_freshness_streaming) \n- [System latency (with and without Streaming Engine)](/dataflow/docs/guides/using-monitoring-intf#system_latency_streaming) \n- [Backlog](/dataflow/docs/guides/using-monitoring-intf#backlog) \n- [Processing (Streaming Engine only)](/dataflow/docs/guides/using-monitoring-intf#processing_streaming) \n- [Parallelism (Streaming Engine only)](/dataflow/docs/guides/using-monitoring-intf#parallelism) \n- [Persistence (Streaming Engine only)](/dataflow/docs/guides/using-monitoring-intf#persistence_streaming) \n- [Duplicates (Streaming Engine only)](/dataflow/docs/guides/using-monitoring-intf#duplicates) \n- [Timers (Streaming Engine only)](/dataflow/docs/guides/using-monitoring-intf#timers) \nResource metrics\n- [CPU utilization](/dataflow/docs/guides/using-monitoring-intf#cpu-use) \n- [Memory utilization](/dataflow/docs/guides/using-monitoring-intf#memory-use) \nInput metrics\n- [Pub/Sub read, BigQuery read, and so on](/dataflow/docs/guides/using-monitoring-intf#input-output) \nOutput metrics\n- [Pub/Sub write, BigQuery write, and so on](/dataflow/docs/guides/using-monitoring-intf#input-output) ## Cloud Monitoring alerts\nSee [Create Cloud Monitoring alerts](/dataflow/docs/guides/using-monitoring-intf#create-alerts) .\n## Cost monitoring\nThe **Cost** page in the Google Cloud console shows the estimated cost of your current Dataflow job. Estimated costs are calculated by multiplying the resource usage metrics as shown in Cloud Monitoring by the [price of those resources in the job region](/dataflow/pricing) .\n**Warning:** The estimated cost might not reflect the actual job cost for a variety of reasons, such as contractual discounts or temporary billing adjustments. To view the actual cost of your Dataflow jobs, view the [Cloud Billing reports for your Cloud Billing account](/billing/docs/how-to/reports#getting_started) in the Google Cloud console.\n### Use cost monitoring\nJob cost estimates are available for both batch and streaming jobs. The **Cost** page in the Google Cloud console provides the following information:\n- Details about which resources contribute to the job cost and by how much. Resources include vCPUs, memory, Dataflow Shuffle data processed or Streaming Engine data processed, and SSD and HDD disk usage.\n- Costs over specific time windows, such as: time since the job started, the previous hour, the last 24 hours, the preceding seven days, and a user-specified time range.\nYou can use monitoring alerts to get notifications when your job costs cross a specified threshold. You can also use alerts to make changes to your jobs, such as stopping or canceling jobs, based on the thresholds that you set.\nTo create a Cloud Monitoring alert rule, click **Create alert** . For instructions about how to configure these alerts, see [Use Cloud Monitoring for Dataflow pipelines](/dataflow/docs/guides/using-cloud-monitoring) .\n### Limitations\nDataflow cost monitoring does not support Dataflow Prime jobs and GPU metrics.\n## Autoscaling metrics\nYou can view autoscaling monitoring charts for streaming jobs within the Dataflow monitoring interface. These charts display metrics over the duration of a pipeline job and include the following information:\n- The number of worker instances used by your job at any point in time\n- Autoscaling log files\n- The estimated backlog over time\n- Average CPU utilization over time\nFor more information, see [Monitor Dataflow autoscaling](/dataflow/docs/guides/autoscaling-metrics) .\n## Recommendations and diagnostics\nDataflow provides recommendations for improving job performance, reducing cost, and troubleshooting errors. This section explains how to review and interpret the recommendations. Keep in mind that some recommendations might not be relevant to your use case.\n### Recommendations\nThe **Recommendations** tab displays insights from Dataflow regarding the pipeline. The goal of these insights is to identify situations in which improvements in cost and performance might be made.\nThe **Update date** column indicates the last time that an insight was observed. Recommendations will be stored for 30 days from the **Update date** .\nFor programmatic access to recommendations, use the [Recommender API](/recommender/docs/using-api) .\nYou can dismiss a recommendation at the Recommendation Hub for your project.\nTo dismiss a recommendation, click the navigation menu in the upper left of the Google Cloud console and select **Home** > **Recommendations** . On the Dataflow Diagnostics card, click **View all** , select the recommendation you want to dismiss, and click **Dismiss** .\n### Diagnostics\nThe **Diagnostics** tab of the **Logs** pane, collects and displays certain log entries produced in your pipelines. These include messages that indicate a probable issue with the pipeline, and error messages with stack traces. Collected log entries are deduplicated and combined into .\nThe error report includes the following information:\n- A list of errors with error messages.\n- The number of times each error occurred.\n- A histogram indicating when each error occurred.\n- The time that the error most recently occurred.\n- The time that the error first occurred.\n- The status of the error.\nTo view the error report for a specific error, click the description under the **Errors** column. The **Error reporting** page is displayed. If the error is a Service Error, an extra link with documentation including further steps will be displayed (\"Troubleshooting guide\").\nTo know more about the page, see [Viewing errors](/error-reporting/docs/viewing-errors) .\nTo mute an error message, open the **Diagnostics** tab, click the error you want to mute, open the resolution status menu (labeled one of: **Open** | **Acknowledged** | **Resolved** | **Muted** ) and select **Muted** .\n## What's next\n- Read how to use [Execution details](/dataflow/docs/concepts/execution-details) to optimize a Dataflow job\n- Explore [Cloud Monitoring](/dataflow/docs/guides/using-cloud-monitoring) to create alerts and view Dataflow metrics, including custom metrics\n- Learn more about [building production-ready data pipelines](/architecture/building-production-ready-data-pipelines-using-dataflow-monitoring)", "guide": "Dataflow"}