{"title": "Dataflow - Run a sample template", "url": "https://cloud.google.com/dataflow/docs/sample-template", "abstract": "# Dataflow - Run a sample template\nThe WordCount template is a batch pipeline that reads text from Cloud Storage, tokenizes the text lines into individual words, and performs a frequency count on each of the words. For more information about WordCount, see [WordCount Example Pipeline](/dataflow/examples/wordcount-example) .\nIf the Cloud Storage bucket is outside of your [service perimeter](/vpc-service-controls/docs/overview) , create an [egress rule](/vpc-service-controls/docs/ingress-egress-rules) that allows access to the bucket.\n", "content": "## Template parameters\n| Parameter | Description          |\n|:------------|:-------------------------------------------------|\n| inputFile | The Cloud Storage input file's path.    |\n| outputFile | The Cloud Storage output file's path and prefix. |\n## Run the WordCount template\n- Go to the Dataflow **Create job from template** page.\n- [Go to Create job from template](https://console.cloud.google.com/dataflow/createjob) \n- In the **Job name** field, enter a unique job name.\n- Optional: For **Regional endpoint** , select a value from the drop-down menu. The default  region is`us-central1`.For a list of regions where you can run a Dataflow job, see [Dataflow locations](/dataflow/docs/resources/locations) .\n- From the **Dataflow template** drop-down menu, select  the WordCount template.\n- In the provided parameter fields, enter your parameter values.\n- Click **Run job** . **Note:** To use the Google Cloud CLI to run classic  templates, you must have [Google Cloud CLI](/sdk/docs/install) version    138.0.0   or later.\nIn your shell or terminal, run the template:```\ngcloud dataflow jobs run JOB_NAME \\\\\u00a0 \u00a0 --gcs-location gs://dataflow-templates/latest/Word_Count \\\\\u00a0 \u00a0 --region REGION_NAME \\\\\u00a0 \u00a0 --parameters \\\\\u00a0 \u00a0 inputFile=gs://dataflow-samples/shakespeare/kinglear.txt,\\\\\u00a0 \u00a0 output=gs://BUCKET_NAME/output/my_output\n```\nReplace the following:- `JOB_NAME` :  a unique job name of your choice\n- `REGION_NAME` :  the [region](/dataflow/docs/resources/locations) where you want to deploy your Dataflow job\u2014for example, `us-central1` \n- `BUCKET_NAME` : the name of your Cloud Storage bucket\nTo run the template using the REST API, send an HTTP POST request. For more information on the  API and its authorization scopes, see [projects.templates.launch](/dataflow/docs/reference/rest/v1b3/projects.templates/launch) .```\nPOST https://dataflow.googleapis.com/v1b3/projects/PROJECT_ID/locations/LOCATION/templates:launch?gcsPath=gs://dataflow-templates/latest/Word_Count{\u00a0 \u00a0 \"jobName\": \"JOB_NAME\",\u00a0 \u00a0 \"parameters\": {\u00a0 \u00a0 \u00a0 \u00a0\"inputFile\" : \"gs://dataflow-samples/shakespeare/kinglear.txt\",\u00a0 \u00a0 \u00a0 \u00a0\"output\": \"gs://BUCKET_NAME/output/my_output\"\u00a0 \u00a0 },\u00a0 \u00a0 \"environment\": { \"zone\": \"us-central1-f\" }}\n```\nReplace the following:- `PROJECT_ID`:  the Google Cloud project ID where you want to run the Dataflow job\n- `JOB_NAME` :  a unique job name of your choice\n- `LOCATION` :  the [region](/dataflow/docs/resources/locations) where you want to deploy your Dataflow job\u2014for example, `us-central1` \n- `BUCKET_NAME` : the name of your Cloud Storage bucket", "guide": "Dataflow"}