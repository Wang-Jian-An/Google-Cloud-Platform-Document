{"title": "Dataflow - Read from Cloud Storage to Dataflow", "url": "https://cloud.google.com/dataflow/docs/guides/read-from-cloud-storage", "abstract": "# Dataflow - Read from Cloud Storage to Dataflow\nTo read data from Cloud Storage to Dataflow, use the Apache Beam `TextIO` or `AvroIO` [I/O connector](https://beam.apache.org/documentation/io/connectors/) .\n**Note:** Depending on your scenario, consider using one of the [Google-provided Dataflow templates](/dataflow/docs/guides/templates/provided-templates) . Several of these templates read from Cloud Storage.\n", "content": "## Include the Google Cloud library dependency\nTo use the `TextIO` or `AvroIO` connector with Cloud Storage, include the following dependency. This library provides a schema handler for `\"gs://\"` filenames.\n```\n<dependency>\u00a0 <groupId>org.apache.beam</groupId>\u00a0 <artifactId>beam-sdks-java-io-google-cloud-platform</artifactId>\u00a0 <version>${beam.version}</version></dependency>\n```\n```\napache-beam[gcp]==VERSION\n```\n```\nimport _ \"github.com/apache/beam/sdks/v2/go/pkg/beam/io/filesystem/gcs\"\n```\nFor more information, see [Install the Apache Beam SDK](/dataflow/docs/guides/installing-beam-sdk) .\n## Parallelism\nThe `TextIO` and `AvroIO` connectors support two levels of parallelism:\n- Individual files are keyed separately, so that multiple workers can read them.\n- If the files are uncompressed, the connector can read sub-ranges of each file separately, leading to a very high level of parallelism. This splitting is only possible if each line in the file is a meaningful record. For example, it's not available by default for JSON files.## Performance\nThe following table shows performance metrics for reading from Cloud Storage. The workloads were run on one `e2-standard2` worker, using the Apache Beam SDK 2.49.0 for Java. They did not use Runner v2.\n| 100 M records | 1 kB | 1 column | Throughput (bytes) | Throughput (elements)  |\n|:----------------------------------|:---------------------|:----------------------------|\n| Read        | 320 MBps    | 320,000 elements per second |\nThese metrics are based on simple batch pipelines. They are intended to compare performance between I/O connectors, and are not necessarily representative of real-world pipelines. Dataflow pipeline performance is complex, and is a function of VM type, the data being processed, the performance of external sources and sinks, and user code. Metrics are based on running the Java SDK, and aren't representative of the performance characteristics of other language SDKs. For more information, see [Beam IO Performance](https://beam.apache.org/performance/) .\n## Best practices\n- Avoid using [watchForNewFiles](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/TextIO.Read.html#watchForNewFiles-org.joda.time.Duration-org.apache.beam.sdk.transforms.Watch.Growth.TerminationCondition-) with Cloud Storage. This approach scales poorly for large production pipelines, because the connector must keep a list of seen files in memory. The list can't be flushed from memory, which reduces the working memory of workers over time. Consider using [Pub/Sub notifications for Cloud Storage](/storage/docs/pubsub-notifications) instead. For more information, see [File processing patterns](https://beam.apache.org/documentation/patterns/file-processing/) .\n- If both the filename and the file contents are useful data, use the [FileIO](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/FileIO.html) class to read filenames. For example, a filename might contain metadata that is useful when processing the data in the file. For more information, see [Accessing filenames](https://beam.apache.org/documentation/patterns/file-processing/) . The [FileIO documentation](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/FileIO.html) also shows an example of this pattern.## What's next\n- Read the [TextIO](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/io/TextIO.html) API documentation.\n- See the list of [Google-provided templates](/dataflow/docs/guides/templates/provided-templates) .", "guide": "Dataflow"}