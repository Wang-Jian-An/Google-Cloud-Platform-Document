{"title": "Dataflow - Create a Dataflow pipeline using Java", "url": "https://cloud.google.com/dataflow/docs/quickstarts/create-pipeline-java", "abstract": "# Dataflow - Create a Dataflow pipeline using Java\n# Create a Dataflow pipeline using Java\nThis document shows you how to set up your Google Cloud project, create an example pipeline built with the Apache Beam SDK for Java, and run the example pipeline on the Dataflow service. The pipeline reads a text file from Cloud Storage, counts the number of unique words in the file, and then writes the word counts back to Cloud Storage. For an introduction to the WordCount pipeline, see the [How to use WordCount in Apache Beam](https://www.youtube.com/watch?v=RTIOW1fIhkM) video.\nThis tutorial requires Maven, but it's also possible to convert the example project from Maven to Gradle. To learn more, see [ Optional: Convert from Maven to Gradle](https://beam.apache.org/get-started/quickstart-java/#optional-convert-from-maven-to-gradle) .To follow step-by-step guidance for this task directly in the Google Cloud console, click **Guide me** :\n [Guide me](https://console.cloud.google.com/?walkthrough_id=dataflow--quickstart-beam--quickstart-beam-java) ", "content": "## Before you begin- Grant roles to your Compute Engine default service account. Run the following command once  for each of the following IAM roles:- `roles/dataflow.admin`\n- `roles/dataflow.worker`\n- `roles/storage.objectAdmin`\n```\ngcloud projects add-iam-policy-binding PROJECT_ID --member=\"serviceAccount:PROJECT_NUMBER-compute@developer.gserviceaccount.com\" --role=SERVICE_ACCOUNT_ROLE\n```- Replace``with your project ID.\n- Replace``with your project number.  To find your project number, see [Identify projects](/resource-manager/docs/creating-managing-projects#identifying_projects) or use the [gcloud projects describe](/sdk/gcloud/reference/projects/describe) command.\n- Replace``with each individual role.\n- Create a Cloud Storage bucket and configure it as follows:- Set the storage class to`S`(Standard).\n- Set the storage location to the following:`US`(United States).\n- Replace``with     a unique bucket name. Don't include sensitive information in the   bucket name because the bucket namespace is global and publicly visible.\n```\ngcloud storage buckets create gs://BUCKET_NAME --default-storage-class STANDARD --location US\n```\n- Copy the following, as you need them in a later section:- Your Cloud Storage bucket name.\n- Your Google Cloud project ID. To find this ID, see [Identifying projects](/resource-manager/docs/creating-managing-projects#identifying_projects) .\n- Download and install the [Java Development Kit (JDK)](https://www.oracle.com/java/technologies/javase-jdk11-downloads.html) version 11. (Dataflow continues to support version 8.) Verify that the [JAVA_HOME](https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/envvars001.html) environment variable is set and points to your JDK installation.\n- Download and install [Apache Maven](https://maven.apache.org/download.cgi) , following Maven's [installation guide](https://maven.apache.org/install.html) for your specific operating system.\n## Get the pipeline codeThe [ Apache Beam SDK](https://beam.apache.org/get-started/beam-overview/) is an open source programming model for data processing pipelines. You define these pipelines with an Apache Beam program and can choose a runner, such as Dataflow, to run your pipeline.- In your shell or terminal, use the [Maven Archetype Plugin](https://maven.apache.org/archetype/maven-archetype-plugin/) to create a Maven project on your computer that  contains the Apache Beam SDK's`WordCount`examples:```\nmvn archetype:generate \\\n -DarchetypeGroupId=org.apache.beam \\\n -DarchetypeArtifactId=beam-sdks-java-maven-archetypes-examples \\\n -DarchetypeVersion=2.54.0 \\\n -DgroupId=org.example \\\n -DartifactId=word-count-beam \\\n -Dversion=\"0.1\" \\\n -Dpackage=org.apache.beam.examples \\\n -DinteractiveMode=false\n```The command creates a new directory called `word-count-beam` under your current directory. The `word-count-beam` directory contains a simple `pom.xml` file and a series of example pipelines that count words in text files.\n- Verify that your`word-count-beam`directory contains the`pom.xml`file:\n```\ncd word-count-beam/\nls\n```\nThe output is the following:\n```\npom.xml src\n``````\ncd word-count-beam/\ndir\n```\nThe output is the following:\n```\npom.xml src\n```\n- Verify that your Maven project contains the example pipelines:\n```\nls src/main/java/org/apache/beam/examples/\n```\nThe output is the following:\n```\nDebuggingWordCount.java WindowedWordCount.java common\nMinimalWordCount.java WordCount.java\n``````\ndir src/main/java/org/apache/beam/examples/\n```\nThe output is the following:\n```\nDebuggingWordCount.java WindowedWordCount.java common\nMinimalWordCount.java WordCount.java\n```\nFor a detailed introduction to the Apache Beam concepts that are used in these examples, see the [Apache Beam WordCount Example](https://beam.apache.org/get-started/wordcount-example/) . The instructions in the next sections use [WordCount.java](https://github.com/apache/beam/blob/master/examples/java/src/main/java/org/apache/beam/examples/WordCount.java) .## Run the pipeline locally\n- In your shell or terminal, run the`WordCount`pipeline locally from your`word-count-beam`directory:```\nmvn compile exec:java \\\n -Dexec.mainClass=org.apache.beam.examples.WordCount \\\n -Dexec.args=\"--output=counts\"\n```The output files have the prefix `counts` and are written to the `word-count-beam` directory. They contain unique words from the input text and the number of occurrences of each word.\n## Run the pipeline on the Dataflow service\n- In your shell or terminal, build and run the`WordCount`pipeline on the Dataflow service from your`word-count-beam`directory:```\nmvn -Pdataflow-runner compile exec:java \\\n -Dexec.mainClass=org.apache.beam.examples.WordCount \\\n -Dexec.args=\"--project=PROJECT_ID \\\n --gcpTempLocation=gs://BUCKET_NAME/temp/ \\\n --output=gs://BUCKET_NAME/output \\\n --runner=DataflowRunner \\\n --region=REGION\"\n```Replace the following:- ``: your Google Cloud project ID\n- ``: the name of your Cloud Storage bucket\n- ``: a [Dataflow region](/dataflow/docs/resources/locations) , like`us-central1`\n **Note:** \n- To specify a [user-managed worker service account](/dataflow/docs/concepts/security-and-permissions#user-managed) , include the`--serviceAccount` [pipeline option](/dataflow/docs/reference/pipeline-options) . User-managed worker service accounts are recommended for production workloads. If you don't specify a worker service account when you create a job, Dataflow uses the [Compute Engine default service account](/dataflow/docs/concepts/security-and-permissions#default-service-account) .\n- Unless specified through the`network`option, the Dataflow runner runs jobs in the`default`Virtual Private Cloud network.## View your results\n- In the Google Cloud console, go to the Dataflow **Jobs** page. [Go to  Jobs](https://console.cloud.google.com/dataflow/jobs) The **Jobs** page shows the details of all the available jobs, including the status. The **wordcount** job's **Status** is **Running** at first, and then updates to **Succeeded** .\n- In the Google Cloud console, go to the Cloud Storage **Buckets** page. [Go to Buckets](https://console.cloud.google.com/storage/browser) The **Buckets** page displays the list of all the storage buckets in your project.\n- Click the storage bucket that you created.The **Bucket details** page shows the output files and staging files that your Dataflow job created.\n## Clean upTo avoid incurring charges to your Google Cloud account for   the resources used on this page, delete the Google Cloud project with the   resources.\n### Delete the projectThe easiest way to eliminate billing is to delete the Google Cloud project that you created for the quickstart.- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n### Delete the individual resourcesIf you want to keep the Google Cloud project that you used in this quickstart, then delete the individual resources:- In the Google Cloud console, go to the Cloud Storage **Buckets** page. [Go to Buckets](https://console.cloud.google.com/storage/browser) \n- Click the checkbox for the bucket that you want to delete.\n- To delete the bucket,  clickdelete **Delete** , and then follow the  instructions.\n- Revoke the roles that you granted to the Compute Engine default service account. Run the following command once for each of the following IAM roles:- `roles/dataflow.admin`\n- `roles/dataflow.worker`\n- `roles/storage.objectAdmin`\n```\ngcloud projects remove-iam-policy-binding PROJECT_ID \\\u00a0 \u00a0 --member=serviceAccount:PROJECT_NUMBER-compute@developer.gserviceaccount.com \\\u00a0 \u00a0 --role=SERVICE_ACCOUNT_ROLE\n```\n- Optional: Revoke the authentication credentials that you created, and delete the local   credential file.```\ngcloud auth application-default revoke\n```\n- Optional: Revoke credentials from the gcloud CLI.```\ngcloud auth revoke\n```\n## What's next\n- Learn about [the Apache Beam programming model](/dataflow/docs/concepts/beam-programming-model) .\n- Learn how to [use Apache Beam to build pipelines](/dataflow/docs/guides/use-beam) .\n- Work through [the WordCount and Mobile Gaming examples](/dataflow/docs/samples/beam-samples) .", "guide": "Dataflow"}