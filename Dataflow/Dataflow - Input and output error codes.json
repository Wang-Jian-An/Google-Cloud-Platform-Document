{"title": "Dataflow - Input and output error codes", "url": "https://cloud.google.com/dataflow/docs/guides/input-and-output-error-codes", "abstract": "# Dataflow - Input and output error codes\nThe I/O metric charts use [canonical error codes](/apis/design/errors#handling_errors) . If these error codes persist in your sources and sinks, refer to the following list for potential causes and actions you can take.\n- `RESOURCE_EXHAUSTED` . The project might have run out of [resource quota](/compute/quotas) for the service the source or sink is using.If the error occurs occasionally or when the **Requests per sec chart** indicates a high volume of requests being made, then this might indicate that you have reached an [API rate limiting quota](/service-infrastructure/docs/rate-limiting) and need to increase the quota.\n- `DEADLINE_EXCEEDED` . Source or sink might have timed out reading or writing a large batch of data. Check the latency chart and worker logs. If the error persists, [contact support](/support-hub) .\n- `INVALID_ARGUMENT` . Parameters specified to the source or sink might be malformed (such as a Pub/Sub topic). Check configuration of the source or sink, and check the worker logs.\n- `FAILED_PRECONDITION` . Check configuration of the source or sink, and check the worker logs. This could also indicate a bug.\n- `OUT_OF_RANGE` . Check that the resource being used by the source or sink exists (such as a Pub/Sub topic or subscription).\n- `UNAUTHENTICATED` . Check that the [Dataflow service account](/dataflow/docs/concepts/security-and-permissions#cloud_dataflow_service_account) has [Identity and Access Management](/resource-manager/docs/access-control-org) permissions to the specific service and relevant [APIs are enabled](/endpoints/docs/openapi/enable-api) for the project.\n- `PERMISSION_DENIED` . Check that the [Dataflow service account](/dataflow/docs/concepts/security-and-permissions#cloud_dataflow_service_account) has [Identity and Access Management](/resource-manager/docs/access-control-org) permissions to the specific service and relevant [APIs are enabled](/endpoints/docs/openapi/enable-api) for the project.\n- `NOT_FOUND` . Check that the entities being used by the source or sink exist (such as a Pub/Sub topic or subscription).\n- `ABORTED` . Service might not be properly handling the source or sinks attempts to read or write data. If the error persists, [contact support](/support-hub) .\n- `ALREADY_EXISTS` . I/O might be trying to create an entity which already exists (such as a Pub/Sub topic or subscription). If the error persists, [contact support](/support-hub) .\n- `CANCELLED` . This can occur when a Dataflow worker is shut down or source or sink logic intentionally decides to cancel attempts to read or write data.\n- `DATALOSS` . Indicates unrecoverable data loss or corruption occurred. You might want to create a new dataset for your sources and rerun the Dataflow job.You might also see if there are any backup and restoring instructions available for the underlying Google Cloud service.\n- `UNKNOWN` . Service might be down. Check for updates on [Cloud Status Dashboard for more information](https://status.cloud.google.com/) .\n- `INTERNAL` . Service might be down. Check for updates on [Cloud Status Dashboard for more information](https://status.cloud.google.com/) .\n- `UNAVAILABLE` . Service might be down. Check for updates on [Cloud Status Dashboard for more information](https://status.cloud.google.com/) .\n- `UNIMPLEMENTED` . The source or sink attempted to use the service in an invalid way. Your pipeline might be misconfigured. If the error persists, [contact support](/support-hub) ", "content": ".", "guide": "Dataflow"}