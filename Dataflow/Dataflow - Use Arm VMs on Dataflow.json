{"title": "Dataflow - Use Arm VMs on Dataflow", "url": "https://cloud.google.com/dataflow/docs/guides/use-arm-vms", "abstract": "# Dataflow - Use Arm VMs on Dataflow\nThis page explains how to use Arm VMs as workers for batch and streaming Dataflow jobs.\nYou can use the [Tau T2A machine series](/compute/docs/general-purpose-machines#t2a_machines) of Arm processors to run Dataflow jobs. Because Arm architecture is optimized for power efficiency, using these VMs yields better price for performance for some workloads. For more information about Arm VMs, see [Arm VMs on Compute](/compute/docs/instances/arm-on-compute) .\n", "content": "## Requirements\n- The following Apache Beam SDKs support Arm VMs:- Apache Beam Java SDK versions 2.50.0 or later\n- Apache Beam Python SDK versions 2.50.0 or later\n- Apache Beam Go SDK versions 2.50.0 or later\n- Select a region where Tau T2A machines are available. For more information, see [Available regions and zones](/compute/docs/regions-zones#available) .\n- Use [Runner v2](/dataflow/docs/runner-v2) to run the job.\n- Streaming jobs must use [Streaming Engine](/dataflow/docs/streaming-engine) .## Limitations\n- All [Tau T2A limitations](/compute/docs/general-purpose-machines#t2a_limitations) apply.\n- [GPUs](/dataflow/docs/gpu) are not supported.\n- [Cloud Profiler](/dataflow/docs/guides/profiling-a-pipeline) is not supported.\n- [Dataflow Prime](/dataflow/docs/guides/enable-dataflow-prime) is not supported.\n- Receiving worker VM metrics from [Cloud Monitoring](/dataflow/docs/guides/using-cloud-monitoring#receive_worker_vm_metrics_from_the_agent) is not supported.\n- [Container image pre-building](/dataflow/docs/guides/build-container-image#prebuild) is not supported.## Run a job using Arm VMs\nTo use Arm VMs, set the following pipeline option.\nSet the `workerMachineType` pipeline option and specify a [Tau T2A machine type](/compute/docs/general-purpose-machines#t2a_machines) .\nFor more information about setting pipeline options, see [Set Dataflow pipeline options](/dataflow/docs/guides/setting-pipeline-options) .\nSet the `machine_type` pipeline option and specify a [Tau T2A machine type](/compute/docs/general-purpose-machines#t2a_machines) .\nFor more information about setting pipeline options, see [Set Dataflow pipeline options](/dataflow/docs/guides/setting-pipeline-options) .\nSet the `worker_machine_type` pipeline option and specify a [Tau T2A machine type](/compute/docs/general-purpose-machines#t2a_machines) .\nFor more information about setting pipeline options, see [Set Dataflow pipeline options](/dataflow/docs/guides/setting-pipeline-options) .\n## Use multi-architecture container images\nIf you use a custom container in Dataflow, the container must match the architecture of the worker VMs. If you plan to use a custom container on ARM VMs, we recommend building a multi-architecture image. For more information, see [Build a multi-architecture container image](/dataflow/docs/guides/multi-architecture-container) .\n## Pricing\nYou are billed for Dataflow compute resources. Dataflow pricing is independent of the machine type family. For more information, see [Dataflow pricing](/dataflow/pricing) .\n## What's next\n- [Set Dataflow pipeline options](/dataflow/docs/guides/setting-pipeline-options) \n- [Use custom containers in Dataflow](/dataflow/docs/guides/using-custom-containers)", "guide": "Dataflow"}