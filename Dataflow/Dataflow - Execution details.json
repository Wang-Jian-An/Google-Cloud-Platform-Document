{"title": "Dataflow - Execution details", "url": "https://cloud.google.com/dataflow/docs/concepts/execution-details", "abstract": "# Dataflow - Execution details\nDataflow provides an **Execution details** tab in its web-based monitoring user interface. This tool can help you optimize performance for your jobs and diagnose why your job might be slow or stuck. This document is for any Dataflow user who needs to inspect the execution details of their Dataflow jobs.\nThis page provides a high-level summary of the execution details feature and its user interface layout. For troubleshooting details, read [Using the Execution details tab](/dataflow/docs/guides/troubleshooting-your-pipeline#ExecutionDetails) .\n", "content": "## Terminology\nTo use execution details effectively, you need to understand how the following key concepts apply to Dataflow jobs:\n### Dataflow terminology\n- **Fusion optimization** : The process of Dataflow fusing multiple steps or transforms. This optimizes user-submitted pipelines. For more information, read [Fusion optimization](/dataflow/docs/pipeline-lifecycle#fusion_optimization) .\n- **Stages** : The unit of fused steps in Dataflow pipelines.\n- **Last stage** : The final node in Dataflow pipelines. A pipeline can have multiple final nodes.\n### Batch terminology\n- **Critical paths** : The sequence of stages of a pipeline that contribute to the overall job runtime. For example, this sequence excludes the following stages:- Branches of the pipeline that finished earlier than the overall job.\n- Inputs that did not delay downstream processing.\n- **Workers** : Compute Engine VM instances running a Dataflow job.\n- **Work items** : The units of work that corresponds to a [bundle](https://beam.apache.org/documentation/runtime/model/#bundling-and-persistence) selected by Dataflow.\n### Streaming terminology\n- **Data Freshness** : The amount of time between real time and the output watermark. More information can be found at [Data freshness (streaming pipelines only)](/dataflow/docs/guides/using-monitoring-intf#data_freshness_streaming_pipelines_only) .## When to use execution details\nThe following are common scenarios for using execution details when running Dataflow jobs:\n- Your pipeline is stuck and you want to troubleshoot the issue.\n- Your pipeline is slow and you want to target pipeline optimization.\n- Nothing needs to be fixed, but you want to see the execution details of your pipeline to understand your job.## Enable execution details\nThe **Stage Workflow** view is automatically enabled for all batch and streaming jobs. Batch and streaming jobs also have a **Stage progress** view, and batch jobs have an additional **Worker progress** view.\nThis feature does not cause additional CPU, network, etc. usage for your VMs. The execution details are collected by Dataflow's backend monitoring system which does not affect the performance of the job.\nOnce you launch your job, you can view the **Execution details** tab using the Dataflow monitoring UI. For more information, read [Accessing theDataflow monitoring interface](/dataflow/docs/guides/using-monitoring-intf#accessing_the_monitoring_interface) .\n## Use the Execution details tab\nThe **Execution details** tab includes four views: **Stage progress** , **Stage info panel** (within **Stage progress** ), **Stage workflow** , and **Workerprogress** . This section walks you through each view and provides examples of successful and unsuccessful Dataflow jobs.\n### Stage progress for Batch jobs\nThe **Stage progress** view for Batch jobs shows the execution stages of the job, arranged by their start and end times. The length of time is represented with a bar. For example, you can visually identify the longest running stages of a pipeline by finding the longest bar.\nBelow each of the bars, you can find a sparkline that shows the progress of the stage over time. To highlight the stages that contributed to the overall runtime of the job, click the **Critical path** toggle. Additionally, you can use the \"Filter Stages\" dropdown to only select the stages you are interested in.### Stage progress for Streaming jobs\nThe **Stage progress** view for Streaming jobs can be broken down into two sections. The top half of the view shows a chart representing the Data Freshness for each execution stage of the job. Hovering over the chart provides the Data Freshness value at that specific instant of time. The bottom half of the view shows the execution stages of the job, arranged in a topological order, where stages with no descendant stages are shown at the top and their descendents are listed underneath. This view makes it easier to identify stages of a pipeline which take longer than they should. The bars are sized relative to the longest Data Freshness for the entire time domain.\nStreaming jobs run until they are cancelled, drained or updated. The time picker above the chart can be used to scope down the domain to a more useful time range. Additionally, you can use the \"Filter Stages\" dropdown to only select the stages you are interested in.\nThe **Stage progress** view makes it easier to identify when your streaming job is slow or stuck in two different ways:\n- The Data Freshness by Stages chart includes anomaly detection, which will automatically display windows of time when the Data Freshness looks unhealthy. The chart will highlight \"potential stuckness\" when Data Freshness exceeds the 99th percentile for the selected time window. Likewise, the chart will highlight \"potential slowness\" when Data Freshness exceeds the 95th percentile.\n- Bottlenecks can be detected by first hovering over a time in the chart which looks abnormal. Once hovered, longer bars indicate slower stages. Alternatively, the x-axis of the chart can be clicked to display the data at that instance of time. A common approach to finding the stage causing the stuckness/slowness is to find the most upstream (topmost) or the most downstream (bottommost) stage causing the Data Freshness to spike. This approach does not suit all scenarios and further debugging might be required to pinpoint the exact cause.### Stage info panel\nThe **Stage info panel** displays a list of steps associated with a fused stage, ranked by descending wall time. The panel opens on the right side of the screen. To open the panel, hover over one of the bars in the **Stage progress** view and click **View details** .### Stage workflow\n**Stage workflow** shows the execution stages of the job, represented as a workflow graph. To show only the stages that directly contributed to the overall runtime of the job, click the **Critical path** toggle.### Worker progress\nFor batch jobs, **Worker progress** shows the workers for a particular stage. This view is not available for streaming jobs.\nEach bar maps to a work item scheduled to a worker. A sparkline that tracks CPU utilization on a worker is located below each worker, making it easier to spot underutilization issues.\nDue to the density of this visualization, you must filter this view by pre-selecting a stage. First, identify a stage in the **Stage progress** view. Hover over that stage and click **View workers** to enter the **Worker progress** view.\n## What's next\n- Learn more about [Using the Execution details tab for troubleshooting](/dataflow/docs/guides/troubleshoot-slow-jobs#batch) .\n- Read about the different components of [Dataflow'sweb-based monitoring user interface](/dataflow/docs/guides/using-monitoring-intf) .", "guide": "Dataflow"}