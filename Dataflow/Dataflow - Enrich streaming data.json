{"title": "Dataflow - Enrich streaming data", "url": "https://cloud.google.com/dataflow/docs/guides/enrichment", "abstract": "# Dataflow - Enrich streaming data\nApache Beam simplifies the data enrichment workflow by providing a turnkey enrichment transform that you can add to your pipeline. This page explains how to use the Apache Beam enrichment transform to enrich your streaming data.\nWhen you enrich data, you augment the raw data from one source by adding related data from a second source. The additional data can come from a variety of sources, such as [Bigtable](/bigtable/docs/overview) or [BigQuery](/bigquery/docs/introduction) . The Apache Beam enrichment transform uses a key-value lookup to connect the additional data to the raw data.\nThe following examples provide some cases where data enrichment is useful:\n- You want to create an ecommerce pipeline that captures user activities from a website or app and provides customized recommendations. The transform incorporates the activities into your pipeline data so that you can provide the customized recommendations.\n- You have user data that you want to join with geographical data to do geography-based analytics.\n- You want to create a pipeline that gathers data from internet-of-things (IOT) devices that send out telemetry events.", "content": "## Benefits\nThe enrichment transform has the following benefits:\n- Transforms your data without requiring you to write complex code or manage underlying libraries.\n- Provides a prebuilt source handler for Bigtable ( [BigTableEnrichmentHandler](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.enrichment_handlers.bigtable.html#apache_beam.transforms.enrichment_handlers.bigtable.BigTableEnrichmentHandler) ) that lets you enrich your data by using a Bigtable source without passing configuration details.\n- Uses client-side throttling to manage rate limiting the requests. The requests are exponentially backed off with a default retry strategy. You can configure rate limiting to suit your use case.## Support and limitations\nThe enrichment transform has the following requirements:\n- Available for batch and streaming pipelines that use the Apache Beam Python SDK versions 2.54.0 and later.\n- Dataflow jobs must use [Runner v2](/dataflow/docs/runner-v2) .## Use the enrichment transform\nTo use the enrichment transform, include the following code in your pipeline:\n```\nimport apache_beam as beamfrom apache_beam.transforms.enrichment import Enrichmentfrom apache_beam.transforms.enrichment_handlers.bigtable import BigTableEnrichmentHandlerbigtable_handler = BigTableEnrichmentHandler(...)with beam.Pipeline() as p:\u00a0 output = (p\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \"Create\" >> beam.Create(data)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \"Enrich with Bigtable\" >> Enrichment(bigtable_handler)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\n```\nBecause the enrichment transform performs a cross join by default, design the custom join to enrich the input data. This design ensures that the join includes only the specified fields.\nIn the following example, `left` is the input element of the enrichment transform, and `right` is data fetched from an external service for that input element.\n```\ndef custom_join(left: Dict[str, Any], right: Dict[str, Any]):\u00a0 enriched = {}\u00a0 enriched['FIELD_NAME'] = left['FIELD_NAME']\u00a0 ...\u00a0 return beam.Row(**enriched)\n```\n### Parameters\nTo use the enrichment transform, the `EnrichmentHandler` parameter is required.\nYou can also use a configuration parameter to specify a `lambda` function for a join function, a timeout, a throttler, or a repeater (retry strategy). The following configuration parameters are available:\n- `join_fn`: A`lambda`function that takes dictionaries as input and returns an enriched row (`Callable[[Dict[str, Any], Dict[str, Any]], beam.Row]`). The enriched row specifies how to join the data fetched from the API. Defaults to a cross join.\n- `timeout`: The number of seconds to wait for the request to be completed by the API before timing out. Defaults to 30 seconds.\n- `throttler`: Specifies the throttling mechanism. The only supported option is default client-side adaptive throttling.\n- `repeater`: Specifies the retry strategy when errors like`TooManyRequests`and`TimeoutException`occur. Defaults to`ExponentialBackOffRepeater`.## What's next\n- For more examples, see [Enrichment transform](https://beam.apache.org/documentation/transforms/python/elementwise/enrichment) in the Apache Beam transform catalog.\n- Run an [interactive notebook in Colab](https://colab.sandbox.google.com/github/apache/beam/blob/master/examples/notebooks/beam-ml/bigtable_enrichment_transform.ipynb) .", "guide": "Dataflow"}