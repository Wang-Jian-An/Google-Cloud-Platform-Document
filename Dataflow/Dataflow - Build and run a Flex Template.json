{"title": "Dataflow - Build and run a Flex Template", "url": "https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates", "abstract": "# Dataflow - Build and run a Flex Template\nDataflow [Flex Templates](/dataflow/docs/concepts/dataflow-templates) allow you to package a Dataflow pipeline for deployment. This tutorial shows you how to build a Dataflow Flex Template and then run a Dataflow job using that template.", "content": "## Objectives\n- Build a Dataflow Flex Template.\n- Use the template to run a Dataflow job.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Dataflow](/dataflow/pricing) \n- [Cloud Storage](/storage/pricing) \n- [Artifact Registry](/artifact-registry/pricing) \n- [Cloud Build](/build/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin- Grant roles to your Compute Engine default service account. Run the following command once for each of the following IAM roles:- `roles/dataflow.admin`\n- `roles/dataflow.worker`\n- `roles/storage.objectAdmin`\n- `roles/artifactregistry.reader`\n```\ngcloud projects add-iam-policy-binding PROJECT_ID --member=\"serviceAccount:PROJECT_NUMBER-compute@developer.gserviceaccount.com\" --role=SERVICE_ACCOUNT_ROLE\n```Replace the following:- ``: your project ID\n- ``your [project number](/resource-manager/docs/creating-managing-projects#identifying_projects) \n- ``: each individual role\n## Prepare the environmentInstall the SDK and any requirements for your development environment.\n- Download and install the [Java Development Kit (JDK)](http://www.oracle.com/technetwork/java/javase/downloads/index.html) version 11. Verify that the [JAVA_HOME](https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/envvars001.html) environment variable is set and points to your JDK installation.\n- Download and install [Apache Maven](http://maven.apache.org/download.cgi) by following Maven's [installation guide](http://maven.apache.org/install.html) for your specific operating system.\nInstall the [Apache Beam SDK for Python](/dataflow/docs/guides/installing-beam-sdk#python) .\nUse Go's [Download and install guide](https://go.dev/doc/install) to download and install Go for your specific operating system. To learn which Go runtime environments are supported by Apache Beam, see [Apache Beam runtime support](/dataflow/docs/support/beam-runtime-support) .Download the code sample.\n- Clone the [java-docs-samples repository](https://github.com/GoogleCloudPlatform/java-docs-samples) .```\ngit clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n```\n- Navigate to the code sample for this tutorial.```\ncd java-docs-samples/dataflow/flex-templates/getting_started\n```\n- Build the Java project into an Uber JAR file.```\nmvn clean package\n```This Uber JAR file has all the dependencies embedded in it. You can run this file as a standalone application with no external dependencies on other libraries.\n- Clone the [python-docs-samples repository](https://github.com/GoogleCloudPlatform/python-docs-samples) .```\ngit clone https://github.com/GoogleCloudPlatform/python-docs-samples.git\n```\n- Navigate to the code sample for this tutorial.```\ncd python-docs-samples/dataflow/flex-templates/getting_started\n```\n- Clone the [golang-samples repository](https://github.com/GoogleCloudPlatform/golang-samples) .```\ngit clone https://github.com/GoogleCloudPlatform/golang-samples.git\n```\n- Navigate to the code sample for this tutorial.```\ncd golang-samples/dataflow/flex-templates/wordcount\n```\n- Compile the Go binary.```\nGOOS=linux GOARCH=amd64 go build -o wordcount .\n```\n## Create a Cloud Storage bucketUse the [gcloud storage buckets create command](/sdk/gcloud/reference/storage/buckets/create) to create a Cloud Storage bucket:\n```\ngcloud storage buckets create gs://BUCKET_NAME\n```\nReplace `` with a name for your Cloud Storage bucket. Cloud Storage bucket names must be globally unique and meet the [bucket naming requirements](/storage/docs/buckets#naming) .## Create an Artifact Registry repositoryCreate an Artifact Registry repository where you will push the Docker container image for the template.- Use the [gcloud artifacts repositories create](/sdk/gcloud/reference/artifacts/repositories/create) command to create a new Artifact Registry repository.```\ngcloud artifacts repositories create REPOSITORY \\\u00a0--repository-format=docker \\\u00a0--location=LOCATION\n```Replace the following:- : a name for your repository. Repository names must be unique for each repository location in a project.\n- : the regional or multi-regional [location](/artifact-registry/docs/repositories/repo-locations) for the repository.\n- Use the [gcloud auth configure-docker](/sdk/gcloud/reference/auth/configure-docker) command to configure Docker to authenticate requests for Artifact Registry. This command updates your Docker configuration, so that you can connect with Artifact Registry to push images.```\ngcloud auth configure-docker LOCATION-docker.pkg.dev\n```\nFlex Templates can also use images stored in private registries. For more information, see [Use an image from a private registry](/dataflow/docs/guides/templates/configuring-flex-templates#use_an_image_from_a_private_registry) .## Build the Flex TemplateIn this step, you use the [gcloud dataflow flex-template build](/sdk/gcloud/reference/dataflow/flex-template/build) command to build the Flex Template.\nA Flex Template consists of the following components:- A Docker container image that packages your pipeline code.\n- A template specification file. This file is a JSON document that contains the location of the container image plus metadata about the template, such as pipeline parameters.```\ngcloud dataflow flex-template build gs://BUCKET_NAME/getting_started-java.json \\\u00a0--image-gcr-path \"LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/getting-started-java:latest\" \\\u00a0--sdk-language \"JAVA\" \\\u00a0--flex-template-base-image JAVA11 \\\u00a0--metadata-file \"metadata.json\" \\\u00a0--jar \"target/flex-template-getting-started-1.0.jar\" \\\u00a0--env FLEX_TEMPLATE_JAVA_MAIN_CLASS=\"com.example.dataflow.FlexTemplateGettingStarted\"\n```\nReplace the following:- : the name of the Cloud Storage bucket that you created earlier\n- : the location\n- : the Google Cloud project ID\n- : the name of the Artifact Registry repository that you created earlier\n```\ngcloud dataflow flex-template build gs://BUCKET_NAME/getting_started-py.json \\\u00a0--image-gcr-path \"LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/getting-started-python:latest\" \\\u00a0--sdk-language \"PYTHON\" \\\u00a0--flex-template-base-image \"PYTHON3\" \\\u00a0--metadata-file \"metadata.json\" \\\u00a0--py-path \".\" \\\u00a0--env \"FLEX_TEMPLATE_PYTHON_PY_FILE=getting_started.py\" \\\u00a0--env \"FLEX_TEMPLATE_PYTHON_REQUIREMENTS_FILE=requirements.txt\"\n```\nReplace the following:- : the name of the Cloud Storage bucket that you created earlier\n- : the location\n- : the Google Cloud project ID\n- : the name of the Artifact Registry repository that you created earlier\n- Use the [gcloud builds submit command](/sdk/gcloud/reference/builds/submit) to build the Docker image using a Dockerfile with Cloud Build. This command builds the file and pushes it to your Artifact Registry repository.```\ngcloud builds submit --tag LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/dataflow/wordcount-go:latest .\n```Replace the following:- : the location\n- : the Google Cloud project ID\n- : the name of the Artifact Registry repository that you created earlier\n- Use the [gcloud dataflow flex-template build](/sdk/gcloud/reference/dataflow/flex-template/build) command to create a Flex Template named `wordcount-go.json` in your Cloud Storage bucket.```\ngcloud dataflow flex-template build gs://BUCKET_NAME/samples/dataflow/templates/wordcount-go.json \\\u00a0 --image \"LOCATION-docker.pkg.dev/PROJECT_ID/REPOSITORY/dataflow/wordcount-go:latest\" \\\u00a0 --sdk-language \"GO\" \\\u00a0 --metadata-file \"metadata.json\"\n```Replace with the name of the Cloud Storage bucket that you created earlier.\n## Run the Flex TemplateIn this step, you use the template to run a Dataflow job.\n- Use the [gcloud dataflow flex-template run command](/sdk/gcloud/reference/dataflow/flex-template/run) to run a Dataflow job that uses the Flex Template.```\ngcloud dataflow flex-template run \"getting-started-`date +%Y%m%d-%H%M%S`\" \\\u00a0--template-file-gcs-location \"gs://BUCKET_NAME/getting_started-java.json\" \\\u00a0--parameters output=\"gs://BUCKET_NAME/output-\" \\\u00a0--region \"REGION\"\n```Replace the following:- : the name of the Cloud Storage bucket that you created earlier\n- : the region\n- To view the status of the Dataflow job in the Google Cloud console, go to the Dataflow **Jobs** page. [Go to Jobs](https://console.cloud.google.com/dataflow/jobs) \nIf the job runs successfully, it writes the output to a file named `gs://` `` `/output--00000-of-00001.txt` in your Cloud Storage bucket.- Use the [gcloud dataflow flex-template run command](/sdk/gcloud/reference/dataflow/flex-template/run) to run a Dataflow job that uses the Flex Template.```\ngcloud dataflow flex-template run \"getting-started-`date +%Y%m%d-%H%M%S`\" \\\u00a0--template-file-gcs-location \"gs://BUCKET_NAME/getting_started-py.json\" \\\u00a0--parameters output=\"gs://BUCKET_NAME/output-\" \\\u00a0--region \"REGION\"\n```Replace the following:- : the name of the Cloud Storage bucket that you created earlier\n- : the region\n- To view the status of the Dataflow job in the Google Cloud console, go to the Dataflow **Jobs** page. [Go to Jobs](https://console.cloud.google.com/dataflow/jobs) \nIf the job runs successfully, it writes the output to a file named `gs://` `` `/output--00000-of-00001.txt` in your Cloud Storage bucket.- Use the [gcloud dataflow flex-template run command](/sdk/gcloud/reference/dataflow/flex-template/run) to run a Dataflow job that uses the Flex Template.```\ngcloud dataflow flex-template run \"wordcount-go-`date +%Y%m%d-%H%M%S`\" \\\u00a0--template-file-gcs-location \"gs://BUCKET_NAME/samples/dataflow/templates/wordcount-go.json\" \\\u00a0--parameters output=\"gs://BUCKET_NAME/samples/dataflow/templates/counts.txt\" \\\u00a0--region \"REGION\"\n```Replace the following:- : the name of the Cloud Storage bucket that you created earlier\n- : the region\n- To view the status of the Dataflow job in the Google Cloud console, go to the Dataflow **Jobs** page. [Go to Jobs](https://console.cloud.google.com/dataflow/jobs) \nIf the job runs successfully, it writes the output to a file named `gs://` `` `/samples/dataflow/templates/count.txt` in your Cloud Storage bucket.\n **Note:** If your job fails to run and the error message `A Timeout in polling error message` is displayed, see [Troubleshoot Flex Template timeouts](/dataflow/docs/guides/troubleshoot-templates) .## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- Delete a Google Cloud project:\n- ```\ngcloud projects delete PROJECT_ID\n```\n### Delete individual resources\n- Delete the Cloud Storage bucket and all the objects in the bucket.```\ngcloud storage rm gs://BUCKET_NAME --recursive\n```\n- Delete the Artifact Registry repository.```\ngcloud artifacts repositories delete REPOSITORY \\\u00a0 \u00a0 --location=LOCATION\n```\n- Revoke the roles that you granted to the Compute Engine default  service account. Run the following command once for each of the following  IAM roles:- `roles/dataflow.admin`\n- `roles/dataflow.worker`\n- `roles/storage.objectAdmin`\n- `roles/artifactregistry.reader`\n```\ngcloud projects remove-iam-policy-binding PROJECT_ID \\\u00a0 \u00a0 --member=serviceAccount:PROJECT_NUMBER-compute@developer.gserviceaccount.com \\\u00a0 \u00a0 --role=SERVICE_ACCOUNT_ROLE\n```\n- Optional: Revoke the authentication credentials that you created, and delete the local   credential file.```\ngcloud auth application-default revoke\n```\n- Optional: Revoke credentials from the gcloud CLI.```\ngcloud auth revoke\n```\n## What's next\n- Learn how to [configure Flex Templates](/dataflow/docs/guides/templates/configuring-flex-templates) .\n- See the list of [Google-provided templates](/dataflow/docs/guides/templates/provided-templates) .", "guide": "Dataflow"}