{"title": "Vertex AI - Add pipeline run to experiment", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Add pipeline run to experiment\nYou can use either the Google Cloud console or the Vertex AI SDK for Python to add a pipeline run to either an experiment or an .\nUse the following instructions to run an ML pipeline and associate the pipeline with  an experiment and, optionally, an experiment run using Google Cloud console. Experiment  runs can only be created through the Vertex AI SDK for Python  (see\n [Create and manage experiment runs](/vertex-ai/docs/experiments/create-manage-exp-run#vertex-ai-sdk-for-python) \n).\n- In the Google Cloud console, in the Vertex AI section, go  to the **Pipelines** page. [Go to Pipelines](https://console.cloud.google.com/vertex-ai/pipelines) \n- In the **Region** drop-down list, select the region that you want to   create a pipeline run in.\n- Click **add_box\n  Create run** to open the **Create pipeline run** pane.\n- Specify the following **Run** details.- In the **File** field, click **Choose** to open the file selector.    Navigate to the compiled pipeline JSON file that you want to run,    select the pipeline, and click **Open** .\n- The **Pipeline name** defaults to the name that you specified in the    pipeline definition. Optionally, specify a different **Pipeline name** .\n- Specify a **Run name** to uniquely identify this pipeline run.- To specify that this pipeline run uses a custom service account, a   customer-managed encryption key, or a peered VPC network, click **Advanced options** (Optional).Use the following instructions to configure advanced options such as a   custom service account.- To specify a,    select a service account from the **Service account** drop-down list.If you do not specify a service account,    Vertex AI Pipelines runs your pipeline using the default    Compute Engine service account.Learn more about [configuring a service account for use with   Vertex AI Pipelines](/vertex-ai/docs/pipelines/configure-project#service-account) .\n- To use a(CMEK),    select **Use a\n   customer-managed encryption key** . The **Select a customer-managed\n   key** drop-down list appears. In the **Select a customer-managed\n   key** drop-down list, select the key that you want to use.\n- To use a peered VPC network in this pipeline run, enter the VPC    network name in the **Peered VPC network** box.- Click **Continue** .The **Cloud Storage** location and **Pipeline parameters** pane appears.\n- Required: Enter the Cloud Storage output directory, for example: gs://.\n- Optional: Specify the parameters that you want to use for this pipeline run.\n- Click **Submit** to create your pipeline run.\n- After the Pipeline is submitted, it appears in the Pipeline's Google Cloud console  table.\n- In the row associated with your pipeline clickmore_vert **View more\u00a0>\u00a0Add to Experiment** \n- Select an existing Experiment or create a new one.\n- Optional: If Experiment runs are associated with the Experiment, they show up in the   drop-down. Select an existing Experiment run.\n- Click **Save** .\n- In the Google Cloud console, go to the **Experiments** page. [Go to Experiments](https://console.cloud.google.com/vertex-ai/experiments) .A list of experiments appears in the **Experiments** page.\n- Select the experiment you want to add your pipeline run to.A list of runs appears.\n- Select the runs you want to compare, then click **Compare** \n- Click the **Add run** button. A list of runs appears\n- Select the pipeline run you want to add. The run is added.\nThe following samples use the [PipelineJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob) API.This sample shows how to associate a pipeline run with an experiment. When you want to compare Pipeline runs, you should associate your pipeline run(s) to an experiment. See [init](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_init) in the Vertex AI SDK for Python reference documentation.#", "content": "## Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/log_pipeline_job_to_experiment_sample.py) \n```\ndef log_pipeline_job_to_experiment_sample(\u00a0 \u00a0 experiment_name: str,\u00a0 \u00a0 pipeline_job_display_name: str,\u00a0 \u00a0 template_path: str,\u00a0 \u00a0 pipeline_root: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 parameter_values: Optional[Dict[str, Any]] = None,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 pipeline_job = aiplatform.PipelineJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=pipeline_job_display_name,\u00a0 \u00a0 \u00a0 \u00a0 template_path=template_path,\u00a0 \u00a0 \u00a0 \u00a0 pipeline_root=pipeline_root,\u00a0 \u00a0 \u00a0 \u00a0 parameter_values=parameter_values,\u00a0 \u00a0 )\u00a0 \u00a0 pipeline_job.submit(experiment=experiment_name)\n```\n- `experiment_name`: Provide a name for your experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `pipeline_job_display_name`: The user-defined name of this Pipeline.\n- `template_path`: The path of PipelineJob or PipelineSpec JSON   or YAML file. It can be a local path or a Cloud Storage URI.   Example: \"gs://project.name\"\n- `pipeline_root`: The root of the pipeline outputs. Default to be   staging bucket.\n- `parameter_values`: The mapping from runtime parameter names to   its values that control the pipeline run.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\nThe sample provided includes associating a pipeline run with an .\nUse cases:- When doing local model training and then running evaluation on that model (evaluation is   done by using a pipeline). In this case you'd want to write the eval metrics from your   pipeline run to an ExperimentRun\n- When re-running the same pipeline multiple times. For example, if you change the input   parameters, or if one component fails and you need to run it again.\nWhen associating a pipeline run to an experiment run, parameters and metrics are not  automatically surfaced and need to be logged manually using the [logging APIs](/vertex-ai/docs/experiments/log-data) .\nNote: When the optional `resume` parameter is specified as `TRUE` ,  the previously started run resumes. When not specified, `resume` defaults to `FALSE` and a new run is created.\nSee [init](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_init) , [start_run](/python/docs/reference/aiplatform/latest/google.cloud.aiplatformm#google_cloud_aiplatform_start_run) , and [log](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log) in the Vertex AI SDK for Python reference documentation.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/log_pipeline_job_sample.py) \n```\ndef log_pipeline_job_sample(\u00a0 \u00a0 experiment_name: str,\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 pipeline_job: aiplatform.PipelineJob,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,):\u00a0 \u00a0 aiplatform.init(experiment=experiment_name, project=project, location=location)\u00a0 \u00a0 aiplatform.start_run(run=run_name, resume=True)\u00a0 \u00a0 aiplatform.log(pipeline_job=pipeline_job)\n```\n- `experiment_name`: Provide a name for your experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `run_name`: Specify a run name.\n- `pipeline_job`: A Vertex AI PipelineJob\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) ## View list of pipeline runs in Google Cloud console\n- In the Google Cloud console, in the Vertex AI section, go to the **Pipelines** page. [Go to the Pipelines page](https://console.cloud.google.com/vertex-ai/pipelines) \n- Check to be sure you are in the correct project.\n- A list of experiments and runs associated with your project's pipeline runs appears in the **Experiment** and **Experiment run** columns, respectively. \n## Codelab\n- [Make the Most of Experimentation: Manage Machine Learning Experiments with Vertex AI](https://codelabs.developers.google.com/vertex_experiments_pipelines_intro#0) This codelab involves using Vertex AI to build a pipeline that trains a custom Keras Model in TensorFlow. Vertex AI Experiments is used to track and compare experiment runs in order to identify which combination of hyperparameters results in the best performance.## What's next\n- [Log data to an experiment run](/vertex-ai/docs/experiments/log-data) ## Relevant notebook sample\n- [Compare pipeline runs](/vertex-ai/docs/experiments/user-journey/uj-compare-pipeline-runs)", "guide": "Vertex AI"}