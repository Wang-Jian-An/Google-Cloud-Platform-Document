{"title": "Documentation - Get online predictions from a custom trained model", "url": "https://cloud.google.com/distributed-cloud/hosted/docs/latest/gdch/overview", "abstract": "# Documentation - Get online predictions from a custom trained model\n**Preview:** The Vertex AI online prediction is a Preview feature that is available as-is and is not recommended for production environments. Google provides no service-level agreements (SLA) or technical support commitments for Preview features. For more information, see GDCH's [feature stages](/distributed-cloud/hosted/docs/latest/gdch/resources/feature-stages) .\nVertex AI offers online predictions on Google Distributed Cloud Hosted (GDCH) through the Prediction API. A prediction is the output of a trained machine learning model. Specifically, online predictions are synchronous requests made to your own model endpoint.\nOnline predictions let you upload, deploy, serve, and make requests using your own prediction models on [a set of supported containers](#available-container-images) . Use online predictions when you are making requests in response to application input or in situations that require timely inference. This page provides an overview of the workflow for getting online predictions from your custom trained models on Vertex AI.\nUse the Prediction API by applying Kubernetes custom resources (CRs) to the dedicated [Prediction user cluster](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/prediction-user-cluster) that your Infrastructure Operator (IO) creates for you.\nBefore getting online predictions, you must first [deploy the model resource to an endpoint](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/vertex-ai-deploy-model) . This action associates compute resources with the model so that it can serve online predictions with low latency. Then, you can get online predictions from a custom trained model by [sending a request](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/vertex-ai-get-online-prediction#send-a-request-to-an-endpoint) .\n", "content": "## Available container images\nThe following table contains the list of supported containers for Vertex AI online predictions in GDCH.\n| ML framework | Version | Supported accelerators | Supported images |\n|:---------------|----------:|:-------------------------|:-------------------|\n| TensorFlow  |  2.6 | CPU only     | tf2-cpu.2-6:latest |\n| TensorFlow  |  2.6 | GPU      | tf2-gpu.2-6:latest |", "guide": "Documentation"}