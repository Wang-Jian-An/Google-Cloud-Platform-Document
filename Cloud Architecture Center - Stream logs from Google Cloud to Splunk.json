{"title": "Cloud Architecture Center - Stream logs from Google Cloud to Splunk", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Stream logs from Google Cloud to Splunk\nLast reviewed 2023-11-16 UTC\nThis document describes a reference architecture that helps you create a production-ready, scalable, fault-tolerant, log export mechanism that streams logs and events from your resources in Google Cloud into Splunk. Splunk is a popular analytics tool that offers a unified security and observability platform. In fact, you have the choice of exporting the logging data to either [Splunk Enterprise](https://www.splunk.com/en_us/software/splunk-enterprise.html) or [Splunk Cloud Platform](https://www.splunk.com/en_us/software/splunk-cloud-platform.html) . If you're an administrator, you can also use this architecture for either IT operations or security use cases. To deploy this reference architecture, see [Deploy log streaming from Google Cloud to Splunk](/architecture/stream-logs-from-google-cloud-to-splunk/deployment) .\nThis reference architecture assumes a resource hierarchy that is similar to the following diagram. All the Google Cloud resource logs from the organization, folder, and project levels are gathered into an aggregated sink. Then, the aggregated sink sends these logs to a log export pipeline, which processes the logs and exports them to Splunk.\n", "content": "## Architecture\nThe following diagram shows the reference architecture that you use when you deploy this solution. This diagram demonstrates how log data flows from Google Cloud to Splunk.\nThis architecture includes the following components:\n- **Cloud Logging\u2013** To start the process, Cloud Logging collects the logs into an organization-level aggregated log sink and sends the logs to Pub/Sub.\n- **Pub/Sub\u2013** The Pub/Sub service then creates a single topic and subscription for the logs and forwards the logs to the main Dataflow pipeline.\n- **Dataflow\u2013** There are two Dataflow pipelines in this reference architecture:- **Primary Dataflow pipeline\u2013** At the center of the process, the main Dataflow pipeline is a Pub/Sub to Splunk streaming pipeline which pulls logs from the Pub/Sub subscription and delivers them to Splunk.\n- **Secondary Dataflow pipeline\u2013** Parallel to the primary Dataflow pipeline, the secondary Dataflow pipeline is a Pub/Sub to Pub/Sub streaming pipeline to replay messages if a delivery fails.\n- **Splunk\u2013** At the end of the process, Splunk Enterprise or Splunk Cloud Platform act as an HTTP Event Collector (HEC) and receive the logs for further analysis. You can deploy Splunk on-premises, in [Google Cloud as SaaS](/splunk) , or through a hybrid approach.## Use case\nThis reference architecture uses a cloud, push-based approach. In this push-based method, you use the [Pub/Sub to SplunkDataflowtemplate](/dataflow/docs/guides/templates/provided/pubsub-to-splunk) to stream logs to a [Splunk HTTP Event Collector(HEC)](https://dev.splunk.com/enterprise/docs/dataapps/httpeventcollector/) . The reference architecture also discusses Dataflow pipeline capacity planning and how to handle potential delivery failures when there are transient server or network issues.\nWhile this reference architecture focuses on Google Cloud logs, the same architecture can be used to export other Google Cloud data, such as real-time asset changes and security findings. By integrating logs from Cloud Logging, you can continue to use existing partner services like Splunk as a unified log analytics solution.\nThe push-based method to stream Google Cloud data into Splunk has the following advantages:\n- **Managed service** . As a managed service, Dataflow maintains the required resources in Google Cloud for data processing tasks such as log export.\n- **Distributed workload** . This method lets you distribute workloads across multiple workers for parallel processing, so there is no single point of failure.\n- **Security** . Because Google Cloud pushes your data to Splunk HEC, there's none of the maintenance and security burden associated with creating and managing service account keys.\n- **Autoscaling** . The Dataflow service autoscales the number of workers in response to variations in incoming log volume and backlog.\n- **Fault-tolerance** . \u200b\u200bIf there are transient server or network issues, the push-based method automatically tries to resend the data to the Splunk HEC. It also supports unprocessed topics (also known as [dead-lettertopics](https://wikipedia.org/wiki/Dead_letter_queue) ) for any undeliverable log messages to avoid data loss.\n- **Simplicity** . You avoid the management overhead and the cost of running one or more [heavyforwarders](https://docs.splunk.com/Splexicon:Heavyforwarder) in Splunk.\nThis reference architecture applies to businesses in many different industry verticals, including regulated ones such as pharmaceutical and financial services. When you choose to export your Google Cloud data into Splunk, you might choose to do so for the following reasons:\n- Business analytics\n- IT operations\n- Application performance monitoring\n- Security operations\n- Compliance## Design alternatives\nAn alternative method for log export to Splunk is one where you pull logs from Google Cloud. In this pull-based method, you use Google Cloud APIs to fetch the data through the [Splunk Add-on forGoogle Cloud](https://splunkbase.splunk.com/app/3088/) . You might choose to use the pull-based method in the following situations:\n- Your Splunk deployment does not offer a Splunk HEC endpoint.\n- Your log volume is low.\n- You want to analyze Cloud Monitoring metrics, Cloud Storage objects, Cloud Resource Manager API metadata, or low-volume logs.\n- You already manage one or more heavy forwarders in Splunk.\n- You use the hosted [Inputs Data Manager for SplunkCloud](https://docs.splunk.com/Documentation/SplunkCloud/latest/Admin/IntroGDI#Work_with_Inputs_Data_Manager) .\nAlso, keep in mind the additional considerations that arise when you use this pull-based method:\n- A single worker handles the data ingestion workload, which does not offer autoscaling capabilities.\n- In Splunk, the use of a heavy forwarder to pull data might cause a single point of failure.\n- The pull-based method requires you to create and manage the service account keys that you use to configure the Splunk Add-on for Google Cloud.\nTo enable the Splunk Add-on, perform the following steps:\n- In Splunk, follow the Splunk instructions to [install the Splunk Add-on for Google Cloud](https://docs.splunk.com/Documentation/AddOns/released/GoogleCloud/installation) .\n- In Google Cloud, [create a Pub/Sub topic](/pubsub/docs/create-topic#create_a_topic) to export your logging data.\n- [Create a Pub/Sub pull subscription](/pubsub/docs/create-subscription#pull_subscription) for this topic.\n- [Create a service account](/iam/docs/service-accounts-create#creating) .\n- [Create a service account key](/iam/docs/keys-create-delete#creating) for the service account that you just created.\n- Grant the Pub/Sub Viewer (`roles/pubsub.viewer`) and Pub/Sub Subscriber (`roles/pubsub.subscriber`) roles to the service account to let the account receive messages from the Pub/Sub subscription.\n- In Splunk, follow the Splunk instructions to [configure a new Pub/Sub input](https://docs.splunk.com/Documentation/AddOns/released/GoogleCloud/Configureinputsv1modular) in the Splunk Add-on for Google Cloud.The Pub/Sub messages from the log export appear in Splunk.\nTo verify that the add-on is working, perform the following steps:\n- In Cloud Monitoring, open Metrics Explorer.\n- In the **Resources** menu, select`pubsub_subscription`.\n- In the **Metric** categories, select`pubsub/subscription/pull_message_operation_count`.\n- Monitor the number of message-pull operations for one to two minutes.## Design considerations\nThe following guidelines can help you to develop an architecture that meets your organization's requirements for security, privacy, compliance, operational efficiency, reliability, fault tolerance, performance, and cost optimization.\n### Security, privacy, and compliance\nThe following sections describe the security considerations for this reference architecture:\n- [Use private IP addresses to secure the VMs that support the Dataflow pipeline](#use_private_ip_addresses_to_secure_the_vms_that_support_the_pipeline) \n- [Enable Private Google Access](#enable_private_google_access) \n- [Restrict Splunk HEC ingress traffic to known IP addresses used by Cloud NAT](#restrict_splunk_hec_ingress_traffic_to_known_ip_addresses_used_by_cloud_nat) \n- [Store the Splunk HEC token in Secret Manager](#store_the_splunk_hec_token_in_secret_manager) \n- [Create a custom Dataflow worker service account to follow least privilege best practices](#create_a_custom_worker_service_account_to_follow_least_privilege_best_practices) \n- [Configure SSL validation for an internal root CA certificate if you use a private CA](#configure_ssl_validation_with_an_internal_root_ca_certificate_if_you_use_a_private_ca) You should restrict access to the worker VMs that are used in the Dataflow pipeline. To restrict access, deploy these VMs with private IP addresses. However, these VMs also need to be able to use HTTPS to stream the exported logs into Splunk and access the internet. To provide this HTTPS access, you need a Cloud NAT gateway which automatically allocates Cloud NAT IP addresses to the VMs that need them. Make sure to map the subnet that contains the VMs to the Cloud NAT gateway.\nWhen you create a Cloud NAT gateway, Private Google Access becomes enabled automatically. However, to allow Dataflow workers with private IP addresses to access the external IP addresses that Google Cloud APIs and services use, you must also manually enable Private Google Access for the subnet.\nIf you want to restrict traffic into the Splunk HEC to a subset of known IP addresses, you can reserve static IP addresses and manually assign them to the Cloud NAT gateway. Depending on your Splunk deployment, you can then configure your Splunk HEC ingress firewall rules using these static IP addresses. For more information about Cloud NAT, see [Set up and managenetwork address translation withCloud NAT](/nat/docs/set-up-manage-network-address-translation) .\nWhen you deploy the Dataflow pipeline, you can pass the token value in one of the following ways:\n- Plaintext\n- Ciphertext encrypted with a Cloud Key Management Service key\n- Secret version encrypted and managed by Secret Manager\nIn this reference architecture, you use the Secret Manager option because this option offers the least complex and most efficient way to protect your Splunk HEC token. This option also prevents leakage of the Splunk HEC token from the Dataflow console or the job details.\nA secret in Secret Manager contains a collection of secret versions. Each secret version stores the actual secret data, such as the Splunk HEC token. If you later choose to rotate your Splunk HEC token as an added security measure, you can add the new token as a new secret version to this secret. For general information about the rotation of secrets, see [Aboutrotation schedules](/secret-manager/docs/rotation-recommendations) .\nWorkers in the Dataflow pipeline use the [Dataflowworker service account](/dataflow/docs/concepts/security-and-permissions#worker-service-account) to access resources and execute operations. By default, the workers use your project's [Compute Engine default serviceaccount](/compute/docs/access/service-accounts#default_service_account) as the worker service account, which grants them broad permissions to all resources in your project. However, to run Dataflow jobs in production, we recommend that you create a custom service account with a minimum set of roles and permissions. You can then assign this custom service account to your Dataflow pipeline workers.\nThe following diagram lists the required roles that you must assign to a service account to enable Dataflow workers to run a Dataflow job successfully.\nAs shown in the diagram, you need to assign the following roles to the service account for your Dataflow worker:\n- Dataflow Admin\n- Dataflow Worker\n- Storage Object Admin\n- Pub/Sub Subscriber\n- Pub/Sub Viewer\n- Pub/Sub Publisher\n- Secret Accessor\nFor more details on the roles that you need to assign to the Dataflow worker service account, see the [Grant roles and access to the Dataflow worker serviceaccount](/architecture/stream-logs-from-google-cloud-to-splunk/deployment#grant_roles_and_access_to_the_worker_service_account) section of the deployment guide.\nBy default, the Dataflow pipeline uses the Dataflow worker\u2019s default trust store to validate the SSL certificate for your Splunk HEC endpoint. If you use a private certificate authority (CA) to sign an SSL certificate that is used by the Splunk HEC endpoint, you can import your internal root CA certificate into the trust store. The Dataflow workers can then use the imported certificate for SSL certificate validation.\nYou can use and import your own internal root CA certificate for Splunk deployments with self-signed or privately signed certificates. You can also disable SSL validation entirely for internal development and testing purposes only. This internal root CA method works best for non-internet facing, internal Splunk deployments.\nFor more information, see the [Pub/Sub to SplunkDataflow templateparameters](/dataflow/docs/guides/templates/provided/pubsub-to-splunk#template-parameters) `rootCaCertificatePath` and `disableCertificateValidation` .\n### Operational efficiency\nThe following sections describe the operational efficiency considerations for this reference architecture:\n- [Use UDF to transform logs or events in-flight](#use_udf_to_transform_logs_or_events_in-flight) \n- [Replay unprocessed messages](#replay_unprocessed_messages) The Pub/Sub to Splunk Dataflow template supports user-defined functions (UDF) for custom event transformation. Example use cases include enriching records with additional fields, redacting some sensitive fields, or filtering out undesired records. UDF enables you to change the Dataflow pipeline's output format without having to re-compile or to maintain the template code itself. This reference architecture uses a UDF to handle messages that the pipeline isn't able to deliver to Splunk.\nSometimes, the pipeline receives delivery errors and doesn't try to deliver the message again. In this case, Dataflow sends these unprocessed messages to an unprocessed topic as shown in the following diagram. After you fix the root cause of the delivery failure, you can then replay the unprocessed messages.\nThe following steps outline the process shown in the previous diagram:\n- The main delivery pipeline from Pub/Sub to Splunk automatically forwards undeliverable messages to the unprocessed topic for user investigation.\n- The operator or site reliability engineer (SRE) investigates the failed messages in the unprocessed subscription. The operator troubleshoots and fixes the root cause of the delivery failure. For example, fixing an HEC token misconfiguration might enable the messages to be delivered. **Note:** To avoid data backlog or data loss, you must regularly inspect any failed messages in the unprocessed subscription and resolve any issues before Pub/Sub discards the messages. The maximum message retention in a Pub/Sub subscription is seven days, which is the default setting for both the input and the unprocessed subscriptions in this reference architecture. You can monitor and receive alerts on the [unacknowledgedmessages](/monitoring/api/metrics_gcp#pubsub/subscription/num_undelivered_messages) in the unprocessed subscription. For more information about monitoring and alerting for Pub/Sub subscriptions, see [Monitor messagebacklog](/pubsub/docs/monitoring#monitoring_the_backlog) .\n- The operator triggers the replay failed message pipeline. This Pub/Sub to Pub/Sub pipeline (highlighted in the dotted section of the preceding diagram) is a temporary pipeline that moves the failed messages from the unprocessed subscription back to the original log sink topic.\n- The main delivery pipeline re-processes the previously failed messages. This step requires the pipeline to use the [sampleUDF](https://storage.googleapis.com/splk-public/js/dataflow_udf_messages_replay.js) for correct detection and decoding of failed messages payloads. The following code shows the part of the function that implements this conditional decoding logic, including a tally of delivery attempts for tracking purposes:```\n// If the message has already been converted to a Splunk HEC object// with a stringified obj.event JSON payload, then it's a replay of// a previously failed delivery.// Unnest and parse the obj.event. Drop the previously injected// obj.attributes such as errorMessage and timestampif (obj.event) {\u00a0try {\u00a0 \u00a0event = JSON.parse(obj.event);\u00a0 \u00a0redelivery = true;\u00a0} catch(e) {\u00a0 \u00a0event = obj;\u00a0}} else {\u00a0event = obj;}// Keep a tally of delivery attemptsevent.delivery_attempt = event.delivery_attempt || 1;if (redelivery) {\u00a0event.delivery_attempt += 1;}\n```\n### Reliability and fault tolerance\nIn regard to reliability and fault tolerance, the following table, Table 1, lists some possible Splunk delivery errors. The table also lists the corresponding `errorMessage` attributes that the pipeline records with each message before forwarding these messages to the unprocessed topic.\n**Table 1: Splunk delivery error types**\n| Delivery error type          | Automatically retried by pipeline? | Example errorMessage attribute    |\n|:-----------------------------------------------------------|:-------------------------------------|:-------------------------------------------|\n| Transient network error         | Yes         | Read timed outorConnection reset   |\n| Splunk server 5xx error         | Yes         | Splunk write status code: 503    |\n| Splunk server 4xx error         | No         | Splunk write status code: 403    |\n| Splunk server down           | No         | The target server failed to respond  |\n| Splunk SSL certificate invalid        | No         | Host name X does not match the certificate |\n| JavaScript syntax error in the user-defined function (UDF) | No         | ReferenceError: X is not defined   |\nIn some cases, the pipeline applies [exponentialbackoff](https://en.wikipedia.org/wiki/Exponential_backoff) and automatically tries to deliver the message again. For example, when the Splunk server generates a `5xx` error code, the pipeline needs to redeliver the message. These error codes occur when the Splunk HEC endpoint is overloaded.\nAlternatively, there could be a persistent issue that prevents a message from being submitted to the HEC endpoint. For such persistent issues, the pipeline does not try to deliver the message again. The following are examples of persistent issues:\n- A syntax error in the [UDF](#use_udf_to_transform_logs_or_events_in-flight) function.\n- An invalid HEC token that causes the Splunk server to generate a`4xx`\"Forbidden\" server response.\n### Performance and cost optimization\nIn regard to performance and cost optimization, you need to determine the maximum size and throughput for your Dataflow pipeline. You must calculate the correct size and throughput values so that your pipeline can handle peak daily log volume (GB/day) and log message rate (events per second, or EPS) from the upstream Pub/Sub subscription.\nYou must select the size and throughput values so that the system doesn't incur either of the following issues:\n- Delays caused by message backlogging or message throttling.\n- Extra costs from overprovisioning a pipeline.\nAfter you perform the size and throughput calculations, you can use the results to configure an optimal pipeline that balances performance and cost. To configure your pipeline capacity, you use the following settings:\n- The [Machine type](#machine_type) and [Machine count](#machine_count) flags are part of the [gcloud command](/sdk/gcloud/reference/beta/dataflow/jobs/run) that deploys the Dataflow job. These flags let you define the type and number of VMs to use.\n- The [Parallelism](#parallelism) and [Batch count](#batch_count) parameters are part of the [Pub/Sub to Splunk Dataflowtemplate](/dataflow/docs/guides/templates/provided/pubsub-to-splunk#template-parameters) . These parameters are important to increase EPS while avoiding overwhelming the Splunk HEC endpoint.\nThe following sections provide an explanation of these settings. When applicable, these sections also provide formulas and example calculations that use each formula. These example calculations and resulting values assume an organization with the following characteristics:\n- Generates 1 TB of logs daily.\n- Has an average message size of 1 KB.\n- Has a sustained peak message rate that is two times the average rate.\nBecause your Dataflow environment is unique, substitute the example values with values from your own organization as you work through the steps.\n**Best practice** : Set the `--worker-machine-type` flag to `n1-standard-4` to select a machine size that provides the best performance to cost ratio.\nBecause the `n1-standard-4` machine type can handle 12k EPS, we recommend that you use this machine type as a baseline for all of your Dataflow workers.\nFor this reference architecture, set the `--worker-machine-type` flag to a value of `n1-standard-4` .\n**Best practice** : Set the `--max-workers` flag to control the maximum number of workers needed to handle expected peak EPS.\nDataflow autoscaling allows the service to adaptively change the number of workers used to execute your streaming pipeline when there are changes to resource usage and load. To avoid overprovisioning when autoscaling, we recommend that you always define the maximum number of virtual machines that are used as Dataflow workers. You define the maximum number of virtual machines with the `--max-workers` flag when you deploy the Dataflow pipeline.\nDataflow statically provisions the storage component as follows:\n- An autoscaling pipeline deploys one data persistent disk for each potential streaming worker. The default persistent disk size is 400 GB, and you set the maximum number of workers with the `--max-workers` flag. The disks are mounted to the running workers at any point in time, including startup.\n- Because each worker instance is limited to 15 persistent disks, the minimum number of starting workers is `\u2308--max-workers/15\u2309` . So, if the default value is `--max-workers=20` , the pipeline usage (and cost) is as follows:- **Storage:** static with 20 persistent disks.\n- **Compute:** dynamic with minimum of 2 worker instances (\u230820/15\u2309 = 2), and a maximum of 20.\nThis value is equivalent to 8 TB of a Persistent Disk. This size of  Persistent Disk could incur unnecessary cost if the disks are not  fully used, especially if only one or two workers are running the  majority of the time.\nTo determine the maximum number of workers that you need for your pipeline, use the following formulas in sequence:\n- Determine the average events per second (EPS) using the following formula: **Example calculation:** Given the example values of 1 TB of logs per day with an average message size of 1 KB, this formula generates an average EPS value of 11.5k EPS.\n- Determine the sustained peak EPS by using the following formula, where the multiplier represents the bursty nature of logging: **Example calculation:** Given an example value of =2 and the average EPS value of 11.5k that you calculated in the previous step, this formula generates a sustained peak EPS value of 23k EPS.\n- Determine the maximum required number of vCPUs by using the following formula: **Example calculation:** Using the sustained peak EPS value of 23k that you calculated in the previous step, this formula generates a maximum of \u230823 / 3\u2309 = 8 vCPU cores. **Note:** A single vCPU in a Splunk Dataflow pipeline can  generally process 3k EPS, assuming there are no artificially low rate  limits. So, one Dataflow VM worker of a default machine  type ( `n1-standard-4` ) is generally enough to process up to 12k EPS.\n- Determine the maximum number of Dataflow workers by using the following formula: **Example calculation:** Using the example maximum vCPUs value of 8 that was calculated in the previous step, this formula [8/4] generates a maximum number of 2 for an `n1-standard-4` machine type.\nFor this example, you would set the `--max-workers` flag to a value of `2` based on the previous set of example calculations. However, remember to use your own unique values and calculations when you deploy this reference architecture in your environment.\n**Best practice** : Set the [parallelism parameter](/dataflow/docs/guides/templates/provided/pubsub-to-splunk#template-parameters) in the Pub/Sub to Splunk Dataflow template to twice the number of vCPUs used by the maximum number of Dataflow workers.\nThe `parallelism` parameter helps maximize the number of parallel Splunk HEC connections, which in turn maximizes the EPS rate for your pipeline.\nThe default `parallelism` value of `1` disables parallelism and limits the output rate. You need to override this default setting to account for 2 to 4 parallel connections per vCPU, with the maximum number of workers deployed. As a rule, you calculate the override value for this setting by multiplying the maximum number of Dataflow workers by the number of vCPUs per worker, and then doubling this value.\nTo determine the total number of parallel connections to the Splunk HEC across all Dataflow workers, use the following formula:**Example calculation:** Using the example maximum vCPUs of 8 that was previously calculated for machine count, this formula generates the number of parallel connections to be 8 x 2 = 16.\nFor this example, you would set the `parallelism` parameter to a value of `16` based on the previous example calculation. However, remember to use your own unique values and calculations when you deploy this reference architecture in your environment.\n**Best practice** : To enable the Splunk HEC to process events in batches rather than one at a time, set the [batchCount parameter](/dataflow/docs/guides/templates/provided/pubsub-to-splunk#template-parameters) to a value between 10 to 50 events/request for logs.\nConfiguring the batch count helps to increase EPS and reduce the load on the Splunk HEC endpoint. The setting combines multiple events into a single batch for more efficient processing. We recommend that you set the `batchCount` parameter to a value between 10 to 50 events/request for logs, provided the max buffering delay of two seconds is acceptable.Because the average log message size is 1 KB in this example, we recommend that you batch at least 10 events per request. For this example, you would set the `batchCount` parameter to a value of `10` . However, remember to use your own unique values and calculations when you deploy this reference architecture in your environment.\nFor more information about these performance and cost optimization recommendations, see [Plan your Dataflowpipeline](/dataflow/docs/guides/plan-pipelines) .\n## Deployment\nTo deploy this reference architecture, see [Deploy log streaming from Google Cloud toSplunk](/architecture/stream-logs-from-google-cloud-to-splunk/deployment) .\n## What's next\n- For a full list of Pub/Sub to Splunk Dataflow template parameters, see the [Pub/Sub to SplunkDataflowdocumentation](/dataflow/docs/guides/templates/provided/pubsub-to-splunk) .\n- For the corresponding Terraform templates to help you deploy this reference architecture, see the [terraform-splunk-log-export](https://github.com/GoogleCloudPlatform/terraform-splunk-log-export) GitHub repository. It includes a pre-built Cloud Monitoring dashboard for monitoring your Splunk Dataflow pipeline.\n- For more details on Splunk Dataflow custom metrics and logging to help you monitor and troubleshoot your Splunk Dataflow pipelines, refer to this blog [New observabilityfeatures for your Splunk Dataflow streamingpipelines](/blog/products/data-analytics/simplify-your-splunk-dataflow-ops-with-improved-pipeline-observability) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Cloud Architecture Center"}