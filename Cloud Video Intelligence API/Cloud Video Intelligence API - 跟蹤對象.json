{"title": "Cloud Video Intelligence API - \u8ddf\u8e64\u5c0d\u8c61", "url": "https://cloud.google.com/video-intelligence/docs/streaming/object-tracking?hl=zh-cn", "abstract": "# Cloud Video Intelligence API - \u8ddf\u8e64\u5c0d\u8c61\n**    Beta \u7248     ** \u6b64\u529f\u80fd\u9808\u9075\u5b88 [\u670d\u52d9\u5c08\u7528\u689d\u6b3e](https://cloud.google.com/terms/service-terms?hl=zh-cn#1) \u7684\u201c\u901a\u7528\u670d\u52d9\u689d\u6b3e\u201d\u90e8\u5206\u4e2d\u7684\u201c\u975e\u6b63\u5f0f\u7248\u7522\u54c1\u689d\u6b3e\u201d\u3002 \u975e\u6b63\u5f0f\u7248\u529f\u80fd\u201c\u6309\u539f\u6a23\u201d\u63d0\u4f9b\uff0c\u53ef\u80fd\u53ea\u80fd\u7372\u5f97\u6709\u9650\u7684\u652f\u6301\u3002 \u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u767c\u4f48\u968e\u6bb5\u8aaa\u660e](https://cloud.google.com/products?hl=zh-cn#product-launch-stages) \u3002\n[\u5c0d\u8c61\u8ddf\u8e64](https://cloud.google.com/video-intelligence/docs/object-tracking?hl=zh-cn) \u529f\u80fd\u53ef\u8ddf\u8e64\u5728\u8f38\u5165\u8996\u983b\u4e2d\u6aa2\u6e2c\u5230\u7684\u591a\u500b\u5c0d\u8c61\u3002\n", "content": "## \u4f7f\u7528\u6a19\u6e96\u6a21\u578b\n\u4ee5\u4e0b\u4ee3\u78bc\u793a\u4f8b\u6f14\u793a\u77ad\u5982\u4f55\u4f7f\u7528\u6d41\u5f0f\u5ba2\u6236\u7aef\u5eab\u8ddf\u8e64\u5c0d\u8c61\u3002\n\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/video/src/main/java/beta/video/StreamingObjectTracking.java) \n```\nimport com.google.api.gax.rpc.BidiStream;import com.google.cloud.videointelligence.v1p3beta1.ObjectTrackingAnnotation;import com.google.cloud.videointelligence.v1p3beta1.ObjectTrackingFrame;import com.google.cloud.videointelligence.v1p3beta1.StreamingAnnotateVideoRequest;import com.google.cloud.videointelligence.v1p3beta1.StreamingAnnotateVideoResponse;import com.google.cloud.videointelligence.v1p3beta1.StreamingFeature;import com.google.cloud.videointelligence.v1p3beta1.StreamingLabelDetectionConfig;import com.google.cloud.videointelligence.v1p3beta1.StreamingVideoAnnotationResults;import com.google.cloud.videointelligence.v1p3beta1.StreamingVideoConfig;import com.google.cloud.videointelligence.v1p3beta1.StreamingVideoIntelligenceServiceClient;import com.google.protobuf.ByteString;import io.grpc.StatusRuntimeException;import java.io.IOException;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;import java.util.Arrays;import java.util.concurrent.TimeoutException;class StreamingObjectTracking {\u00a0 // Perform streaming video object tracking\u00a0 static void streamingObjectTracking(String filePath)\u00a0 \u00a0 \u00a0 throws IOException, TimeoutException, StatusRuntimeException {\u00a0 \u00a0 // String filePath = \"path_to_your_video_file\";\u00a0 \u00a0 try (StreamingVideoIntelligenceServiceClient client =\u00a0 \u00a0 \u00a0 \u00a0 StreamingVideoIntelligenceServiceClient.create()) {\u00a0 \u00a0 \u00a0 Path path = Paths.get(filePath);\u00a0 \u00a0 \u00a0 byte[] data = Files.readAllBytes(path);\u00a0 \u00a0 \u00a0 // Set the chunk size to 5MB (recommended less than 10MB).\u00a0 \u00a0 \u00a0 int chunkSize = 5 * 1024 * 1024;\u00a0 \u00a0 \u00a0 int numChunks = (int) Math.ceil((double) data.length / chunkSize);\u00a0 \u00a0 \u00a0 StreamingLabelDetectionConfig labelConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StreamingLabelDetectionConfig.newBuilder().setStationaryCamera(false).build();\u00a0 \u00a0 \u00a0 StreamingVideoConfig streamingVideoConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StreamingVideoConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setFeature(StreamingFeature.STREAMING_OBJECT_TRACKING)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setLabelDetectionConfig(labelConfig)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 BidiStream<StreamingAnnotateVideoRequest, StreamingAnnotateVideoResponse> call =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 client.streamingAnnotateVideoCallable().call();\u00a0 \u00a0 \u00a0 // The first request must **only** contain the audio configuration:\u00a0 \u00a0 \u00a0 call.send(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StreamingAnnotateVideoRequest.newBuilder().setVideoConfig(streamingVideoConfig).build());\u00a0 \u00a0 \u00a0 // Subsequent requests must **only** contain the audio data.\u00a0 \u00a0 \u00a0 // Send the requests in chunks\u00a0 \u00a0 \u00a0 for (int i = 0; i < numChunks; i++) {\u00a0 \u00a0 \u00a0 \u00a0 call.send(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StreamingAnnotateVideoRequest.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputContent(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ByteString.copyFrom(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Arrays.copyOfRange(data, i * chunkSize, i * chunkSize + chunkSize)))\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build());\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 // Tell the service you are done sending data\u00a0 \u00a0 \u00a0 call.closeSend();\u00a0 \u00a0 \u00a0 for (StreamingAnnotateVideoResponse response : call) {\u00a0 \u00a0 \u00a0 \u00a0 StreamingVideoAnnotationResults annotationResults = response.getAnnotationResults();\u00a0 \u00a0 \u00a0 \u00a0 for (ObjectTrackingAnnotation objectAnnotations :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 annotationResults.getObjectAnnotationsList()) {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String entity = objectAnnotations.getEntity().getDescription();\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float confidence = objectAnnotations.getConfidence();\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 long trackId = objectAnnotations.getTrackId();\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"%s: %f (ID: %d)\\n\", entity, confidence, trackId);\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // In streaming, there is always one frame.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ObjectTrackingFrame frame = objectAnnotations.getFrames(0);\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 double offset =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 frame.getTimeOffset().getSeconds() + frame.getTimeOffset().getNanos() / 1e9;\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Offset: %f\\n\", offset);\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Bounding Box:\");\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\tLeft: %f\\n\", frame.getNormalizedBoundingBox().getLeft());\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\tTop: %f\\n\", frame.getNormalizedBoundingBox().getTop());\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\tRight: %f\\n\", frame.getNormalizedBoundingBox().getRight());\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\tBottom: %f\\n\", frame.getNormalizedBoundingBox().getBottom());\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}\n```\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/video-intelligence/analyze-streaming-object.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\u00a0*/// const path = 'Local file to analyze, e.g. ./my-file.mp4';const {StreamingVideoIntelligenceServiceClient} =\u00a0 require('@google-cloud/video-intelligence').v1p3beta1;const fs = require('fs');// Instantiates a clientconst client = new StreamingVideoIntelligenceServiceClient();// Streaming configurationconst configRequest = {\u00a0 videoConfig: {\u00a0 \u00a0 feature: 'STREAMING_OBJECT_TRACKING',\u00a0 },};const readStream = fs.createReadStream(path, {\u00a0 highWaterMark: 5 * 1024 * 1024, //chunk size set to 5MB (recommended less than 10MB)\u00a0 encoding: 'base64',});//Load file contentconst chunks = [];readStream\u00a0 .on('data', chunk => {\u00a0 \u00a0 const request = {\u00a0 \u00a0 \u00a0 inputContent: chunk.toString(),\u00a0 \u00a0 };\u00a0 \u00a0 chunks.push(request);\u00a0 })\u00a0 .on('close', () => {\u00a0 \u00a0 // configRequest should be the first in the stream of requests\u00a0 \u00a0 stream.write(configRequest);\u00a0 \u00a0 for (let i = 0; i < chunks.length; i++) {\u00a0 \u00a0 \u00a0 stream.write(chunks[i]);\u00a0 \u00a0 }\u00a0 \u00a0 stream.end();\u00a0 });const options = {timeout: 120000};// Create a job using a long-running operationconst stream = client.streamingAnnotateVideo(options).on('data', response => {\u00a0 //Gets annotations for video\u00a0 const annotations = response.annotationResults;\u00a0 const objects = annotations.objectAnnotations;\u00a0 objects.forEach(object => {\u00a0 \u00a0 console.log(`Entity description: ${object.entity.description}`);\u00a0 \u00a0 console.log(`Entity id: ${object.entity.entityId}`);\u00a0 \u00a0 console.log(`Track id: ${object.trackId}`);\u00a0 \u00a0 console.log(`Confidence: ${object.confidence}`);\u00a0 \u00a0 console.log(\u00a0 \u00a0 \u00a0 `Time offset for the frame: ${\u00a0 \u00a0 \u00a0 \u00a0 object.frames[0].timeOffset.seconds || 0\u00a0 \u00a0 \u00a0 }` + `.${(object.frames[0].timeOffset.nanos / 1e6).toFixed(0)}s`\u00a0 \u00a0 );\u00a0 \u00a0 //Every annotation has only one frame.\u00a0 \u00a0 const box = object.frames[0].normalizedBoundingBox;\u00a0 \u00a0 console.log('Bounding box position:');\u00a0 \u00a0 console.log(` left \u00a0:${box.left}`);\u00a0 \u00a0 console.log(` top \u00a0 :${box.top}`);\u00a0 \u00a0 console.log(` right :${box.right}`);\u00a0 \u00a0 console.log(` bottom:${box.bottom}`);\u00a0 });});\n```\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/videointelligence/samples/analyze/beta_snippets.py) \n```\nfrom google.cloud import videointelligence_v1p3beta1 as videointelligence# path = 'path_to_file'client = videointelligence.StreamingVideoIntelligenceServiceClient()# Set streaming config.config = videointelligence.StreamingVideoConfig(\u00a0 \u00a0 feature=(videointelligence.StreamingFeature.STREAMING_OBJECT_TRACKING))# config_request should be the first in the stream of requests.config_request = videointelligence.StreamingAnnotateVideoRequest(\u00a0 \u00a0 video_config=config)# Set the chunk size to 5MB (recommended less than 10MB).chunk_size = 5 * 1024 * 1024# Load file content.stream = []with io.open(path, \"rb\") as video_file:\u00a0 \u00a0 while True:\u00a0 \u00a0 \u00a0 \u00a0 data = video_file.read(chunk_size)\u00a0 \u00a0 \u00a0 \u00a0 if not data:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 break\u00a0 \u00a0 \u00a0 \u00a0 stream.append(data)def stream_generator():\u00a0 \u00a0 yield config_request\u00a0 \u00a0 for chunk in stream:\u00a0 \u00a0 \u00a0 \u00a0 yield videointelligence.StreamingAnnotateVideoRequest(input_content=chunk)requests = stream_generator()# streaming_annotate_video returns a generator.# The default timeout is about 300 seconds.# To process longer videos it should be set to# larger than the length (in seconds) of the stream.responses = client.streaming_annotate_video(requests, timeout=900)# Each response corresponds to about 1 second of video.for response in responses:\u00a0 \u00a0 # Check for errors.\u00a0 \u00a0 if response.error.message:\u00a0 \u00a0 \u00a0 \u00a0 print(response.error.message)\u00a0 \u00a0 \u00a0 \u00a0 break\u00a0 \u00a0 object_annotations = response.annotation_results.object_annotations\u00a0 \u00a0 # object_annotations could be empty\u00a0 \u00a0 if not object_annotations:\u00a0 \u00a0 \u00a0 \u00a0 continue\u00a0 \u00a0 for annotation in object_annotations:\u00a0 \u00a0 \u00a0 \u00a0 # Each annotation has one frame, which has a timeoffset.\u00a0 \u00a0 \u00a0 \u00a0 frame = annotation.frames[0]\u00a0 \u00a0 \u00a0 \u00a0 time_offset = (\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 description = annotation.entity.description\u00a0 \u00a0 \u00a0 \u00a0 confidence = annotation.confidence\u00a0 \u00a0 \u00a0 \u00a0 # track_id tracks the same object in the video.\u00a0 \u00a0 \u00a0 \u00a0 track_id = annotation.track_id\u00a0 \u00a0 \u00a0 \u00a0 # description is in Unicode\u00a0 \u00a0 \u00a0 \u00a0 print(\"{}s\".format(time_offset))\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tEntity description: {}\".format(description))\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tTrack Id: {}\".format(track_id))\u00a0 \u00a0 \u00a0 \u00a0 if annotation.entity.entity_id:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tEntity id: {}\".format(annotation.entity.entity_id))\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tConfidence: {}\".format(confidence))\u00a0 \u00a0 \u00a0 \u00a0 # Every annotation has only one frame\u00a0 \u00a0 \u00a0 \u00a0 frame = annotation.frames[0]\u00a0 \u00a0 \u00a0 \u00a0 box = frame.normalized_bounding_box\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tBounding box position:\")\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tleft \u00a0: {}\".format(box.left))\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\ttop \u00a0 : {}\".format(box.top))\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tright : {}\".format(box.right))\u00a0 \u00a0 \u00a0 \u00a0 print(\"\\tbottom: {}\\n\".format(box.bottom))\n```", "guide": "Cloud Video Intelligence API"}