{"title": "Cloud Video Intelligence API - Detect explicit content in videos", "url": "https://cloud.google.com/video-intelligence/docs/analyze-safesearch", "abstract": "# Cloud Video Intelligence API - Detect explicit content in videos\n**Explicit Content Detection** detects adult content in videos. Adult content is generally inappropriate for those under under 18 years of age and includes, but is not limited to, nudity, sexual activities, and pornography. Such content detected in cartoons or anime is also identified.\nThe response includes a bucketized [likelihood](/video-intelligence/docs/reference/rest/Shared.Types/Likelihood) value, from `VERY_UNLIKELY` to `VERY_LIKELY` .\nWhen Explicit Content Detection evaluates a video, it does so on a per-frame basis and considers . The audio component of the video is not used to evaluate explicit content level.\n**Note:** Google does not guarantee the accuracy of its Explicit Content Detection predictions.\nHere is an example of performing video analysis for Explicit Content Detection features on a file located in Cloud Storage.\n", "content": "## Send video annotation requestThe following shows how to send a POST request to the [videos:annotate](/video-intelligence/docs/reference/rest/v1/videos/annotate) method. The example uses the Google Cloud CLI to create an access token. For instructions on installing the gcloud CLI, see the [Video Intelligence API Quickstart](/video-intelligence/docs/annotate-video-command-line) .\nBefore using any of the request data, make the following replacements:- : a Cloud Storage bucket that contains  the file you want to annotate, including the file name. Must  start with`gs://`.For example:`\"inputUri\": \"gs://cloud-videointelligence-demo/assistant.mp4\",`\n- : The numeric identifier for your Google Cloud project\nHTTP method and URL:\n```\nPOST https://videointelligence.googleapis.com/v1/videos:annotate\n```\nRequest JSON body:\n```\n{\n \"inputUri\": \"INPUT_URI\",\n \"features\": [\"EXPLICIT_CONTENT_DETECTION\"]\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION_ID/operations/OPERATION_ID\"\n}\n```\nIf the response is successful, the Video Intelligence API returns the `name` for your operation. The above shows an example of such a response, where:- : the number of your project.\n- : the Cloud region where annotation should take  place. Supported cloud regions are:`us-east1`,`us-west1`,`europe-west1`,`asia-east1`. If no region is  specified, a region will be determined based on video file location.\n- : the ID of the long running operation created  for the request and provided in the response when you started the  operation, for example`12345...`\n## Get annotation resultsTo retrieve the result of the operation, make a [GET](/video-intelligence/docs/reference/rest/v1/projects.locations.operations/get) request, using the operation name returned from the call to [videos:annotate](/video-intelligence/docs/reference/rest/v1/videos/annotate) , as shown in the following example.\nBefore using any of the request data, make the following replacements:- : the name of the operation as returned by Video Intelligence API. The operation name has the format`projects/` `` `/locations/` `` `/operations/` ``\n- : The numeric identifier for your Google Cloud project\nHTTP method and URL:\n```\nGET https://videointelligence.googleapis.com/v1/OPERATION_NAME\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION_ID/operations/OPERATION_ID\",\n \"metadata\": {\n \"@type\": \"type.googleapis.com/google.cloud.videointelligence.v1.AnnotateVideoProgress\",\n \"annotationProgress\": [  {\n  \"inputUri\": \"/demomaker/gbikes_dinosaur.mp4\",\n  \"progressPercent\": 100,\n  \"startTime\": \"2020-03-26T00:16:35.112404Z\",\n  \"updateTime\": \"2020-03-26T00:16:55.937889Z\"\n  }\n ]\n },\n \"done\": true,\n \"response\": {\n \"@type\": \"type.googleapis.com/google.cloud.videointelligence.v1.AnnotateVideoResponse\",\n \"annotationResults\": [  {\n  \"inputUri\": \"/demomaker/gbikes_dinosaur.mp4\",\n  \"explicitAnnotation\": {\n  \"frames\": [  {\n   \"timeOffset\": \"0.056149s\",\n   \"pornographyLikelihood\": \"VERY_UNLIKELY\"\n  },\n  {\n   \"timeOffset\": \"1.166841s\",\n   \"pornographyLikelihood\": \"VERY_UNLIKELY\"\n  },\n   ...\n  {\n   \"timeOffset\": \"41.678209s\",\n   \"pornographyLikelihood\": \"VERY_UNLIKELY\"\n  },\n  {\n   \"timeOffset\": \"42.596413s\",\n   \"pornographyLikelihood\": \"VERY_UNLIKELY\"\n  }\n  ]\n  }\n  }\n ]\n }\n }\n```\nShot detection annotations are returned as a\n`shotAnnotations`\nlist. Note: The\n **done** \nfield is only returned when its value is\n **True** \n. It's not included in responses for which the operation has not completed.\n## Download annotation resultsCopy the annotation from the source to the destination bucket: (see [Copy files and objects](https://cloud.google.com/storage/docs/gsutil/commands/cp) )\n`gsutil cp` `` `gs://my-bucket`\nNote: If the output gcs uri is provided by the user, then the annotation is stored in that gcs uri. [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/videointelligence/video_analyze/video_analyze_gcs.go) \n```\nfunc explicitContentURI(w io.Writer, file string) error {\u00a0 \u00a0 \u00a0 \u00a0 ctx := context.Background()\u00a0 \u00a0 \u00a0 \u00a0 client, err := video.NewClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 defer client.Close()\u00a0 \u00a0 \u00a0 \u00a0 op, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Features: []videopb.Feature{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 videopb.Feature_EXPLICIT_CONTENT_DETECTION,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 InputUri: file,\u00a0 \u00a0 \u00a0 \u00a0 })\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 resp, err := op.Wait(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 // A single video was processed. Get the first result.\u00a0 \u00a0 \u00a0 \u00a0 result := resp.AnnotationResults[0].ExplicitAnnotation\u00a0 \u00a0 \u00a0 \u00a0 for _, frame := range result.Frames {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 offset, _ := ptypes.Duration(frame.TimeOffset)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"%s - %s\\n\", offset, frame.PornographyLikelihood.String())\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 return nil}\n```To authenticate to Video Intelligence, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/video/src/main/java/video/Detect.java) \n```\n// Instantiate a com.google.cloud.videointelligence.v1.VideoIntelligenceServiceClienttry (VideoIntelligenceServiceClient client = VideoIntelligenceServiceClient.create()) {\u00a0 // Create an operation that will contain the response when the operation completes.\u00a0 AnnotateVideoRequest request =\u00a0 \u00a0 \u00a0 AnnotateVideoRequest.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputUri(gcsUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addFeatures(Feature.EXPLICIT_CONTENT_DETECTION)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 OperationFuture<AnnotateVideoResponse, AnnotateVideoProgress> response =\u00a0 \u00a0 \u00a0 client.annotateVideoAsync(request);\u00a0 System.out.println(\"Waiting for operation to complete...\");\u00a0 // Print detected annotations and their positions in the analyzed video.\u00a0 for (VideoAnnotationResults result : response.get().getAnnotationResultsList()) {\u00a0 \u00a0 for (ExplicitContentFrame frame : result.getExplicitAnnotation().getFramesList()) {\u00a0 \u00a0 \u00a0 double frameTime =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 frame.getTimeOffset().getSeconds() + frame.getTimeOffset().getNanos() / 1e9;\u00a0 \u00a0 \u00a0 System.out.printf(\"Location: %.3fs\\n\", frameTime);\u00a0 \u00a0 \u00a0 System.out.println(\"Adult: \" + frame.getPornographyLikelihood());\u00a0 \u00a0 }\u00a0 }\n```To authenticate to Video Intelligence, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/video-intelligence/analyze.js) \n```\n// Imports the Google Cloud Video Intelligence libraryconst video = require('@google-cloud/video-intelligence').v1;// Creates a clientconst client = new video.VideoIntelligenceServiceClient();/**\u00a0* TODO(developer): Uncomment the following line before running the sample.\u00a0*/// const gcsUri = 'GCS URI of video to analyze, e.g. gs://my-bucket/my-video.mp4';const request = {\u00a0 inputUri: gcsUri,\u00a0 features: ['EXPLICIT_CONTENT_DETECTION'],};// Human-readable likelihoodsconst likelihoods = [\u00a0 'UNKNOWN',\u00a0 'VERY_UNLIKELY',\u00a0 'UNLIKELY',\u00a0 'POSSIBLE',\u00a0 'LIKELY',\u00a0 'VERY_LIKELY',];// Detects unsafe contentconst [operation] = await client.annotateVideo(request);console.log('Waiting for operation to complete...');const [operationResult] = await operation.promise();// Gets unsafe contentconst explicitContentResults =\u00a0 operationResult.annotationResults[0].explicitAnnotation;console.log('Explicit annotation results:');explicitContentResults.frames.forEach(result => {\u00a0 if (result.timeOffset === undefined) {\u00a0 \u00a0 result.timeOffset = {};\u00a0 }\u00a0 if (result.timeOffset.seconds === undefined) {\u00a0 \u00a0 result.timeOffset.seconds = 0;\u00a0 }\u00a0 if (result.timeOffset.nanos === undefined) {\u00a0 \u00a0 result.timeOffset.nanos = 0;\u00a0 }\u00a0 console.log(\u00a0 \u00a0 `\\tTime: ${result.timeOffset.seconds}` +\u00a0 \u00a0 \u00a0 `.${(result.timeOffset.nanos / 1e6).toFixed(0)}s`\u00a0 );\u00a0 console.log(\u00a0 \u00a0 `\\t\\tPornography likelihood: ${likelihoods[result.pornographyLikelihood]}`\u00a0 );});\n```\nFor more information on installing and using the Cloud Video Intelligence API Client Library for Python, refer to\n [Cloud Video Intelligence API Client Libraries](/video-intelligence/docs/reference/libraries) \n.\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/videointelligence/samples/analyze/analyze.py) \n```\n\"\"\"Detects explicit content from the GCS path to a video.\"\"\"video_client = videointelligence.VideoIntelligenceServiceClient()features = [videointelligence.Feature.EXPLICIT_CONTENT_DETECTION]operation = video_client.annotate_video(\u00a0 \u00a0 request={\"features\": features, \"input_uri\": path})print(\"\\nProcessing video for explicit content annotations:\")result = operation.result(timeout=90)print(\"\\nFinished processing.\")# Retrieve first result because a single video was processedfor frame in result.annotation_results[0].explicit_annotation.frames:\u00a0 \u00a0 likelihood = videointelligence.Likelihood(frame.pornography_likelihood)\u00a0 \u00a0 frame_time = frame.time_offset.seconds + frame.time_offset.microseconds / 1e6\u00a0 \u00a0 print(\"Time: {}s\".format(frame_time))\u00a0 \u00a0 print(\"\\tpornography: {}\".format(likelihood.name))\n```No preface\n **C#** : Please follow the [C# setup instructions](/video-intelligence/docs/libraries) on the client libraries page  and then visit the [Video Intelligence reference documentation for .NET.](https://googleapis.github.io/google-cloud-dotnet/docs/Google.Cloud.VideoIntelligence.V1/index.html) \n **PHP** : Please follow the [PHP setup instructions](/video-intelligence/docs/libraries) on the client libraries page  and then visit the [Video Intelligence reference documentation for PHP.](/php/docs/reference/cloud-videointelligence/latest) \n **Ruby** : Please follow the [Ruby setup instructions](/video-intelligence/docs/libraries) on the client libraries page  and then visit the [Video Intelligence reference documentation for Ruby.](https://googleapis.dev/ruby/google-cloud-video_intelligence/latest/Google/Cloud/VideoIntelligence/V1.html)", "guide": "Cloud Video Intelligence API"}