{"title": "Cloud Video Intelligence API - Analyze videos for labels", "url": "https://cloud.google.com/video-intelligence/docs/feature-label-detection", "abstract": "# Cloud Video Intelligence API - Analyze videos for labels\nThe Video Intelligence API can identify entities shown in video footage using the [LABEL_DETECTION](/video-intelligence/docs/reference/rest/v1/videos/annotate#feature) feature and annotate these entities with labels (tags). This feature identifies objects, locations, activities, animal species, products, and more.\nLabel detection differs from [Object tracking](/video-intelligence/docs/object-tracking) . Unlike object tracking, label detection provides labels for the entire frame (without bounding boxes).\nFor example, for a video of a train at a crossing, the Video Intelligence API returns labels such as \"train\", \"transportation\", \"railroad crossing\", and so on. Each label includes a time segment with the time offset (timestamp) for the entity's appearance from the beginning of the video. Each annotation also contains additional information including an entity id that you can use to find more information about the entity in the [Google Knowledge Graph Search API](https://developers.google.com/knowledge-graph/) .\nEach entity returned can also include associated category entities in the `categoryEntities` field. For example the \"Terrier\" entity label has a category of \"Dog\". Category entities have a hierarchy. For example, the \"Dog\" category is a child of the \"Mammal\" category in the hierarchy. For a list of the common category entities that the Video Intelligence uses, see [entry-level-categories.json](/static/video-intelligence/docs/entry-level-categories.json) .\nThe analysis can be compartmentalized as follows:\n- Segment level:User-selected segments of a video can be specified  for analysis by stipulating beginning and ending timestamps for the purposes  of annotation (see [VideoSegment](/video-intelligence/docs/reference/rest/v1/videos/annotate#videosegment) ).  Entities are then identified and labeled within each segment. If no segments  are specified, the whole video is treated as one segment.\n- Shot level:Shots (also known as a) are automatically detected within  every segment (or video). Entities are then identified and labeled within  each scene. For details, see [Shot change detection](#shot-change) \n- Frame level:Entities are identified and labeled within each frame  (with one frame per second sampling).To detect labels in a video, call the [annotate](/video-intelligence/docs/reference/rest/v1/videos/annotate) method and specify [LABEL_DETECTION](/video-intelligence/docs/reference/rest/v1/videos#Feature) in the `features` field.\nSee [Analyzing Videos for Labels](/video-intelligence/docs/analyze-labels) and [Label Detection Tutorial](/video-intelligence/docs/label-tutorial) .\n# Video Intelligence API Visualizer\nCheck out the [Video Intelligence API visualizer](https://zackakil.github.io/video-intelligence-api-visualiser/#Label%20Detection) to see this feature in action", "content": ".", "guide": "Cloud Video Intelligence API"}