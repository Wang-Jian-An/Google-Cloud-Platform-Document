{"title": "Cloud Video Intelligence API - \u7372\u53d6\u97f3\u8ecc\u8f49\u9304", "url": "https://cloud.google.com/video-intelligence/docs/transcription?hl=zh-cn", "abstract": "# Cloud Video Intelligence API - \u7372\u53d6\u97f3\u8ecc\u8f49\u9304\nVideo Intelligence API \u6703\u5c07\u8a9e\u97f3\u5f9e [\u652f\u6301\u7684\u8996\u983b\u6587\u4ef6](https://cloud.google.com/video-intelligence/docs/supported-formats?hl=zh-cn) \u8f49\u9304\u7232\u6587\u672c\u3002\u6709\u5169\u7a2e\u53d7\u652f\u6301\u7684\u6a21\u578b\uff0c\u5373\u201c\u9ed8\u8a8d\u201d\u548c\u201c\u8996\u983b\u201d\u3002\n", "content": "## \u8acb\u6c42\u5c0d\u8996\u983b\u57f7\u884c\u8a9e\u97f3\u8f49\u9304\n### \u767c\u9001\u8655\u7406\u8acb\u6c42\u4e0b\u9762\u6f14\u793a\u77ad\u5982\u4f55\u5411 [videos:annotate](https://cloud.google.com/video-intelligence/docs/reference/rest/v1/videos/annotate?hl=zh-cn) \u65b9\u6cd5\u767c\u9001 `POST` \u8acb\u6c42\u3002\u8a72\u793a\u4f8b\u4f7f\u7528\u901a\u904e Google Cloud CLI \u7232\u9805\u76ee\u8a2d\u7f6e\u7684\u670d\u52d9\u5e33\u865f\u7684\u8a2a\u554f\u4ee4\u724c\u3002\u5982\u9700\u77ad\u89e3\u5982\u4f55\u5b89\u88dd Google Cloud CLI\u3001\u7232\u9805\u76ee\u8a2d\u7f6e\u670d\u52d9\u5e33\u865f\u4ee5\u53ca\u7372\u53d6\u8a2a\u554f\u4ee4\u724c\uff0c\u8acb\u53c3\u95b1 [Video Intelligence \u5feb\u901f\u5165\u9580](https://cloud.google.com/video-intelligence/docs/quickstarts?hl=zh-cn) \u3002\n\u5728\u4f7f\u7528\u4efb\u4f55\u8acb\u6c42\u6578\u64da\u4e4b\u524d\uff0c\u8acb\u5148\u9032\u884c\u4ee5\u4e0b\u66ff\u63db\uff1a- \uff1a\u5305\u542b\u8981\u6dfb\u52a0\u8a3b\u91cb\u7684\u6587\u4ef6\u7684 Cloud Storage \u5b58\u5132\u6876\uff08\u5305\u62ec\u6587\u4ef6\u540d\uff09\u3002\u5fc5\u9808\u4ee5`gs://`\u958b\u982d\u3002\u4f8b\u5982\uff1a`\"inputUri\": \"gs://cloud-videointelligence-demo/assistant.mp4\",`\u3002\n- \uff1a[\u53ef\u9078]\u8acb\u53c3\u95b1 [\u652f\u6301\u7684\u8a9e\u8a00](https://cloud.google.com/speech-to-text/docs/speech-to-text-supported-languages?hl=zh-cn) \n- \uff1a\u60a8\u7684 Google Cloud \u9805\u76ee\u7684\u6578\u5b57\u6a19\u8b58\u7b26\nHTTP \u65b9\u6cd5\u548c\u7db2\u5740\uff1a\n```\nPOST https://videointelligence.googleapis.com/v1/videos:annotate\n```\n\u8acb\u6c42 JSON \u6b63\u6587\uff1a\n```\n{\n\"inputUri\": \"INPUT_URI\",\n \"features\": [\"SPEECH_TRANSCRIPTION\"],\n \"videoContext\": {\n \"speechTranscriptionConfig\": {\n  \"languageCode\": \"LANGUAGE_CODE\",\n  \"enableAutomaticPunctuation\": true,\n  \"filterProfanity\": true\n }\n }\n}\n```\n\u5982\u9700\u767c\u9001\u60a8\u7684\u8acb\u6c42\uff0c\u8acb\u5c55\u958b\u4ee5\u4e0b\u9078\u9805\u4e4b\u4e00\uff1a\u60a8\u61c9\u8a72\u6536\u5230\u985e\u4f3c\u4ee5\u4e0b\u5167\u5bb9\u7684 JSON \u97ff\u61c9\uff1a\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION_ID/operations/OPERATION_ID\"\n}\n```\n\u5982\u679c\u8acb\u6c42\u6210\u529f\uff0c\u5247 Video Intelligence \u6703\u7232\u60a8\u7684\u64cd\u4f5c\u8fd4\u56de `name` \u3002\u4e0a\u9762\u7684\u793a\u4f8b\u5c55\u793a\u4e86\u6b64\u985e\u97ff\u61c9\u7684\u793a\u4f8b\uff0c\u5176\u4e2d `project-number` \u662f\u60a8\u7684\u9805\u76ee\u7de8\u865f\uff0c `operation-id` \u662f\u7232\u8acb\u6c42\u5275\u5efa\u7684\u9577\u6642\u9593\u904b\u884c\u7684\u64cd\u4f5c\u7684 ID\u3002\n### \u7372\u53d6\u7d50\u679c\u8981\u7372\u53d6\u8acb\u6c42\u7684\u7d50\u679c\uff0c\u60a8\u5fc5\u9808\u4f7f\u7528\u5c0d `videos:annotate` \u7684\u8abf\u7528\u8fd4\u56de\u7684\u64cd\u4f5c\u540d\u7a31\u767c\u9001 `GET` \uff0c\u5982\u4e0b\u4f8b\u6240\u793a\u3002\n\u5728\u4f7f\u7528\u4efb\u4f55\u8acb\u6c42\u6578\u64da\u4e4b\u524d\uff0c\u8acb\u5148\u9032\u884c\u4ee5\u4e0b\u66ff\u63db\uff1a- \uff1aVideo Intelligence API \u8fd4\u56de\u7684\u64cd\u4f5c\u540d\u7a31\u3002\u64cd\u4f5c\u540d\u7a31\u63a1\u7528`projects/` `` `/locations/` `` `/operations/` ``\u683c\u5f0f\n- \u6ce8\u610f\uff1a **done** \u5b57\u6bb5\u50c5\u5728\u5176\u503c\u7232 **True** \u6642\u7e94\u6703\u8fd4\u56de\u3002\u5b83\u4e0d\u6703\u5305\u542b\u5728\u64cd\u4f5c\u5c1a\u672a\u5b8c\u6210\u7684\u97ff\u61c9\u4e2d\u3002\n- \uff1a\u60a8\u7684 Google Cloud \u9805\u76ee\u7684\u6578\u5b57\u6a19\u8b58\u7b26\nHTTP \u65b9\u6cd5\u548c\u7db2\u5740\uff1a\n```\nGET https://videointelligence.googleapis.com/v1/OPERATION_NAME\n```\n\u5982\u9700\u767c\u9001\u60a8\u7684\u8acb\u6c42\uff0c\u8acb\u5c55\u958b\u4ee5\u4e0b\u9078\u9805\u4e4b\u4e00\uff1a\u60a8\u61c9\u8a72\u6536\u5230\u985e\u4f3c\u4ee5\u4e0b\u5167\u5bb9\u7684 JSON \u97ff\u61c9\uff1a## \u4e0b\u8f09\u8a3b\u89e3\u7d50\u679c\u5c07\u4f86\u6e90\u4e2d\u7684\u8a3b\u89e3\u8907\u88fd\u5230\u76ee\u6a19\u5b58\u5132\u6876\uff08\u8acb\u53c3\u95b1 [\u8907\u88fd\u6587\u4ef6\u548c\u5c0d\u8c61](https://cloud.google.com/storage/docs/gsutil/commands/cp?hl=zh-cn) \uff09\uff1a\n`gsutil cp` `` `gs://my-bucket`\n\u6ce8\u610f\uff1a\u5982\u679c\u8f38\u51fa gcs uri \u7531\u7528\u6236\u63d0\u4f9b\uff0c\u5247\u8a3b\u89e3\u5b58\u5132\u5728\u8a72 gcs uri \u4e2d\u3002\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/videointelligence/video_analyze/video_analyze_gcs.go) \n```\nfunc speechTranscriptionURI(w io.Writer, file string) error {\u00a0 \u00a0 \u00a0 \u00a0 ctx := context.Background()\u00a0 \u00a0 \u00a0 \u00a0 client, err := video.NewClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 defer client.Close()\u00a0 \u00a0 \u00a0 \u00a0 op, err := client.AnnotateVideo(ctx, &videopb.AnnotateVideoRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Features: []videopb.Feature{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 videopb.Feature_SPEECH_TRANSCRIPTION,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 VideoContext: &videopb.VideoContext{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SpeechTranscriptionConfig: &videopb.SpeechTranscriptionConfig{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 LanguageCode: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"en-US\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 EnableAutomaticPunctuation: true,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 InputUri: file,\u00a0 \u00a0 \u00a0 \u00a0 })\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 resp, err := op.Wait(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 // A single video was processed. Get the first result.\u00a0 \u00a0 \u00a0 \u00a0 result := resp.AnnotationResults[0]\u00a0 \u00a0 \u00a0 \u00a0 for _, transcription := range result.SpeechTranscriptions {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // The number of alternatives for each transcription is limited by\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // SpeechTranscriptionConfig.MaxAlternatives.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // Each alternative is a different possible transcription\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // and has its own confidence score.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 for _, alternative := range transcription.GetAlternatives() {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Alternative level information:\\n\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"\\tTranscript: %v\\n\", alternative.GetTranscript())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"\\tConfidence: %v\\n\", alternative.GetConfidence())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Word level information:\\n\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 for _, wordInfo := range alternative.GetWords() {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 startTime := wordInfo.GetStartTime()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 endTime := wordInfo.GetEndTime()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"\\t%4.1f - %4.1f: %v (speaker %v)\\n\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float64(startTime.GetSeconds())+float64(startTime.GetNanos())*1e-9, // start as seconds\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float64(endTime.GetSeconds())+float64(endTime.GetNanos())*1e-9, \u00a0 \u00a0 // end as seconds\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 wordInfo.GetWord(),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 wordInfo.GetSpeakerTag())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 return nil}\n```\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/video/src/main/java/video/Detect.java) \n```\n// Instantiate a com.google.cloud.videointelligence.v1.VideoIntelligenceServiceClienttry (VideoIntelligenceServiceClient client = VideoIntelligenceServiceClient.create()) {\u00a0 // Set the language code\u00a0 SpeechTranscriptionConfig config =\u00a0 \u00a0 \u00a0 SpeechTranscriptionConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setLanguageCode(\"en-US\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEnableAutomaticPunctuation(true)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 // Set the video context with the above configuration\u00a0 VideoContext context = VideoContext.newBuilder().setSpeechTranscriptionConfig(config).build();\u00a0 // Create the request\u00a0 AnnotateVideoRequest request =\u00a0 \u00a0 \u00a0 AnnotateVideoRequest.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputUri(gcsUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addFeatures(Feature.SPEECH_TRANSCRIPTION)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setVideoContext(context)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 // asynchronously perform speech transcription on videos\u00a0 OperationFuture<AnnotateVideoResponse, AnnotateVideoProgress> response =\u00a0 \u00a0 \u00a0 client.annotateVideoAsync(request);\u00a0 System.out.println(\"Waiting for operation to complete...\");\u00a0 // Display the results\u00a0 for (VideoAnnotationResults results :\u00a0 \u00a0 \u00a0 response.get(600, TimeUnit.SECONDS).getAnnotationResultsList()) {\u00a0 \u00a0 for (SpeechTranscription speechTranscription : results.getSpeechTranscriptionsList()) {\u00a0 \u00a0 \u00a0 try {\u00a0 \u00a0 \u00a0 \u00a0 // Print the transcription\u00a0 \u00a0 \u00a0 \u00a0 if (speechTranscription.getAlternativesCount() > 0) {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SpeechRecognitionAlternative alternative = speechTranscription.getAlternatives(0);\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.printf(\"Transcript: %s\\n\", alternative.getTranscript());\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.printf(\"Confidence: %.2f\\n\", alternative.getConfidence());\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Word level information:\");\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 for (WordInfo wordInfo : alternative.getWordsList()) {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 double startTime =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 wordInfo.getStartTime().getSeconds() + wordInfo.getStartTime().getNanos() / 1e9;\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 double endTime =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 wordInfo.getEndTime().getSeconds() + wordInfo.getEndTime().getNanos() / 1e9;\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.printf(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\t%4.2fs - %4.2fs: %s\\n\", startTime, endTime, wordInfo.getWord());\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 } else {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"No transcription found\");\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 } catch (IndexOutOfBoundsException ioe) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Could not retrieve frame: \" + ioe.getMessage());\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}\n```\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/video-intelligence/analyze.js) \n```\n// Imports the Google Cloud Video Intelligence libraryconst videoIntelligence = require('@google-cloud/video-intelligence');// Creates a clientconst client = new videoIntelligence.VideoIntelligenceServiceClient();/**\u00a0* TODO(developer): Uncomment the following line before running the sample.\u00a0*/// const gcsUri = 'GCS URI of video to analyze, e.g. gs://my-bucket/my-video.mp4';async function analyzeVideoTranscript() {\u00a0 const videoContext = {\u00a0 \u00a0 speechTranscriptionConfig: {\u00a0 \u00a0 \u00a0 languageCode: 'en-US',\u00a0 \u00a0 \u00a0 enableAutomaticPunctuation: true,\u00a0 \u00a0 },\u00a0 };\u00a0 const request = {\u00a0 \u00a0 inputUri: gcsUri,\u00a0 \u00a0 features: ['SPEECH_TRANSCRIPTION'],\u00a0 \u00a0 videoContext: videoContext,\u00a0 };\u00a0 const [operation] = await client.annotateVideo(request);\u00a0 console.log('Waiting for operation to complete...');\u00a0 const [operationResult] = await operation.promise();\u00a0 // There is only one annotation_result since only\u00a0 // one video is processed.\u00a0 const annotationResults = operationResult.annotationResults[0];\u00a0 for (const speechTranscription of annotationResults.speechTranscriptions) {\u00a0 \u00a0 // The number of alternatives for each transcription is limited by\u00a0 \u00a0 // SpeechTranscriptionConfig.max_alternatives.\u00a0 \u00a0 // Each alternative is a different possible transcription\u00a0 \u00a0 // and has its own confidence score.\u00a0 \u00a0 for (const alternative of speechTranscription.alternatives) {\u00a0 \u00a0 \u00a0 console.log('Alternative level information:');\u00a0 \u00a0 \u00a0 console.log(`Transcript: ${alternative.transcript}`);\u00a0 \u00a0 \u00a0 console.log(`Confidence: ${alternative.confidence}`);\u00a0 \u00a0 \u00a0 console.log('Word level information:');\u00a0 \u00a0 \u00a0 for (const wordInfo of alternative.words) {\u00a0 \u00a0 \u00a0 \u00a0 const word = wordInfo.word;\u00a0 \u00a0 \u00a0 \u00a0 const start_time =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 wordInfo.startTime.seconds + wordInfo.startTime.nanos * 1e-9;\u00a0 \u00a0 \u00a0 \u00a0 const end_time =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 wordInfo.endTime.seconds + wordInfo.endTime.nanos * 1e-9;\u00a0 \u00a0 \u00a0 \u00a0 console.log('\\t' + start_time + 's - ' + end_time + 's: ' + word);\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}analyzeVideoTranscript();\n```\u8981\u5411 Video Intelligence \u9032\u884c\u8eab\u4efd\u9a57\u8b49\uff0c\u8acb\u8a2d\u7f6e\u61c9\u7528\u9ed8\u8a8d\u6191\u64da\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7232\u672c\u5730\u958b\u767c\u74b0\u5883\u8a2d\u7f6e\u8eab\u4efd\u9a57\u8b49](https://cloud.google.com/docs/authentication/provide-credentials-adc?hl=zh-cn#local-dev) \u3002\n [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/videointelligence/samples/analyze/analyze.py) \n```\n\"\"\"Transcribe speech from a video stored on GCS.\"\"\"from google.cloud import videointelligencevideo_client = videointelligence.VideoIntelligenceServiceClient()features = [videointelligence.Feature.SPEECH_TRANSCRIPTION]config = videointelligence.SpeechTranscriptionConfig(\u00a0 \u00a0 language_code=\"en-US\", enable_automatic_punctuation=True)video_context = videointelligence.VideoContext(speech_transcription_config=config)operation = video_client.annotate_video(\u00a0 \u00a0 request={\u00a0 \u00a0 \u00a0 \u00a0 \"features\": features,\u00a0 \u00a0 \u00a0 \u00a0 \"input_uri\": path,\u00a0 \u00a0 \u00a0 \u00a0 \"video_context\": video_context,\u00a0 \u00a0 })print(\"\\nProcessing video for speech transcription.\")result = operation.result(timeout=600)# There is only one annotation_result since only# one video is processed.annotation_results = result.annotation_results[0]for speech_transcription in annotation_results.speech_transcriptions:\u00a0 \u00a0 # The number of alternatives for each transcription is limited by\u00a0 \u00a0 # SpeechTranscriptionConfig.max_alternatives.\u00a0 \u00a0 # Each alternative is a different possible transcription\u00a0 \u00a0 # and has its own confidence score.\u00a0 \u00a0 for alternative in speech_transcription.alternatives:\u00a0 \u00a0 \u00a0 \u00a0 print(\"Alternative level information:\")\u00a0 \u00a0 \u00a0 \u00a0 print(\"Transcript: {}\".format(alternative.transcript))\u00a0 \u00a0 \u00a0 \u00a0 print(\"Confidence: {}\\n\".format(alternative.confidence))\u00a0 \u00a0 \u00a0 \u00a0 print(\"Word level information:\")\u00a0 \u00a0 \u00a0 \u00a0 for word_info in alternative.words:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 word = word_info.word\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 start_time = word_info.start_time\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 end_time = word_info.end_time\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\t{}s - {}s: {}\".format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 start_time.seconds + start_time.microseconds * 1e-6,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 end_time.seconds + end_time.microseconds * 1e-6,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 word,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\n```No preface\n **C#** \uff1a\u8acb\u6309\u7167\u201c\u5ba2\u6236\u7aef\u5eab\u201d\u9801\u9762\u4e0a\u7684 [C# \u8a2d\u7f6e\u8aaa\u660e](https://cloud.google.com/video-intelligence/docs/libraries?hl=zh-cn) \u9032\u884c\u64cd\u4f5c\uff0c\u7136\u5f8c\u8a2a\u554f [\u9069\u7528\u65bc .NET \u7684 Video Intelligence \u53c3\u8003\u6587\u6a94](https://googleapis.github.io/google-cloud-dotnet/docs/Google.Cloud.VideoIntelligence.V1/index.html) \u3002\n **PHP** \uff1a\u8acb\u6309\u7167\u5ba2\u6236\u7aef\u5eab\u9801\u9762\u4e0a\u7684 [PHP \u8a2d\u7f6e\u8aaa\u660e](https://cloud.google.com/video-intelligence/docs/libraries?hl=zh-cn) \u64cd\u4f5c\uff0c\u7136\u5f8c\u8a2a\u554f [PHP \u7248 Video Intelligence \u53c3\u8003\u6587\u6a94](https://cloud.google.com/php/docs/reference/cloud-videointelligence/latest?hl=zh-cn) \u3002\n **Ruby** \uff1a\u8acb\u6309\u7167\u5ba2\u6236\u7aef\u5eab\u9801\u9762\u4e0a\u7684 [Ruby \u8a2d\u7f6e\u8aaa\u660e](https://cloud.google.com/video-intelligence/docs/libraries?hl=zh-cn) \u64cd\u4f5c\uff0c\u7136\u5f8c\u8a2a\u554f [Ruby \u7248 Video Intelligence \u53c3\u8003\u6587\u6a94](https://googleapis.dev/ruby/google-cloud-video_intelligence/latest/Google/Cloud/VideoIntelligence/V1.html) \u3002", "guide": "Cloud Video Intelligence API"}