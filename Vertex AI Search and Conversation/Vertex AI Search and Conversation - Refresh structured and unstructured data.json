{"title": "Vertex AI Search and Conversation - Refresh structured and unstructured data", "url": "https://cloud.google.com/generative-ai-app-builder/docs/refresh-data?hl=zh-cn", "abstract": "# Vertex AI Search and Conversation - Refresh structured and unstructured data\nThis page describes refreshing [structured](#refresh-structured) and [unstructured](#refresh-unstructured) data.\nTo refresh your website apps, see [Refresh your web page](/generative-ai-app-builder/docs/recrawl-websites) .\n", "content": "## Refresh structured data\n**Note:** This feature is a Preview offering, subject to the \"Pre-GA Offerings Terms\" of the [GCP Service Specific Terms](https://cloud.google.com/terms/service-terms) . Pre-GA products and features may have limited support, and changes to pre-GA products and features may not be compatible with other pre-GA versions. For more information, see the [launch stage descriptions](https://cloud.google.com/products#product-launch-stages) . Further, by using this feature, you agree to the [Generative AI Preview terms and conditions](https://cloud.google.com/trustedtester/aitos) (\"Preview Terms\"). For this feature, you can process personal data as outlined in the [Cloud Data Processing Addendum](https://cloud.google.com/terms/data-processing-terms) , subject to applicable restrictions and obligations in the Agreement (as defined in the Preview Terms).\nYou can refresh the data in a structured data store as long as you use a schema that is the same or backward compatible with the schema in the data store. For example, adding only new fields to an existing schema is backward compatible.\nYou can refresh structured data in the Google Cloud console or using the API.\nTo use the Google Cloud console to refresh structured data from a branch of a data store, follow these steps:- In the Google Cloud console, go to the **Search and Conversation** page. [Search and Conversation](https://console.cloud.google.com/gen-app-builder/engines) \n- In the navigation menu, click **Data stores** .\n- In the **Name** column, click the data store that you want to edit.\n- On the **Documents** tab, click add **Import data** .\n- To refresh from Cloud Storage:- In the **Select a data source** pane, select **Cloud Storage** .\n- In the **Import data from Cloud Storage** pane, click **Browse** , select the bucket that contains your refreshed data, and then click **Select** . Alternatively, enter the bucket location directly in the **gs://** field.\n- Under **Data Import Options** , select an import option.\n- Click **Import** .\n- To refresh from BigQuery:- In the **Select a data source** pane, select **BigQuery** .\n- In the **Import data from BigQuery** pane, click **Browse** , select a table that contains your refreshed data, and then click **Select** . Alternatively, enter the table location directly in the **BigQuery path** field.\n- Under **Data Import Options** , select an import option.\n- Click **Import** .Use the [documents.import](/generative-ai-app-builder/docs/reference/rest/v1beta/projects.locations.collections.dataStores.branches.documents/import) method to refresh your data, specifying the appropriate `reconciliationMode` value.\nTo refresh structured data from BigQuery using the command line, follow these steps:- Find your data store ID. If you already have your data store ID, skip to the next step.- In the Google Cloud console, go to the **Search and Conversation** page and in the navigation menu, click **Data stores** . [Go to the Data stores page](https://console.cloud.google.com/gen-app-builder/data-stores) \n- Click the name of your data store.\n- On the **Data** page for your data store, get the data store ID.\n- Import your structured data using BigQuery.```\ncurl -X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\\"https://discoveryengine.googleapis.com/v1beta/projects/PROJECT_ID/locations/global/collections/default_collection/dataStores/DATA_STORE_ID/branches/0/documents:import\" \\-d '{\u00a0 \"bigquerySource\": {\u00a0 \u00a0 \"projectId\": \"PROJECT_ID\",\u00a0 \u00a0 \"datasetId\":\"DATASET_ID\",\u00a0 \u00a0 \"tableId\": \"TABLE_ID\",\u00a0 \u00a0 \"dataSchema\": \"DATA_SCHEMA\",\u00a0 },\u00a0 \"reconciliationMode\": \"RECONCILIATION_MODE\",\u00a0 \"autoGenerateIds\": \"AUTO_GENERATE_IDS\",\u00a0 \"idField\": \"ID_FIELD\",\u00a0 \"errorConfig\": {\u00a0 \u00a0 \"gcsPrefix\": \"ERROR_DIRECTORY\"\u00a0 }}'\n```- : The ID of your project.\n- : The ID of your data store.\n- : The name of your BigQuery dataset.\n- : The name of your BigQuery table.\n- Optional. Values are`document`and`custom`. The default is`document`.- If you specify`document`, the BigQuery table that you use must conform to the following default BigQuery schema. You can define the ID of each document yourself, while wrapping all the data in the jsonData string.\n- If you specify`custom`, any BigQuery table schema is accepted, and Vertex AI Search and Conversation automatically generates the IDs for each document that is imported.\n- : Optional. A Cloud Storage directory for error information about the import\u2014for example,`gs://<your-gcs-bucket>/directory/import_errors`. Google recommends leaving this field empty to let Vertex AI Search and Conversation automatically create a temporary directory.\n- : Optional. Values are`FULL`and`INCREMENTAL`. Default is`INCREMENTAL`. Specifying`INCREMENTAL`causes an incremental refresh of data from BigQuery to your data store. This does an upsert operation, which adds new documents and replaces existing documents with updated documents with the same ID. Specifying`FULL`causes a full rebase of the documents in your data store. In other words, new and updated documents are added to your data store, and documents that are not in BigQuery are removed from your data store. The`FULL`mode is helpful if you want to automatically delete documents that you no longer need.\n- : Optional. Specifies whether to automatically generate document IDs. If set to `true` , document IDs are generated based on a hash of the payload. Note that generated document IDs might not remain consistent over multiple imports. If you auto-generate IDs over multiple imports, Google highly recommends setting `reconciliationMode` to `FULL` to maintain consistent document IDs.Specify `autoGenerateIds` only when `bigquerySource.dataSchema` is set to `custom` . Otherwise an `INVALID_ARGUMENT` error is returned. If you don't specify `autoGenerateIds` or set it to `false` , you must specify `idField` . Otherwise the documents fail to import.\n- : Optional. Specifies which fields are the document IDs. For BigQuery source files, `idField` indicates the name of the column in the BigQuery table that contains the document IDs.Specify `idField` only when: (1) `bigquerySource.dataSchema` is set to `custom` , and (2) `auto_generate_ids` is set to `false` or is unspecified. Otherwise an `INVALID_ARGUMENT` error is returned.Note that the value of the BigQuery column name must be of string type, must be between 1 and 63 characters, and must conform to [RFC-1034](https://tools.ietf.org/html/rfc1034) . Otherwise, the documents fail to import.\nHere is the default BigQuery schema. Your BigQuery table must conform to this schema when you set `dataSchema` to `document` .```\n[\u00a0{\u00a0 \u00a0\"name\": \"id\",\u00a0 \u00a0\"mode\": \"REQUIRED\",\u00a0 \u00a0\"type\": \"STRING\",\u00a0 \u00a0\"fields\": []\u00a0},\u00a0{\u00a0 \u00a0\"name\": \"jsonData\",\u00a0 \u00a0\"mode\": \"NULLABLE\",\u00a0 \u00a0\"type\": \"STRING\",\u00a0 \u00a0\"fields\": []\u00a0}]\n```\n## Refresh unstructured data\nYou can refresh unstructured data in the Google Cloud console or using the API.\nTo use the Google Cloud console to refresh unstructured data from a branch of a data store, follow these steps:- In the Google Cloud console, go to the **Search and Conversation** page. [Search and Conversation](https://console.cloud.google.com/gen-app-builder/engines) \n- In the navigation menu, click **Data stores** .\n- In the **Name** column, click the data store that you want to edit.\n- On the **Documents** tab, click add **Import data** .\n- To ingest from a Cloud Storage bucket (with or without metadata):- In the **Select a data source** pane, select **Cloud Storage** .\n- In the **Import data from Cloud Storage** pane, click **Browse** , select the bucket that contains your refreshed data, and then click **Select** . Alternatively, enter the bucket location directly in the **gs://** field.\n- Under **Data Import Options** , select an import option.\n- Click **Import** .\n- To ingest from BigQuery:- In the **Select a data source** pane, select **BigQuery** .\n- In the **Import data from BigQuery** pane, click **Browse** , select a table that contains your refreshed data, and then click **Select** . Alternatively, enter the table location directly in the **BigQuery path** field.\n- Under **Data Import Options** , select an import option.\n- Click **Import** .To refresh unstructured data using the API, re-import it using the [documents.import](/generative-ai-app-builder/docs/reference/rest/v1beta/projects.locations.collections.dataStores.branches.documents/import) method, specifying the appropriate `reconciliationMode` value. For more information about importing unstructured data, see [Unstructured data](/generative-ai-app-builder/docs/create-engine-es#unstructured-data) .", "guide": "Vertex AI Search and Conversation"}