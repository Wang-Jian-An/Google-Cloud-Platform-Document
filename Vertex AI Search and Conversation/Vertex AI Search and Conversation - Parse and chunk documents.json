{"title": "Vertex AI Search and Conversation - Parse and chunk documents", "url": "https://cloud.google.com/generative-ai-app-builder/docs/parse-chunk-documents?hl=zh-cn", "abstract": "# Vertex AI Search and Conversation - Parse and chunk documents\nThis page describes how to use Vertex AI Search to parse and chunk your documents.\nYou can configure parsing or chunking settings in order to:\n- **Specify how Vertex AI Search parses content.** You can specify how to parse unstructured content when you upload it to Vertex AI Search. Vertex AI Search provides a digital parser, OCR parser for PDFs, and a layout parser. You can also bring your own parsed documents. Specifying OCR parsing for PDFs is recommended if you upload scanned PDFs, PDFs with text in images, or PDFs with many tables.See [Improve content detection with parsing](#parsing) .\n- **Use Vertex AI Search for retrieval-augmented generation (RAG).** Improve the output of LLMs with relevant data that you've uploaded to your Vertex AI Search app. To do this, you'll turn on document chunking, which indexes your data as chunks to improve relevance and decrease computational load for LLMs. You'll also turn on the layout parser, which detects document elements such as headings and lists, to improve how documents are chunked.For information about chunking for RAG and how to return chunks in search requests, see [Chunk documents for RAG](#parse-chunk-rag) .", "content": "## Parse documents\nYou can control content parsing in the following ways:\n- **Specify parser type.** You can specify the type of parsing to apply depending on file type:- **Digital parser.** The digital parser is on by default for all file types unless a different parser type is specified. The digital parser processes ingested documents if no other default parser is specified for the data store or if the specified parser doesn't support the file type of an ingested document.\n- **OCR parsing for PDFs** . Public preview. If you plan to upload scanned PDFs or PDFs with text inside images, you can turn on the OCR parser to improve PDF indexing. See [About OCR parsing for PDFs](#parsing-pdfs) .\n- **Layout parser.** Public preview. Turn on the layout parser for HTML, PDF, or DOCX files if you plan to use Vertex AI Search for RAG. See [Chunk documents for RAG](#parse-chunk-rag) for information about this parser and how to turn it on.\n- **Bring your own parsed document.** (Preview with allowlist) If you've already parsed your unstructured documents, you can import that pre-parsed content into Vertex AI Search. See [Bring your own parseddocument](#bring-parsed-document) .\n### Parser availability comparison\nThe following table lists the availability of each parser by document file types and shows which elements each parser can detect and parse.\n| File type | Digital parser       | OCR parser     | Layout parser                 |\n|:------------|:------------------------------------------|:---------------------------|:------------------------------------------------------------------------------|\n| HTML  | Detects paragraph elements    | nan      | Detects paragraph, table, list, title, and heading elements     |\n| PDF   | Detects paragraph (digital text) elements | Detects paragraph elements | Detects paragraph, table, title, and heading elements       |\n| DOCX  | Detects paragraph elements    | nan      | Detects paragraph, table, list, title, heading, header, and footnote elements |\n| PPTX  | Detects paragraph elements    | nan      | nan                   |\n| TXT   | Detects paragraph elements    | nan      | nan                   |\n### Digital parser\nThe digital parser extracts machine-readable text from documents. It detects text blocks, but not document elements such as tables, lists, and headings.\nThe digital parser is used as the default if you don't specify a different parser as the default during data store creation or if a specified parser doesn't support a file type that's being uploaded.\n### OCR parser for PDFs\n**Note:** The OCR parser is in Public preview. The OCR parser is offered without charge until it reaches General Availability.\nIf you have non-searchable PDFs (scanned PDFs or PDFs with text inside images, such as infographics) Google recommends turning on optical character recognition (OCR) processing during data store creation. This allows Vertex AI Search to extract paragraph elements.\nIf you have searchable PDFs or other digital formats that are mostly composed of machine-readable text, you typically don't need to use the OCR parser. However, if you have PDFs that have both non-searchable text (such as scanned text or infographics) and machine-readable text, you can set the field `useNativeText` to true when specifying the OCR parser. In this case, machine-readable text is merged with OCR parsing outputs to improve text extraction quality.\nOCR processing features are available for generic search apps with unstructured data stores.\nThe OCR processor can parse a maximum of 80 pages per PDF file. For long PDFs, the OCR processor parses the first 80 pages and the default parser parses the rest.\n### Layout parser\n**Note:** The layout parser is in Public preview. The layout parser is offered without charge until it reaches General Availability.\nLayout parsing lets Vertex AI Search detect layouts for PDF, HTML, and DOCX files. Vertex AI Search can then identify content elements like text blocks, tables, lists and structural elements such as titles and headings and use them to define the organization and hierarchy of a document.\nYou can either turn on layout parsing for all file types or specify which file types to turn it on for. The layout parser detects content elements like paragraphs, tables, lists, and structural elements like titles, headings, headers, footnotes.\nThe layout parser is available only when using document chunking for RAG. When document chunking is turned on, Vertex AI Search breaks documents up into chunks at ingestion time and can return documents as chunks. Detecting document layout enables content-aware chunking and enhances search and answer generation related to document elements. For more information about chunking documents for RAG, see [Chunk documents for RAG](#parse-chunk-rag) .\nThe layout parser supports a maximum PDF file size of 40 MB and a daily cap of 100 document files per project.\n### Specify a default parser\nBy including the [documentProcessingConfig](/generative-ai-app-builder/docs/reference/rest/v1alpha/DocumentProcessingConfig) field when you create a data store, you can specify a default parser for that data store. If you don't include `documentProcessingConfig.defaultParsingConfig` , the digital parser will be used. The digital parser is also used if the specified parser is not available for a file type.\nTo specify a default parser:\n- When [creating a search data store](/generative-ai-app-builder/docs/create-data-store-es) using the API, include `documentProcessingConfig.defaultParsingConfig` in the data store creation request. You can specify the OCR parser, the layout parser, or the digital parser:- To specify the OCR parser for PDFs:```\n\"documentProcessingConfig\": {\u00a0 \"defaultParsingConfig\": {\u00a0 \u00a0 \"ocrParsingConfig\": {\u00a0 \u00a0 \u00a0 \"useNativeText\": \"NATIVE_TEXT_BOOLEAN\"\u00a0 \u00a0 }\u00a0 }}\n```- : Optional. Set only if you're ingesting PDFs. If set to`true`, this turns on machine-readable text processing for the OCR parser. The default is`false`.\n- To specify the layout parser:```\n\"documentProcessingConfig\": {\u00a0 \"defaultParsingConfig\": {\u00a0 \u00a0 \"layoutParsingConfig\": {}\u00a0 }}\n```\n- To specify the digital parser: **Note:** Specifying the digital parser as `defaultParsingConfig` is typically not necessary. When no other parser is explicitly specified, the digital parser is used by default.```\n\u00a0\"documentProcessingConfig\": {\u00a0 \u00a0 \"defaultParsingConfig\": { \"digitalParsingConfig\": {} }\u00a0}\n```\nThe following example specifies during data store creation that the OCR parser will be the default parser. Because the OCR parser only applies to PDF files, all PDF files that are ingested will be processed by the OCR parser, and any other file types will be processed by the digital parser.\n```\ncurl -X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\-H \"X-Goog-User-Project: exampleproject\" \\\"https://discoveryengine.googleapis.com/v1alpha/projects/exampleproject/locations/global/collections/default_collection/dataStores?dataStoreId=datastore123\" \\-d '{\u00a0 \"displayName\": \"exampledatastore\",\u00a0 \"industryVertical\": \"GENERIC\",\u00a0 \"solutionTypes\": [\"SOLUTION_TYPE_SEARCH\"],\u00a0 \"contentConfig\": \"CONTENT_REQUIRED\",\u00a0 \"documentProcessingConfig\": {\u00a0 \u00a0 \"defaultParsingConfig\": {\u00a0 \u00a0 \u00a0 \"ocrParsingConfig\": {\u00a0 \u00a0 \u00a0 \u00a0 \"useNativeText\": \"false\"\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}'\n```\n### Specify parser overrides for file types\nYou can specify that a particular file type (PDF, HTML, or DOCX) should be parsed by a different parser than the default parser. To do so, include [documentProcessingConfig](/generative-ai-app-builder/docs/reference/rest/v1alpha/DocumentProcessingConfig) in your data store creation request and specify the override parser. If you don't specify a default parser, then the digital parser is the default.\nTo specify a file-type-specific parser override:\n- When [creating a search data store](/generative-ai-app-builder/docs/create-data-store-es) using the API, include `documentProcessingConfig.defaultParsingConfig` in the data store creation request.You can specify a parser for `pdf` , `html` , or `docx` :```\n\"documentProcessingConfig\": {\u00a0 \"parsingConfigOverrides\": {\u00a0 \u00a0 \"FILE_TYPE\": { PARSING_CONFIG },\u00a0 }\u00a0}\n```Replace the following:- : Accepted values are`pdf`,`html`, and`docx`.\n- : Specify the configuration for the parser that you want to apply to the file type. You can specify the OCR parser, the layout parser, or the digital parser:- To specify the OCR parser for PDFs:```\n\"ocrParsingConfig\": {\u00a0 \"useNativeText\": \"NATIVE_TEXT_BOOLEAN\"}\n```- : Optional. Set only if you're ingesting PDFs. If set to`true`, this turns on machine-readable text processing for the OCR parser. The default is`false`.\n- To specify the layout parser:```\n\"layoutParsingConfig\": {}\n```\n- To specify the digital parser:```\n\"documentProcessingConfig\": {\u00a0 \"defaultParsingConfig\": { \"digitalParsingConfig\": {} }}\n```The following example specifies during data store creation that PDF files should be processed by the OCR parser and that HTML files should be processed by the layout parser. In this case, any files other than PDF and HTML files would be processed by the digital parser.\n```\ncurl -X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\-H \"X-Goog-User-Project: exampleproject\" \\\"https://discoveryengine.googleapis.com/v1alpha/projects/exampleproject/locations/global/collections/default_collection/dataStores?dataStoreId=datastore123\" \\-d '{\u00a0 \"displayName\": \"exampledatastore\",\u00a0 \"industryVertical\": \"GENERIC\",\u00a0 \"solutionTypes\": [\"SOLUTION_TYPE_SEARCH\"],\u00a0 \"contentConfig\": \"CONTENT_REQUIRED\",\u00a0 \"documentProcessingConfig\": {\u00a0 \u00a0 \"parsingConfigOverrides\": {\u00a0 \u00a0 \u00a0 \"pdf\": {\u00a0 \u00a0 \u00a0 \u00a0 \"ocrParsingConfig\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"useNativeText\": \"false\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \"html\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"layoutParsingConfig\": {}\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}'\n```\n### Bring your own parsed document\n**Note:** This feature is in Preview with allowlist.\nYou can import pre-parsed, unstructured documents into Vertex AI Search data stores. For example, instead of importing a raw PDF document, you can parse the PDF yourself and import the parsing result instead. This lets you import your documents in a structured way, ensuring that search and answer generation have information about the document's layout and elements.\nA parsed, unstructured document is represented by JSON that describes the unstructured document using a sequence of text, table, and list blocks. You import JSON files with your parsed unstructured document data in the same way that you import other types of unstructured documents, such as PDFs. When this feature is turned on, whenever a JSON file is uploaded and identified by either an `application/json` MIME type or a .JSON extension, it is treated as a parsed document.\nTo turn on this feature and for information about how to use it, contact your Google account team.\n## Chunk documents for RAG\nBy default, Vertex AI Search is optimized for document retrieval, where your search app returns a document such as a PDF or web page with each search result.\nDocument chunking features are available for generic search apps with unstructured data stores.\nVertex AI Search can instead be optimized for RAG, where your search app is primarily used to augment LLM output with your custom data.\nTo use Vertex AI Search for RAG, [turn on documentchunking](#specify-chunking) when you create your data store. When document chunking is turned on, Vertex AI Search breaks up your documents into chunks. In search results, your search app can return relevant chunks of data instead of full documents. Using chunked data for RAG increases relevance for LLM answers and reduces computational load for LLMs.\nThen when you make search requests to your app, specify that you need to return chunks in your responses.\n### Limitations\nThe following limitations apply to chunking:\n- Document chunking can't be turned on or off after data store creation.\n- You can make search requests for documents instead of chunks from a data store with document chunking turned on. However, data stores with document chunking turned on aren't optimized for returning documents. Documents are returned by aggregating chunks into documents.\n- When document chunking is turned on, search summaries and search with follow-ups are not supported.\n### Document chunking options\nThis section describes the options that you specify in order to turn on document chunking.\nDuring data store creation, turn on the following options so that Vertex AI Search can index your documents as chunks.\n- **Layout-aware document chunking.** To turn this option on, include `documentProcessingConfig` in your data store creation request and specify `ChunkingConfig.LayoutBasedChunkingConfig` .When layout-aware document chunking is turned on, Vertex AI Search detects a document's layout and take it into account during chunking. This improves semantic coherence and reduces noise in the content when it's used for retrieval and LLM generation. All text in a chunk will come from the same layout entity, such as headings, subheadings, and lists.\n- **Layout parsing.** To turn this option on, specify `ParsingConfig.LayoutParsingConfig` during data store creation.The layout parser detect layouts for PDF, HTML, and DOCX files. It identifies elements like text blocks, tables, lists, titles, and headings, and uses them to define the organization and hierarchy of a document.For more about layout parsing, see [Layout parsing](#layout-parsing) .\n### Turn on document chunking\nYou can turn on document chunking by including [documentProcessingConfig](/generative-ai-app-builder/docs/reference/rest/v1alpha/DocumentProcessingConfig) in your data store creation request and turning on layout-aware document chunking and layout parsing.\nTo turn on document chunking:\n- When [creating a search data store](/generative-ai-app-builder/docs/create-data-store-es) using the API, include `documentProcessingConfig.chunkingConfig` in the data store creation request.```\n\u00a0\"documentProcessingConfig\": {\u00a0 \u00a0\"chunkingConfig\": {\u00a0 \u00a0 \u00a0 \u00a0\"layoutBasedChunkingConfig\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"chunkSize\": CHUNK_SIZE_LIMIT,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"includeAncestorHeadings\": HEADINGS_BOOLEAN,\u00a0 \u00a0 \u00a0 \u00a0}\u00a0 \u00a0},\u00a0 \u00a0\"defaultParsingConfig\": {\u00a0 \u00a0 \u00a0\"layoutParsingConfig\": {}\u00a0 \u00a0}\u00a0}\n```Replace the following:- : Optional. The token size limit for each chunk. The default value is 500. Supported values are 100-500 (inclusive).\n- : Optional. Determines whether headings are included in each chunk. The default value is`false`. Appending title and headings at all levels to chunks from the middle of the document can help prevent context loss in chunk retrieval and ranking.\n### Get chunks in search requests\nAfter you've confirmed that your data has been chunked correctly, your Vertex AI Search can return chunked data in its search results.\nTo get chunked data:\n- When making a search request, specify `ContentSearchSpec.SearchResultMode` as `chunks` .```\ncontentSearchSpec\": {\u00a0 \"searchResultMode\": \"RESULT_MODE\"}\n```- : Determines whether search results are returned as full documents or in chunks. To get chunks, the data store must have document chunking turned on. Accepted values are`documents`and`chunks`. If document chunking is turned on for your data store, the default value is`chunks`.\nThe following example of a search query request sets `SearchResultMode` to `chunks` .\n```\ncurl -X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\-H \"X-Goog-User-Project: exampleproject\" \\\"https://discoveryengine.googleapis.com/v1alpha/projects/exampleproject/locations/global/collections/default_collection/dataStores/datastore123/default_search:search\" \\-d '{\u00a0 \u00a0 \"servingConfig\": \"projects/exampleproject/locations/global/collections/default_collection/dataStores/datastore123/servingConfigs/default_search\",\u00a0 \u00a0 \"query\": \"example query\",\u00a0 \u00a0 \"contentSearchSpec\": {\u00a0 \u00a0 \u00a0 \u00a0 \"searchResultMode\": \"chunks\"\u00a0 \u00a0 }}'\n```\n## What's next\n- [Create a search data store](/generative-ai-app-builder/docs/create-data-store-es)", "guide": "Vertex AI Search and Conversation"}