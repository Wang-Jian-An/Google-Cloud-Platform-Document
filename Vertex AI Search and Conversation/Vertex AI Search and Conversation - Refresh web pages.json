{"title": "Vertex AI Search and Conversation - Refresh web pages", "url": "https://cloud.google.com/generative-ai-app-builder/docs/recrawl-websites?hl=zh-cn", "abstract": "# Vertex AI Search and Conversation - Refresh web pages\n**Key Term:** The term can be used interchangeably with the term in the context of a website. Refreshing or recrawling fetches the most recent version of a page and it. Reindexing indexes documents that have already been crawled.\nIf advanced website indexing is enabled in your data store, the web pages in your data store are refreshed in the following ways:\n- Automatic refresh\n- Manual refresh\nThis page describes both these methods.\n", "content": "## Automatic refresh\nVertex AI Search performs automatic refresh as follows:\n- After you create a data store, it generates an initial index for the included pages.\n- After the initial indexing, it indexes any newly discovered pages and recrawls existing pages on a best-effort basis.\n- It regularly refreshes data stores that encounter a query rate of 50 queries/30 days.## Manual refresh\nIf you want to refresh specific web pages in a data store with [Advanced websiteindexing](/generative-ai-app-builder/docs/about-advanced-features#advanced-website-indexing) turned on, you can call the [recrawlUris](/generative-ai-app-builder/docs/reference/rest/v1alpha/projects.locations.collections.dataStores.siteSearchEngine/recrawlUris) method. You use the `uris` field to specify each web page that you want to crawl. The `recrawlUris` method is a [long-runningoperation](/generative-ai-app-builder/docs/long-running-operations) that runs until your specified web pages are crawled or until it times out after 24 hours, whichever comes first. If the `recrawlUris` method times out you can call the method again, specifying the web pages that remain to be crawled. You can poll the [operations.get](https://cloud.google.com/generative-ai-app-builder/docs/reference/rest/v1beta/projects.locations.collections.dataStores.branches.operations/get) method to [monitor the status of your recrawl operation](#monitor-status-of-recrawl) .\n**Note:** The [recrawlUris](/generative-ai-app-builder/docs/reference/rest/v1alpha/projects.locations.collections.dataStores.siteSearchEngine/recrawlUris) method recognizes **literal URIs, not URI patterns** . Any asterisks ( `*` ) in your URI will be treated as a regular character. This is different from specifying the URLs to index when creating a website data store. When creating a data store, you can specify individual web pages or use wildcards to specify an entire website or part of a website\u2014for example, `www.mysite.com/*` . By contrast, `recrawlUris` assumes `www.mysite.com/*` is a single page. For more information about creating a website data store, see [Website URLs](/generative-ai-app-builder/docs/create-data-store-es#website) .\n### Limits on recrawling\nThere are limits to how often you can crawl web pages and how many web pages that you can crawl at a time:\n- **Calls per day.** The maximum number of calls to the`recrawlUris`method allowed is five per day, per project.\n- **Web pages per call.** The maximum number of`uris`values that you can specify with a call to the`recrawlUris`method is 10,000.\n### Recrawl the web pages in your data store\nYou can manually crawl specific web pages in a data store that has [Advanced website indexing](/generative-ai-app-builder/docs/about-advanced-features#advanced-website-indexing) turned on.\nTo use the command line to crawl specific web pages in your data store, follow these steps:- Find your data store ID. If you already have your data store ID, skip to the next step.- In the Google Cloud console, go to the **Search and Conversation** page and in the navigation menu, click **Data stores** . [Go to the Data stores page](https://console.cloud.google.com/gen-app-builder/data-stores) \n- Click the name of your data store.\n- On the **Data** page for your data store, get the data store ID.\n- Call the [recrawlUris](/generative-ai-app-builder/docs/reference/rest/v1alpha/projects.locations.collections.dataStores.siteSearchEngine/recrawlUris) method, using the `uris` field to specify each web page that you want to crawl. Each `uri` represents a single page even if it contains asterisks ( `*` ). Wildcard patterns are not supported.```\ncurl -X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\-H \"X-Goog-User-Project: PROJECT_ID\" \\\"https://discoveryengine.googleapis.com/v1alpha/projects/PROJECT_ID/locations/global/collections/default_collection/dataStores/DATA_STORE_ID/siteSearchEngine:recrawlUris\" \\-d '{\u00a0 \"uris\": [URIS]}'\n```Replace the following:- : The ID of your project.\n- : The ID of your data store.\n- : The list of web pages that you want to crawl\u2014for example,`\"https://example.com/page-1\", \"https://example.com/page-2\", \"https://example.com/page-3\"`.\nThe output is similar to the following:```\n{\u00a0 \"name\": \"projects/PROJECT_ID/locations/global/collections/default_collection/dataStores/DATA_STORE_ID/operations/recrawl-uris-0123456789012345678,\u00a0 \"metadata\": {\u00a0 \u00a0 \"@type\": \"type.googleapis.com/google.cloud.discoveryengine.v1alpha.RecrawlUrisMetadata\"\u00a0 }}\n```\n- Save the `name` value as input for the `operations.get` operation when [monitoring the status of your recrawl operation](#monitor-status-of-recrawl) .### Monitor the status of your recrawl operation\nThe `recrawlUris` method, which you use to [crawl web pages in a datastore](#recrawl-web-pages) , is a [long-running operation](/generative-ai-app-builder/docs/long-running-operations) that runs until your specified web pages are crawled or until it times out after 24 hours, whichever comes first. You can monitor the status of the this long-running operation by polling the [operations.get](https://cloud.google.com/generative-ai-app-builder/docs/reference/rest/v1beta/projects.locations.collections.dataStores.branches.operations/get) method, specifying the `name` value returned by the `recrawlUris` method. Continue polling until the response indicates that either: (1) All of your web pages are crawled, or (2) The operation timed out before all of your web pages were crawled. If `recrawlUris` times out, you can call it again, specifying the websites that were not crawled.\nTo use the command line to monitor the status of a recrawl operation, follow these steps:- Find your data store ID. If you already have your data store ID, skip to the next step.- In the Google Cloud console, go to the **Search and Conversation** page and in the navigation menu, click **Data stores** . [Go to the Data stores page](https://console.cloud.google.com/gen-app-builder/data-stores) \n- Click the name of your data store.\n- On the **Data** page for your data store, get the data store ID.\n- Poll the [operations.get](https://cloud.google.com/generative-ai-app-builder/docs/reference/rest/v1beta/projects.locations.collections.dataStores.branches.operations/get) method.```\ncurl -X GET \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\-H \"X-Goog-User-Project: PROJECT_ID\" \\\"https://discoveryengine.googleapis.com/v1alpha/projects/OPERATION_NAME\"\n```Replace the following:- : The ID of your project.\n- : The ID of your data store.\n- : The operation name, found in the`name`field returned in your call to the`recrawlUris`method in [Recrawl the web pages in your data store](#recrawl-web-pages) . You can also get the operation name by [listing long-running operations](/generative-ai-app-builder/docs/long-running-operations#list-lros) .\n- Evaluate each response.- If a response indicates that there are pending URIs and the recrawl operation is not done, your web pages are still being crawled. Continue polling.\n- If a response indicates that there are no pending URIs (no `pendingCount` field is returned) and the recrawl operation is done, then your web pages are crawled. Stop polling\u2014you can quit this procedure.\n- If a response indicates that there are pending URIs and the recrawl operation is done, then the recrawl operation timed out (after 24 hours) before all of your web pages were crawled. Start again at [Recrawl theweb pages in your data store](#recrawl-web-pages) . Use the `failedUris` values in the `operations.get` response for the values in the `uris` field in your new call to the `recrawlUris` method.\n### Error messages\nWhen you are [monitoring the status of your recrawl operation](#monitor-status-of-recrawl) , if the recrawl operation times out while you are polling the `operations.get` method, `operations.get` returns error messages for web pages that were not crawled. The following list shows the error messages, along with actions you can take if you receive them.\n- **Page was crawled but was not indexed by Vertex AI Search within 24 hours.** To crawl and index this and other pending URIs, retry at [Recrawl the webpages in your data store](#recrawl-web-pages) . Use the `failedUris` values in the `operations.get` response for the values in the `uris` field in your new call to the `recrawlUris` method.\n- **Crawling was blocked by the site's robots.txt.** Unblock the URI in your website's robots.txt file and retry at [Recrawl the web pages in your data store](#recrawl-web-pages) .\n- **Page is unreachable.** Check the URI that you specified in your call to `recrawlUris` and retry at [Recrawl the web pages in your data store](#recrawl-web-pages) .\n- **Crawling timed out.** To crawl and index this and other pending URIs, retry at [Recrawl the web pages in your data store](#recrawl-web-pages) . Use the `failedUris` values in the `operations.get` response for the values in the `uris` field in your new call to the `recrawlUris` method.\n- **Page was rejected by Google crawler.** Retry at [Recrawl the web pages in your data store](#recrawl-web-pages) .\n- **URL could not be followed by Google crawler.** If there are multiple redirects, use the URI from the last redirect and retry at [Recrawl the webpages in your data store](#recrawl-web-pages) .\n- **Page was not found (404).** Check the URI that you specified in your call to `recrawlUris` and retry at [Recrawl the web pages in your data store](#recrawl-web-pages) .\n- **Page requires authentication.** Advanced website search does not support crawling web pages that require authentication.", "guide": "Vertex AI Search and Conversation"}