{"title": "Vertex AI Search and Conversation - Responsible AI", "url": "https://cloud.google.com/generative-ai-app-builder/docs/responsible-ai?hl=zh-cn", "abstract": "# Vertex AI Search and Conversation - Responsible AI\nVertex AI Search and Conversation lets developers tap into the power of Google's foundation models, search expertise, and conversational AI technologies to create enterprise-grade generative AI applications through [Vertex AI Conversation andVertex AI Search](/generative-ai-app-builder/docs/introduction) . As an early-stage technology, its evolving capabilities and uses create potential for misapplication, misuse, and unintended or unforeseen consequences. For example, Vertex AI Search and Conversation can generate output that you don't expect, including text that's offensive, insensitive, or factually incorrect.\nGiven these risks and complexities, Vertex AI Search and Conversation is designed with Google's [AI Principles](https://ai.google/principles/) in mind. However, it is important for developers to understand and test their models to deploy safely and responsibly. To aid developers, Vertex AI Search and Conversation has built-in safety filters to help customers block potentially harmful outputs within their use case. For more information, see [Safety settings for Vertex AI Search](#safety-settings-search) .\nWhen Vertex AI Search and Conversation is integrated into a customer's unique use case and context, additional responsible AI considerations and model limitations might need to be considered. We encourage customers to leverage fairness, interpretability, privacy, and security [recommendedpractices](https://ai.google/responsibilities/responsible-ai-practices/) .\n", "content": "## Safety settings for Vertex AI Search\nVertex AI Search offers SafeSearch filters to filter explicit website search results. Explicit results might include content like pornography, violence, and gore. SafeSearch filtering is not available for private content.\nSummarization (both for website search and private content) filters out responses such as derogatory, sexually explicit, toxic, or violent information. Additionally, the summarization response contains safety attributes, which include \"harmful categories\" and topics that might be considered sensitive.\n### Website search\nSafeSearch can be applied to public content indexed by Vertex AI Search, such as [websites](/generative-ai-app-builder/docs/enterprise-search-introduction#websites) . When SafeSearch is on, Vertex AI Search helps filter out explicit content in a customer's Vertex AI Search results for all queries across images, videos, and websites. While those filters are not 100% accurate, we continuously evaluate and update filtering capabilities.\nIn certain contexts and use cases, customers might require access to a wide range of information, even if it includes explicit content, to gather comprehensive insights and results from Vertex AI Search. Customers can enable and disable safety filters using the API by setting `safe_search` to \"true\" or \"false\".\nTo enable SafeSearch for Vertex AI Search, use the following API call:\n```\ncurl -X POST\\\u00a0-H \"Authorization: Bearer $(gcloud auth application-default print-access-token)\"\u00a0-H \"Content-Type: application/json\"\\\"https://discoveryengine.googleapis.com/v1/projects/PROJECT_ID/locations/global/collections/default_collection/dataStores/DATA_STORE_ID/servingConfigs/default_config:search\"\u00a0 \u00a0 \u00a0-d '{\u00a0 \u00a0 \u00a0 \"query\": { \"input\": \"FREE_TEXT\"},\u00a0 \"serving_config\": \"SERVING_CONFIG_ID\",\u00a0 \"safe_search\": \"true\",}'\n```\nTo enable SafeSearch for Search with follow-ups in Vertex AI Search, use the following API call:\n```\ncurl -X POST \\-H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\-H \"Content-Type: application/json\" \\\"https://discoveryengine.googleapis.com/v1beta/projects/PROJECT_ID/locations/global/collections/default_collection/dataStores/DATA_STORE_ID/conversations/CONVERSATION_ID:converse\" \\-d '{\u00a0 \"query\": { \"input\": \"FREE_TEXT\"},\u00a0 \"serving_config\": \"SERVING_CONFIG_ID\",\u00a0 \"safe_search\": \"true\",}'\n```\nThe `safe_search` setting applies to search results and also to Vertex AI Search outputs like summarization (which is based on the search results).\nVertex AI Search outputs, such as summarization, are assessed against a list of safety attributes which filter potentially harmful content even when `safe_search` is turned off.\n### Summarization for private content and website search\nVertex AI Search outputs, such as summarization, are assessed against a list of safety attributes, which filters potentially harmful content such as derogatory, sexually explicit, toxic, or violent information, even when `safe_search` for website search is turned off. Additionally, you can filter out responses which include \"harmful categories\" and topics that might be considered sensitive by using `safetyAttributes` in the Vertex AI Search API response.\n### Fallback responses\nIf the summarization model responds to a request with an empty string or a generic response, it means that either the input or the output is triggering a safety filter. In the Vertex AI Search API response, `SummarySkippedReason` is set to `BLOCKED_DUE_TO_POTENTIAL_POLICY_VIOLATION` if a potential policy violation is detected.\nIf you think that a safety filter is being inappropriately triggered, [report this issue](/support/docs/issue-trackers) via the Google Cloud console.\n## Safety settings for Vertex AI Conversation\nChat uses various safety filtering mechanisms on both user queries and agent answers. The filtering includes categories such as derogatory, sexually explicit, toxic, or violent information. This ensures that chat replies appropriately to unsafe queries and that replies are safe in general. You can also specify additional filters for content that you deem undesirable and define fallback responses when that filtering applies in the Dialogflow console. If you think that safety filtering is being inappropriately triggered, report this issue via the Google Cloud console.\n### Responsible AI best practices\nWhen leveraging Vertex AI Conversation, we recommended the following Responsible AI best practices:\n- Ensure end users are informed that they are interacting with a bot\n- If applicable, state to users if and when their responses are being recorded\n- Provide users a way to flag harmful responses\n### Limitations\nVertex AI Conversation incorporates responsibility in several ways including safety filters for categories such as derogatory, sexually explicit, toxic, or violent information. However, as outlined above, these safety filters are not 100% accurate. As we continue to evaluate and update our filtering capabilities, we encourage customers to provide model feedback, explore use cases that will lead to societal benefit, and avoid using Vertex AI Conversations in safety-critical contexts.\nVertex AI Conversation is one of several tools that can inform subject matter experts, and is not intended to be used in decision-making contexts without human oversight. When incorporating unstructured private data where safety filters are not enabled, we encourage a larger role of model evaluation and human validation prior to use.\n## Additional resources\n- Learn more about Google's recommendations for [Responsible AI practices](https://ai.google/responsibility/responsible-ai-practices/) \n- Read our blog, [A shared agenda for responsible AI progress](https://blog.google/technology/ai/a-shared-agenda-for-responsible-ai-progress/)", "guide": "Vertex AI Search and Conversation"}