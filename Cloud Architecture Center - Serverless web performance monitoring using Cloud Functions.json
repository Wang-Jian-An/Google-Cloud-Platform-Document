{"title": "Cloud Architecture Center - Serverless web performance monitoring using Cloud Functions", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Serverless web performance monitoring using Cloud Functions\nThis tutorial describes how to create a web-performance-monitoring app using Google Cloud serverless technologies.\nPerformance plays a [major role](https://developers.google.com/web/fundamentals/performance/why-performance-matters/) in the success of any web app. If your site performs poorly, you might experience fewer sign-ups and lower user retention, which will probably impact your business goals. Performance should be a key success criterion when designing, building, and testing your web app.\nHowever, page performance can also change over time as your app evolves. Developers can add or update images and scripts, or the underlying app serving infrastructure itself can change. Therefore, it's important to regularly monitor page performance. Typically, you store the performance metrics to enable historical analysis. It's also common practice to generate alerts if page performance falls below some defined thresholds.", "content": "## Objectives\n- Create a [Cloud Function](/functions) that uses headless Chrome to collect web page performance metrics.\n- Store the metrics in [Cloud Storage](/storage) .\n- Create another Cloud Function, triggered by the Cloud Storage creation event, to analyze the page metrics.\n- Store the analysis results in [Firestore](/firestore) .\n- Create another Cloud Function, triggered by the Firestore creation event, to publish an alert to [Pub/Sub](/pubsub) if page performance is poor.\n- Create a [Cloud Scheduler](/scheduler) job to periodically trigger the first Cloud Function.\n- Verify the outputs for success and for failure scenarios.\n## CostsThis tutorial uses billable components of Google Cloud, including:- Cloud Functions\n- Cloud Scheduler\n- Cloud Storage\n- Firestore\n- Pub/Sub\n- Container Registry\n- Cloud Build\nUse the [pricing calculator](/products/calculator#id=d8864505-8045-462f-804e-4920af970f1d) to generate a cost estimate based on your projected usage.## Before you begin\n## ArchitectureWeb performance monitoring operations are typically stateless and short-lived. They are also often event-driven, occurring either on a schedule or triggered as part of some other process, such as an automated testing pipeline. These characteristics make serverless architectures an appealing choice for implementing web analysis apps.\nIn this tutorial, you use various parts of the Google Cloud [serverless](/serverless) stack, including Cloud Functions, Firestore, Cloud Scheduler, and Pub/Sub. You don't have to manage the infrastructure for any of these services, and you pay only for what you use. The core of the app is implemented using Cloud Functions, which provides an event-driven and scalable serverless execution environment. Using Cloud Functions, you can create and connect apps using independent, loosely coupled pieces of logic.\nThe following diagram shows the architecture of the serverless solution that you create in this tutorial.## Preparing the environmentBefore you create the serverless environment, you get the code from GitHub, set variables, and prepare resources you need later for analyzing and storing.\n### Get the code and set environment variables\n- In the Google Cloud console, open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/?cloudshell=true) \n- Clone the repository that contains the code for the Cloud Functions used in this tutorial:```\ngit clone https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring.git\n```\n- Change to the functions directory:```\ncd solutions-serverless-web-monitoring/functions\n```\n- Set the current project ID and project number as shell variables:```\nexport PROJECT=$DEVSHELL_PROJECT_ID\nexport PROJECT_NUM=$(gcloud projects list \\\n --filter=\"$PROJECT\" \\\n --format=\"value(PROJECT_NUMBER)\")\n```\n- Set the default deployment region for Cloud Functions. The following example sets the region to `us-east1` , but you can change this to any [region where Cloud Functions is available](/functions/docs/locations) .```\nexport REGION=us-east1\ngcloud config set functions/region $REGION\n```\n### Create Cloud Storage bucketsIn this section, you create a Cloud Storage bucket to store the collected page performance data. You can choose any location or [storage class](/storage/docs/storage-classes) , but it's a good practice to create buckets in the same location as the Cloud Functions that will use the buckets.- In Cloud Shell, export a shell variable for the names of the Cloud Storage buckets that will store the metrics. Bucket names must be globally unique, so the following command uses your Google Cloud project number as a suffix on the bucket name.```\nexport METRICS_BUCKET=page-metrics-$PROJECT_NUM\n```\n- Use the `gsutil` tool to create the buckets:```\ngsutil mb -l $REGION gs://$METRICS_BUCKET\n```\n- Update the `env-vars.yaml` file with the bucket names. This file contains environment variables that you will pass to the Cloud Functions later.```\nsed -i \"s/\\[YOUR_METRICS_BUCKET\\]/$METRICS_BUCKET/\" env-vars.yaml\n```\n### Create a Firestore collectionIn a later section, you analyze the page performance metrics. In this section, you create a Firestore [collection](/firestore/docs/data-model) to store the results of each analysis.- In the Google Cloud console, go to the Firestore page. [Go to the Firestore page](https://console.cloud.google.com/firestore) \n- If you've never created a Firestore database before, perform the following steps:- Click **Select Native mode** to activate Firestore.\n- Select a regional location close to the region where your Cloud Functions will run.\n- Click **Create Database** .\nIt takes a few moments to complete the configuration.\n- Click **Start Collection** and set the collection ID to `page-metrics` .\n- Click **Save** .\n### Create a Pub/Sub topic and subscriptionTypically you want to notify interested systems and parties if the analysis indicates that a page is performing poorly. In this section, you create Pub/Sub topics that will contain messages that describe any poor performance.- In Cloud Shell, create a Pub/Sub topic named `performance-alerts` :```\ngcloud pubsub topics create performance-alerts\n```\n- Create a subscription to the topic. You use the subscription to verify that alert messages are being published to the topic.```\ngcloud pubsub subscriptions create performance-alerts-sub \\\n --topic performance-alerts\n```\n## Collecting page performance metricsMany websites use JavaScript to dynamically render page content. This makes performance analysis more complicated, because the client needs to emulate a browser in order to fully load the web page. The Node.js runtime for Cloud Functions has support for headless Chrome, which provides the functionality of a full web browser in a serverless environment.\n [Puppeteer](https://github.com/GoogleChrome/puppeteer) is a Node.js library built by the Chrome DevTools team that provides a high-level API to control headless Chrome. By default, Puppeteer installs a recent version of the browser alongside the library. Therefore, you can add Puppeteer as a dependency to the Cloud Function as an easy way to use headless Chrome within the function.\nMeasuring and analyzing web page performance is a large and complex field. For simplicity, in this tutorial you use Puppeteer to collect some top-level page performance metrics. However, you can also use Puppeteer and the [Chrome DevTools Protocol (CDP)](https://chromedevtools.github.io/devtools-protocol/) to collect more detailed information, such as timeline traces. You can also better represent your end-user experience by emulating network congestion and performing CPU throttling. For a good introduction to analyzing web page performance, see the [Chrome web developers site](https://developers.google.com/web/tools/chrome-devtools/evaluate-performance/) .\nNote that there are many factors that influence web page load times, including the performance characteristics of the client. It's important to establish baselines using the CPU and RAM configurations of the Cloud Function.\nThe following snippet from the `tracer/index.js` file shows how to use Puppeteer to load the web page:\n [  functions/tracer/index.js ](https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring/blob/HEAD/functions/tracer/index.js) [View on GitHub](https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring/blob/HEAD/functions/tracer/index.js) \n```\n// launch Puppeteer and start a Chrome DevTools Protocol (CDP) session// with performance tracking enabled.browser = await puppeteer.launch({\u00a0 headless: true,\u00a0 args: ['--no-sandbox']});const page = await browser.newPage();const client = await page.target().createCDPSession();await client.send('Performance.enable');// browse to the page, capture and write the performance metricsconsole.log('Fetching url: '+url.href);await page.goto(url.href, {\u00a0 'waitUntil' : 'networkidle0'});const performanceMetrics = await client.send('Performance.getMetrics');options = createUploadOptions('application/json', page.url());await writeToGcs(metricsBucket, filename, JSON.stringify(performanceMetrics), options);\n```- In Cloud Shell, deploy the `trace` Cloud Function:```\ngcloud functions deploy trace \\\n --trigger-http \\\n --runtime nodejs10 \\\n --memory 1GB \\\n --source tracer \\\n --env-vars-file env-vars.yaml \\\n --quiet\n```It can take several minutes to deploy the Cloud Function.The deployment parameters specify that the function should have an HTTP trigger, should use the Node.js 10 runtime, and should have 1 GB memory. This amount of memory is required in order to run headless Chrome. Environment variables are supplied to the function by using the `env-vars.yaml` file\nBy default, HTTP-triggered Cloud Functions allow unauthenticated invocations. Therefore, you must [secure](/functions/docs/securing) the trace function.- Remove the `cloudfunctions.invoker` IAM role for `allUsers` :```\ngcloud beta functions remove-iam-policy-binding trace \\\n --member allUsers \\\n --role roles/cloudfunctions.invoker\n```\n## Analyzing the metricsA typical goal of web-performance-monitoring exercises is to track performance against some defined benchmarks. If a particular metric exceeds an expected threshold, it can indicate a problem with a recent software release, or a problem with the underlying infrastructure.\nIn this section, you create a Cloud Function in Python to parse the page metrics and persist the results to a Firestore collection. The function evaluates the `FirstMeaningfulPaint` metric against an expected threshold, and marks the analysis result as problematic if the threshold is exceeded. `FirstMeaningfulPaint` is a [user-centric metric](https://developers.google.com/web/fundamentals/performance/user-centric-performance-metrics) that broadly describes when a page becomes useful to the user. You use a Cloud Storage trigger to execute the analysis function whenever a new file is written to the bucket that contains the metrics.\nThe following snippet from the `analyzer/main.py` file shows the function logic:\n [  functions/analyzer/main.py ](https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring/blob/HEAD/functions/analyzer/main.py) [View on GitHub](https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring/blob/HEAD/functions/analyzer/main.py) \n```\ndef analyze(data, context):\u00a0 \"\"\"Function entry point, triggered by creation of an object in a GCS bucket.\u00a0 The function reads the content of the triggering file, analyses its contents,\u00a0 and persists the results of the analysis to a new Firestore document.\u00a0 Args:\u00a0 \u00a0 data (dict): The trigger event payload.\u00a0 \u00a0 context (google.cloud.functions.Context): Metadata for the event.\u00a0 \"\"\"\u00a0 page_metrics = get_gcs_file_contents(data)\u00a0 max_time_meaningful_paint = int(os.environ.get('MAX_TIME_MEANINGFUL_PAINT'))\u00a0 analysis_result = analyze_metrics(data, page_metrics,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 max_time_meaningful_paint)\u00a0 docref = persist(analysis_result, data['name'])\u00a0 logging.info('Created new Firestore document %s/%s describing analysis of %s',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0docref.parent.id, docref.id, analysis_result['input_file'])\n```- Deploy the `analyze` Cloud Function:```\ngcloud functions deploy analyze \\\n --trigger-resource gs://$METRICS_BUCKET \\\n --trigger-event google.storage.object.finalize \\\n --runtime python37 \\\n --source analyzer \\\n --env-vars-file env-vars.yaml\n```The function is triggered by a `finalize` event in the metrics bucket, which is sent every time an object is created in the bucket. The function uses the Python 3.7 runtime.\n## Alerting on failuresTypically, you want to take action if the metrics analysis indicates a poorly performing page.\nIn this section, you create a Cloud Function to send a message to a Pub/Sub topic if page performance is unsatisfactory. The function is triggered every time a document is created in the Firestore collection. Interested parties can subscribe to the Pub/Sub topic and take appropriate action. For example, a support app could subscribe to the Pub/Sub messages and send an email, trigger a support pager, or open a bug.\nThe following snippet from the `alerter/main.py` file shows the function logic:\n [  functions/alerter/main.py ](https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring/blob/HEAD/functions/alerter/main.py) [View on GitHub](https://github.com/GoogleCloudPlatform/solutions-serverless-web-monitoring/blob/HEAD/functions/alerter/main.py) \n```\ndef generate_alert(data, context):\u00a0 \"\"\"Cloud Function entry point, triggered by a change to a Firestore document.\u00a0 If the triggering document indicates a Failed status, send the document to\u00a0 configured PubSub topic.\u00a0 Args:\u00a0 \u00a0 data (dict): The event payload.\u00a0 \u00a0 context (google.cloud.functions.Context): Metadata for the event.\u00a0 \"\"\"\u00a0 doc_fields = data['value']['fields']\u00a0 status = doc_fields['status']['stringValue']\u00a0 if 'FAIL' in status:\u00a0 \u00a0 global publish_client\u00a0 \u00a0 if not publish_client:\u00a0 \u00a0 \u00a0 publish_client = pubsub.PublisherClient()\u00a0 \u00a0 logging.info('Sending alert in response to %s status in document %s',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0status, context.resource)\u00a0 \u00a0 project = os.environ.get('GCP_PROJECT')\u00a0 \u00a0 topic = os.environ.get('ALERT_TOPIC')\u00a0 \u00a0 fqtn = 'projects/{}/topics/{}'.format(project, topic)\u00a0 \u00a0 msg = json.dumps(data['value']).encode('utf-8')\u00a0 \u00a0 publish_client.publish(fqtn, msg)\n```\nNotice that the alert is sent only if the status field indicates a failure.- Deploy the `alert` Cloud Function:```\ngcloud functions deploy alert \\\n --trigger-event providers/cloud.firestore/eventTypes/document.create \\\n --trigger-resource \"projects/$PROJECT/databases/(default)/documents/page-metrics/{any}\" \\\n --runtime python37 \\\n --source alerter \\\n --env-vars-file env-vars.yaml \\\n --entry-point generate_alert\n```The function is triggered by a `document.create` event in the `page-metrics` Firestore collection. The `{any}` suffix is a wildcard indicating that the function should be triggered any time a document is created in the collection.\n## Scheduling the analysisIt's good practice to regularly monitor page performance. For example, you might want to analyze a certain page every hour, every day, or every week. In this section, you create a Cloud Scheduler job to periodically run the the analysis pipeline by triggering the `trace` function.\nThe Cloud Scheduler job is executed using a service account that's been granted the required `cloudfunctions.invoker` IAM role for the `trace` function.\nSometimes web pages don't respond correctly, or requests time out, so retries are unavoidable with web analysis apps. It's therefore important to have retry logic in your app. Cloud Functions supports retries for [background functions](/functions/docs/writing/background) .\nRetries are not available for HTTP-triggered Cloud Functions, so you can't use Cloud Functions to retry the `trace` function. However, Cloud Scheduler supports retries. For more information on configuring retry parameters, see the [RetryConfig](/scheduler/docs/reference/rest/v1/projects.locations.jobs#RetryConfig) documentation.- Verify that the three Cloud Functions have been correctly deployed and are showing `ACTIVE` status:```\ngcloud functions list\n```\n- Create a new service account that will be used as the identity for executing the Cloud Scheduler job:```\ngcloud iam service-accounts create tracer-job-sa\n```\n- Grant the new service account the `cloudfunctions.invoker` IAM role for the `trace` function:```\ngcloud beta functions add-iam-policy-binding trace \\\n --role roles/cloudfunctions.invoker \\\n --member \"serviceAccount:tracer-job-sa@$PROJECT.iam.gserviceaccount.com\"\n```\n- Create a Cloud Scheduler job:```\ngcloud scheduler jobs create http traceWithRetry \\\n --uri=\"https://$REGION-$PROJECT.cloudfunctions.net/trace\" \\\n --http-method=POST \\\n --message-body=\"{\\\"url\\\":\\\"http://www.example.com\\\"}\" \\\n --headers=\"Content-Type=application/json\" \\\n --oidc-service-account-email=\"tracer-job-sa@$PROJECT.iam.gserviceaccount.com\" \\\n --schedule=\"0 3 * * *\" \\\n --time-zone=\"UTC\" \\\n --max-retry-attempts=3 \\\n --min-backoff=30s\n```Because the job will call the HTTP-triggered `trace` function, the command specifies the job type as `http` , and supplies the function trigger URL as the `uri` value. The page to analyze, in this case `www.example.com` , is provided in the `message-body` flag. The `oidc-service-account-email` flag defines the service account to use for authentication. The command indicates the number of retries to attempt using the `max-retry-attempts` flag, and the value passed with the `schedule` flag sets the run schedule to 3:00 AM UTC every day.\n## Verifying resultsIn this section, you verify that you get the expected behavior for both success and failure conditions.\n### Verify successThe Cloud Scheduler job won't run until the next scheduled time, which in this case is 3:00 AM UTC. To see the results immediately, you can manually trigger a run.- Wait 90 seconds for the scheduler job to finish initializing.\n- Run the Cloud Scheduler job manually:```\ngcloud scheduler jobs run traceWithRetry\n```\n- Wait about 30 seconds for the function pipeline to complete.\n- List the contents of the metrics bucket to show that page metrics have been collected:```\ngsutil ls -l gs://$METRICS_BUCKET\n```\n- In the Google Cloud console, open the Cloud Logging viewer page: [Go to the Logging page](https://console.cloud.google.com/logs/viewer?resource=cloud_function) You see log messages from each of the three Cloud Functions: `trace` , `analyze` , and `alert` . It can take a few moments for the logs to flow through, so you might need to refresh to the logs pane. \n- Make a note of the Firestore document ID, which is listed following the text `Created new Firestore document page-metrics/`\n- In the Google Cloud console, go to the Firestore page: [Go to the Firestore page](https://console.cloud.google.com/firestore/data/) \n- Inspect the document that contains results of the analysis. The document values indicate a `PASS` status and contain the latest page performance metrics.\n- In Cloud Shell, verify that no alert messages have been sent to the Pub/Sub topic by trying to pull a message off the subscription:```\ngcloud pubsub subscriptions pull \\\n projects/$PROJECT/subscriptions/performance-alerts-sub \\\n --auto-ack\n```You see no items listed.\n### Verify failure\n- Manually trigger the trace function. This time, you provide the [Google Cloud Tutorials](https://cloud.google.com/docs/tutorials) page as the URL. This page has a lot of dynamic content that increases the page load time over the expected maximum threshold.```\ngcloud functions call trace \\\n --data='{\"url\":\"https://cloud.google.com/docs/tutorials\"}'\n```Because you have project the `Owner` or `Editor` IAM role, you have sufficient permissions to invoke the function.\n- Wait about 30 seconds for the function pipeline to complete.\n- List the contents of the metrics bucket to verify that additional metrics have been collected:```\ngsutil ls -l gs://$METRICS_BUCKET\n```You now see two items in each bucket.\n- In the Google Cloud console, go to the Cloud Logging viewer page and filter for the Cloud Function logs: [Go to the Logging page](https://console.cloud.google.com/logs/viewer?resource=cloud_function) You see an error from the `analyze` function indicating that the page exceeded the maximum allowed load time. Again, you might need to refresh the logs pane to see the latest messages. \n- Make a note of the Firestore document ID.\n- In the Google Cloud console, go to the Firestore page: [Go to the Firestore page](https://console.cloud.google.com/firestore/data/) \n- Find the document that describes the failed analysis.The status field is marked as `FAIL` .\n- In Cloud Shell, verify that an alert message was sent to the Pub/Sub topic by pulling a message off the subscription.```\ngcloud pubsub subscriptions pull \\\n projects/$PROJECT/subscriptions/performance-alerts-sub \\\n --auto-ack\n```This time, you see the contents of the message.\n## Clean up\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Learn more about Google Cloud [serverless](/serverless) technologies.\n- Explore other Cloud Functions [tutorials](/functions/docs/tutorials) .\n- Watch the [video](https://youtu.be/lhZOFUY1weo) from Google I/O '18 that describes other uses for Puppeteer and headless Chrome.\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Cloud Architecture Center"}