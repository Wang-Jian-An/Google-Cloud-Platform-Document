{"title": "Compute Engine - Cloning a Microsoft SQL Server database on Compute Engine", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Cloning a Microsoft SQL Server database on Compute Engine\nThis tutorial shows two ways to clone a [Microsoft SQL Server database](https://en.wikipedia.org/wiki/Microsoft_SQL_Server) running on Compute Engine. One method uses [persistent disk snapshots](/compute/docs/disks/create-snapshots) . The other method uses native SQL Server backup and restore, transferring the backup using [Cloud Storage](/storage) . Cloud Storage is Google Cloud's object storage service. It offers a straightforward, security-enhanced, durable, and highly available way to store files.\nCloning is the process of copying an online database onto another server. The copy is independent of the existing database and is preserved as a point-in-time snapshot. You can use a cloned database for various purposes without putting a load on the production server or risking the integrity of production data. Some of these purposes include the following:- Performing analytical queries\n- Load testing or integration testing of your apps\n- Data extraction for populating data warehouses\n- Running experiments on the data\nEach cloning method described in this tutorial has advantages and disadvantages. The ideal method for you depends on your situation. The following table highlights some key issues.\n| Issue               | Method 1: Disk snapshots         | Method 2: Backup and restore using Cloud Storage         |\n|:--------------------------------------------------------------|:----------------------------------------------------------|:----------------------------------------------------------------------------------|\n| Additional disk space required on SQL Server instances  | No additional disk space required       | Additional space required for storing the backup file when creating and restoring |\n| Additional load on source SQL Server instances during cloning | No additional load          | Additional load on CPU and I/O when creating and uploading backup files   |\n| Duration of cloning           | Relatively fast for large databases      | Relatively slow for large databases            |\n| Can clone from SQL Server instances external to Google Cloud | No              | Yes                    |\n| Complexity             | A complex sequence of commands for attaching cloned disks | A relatively straightforward set of commands for cloning       |\n| Can leverage existing backup systems       | Yes, if backup system uses Google Cloud disk snapshots | Yes, if backup system writes native SQL Server backup files to Cloud Storage  |\n| Granularity of cloning          | Can clone only entire disks        | Can clone only the specified database            |\n| Data consistency            | Consistent at point of snapshot       | Consistent at point of backup              |\nThis tutorial assumes you're familiar with [Microsoft Windows](https://www.microsoft.com/windows) system administration, PowerShell, and Microsoft SQL Server administration using Microsoft [SQL Server Management Studio](https://docs.microsoft.com/sql/ssms/sql-server-management-studio-ssms) .", "content": "## Objectives\n- Learn how to run a SQL Server instance on Google Cloud.\n- Learn how to create a demo database on a secondary disk.\n- Learn how to clone a SQL Server database using [Compute Engine disk snapshots](/compute/docs/disks/create-snapshots) .\n- Learn how to clone a SQL Server database by transferring a backup using Cloud Storage.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Compute Engine](/compute/pricing) \n- [Cloud Storage](/storage/pricing) \n- Microsoft Windows and SQL server licenses\nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin- Enable the Compute Engine API.\n- [  Enable the API](https://console.cloud.google.com/flows/enableapi?apiid=compute_component) \nEnsure that you're meeting these additional prerequisites:- You use the [Google Chrome](https://www.google.com/chrome/) browser.\n- Install a Remote Desktop Protocol (RDP) client of your choice. For more information, see [Microsoft Remote Desktop clients](https://docs.microsoft.com/windows-server/remote/remote-desktop-services/clients/remote-desktop-clients) . If you already have an RDP client installed, you can skip this task.## Setting up the environmentTo complete this tutorial, you need to set up your computing environment with the following:- A SQL Server instance on Compute Engine (named`sql-server-prod`) to represent your production database server.\n- An additional disk (named`sql-server-prod-data`) that's attached to your production server for storing your production database.\n- A copy of the [Wide World Importers SQL Server sample database](https://github.com/Microsoft/sql-server-samples/releases/tag/wide-world-importers-v1.0) to simulate the production database that you want to clone.\n- A SQL Server instance on Compute Engine named`sql-server-test`to represent your testing database server. You clone your database onto this server.\nThe following diagram illustrates this architecture.\n### Create the production VM instanceTo simulate a production environment, you set up a Compute Engine VM instance running SQL Server on Windows Server.\nThe VM instance for this tutorial uses two disks: a 50 GB disk for the OS and user accounts, and a 100 GB disk for database storage.\nIn Compute Engine, using separate disks offers no [performance](/compute/docs/disks#pdspecs) benefits. Disk performance is determined by the total storage capacity of all disks attached to an instance and the total number of vCPUs on your VM instance. Therefore, the database and log file can reside on the same disk.\n **Note:** For simplicity in this tutorial, you give the VM instances' default service account full access to all Cloud APIs. In a production environment, it's best to grant access only to required Cloud APIs, or to use a specific service account with limited access.- In the Google Cloud console, go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Click **Create** .\n- In the **Name** field, type `sql-server-prod` .\n- For **Region** , select **us-east1** . **Note:** This tutorial uses the `us-east1` region and `us-east1-b` zone for its Google Cloud resources. If you choose a different region and zone, then replace references to `us-east1` and `us-east1-b` with your preferred region and zone.\n- For **Zone** , select **us-east1-b** .\n- Under **Machine configuration** , change **Machine type** to **n1-standard-2** (2 vCPU).\n- Next to the **Boot disk** description, click **Change** .\n- In the **Boot disk** panel, click the **Public images** tab.\n- In the **Operating System** drop-down list, select **SQL Server on Windows Server** .\n- In the **Version** drop-down list, select **SQL Server 2022 Standard on Windows Server 2022 Datacenter** .\n- Ensure that the following values are set:- **Boot disk type** is set to **Standard persistent disk** .\n- **Size (GB)** is set to **50** .\n- Click **Select** .\n- Under **Identity and API access** , set **Access scopes** to **Allow full access to all Cloud APIs** .\n- Expand **Management, security, disks, networking, sole tenancy** .\n- Click the **Disks** tab.\n- Click **Add new disk** .\n- In the **Name** field, type `sql-server-prod-data` .\n- In the **Size (GB)** field, type `100` .\n- Click **Done** .\n- Click **Create** .\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Initialize the following variables:```\nVPC_NAME=VPC_NAME\nSUBNET_NAME=SUBNET_NAME\n```Where:- ``: name of your VPC\n- ``: name of your subnet\n- Set your default [project ID](/resource-manager/docs/creating-managing-projects) :```\ngcloud config set project PROJECT_ID\n```Replace `` with the ID of your Google Cloud project.\n- Set your default region:```\ngcloud config set compute/region REGION\n```Replace `` with the ID of the region you want to deploy in.\n- Set your default zone:```\ngcloud config set compute/zone ZONE\n```Replace `` with the ID of the zone you want to deploy in.\n- Create a Compute Engine instance by using the app image for SQL Server 2022 Standard on Windows Server 2022 Datacenter:```\nREGION=$(gcloud config get-value compute/region)ZONE=$(gcloud config get-value compute/zone)gcloud compute instances create sql-server-prod \\\u00a0 \u00a0 --machine-type=n1-standard-2 \\\u00a0 \u00a0 --scopes=cloud-platform \\\u00a0 \u00a0 --image-family=sql-std-2022-win-2022 \\\u00a0 \u00a0 --image-project=windows-sql-cloud \\\u00a0 \u00a0 --boot-disk-size=50GB \\\u00a0 \u00a0 --boot-disk-device-name=sql-server-prod \\\u00a0 \u00a0 --create-disk=\"mode=rw,size=100,type=pd-standard,name=sql-server-prod-data,device-name=sql-server-prod-data\" \\\u00a0 \u00a0 --subnet=$SUBNET_NAME \n```This command grants the instance full access to Google Cloud APIs, creates a 100 GB secondary disk, and attaches the disk to the instance. Ignore the disk performance warning because you don't need high performance for this tutorial.### Connect to the VM instance\n- In the Google Cloud console, go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Wait about 5 minutes for the VM instance to be ready.To monitor the initialization process of the VM, view its serial port output in Cloud Shell:```\ngcloud compute instances tail-serial-port-output sql-server-prod\n```When you see the following message, the initialization is complete.```\nInstance setup finished. sql-server-prod is ready to use.\n```Press to stop monitoring the serial port.\n- Click the instance name `sql-server-prod` to open the **VM instancedetails** page.\n- Under **Remote access** , click **Set Windows password** , and then click **Set** to create your account on the remote machine.This step generates a password for you. Make a note of the password or copy it to a secure, temporary file.\n- In the [Compute Engine section](https://console.cloud.google.com/compute/instances) of the Google Cloud console, click the **RDP** dropdown and select the **Download the RDP file** option to download the RDP file for your instance.Use this file to connect to the instance using an RDP client. For more information, see [Microsoft Remote Desktop clients](https://docs.microsoft.com/windows-server/remote/remote-desktop-services/clients/remote-desktop-clients) .\n- When you're prompted, enter the password you just generated, and then click **OK** .\n- To accept the server certificate and log into your remote Windows instance, click **Continue** .\n- When you're prompted whether you want your computer discoverable by other PCs and devices on the network, click **No** .\n### Set up the additional diskThe second disk attached to the production instance is for storing your production database. This disk is blank, so you need to partition, format, and mount it.- In an RDP session connected to your`sql-server-prod`instance, click the **Start** button on the Windows taskbar, type`diskpart`, and then click **diskpart** to open DiskPart.\n- When you're prompted to let the app make changes, click **Yes** .\n- Display a lists of disks attached to your instance:```\nlist disk\n```The output is the following:```\nDisk \n### Status   Size  Free  Dyn Gpt\n-------- ------------- ------- ------- --- --Disk 0 Online   50 GB  0 B\nDisk 1 Online   100 GB 100 GB\n```Disk 1 (100 GB) is your data disk.\n- Select the data disk:```\nselect disk 1\n```\n- Initialize the disk:```\nclean\n```\n- Create a [GUID partition table](https://en.wikipedia.org/wiki/GUID_Partition_Table) :```\nconvert gpt\n```\n- Create the data partition by using the entire disk:```\ncreate partition primary\n```\n- List the available volumes:```\nlist volume\n```The output is the following:```\nVolume \n### Ltr Label  Fs  Type  Size  Status  Info\n---------- --- ----------- ----- ---------- ------- --------- -------Volume 0  C    NTFS Partition  49 GB Healthy Boot\nVolume 1      FAT32 Partition 100 MB Healthy System\nVolume 2      RAW Partition  99 GB Healthy\n```Volume 2 (99 GB) is your data disk.\n- Select the volume:```\nselect volume 2\n```\n- Format the partition with the [NTFS file system](https://wikipedia.org/wiki/NTFS) and label it `data` :```\nformat quick fs=ntfs label=data\n```\n- Mount the disk as drive D:```\nassign letter=d\n```\n- Exit DiskPart:```\nexit\n```\n### Download the sample databaseTo set up your environment for this cloning exercise, you need to do the following:- Create a directory structure on drive D (`data`) to store your database.\n- Download the [Wide World Importers SQL Server sample database](https://github.com/Microsoft/sql-server-samples/releases/tag/wide-world-importers-v1.0) full backup file. This database simulates the production database you want to clone.\nTo create the directory and download the backup file, follow these steps:- In your RDP session, click the **Start** button on the Windows taskbar, type `PowerShell` , and then select the Windows PowerShell app.\n- At the PowerShell prompt, create a directory structure for the database storage:```\nmkdir D:\\sql-server-data\\wideworldimporters\n```\n- Download the backup file to drive D:```\nbitsadmin /transfer sampledb /dynamic /download /priority FOREGROUND `\u00a0 https://github.com/Microsoft/sql-server-samples/releases/download/wide-world-importers-v1.0/WideWorldImporters-Full.bak `\u00a0 D:\\sql-server-data\\WideWorldImporters-Full.bak\n```\n### Restore the sample databaseYou need to restore the sample database to drive D ( `data` ), either interactively by using the Microsoft [SQL Server Management Studio (SSMS)](https://docs.microsoft.com/en-us/sql/ssms/sql-server-management-studio-ssms?view=sql-server-2017) wizards, or directly by running a Transact-SQL command.\n- In your RDP session, click the **Start** button on the Windows taskbar, type`ssms`, and then select **Microsoft SQL Server Management Studio (Run as Administrator)** .\n- After the app starts, click **Connect** to connect to the`sql-server-prod`database engine using Windows Authentication.\n- In Object Explorer, right-click **Databases** , and then select **Restore Database** .\n- Under **Source** , select **Device** , and then click the **[...]** button next to the device name.\n- In the **Select backup devices** dialog, ensure that **File** is selected for **Backup media type** , and then click **Add** .\n- In the file selector, browse to`D:\\sql-server-data`, click the`WideWorldImporters-Full.bak`file, and then click **OK** .\n- Click **OK** to close the **Select backup devices** dialog.The **Restore Database** dialog is now populated with data about the Wide World Importers database backup.\n- Under **Select a page** , click **Files** .\n- Select the **Relocate all files to folder** checkbox.\n- In both the **Data file folder** and **Log file folder** fields, enter `D:\\sql-server-data\\wideworldimporters` .\n- Click **OK** to start the restore operation.\nAfter a couple of minutes you're notified that the database is restored.- In your RDP session, click the **Start** button on the Windows taskbar, type`ssms`, and then select **Microsoft SQL Server Management Studio (Run as Administrator)** .\n- After the app starts, click **Connect** to connect to the`sql-server-prod`database engine using Windows Authentication.\n- Select **File** > **New** > **Query with Current Connection** to open a new query window.\n- Initiate a restore from the backup file you downloaded:```\nUSE [master]GORESTORE DATABASE [WideWorldImporters]\u00a0 FROM \u00a0DISK = N'D:\\SQL-SERVER-DATA\\WideWorldImporters-Full.bak'\u00a0 WITH \u00a0FILE = 1,\u00a0 MOVE N'WWI_Primary' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters.mdf',\u00a0 MOVE N'WWI_UserData' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters_UserData.ndf',\u00a0 MOVE N'WWI_Log' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters.ldf',\u00a0 MOVE N'WWI_InMemory_Data_1' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters_InMemory_Data_1',\u00a0 NOUNLOAD,\u00a0 STATS = 5GO\n```This command restores the database and log file into the `D:\\sql-server-data\\wideworldimporters` directory.\n- Right-click the query code and click **Execute** .Allow a couple of minutes for the database restore to complete. You can click **Refresh** in Object Explorer to see whether the database is listed in the Databases tree. After the database restore is finished, you can close the query window without saving.\nTo verify the sample database is functional, you can run a query.- In Microsoft SQL Server Management Studio, select **File** > **New** > **Query with Current Connection** to open a new query window, and then copy the following code:```\nSELECT top(100)\u00a0 i.InvoiceDate, i.InvoiceID, i.CustomerID, c.CustomerName,\u00a0 i.ConfirmedDeliveryTime, i.ConfirmedReceivedByFROM\u00a0 WideWorldImporters.Sales.Invoices i\u00a0 JOIN WideWorldImporters.Sales.Customers c\u00a0 ON i.CustomerID=c.CustomerIDWHERE i.ConfirmedDeliveryTime IS NOT NULLORDER BY i.InvoiceDate desc;\n```This query retrieves summary information from the 100 most recently delivered invoices.\n- Right-click the query window and click **Execute** .The **Results** pane displays the summary information.\n### Create the test VM instanceIn this section you create a SQL Server instance named `sql-server-test` as the destination for the cloned database. The configuration of this instance is identical to the production instance. However, you don't create a second data disk; instead, you attach the data disk later in this tutorial.\n- Go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Click **Create** .\n- In the **Name** field, type `sql-server-test` .\n- For **Region** , select **us-east1** . **Note:** This tutorial uses the `us-east1` region and `us-east1-b` zone for its Google Cloud resources. If you choose a different region and zone, then replace references to `us-east1` and `us-east1-b` with your preferred region and zone.\n- For **Zone** , select **us-east1-b** .\n- Under **Machine configuration** , change **Machine Type** to **n1-standard-2** ( **2 vCPU** ).\n- Next to the **Book disk** image, click **Change** .\n- In the **Boot disk** panel, click the **Public images** tab.\n- In the **Operating System** drop-down list, select **SQL Server on Windows Server** .\n- In the **Version** drop-down list, select **SQL Server 2022 Standard on Windows Server 2022 Datacenter** .\n- Ensure that the following values are set:- **Boot disk type** is set to **Standard persistent disk** .\n- **Size (GB)** is set to **50** .\n- Click **Select** .\n- Under **Identity and API access** , set **Access scopes** to **Allowfull access to all Cloud APIs** .\n- Click **Create** .\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Create the test SQL Server instance:```\ngcloud compute instances create sql-server-test \\\u00a0 \u00a0 --machine-type=n1-standard-2 \\\u00a0 \u00a0 --scopes=cloud-platform \\\u00a0 \u00a0 --image-family=sql-std-2022-win-2022 \\\u00a0 \u00a0 --image-project=windows-sql-cloud \\\u00a0 \u00a0 --boot-disk-size=50GB \\\u00a0 \u00a0 --boot-disk-device-name=sql-server-test \\\u00a0 \u00a0 --subnet=$SUBNET_NAME\n```You can ignore the disk performance warning because you don't need high performance for this tutorial.### Connect to the VM instance\n- In the Google Cloud console, go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Wait about 5 minutes for the VM instance to be ready.To monitor the initialization process of the VM, view its serial port output in Cloud Shell:```\ngcloud compute instances tail-serial-port-output sql-server-prod\n```When you see the following message, the initialization is complete.```\nInstance setup finished. sql-server-test is ready to use.\n```Press to stop monitoring the serial port.\n- Click the instance name `sql-server-test` to display the **VMinstance details** page.\n- Under **Remote access** , click **Set Windows password** , and then click **Set** to create your account on the remote machine.This step generates a password for you. Make a note of the password or copy it to a secure, temporary file.\n- In the [Compute Engine section](https://console.cloud.google.com/compute/instances) of the Google Cloud console, click the **RDP** dropdown and select the **Download the RDP file** option to download the RDP file for your instance.Use this file to connect to the instance using an RDP client. For more information, see [Microsoft Remote Desktop clients](https://docs.microsoft.com/windows-server/remote/remote-desktop-services/clients/remote-desktop-clients) .\n- When you're prompted, enter the password you just generated, and then click **OK** .\n- To accept the server certificate and log into your remote Windows instance, click **Continue** .\n- When you're prompted whether you want your PC discoverable, click **No** .\n## Cloning the database using Compute Engine disk snapshotsOne way to clone a SQL Server database running on Compute Engine is to store the database on a separate data disk and use persistent disk snapshots to create a clone of that disk.\n [Persistent disk snapshots](/compute/docs/disks/create-snapshots) let you get a point-in-time copy of on-disk data. Scheduling disk snapshots is one way to automatically back up your data.\nIn this section of the tutorial, you do the following:- Take a snapshot of the production server's data disk.\n- Create a new disk from the snapshot.\n- Mount the new disk onto the test server.\n- Attach the database on this disk to SQL Server on the test instance.\nThe following diagram shows how a database is cloned by using disk snapshots. **Note:** For simplicity in this tutorial, you create the production and test VM instances in the same project. In a true production environment, it's likely these instances would be in separate projects. Disk snapshots can be shared between projects using the [Google Cloud CLI or API](/compute/docs/images/sharing-images-across-projects) .\n### Create the disk snapshot\n- In the Google Cloud console, go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Click the name of the `sql-server-prod` instance.\n- On the **VM instance details** page, click the disk `sql-server-prod-data` .\n- Click **Create Snapshot** .\n- Name the snapshot `sql-server-prod-data-snapshot` .\n- For **Location** , select **Regional** .\n- Verify that the region is set to **us-east1** (the same as your VM instances). **Note:** This tutorial uses the `us-east1` region and `us-east1-b` zone for its Google Cloud resources. If you choose a different region and zone, then replace references to `us-east1` and `us-east1-b` with your preferred region and zone.\n- Select the **Enable VSS** option.This option uses the [Volume Shadow Copy Service](/compute/docs/instances/windows/creating-windows-persistent-disk-snapshot#create-snapshot) in Microsoft Windows to make a consistent snapshot.\n- Click **Create** .After a few minutes, your snapshot is created.\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Create a snapshot of your data disk in the same zone as the VM instance:```\ngcloud compute disks snapshot sql-server-prod-data \\\u00a0 \u00a0 \u00a0--snapshot-names=sql-server-prod-data-snapshot \\\u00a0 \u00a0 \u00a0--guest-flush \\\u00a0 \u00a0 \u00a0--zone=\"${ZONE}\"\n```The `--guest-flush` option uses the [Volume Shadow Copy Service](/compute/docs/instances/windows/creating-windows-persistent-disk-snapshot#create-snapshot) in Microsoft Windows to create a consistent snapshot. After a few minutes, your snapshot is created.### Attach the disk snapshot to the test instanceYou need to create a new data disk from the snapshot you created and then attach it to the `sql-server-test` instance.\nIn the following steps, you create a new persistent disk, use the snapshot of the production disk for its contents, and then attach the disk to the test instance.- In the Google Cloud console, go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Click the instance name `sql-server-test` .\n- On the **VM instance details** page, click **Edit** .\n- Click **Add new disk** .\n- Name the new disk `sql-server-test-data` .\n- For **Source Type** , select **Snapshot** .\n- For the `sql-server-prod-data-snapshot` instance you created, select the **Source snapshot** .\n- Ensure that **Mode** is set to **Read/Write** .\n- Click **Done** .\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Create a new persistent disk by using the snapshot of the production disk for its contents:```\ngcloud beta compute disks create sql-server-test-data \\\u00a0 \u00a0 \u00a0--size=100GB \\\u00a0 \u00a0 \u00a0--source-snapshot=sql-server-prod-data-snapshot \\\u00a0 \u00a0 \u00a0--zone=\"${ZONE}\"\n```\n- Attach the new disk to your `sql-server-test` instance with read-write permissions:```\ngcloud compute instances attach-disk sql-server-test \\\u00a0 \u00a0 --disk=sql-server-test-data --mode=rw\n```### Mount the new data disk in WindowsThe disk you created is attached to the VM instance but is offline, and the volume is set to read-only. To configure the volume as read-write and mountable, perform the following steps:- In the RDP client window that's connected to your`sql-server-test`instance, click the **Start** button on the Windows taskbar, type`diskpart`, and then click **diskpart** to open DiskPart.\n- When you're prompted to let the app make changes, click **Yes** .\n- Display a list of the disks attached to your instance:```\nlist disk\n```The output is the following:```\nDisk \n### Status   Size  Free  Dyn Gpt\n-------- ------------- ------- ------- --- --Disk 0 Online   50 GB  0 B\nDisk 1 Offline   100 GB  0 B  *\n \n```Your data disk (Disk 1, 100 GB) is offline.\n- Select the data disk:```\nselect disk 1\n```\n- Bring the disk online:```\nonline disk\n```\n- List the available volumes:```\nlist volume\n```The output is the following:```\nVolume \n### Ltr Label  Fs  Type  Size  Status  Info\n---------- --- ----------- ----- ---------- ------- --------- -------Volume 0  C    NTFS Partition  49 GB Healthy Boot\nVolume 1      FAT32 Partition 100 MB Healthy System\nVolume 2      RAW Partition  99 GB Healthy\n```Volume 2 (99 GB) is your data volume. It's listed as **Hidden** with no drive letter assigned.\n- Select the volume:```\nselect volume 2\n```\n- Clear the attributes that were set when you created the volume from the snapshot:```\nattr volume clear readonly hidden nodefaultdriveletter shadowcopy\n```This command makes the volume mountable.\n- Mount the volume as drive D:```\nassign letter=d\n```\n- Exit DiskPart:```\nexit\n```\n### Reset file ownership and permissionsBecause you created the data disk by taking a snapshot on the `sql-server-prod` instance, the user IDs for file ownership and permissions are different than those on the `sql-server-test` instance. You need to change the ownership of the files to a user on the `sql-server-test` instance and update the permissions to make the files readable for your local user and the `MSSQLSERVER` user.- In the RDP client window connected to your`sql-server-test`instance, click the **Start** button on the Windows taskbar, and then type`cmd`.\n- Open the Command Prompt app as an administrator.\n- Set the owner of the files in the `sql-server-data` folder to the `MSSQLSERVER` service user:```\nicacls d:\\sql-server-data /setowner \"nt service\\mssqlserver\" /t\n```\n- Reset all permissions on all files in the top-level `sql-server-data` folder:```\nicacls d:\\sql-server-data /reset /t\n```\n- Update the access control lists (ACLs) for the `sql-server-data` folder:```\nicacls d:\\sql-server-data /grant Administrators:(oi)(ci)f \"nt service\\mssqlserver\":(oi)(ci)f \"owner rights\":(oi)(ci)f \u00a0%USERNAME%:(oi)(ci)f\n```\n- Disable the inheritance from the root folder of the drive, so that only the preceding permissions are applied:```\nicacls d:\\sql-server-data /inheritancelevel:r\n```\n- Exit the Command Prompt app:```\nexit\n```\nThe SQL Server instance and the local user on the `sql-server-test` instance can now access the database files.\n### Attach the cloned databaseYou now attach the cloned database on drive D ( `data` ) to the test SQL Server instance. You can attach the database either interactively by using the Microsoft SQL Server Management Studio wizards, or directly by running a Transact-SQL command.\n- In the RDP session connected to your`sql-server-test`instance, click the **Start** button on the Windows taskbar, type`ssms`, and then select **Microsoft SQL Server Management Studio (Run as Administrator)** .\n- Click **Connect** to connect to the`sql-server-test`database engine using Windows Authentication.\n- In Object Explorer, right-click **Databases** , and then select **Attach** .\n- In the **Attach Databases** wizard, click **Add** .\n- Browse to the directory`D:\\sql-server-data\\wideworldimporters`, click the`WideWorldImporters.mdf`file, and then click **OK** .\n- Click **OK** to attach the database.After a few moments, your cloned database is attached. You can click **Refresh** in Object Explorer to see whether the database is listed in the Databases tree.\n- In an RDP session connected to your`sql-server-test`instance, click the **Start** button on the Windows taskbar, type`ssms`, and then select **Microsoft SQL Server Management Studio (Run as Administrator)** .\n- Click **Connect** to connect to the`sql-server-prod`database engine using Windows Authentication.\n- Select **File** > **New** > **Query with Current Connection** to open a new query window.\n- Attach the data and log files in the `D:\\sql-server-data\\wideworldimporters` directory:```\nUSE [master]GOCREATE DATABASE [WideWorldImporters] ON( FILENAME = N'D:\\sql-server-data\\wideworldimporters\\WideWorldImporters.mdf' ),( FILENAME = N'D:\\sql-server-data\\wideworldimporters\\WideWorldImporters.ldf' ),( FILENAME = N'D:\\sql-server-data\\wideworldimporters\\WideWorldImporters_UserData.ndf' )\u00a0FOR ATTACHGO\n```\n- Right-click the query code and click **Execute** .After a few moments, your cloned database is attached. You can click **Refresh** in Object Explorer to see whether your database is listed in the Databases tree. After the database is attached, you can close the query window without saving.\nTo verify that the sample database is functional, you can run a query.- In SQL Server Management Studio, select **File** > **New** > **Query withCurrent Connection** to open a new query window, and then copy the following code:```\nSELECT top(100)\u00a0 i.InvoiceDate, i.InvoiceID, i.CustomerID, c.CustomerName,\u00a0 i.ConfirmedDeliveryTime, i.ConfirmedReceivedByFROM\u00a0 WideWorldImporters.Sales.Invoices i\u00a0 JOIN WideWorldImporters.Sales.Customers c\u00a0 ON i.CustomerID=c.CustomerIDWHERE i.ConfirmedDeliveryTime IS NOT NULLORDER BY i.InvoiceDate desc;\n```This query retrieves summary information from the 100 most recently delivered invoices.\n- To run the query, right-click the query window, and then select **Execute** .The **Results** pane displays the summary information.\nNow that you have seen how to clone a database using persistent disk snapshots, you might want to try cloning a database by using backup and restore. To complete the tutorial for this second approach, you must delete the database that you cloned from the `sql-server-test` instance.\n### Delete the cloned databaseTo delete the cloned database you created by using disk snapshots, perform the following steps.\n- In the RDP session connected to your`sql-server-test`instance, open Microsoft SQL Server Management Studio, and then connect to the`sql-server-test`database engine.\n- In Object Explorer, expand **Databases** , right-click the`WorldWideImporters`database, and then select **Delete** .\n- In the **Delete Object** wizard, ensure that the **Close existing\nconnections** checkbox is selected.\n- Click **OK** .\n- In the RDP session connected to your`sql-server-test`instance, open Microsoft SQL Server Management Studio, and then connect to the`sql-server-test`database engine.\n- To close all connections to the `WideWorldImporters` database and delete it, copy the following script into a new query window, right-click the code, and then click **Execute** :```\nUSE [master]GOALTER DATABASE [WideWorldImporters] SET SINGLE_USER WITH ROLLBACK IMMEDIATEGODROP DATABASE [WideWorldImporters]GO\n```After the database is deleted, you can close the query window without saving. You can click **Refresh** in Object Explorer to confirm the database is deleted.\n## Cloning using backup and restoreA second method of cloning a SQL Server database running on Compute Engine is to use native SQL Server backup and restore. With this approach, you transfer the backup by using Cloud Storage.\nThis section of the tutorial uses resources that you created in the [Cloning the database using Compute Engine disk snapshots](#cloning_the_database_using_compute_engine_disk_snapshots) section of this tutorial. If you didn't complete that section, you must do so before continuing.\nIn this section of the tutorial, you do the following:- Create a Cloud Storage bucket.\n- Back up the database on the production server.\n- Copy the backup file from the production server to Cloud Storage.\n- Copy the backup file from Cloud Storage to the test server.\n- Restore the backup on the test instance.\nThe following diagram shows how a database is cloned by transferring a backup using Cloud Storage.Because systems outside of Google Cloud can be given access to Cloud Storage, you can use this approach to clone databases from external SQL Server instances.\n **Note:** This setup requires that the production and test instances have enough free disk space to temporarily store the backup file.\n### Create a Cloud Storage bucketYou need to create a Cloud Storage bucket that stores the backup files while you transfer them from the `sql-server-prod` instance to the `sql-server-test` instance.\n- In the Google Cloud console, go to the Cloud Storage **Browser** page. [Go to the Cloud Storage Browser page](https://console.cloud.google.com/storage/browser) \n- Click **Create bucket** .\n- Name the bucket `` -bucket.Replace the following:- ``: The ID of your Google Cloud project.\n- Expand **Choose a default storage class** , and then select **Regional** .\n- For **Location** , select **us-east1** . **Note:** This tutorial uses the `us-east1` region and `us-east1-b` zone for its Google Cloud resources. If you choose a different region and zone, then replace references to `us-east1` and `us-east1-b` with your preferred region and zone.\n- Click **Create** .\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Create a Cloud Storage bucket in the same region as your VM instances:```\ngsutil mb -l \"${REGION}\" \"gs://$(gcloud config get-value project)-bucket\"\n```### Make a full point-in-time backup of the databaseIn your production environment, you might already make backups. You can use these backups as a base for cloning your database. In this tutorial, you make a [copy-only backup](https://docs.microsoft.com/en-us/sql/relational-databases/backup-restore/copy-only-backups-sql-server?view=sql-server-2017) so that it doesn't impact any existing full or incremental backup schedules.\n **Note:** The article [Best practices for running SQL Server on Compute Engine](/compute/docs/instances/sql-server/best-practices) recommends using a local SSD (instead of a persistent disk) to temporarily store backup files. Although this tutorial uses another approach, this best practice can help to minimize the CPU and I/O usage associated with writing to persistent disks.- In the RDP session connected to your`sql-server-prod`instance, open Microsoft SQL Server Management Studio, and then connect to the`sql-server-prod`database engine.\n- In Object Explorer, expand **Databases** , right-click the`WorldWideImporters`database, and then select **Tasks** > **Back Up** .\n- In the **Back Up Database** wizard, ensure that the following values are set:- **Backup type** is set to **Full** .\n- **Copy-only backup** is selected.\n- **Back up to** is set to **Disk** .\n- To add a backup file, click **Add** .\n- In the **Destination** field, enter `D:\\sql-server-data\\WideWorldImporters-copy.bak` .\n- Select the **Media Options** page, and then select **Overwrite allexisting backup sets** .\n- Select the **Backup Options** page, and then change **Set backupcompression** to **Compress backup** .\n- To create the backup, click **OK** .The backup takes a few minutes to create.\n- In the RDP session connected to your`sql-server-prod`instance, open Microsoft SQL Server Management Studio, and then connect to the`sql-server-prod`database engine.\n- To perform a copy-only compressed backup of the `WideWorldImporters` database to the file `d:\\sql-server-data\\WideWorldImporters-copy.bak` , copy the following script into a new query window, right-click the code, and then click **Execute** .```\nBACKUP DATABASE [WideWorldImporters]\u00a0 \u00a0TO \u00a0DISK = N'd:\\sql-server-data\\WideWorldImporters-copy.bak'\u00a0 \u00a0WITH \u00a0COPY_ONLY, NOFORMAT, INIT,\u00a0 \u00a0NAME = N'WideWorldImporters-Full Database Backup',\u00a0 \u00a0SKIP, NOREWIND, NOUNLOAD, COMPRESSION, \u00a0STATS = 10GO\n```Allow a few minutes for the server to create the backup. After the database backup is complete, you can close the query window without saving.### Copy the backup file to Cloud Storage\n- In the RDP session connected to your`sql-server-prod`instance, open a Windows PowerShell window.\n- Copy the backup file into the Cloud Storage bucket you created earlier:```\ngsutil cp -n d:\\sql-server-data\\WideWorldImporters-copy.bak \"gs://$(gcloud config get-value project)-bucket/\"\n``` **Note:** The `-n` flag prevents the `gsutil` tool from overwriting existing files with the same name.\n- Exit PowerShell.```\nexit\n```\n### Copy the backup file from Cloud Storage to sql-server-test\n- In the RDP session connected to your`sql-server-test`instance, open a Windows PowerShell window.\n- Copy the backup file into the Cloud Storage bucket you created earlier:```\ngsutil cp \"gs://$(gcloud config get-value project)-bucket/WideWorldImporters-copy.bak\" d:\\sql-server-data\\\n```\n- Exit PowerShell.```\nexit\n```\nYour test instance now has the full-copy backup of your database on its local disk.\n### Restore the backupYou can now restore the full-copy backup onto drive D ( `data` ) of the `sql-server-test` instance.\n- In the RDP session connected to your`sql-server-test`instance, open Microsoft SQL Server Management Studio, and then connect to the`sql-server-test`database engine.\n- In Object Explorer, right-click **Databases** , and then select **Restore Database** .\n- For **Source** , select the **Device** , and then click the **[...]** button next to the device name.\n- In the **Select backup devices** dialog, select **File** in the **Backup\nmedia type** list, and then click **Add** .\n- In the file selector, browse to`D:\\sql-server-data`, click the`WideWorldImporters-copy.bak`file, and then click **OK** .\n- Click **OK** to close the **Select backup devices** dialog.The **Restore Database** dialog is now populated with data about the `WideWorldImporters` database backup.\n- Under **Select a page** , click **Files** .\n- Select **Relocate all files to folder** .\n- In the **Data file folder** and **Log file folder** fields, enter `D:\\sql-server-data\\wideworldimporters` .\n- To start the restore operation, click **OK** .When the process is complete, you see the message `Database 'WideWorldImporters' restored successfully` .\n- In the RDP session connected to your`sql-server-test`instance, open Microsoft SQL Server Management Studio, and then connect to the`sql-server-test`database engine.\n- Select **File** > **New** > **Query with Current Connection** to open a new query window.\n- Copy the following T-SQL command to initiate a restore from the backup file you copied from Cloud Storage, restoring the database and log file into the `D:\\sql-server-data\\wideworldimporters` directory:```\nUSE [master]GORESTORE DATABASE [WideWorldImporters]\u00a0 FROM \u00a0DISK = N'D:\\SQL-SERVER-DATA\\WideWorldImporters-copy.bak'\u00a0 WITH \u00a0FILE = 1,\u00a0 MOVE N'WWI_Primary' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters.mdf',\u00a0 MOVE N'WWI_UserData' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters_UserData.ndf',\u00a0 MOVE N'WWI_Log' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters.ldf',\u00a0 MOVE N'WWI_InMemory_Data_1' TO\u00a0 \u00a0 N'D:\\SQL-SERVER-DATA\\WideWorldImporters\\WideWorldImporters_InMemory_Data_1',\u00a0 NOUNLOAD,\u00a0 STATS = 5GO\n```\n- Right-click the code and click **Execute** .After a couple of minutes the database restore completes. You can click **Refresh** in Object Explorer to see whether the database is listed in the Databases tree. After the database restore is complete, you can close the query window without saving.\nTo demonstrate that the database is functional, you can run a query.- In Microsoft SQL Management Studio, select **File** > **New** > **Query withCurrent Connection** to open a new query window, and then copy the following code:```\nSELECT top(100)\u00a0 i.InvoiceDate, i.InvoiceID, i.CustomerID, c.CustomerName,\u00a0 i.ConfirmedDeliveryTime, i.ConfirmedReceivedByFROM\u00a0 WideWorldImporters.Sales.Invoices i\u00a0 JOIN WideWorldImporters.Sales.Customers c\u00a0 ON i.CustomerID=c.CustomerIDWHERE i.ConfirmedDeliveryTime IS NOT NULLORDER BY i.InvoiceDate desc;\n```This query retrieves summary information from the 100 most recently delivered invoices.\n- Right-click on the query window and click **Execute** .The **Results** pane displays the summary information.\n## Using Cloud SQL as the cloning destinationIf your destination database is hosted on Cloud SQL, and the origin database is on Compute Engine, then the only supported mechanism for cloning is by backing up the database to Cloud Storage, and then restoring the database into Cloud SQL.\nFor this tutorial, you reuse the backup that you created during the previous section.\n### Create a Cloud SQL for SQL Server instance\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Create a Cloud SQL for SQL Server instance running the same database version as your `sql-server-prod` instance:```\ngcloud sql instances create sqlserver-cloudsql \u00a0\\\u00a0 --database-version=SQLSERVER_2022_STANDARD \\\u00a0 --cpu=2 \\\u00a0 --memory=5GB \\\u00a0 --root-password=sqlserver12@ \\\u00a0 --region=${REGION}\n```This creates an instance with root user of `sqlserver` with a password of `sqlserver12@` .\n### Update object permissionsThe correct permissions need to be set on both the Cloud Storage bucket and the backup object so that the Cloud SQL service account is able to read them. These permissions are set automatically when you use the Google Cloud console to import the object, or you can set them using `gcloud` commands.- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Set an environment variable containing the address of the service account of your Cloud SQL instance:```\nCLOUDSQL_SA=\"$(gcloud sql instances describe sqlserver-cloudsql --format='get(serviceAccountEmailAddress)')\"\n```\n- Add the service account to the bucket ACL as a writer, and to the export object as a reader:```\ngsutil acl ch -u \"${CLOUDSQL_SA}\":W \"gs://$(gcloud config get-value project)-bucket/\"gsutil acl ch -u \"${CLOUDSQL_SA}\":R \\\u00a0 \u00a0 \"gs://$(gcloud config get-value project)-bucket/WideWorldImporters-copy.bak\"\n```\n### Import the exported database\n- Open Cloud Shell. [Open Cloud Shell](https://console.cloud.google.com/welcome?cloudshell=true) \n- Import the exported file into your Cloud SQL instance:```\ngcloud sql import bak sqlserver-cloudsql \\\u00a0 \u00a0 \"gs://$(gcloud config get-value project)-bucket/WideWorldImporters-copy.bak\" \\\u00a0 \u00a0 --database WideWorldImporters\n```When prompted, enter `y` .\n- Install the SQL Server tools package:```\nsudo apt install -y mssql-tools\n```If you accept the licence terms, enter `yes` when prompted.You use these tools to connect to Cloud SQL from Cloud Shell so that you can run queries on the Cloud SQL instance.\n- Connect the Cloud SQL proxy to your SQL Server instance:```\nCONNECTION_NAME=$(gcloud sql instances describe sqlserver-cloudsql --format='value(connectionName)')cloud_sql_proxy -instances=${CONNECTION_NAME}=tcp:1433 &\n```\n- To verify that the cloned database is functional, run a query:```\n/opt/mssql-tools/bin/sqlcmd -U sqlserver -S 127.0.0.1 -Q \\\u00a0 'SELECT top(100)\u00a0 \u00a0 i.InvoiceDate, i.InvoiceID, i.CustomerID, LEFT(c.CustomerName,20) CustomerName,\u00a0 \u00a0 i.ConfirmedDeliveryTime, LEFT(i.ConfirmedReceivedBy,20) ConfirmedReceivedBy\u00a0 FROM\u00a0 \u00a0 WideWorldImporters.Sales.Invoices i\u00a0 \u00a0 JOIN WideWorldImporters.Sales.Customers c\u00a0 \u00a0 ON i.CustomerID=c.CustomerID\u00a0 WHERE i.ConfirmedDeliveryTime IS NOT NULL\u00a0 ORDER BY i.InvoiceDate desc;'\n```When prompted, enter the `sqlserver` user's password of the `sqlserver-cloudsql` database server ( `sqlserver12@` ).This query retrieves summary information from the 100 most recently delivered invoices.The output is the following:```\nInvoiceDate  InvoiceID CustomerID CustomerName   ConfirmedDeliveryTime     ConfirmedReceivedBy\n---------------- ----------- ----------- -------------------- -------------------------------------- -------------------  2016-05-30  70349   581 Wingtip Toys (Munich   2016-05-31 07:05:00.0000000 Youssef Eriksson\n  2016-05-30  70350   123 Tailspin Toys (Roe P   2016-05-31 07:10:00.0000000 Ella Zvirbule\n  2016-05-30  70351   175 Tailspin Toys (San A   2016-05-31 07:15:00.0000000 Julio Correa\n  2016-05-30  70352  1029 Veronika Necesana    2016-05-31 07:20:00.0000000 Veronika Necesana\n  2016-05-30  70353  1014 Narendra Tickoo     2016-05-31 07:25:00.0000000 Narendra Tickoo\n  2016-05-30  70354   930 Shantanu Huq     2016-05-31 07:30:00.0000000 Shantanu Huq\n  2016-05-30  70355   963 Be Trang      2016-05-31 07:35:00.0000000 Be Trang\n  2016-05-30  70356   567 Wingtip Toys (Jerome   2016-05-31 07:40:00.0000000 Severins Polis\n  2016-05-30  70357   510 Wingtip Toys (Grabil   2016-05-31 07:45:00.0000000 Manish Ghosh\n...\n```\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this tutorial, you can delete the Google Cloud project that you created for this tutorial.- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Learn how to use [Microsoft SQL Server backups for point-in-time recovery on Compute Engine](/solutions/backup-and-archival-of-sql-with-point-in-time-recovery) .\n- Learn about the [best practices for running SQL Server instances on Compute Engine](/compute/docs/instances/sql-server/best-practices) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Compute Engine"}