{"title": "Vertex AI Vision - Person/vehicle detector guide", "url": "https://cloud.google.com/vision-ai/docs/person-vehicle-model?hl=zh-cn", "abstract": "# Vertex AI Vision - Person/vehicle detector guide\nThe **Person/vehicle detector** model lets you detect and count people or vehicles in video frames. The model accepts a video stream as input and outputs a [protocol buffer](https://developers.google.com/protocol-buffers/docs/overview) with the count of detected people and vehicles detected in each frame. The model runs at six FPS.\n", "content": "## Model output\nThe Person/vehicle detector model shows the number of people and vehicles detected in the current processed frame. Below is the [protocol buffer](https://developers.google.com/protocol-buffers/docs/overview) definition of the model output. The frequency of the output stream is constant: one frame per second.\n```\n// The prediction result proto for Person/Vehicle Detection.\nmessage OccupancyCountingPredictionResult {\n // Current timestamp.\n google.protobuf.Timestamp current_time = 1;\n // The entity info for annotations from the model.\n message Entity {\n // Label id.\n int64 label_id = 1;\n // Human readable string of the label.\n string label_string = 2;\n }\n // Identified box contains location and the entity of the object.\n message IdentifiedBox {\n // An unique id for this box.\n int64 box_id = 1;\n // Bounding Box in the normalized coordinates.\n message NormalizedBoundingBox {\n  // Min in x coordinate.\n  float xmin = 1;\n  // Min in y coordinate.\n  float ymin = 2;\n  // Width of the bounding box.\n  float width = 3;\n  // Height of the bounding box.\n  float height = 4;\n }\n // Bounding Box in the normalized coordinates.\n NormalizedBoundingBox normalized_bounding_box = 2;\n // Confidence score associated with this box.\n float score = 3;\n // Entity of this box.\n Entity entity = 4;\n }\n // A list of identified boxes.\n repeated IdentifiedBox identified_boxes = 2;\n // The statistics info for annotations from the model.\n message Stats {\n // The object info and count for annotations from the model.\n message ObjectCount {\n  // Entity of this object.\n  Entity entity = 1;\n  // Count of the object.\n  int32 count = 2;\n }\n // Counts of the full frame.\n repeated ObjectCount full_frame_count = 1;\n }\n // Detection statistics.\n Stats stats = 3;\n}\n```\n## Best practices and limitations\n- Avoid unusual camera viewpoints (for example, a top-down view) where people and vehicles appear differently from a standard or common view of them. The detection quality can be largely impacted by unusual views.\n- Ensure that people and vehicles are fully or mostly visible. The detection quality can be affected by partial occlusion by other objects.\n- The Person/vehicle detector has a minimal detectable object size. This size is approximately 2% with respect to the size of the camera view. Ensure that the target people and vehicles are not too far away from the camera. These key objects' viewable sizes must be sufficiently large.\n- Areas of interest must have proper lighting.\n- Ensure the video source camera lens is clean.\n- Ensure entities (other than people or cars) don't obstruct any part of the camera's field of view.\n- The following factors might degrade the model's performance. Consider these factors when you source data:- Poor lighting conditions.\n- Crowdedness and object occlusions.\n- Uncommon viewpoints.\n- Small object sizes.", "guide": "Vertex AI Vision"}