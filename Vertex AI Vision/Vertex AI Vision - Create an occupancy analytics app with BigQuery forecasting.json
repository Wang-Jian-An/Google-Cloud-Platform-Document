{"title": "Vertex AI Vision - Create an occupancy analytics app with BigQuery forecasting", "url": "https://cloud.google.com/vision-ai/docs/occupancy-bq-tutorial?hl=zh-cn", "abstract": "# Vertex AI Vision - Create an occupancy analytics app with BigQuery forecasting\nVertex AI Vision is an AI-powered platform you can use to ingest, analyze, and store video and image data. Vertex AI Vision lets you build and deploy AI applications. You can build end-to-end Vertex AI Vision solutions by leveraging Vertex AI Vision's integration with other product components.\nTo start implementing solutions using the Vertex AI Vision platform, review the following Vertex AI Vision concepts and components:- **Streams** : Represent a video streaming layer from your solution. The stream source can be a live video (for example, an IP camera) or a video file (for example, an MP4 file).\n- **Applications** : Enable the connection between a stream and an AI processor to perform a machine learning operation on the video. For example, you can connect a camera stream to an AI model that counts people passing in front of it.\n- **App output destination** : Send analyzed data to a storage destination (Vertex AI Vision's Media Warehouse or BigQuery) or receive live data. Storing to Vertex AI Vision's Media Warehouse lets you search analysis output and metadata from the AI processors used on data from the ingested streams. Storing to BigQuery lets you use the product's offline analytics capabilities. If you directly receive app output, you can use insights to instantly inform business decisions. For more information, see [Overview: Connect app output to a data destination](/vision-ai/docs/connect-data-destination) .\n", "content": "## ObjectivesThis tutorial shows you how to do the following:- Create a BigQuery dataset and table.\n- Build a Vertex AI Vision occupancy analytics app that connects to BigQuery.\n- Create a Compute Engine VM instance and set up its environment.\n- Stream video from the VM instance to the app.\n- Use stored app output to create a forecasting model with BigQuery ML.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Vertex AI Vision](/vision-ai/pricing) (Streams -  Data ingested, Streams - Data consumed, Models - Occupancy  analytics suite)\n- [Compute Engine](/compute/all-pricing) \n- [BigQuery](/bigquery/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin Role only needed if you copy a sample video file from a Cloud Storage bucket.## Set up BigQuery to receive dataTo be able to receive data and make predictions from your analytics app data, you must create a BigQuery dataset and table that match the processed information.\n### Create a datasetBefore you can create a BigQuery table, you must first create a dataset to receive the analyzed information from your app.\n- Open the BigQuery page in the Google Cloud console. [Go to the BigQuery page](https://console.cloud.google.com/bigquery) \n- In the **Explorer** panel, select the project where you want to create the dataset.\n- Expand the more_vert **Actions** option and click **Create dataset** .\n- On the **Create dataset** page:- For **Dataset ID** , enter`occupancy_dataset`.\n- For **Data location** , choose a geographic [location](/bigquery/docs/locations) for the dataset. After a dataset is created, the location can't be changed. **Note:** If you choose`EU`or an EU-based region for the dataset location, your Core Vertex AI Vision Customer Data resides in the EU. Core Vertex AI Vision Customer Data is defined in the [Service Specific Terms](/terms/service-terms#13-google-bigquery-service) .\n- For **Default table expiration** , choose one of the following options:- **Never:** (Default) Tables created in the dataset are never automatically deleted. You must delete them manually.\n- **Number of days after table creation:** This value determines when a newly created table in the dataset is deleted. This value is applied if you don't set a table expiration when the table is [created](/bigquery/docs/tables#create-table) . **Note:** If your project is not associated with a billing account, BigQuery automatically sets the default table expiration for datasets that you create in the project. You can specify a shorter default table expiration for a dataset, but you can't specify a longer default table expiration.\n- Click **Create dataset** .\n### Create a BigQuery table- In the Google Cloud console, go to the **BigQuery** page. [Go to BigQuery](https://console.cloud.google.com/bigquery) \n- In the **Explorer** pane, expand your project, and then select   the`occupancy_dataset`dataset.\n- In the **Dataset info** section, clickadd_box **Create table** .\n- In the **Create table** panel, specify the following details:- In the **Source** section, select **Empty table** in the **Create table from** list.\n- In the **Destination** section, specify the following    details:- Verify that in the **Dataset** field`occupancy_dataset`is specified.\n- In the **Table** field, enter`occupancy_dataset_table`.\n- Verify that the **Table type** field is set to **Native table** .\n- In the **Schema** section, enter the [schema](/bigquery/docs/schemas) definition. You can    enter schema information manually by doing the following:- Clicktoggle_on **Edit as text** and paste the following JSON array      schema. When you use a JSON array, you      generate the schema using the same process as [creating      a JSON schema file](/bigquery/docs/schemas#specifying_a_json_schema_file) .```\n[\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"name\": \"ingestion_time\",\u00a0 \u00a0 \u00a0 \"type\": \"TIMESTAMP\",\u00a0 \u00a0 \u00a0 \"mode\": \"REQUIRED\"\u00a0 \u00a0 },\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"name\": \"application\",\u00a0 \u00a0 \u00a0 \"type\": \"STRING\",\u00a0 \u00a0 \u00a0 \"mode\": \"REQUIRED\"\u00a0 \u00a0 },\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"name\": \"instance\",\u00a0 \u00a0 \u00a0 \"type\": \"STRING\",\u00a0 \u00a0 \u00a0 \"mode\": \"REQUIRED\"\u00a0 \u00a0 },\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"name\": \"node\",\u00a0 \u00a0 \u00a0 \"type\": \"STRING\",\u00a0 \u00a0 \u00a0 \"mode\": \"REQUIRED\"\u00a0 \u00a0 },\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"name\": \"annotation\",\u00a0 \u00a0 \u00a0 \"type\": \"STRING\"\u00a0 \u00a0 }]\n```- Click **Create table** .\n## Create an occupancy count applicationAfter you have set up your BigQuery dataset and table, you can create the app that processes the data sent to these BigQuery resources.\n### Create an empty appBefore you can populate the app graph, you must first create an empty app.\nCreate an app in the Google Cloud console.- Open the **Applications** tab of the Vertex AI Vision dashboard. [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n- Click the add **Create** button.\n- Enter `occupancy-bq-app` as the app name and choose your region.\n- Click **Create** .### Add app component nodesAfter you have created the empty application, you can then add the three nodes to the app graph:- **Ingestion node** : The stream resource that ingests data sent from a Compute Engine VM instance you create.\n- **Processing node** : The occupancy analytics model that acts on ingested data.\n- **BigQuery node** : The connector node that lets your app to store metadata to your BigQuery table.Add component nodes to your app in the console.- Open the **Applications** tab of the Vertex AI Vision dashboard. [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n- In the `occupancy-bq-app` line, select schema **View graph** . This takes you to the graph visualization of the processing pipeline.\n **Add a data ingestion node** - To add an input stream node, select the **Streams** option in the **Connectors** section of the side menu.\n- In the **Source** section of the **Stream** menu that opens, select add **Add streams** .\n- In the **Add streams** menu, choose radio_button_checked **Register newstreams** and add `occupancy-bq-stream` as the stream name.\n- To add the stream to the app graph, click **Add streams** .\n **Add a data processing node** - To add the occupancy count model node, select the **occupancy analytics** option in the **Specialized models** section of the side menu.\n- Leave the default selections check_box **People** and check_box **Vehicles** .\n **Add a BigQuery node** - To add the output destination (storage) node, select the **BigQuery** option in the **Connectors** section of the side menu.\n- In the **BigQuery** menu, search for `occupancy_dataset_table` and select your table.\n- In the **Store metadata from:** section, select both check_box **Streams** and check_box **Occupancy analytics** .\n## Deploy your app for useAfter you have built your end-to-end app with all the necessary components, the last step to using the app is to deploy it.\n- Open the **Applications** tab of the Vertex AI Vision dashboard. [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n- Select **View graph** next to the `occupancy-bq-app` app in the list.\n- From the application graph builder page, click the play_arrow **Deploy** button.\n- In the following confirmation dialog, select **Deploy** .The deploy operation might take several minutes to complete. After deployment finishes, green check marks appear next to the nodes.\n## Set up a remote machine to stream videoNow that you have a deployed occupancy count app ready to receive, process, and store streaming data out to a BigQuery table, you must actually stream video data into the app.\nIn this tutorial you create a Compute Engine VM instance that hosts a video, and you send that streaming video data from the VM.\n### Create a Linux VMThe first step in sending video from a Compute Engine VM instance is creating the VM instance.\n- In the console, go to the **VM instances** page. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- Select your project and click **Continue** .\n- Click **Create instance** .\n- Specify a **Name** for your VM. For more information, see [Resource naming convention](/compute/docs/naming-resources#resource-name-format) .\n- Optional: Change the **Zone** for this VM. Compute Engine randomizes the list of zones within each region to encourage use across multiple zones.\n- Accept the remaining default options. For more information about these options, see [Create and start a VM](/compute/docs/instances/create-start-instance#startinstanceconsole) .\n- To create and start the VM, click **Create** .### Set up the VM environmentAfter the VM has started, you can use the console to establish an SSH connection in your browser. After establishing this connection, you can download the `vaictl` command-line tool to ingest video into your app.\n **Establish an SSH connection to your VM** - In the console, go to the **VM instances** page. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- In the **Connect** section of the instance line you created, click on **SSH** . This opens an SSH connection in a new browser window.\n **Download the vaictl command-line tool** - In the **SSH-in-browser** window, download the Vertex AI Vision ( `vaictl` ) command-line tool using the following command:```\nwget https://github.com/google/visionai/releases/download/v0.0.5/visionai_0.0-5_amd64.deb\n```\n- Install the command-line tool by running the following command:```\nsudo apt install ./visionai_0.0-5_amd64.deb\n```\n- You can test the installation by running the following command:```\nvaictl --help\n```\n## Ingest a video file into your appAfter you set up your VM environment, you can copy a sample video file and then use `vaictl` to stream the video data to your occupancy count app.\nAfter you send this command, you must let several hours of data to stream before you move to the next step. **Copy a sample video to your VM** - In the **SSH-in-browser** window for your VM, copy a sample   video with the following [gsutil cp](/storage/docs/gsutil/commands/cp) command. Replace the following variable:- : The location of a video file to use. You    can use your own video file source (for example,`gs://` `` `/` `` `.mp4`),    or use one of the sample videos:- `gs://cloud-samples-data/vertex-ai-vision/street_vehicles_people.mp4`(video with people and vehicles, [ video source](https://pixabay.com/videos/traffic-london-england-21438/) )\n- `gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4`(video with vehicles only, [video source](https://pixabay.com/videos/traffic-car-highway-street-27260/) )```\ngsutil cp SOURCE .\n```\n **Stream video from VM and ingest data into your app** - To send this local video file to the app input stream, use the   following command. You must take the following variable substitutions:- : Your Google Cloud project ID.\n- : Your location ID. For example,`us-central1`. [More    information](/about/locations) .\n- : The filename of a local video file.    For example,`my-video.mp4`.\n- `--loop`flag: Optional. Loops file data to simulate    streaming.\nThis command streams a video file to a stream. If using the `--loop` flag, the video is looped into the stream until you    stop the command:```\nvaictl -p PROJECT_ID \\\n -l LOCATION_ID \\\n -c application-cluster-0 \\\n --service-endpoint visionai.googleapis.com \\\nsend video-file to streams 'occupancy-bq-stream' --file-path LOCAL_FILE.EXT --loop\n```\nIt might take ~100 seconds between starting the `vaictl` ingest operation and the video appearing in the dashboard.\nAfter the stream ingestion is available, you can see the video feed in the **Streams** tab of the Vertex AI Vision dashboard by selecting the `occupancy-bq-stream` stream.\n [Go to the Streams tab](https://console.cloud.google.com/ai/vision-ai/video-streams) ## Build a forecasting model with BigQuery MLYou now have a functioning app storing metadata out to BigQuery. After you have a couple of hours of data streamed into your app, you can begin to build a forecasting model with BigQuery ML.\n### Optional: Run an occupancy queryYou can view the app-produced data stored to the table by running a simple query.\n- In the Google Cloud console, open the BigQuery page. [Go to BigQuery](https://console.cloud.google.com/bigquery) \n- Select arrow_drop_down **Expand** next to `occupancy_dataset` , and select `occupancy_dataset_table` .\n- In the table detail view, click add_box **Compose new query** . \n- Enter the following Google Standard SQL query in the **Query editor** text area:```\nSELECT\u00a0*FROM (\u00a0SELECT\u00a0 \u00a0TIMESTAMP_TRUNC(PARSE_TIMESTAMP('\"%Y-%m-%dT%H:%M:%E*SZ\"', JSON_QUERY(annotation,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"$.currentTime\")), MINUTE) currentTime,\u00a0 \u00a0CAST(JSON_QUERY(annotation,\u00a0 \u00a0 \u00a0 \u00a0'$.stats.fullFrameCount[0].count') AS INT64) AS count,\u00a0 \u00a0JSON_QUERY(annotation,\u00a0 \u00a0 \u00a0'$.stats.fullFrameCount[0].entity.labelString') AS type\u00a0FROM\u00a0 \u00a0`PROJECT_ID.occupancy_dataset.occupancy_dataset_table` )WHERE\u00a0count IS NOT NULL\n```\n- Optional: To change the data processing location, click **More** , then **Query settings** . Under **Processing location** , click **Auto-select** and choose your data's [location](/bigquery/docs/locations) . Finally, click **Save** to update the query settings.\n- Click **Run** .\nThis creates a query job that writes the output to a temporary table.Running this query produces a table with time and count information when people are present in the video.\n| currentTime    | count | type  |\n|:------------------------|--------:|:---------|\n| 2022-08-10 16:17:00 UTC |  2 | \"Person\" |\n| 2022-08-10 16:17:00 UTC |  2 | \"Person\" |\n| 2022-08-10 16:17:00 UTC |  4 | \"Person\" |\n| 2022-08-10 16:17:00 UTC |  1 | \"Person\" |\n| 2022-08-10 16:17:00 UTC |  5 | \"Person\" |\n| 2022-08-10 16:17:00 UTC |  2 | \"Person\" |\n### Create a view for trainingAis a virtual table defined by a SQL query. When you create a view, you query it in the same way you query a table, and the results contain data only from the tables and fields specified in the query that defines the view.\nAfter seeing the data stored to the table, you can create a view, and then inspect the contents of the resulting table. You use this view data to train your forecasting model.\nYou can create a view by composing a SQL query that is used to define the data accessible to the view. The SQL query must consist of a `SELECT` statement. For more information about BigQuery views, see [Introduction to views](/bigquery/docs/views-intro) .\nTo create a training table view:\n- In the Google Cloud console, open the BigQuery page. [Go to BigQuery](https://console.cloud.google.com/bigquery) \n- Select arrow_drop_down **Expand** next to `occupancy_dataset` , and select `occupancy_dataset_table` .\n- In the table detail view, click add_box **Compose new query** . \n- Enter the following Google Standard SQL query in the **Query editor** text area:```\nCREATE VIEW `PROJECT_ID.occupancy_dataset.forecast_training_data` AS (\u00a0 WITH\u00a0 \u00a0 raw_counts AS (\u00a0 \u00a0 SELECT\u00a0 \u00a0 \u00a0 *\u00a0 \u00a0 FROM (\u00a0 \u00a0 \u00a0 SELECT\u00a0 \u00a0 \u00a0 \u00a0 TIMESTAMP_TRUNC(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 PARSE_TIMESTAMP('\"%Y-%m-%dT%H:%M:%E*SZ\"',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 JSON_QUERY(annotation,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"$.currentTime\")),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MINUTE) AS currentTime,\u00a0 \u00a0 \u00a0 \u00a0 CAST(JSON_QUERY(annotation,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 '$.stats.fullFrameCount[0].count') AS INT64) AS count,\u00a0 \u00a0 \u00a0 \u00a0 JSON_QUERY(annotation,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 '$.stats.fullFrameCount[0].entity.labelString') AS type\u00a0 \u00a0 \u00a0 FROM\u00a0 \u00a0 \u00a0 \u00a0 `PROJECT_ID.occupancy_dataset.occupancy_dataset_table` )\u00a0 \u00a0 WHERE\u00a0 \u00a0 \u00a0 count IS NOT NULL )\u00a0 SELECT\u00a0 \u00a0 currentTime,\u00a0 \u00a0 SUM(count) AS total_count,\u00a0 \u00a0 type\u00a0 FROM\u00a0 \u00a0 raw_counts\u00a0 GROUP BY\u00a0 \u00a0 currentTime, type)\n```\n- Click **Run** .### Optional: Query the viewRun the following query to see the results of the new view training data:\n- In the `occupancy_dataset_table` table detail view, click add_box **Compose new query** .\n- Enter the following Google Standard SQL query in the **Query editor** text area:```\nSELECT\u00a0*FROM\u00a0 `PROJECT_ID.occupancy_dataset.forecast_training_data`ORDER BY\u00a0currentTime, typeLIMIT\u00a0100\n```\n- Click **Run** .\nThis returns a result sorted by time that looks like the following:\n| currentTime    | total_count | type  |\n|:------------------------|--------------:|:----------|\n| 2022-08-10 16:17:00 UTC |   129 | \"Person\" |\n| 2022-08-10 16:18:00 UTC |   150 | \"Person\" |\n| 2022-08-10 16:19:00 UTC |   80 | \"Person\" |\n| 2022-08-10 16:20:00 UTC |   129 | \"Person\" |\n| 2022-08-10 16:21:00 UTC |   142 | \"Person\" |\n| 2022-08-10 16:22:00 UTC |   71 | \"Person\" |\n| 2022-08-10 16:22:00 UTC |    2 | \"Vehicle\" |\n### Train the forecast model with BigQuery MLNow that you have data in a view to serve as training data, you can train the forecast model with BigQuery ML.\n- In the `occupancy_dataset_table` table detail view, click add_box **Compose new query** .\n- Enter the following Google Standard SQL query in the **Query editor** text area:```\nCREATE OR REPLACE MODEL `PROJECT_ID.occupancy_dataset.occupancy_forecast_model`\u00a0 OPTIONS( MODEL_TYPE = \"ARIMA_PLUS\",\u00a0 \u00a0 TIME_SERIES_TIMESTAMP_COL = \"currentTime\",\u00a0 \u00a0 TIME_SERIES_DATA_COL = \"total_count\",\u00a0 \u00a0 TIME_SERIES_ID_COL = \"type\" ) ASSELECT\u00a0 *FROM\u00a0 `PROJECT_ID.occupancy_dataset.forecast_training_data`\n```\n- Click **Run** .\nThe query takes several minutes to complete. After the first iteration is complete, your model ( `occupancy_forecast_model` ) appears in the navigation panel. Because the query uses a `CREATE MODEL` statement to create a model, you don't see query results.\nYou can observe the model as it's being trained by viewing the **Model stats** tab. As soon as the first iteration completes, the tab is updated. The stats continue to update as each iteration completes.## Get an occupancy prediction with BigQueryAfter your model is done training, you can get a prediction from the model about occupancy count.\nThe following [ML.FORECAST](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-forecast) query uses the [HORIZON](/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-forecast#horizon) function input to make a forecast of the next 60 minutes.\n- In the `occupancy_dataset_table` table detail view, click add_box **Compose new query** .\n- Enter the following Google Standard SQL query in the **Query editor** text area:```\nSELECT\u00a0 *FROM\u00a0 ML.FORECAST(MODEL `PROJECT_ID.occupancy_dataset.occupancy_forecast_model`,\u00a0 STRUCT(60 AS HORIZON))\n```\n- Click **Run** .\nThe model produces forecasts under `forecast_value` for future timestamps where type is `\"Person\"` . For example, on `2022-08-12` at `11:06:00` , the model forecasts there will be ~15.26 \"Persons\" in total.\n| type  | forecast_timestamp  | forecast_value | standard_error | confidence_level | prediction_interval_lower_bound | prediction_interval_upper_bound |\n|:---------|:------------------------|-----------------:|-----------------:|-------------------:|----------------------------------:|----------------------------------:|\n| \"Person\" | 2022-08-12 11:06:00 UTC |   15.2622 |   2.5647 |    0.95 |       10.2445 |       20.2799 |\n| \"Person\" | 2022-08-12 11:07:00 UTC |   13.2353 |   3.1938 |    0.95 |       6.98673 |       19.4838 |\n| \"Person\" | 2022-08-12 11:08:00 UTC |   16.2573 |   3.87581 |    0.95 |       8.67446 |       23.8402 |\n| \"Person\" | 2022-08-12 11:09:00 UTC |   31.4322 |   4.24905 |    0.95 |       23.1191 |       39.7453 |\n| \"Person\" | 2022-08-12 11:10:00 UTC |   26.1992 |   4.26157 |    0.95 |       17.8616 |       34.5368 |\n| \"Person\" | 2022-08-12 11:11:00 UTC |   26.2116 |   4.27963 |    0.95 |       17.8387 |       34.5845 |## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n## What's next\n- Read more about [Responsible AI practices](https://ai.google/responsibilities/responsible-ai-practices/) .\n- Learn about other components you can add to an app in [Build an app](/vision-ai/docs/build-app) .\n- Learn about other output storage and processing options in [Connect app output to a data destination ](/vision-ai/docs/connect-data-destination) .\n- Read about how to [Search Warehouse data in the console](/vision-ai/docs/search-streaming-warehouse) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Vertex AI Vision"}