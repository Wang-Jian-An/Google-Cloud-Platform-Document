{"title": "Vertex AI Vision - Create an occupancy count app with remote streaming input", "url": "https://cloud.google.com/vision-ai/docs/occupancy-count-tutorial?hl=zh-cn", "abstract": "# Vertex AI Vision - Create an occupancy count app with remote streaming input\nVertex AI Vision is an AI-powered platform you can use to ingest, analyze, and store video and image data. Vertex AI Vision lets you build and deploy AI applications. You can build end-to-end Vertex AI Vision solutions by leveraging Vertex AI Vision's integration with other product components.\nTo start implementing solutions using the Vertex AI Vision platform, review the following Vertex AI Vision concepts and components:- **Streams** : Represent a video streaming layer from your solution. The stream source can be a live video (for example, an IP camera) or a video file (for example, an MP4 file).\n- **Applications** : Enable the connection between a stream and an AI processor to perform a machine learning operation on the video. For example, you can connect a camera stream to an AI model that counts people passing in front of it.\n- **Media warehouses** : Store the video ingested by streams out to Google Cloud storage. Storing data out to this destination lets you query analysis output and metadata from the AI processors used on data from the ingested streams.\n", "content": "## ObjectivesThis tutorial shows you how to do the following:- Create an occupancy count app.\n- Deploy your app for use.\n- Set up a remote machine to stream video.\n- Ingest the streaming video into a stream node in your app.\n- Search for videos in your storage Vertex AI Vision's Media Warehouse.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Vertex AI Vision](/vision-ai/pricing) (Streams -  Data ingested, Streams - Data consumed, Models - Occupancy  analytics suite, Warehouse - Video storage)\n- [Compute Engine](/compute/all-pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin Role only needed if you copy a sample video file from a Cloud Storage bucket.## Create an occupancy count applicationAfter you have set up your environment, the first step is to create the app that processes your data. An app can be thought of as an automated pipeline that connects the following:- **Data ingestion** : A video feed is ingested into a stream.\n- **Data analysis** : An AI model can be added after the ingestion. Any computer vision operation can be performed on the ingested video information.\n- **Data storage** : The two versions of the video feed (the original stream and the stream processed by the AI model) can be stored in a media warehouse.\nIn the Google Cloud console an app is represented as a graph. Additionally, in Vertex AI Vision an app graph must have at least two nodes: a video source node (stream), and one more node (a processing model or output destination).\n### Create an empty appBefore you can populate the app graph, you must first create an empty app.\nCreate an app in the Google Cloud console.- Open the **Applications** tab of the Vertex AI Vision dashboard. [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n- Click the add **Create** button.\n- Enter `occupancy-count-app` as the app name and choose your region.\n- Click **Create** .### Add app component nodesAfter you have created the empty application, you can then add the three nodes to the app graph:- **Ingestion node** : The stream resource that ingests data sent from a Compute Engine VM instance you create.\n- **Processing node** : The occupancy analytics model that acts on ingested data.\n- **Storage node** : The media warehouse that stores processed videos, and also serves as a metadata store. The warehouse allows analytics information to be generated about ingested video data, as well as stores information that AI models infer about the data.Add component nodes to your app in the console.- Open the **Applications** tab of the Vertex AI Vision dashboard. [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n- In the `occupancy-count-app` line, select schema **View graph** . This takes you to the graph visualization of the processing pipeline.\n **Add a data ingestion node** - To add an input stream node, select the **Streams** option in the **Connectors** section of the side menu.\n- In the **Source** section of the **Stream** menu that opens, select add **Add streams** .\n- In the **Add streams** menu, choose radio_button_checked **Register newstreams** and add `occupancy-count-stream` as the stream name.\n- To add the stream to the app graph, click **Add streams** .\n **Add a data processing node** - To add the occupancy count model node, select the **occupancy analytics** option in the **Specialized models** section of the side menu.\n- Leave the default selections check_box **People** and check_box **Vehicles** .\n **Add a data storage node** - To add the output destination (storage) node, select the **Vertex AI Vision's Media Warehouse** option in the **Connectors** section of the side menu.\n- In the **Vertex AI Vision's Media Warehouse** menu, click **Connect warehouse** .\n- In the **Connect warehouse** menu, select radio_button_checked **Create newwarehouse** . Name the warehouse `occupancy-count-warehouse` , and leave the TTL duration at 14 days.\n- Click the **Create** button to add the warehouse.\n## Deploy your app for use\nAfter you have built your end-to-end app with all the necessary components, the last step to using the app is to deploy it.\n- Open the **Applications** tab of the Vertex AI Vision dashboard. [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n- Select **View graph** next to the `occupancy-count-app` app in the list.\n- From the application graph builder page, click the play_arrow **Deploy** button.\n- In the following confirmation dialog, select **Deploy** .The deploy operation might take several minutes to complete. After deployment finishes, green check marks appear next to the nodes. \n## Set up a remote machine to stream videoNow that you have a deployed occupancy count app ready to receive, process, and store streaming data, you must actually stream video data into the app.\nIn this tutorial you create a Compute Engine VM instance that hosts a video, and you send that streaming video data from the VM.\n### Create a Linux VMThe first step in sending video from a Compute Engine VM instance is creating the VM instance.\n- In the console, go to the **VM instances** page. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- Select your project and click **Continue** .\n- Click **Create instance** .\n- Specify a **Name** for your VM. For more information, see [Resource naming convention](/compute/docs/naming-resources#resource-name-format) .\n- Optional: Change the **Zone** for this VM. Compute Engine randomizes the list of zones within each region to encourage use across multiple zones.\n- Accept the remaining default options. For more information about these options, see [Create and start a VM](/compute/docs/instances/create-start-instance#startinstanceconsole) .\n- To create and start the VM, click **Create** .### Set up the VM environmentAfter the VM has started, you can use the console to establish an SSH connection in your browser. After establishing this connection, you can download the `vaictl` command-line tool to ingest video into your app.\n **Establish an SSH connection to your VM** - In the console, go to the **VM instances** page. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- In the **Connect** section of the instance line you created, click **SSH** . This opens an SSH connection in a new browser window.\n **Download the vaictl command-line tool** - In the **SSH-in-browser** window, download the Vertex AI Vision ( `vaictl` ) command-line tool using the following command:```\nwget https://github.com/google/visionai/releases/download/v0.0.5/visionai_0.0-5_amd64.deb\n```\n- Install the command-line tool by running the following command:```\nsudo apt install ./visionai_0.0-5_amd64.deb\n```\n- You can test the installation by running the following command:```\nvaictl --help\n```\n## Ingest a video file into your appAfter you set up your VM environment, you can copy a sample video file and then use `vaictl` to stream the video data to your occupancy count app. **Copy a sample video to your VM** - In the **SSH-in-browser** window for your VM, copy a sample   video with the following [gsutil cp](/storage/docs/gsutil/commands/cp) command. Replace the following variable:- : The location of a video file to use. You    can use your own video file source (for example,`gs://` `` `/` `` `.mp4`),    or use one of the sample videos:- `gs://cloud-samples-data/vertex-ai-vision/street_vehicles_people.mp4`(video with people and vehicles, [source](https://pixabay.com/videos/traffic-london-england-21438/) )\n- `gs://cloud-samples-data/vertex-ai-vision/highway_vehicles.mp4`(video with vehicles only, [source](https://pixabay.com/videos/traffic-car-highway-street-27260/) )```\ngsutil cp SOURCE .\n```\n **Stream video from VM and ingest data into your app** - To send this local video file to the app input stream, use the   following command. You must make the following variable substitutions:- : Your Google Cloud project ID.\n- : Your location ID. For example,`us-central1`. For more information, see [Cloud locations](/about/locations) .\n- : The filename of a local video file.    For example,`my-video.mp4`.\n- `--loop`flag: Optional. Loops file data to simulate    streaming.\nThis command streams a video file to a stream. If you use the `--loop` flag, the video is looped into the stream until you    stop the command:```\nvaictl -p PROJECT_ID \\\n -l LOCATION_ID \\\n -c application-cluster-0 \\\n --service-endpoint visionai.googleapis.com \\\nsend video-file to streams 'occupancy-count-stream' --file-path LOCAL_FILE.EXT --loop\n```\nIt might take ~100 seconds between starting the `vaictl` ingest operation and the video appearing in the dashboard.\nAfter the stream ingestion is available, you can see the video feed in the **Streams** tab of the Vertex AI Vision dashboard by selecting the `occupancy-count-stream` stream.\n [Go to the Streams tab](https://console.cloud.google.com/ai/vision-ai/video-streams) ## Search video content in the storage warehouseAfter you ingest video data into your processing app, you can view analyzed video data, and search the data based on occupancy analytics information.\n- Open the **Warehouses** tab of the Vertex AI Vision dashboard. [Go to the Warehouses tab](https://console.cloud.google.com/ai/vision-ai/media-warehouse) \n- Find the `occupancy-count-warehouse` warehouse in the list, and click widgets **View assets** .\n- In the **People count** or **Vehicle count** section, set the **Min** value to `1` , and the **Max** value to `5` .\n- To filter processed video data stored in Vertex AI Vision's Media Warehouse, click **Search** .\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n## What's next\n- Read more about [Responsible AI practices](https://ai.google/responsibilities/responsible-ai-practices/) .\n- Learn about other components you can add to an app in [Build an app](/vision-ai/docs/build-app) .\n- Learn about other output storage and processing options in [Connect app output to a data destination ](/vision-ai/docs/connect-data-destination) .\n- Read about how to [Search Warehouse data in the console](/vision-ai/docs/search-streaming-warehouse) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Vertex AI Vision"}