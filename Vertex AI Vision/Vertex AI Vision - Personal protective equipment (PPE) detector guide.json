{"title": "Vertex AI Vision - Personal protective equipment (PPE) detector guide", "url": "https://cloud.google.com/vision-ai/docs/ppe-detector-model?hl=zh-cn", "abstract": "# Vertex AI Vision - Personal protective equipment (PPE) detector guide\nThe **Personal Protective Equipment (PPE) Detector** model helps you verify the presence of equipment that limits exposure to hazards in a workplace or community environment.\nThe model detects people and the PPE items (gloves, masks, and helmets) on a specific person. The model detects the PPE items, and if the items cover the corresponding human body parts. The model reports this coverage information as a coverage score ranging from [0, 1]. The model accepts a video stream as input. The model outputs detection results as a [protocol buffer](https://developers.google.com/protocol-buffers) that you can view in BigQuery. The model runs at one FPS.\nThe PPE detection operator has three control parameters you can set:\n- check_box **Head coverings** : The operator outputs head coverage-related PPE item information. Set this value in the Google Cloud console, or set`enableHeadCoverageDetection`to true in the [PersonalProtectiveEquipmentDetectionConfig](/vision-ai/docs/reference/rest/v1alpha1/ApplicationConfigs?#personalprotectiveequipmentdetectionconfig) .\n- check_box **Face coverings** : The operator outputs face coverage-related PPE item information. Set this value in the Google Cloud console, or set`enableFaceCoverageDetection`to true in the [PersonalProtectiveEquipmentDetectionConfig](/vision-ai/docs/reference/rest/v1alpha1/ApplicationConfigs?#personalprotectiveequipmentdetectionconfig) .\n- check_box **Hand coverings** : The operator outputs hand coverage-related PPE item information. Set this value in the Google Cloud console, or set`enableHandsCoverageDetection`true in the [PersonalProtectiveEquipmentDetectionConfig](/vision-ai/docs/reference/rest/v1alpha1/ApplicationConfigs?#personalprotectiveequipmentdetectionconfig) .", "content": "## PPE detector model app specifications\nUse the following instructions to create a PPE detector model in the Google Cloud console.\n**Create an app in the Google Cloud console** - To create a PPE detector app, follow instructions in [Build an application](/vision-ai/docs/build-app) . [Go to the Applications tab](https://console.cloud.google.com/ai/vision-ai/applications) \n **Add a PPE detector model** - When you add model nodes, select the **PPE detector** from the list of pre-trained models.\n- Set the types of PPE you want to detect in the options menu.\n **Add a BigQuery connector** - To use the output, connect the app to a **BigQuery** connector.For information about using the **BigQuery** connector, see [Connect and store data to BigQuery](/vision-ai/docs/connect-bigquery) . For BigQuery pricing information, see the [BigQuery pricing](/bigquery/pricing) page.\n **View output results in BigQuery** \nAfter the model outputs data to BigQuery, view output annotations in the BigQuery dashboard.\nIf you didn't specify a BigQuery path, you can view the system-created path in the Vertex AI Vision schema **Studio** page.- In the Google Cloud console, open the BigQuery page. [Go to BigQuery](https://console.cloud.google.com/bigquery) \n- Select arrow_drop_down **Expand** next to the target project, dataset name, and application name. \n- In the table detail view, click **Preview** . View results in the **annotation** column. For a description of the output format, see [model output](#model-output) .\nThe application stores results in chronological order. The oldest results are the beginning of the table, while the most recent results are added to the end of the table. To check the latest results, click the page number to go to the last table page.\n## Model output\nThe model output includes a timestamp, the detection boxes, object labels that correspond to the boxes, and confidence scores from that object. The rate of the output stream is one frame per second.\nThe model output is a [protocol buffer](https://developers.google.com/protocol-buffers) format that includes information on the video frame and PPE detection prediction result. The goal of the model is to check whether people are properly wearing protective equipment. As a result, the model focuses on detecting people and the PPE the person wears. The model output focuses on person detection. For each person that is detected, the model lists the PPE around the person and the coverage score of each piece of equipment.\nIn the protocol buffer example that follows, note the following.\n- Current time - The timestamp notes the time the inference result is made.\n- Detected persons - The main detection result that includes one person-identified box, multiple PPE-identified boxes, and a coverage score for each body part.\n- Person identified box - The bounding box, confidence score, and person entity.\n- PPE identified box - The bounding box, confidence score, and PPE entity.\n### Sample annotation output JSON object\n```\n{\n \"currentTime\": \"2022-11-10T21:02:13.499255040Z\",\n \"detectedPersons\": [ {\n  \"personId\": \"0\",\n  \"detectedPersonIdentifiedBox\": {\n  \"boxId\": \"0\",\n  \"normalizedBoundingBox\": {\n   \"xmin\": 0.486749,\n   \"ymin\": 0.35927793,\n   \"width\": 0.048630536,\n   \"height\": 0.21746585\n  },\n  \"confidenceScore\": 0.31775203,\n  \"personEntity\":{\n   \"personEntityId\":\"0\"\n  }\n  },\n  \"detected_ppe_identified_boxes\": {\n  \"normalized_bounding_box\": {\n   \"xmin\": 0.07268746,\n   \"ymin\": 0.80575824,\n   \"width\": 0.22973709,\n   \"height\": 0.18754286\n  },\n  \"confidence_score\": 0.45171335,\n  \"ppe_entity\": {\n   \"ppe_label_string\": \"Glove\",\n   \"ppe_supercategory_label_string\": \"Hand Coverage\"\n  }\n  },\n  \"detected_ppe_identified_boxes\":{\n  \"normalized_bounding_box\":{\n   \"xmin\": 0.35457548,\n   \"ymin\": 0.016402662,\n   \"width\": 0.31828704,\n   \"height\": 0.18849815\n  },\n  \"confidence_score\": 0.44129524,\n  \"ppe_entity\":{\n   \"ppe_label_string\": \"Helmet\",\n   \"ppe_supercategory_label_string\": \"Head Coverage\"\n   }\n  }\n }\n ]\n}\n```\n### Protocol buffer definition\n```\n// Output format for Personal Protective Equipment Detection Operatormessage PersonalProtectiveEquipmentDetectionOutput {\u00a0// Current timestamp\u00a0protobuf.Timestamp current_time = 1;\u00a0// The entity info for annotations from person detection prediction result\u00a0message PersonEntity {\u00a0 \u00a0// Entity id\u00a0 \u00a0int64 person_entity_id = 1;\u00a0}\u00a0// The entity info for annotations from PPE detection prediction result\u00a0message PPEEntity {\u00a0 \u00a0// Label id\u00a0 \u00a0int64 ppe_label_id = 1;\u00a0 \u00a0// Human readable string of the label (Examples: helmet, glove, mask)\u00a0 \u00a0string ppe_label_string = 2;\u00a0 \u00a0// Human readable string of the super category label (Examples: head_cover,\u00a0 \u00a0// hands_cover, face_cover)\u00a0 \u00a0string ppe_supercategory_label_string = 3;\u00a0 \u00a0// Entity id\u00a0 \u00a0int64 ppe_entity_id = 4;\u00a0}\u00a0// Bounding Box in the normalized coordinates\u00a0message NormalizedBoundingBox {\u00a0 \u00a0// Min in x coordinate\u00a0 \u00a0float xmin = 1;\u00a0 \u00a0// Min in y coordinate\u00a0 \u00a0float ymin = 2;\u00a0 \u00a0// Width of the bounding box\u00a0 \u00a0float width = 3;\u00a0 \u00a0// Height of the bounding box\u00a0 \u00a0float height = 4;\u00a0}\u00a0// PersonIdentified box contains the location and the entity info of the\u00a0// person\u00a0message PersonIdentifiedBox {\u00a0 \u00a0// An unique id for this box\u00a0 \u00a0int64 box_id = 1;\u00a0 \u00a0// Bounding Box in the normalized coordinates\u00a0 \u00a0NormalizedBoundingBox normalized_bounding_box = 2;\u00a0 \u00a0// Confidence score associated with this box\u00a0 \u00a0float confidence_score = 3;\u00a0 \u00a0// Person entity info\u00a0 \u00a0PersonEntity person_entity = 4;\u00a0}\u00a0// PPEIdentified box contains the location and the entity info of the PPE\u00a0message PPEIdentifiedBox {\u00a0 \u00a0// An unique id for this box\u00a0 \u00a0int64 box_id = 1;\u00a0 \u00a0// Bounding Box in the normalized coordinates\u00a0 \u00a0NormalizedBoundingBox normalized_bounding_box = 2;\u00a0 \u00a0// Confidence score associated with this box\u00a0 \u00a0float confidence_score = 3;\u00a0 \u00a0// PPE entity info\u00a0 \u00a0PPEEntity ppe_entity = 4;\u00a0}\u00a0// Detected Person contains the detected person and their associated\u00a0// PPE and their protecting information\u00a0message DetectedPerson {\u00a0 \u00a0// The id of detected person\u00a0 \u00a0int64 person_id = 1;\u00a0 \u00a0// The info of detected person identified box\u00a0 \u00a0PersonIdentifiedBox detected_person_identified_box = 2;\u00a0 \u00a0// The info of detected person associated ppe identified boxes\u00a0 \u00a0repeated PPEIdentifiedBox detected_ppe_identified_boxes = 3;\u00a0 \u00a0// Coverage score for each body part\u00a0 \u00a0// Coverage score for face\u00a0 \u00a0optional float face_coverage_score = 4;\u00a0 \u00a0// Coverage score for eyes\u00a0 \u00a0optional float eyes_coverage_score = 5;\u00a0 \u00a0// Coverage score for head\u00a0 \u00a0optional float head_coverage_score = 6;\u00a0 \u00a0// Coverage score for hands\u00a0 \u00a0optional float hands_coverage_score = 7;\u00a0 \u00a0// Coverage score for body\u00a0 \u00a0optional float body_coverage_score = 8;\u00a0 \u00a0// Coverage score for feet\u00a0 \u00a0optional float feet_coverage_score = 9;\u00a0}\u00a0// A list of DetectedPersons\u00a0repeated DetectedPerson detected_persons = 2;}\n```\n## Best practices and limitations\nTo get the best results when you use the PPE detector, consider the following when you source data and use the model.\n### Source data recommendations\nRecommended: When possible, have detection subjects stand still and face the camera.\nSample image data the PPE detector is able to process correctly:\n| 0           | 1           | 2             |\n|:------------------------------------------|:------------------------------------------|:--------------------------------------------------|\n| Image source: Ani Kolleshi on Unsplash. | Image source: Ahsanization on Unsplash. | Image source: Anastasiia Chepinska on Unsplash. |\nNot recommended: Avoid image data where the key PPE items are too small in the frame.\nSample image data the PPE detector isn't able to process correctly:\n| 0              |\n|:-------------------------------------------------------|\n| Image source: Josue Isai Ramos Figueroa on Unsplash. |\nNot recommended: Avoid image data that show the key PPE items from an uncommon point-of-view or irregular angles.\nSample image data the PPE detector isn't able to process correctly:\n| 0           |\n|:------------------------------------------|\n| Image source: Niclas Moser on Unsplash. |\n### Limitations\n- **Resolution** : The recommended maximum input video resolution is 1920 x 1080, and the recommended minimum resolution is 160 x 120.\n- **Minimum detectable object size** : The model ignores any object in the scene that occupy less than 5% of the frame size.\n- **Lighting** : Video lighting should be normal. Extreme brightness or darkness in video data can cause lower detector performance.\n- **PPE item placement** : The PPE model focuses on analyzing if people are properly using PPE items. As a result, if someone is not wearing a PPE item, the model ignores the item.\n- **PPE item type** : The model focuses on construction protective equipment andmedical PPE items. Therefore, the detector might not work well in medical centers or hospitals.\n- **Custom PPE types** : The PPE model doesn't support customer-defined PPE items. The model supports detection of helmets, masks, and gloves.\nThis list is not meant to be exhaustive, and these limitations and functionality are subject to future product modifications.", "guide": "Vertex AI Vision"}