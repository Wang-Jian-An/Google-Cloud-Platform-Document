{"title": "Compute Engine - Monitoring GPU performance on Windows VMs", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Monitoring GPU performance on Windows VMs\nTo help with better utilization of resources, you can track the GPU usage rates of your virtual machine (VM) instances.\nWhen you know the GPU usage rates, you can perform tasks such as setting up [managed instance groups](/compute/docs/instance-groups#managed_instance_groups) that can be used to autoscale resources.\nTo review GPU metrics using [Cloud Monitoring](/monitoring/docs) , complete the following steps:\n- On each VM, [set up the GPU metrics reporting script](#setup-script) . This script installs the GPU metrics reporting agent. This agent runs at intervals on the VM to collect GPU data, and sends this data to Cloud Monitoring.\n- On each VM, [run the script](#run-script) .\n- On each VM, set GPU metrics reporting agent to [automatically start on boot](#autostart) .\n- [View logs in Google Cloud Cloud Monitoring](#review-metrics) .", "content": "## Set up the GPU metrics reporting script\n### Requirements\nOn each of your VMs, check that you meet the following requirements:\n- Each VM must have [GPUs attached](/compute/docs/gpus/create-vm-with-gpus) .\n- Each VM must have a [GPU driver installed](/compute/docs/gpus/install-drivers-gpu#verify-driver-install) .\n### Download the script\nOpen a PowerShell terminal as an administrator and use the [Invoke-WebRequest command](https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/invoke-webrequest?view=powershell-7.1) to download the script.\n`Invoke-WebRequest` is available on PowerShell 3.0 or later. Google Cloud recommends that you use `ctrl+v` to paste the copied code blocks.\n```\nmkdir c:\\google-scripts\ncd c:\\google-scripts\nInvoke-Webrequest -uri https://raw.githubusercontent.com/GoogleCloudPlatform/compute-gpu-monitoring/main/windows/gce-gpu-monitoring-cuda.ps1 -outfile gce-gpu-monitoring-cuda.ps1\n```\n## Run the script\n```\ncd c:\\google-scripts\n.\\gce-gpu-monitoring-cuda.ps1\n```\n## Configure the agent to automatically start on boot\nTo ensure that the GPU metrics reporting agent agent is set up to run on system boot, use the following command to add the agent to the Windows Task Scheduler.\n```\n$Trigger= New-ScheduledTaskTrigger -AtStartup\n$Trigger.ExecutionTimeLimit = \"PT0S\"\n$User= \"NT AUTHORITY\\SYSTEM\"\n$Action= New-ScheduledTaskAction -Execute \"PowerShell.exe\" -Argument \"C:\\google-scripts\\gce-gpu-monitoring-cuda.ps1\"\n$settingsSet = New-ScheduledTaskSettingsSet\n# Set the Execution Time Limit to unlimited on all versions of Windows Server\n$settingsSet.ExecutionTimeLimit = 'PT0S'\nRegister-ScheduledTask -TaskName \"MonitoringGPUs\" -Trigger $Trigger -User $User -Action $Action -Force -Settings $settingsSet\n```\n## Review metrics in Cloud Monitoring\n- In the Google Cloud console, go to the **Metrics Explorer** page. [Go to Monitoring](https://console.cloud.google.com/monitoring/metrics-explorer) \n- Expand the **Select a metric** menu.\n- In the **Resource** menu, select **VM Instance** .\n- In the **Metric category** menu, select **Custom** .\n- In the **Metric** menu, select the metric to chart. For example `custom/instance/gpu/utilization` . **Note:** Custom metrics might take some time to display.\n- Click **Apply** .Your GPU utilization should resemble the following output: ## Available metrics\n| Metric name      | Description                        |\n|:---------------------------------|:-----------------------------------------------------------------------------------------------------------|\n| instance/gpu/utilization   | Percent of time over the past sample period during which one or more kernels was executing on the GPU.  |\n| instance/gpu/memory_utilization | Percent of time over the past sample period during which global (device) memory was being read or written. |\n| instance/gpu/memory_total  | Total installed GPU memory.                    |\n| instance/gpu/memory_used   | Total memory allocated by active contexts.                 |\n| instance/gpu/memory_used_percent | Percentage of total memory allocated by active contexts. Ranges from 0 to 100.        |\n| instance/gpu/memory_free   | Total free memory.                       |\n| instance/gpu/temperature   | Core GPU temperature in Celsius (\u00b0C).                  |\n## What's next?\n- To handle GPU host maintenance, see [Handling GPU host maintenance events](/compute/docs/gpus/gpu-host-maintenance) .\n- To improve network performance, see [Use higher network bandwidth](/compute/docs/gpus/optimize-gpus) .", "guide": "Compute Engine"}