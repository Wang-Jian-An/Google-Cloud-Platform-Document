{"title": "Vertex AI - Use Vertex AI TensorBoard with Vertex AI Pipelines", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Use Vertex AI TensorBoard with Vertex AI Pipelines\nTo see an example of TensorBoard integration with pipelines,  run the \"Vertex AI TensorBoard integration with Vertex AI Pipelines\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_vertex_ai_pipelines_integration.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftensorboard%2Ftensorboard_vertex_ai_pipelines_integration.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_vertex_ai_pipelines_integration.ipynb)\nYour training code can be packaged into a custom training component and run in a pipeline job. TensorBoard logs are automatically streamed to your Vertex AI TensorBoard experiment. You can use this integration to monitor your training in near real time as Vertex AI TensorBoard streams in Vertex AI TensorBoard logs as they are written to Cloud Storage.\nFor initial setup see [Set up for Vertex AI TensorBoard](/vertex-ai/docs/experiments/tensorboard-setup) .\n#", "content": "## Changes to your training script\nYour training script must be configured to write TensorBoard logs to the Cloud Storage bucket, the location of which the Vertex AI Training Service will automatically make available through a predefined environment variable ` **AIP_TENSORBOARD_LOG_DIR** ` .\nThis can usually be done by providing `os.environ['AIP_TENSORBOARD_LOG_DIR']` as the log directory to the open source TensorBoard log writing APIs. The location of the `AIP_TENSORBOARD_LOG_DIR` is typically set with the `staging_bucket` variable.\nTo configure your training script in TensorFlow 2.x, create a TensorBoard callback and set the `log_dir` variable to `os.environ['AIP_TENSORBOARD_LOG_DIR']` The TensorBoard callback is then included in the TensorFlow `model.fit` callbacks list.\n```\n\u00a0 tensorboard_callback = tf.keras.callbacks.TensorBoard(\u00a0 \u00a0 \u00a0 \u00a0log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'],\u00a0 \u00a0 \u00a0 \u00a0histogram_freq=1\u00a0 )\u00a0 \u00a0 model.fit(\u00a0 \u00a0 \u00a0 \u00a0x=x_train,\u00a0 \u00a0 \u00a0 \u00a0y=y_train,\u00a0 \u00a0 \u00a0 \u00a0epochs=epochs,\u00a0 \u00a0 \u00a0 \u00a0validation_data=(x_test, y_test),\u00a0 \u00a0 \u00a0 \u00a0callbacks=[tensorboard_callback],\u00a0 )\u00a0 \n```\nLearn more about [how Vertex AI](/vertex-ai/docs/training/code-requirements#environment-variables) sets environment variables in your custom training environment.\n### Build and run a pipeline\nThe following example shows how to build and run a pipeline using Kubeflow Pipelines DSL package. For more examples and additional details, see [Vertex AI Pipelines documentation](/vertex-ai/docs/pipelines) .\nPackage your training code into a custom component, making sure that the code is configured to write TensorBoard logs to a Cloud Storage bucket. For more examples see [Build your own pipeline components](/vertex-ai/docs/pipelines/build-own-components) .\n```\nfrom kfp.v2.dsl import component@component(\u00a0 \u00a0 base_image=\"tensorflow/tensorflow:latest\",\u00a0 \u00a0 packages_to_install=[\"tensorflow_datasets\"],)def train_tensorflow_model_with_tensorboard():\u00a0 \u00a0 import datetime, os\u00a0 \u00a0 import tensorflow as tf\u00a0 \u00a0 (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\u00a0 \u00a0 x_train, x_test = x_train / 255.0, x_test / 255.0\u00a0 \u00a0 def create_model():\u00a0 \u00a0 \u00a0 \u00a0 return tf.keras.models.Sequential(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tf.keras.layers.Flatten(input_shape=(28, 28)),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tf.keras.layers.Dense(512, activation=\"relu\"),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ]\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 model = create_model()\u00a0 \u00a0 model.compile(\u00a0 \u00a0 \u00a0 \u00a0 optimizer=\"adam\",\u00a0 \u00a0 \u00a0 \u00a0 loss=\"sparse_categorical_crossentropy\",\u00a0 \u00a0 \u00a0 \u00a0 metrics=[\"accuracy\"]\u00a0 \u00a0 )\u00a0 \u00a0 tensorboard_callback = tf.keras.callbacks.TensorBoard(\u00a0 \u00a0 \u00a0 \u00a0 log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'],\u00a0 \u00a0 \u00a0 \u00a0 histogram_freq=1\u00a0 \u00a0 )\u00a0 \u00a0 model.fit(\u00a0 \u00a0 \u00a0 \u00a0 x=x_train,\u00a0 \u00a0 \u00a0 \u00a0 y=y_train,\u00a0 \u00a0 \u00a0 \u00a0 epochs=5,\u00a0 \u00a0 \u00a0 \u00a0 validation_data=(x_test, y_test),\u00a0 \u00a0 \u00a0 \u00a0 callbacks=[tensorboard_callback],\u00a0 \u00a0 )\n```\nCreate a custom training job from the component you've created by specifying the component spec in `create_custom_training_job_op_from_component` . Set the `tensorboard_resource_name` to your TensorBoard instance, and the `staging_bucket` to the location to stage artifacts during API calls (including TensorBoard logs).\nThen, build a pipeline to include this job and compile the pipeline to a JSON file.\nFor more examples and information, see [Custom job components](/vertex-ai/docs/pipelines/customjob-component) and [Build a pipeline](/vertex-ai/docs/pipelines/build-pipeline) .\n```\nfrom kfp.v2 import compilerfrom google_cloud_pipeline_components.v1.custom_job.utils import \\\u00a0 \u00a0 create_custom_training_job_op_from_componentfrom kfp.v2 import dsldef create_tensorboard_pipeline_sample(\u00a0 \u00a0 project, location, staging_bucket, display_name, service_account, experiment, tensorboard_resource_name):\u00a0 \u00a0 @dsl.pipeline(\u00a0 \u00a0 \u00a0 \u00a0 pipeline_root=f\"{staging_bucket}/pipeline_root\",\u00a0 \u00a0 \u00a0 \u00a0 name=display_name,\u00a0 \u00a0 )\u00a0 \u00a0 def pipeline():\u00a0 \u00a0 \u00a0 \u00a0 custom_job_op = create_custom_training_job_op_from_component(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 component_spec=train_tensorflow_model_with_tensorboard,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tensorboard=tensorboard_resource_name,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 base_output_directory=staging_bucket,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 service_account=service_account,\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 custom_job_op(project=project, location=location)\u00a0 \u00a0 compiler.Compiler().compile(\u00a0 \u00a0 \u00a0 \u00a0 pipeline_func=pipeline, package_path=f\"{display_name}.json\"\u00a0 \u00a0 )\n```\nSubmit your pipeline using the Vertex AI SDK for Python. For more information, see [Run a pipeline](/vertex-ai/docs/pipelines/run-pipeline#vertex-ai-sdk-for-python) .### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/log_pipeline_job_to_experiment_sample.py) \n```\ndef log_pipeline_job_to_experiment_sample(\u00a0 \u00a0 experiment_name: str,\u00a0 \u00a0 pipeline_job_display_name: str,\u00a0 \u00a0 template_path: str,\u00a0 \u00a0 pipeline_root: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 parameter_values: Optional[Dict[str, Any]] = None,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 pipeline_job = aiplatform.PipelineJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=pipeline_job_display_name,\u00a0 \u00a0 \u00a0 \u00a0 template_path=template_path,\u00a0 \u00a0 \u00a0 \u00a0 pipeline_root=pipeline_root,\u00a0 \u00a0 \u00a0 \u00a0 parameter_values=parameter_values,\u00a0 \u00a0 )\u00a0 \u00a0 pipeline_job.submit(experiment=experiment_name)\n```\n- `experiment_name`: Provide a name for your experiment.\n- `pipeline_job_display_name`: The display name for the pipeline job.\n- `template_path`: The path to the compiled pipeline template.\n- `pipeline_root`: Specify a Cloud Storage URI that your pipelines service account can access. The artifacts of your pipeline runs are stored within the pipeline root.\n- `parameter_values`: The pipeline parameters to pass to this run. For example, create a`dict()`with the parameter names as the dictionary keys and the parameter values as the dictionary values.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . The Google Cloud project to run the pipeline in. You can find your IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: The region to run the pipeline in. This should be the same region as the TensorBoard instance you are using.## What's next\n- View your results: [View TensorBoard for Vertex AI Pipelines](/vertex-ai/docs/experiments/tensorboard-view#vertex-ai-pipelines) .\n- Learn how to optimize the performance of your custom training jobs using [Vertex AI TensorBoard Profiler](/vertex-ai/docs/training/tensorboard-profiler) .", "guide": "Vertex AI"}