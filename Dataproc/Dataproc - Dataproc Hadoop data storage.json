{"title": "Dataproc - Dataproc Hadoop data storage", "url": "https://cloud.google.com/dataproc/docs/concepts/dataproc-hdfs", "abstract": "# Dataproc - Dataproc Hadoop data storage\nDataproc integrates with Apache Hadoop and the Hadoop Distributed File System (HDFS). The following features and considerations can be important when selecting compute and data storage options for Dataproc clusters and jobs:\n- HDFS with Cloud Storage: Dataproc uses the Hadoop Distributed File System (HDFS) for storage. Additionally, Dataproc automatically installs the HDFS-compatible [Cloud Storage connector](/dataproc/docs/concepts/connectors/cloud-storage) , which enables the use of Cloud Storage in parallel with HDFS. Data can be moved in and out of a cluster through upload and download to HDFS or Cloud Storage.\n- VM disks:- By default, when no local SSDs are provided, HDFS data and intermediate shuffle data is stored on VM boot disks, which are [Persistent Disks](https://cloud.google.com/persistent-disk/) .\n- If you use [local SSDs](/dataproc/docs/concepts/compute/dataproc-local-ssds) , HDFS data and intermediate shuffle data is stored on the SSDs.\n- Persistent disk (PD) size and type affect performance and VM size, whether using HDFS or Cloud Storage for data storage.\n- **VM Boot disks are deleted when the cluster is deleted.*", "content": "*", "guide": "Dataproc"}