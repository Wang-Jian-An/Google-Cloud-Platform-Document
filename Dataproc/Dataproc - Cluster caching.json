{"title": "Dataproc - Cluster caching", "url": "https://cloud.google.com/dataproc/docs/concepts/cluster-caching", "abstract": "# Dataproc - Cluster caching\nWhen you enable Dataproc cluster caching, the cluster caches Cloud Storage data frequently accessed by your Spark jobs.\n", "content": "## Benefits\n- **Improved performance:** Caching can improve job performance by reducing the amount of time spent retrieving data from storage.\n- **Reduced storage costs:** Since hot data is cached on local disk, fewer API calls are made to storage to retrieve data.## Limitations and requirements\n- Caching applies to Dataproc Spark jobs only.\n- Only Cloud Storage data is cached.\n- Caching only applies only to clusters that meet the following requirements:- The cluster has one master and`n`workers ( [High Availability (HA)](/dataproc/docs/concepts/configuring-clusters/high-availability) and [single node](/dataproc/docs/concepts/configuring-clusters/single-node-clusters) clusters are not supported).\n- This feature is available in Dataproc on Compute Engine [image versions](/dataproc/docs/concepts/versioning/dataproc-version-clusters#supported_dataproc_versions) `2.0.72+ or 2.1.20+`.\n- Each cluster node must have [local SSDs](/dataproc/docs/concepts/compute/dataproc-local-ssds) attached with the [NVME (Non-Volatile Memory Express)](/compute/docs/disks/local-ssd#nvme) interface (Persistent Disks (PDs) are not supported). Data is cached on NVME local SSDs only.\n- The cluster uses the [default VM service account](/dataproc/docs/concepts/configuring-clusters/service-accounts#VM_service_account) for authentication. [Custom VM service accounts](/dataproc/docs/concepts/configuring-clusters/service-accounts#create_a_cluster_with_a_custom_vm_service_account) are not supported.\n## Enable cluster caching\nYou can enable cluster caching when you create a Dataproc cluster using the Google Cloud CLI or the Dataproc API.\nCurrently, enabling cluster caching from the Google Cloud console  is not supported.Run the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command locally in a terminal window or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) using the `dataproc:dataproc.cluster.caching=true` [cluster property](/dataproc/docs/concepts/configuring-clusters/cluster-properties#dataproc_service_properties_table) .\nExample:\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--properties dataproc:dataproc.cluster.caching.enabled=true \\\n\u00a0\u00a0\u00a0\u00a0--num-master-local-ssds=2 \\\n\u00a0\u00a0\u00a0\u00a0--master-local-ssd-interface=NVME \\\n\u00a0\u00a0\u00a0\u00a0--num-worker-local-ssds=2 \\\n\u00a0\u00a0\u00a0\u00a0--worker-local-ssd-interface=NVME \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n \n```Set [SoftwareConfig.properties](/dataproc/docs/reference/rest/v1/SoftwareConfig#EndpointConfig) to include the `\"dataproc:dataproc.cluster.caching\": \"true\"` [cluster property](/dataproc/docs/concepts/configuring-clusters/cluster-properties#dataproc_service_properties_table) as part of a [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request.", "guide": "Dataproc"}