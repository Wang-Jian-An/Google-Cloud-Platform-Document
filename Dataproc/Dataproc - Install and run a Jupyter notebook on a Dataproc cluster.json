{"title": "Dataproc - Install and run a Jupyter notebook on a Dataproc cluster", "url": "https://cloud.google.com/dataproc/docs/tutorials/jupyter-notebook", "abstract": "# Dataproc - Install and run a Jupyter notebook on a Dataproc cluster\n", "content": "## ObjectivesThis tutorial shows you how to install the Dataproc [Jupyter and Anaconda components](/dataproc/docs/concepts/components/jupyter) on a new cluster, and then connect to the Jupyter notebook UI running on the cluster from your local browser using the Dataproc [Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways)  [](None) .\n **Note:** Running this tutorial will incur Google Cloud charges\u2014see [Dataproc Pricing](/dataproc/docs/resources/pricing) .## CostsIn this document, you use the following billable components of Google Cloud:- [Dataproc](/dataproc/pricing) \n- [Cloud Storage](/storage/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . ## Before you beginIf you haven't already done so, create a Google Cloud Platform project and a Cloud Storage [bucket](/storage/docs/xml-api/put-bucket-create) .- **Setting up your project** \n- **Creating a Cloud Storage bucket** in your project to store any notebooks you create in this tutorial.- In the Google Cloud console, go to the Cloud Storage **Buckets** page. [Go to Buckets page](https://console.cloud.google.com/storage/browser) \n- Click **Create bucket** .\n- On the **Create a bucket** page, enter your bucket information. To go to the next step, click **Continue** .- For **Name your bucket** , enter a name that meets the [bucket naming requirements](/storage/docs/bucket-naming#requirements) .\n- For **Choose where to store your data** , do the following:- Select a **Location type** option.\n- Select a **Location** option.\n- For **Choose a default storage class for your data** , select a [storage class](/storage/docs/storage-classes) .\n- For **Choose how to control access to objects** , select an **Access control** option.\n- For **Advanced settings (optional)** , specify  an [encryption method](/storage/docs/encryption) ,  a [retention policy](/storage/docs/bucket-lock) ,  or [bucket labels](/storage/docs/tags-and-labels#bucket-labels) .\n- Click **Create** .\n- Your notebooks will be stored in Cloud Storage under\n- `gs://` `` `/notebooks/jupyter`\n- .\n## Create a cluster and install the Jupyter component [Create a cluster with the installed Jupyter component](/dataproc/docs/concepts/components/jupyter#install_jupyter) .\n **Note:** When creating the cluster, specify the name of the bucket you created in [Before you begin](#before-you-begin) , step 2 (only specify the name of the bucket) as the Dataproc `staging bucket` (see [Dataproc staging and temp buckets](/dataproc/docs/concepts/configuring-clusters/staging-bucket) for instructions on setting the staging bucket). Your notebooks will be stored in Cloud Storage under `gs://` `` `/notebooks/jupyter` .## Open the Jupyter and JupyterLab UIsClick the [Google Cloud console Component Gateway links](/dataproc/docs/concepts/accessing/dataproc-gateways#viewing_and_accessing_component_gateway_urls) in the Google Cloud console to open the Jupyter notebook or JupyterLab UIs running on your cluster's master node.\nThe top-level directory displayed by your Jupyter instance is a virtual directory that allows you to see the contents of either your Cloud Storage bucket or your local file system. You can choose either location by clicking on the **GCS** link for Cloud Storage or **Local Disk** for the local filesystem of the master node in your cluster.- Click the **GCS** link. The Jupyter notebook web UI displays notebooks stored in your Cloud Storage bucket, including any notebooks you create in this tutorial.\n## Clean up\nAfter you finish the tutorial, you can clean up the resources that you created so that they stop using quota and incurring charges. The following sections describe how to delete or turn off these resources.\n### Deleting the project\nThe easiest way to eliminate billing is to delete the project that you created for the tutorial.\nTo delete the project:\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.### Deleting the cluster\n- To delete your cluster:```\ngcloud dataproc clusters delete cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--region=${REGION}\n```\n### Deleting the bucket\n- To delete the Cloud Storage bucket you created in [Before you begin](#before-you-begin) , step 2, **including the notebooks\nstored in the bucket** :```\ngsutil -m rm -r gs://${BUCKET_NAME}\n```\n## What's next\n- See the [Jupyter/IPython Notebook Quick Start Guide](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/)", "guide": "Dataproc"}