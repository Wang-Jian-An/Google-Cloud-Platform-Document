{"title": "Dataproc - Create and manage Labels", "url": "https://cloud.google.com/dataproc/docs/guides/creating-managing-labels", "abstract": "# Dataproc - Create and manage Labels\nYou can also add labels to Compute Engine resources associated with cluster resources, such as Virtual Machine instances and disks.\n", "content": "## What are labels?\nA label is a key-value pair that you can assign to Google Cloud Dataproc clusters and jobs. They help you organize these resources and manage your costs at scale, with the granularity you need. You can attach a label to each resource, then filter the resources based on their labels. Information about labels is forwarded to the billing system that lets you break down your billed charges by label. With built-in [billing reports](/billing/docs/how-to/reports) , you can filter and group costs by resource labels. You can also use labels to query [billing data exports](/billing/docs/how-to/bq-examples) .\n## Requirements for labels\nThe labels applied to a resource must meet the following requirements:\n- Each resource can have up to 64 labels.\n- Each label must be a key-value pair.\n- Keys have a minimum length of 1 character and a maximum length of 63 characters, and cannot be empty. Values can be empty, and have a maximum length of 63 characters.\n- Keys and values can contain only lowercase letters, numeric characters, underscores, and dashes. All characters must use UTF-8 encoding, and international characters are allowed. Keys must start with a lowercase letter or international character.\n- The key portion of a label must be unique within a single resource. However, you can use the same key with multiple resources.\nThese limits apply to the key and value for each label, and to the individual Google Cloud resources that have labels. There is no limit on how many labels you can apply across all resources within a project.\n## Common uses of labels\nHere are some common use cases for labels:\n- **Team or cost center labels** : Add labels based on team or cost center to distinguish Dataproc clusters and jobs owned by different teams (for example, `team:research` and `team:analytics` ). You can use this type of label for cost accounting or budgeting.\n- **Component labels** : For example, `component:redis` , `component:frontend` , `component:ingest` , and `component:dashboard` .\n- **Environment or stage labels** : For example, `environment:production` and `environment:test` .\n- **State labels** : For example, `state:active` , `state:readytodelete` , and `state:archive` .\n- **Ownership labels** : Used to identify the teams that are responsible for operations, for example: `team:shopping-cart` .**Note:** Don't include sensitive information in labels, including personally identifiable information, such as an individual's name or title. Labels are not designed to handle sensitive information.\nWe don't recommend creating large numbers of unique labels, such as for timestamps or individual values for every API call. The problem with this approach is that when the values change frequently or with keys that clutter the catalog, this makes it difficult to effectively filter and report on resources.\n## Labels and tags\nLabels can be used as queryable annotations for resources, but can't be used to set conditions on policies. Tags provide a way to conditionally allow or deny policies based on whether a resource has a specific tag, by providing fine-grained control over policies. For more information, see the [Tags overview](/resource-manager/docs/tags/tags-overview) .\n## Creating and using Dataproc labels\n**Updating labels on clusters with secondary workers.** A cluster can contain either [preemptible secondary workers](/dataproc/docs/concepts/compute/preemptible-vms) or non-preemptible secondary workers, but not both. Label updates propagate to all preemptible secondary workers within 24 hours. Currently, label updates do not propagate to existing non-preemptible secondary workers. Labels updates also propagate to workers added to a cluster after the label update. For example, if you scale up the cluster, all new primary and secondary workers will have the new labels.\nYou can specify one or more labels to be applied to a Dataproc cluster or job at creation or submit time using the Google Cloud CLI.\n```\ngcloud dataproc clusters create args --labels environment=production,customer=acme\ngcloud dataproc jobs submit args --labels environment=production,customer=acme\n```\nOnce a Dataproc cluster or job has been created, you can update the labels associated with that resource using the Google Cloud CLI.\n```\ngcloud dataproc clusters update args --update-labels environment=production,customer=acme\ngcloud dataproc jobs update args --update-labels environment=production,customer=acme\n```\nSimilarly, you can use the Google Cloud CLI to filter Dataproc resources by label using a filter expression of the following format: `labels.<key=value>` .\n```\ngcloud dataproc clusters list \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--filter=\"status.state=ACTIVE AND labels.environment=production\"\ngcloud dataproc jobs list \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--filter=\"status.state=ACTIVE AND labels.customer=acme\"\n```\nSee the [clusters.list](/dataproc/docs/reference/rest/v1/projects.regions.clusters/list#query-parameters) and [jobs.list](/dataproc/docs/reference/rest/v1/projects.regions.jobs/list#query-parameters) Dataproc API documentation for more information on writing a filter expression.\nLabels can be attached to Dataproc resources through the [Dataproc REST API](/dataproc/docs/reference/rest) . The [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) , [jobs.submit](/dataproc/docs/reference/rest/v1/projects.regions.jobs/submit) APIs can be used to attach labels to a cluster or job at creation or submit time. The [clusters.patch](/dataproc/docs/reference/rest/v1/projects.regions.clusters/patch) , [jobs.patch](/dataproc/docs/reference/rest/v1/projects.regions.jobs/patch) APIs can be used to edit labels after the resource has been created. Here is the JSON body of a cluster.create request that includes attaches a `key1:value` label to the cluster.\n```\n{\n\u00a0\u00a0\"clusterName\":\"cluster-1\",\n\u00a0\u00a0\"projectId\":\"my-project\",\n\u00a0\u00a0\"config\":{\n\u00a0\u00a0\u00a0\u00a0\"configBucket\":\"\",\n\u00a0\u00a0\u00a0\u00a0\"gceClusterConfig\":{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"networkUri\":\".../networks/default\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"zoneUri\":\".../zones/us-central1-f\"\n\u00a0\u00a0\u00a0\u00a0},\n\u00a0\u00a0\u00a0\u00a0\"masterConfig\":{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"numInstances\":1,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"machineTypeUri\":\"..../machineTypes/n1-standard-4\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"diskConfig\":{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"bootDiskSizeGb\":500,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"numLocalSsds\":0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n\u00a0\u00a0\u00a0\u00a0},\n\u00a0\u00a0\u00a0\u00a0\"workerConfig\":{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"numInstances\":2,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"machineTypeUri\":\"...machineTypes/n1-standard-4\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"diskConfig\":{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"bootDiskSizeGb\":500,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"numLocalSsds\":0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n\u00a0\u00a0\u00a0\u00a0}\n\u00a0\u00a0},\n\u00a0\u00a0\"labels\":{\n\u00a0\u00a0\u00a0\u00a0\"key1\":\"value1\"\n\u00a0\u00a0}\n}\n```\nThe [clusters.list](/dataproc/docs/reference/rest/v1/projects.regions.clusters/list) and [jobs.list](/dataproc/docs/reference/rest/v1/projects.regions.jobs/list) APIs can be used to list resources that match a specified filter, using the following format: `labels.<key=value>` .\nHere is a sample Dataproc API [clusters.list](/dataproc/docs/reference/rest/v1/projects.regions.clusters/list) HTTPS GET request that specifies a `key=value` label filter. The caller inserts `project` , `region` , a filter `label-key` and `label-value` , and an `api-key` . Note that this sample request is broken into two lines for readability.\n```\nGET https://dataproc.googleapis.com/v1/projects/project/regions/region/clusters?\nfilter=labels.label-key=label-value&key=api-key\n```\nSee the [clusters.list](/dataproc/docs/reference/rest/v1/projects.regions.clusters/list#query-parameters) and [jobs.list](/dataproc/docs/reference/rest/v1/projects.regions.jobs/list#query-parameters) Dataproc API documentation for more information on writing a filter expression.\nIf you want to examine the JSON body of a Dataproc API request or response, an easy way is to construct the request or select the resource to list from the appropriate Dataproc page of the Google Cloud console, then click the **Equivalent REST** button at the bottom of the page.\nYou can specify a set of labels to add to a Dataproc resource at creation or submit time using the Google Cloud console.\n- Add labels to a cluster from the Labels section of the Customize cluster panel of the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page.\n- Add labels to a job from the Dataproc [Submit a job](https://console.cloud.google.com/dataproc/jobs) page.\nOnce a Dataproc resource has been created, you can update the labels associated with that resource. To update labels, you must first click `SHOW INFO PANEL` in the top- left of the page. This is an example from the [Dataproc\u2192List clusters](https://console.cloud.google.com/dataproc/clusters) page.Once the info panel is displayed, you can update the labels for your Dataproc resources. Below is an example of updating labels for a Dataproc cluster.It is also possible to update labels for multiple items in one operation. In this example, labels are being updated for multiple Dataproc jobs at the same time.Labels allow you to filter the Dataproc resources shown on the [Dataproc\u2192List clusters](https://console.cloud.google.com/dataproc/clusters) and [Dataproc\u2192List jobs](https://console.cloud.google.com/dataproc/jobs) pages. In the top of the page, you can use the search pattern `labels.<labelname>=<value>` to filter resources by a label.\n## Automatically applied labels\nWhen creating or updating a cluster, Dataproc automatically applies several labels to the cluster and cluster resources. For example, Dataproc applies labels to virtual machines, persistent disks, and accelerators when a cluster is created. Automatically applied labels have a special `goog-dataproc` prefix.\nThe following `goog-dataproc` labels are automatically applied to Dataproc resources. Any values you supply for the reserved `goog-dataproc` labels at cluster creation will override automatically supplied values. For this reason, supplying your own values for these labels is not recommended.\n| Label      | Description      |\n|:---------------------------|:-----------------------------------|\n| goog-dataproc-cluster-name | User-specified cluster name  |\n| goog-dataproc-cluster-uuid | Unique cluster ID     |\n| goog-dataproc-location  | Dataproc regional cluster endpoint |\nYou can use these automatically applied labels in many ways, including:\n- [Searching and filtering](/compute/docs/labeling-resources#filter) for Dataproc resources\n- [Filtering billing data](/billing/docs/how-to/bq-examples) to calculate Dataproc costs## What's next\n- [Google Cloud Resource Manager\u2192Using Labels](/resource-manager/docs/using-labels) \n- [Google Compute Engine\u2192Labeling or Tagging Resources](/compute/docs/label-or-tag-resources)", "guide": "Dataproc"}