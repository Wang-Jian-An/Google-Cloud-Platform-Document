{"title": "Dataproc - \u5c07 GPU \u639b\u63a5\u5230\u96c6\u7fa3", "url": "https://cloud.google.com/dataproc/docs/concepts/compute/gpus?hl=zh-cn", "abstract": "# Dataproc - \u5c07 GPU \u639b\u63a5\u5230\u96c6\u7fa3\nDataproc \u5141\u8a31\u5c07\u5716\u5f62\u8655\u7406\u55ae\u5143 (GPU) \u9023\u63a5\u5230 Dataproc \u96c6\u7fa3\u4e2d\u7684\u4e3b\u5be6\u4f8b\u548c\u5de5\u4f5c\u5668 Compute Engine \u7bc0\u9ede\u3002\u60a8\u53ef\u4ee5\u4f7f\u7528\u9019\u4e9b GPU \u52a0\u901f\u5be6\u4f8b\u4e0a\u7684\u7279\u5b9a\u5de5\u4f5c\u8ca0\u8f09\uff0c\u4f8b\u5982\u6a5f\u5668\u5b78\u7fd2\u548c\u6578\u64da\u8655\u7406\u3002\n\u8981\u8a73\u7d30\u77ad\u89e3\u53ef\u4ee5\u4f7f\u7528 GPU \u57f7\u884c\u7684\u64cd\u4f5c\u4ee5\u53ca\u53ef\u7528\u7684 GPU \u786c\u4ef6\u985e\u578b\uff0c\u8acb\u53c3\u95b1 [Compute Engine \u4e0a\u7684 GPU](https://cloud.google.com/compute/docs/gpus?hl=zh-cn) \u3002\n\u5c0d\u65bc Dataproc \u96c6\u7fa3\u4e2d\u4f7f\u7528\u7684 GPU\uff0c\u6211\u5011\u4e0d\u6703\u5728 Compute Engine \u8cbb\u7528\u7684\u57fa\u790e\u4e0a\u6536\u53d6\u984d\u5916\u7684 [Dataproc \u50f9\u683c](https://cloud.google.com/dataproc/pricing?hl=zh-cn) \u8cbb\u7528\u3002\n", "content": "## \u6e96\u5099\u5de5\u4f5c\n- GPU \u9700\u8981\u7279\u6b8a\u7684\u9a45\u52d5\u7a0b\u5e8f\u548c\u8edf\u4ef6\u3002\u9019\u4e9b\u7d44\u4ef6\u672a\u9810\u5148\u5b89\u88dd\u5728 Dataproc \u96c6\u7fa3\u4e0a\u3002\n- \u8acb\u53c3\u95b1 [Compute Engine \u4e0a\u7684 GPU \u50f9\u683c](https://cloud.google.com/compute/pricing?hl=zh-cn#gpus) \u4ee5\u77ad\u89e3\u5728\u60a8\u7684\u5be6\u4f8b\u4e2d\u4f7f\u7528 GPU \u6240\u9700\u652f\u4ed8\u7684\u8cbb\u7528\u3002\n- \u8acb\u53c3\u95b1 [\u5305\u542b GPU \u7684\u5be6\u4f8b\u7684\u9650\u5236](https://cloud.google.com/compute/docs/gpus?hl=zh-cn#restrictions) \u4ee5\u77ad\u89e3\u9019\u4e9b\u5be6\u4f8b\u8207\u4e0d\u5305\u542b GPU \u7684\u5be6\u4f8b\u5728\u529f\u80fd\u4e0a\u6709\u4f55\u4e0d\u540c\u3002\n- \u6aa2\u67e5\u9805\u76ee\u7684 [\u914d\u984d\u9801\u9762](https://console.cloud.google.com/compute/quotas?hl=zh-cn) \u4ee5\u78ba\u4fdd\u9805\u76ee\u4e2d\u6709\u8db3\u5920\u7684 GPU \u914d\u984d\uff08`NVIDIA_K80_GPUS`\u3001`NVIDIA_P100_GPUS`\u6216`NVIDIA_V100_GPUS`\uff09\u3002\u5982\u679c\u914d\u984d\u9801\u9762\u4e0a\u672a\u5217\u51fa GPU\uff0c\u6216\u8005\u60a8\u9700\u8981\u984d\u5916\u7684 GPU \u914d\u984d\uff0c\u8acb [\u7533\u8acb\u589e\u52a0\u914d\u984d](https://cloud.google.com/compute/quotas?hl=zh-cn#requesting_additional_quota) \u3002## GPU \u7684\u985e\u578b\nDataproc \u7bc0\u9ede\u652f\u6301\u4ee5\u4e0b GPU \u985e\u578b\u3002\u5c07 GPU \u639b\u63a5\u5230 Dataproc \u96c6\u7fa3\u6642\uff0c\u60a8\u5fc5\u9808\u6307\u5b9a GPU \u985e\u578b\u3002\n- `nvidia-tesla-l4`- NVIDIA\u00ae Tesla\u00ae L4\n- `nvidia-tesla-a100`- NVIDIA\u00ae Tesla\u00ae A100\n- `nvidia-tesla-k80`- NVIDIA\u00ae Tesla\u00ae K80\n- `nvidia-tesla-p100`- NVIDIA\u00ae Tesla\u00ae P100\n- `nvidia-tesla-v100`- NVIDIA\u00ae Tesla\u00ae V100\n- `nvidia-tesla-p4`- NVIDIA\u00ae Tesla\u00ae P4\n- `nvidia-tesla-t4`- NVIDIA\u00ae Tesla\u00ae T4\n- `nvidia-tesla-p100-vws`- NVIDIA\u00ae Tesla\u00ae P100 \u865b\u64ec\u5de5\u4f5c\u7ad9\n- `nvidia-tesla-p4-vws`- NVIDIA\u00ae Tesla\u00ae P4 \u865b\u64ec\u5de5\u4f5c\u7ad9\n- `nvidia-tesla-t4-vws`- NVIDIA\u00ae Tesla\u00ae T4 \u865b\u64ec\u5de5\u4f5c\u7ad9## \u5c07 GPU \u639b\u63a5\u5230\u96c6\u7fa3\n\u5728\u4f7f\u7528\u4ee5\u4e0b\u6a19\u8a8c\u5275\u5efa\u96c6\u7fa3\u6642\uff0c\u5c07 GPU \u639b\u63a5\u5230 Dataproc \u96c6\u7fa3\u4e2d\u7684\u4e3b\u5be6\u4f8b\u4ee5\u53ca\u4e3b\u8981\u548c\u8f14\u52a9\u5de5\u4f5c\u5668\u7bc0\u9ede\uff1a [\u2011\u2011master-accelerator](https://cloud.google.com/sdk/gcloud/reference/dataproc/clusters/create?hl=zh-cn#--master-accelerator) \u3001 [\u2011\u2011worker-accelerator](https://cloud.google.com/sdk/gcloud/reference/dataproc/clusters/create?hl=zh-cn#--worker-accelerator) \u548c [\u2011\u2011secondary-worker-accelerator](https://cloud.google.com/sdk/gcloud/reference/dataproc/clusters/create?hl=zh-cn#--secondary-worker-accelerator) \u6a19\u8a8c\u3002\u9019\u4e9b\u6a19\u8a8c\u5177\u6709\u4ee5\u4e0b\u5169\u500b\u503c\uff1a- \u8981\u9023\u63a5\u5230\u7bc0\u9ede\u7684 GPU \u985e\u578b\uff0c\u4ee5\u53ca\n- \u8981\u9023\u63a5\u5230\u7bc0\u9ede\u7684 GPU \u6578\u91cf\u3002\n\u5fc5\u9808\u6307\u5b9a GPU \u7684\u985e\u578b\uff0c\u662f\u5426\u6307\u5b9a GPU \u7684\u6578\u91cf\u5247\u53d6\u6c7a\u65bc\u60a8\u7684\u9078\u64c7\uff08\u9ed8\u8a8d\u7232 1 \u500b GPU\uff09\u3002\n **\u4f8b\u5982\uff1a** \n```\ngcloud dataproc clusters create cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--master-accelerator type=nvidia-tesla-k80 \\\n\u00a0\u00a0\u00a0\u00a0--worker-accelerator type=nvidia-tesla-k80,count=4 \\\n\u00a0\u00a0\u00a0\u00a0--secondary-worker-accelerator type=nvidia-tesla-k80,count=4 \\\n\u00a0\u00a0\u00a0\u00a0... other flags\n```\n\u8981\u5728\u96c6\u7fa3\u4e2d\u4f7f\u7528 GPU\uff0c\u60a8\u5fc5\u9808 [\u5b89\u88dd GPU \u9a45\u52d5\u7a0b\u5e8f](https://cloud.google.com/compute/docs/gpus/install-drivers-gpu?hl=zh-cn) \u3002\u901a\u904e\u586b\u5beb [InstanceGroupConfig.AcceleratorConfig](https://cloud.google.com/dataproc/docs/reference/rest/v1/ClusterConfig?hl=zh-cn#AcceleratorConfig) `acceleratorTypeUri` \u548c `acceleratorCount` \u5b57\u6bb5\uff08\u5728 [cluster.create](https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.clusters/create?hl=zh-cn) API \u8acb\u6c42\u4e2d\uff09\uff0c\u5c07 GPU \u639b\u63a5\u5230 Dataproc \u96c6\u7fa3\u4e2d\u7684\u4e3b\u5be6\u4f8b\u4ee5\u53ca\u4e3b\u8981\u5de5\u4f5c\u5668\u7bc0\u9ede\u548c\u6b21\u8981\u5de5\u4f5c\u5668\u7bc0\u9ede\u3002\u5728 Google Cloud \u63a7\u5236\u6aaf\u4e2d [\u5275\u5efa\u96c6\u7fa3](https://console.cloud.google.com/dataproc/clustersAdd?hl=zh-cn) \u9801\u9762\u4e0a\uff0c\u9ede\u64ca\u201c\u914d\u7f6e\u7bc0\u9ede\u201d\u9762\u677f\u7684\u4e3b\u7bc0\u9ede\u548c\u5de5\u4f5c\u5668\u7bc0\u9ede\u90e8\u5206\u4e2d\u7684\u201cCPU \u5e73\u81fa\u548c GPU\u2192GPU\u201d\u2192\u201c\u6dfb\u52a0 GPU\u201d\uff0c\u7232\u7bc0\u9ede\u6307\u5b9a GPU \u6578\u91cf\u548c GPU \u985e\u578b\u3002\n## \u5b89\u88dd GPU \u9a45\u52d5\u7a0b\u5e8f\n\u8981\u4f7f\u7528\u9023\u63a5\u5230 Dataproc \u7bc0\u9ede\u7684\u4efb\u4f55 GPU\uff0c\u9700\u8981\u5b89\u88dd GPU \u9a45\u52d5\u7a0b\u5e8f\u3002\u60a8\u53ef\u4ee5\u6309\u7167\u4e0b\u9762\u5217\u51fa\u7684 [\u6b64\u521d\u59cb\u5316\u64cd\u4f5c\u7684\u8aaa\u660e](https://github.com/GoogleCloudDataproc/initialization-actions/tree/master/gpu) \u4f86\u5b89\u88dd GPU \u9a45\u52d5\u7a0b\u5e8f\u3002\n[gpu/install_gpu_driver.sh](https://github.com/GoogleCloudDataproc/initialization-actions/blob/HEAD/gpu/install_gpu_driver.sh) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudDataproc/initialization-actions/blob/HEAD/gpu/install_gpu_driver.sh)\n```\n#!/bin/bash\n## Licensed under the Apache License, Version 2.0 (the \"License\");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at\n## \u00a0 \u00a0 \u00a0http://www.apache.org/licenses/LICENSE-2.0\n## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS-IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.\n## This script installs NVIDIA GPU drivers and collects GPU utilization metrics.set -euxo pipefailfunction compare_versions_lte {\u00a0 [ \"$1\" = \"$(echo -e \"$1\\n$2\" | sort -V | head -n1)\" ]}function compare_versions_lt() {\u00a0 [ \"$1\" = \"$2\" ] && return 1 || compare_versions_lte $1 $2}function get_metadata_attribute() {\u00a0 local -r attribute_name=$1\u00a0 local -r default_value=$2\u00a0 /usr/share/google/get_metadata_value \"attributes/${attribute_name}\" || echo -n \"${default_value}\"}OS_NAME=$(lsb_release -is | tr '[:upper:]' '[:lower:]')distribution=$(. /etc/os-release;echo $ID$VERSION_ID)readonly OS_NAME# node roleROLE=\"$(/usr/share/google/get_metadata_value attributes/dataproc-role)\"readonly ROLE# CUDA version and Driver version# https://docs.nvidia.com/deeplearning/frameworks/support-matrix/index.htmlreadonly -A DRIVER_FOR_CUDA=([10.1]=\"418.88\" \u00a0 \u00a0[10.2]=\"440.64.00\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.0]=\"450.51.06\" [11.1]=\"455.45.01\" [11.2]=\"460.73.01\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.5]=\"495.29.05\" [11.6]=\"510.47.03\" [11.7]=\"515.65.01\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.8]=\"520.56.06\")readonly -A CUDNN_FOR_CUDA=( [10.1]=\"7.6.4.38\" \u00a0[10.2]=\"7.6.5.32\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.0]=\"8.0.4.30\" \u00a0[11.1]=\"8.0.5.39\" \u00a0[11.2]=\"8.1.1.33\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.5]=\"8.3.3.40\" \u00a0[11.6]=\"8.4.1.50\" \u00a0[11.7]=\"8.5.0.96\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.8]=\"8.6.0.163\")readonly -A NCCL_FOR_CUDA=( \u00a0[10.1]=\"2.4.8\" \u00a0 \u00a0 [10.2]=\"2.5.6\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.0]=\"2.7.8\" \u00a0 \u00a0 [11.1]=\"2.8.3\" \u00a0 \u00a0 [11.2]=\"2.8.3\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.5]=\"2.11.4\" \u00a0 \u00a0[11.6]=\"2.11.4\" \u00a0 \u00a0[11.7]=\"2.12.12\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.8]=\"2.15.5\")readonly -A CUDA_SUBVER=( \u00a0 \u00a0[10.1]=\"10.1.243\" \u00a0[10.2]=\"10.2.89\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.0]=\"11.0.3\" \u00a0 \u00a0[11.1]=\"11.1.0\" \u00a0 \u00a0[11.2]=\"11.2.2\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.5]=\"11.5.2\" \u00a0 \u00a0[11.6]=\"11.6.2\" \u00a0 \u00a0[11.7]=\"11.7.1\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 [11.8]=\"11.8.0\")RUNTIME=$(get_metadata_attribute 'rapids-runtime' 'SPARK')DEFAULT_CUDA_VERSION='11.2'if [[ ${DATAPROC_IMAGE_VERSION} == 2.* ]] && [[ \"${RUNTIME}\" == \"SPARK\" ]]; then\u00a0 DEFAULT_CUDA_VERSION='11.5'fireadonly DEFAULT_CUDA_VERSIONreadonly CUDA_VERSION=$(get_metadata_attribute 'cuda-version' \"${DEFAULT_CUDA_VERSION}\")readonly DEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_VERSION=${DRIVER_FOR_CUDA[\"${CUDA_VERSION}\"]}readonly NVIDIA_DEBIAN_GPU_DRIVER_VERSION=$(get_metadata_attribute 'gpu-driver-version' ${DEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_VERSION})readonly NVIDIA_DEBIAN_GPU_DRIVER_VERSION_PREFIX=${NVIDIA_DEBIAN_GPU_DRIVER_VERSION%%.*}readonly DRIVER=${NVIDIA_DEBIAN_GPU_DRIVER_VERSION_PREFIX}# As of Rocky 8.7, kernel 4.18.0-425 is unable to build older nvidia kernel driversif [[ \"${OS_NAME}\" == \"rocky\" && \u00a0\"${DRIVER}\" < \"510\" ]]; then\u00a0 readonly ROCKY_BINARY_INSTALL=\"true\"fi# Fail early for configurations known to be unsupportedfunction unsupported_error {\u00a0 echo \"Unsupported kernel driver on ${distribution}: '${DRIVER}'\"\u00a0 exit -1}if [[ \"${OS_NAME}\" == \"rocky\" ]]; then\u00a0 KERNEL_SUBVERSION=$(uname -r | awk -F- '{print $2}')\u00a0 if [[ \"${DRIVER}\" < \"460\" && \"${DRIVER}\" != \"450\"\u00a0 \u00a0 \u00a0&& \"${KERNEL_SUBVERSION%%.*}\" > \"305\" ]]; then\u00a0 \u00a0 unsupported_error\u00a0 fielif [[ \"${OS_NAME}\" == \"debian\" ]]; then\u00a0 KERNEL_VERSION=$(uname -r | awk -F- '{print $1}')\u00a0 if [[ \"${DRIVER}\" < \"455\"\u00a0 \u00a0 \u00a0&& $(echo \"${KERNEL_VERSION%.*} > 5.7\" | bc -l) == 1 \u00a0]]; then\u00a0 \u00a0 unsupported_error\u00a0 fifiDEFAULT_NCCL_VERSION=${NCCL_FOR_CUDA[\"${CUDA_VERSION}\"]}if [[ \"${OS_NAME}\" == \"rocky\" ]] \\\u00a0 \u00a0&& (compare_versions_lte \"${DEFAULT_NCCL_VERSION}\" \"2.8.4\") ; then\u00a0 DEFAULT_NCCL_VERSION=\"2.8.4\"fireadonly DEFAULT_NCCL_VERSIONreadonly NCCL_VERSION=$(get_metadata_attribute 'nccl-version' ${DEFAULT_NCCL_VERSION})# Parameters for NVIDIA-provided Debian GPU driverDEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_URL=\"https://download.nvidia.com/XFree86/Linux-x86_64/${NVIDIA_DEBIAN_GPU_DRIVER_VERSION}/NVIDIA-Linux-x86_64-${NVIDIA_DEBIAN_GPU_DRIVER_VERSION}.run\"if [[ \"$(curl -s -I ${DEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_URL} | head -1 | awk '{print $2}')\" != \"200\" ]]; then\u00a0 DEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_URL=\"https://download.nvidia.com/XFree86/Linux-x86_64/${NVIDIA_DEBIAN_GPU_DRIVER_VERSION%.*}/NVIDIA-Linux-x86_64-${NVIDIA_DEBIAN_GPU_DRIVER_VERSION%.*}.run\"fireadonly DEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_URLNVIDIA_DEBIAN_GPU_DRIVER_URL=$(get_metadata_attribute 'gpu-driver-url' \"${DEFAULT_NVIDIA_DEBIAN_GPU_DRIVER_URL}\")readonly NVIDIA_DEBIAN_GPU_DRIVER_URLreadonly NVIDIA_BASE_DL_URL='https://developer.download.nvidia.com/compute'# Parameters for NVIDIA-provided NCCL libraryreadonly DEFAULT_NCCL_REPO_URL=\"${NVIDIA_BASE_DL_URL}/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\"NCCL_REPO_URL=$(get_metadata_attribute 'nccl-repo-url' \"${DEFAULT_NCCL_REPO_URL}\")readonly NCCL_REPO_URLreadonly NCCL_REPO_KEY=\"${NVIDIA_BASE_DL_URL}/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\"readonly -A DEFAULT_NVIDIA_DEBIAN_CUDA_URLS=(\u00a0 [10.1]=\"${NVIDIA_BASE_DL_URL}/cuda/10.1/Prod/local_installers/cuda_10.1.243_418.87.00_linux.run\"\u00a0 [10.2]=\"${NVIDIA_BASE_DL_URL}/cuda/10.2/Prod/local_installers/cuda_10.2.89_440.33.01_linux.run\"\u00a0 [11.0]=\"${NVIDIA_BASE_DL_URL}/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run\"\u00a0 [11.1]=\"${NVIDIA_BASE_DL_URL}/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run\"\u00a0 [11.2]=\"${NVIDIA_BASE_DL_URL}/cuda/11.2.2/local_installers/cuda_11.2.2_460.32.03_linux.run\"\u00a0 [11.5]=\"${NVIDIA_BASE_DL_URL}/cuda/11.5.2/local_installers/cuda_11.5.2_495.29.05_linux.run\"\u00a0 [11.6]=\"${NVIDIA_BASE_DL_URL}/cuda/11.6.2/local_installers/cuda_11.6.2_510.47.03_linux.run\"\u00a0 [11.7]=\"${NVIDIA_BASE_DL_URL}/cuda/11.7.1/local_installers/cuda_11.7.1_515.65.01_linux.run\"\u00a0 [11.8]=\"${NVIDIA_BASE_DL_URL}/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run\")readonly DEFAULT_NVIDIA_DEBIAN_CUDA_URL=${DEFAULT_NVIDIA_DEBIAN_CUDA_URLS[\"${CUDA_VERSION}\"]}NVIDIA_DEBIAN_CUDA_URL=$(get_metadata_attribute 'cuda-url' \"${DEFAULT_NVIDIA_DEBIAN_CUDA_URL}\")readonly NVIDIA_DEBIAN_CUDA_URL# Parameters for NVIDIA-provided Ubuntu GPU driverreadonly NVIDIA_UBUNTU_REPO_URL=\"${NVIDIA_BASE_DL_URL}/cuda/repos/ubuntu1804/x86_64\"readonly NVIDIA_UBUNTU_REPO_KEY_PACKAGE=\"${NVIDIA_UBUNTU_REPO_URL}/cuda-keyring_1.0-1_all.deb\"readonly NVIDIA_UBUNTU_REPO_CUDA_PIN=\"${NVIDIA_UBUNTU_REPO_URL}/cuda-ubuntu1804.pin\"# Parameter for NVIDIA-provided Rocky Linux GPU driverreadonly NVIDIA_ROCKY_REPO_URL=\"${NVIDIA_BASE_DL_URL}/cuda/repos/rhel8/x86_64/cuda-rhel8.repo\"# Parameters for NVIDIA-provided CUDNN libraryDEFAULT_CUDNN_VERSION=${CUDNN_FOR_CUDA[\"${CUDA_VERSION}\"]}if [[ \"${OS_NAME}\" == \"rocky\" ]] \\\u00a0 \u00a0&& (compare_versions_lte \"${DEFAULT_CUDNN_VERSION}\" \"8.0.5.39\") ; then\u00a0 DEFAULT_CUDNN_VERSION=\"8.0.5.39\"fireadonly DEFAULT_CUDNN_VERSIONreadonly CUDNN_VERSION=$(get_metadata_attribute 'cudnn-version' \"${DEFAULT_CUDNN_VERSION}\")CUDNN_TARBALL=\"cudnn-${CUDA_VERSION}-linux-x64-v${CUDNN_VERSION}.tgz\"CUDNN_TARBALL_URL=\"${NVIDIA_BASE_DL_URL}/redist/cudnn/v${CUDNN_VERSION%.*}/${CUDNN_TARBALL}\"if ( compare_versions_lte \"8.3.1.22\" \"${CUDNN_VERSION}\" ); then\u00a0 CUDNN_TARBALL=\"cudnn-linux-x86_64-${CUDNN_VERSION}_cuda${CUDA_VERSION%.*}-archive.tar.xz\"\u00a0 if ( compare_versions_lte \"${CUDNN_VERSION}\" \"8.4.1.50\" ); then\u00a0 \u00a0 CUDNN_TARBALL=\"cudnn-linux-x86_64-${CUDNN_VERSION}_cuda${CUDA_VERSION}-archive.tar.xz\"\u00a0 fi\u00a0 CUDNN_TARBALL_URL=\"${NVIDIA_BASE_DL_URL}/redist/cudnn/v${CUDNN_VERSION%.*}/local_installers/${CUDA_VERSION}/${CUDNN_TARBALL}\"fireadonly CUDNN_TARBALLreadonly CUDNN_TARBALL_URL# Whether to install NVIDIA-provided or OS-provided GPU driverGPU_DRIVER_PROVIDER=$(get_metadata_attribute 'gpu-driver-provider' 'NVIDIA')readonly GPU_DRIVER_PROVIDER# Stackdriver GPU agent parametersreadonly GPU_AGENT_REPO_URL='https://raw.githubusercontent.com/GoogleCloudPlatform/ml-on-gcp/master/dlvm/gcp-gpu-utilization-metrics'# Whether to install GPU monitoring agent that sends GPU metrics to StackdriverINSTALL_GPU_AGENT=$(get_metadata_attribute 'install-gpu-agent' 'false')readonly INSTALL_GPU_AGENT# Dataproc configurationsreadonly HADOOP_CONF_DIR='/etc/hadoop/conf'readonly HIVE_CONF_DIR='/etc/hive/conf'readonly SPARK_CONF_DIR='/etc/spark/conf'NVIDIA_SMI_PATH='/usr/bin'MIG_MAJOR_CAPS=0IS_MIG_ENABLED=0function execute_with_retries() {\u00a0 local -r cmd=$1\u00a0 for ((i = 0; i < 10; i++)); do\u00a0 \u00a0 if eval \"$cmd\"; then\u00a0 \u00a0 \u00a0 return 0\u00a0 \u00a0 fi\u00a0 \u00a0 sleep 5\u00a0 done\u00a0 return 1}function install_nvidia_nccl() {\u00a0 local -r nccl_version=\"${NCCL_VERSION}-1+cuda${CUDA_VERSION}\"\u00a0 if [[ ${OS_NAME} == rocky ]]; then\u00a0 \u00a0 execute_with_retries \"dnf -y -q install libnccl-${nccl_version} libnccl-devel-${nccl_version} libnccl-static-${nccl_version}\"\u00a0 elif [[ ${OS_NAME} == ubuntu ]] || [[ ${OS_NAME} == debian ]]; then\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \"${NCCL_REPO_KEY}\" | apt-key add -\u00a0 \u00a0 local tmp_dir\u00a0 \u00a0 tmp_dir=$(mktemp -d -t gpu-init-action-nccl-XXXX)\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${NCCL_REPO_URL}\" -o \"${tmp_dir}/nvidia-ml-repo.deb\"\u00a0 \u00a0 dpkg -i \"${tmp_dir}/nvidia-ml-repo.deb\"\u00a0 \u00a0 execute_with_retries \"apt-get update\"\u00a0 \u00a0 execute_with_retries \\\u00a0 \u00a0 \u00a0 \"apt-get install -y --allow-unauthenticated libnccl2=${nccl_version} libnccl-dev=${nccl_version}\"\u00a0 else\u00a0 \u00a0 echo \"Unsupported OS: '${OS_NAME}'\"\u00a0 \u00a0 exit 1\u00a0 fi}function install_nvidia_cudnn() {\u00a0 local major_version\u00a0 major_version=\"${CUDNN_VERSION%%.*}\"\u00a0 local cudnn_pkg_version\u00a0 cudnn_pkg_version=\"${CUDNN_VERSION}-1+cuda${CUDA_VERSION}\"\u00a0 if [[ ${OS_NAME} == rocky ]]; then\u00a0 \u00a0 if [[ ${major_version} == 8 ]]; then\u00a0 \u00a0 \u00a0 execute_with_retries \"dnf -y -q install libcudnn8-${cudnn_pkg_version} libcudnn8-devel-${cudnn_pkg_version}\"\u00a0 \u00a0 else\u00a0 \u00a0 \u00a0 echo \"Unsupported CUDNN version: '${CUDNN_VERSION}'\"\u00a0 \u00a0 \u00a0 exit 1\u00a0 \u00a0 fi\u00a0 elif [[ ${OS_NAME} == ubuntu ]]; then\u00a0 \u00a0 local -a packages\u00a0 \u00a0 packages=(\u00a0 \u00a0 \u00a0 \"libcudnn${major_version}=${cudnn_pkg_version}\"\u00a0 \u00a0 \u00a0 \"libcudnn${major_version}-dev=${cudnn_pkg_version}\")\u00a0 \u00a0 execute_with_retries \\\u00a0 \u00a0 \u00a0 \"apt-get install -y --no-install-recommends ${packages[*]}\"\u00a0 elif [[ ${OS_NAME} == debian ]]; then\u00a0 \u00a0 local tmp_dir\u00a0 \u00a0 tmp_dir=$(mktemp -d -t gpu-init-action-cudnn-XXXX)\u00a0 \u00a0 curl -fSsL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${CUDNN_TARBALL_URL}\" -o \"${tmp_dir}/${CUDNN_TARBALL}\"\u00a0 \u00a0 if ( compare_versions_lte \"${CUDNN_VERSION}\" \"8.3.0.98\" ); then\u00a0 \u00a0 \u00a0 tar -xzf \"${tmp_dir}/${CUDNN_TARBALL}\" -C /usr/local\u00a0 \u00a0 else\u00a0 \u00a0 \u00a0 ln -sf /usr/local/cuda/targets/x86_64-linux/lib /usr/local/cuda/lib\u00a0 \u00a0 \u00a0 tar -h --no-same-owner --strip-components=1 \\\u00a0 \u00a0 \u00a0 \u00a0 -xJf \"${tmp_dir}/${CUDNN_TARBALL}\" -C /usr/local/cuda\u00a0 \u00a0 fi\u00a0 \u00a0 cat <<'EOF' >>/etc/profile.d/cudnn.shexport LD_LIBRARY_PATH=/usr/local/cuda/lib64:${LD_LIBRARY_PATH}EOF\u00a0 else\u00a0 \u00a0 echo \"Unsupported OS: '${OS_NAME}'\"\u00a0 \u00a0 exit 1\u00a0 fi\u00a0 ldconfig\u00a0 echo \"NVIDIA cuDNN successfully installed for ${OS_NAME}.\"}# Install NVIDIA GPU driver provided by NVIDIAfunction install_nvidia_gpu_driver() {\u00a0 if [[ ${OS_NAME} == debian ]]; then\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${NVIDIA_UBUNTU_REPO_KEY_PACKAGE}\" -o /tmp/cuda-keyring.deb\u00a0 \u00a0 dpkg -i \"/tmp/cuda-keyring.deb\"\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${NVIDIA_DEBIAN_GPU_DRIVER_URL}\" -o driver.run\u00a0 \u00a0 bash \"./driver.run\" --silent --install-libglvnd\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${NVIDIA_DEBIAN_CUDA_URL}\" -o cuda.run\u00a0 \u00a0 bash \"./cuda.run\" --silent --toolkit --no-opengl-libs\u00a0 elif [[ ${OS_NAME} == ubuntu ]]; then\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${NVIDIA_UBUNTU_REPO_KEY_PACKAGE}\" -o /tmp/cuda-keyring.deb\u00a0 \u00a0 dpkg -i \"/tmp/cuda-keyring.deb\"\u00a0 \u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \u00a0 \"${NVIDIA_UBUNTU_REPO_CUDA_PIN}\" -o /etc/apt/preferences.d/cuda-repository-pin-600\u00a0 \u00a0 add-apt-repository \"deb ${NVIDIA_UBUNTU_REPO_URL} /\"\u00a0 \u00a0 execute_with_retries \"apt-get update\"\u00a0 \u00a0 if [[ -n \"${CUDA_VERSION}\" ]]; then\u00a0 \u00a0 \u00a0 local -r cuda_package=cuda-toolkit-${CUDA_VERSION//./-}\u00a0 \u00a0 else\u00a0 \u00a0 \u00a0 local -r cuda_package=cuda-toolkit\u00a0 \u00a0 fi\u00a0 \u00a0 # Without --no-install-recommends this takes a very long time.\u00a0 \u00a0 execute_with_retries \"apt-get install -y -q --no-install-recommends cuda-drivers-${NVIDIA_DEBIAN_GPU_DRIVER_VERSION_PREFIX}\"\u00a0 \u00a0 execute_with_retries \"apt-get install -y -q --no-install-recommends ${cuda_package}\"\u00a0 elif [[ ${OS_NAME} == rocky ]]; then\u00a0 \u00a0 execute_with_retries \"dnf config-manager --add-repo ${NVIDIA_ROCKY_REPO_URL}\"\u00a0 \u00a0 execute_with_retries \"dnf clean all\"\u00a0 \u00a0 if [[ \"${ROCKY_BINARY_INSTALL}\" == \"true\" ]]; then\u00a0 \u00a0 \u00a0 execute_with_retries \"dnf -y -q module install nvidia-driver\"\u00a0 \u00a0 else\u00a0 \u00a0 \u00a0 execute_with_retries \"dnf -y -q module install nvidia-driver:${NVIDIA_DEBIAN_GPU_DRIVER_VERSION_PREFIX}-dkms\"\u00a0 \u00a0 fi\u00a0 \u00a0 NVIDIA_ROCKY_GPU_DRIVER_VERSION=\"$(ls -d /usr/src/nvidia-* | awk -F\"nvidia-\" '{print $2}')\"\u00a0 \u00a0 execute_with_retries \"dkms build nvidia/${NVIDIA_ROCKY_GPU_DRIVER_VERSION}\"\u00a0 \u00a0 execute_with_retries \"dkms install nvidia/${NVIDIA_ROCKY_GPU_DRIVER_VERSION}\"\u00a0 \u00a0 modprobe nvidia\u00a0 \u00a0 execute_with_retries \"dnf -y -q install cuda-${CUDA_VERSION//./-}\"\u00a0 else\u00a0 \u00a0 echo \"Unsupported OS: '${OS_NAME}'\"\u00a0 \u00a0 exit 1\u00a0 fi\u00a0 ldconfig\u00a0 echo \"NVIDIA GPU driver provided by NVIDIA was installed successfully\"}# Collects 'gpu_utilization' and 'gpu_memory_utilization' metricsfunction install_gpu_agent() {\u00a0 if ! command -v pip; then\u00a0 \u00a0 execute_with_retries \"apt-get install -y -q python-pip\"\u00a0 fi\u00a0 local install_dir=/opt/gpu-utilization-agent\u00a0 mkdir -p \"${install_dir}\"\u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \"${GPU_AGENT_REPO_URL}/requirements.txt\" -o \"${install_dir}/requirements.txt\"\u00a0 curl -fsSL --retry-connrefused --retry 10 --retry-max-time 30 \\\u00a0 \u00a0 \"${GPU_AGENT_REPO_URL}/report_gpu_metrics.py\" -o \"${install_dir}/report_gpu_metrics.py\"\u00a0 pip install -r \"${install_dir}/requirements.txt\"\u00a0 # Generate GPU service.\u00a0 cat <<EOF >/lib/systemd/system/gpu-utilization-agent.service[Unit]Description=GPU Utilization Metric Agent[Service]Type=simplePIDFile=/run/gpu_agent.pidExecStart=/bin/bash --login -c 'python \"${install_dir}/report_gpu_metrics.py\"'User=rootGroup=rootWorkingDirectory=/Restart=always[Install]WantedBy=multi-user.targetEOF\u00a0 # Reload systemd manager configuration\u00a0 systemctl daemon-reload\u00a0 # Enable gpu-utilization-agent service\u00a0 systemctl --no-reload --now enable gpu-utilization-agent.service}function set_hadoop_property() {\u00a0 local -r config_file=$1\u00a0 local -r property=$2\u00a0 local -r value=$3\u00a0 bdconfig set_property \\\u00a0 \u00a0 --configuration_file \"${HADOOP_CONF_DIR}/${config_file}\" \\\u00a0 \u00a0 --name \"${property}\" --value \"${value}\" \\\u00a0 \u00a0 --clobber}function configure_yarn() {\u00a0 if [[ ! -f ${HADOOP_CONF_DIR}/resource-types.xml ]]; then\u00a0 \u00a0 printf '<?xml version=\"1.0\" ?>\\n<configuration/>' >\"${HADOOP_CONF_DIR}/resource-types.xml\"\u00a0 fi\u00a0 set_hadoop_property 'resource-types.xml' 'yarn.resource-types' 'yarn.io/gpu'\u00a0 set_hadoop_property 'capacity-scheduler.xml' \\\u00a0 \u00a0 'yarn.scheduler.capacity.resource-calculator' \\\u00a0 \u00a0 'org.apache.hadoop.yarn.util.resource.DominantResourceCalculator'\u00a0 set_hadoop_property 'yarn-site.xml' 'yarn.resource-types' 'yarn.io/gpu'}# This configuration should be applied only if GPU is attached to the nodefunction configure_yarn_nodemanager() {\u00a0 set_hadoop_property 'yarn-site.xml' 'yarn.nodemanager.resource-plugins' 'yarn.io/gpu'\u00a0 set_hadoop_property 'yarn-site.xml' \\\u00a0 \u00a0 'yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices' 'auto'\u00a0 set_hadoop_property 'yarn-site.xml' \\\u00a0 \u00a0 'yarn.nodemanager.resource-plugins.gpu.path-to-discovery-executables' $NVIDIA_SMI_PATH\u00a0 set_hadoop_property 'yarn-site.xml' \\\u00a0 \u00a0 'yarn.nodemanager.linux-container-executor.cgroups.mount' 'true'\u00a0 set_hadoop_property 'yarn-site.xml' \\\u00a0 \u00a0 'yarn.nodemanager.linux-container-executor.cgroups.mount-path' '/sys/fs/cgroup'\u00a0 set_hadoop_property 'yarn-site.xml' \\\u00a0 \u00a0 'yarn.nodemanager.linux-container-executor.cgroups.hierarchy' 'yarn'\u00a0 set_hadoop_property 'yarn-site.xml' \\\u00a0 \u00a0 'yarn.nodemanager.container-executor.class' \\\u00a0 \u00a0 'org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor'\u00a0 set_hadoop_property 'yarn-site.xml' 'yarn.nodemanager.linux-container-executor.group' 'yarn'\u00a0 # Fix local dirs access permissions\u00a0 local yarn_local_dirs=()\u00a0 readarray -d ',' yarn_local_dirs < <(bdconfig get_property_value \\\u00a0 \u00a0 --configuration_file \"${HADOOP_CONF_DIR}/yarn-site.xml\" \\\u00a0 \u00a0 --name \"yarn.nodemanager.local-dirs\" 2>/dev/null | tr -d '\\n')\u00a0 chown yarn:yarn -R \"${yarn_local_dirs[@]/,/}\"}function configure_gpu_exclusive_mode() {\u00a0 # check if running spark 3, if not, enable GPU exclusive mode\u00a0 local spark_version\u00a0 spark_version=$(spark-submit --version 2>&1 | sed -n 's/.*version[[:blank:]]\\+\\([0-9]\\+\\.[0-9]\\).*/\\1/p' | head -n1)\u00a0 if [[ ${spark_version} != 3.* ]]; then\u00a0 \u00a0 # include exclusive mode on GPU\u00a0 \u00a0 nvidia-smi -c EXCLUSIVE_PROCESS\u00a0 fi}function fetch_mig_scripts() {\u00a0 mkdir -p /usr/local/yarn-mig-scripts\u00a0 sudo chmod 755 /usr/local/yarn-mig-scripts\u00a0 wget -P /usr/local/yarn-mig-scripts/ https://raw.githubusercontent.com/NVIDIA/spark-rapids-examples/branch-22.10/examples/MIG-Support/yarn-unpatched/scripts/nvidia-smi\u00a0 wget -P /usr/local/yarn-mig-scripts/ https://raw.githubusercontent.com/NVIDIA/spark-rapids-examples/branch-22.10/examples/MIG-Support/yarn-unpatched/scripts/mig2gpu.sh\u00a0 sudo chmod 755 /usr/local/yarn-mig-scripts/*}function configure_gpu_script() {\u00a0 # Download GPU discovery script\u00a0 local -r spark_gpu_script_dir='/usr/lib/spark/scripts/gpu'\u00a0 mkdir -p ${spark_gpu_script_dir}\u00a0 # need to update the getGpusResources.sh script to look for MIG devices since if multiple GPUs nvidia-smi still\u00a0 # lists those because we only disable the specific GIs via CGROUPs. Here we just create it based off of:\u00a0 # https://raw.githubusercontent.com/apache/spark/master/examples/src/main/scripts/getGpusResources.sh\u00a0 echo '#!/usr/bin/env bash\n## Licensed to the Apache Software Foundation (ASF) under one or more# contributor license agreements. \u00a0See the NOTICE file distributed with# this work for additional information regarding copyright ownership.# The ASF licenses this file to You under the Apache License, Version 2.0# (the \"License\"); you may not use this file except in compliance with# the License. \u00a0You may obtain a copy of the License at\n## \u00a0 \u00a0http://www.apache.org/licenses/LICENSE-2.0\n## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#NUM_MIG_DEVICES=$(nvidia-smi -L | grep MIG | wc -l)ADDRS=$(nvidia-smi --query-gpu=index --format=csv,noheader | sed -e '\\'':a'\\'' -e '\\''N'\\'' -e'\\''$!ba'\\'' -e '\\''s/\\n/\",\"/g'\\'')if [ $NUM_MIG_DEVICES -gt 0 ]; then\u00a0 MIG_INDEX=$(( $NUM_MIG_DEVICES - 1 ))\u00a0 ADDRS=$(seq -s '\\''\",\"'\\'' 0 $MIG_INDEX)fiecho {\\\"name\\\": \\\"gpu\\\", \\\"addresses\\\":[\\\"$ADDRS\\\"]}' > ${spark_gpu_script_dir}/getGpusResources.sh\u00a0 chmod a+rwx -R ${spark_gpu_script_dir}}function configure_gpu_isolation() {\u00a0 # enable GPU isolation\u00a0 sed -i \"s/yarn\\.nodemanager\\.linux\\-container\\-executor\\.group\\=.*$/yarn\\.nodemanager\\.linux\\-container\\-executor\\.group\\=yarn/g\" \"${HADOOP_CONF_DIR}/container-executor.cfg\"\u00a0 if [[ $IS_MIG_ENABLED -ne 0 ]]; then\u00a0 \u00a0 # configure the container-executor.cfg to have major caps\u00a0 \u00a0 printf '\\n[gpu]\\nmodule.enabled=true\\ngpu.major-device-number=%s\\n\\n[cgroups]\\nroot=/sys/fs/cgroup\\nyarn-hierarchy=yarn\\n' $MIG_MAJOR_CAPS >> \"${HADOOP_CONF_DIR}/container-executor.cfg\"\u00a0 \u00a0 printf 'export MIG_AS_GPU_ENABLED=1\\n' >> \"${HADOOP_CONF_DIR}/yarn-env.sh\"\u00a0 \u00a0 printf 'export ENABLE_MIG_GPUS_FOR_CGROUPS=1\\n' >> \"${HADOOP_CONF_DIR}/yarn-env.sh\"\u00a0 else\u00a0 \u00a0 printf '\\n[gpu]\\nmodule.enabled=true\\n[cgroups]\\nroot=/sys/fs/cgroup\\nyarn-hierarchy=yarn\\n' >> \"${HADOOP_CONF_DIR}/container-executor.cfg\"\u00a0 fi\u00a0 # Configure a systemd unit to ensure that permissions are set on restart\u00a0 cat >/etc/systemd/system/dataproc-cgroup-device-permissions.service<<EOF[Unit]Description=Set permissions to allow YARN to access device directories[Service]ExecStart=/bin/bash -c \"chmod a+rwx -R /sys/fs/cgroup/cpu,cpuacct; chmod a+rwx -R /sys/fs/cgroup/devices\"[Install]WantedBy=multi-user.targetEOF\u00a0 systemctl enable dataproc-cgroup-device-permissions\u00a0 systemctl start dataproc-cgroup-device-permissions}function main() {\u00a0 if [[ ${OS_NAME} != debian ]] && [[ ${OS_NAME} != ubuntu ]] && [[ ${OS_NAME} != rocky ]]; then\u00a0 \u00a0 echo \"Unsupported OS: '${OS_NAME}'\"\u00a0 \u00a0 exit 1\u00a0 fi\u00a0 if [[ ${OS_NAME} == debian ]] || [[ ${OS_NAME} == ubuntu ]]; then\u00a0 \u00a0 export DEBIAN_FRONTEND=noninteractive\u00a0 \u00a0 execute_with_retries \"apt-get update\"\u00a0 \u00a0 execute_with_retries \"apt-get install -y -q pciutils\"\u00a0 elif [[ ${OS_NAME} == rocky ]] ; then\u00a0 \u00a0 execute_with_retries \"dnf -y -q update\"\u00a0 \u00a0 execute_with_retries \"dnf -y -q install pciutils\"\u00a0 \u00a0 execute_with_retries \"dnf -y -q install kernel-devel-$(uname -r)\"\u00a0 \u00a0 execute_with_retries \"dnf -y -q install gcc\"\u00a0 fi\u00a0 # This configuration should be ran on all nodes\u00a0 # regardless if they have attached GPUs\u00a0 configure_yarn\u00a0 # Detect NVIDIA GPU\u00a0 if (lspci | grep -q NVIDIA); then\u00a0 \u00a0 # if this is called without the MIG script then the drivers are not installed\u00a0 \u00a0 if (/usr/bin/nvidia-smi --query-gpu=mig.mode.current --format=csv,noheader | uniq | wc -l); then\u00a0 \u00a0 \u00a0 NUM_MIG_GPUS=`/usr/bin/nvidia-smi --query-gpu=mig.mode.current --format=csv,noheader | uniq | wc -l`\u00a0 \u00a0 \u00a0 if [[ $NUM_MIG_GPUS -eq 1 ]]; then\u00a0 \u00a0 \u00a0 \u00a0 if (/usr/bin/nvidia-smi --query-gpu=mig.mode.current --format=csv,noheader | grep Enabled); then\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 IS_MIG_ENABLED=1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 NVIDIA_SMI_PATH='/usr/local/yarn-mig-scripts/'\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MIG_MAJOR_CAPS=`grep nvidia-caps /proc/devices | cut -d ' ' -f 1`\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fetch_mig_scripts\u00a0 \u00a0 \u00a0 \u00a0 fi\u00a0 \u00a0 \u00a0 fi\u00a0 \u00a0 fi\u00a0 \u00a0 if [[ ${OS_NAME} == debian ]] || [[ ${OS_NAME} == ubuntu ]]; then\u00a0 \u00a0 \u00a0 execute_with_retries \"apt-get install -y -q 'linux-headers-$(uname -r)'\"\u00a0 \u00a0 fi\u00a0 \u00a0 # if mig is enabled drivers would have already been installed\u00a0 \u00a0 if [[ $IS_MIG_ENABLED -eq 0 ]]; then\u00a0 \u00a0 \u00a0 install_nvidia_gpu_driver\u00a0 \u00a0 \u00a0 if [[ -n ${CUDNN_VERSION} ]]; then\u00a0 \u00a0 \u00a0 \u00a0 install_nvidia_nccl\u00a0 \u00a0 \u00a0 \u00a0 install_nvidia_cudnn\u00a0 \u00a0 \u00a0 fi\u00a0 \u00a0 \u00a0 #Install GPU metrics collection in Stackdriver if needed\u00a0 \u00a0 \u00a0 if [[ ${INSTALL_GPU_AGENT} == true ]]; then\u00a0 \u00a0 \u00a0 \u00a0 install_gpu_agent\u00a0 \u00a0 \u00a0 \u00a0 echo 'GPU metrics agent successfully deployed.'\u00a0 \u00a0 \u00a0 else\u00a0 \u00a0 \u00a0 \u00a0 echo 'GPU metrics agent will not be installed.'\u00a0 \u00a0 \u00a0 fi\u00a0 \u00a0 \u00a0 configure_gpu_exclusive_mode\u00a0 \u00a0 fi\u00a0 \u00a0 configure_yarn_nodemanager\u00a0 \u00a0 configure_gpu_script\u00a0 \u00a0 configure_gpu_isolation\u00a0 elif [[ \"${ROLE}\" == \"Master\" ]]; then\u00a0 \u00a0 configure_yarn_nodemanager\u00a0 \u00a0 configure_gpu_script\u00a0 fi\u00a0 # Restart YARN services if they are running already\u00a0 if [[ $(systemctl show hadoop-yarn-resourcemanager.service -p SubState --value) == 'running' ]]; then\u00a0 \u00a0 systemctl restart hadoop-yarn-resourcemanager.service\u00a0 fi\u00a0 if [[ $(systemctl show hadoop-yarn-nodemanager.service -p SubState --value) == 'running' ]]; then\u00a0 \u00a0 systemctl restart hadoop-yarn-nodemanager.service\u00a0 fi}main\n```\n## \u9a57\u8b49 GPU \u9a45\u52d5\u7a0b\u5e8f\u5b89\u88dd\n\u5728 Dataproc \u7bc0\u9ede\u4e0a\u5b8c\u6210 GPU \u9a45\u52d5\u7a0b\u5e8f\u7684\u5b89\u88dd\u4e4b\u5f8c\uff0c\u60a8\u53ef\u4ee5\u9a57\u8b49\u8a72\u9a45\u52d5\u7a0b\u5e8f\u662f\u5426\u6b63\u5e38\u904b\u884c\u3002\u901a\u904e SSH \u9023\u63a5\u5230 Dataproc \u96c6\u7fa3\u7684\u4e3b\u7bc0\u9ede\uff0c\u7136\u5f8c\u904b\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a\n```\nnvidia-smi\n```\n\u5982\u679c\u9a45\u52d5\u7a0b\u5e8f\u6b63\u5e38\u904b\u884c\uff0c\u8f38\u51fa\u5c07\u986f\u793a\u9a45\u52d5\u7a0b\u5e8f\u7248\u672c\u548c GPU \u7d71\u8a08\u4fe1\u606f\uff08\u8acb\u53c3\u95b1 [\u9a57\u8b49 GPU \u9a45\u52d5\u7a0b\u5e8f\u5b89\u88dd](https://cloud.google.com/compute/docs/gpus/install-drivers-gpu?hl=zh-cn#verify-driver-install) \uff09\u3002\n**\u6ce8\u610f** \uff1a\u5728 Linux [\u7121\u4eba\u8518\u8207\u5347\u7d1a](https://wiki.debian.org/UnattendedUpgrades) \u5f8c\u91cd\u5553\u865b\u64ec\u6a5f\u5f8c\uff0c\u9a45\u52d5\u7a0b\u5e8f\u53ef\u80fd\u7121\u6cd5\u6b63\u5e38\u5de5\u4f5c\u3002\u53ef\u80fd\u7684\u89e3\u6c7a\u65b9\u6848\uff1a\u60a8\u53ef\u4ee5\u901a\u904e\u4fee\u6539\u7121\u4eba\u503c\u5b88\u7684\u5347\u7d1a\u670d\u52d9\u914d\u7f6e\u4f86\u505c\u7528\u7121\u4eba\u503c\u5b88\u7684\u5347\u7d1a\u6216\u6392\u9664\u5167\u6838\u66f4\u65b0\u3002\n## Spark \u914d\u7f6e\n\u5411 Spark [\u63d0\u4ea4\u4f5c\u696d](https://cloud.google.com/dataproc/docs/guides/submit-job?hl=zh-cn) \u6642\uff0c\u60a8\u53ef\u4ee5\u5c07 `spark.executorEnv` Spark \u914d\u7f6e\u7684 [\u904b\u884c\u6642\u74b0\u5883\u5c6c\u6027](https://spark.apache.org/docs/latest/configuration.html#runtime-environment) \u5c6c\u6027\u8207 `LD_PRELOAD` \u74b0\u5883\u8b8a\u91cf\u7d50\u5408\u4f7f\u7528\uff0c\u4ee5\u9810\u52a0\u8f09\u6240\u9700\u7684\u5eab\u3002\n\u793a\u4f8b\uff1a\n```\ngcloud dataproc jobs submit spark --cluster=CLUSTER_NAME \\\n\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0--class=org.apache.spark.examples.SparkPi \\\n\u00a0\u00a0--jars=file:///usr/lib/spark/examples/jars/spark-examples.jar \\\n\u00a0\u00a0--properties=spark.executorEnv.LD_PRELOAD=libnvblas.so,spark.task.resource.gpu.amount=1,spark.executor.resource.gpu.amount=1,spark.executor.resource.gpu.discoveryScript=/usr/lib/spark/scripts/gpu/getGpusResources.sh\n```\n## GPU \u4f5c\u696d\u793a\u4f8b\n\u60a8\u53ef\u4ee5\u901a\u904e\u904b\u884c\u4ee5\u4e0b\u4efb\u4f55\u4f5c\u696d\u5728 Dataproc \u4e0a\u6e2c\u8a66 GPU\uff0c\u9019\u4e9b\u4f5c\u696d\u5728\u4f7f\u7528 GPU \u904b\u884c\u6642\u6703\u53d7\u76ca\uff1a\n- \u904b\u884c\u5176\u4e2d\u4e00\u500b [Spark ML \u793a\u4f8b](https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/classification/MultilayerPerceptronClassifier.scala) \u3002\n- \u4f7f\u7528`spark-shell`\u904b\u884c\u4ee5\u4e0b\u793a\u4f8b\u4ee5\u904b\u884c\u77e9\u9663\u8a08\u7b97\uff1a\n```\nimport org.apache.spark.mllib.linalg._\nimport org.apache.spark.mllib.linalg.distributed._\nimport java.util.Random\ndef makeRandomSquareBlockMatrix(rowsPerBlock: Int, nBlocks: Int): BlockMatrix = {\n val range = sc.parallelize(1 to nBlocks)\n val indices = range.cartesian(range)\n return new BlockMatrix(\n  indices.map(\n   ij => (ij, Matrices.rand(rowsPerBlock, rowsPerBlock, new Random()))),\n  rowsPerBlock, rowsPerBlock, 0, 0)\n}\nval N = 1024 * 4\nval n = 2\nval mat1 = makeRandomSquareBlockMatrix(N, n)\nval mat2 = makeRandomSquareBlockMatrix(N, n)\nval mat3 = mat1.multiply(mat2)\nmat3.blocks.persist.count\nprintln(\"Processing complete!\")\n```\n## \u5f8c\u7e8c\u6b65\u9a5f\n- [Compute Engine\u2192\u5c07 GPU \u639b\u63a5\u5230\u5be6\u4f8b](https://cloud.google.com/compute/docs/gpus/add-gpus?hl=zh-cn) \n- [Compute Engine\u2192Compute Engine \u4e0a\u7684 GPU](https://cloud.google.com/compute/docs/gpus?hl=zh-cn)", "guide": "Dataproc"}