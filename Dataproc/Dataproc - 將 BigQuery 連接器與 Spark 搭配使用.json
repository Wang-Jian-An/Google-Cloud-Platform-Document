{"title": "Dataproc - \u5c07 BigQuery \u9023\u63a5\u5668\u8207 Spark \u642d\u914d\u4f7f\u7528", "url": "https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-spark-example?hl=zh-cn", "abstract": "# Dataproc - \u5c07 BigQuery \u9023\u63a5\u5668\u8207 Spark \u642d\u914d\u4f7f\u7528\n\u60a8\u53ef\u4ee5\u5c07 [spark-bigquery-connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) \u8207 [Apache Spark](https://spark.apache.org) \u642d\u914d\u4f7f\u7528\uff0c\u4ee5\u5f9e [BigQuery](https://cloud.google.com/bigquery?hl=zh-cn) \u4e2d\u8b80\u53d6\u6578\u64da\u4ee5\u53ca\u5c07\u6578\u64da\u5beb\u5165\u5176\u4e2d\u3002\u672c\u6559\u7a0b\u63d0\u4f9b\u77ad\u5982\u4f55\u5728 Spark \u61c9\u7528\u4e2d\u4f7f\u7528 spark-bigquery-connector \u7684\u793a\u4f8b\u4ee3\u78bc\u3002 \u5982\u9700\u77ad\u89e3\u5982\u4f55\u5275\u5efa\u96c6\u7fa3\uff0c\u8acb\u53c3\u95b1 [Dataproc \u5feb\u901f\u5165\u9580](https://cloud.google.com/dataproc/docs/quickstarts?hl=zh-cn) \u3002\n\u5f9e BigQuery \u8b80\u53d6\u6578\u64da\u6642\uff0cspark-bigquery-connector \u5229\u7528\u4e86 [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage?hl=zh-cn) \u3002\n", "content": "## \u4f7f\u9023\u63a5\u5668\u53ef\u4f9b\u60a8\u7684\u61c9\u7528\u4f7f\u7528\n\u60a8\u53ef\u4ee5\u901a\u904e\u4ee5\u4e0b\u4efb\u4e00\u65b9\u5f0f\u5c07 spark-bigquery-connector \u63d0\u4f9b\u7d66\u60a8\u7684\u61c9\u7528\uff1a\n- \u5728\u5275\u5efa\u96c6\u7fa3\u6642\uff0c\u4f7f\u7528 [Dataproc \u9023\u63a5\u5668\u521d\u59cb\u5316\u64cd\u4f5c](https://github.com/GoogleCloudDataproc/initialization-actions/tree/master/connectors) \u5728\u6bcf\u500b\u7bc0\u9ede\u7684 Spark jars \u76ee\u9304\u4e2d\u5b89\u88dd spark-bigquery-connector\u3002\n- \u63d0\u4ea4\u4f5c\u696d\u6642\u63d0\u4f9b\u9023\u63a5\u5668 URI\uff1a- **Google Cloud \u63a7\u5236\u6aaf** \uff1a\u4f7f\u7528 Dataproc [\u63d0\u4ea4\u4f5c\u696d](https://console.cloud.google.com/dataproc/jobs/jobsSubmit?hl=zh-cn) \u9801\u9762\u4e0a\u7684 Spark \u4f5c\u696d`Jars files`\u9805\u3002\n- **gcloud CLI** \uff1a\u4f7f\u7528 [gcloud dataproc jobs submit spark --jars \u6a19\u8a8c](https://cloud.google.com/sdk/gcloud/reference/dataproc/jobs/submit/spark?hl=zh-cn#--jars) \u3002\n- **Dataproc API** \uff1a\u4f7f\u7528 [SparkJob.jarFileUris \u5b57\u6bb5](https://cloud.google.com/dataproc/docs/reference/rest/v1/SparkJob?hl=zh-cn#FIELDS.jar_file_uris) \u3002\n- \u5c07\u8a72 jar \u4f5c\u7232\u4f9d\u8cf4\u9805\u6dfb\u52a0\u5230 Scala \u6216 Java Spark \u61c9\u7528\u4e2d\uff08\u8acb\u53c3\u95b1 [\u91dd\u5c0d\u9023\u63a5\u5668\u7de8\u8b6f](https://github.com/GoogleCloudDataproc/spark-bigquery-connector#compiling-against-the-connector) \uff09\u3002\n**\u6ce8\u610f** \uff1a\u5982\u679c\u9023\u63a5\u5668\u5728\u904b\u884c\u6642\u4e0d\u53ef\u7528\uff0c\u7cfb\u7d71\u6703\u62cb\u51fa `ClassNotFoundException` \u3002\n### \u5982\u4f55\u6307\u5b9a\u9023\u63a5\u5668 jar URI\nGitHub [GoogleCloudDataproc/spark-bigquery-connector \u4ee3\u78bc\u5eab](https://github.com/GoogleCloudDataproc/spark-bigquery-connector/releases) \u4e2d\u5217\u51fa\u4e86 Spark-BigQuery \u9023\u63a5\u5668\u7248\u672c\u3002\n\u66ff\u63db\u4ee5\u4e0b URI \u5b57\u7b26\u4e32\u4e2d\u7684 Scala \u548c\u9023\u63a5\u5668\u7248\u672c\u4fe1\u606f\uff0c\u4ee5\u6307\u5b9a\u9023\u63a5\u5668 jar\uff1a\n```\ngs://spark-lib/bigquery/spark-bigquery-with-dependencies_SCALA_VERSION-CONNECTOR_VERSION.jar\n```- \u5c07 Scala `2.12` \u8207 Dataproc \u6620\u50cf\u7248\u672c `1.5+` \u642d\u914d\u4f7f\u7528```\ngs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-CONNECTOR_VERSION.jar\n```gcloud CLI \u793a\u4f8b\uff1a```\ngcloud dataproc jobs submit spark \\\n\u00a0\u00a0\u00a0\u00a0--jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.23.2.jar \\\n\u00a0\u00a0\u00a0\u00a0-- job-args\n```\n- \u5c07 Scala `2.11` \u8207 Dataproc \u6620\u50cf\u7248\u672c `1.4` \u53ca\u66f4\u4f4e\u7248\u672c\u642d\u914d\u4f7f\u7528\uff1a```\ngs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.11-CONNECTOR_VERSION.jar\n```gcloud CLI \u793a\u4f8b\uff1a```\ngcloud dataproc jobs submit spark \\\n\u00a0\u00a0\u00a0\u00a0--jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.11-0.23.2.jar \\\n\u00a0\u00a0\u00a0\u00a0-- job-args\n```\n\u5728\u975e\u751f\u7522\u74b0\u5883\u4e0b\uff0c\u60a8\u9084\u53ef\u4ee5\u6307\u5411`latest`jar\uff0c\u5982\u4e0b\u6240\u793a\uff1a- Dataproc \u6620\u50cf\u7248\u672c`1.5+`\uff1a`--jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar`\n- Dataproc \u6620\u50cf\u7248\u672c 1.4 \u53ca\u66f4\u65e9\u7248\u672c\uff1a`--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar`## \u8a08\u7b97\u8cbb\u7528\u5728\u672c\u6587\u6a94\u4e2d\uff0c\u60a8\u5c07\u4f7f\u7528 Google Cloud \u7684\u4ee5\u4e0b\u6536\u8cbb\u7d44\u4ef6\uff1a\n- Dataproc\n- BigQuery\n- Cloud Storage\n\u60a8\u53ef\u4f7f\u7528 [\u50f9\u683c\u8a08\u7b97\u5668](https://cloud.google.com/products/calculator?hl=zh-cn) \u6839\u64da\u60a8\u7684\u9810\u8a08\u4f7f\u7528\u60c5\u6cc1\u4f86\u4f30\u7b97\u8cbb\u7528\u3002\n## \u5f9e BigQuery \u8b80\u53d6\u548c\u5beb\u5165\u6578\u64da\n\u6b64\u793a\u4f8b\u5c55\u793a\u5982\u4f55\u5c07 [BigQuery](https://console.cloud.google.com/bigquery?hl=zh-cn) \u4e2d\u7684\u6578\u64da\u8b80\u53d6\u5230 Spark DataFrame \u4e2d\uff0c\u4ee5\u4f7f\u7528 [\u6a19\u6e96\u6578\u64da\u6e90 API](https://spark.apache.org/docs/latest/sql-data-sources.html) \u57f7\u884c\u5b57\u6578\u7d71\u8a08\u64cd\u4f5c\u3002\n\u9023\u63a5\u5668\u9996\u5148\u5c07\u6240\u6709\u6578\u64da\u7de9\u885d\u5230\u4e00\u500b Cloud Storage \u81e8\u6642\u8868\u4e2d\uff0c\u5f9e\u800c\u5c07\u6578\u64da\u5beb\u5165 BigQuery\u3002\u7136\u5f8c\uff0c\u5b83\u6703\u901a\u904e\u4e00\u6b21\u64cd\u4f5c\u5c07\u6240\u6709\u6578\u64da\u5f9e BigQuery \u8907\u88fd\u5230 BigQuery\u3002\u5728 BigQuery \u52a0\u8f09\u64cd\u4f5c\u6210\u529f\u4e26\u4e14\u7576 Spark \u61c9\u7528\u7d42\u6b62\u6642\u518d\u6b21\u6210\u529f\u4e4b\u5f8c\uff0c\u9023\u63a5\u5668\u4fbf\u6703\u5617\u8a66\u522a\u9664\u81e8\u6642\u6587\u4ef6\u3002\u5982\u679c\u4f5c\u696d\u5931\u6557\uff0c\u8acb\u79fb\u9664\u4efb\u4f55\u5269\u9918\u7684\u81e8\u6642 Cloud Storage \u6587\u4ef6\u3002\u81e8\u6642 BigQuery \u6587\u4ef6\u901a\u5e38\u4f4d\u65bc `gs://[bucket]/.spark-bigquery-[jobid]-[UUID]` \u3002\n## \u914d\u7f6e\u7d50\u7b97\u529f\u80fd\n\u9ed8\u8a8d\u60c5\u6cc1\u4e0b\uff0c\u7cfb\u7d71\u6703\u5411\u8207\u6191\u64da\u6216\u670d\u52d9\u5e33\u865f\u95dc\u806f\u7684\u9805\u76ee\u6536\u53d6 API \u4f7f\u7528\u8cbb\u3002\u8981\u5c0d\u5176\u4ed6\u9805\u76ee\u8a08\u8cbb\uff0c\u8acb\u8a2d\u7f6e\u4ee5\u4e0b\u914d\u7f6e\uff1a `spark.conf.set(\"parentProject\", \"<BILLED-GCP-PROJECT>\")` \u3002\n\u9084\u53ef\u4ee5\u5c07\u5176\u6dfb\u52a0\u5230\u8b80/\u5beb\u64cd\u4f5c\uff0c\u5982\u4e0b\u6240\u793a\uff1a `.option(\"parentProject\", \"<BILLED-GCP-PROJECT>\")` \u3002\n## \u904b\u884c\u4ee3\u78bc\n\u5728\u904b\u884c\u6b64\u793a\u4f8b\u4e4b\u524d\uff0c\u8acb\u5148\u5275\u5efa\u540d\u7232\u201cwordcount_dataset\u201d\u7684\u6578\u64da\u96c6\uff0c\u6216\u5c07\u4ee3\u78bc\u4e2d\u7684\u8f38\u51fa\u6578\u64da\u96c6\u66f4\u6539\u7232 Google Cloud \u9805\u76ee\u4e2d\u7684\u73fe\u6709 BigQuery \u6578\u64da\u96c6\u3002\n\u4f7f\u7528 [bq](https://cloud.google.com/bigquery/bq-command-line-tool?hl=zh-cn) \u547d\u4ee4\u5275\u5efa `wordcount_dataset` \uff1a\n```\nbq mk wordcount_dataset\n```\n\u4f7f\u7528 [gsutil](https://cloud.google.com/storage/docs/gsutil?hl=zh-cn) \u547d\u4ee4\u5275\u5efa Cloud Storage \u5b58\u5132\u6876\uff0c\u8a72\u5b58\u5132\u5206\u5340\u5c07\u7528\u65bc\u5c0e\u51fa\u5230 BigQuery\uff1a\n```\ngsutil mb gs://[bucket]\n```\n- \u6aa2\u67e5\u4ee3\u78bc\u4e26\u5c07\u4f54\u4f4d\u7b26\u66ff\u63db\u7232\u60a8\u4e4b\u524d\u5275\u5efa\u7684 Cloud Storage \u5b58\u5132\u6876\u3002 [](None) ```\n/*\u00a0* Remove comment if you are not running in spark-shell.\u00a0*import org.apache.spark.sql.SparkSessionval spark = SparkSession.builder()\u00a0 .appName(\"spark-bigquery-demo\")\u00a0 .getOrCreate()*/// Use the Cloud Storage bucket for temporary BigQuery export data used// by the connector.val bucket = \"[bucket]\"spark.conf.set(\"temporaryGcsBucket\", bucket)// Load data in from BigQuery. See// https://github.com/GoogleCloudDataproc/spark-bigquery-connector/tree/0.17.3#properties// for option information.val wordsDF =\u00a0 (spark.read.format(\"bigquery\")\u00a0 .option(\"table\",\"bigquery-public-data:samples.shakespeare\")\u00a0 .load()\u00a0 .cache())wordsDF.createOrReplaceTempView(\"words\")// Perform word count.val wordCountDF = spark.sql(\u00a0 \"SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word\")wordCountDF.show()wordCountDF.printSchema()// Saving the data to BigQuery.(wordCountDF.write.format(\"bigquery\")\u00a0 .option(\"table\",\"wordcount_dataset.wordcount_output\")\u00a0 .save())\n```\n- \u5728\u96c6\u7fa3\u4e0a\u904b\u884c\u4ee3\u78bc\n- \u4f7f\u7528 SSH \u9023\u63a5\u5230 Dataproc \u96c6\u7fa3\u4e3b\u670d\u52d9\u5668\u7bc0\u9ede\n- \u8f49\u5230 Google Cloud \u63a7\u5236\u6aaf\u4e2d\u7684 [Dataproc \u96c6\u7fa3](https://console.cloud.google.com/dataproc/clusters?hl=zh-cn) \u9801\u9762\uff0c\u7136\u5f8c\u9ede\u64ca\u96c6\u7fa3\u7684\u540d\u7a31\n- \u5728 **>\u96c6\u7fa3\u8a73\u60c5** \u9801\u9762\u4e0a\uff0c\u9078\u64c7\u201c\u865b\u64ec\u6a5f\u5be6\u4f8b\u201d\u6a19\u7c64\u9801\u3002\u7136\u5f8c\uff0c\u9ede\u64ca\u96c6\u7fa3\u4e3b\u670d\u52d9\u5668\u7bc0\u9ede\u540d\u7a31\u53f3\u5074\u7684`SSH`\u7cfb\u7d71\u6703\u5728\u4e3b\u7bc0\u9ede\u4e0a\u7684\u4e3b\u76ee\u9304\u4e2d\u6253\u958b\u4e00\u500b\u700f\u89bd\u5668\u7a97\u53e3```\n Connected, host fingerprint: ssh-rsa 2048 ...\n ...\n user@clusterName-m:~$\n \n```- \u4f7f\u7528\u9810\u88dd\u7684`vi`\u3001`vim`\u6216`nano`\u6587\u672c\u7de8\u8f2f\u5668\u5275\u5efa`wordcount.scala`\uff0c\u7136\u5f8c\u7c98\u8cbc [Scala \u4ee3\u78bc\u5217\u8868](#scala-code-listing) \u4e2d\u7684 Scala \u4ee3\u78bc```\nnano wordcount.scala\n \n```\n- \u5553\u52d5`spark-shell`REPL\u3002```\n$ spark-shell --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n...\nUsing Scala version ...\nType in expressions to have them evaluated.\nType :help for more information.\n...\nSpark context available as sc.\n...\nSQL context available as sqlContext.\nscala>\n```\n- \u904b\u884c wordcount.scala \u4e26\u4f7f\u7528`:load wordcount.scala`\u547d\u4ee4\u5275\u5efa BigQuery`wordcount_output`\u8868\u3002\u8f38\u51fa\u5217\u8868\u5c07\u986f\u793a\u4f86\u81ea wordcount \u8f38\u51fa\u7684 20 \u884c\u5167\u5bb9\u3002```\n:load wordcount.scala\n...\n+---------+----------+\n|  word|word_count|\n+---------+----------+\n|  XVII|   2|\n| spoil|  28|\n| Drink|   7|\n|forgetful|   5|\n| Cannot|  46|\n| cures|  10|\n| harder|  13|\n| tresses|   3|\n|  few|  62|\n| steel'd|   5|\n| tripping|   7|\n| travel|  35|\n| ransom|  55|\n|  hope|  366|\n|  By|  816|\n|  some|  1169|\n| those|  508|\n| still|  567|\n|  art|  893|\n| feign|  10|\n+---------+----------+\nonly showing top 20 rows\nroot\n |-- word: string (nullable = false)\n |-- word_count: long (nullable = true)\n```\u5982\u9700\u9810\u89bd\u8f38\u51fa\u8868\uff0c\u8acb\u6253\u958b [BigQuery](https://console.cloud.google.com/bigquery?hl=zh-cn) \u9801\u9762\uff0c\u9078\u64c7`wordcount_output`\u8868\uff0c\u7136\u5f8c\u9ede\u64ca **\u9810\u89bd** \u3002- \u6aa2\u67e5\u4ee3\u78bc\u4e26\u5c07\u4f54\u4f4d\u7b26\u66ff\u63db\u7232\u60a8\u4e4b\u524d\u5275\u5efa\u7684 Cloud Storage \u5b58\u5132\u6876\u3002 [](None) ```\n#!/usr/bin/env python\"\"\"BigQuery I/O PySpark example.\"\"\"from pyspark.sql import SparkSessionspark = SparkSession \\\u00a0 .builder \\\u00a0 .master('yarn') \\\u00a0 .appName('spark-bigquery-demo') \\\u00a0 .getOrCreate()# Use the Cloud Storage bucket for temporary BigQuery export data used# by the connector.bucket = \"[bucket]\"spark.conf.set('temporaryGcsBucket', bucket)# Load data from BigQuery.words = spark.read.format('bigquery') \\\u00a0 .option('table', 'bigquery-public-data:samples.shakespeare') \\\u00a0 .load()words.createOrReplaceTempView('words')# Perform word count.word_count = spark.sql(\u00a0 \u00a0 'SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word')word_count.show()word_count.printSchema()# Save the data to BigQueryword_count.write.format('bigquery') \\\u00a0 .option('table', 'wordcount_dataset.wordcount_output') \\\u00a0 .save()\n```\n- \u5728\u96c6\u7fa3\u4e0a\u904b\u884c\u4ee3\u78bc **\u4f7f\u7528 Dataproc \u63d0\u4ea4 PySpark \u4ee3\u78bc** \uff1a\u60a8\u53ef\u4ee5\u5c07 PySpark \u6587\u4ef6\u76f4\u63a5\u63d0\u4ea4\u5230\u60a8\u7684\u96c6\u7fa3\uff0c\u800c\u7121\u9700\u5f9e\u96c6\u7fa3\u4e3b\u670d\u52d9\u5668\u5be6\u4f8b\u624b\u52d5\u904b\u884c PySpark \u4ee3\u78bc\uff08\u8acb\u53c3\u95b1 [Dataproc \u5feb\u901f\u5165\u9580](https://cloud.google.com/dataproc/docs/quickstarts?hl=zh-cn) \uff09\u3002\u4f7f\u7528 Google Cloud CLI \u7684\u6b65\u9a5f\u5982\u4e0b\uff1a\n- \u901a\u904e\u8907\u88fd [PySpark \u4ee3\u78bc\u5217\u8868](#python-code-listing) \u4e2d\u7684 PySpark \u4ee3\u78bc\uff0c\u5728\u6587\u672c\u7de8\u8f2f\u5668\u4e2d\u672c\u5730\u5275\u5efa`wordcount.py`\n- \u901a\u904e\u4f7f\u7528`gcloud dataproc jobs submit`\u547d\u4ee4\u5c07\u4f5c\u696d\u63d0\u4ea4\u5230\u96c6\u7fa3\u4f86\u904b\u884c PySpark \u4ee3\u78bc\uff1a```\ngcloud dataproc jobs submit pyspark wordcount.py \\\n\u00a0\u00a0\u00a0\u00a0--cluster=cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n```\n- \u4f7f\u7528 SSH \u9023\u63a5\u5230 Dataproc \u96c6\u7fa3\u4e3b\u670d\u52d9\u5668\u7bc0\u9ede\n- \u8f49\u5230 Google Cloud \u63a7\u5236\u6aaf\u4e2d\u7684 [Dataproc \u96c6\u7fa3](https://console.cloud.google.com/dataproc/clusters?hl=zh-cn) \u9801\u9762\uff0c\u7136\u5f8c\u9ede\u64ca\u96c6\u7fa3\u7684\u540d\u7a31\n- \u5728 **\u96c6\u7fa3\u8a73\u60c5** \u9801\u9762\u4e0a\uff0c\u9078\u64c7\u201c\u865b\u64ec\u6a5f\u5be6\u4f8b\u201d\u6a19\u7c64\u9801\u3002\u7136\u5f8c\uff0c\u9ede\u64ca\u96c6\u7fa3\u4e3b\u670d\u52d9\u5668\u7bc0\u9ede\u540d\u7a31\u53f3\u5074\u7684`SSH`\u7cfb\u7d71\u6703\u5728\u4e3b\u7bc0\u9ede\u4e0a\u7684\u4e3b\u76ee\u9304\u4e2d\u6253\u958b\u4e00\u500b\u700f\u89bd\u5668\u7a97\u53e3```\n Connected, host fingerprint: ssh-rsa 2048 ...\n ...\n user@clusterName-m:~$\n \n```- \u4f7f\u7528\u9810\u5b89\u88dd\u7684`vi`\u3001`vim`\u6216`nano`\u6587\u672c\u7de8\u8f2f\u5668\u5275\u5efa`wordcount.py`\uff0c\u7136\u5f8c\u7c98\u8cbc [PySpark \u4ee3\u78bc\u5217\u8868](#python-code-listing) \u4e2d\u7684 PySpark \u4ee3\u78bc```\nnano wordcount.py\n```\n- \u4f7f\u7528`spark-submit`\u904b\u884c wordcount \u4ee5\u5275\u5efa BigQuery`wordcount_output`\u8868\u3002\u8f38\u51fa\u5217\u8868\u5c07\u986f\u793a\u4f86\u81ea wordcount \u8f38\u51fa\u7684 20 \u884c\u5167\u5bb9\u3002```\nspark-submit --jars gs://spark-lib/bigquery/spark-bigquery-latest.jar wordcount.py\n...\n+---------+----------+\n|  word|word_count|\n+---------+----------+\n|  XVII|   2|\n| spoil|  28|\n| Drink|   7|\n|forgetful|   5|\n| Cannot|  46|\n| cures|  10|\n| harder|  13|\n| tresses|   3|\n|  few|  62|\n| steel'd|   5|\n| tripping|   7|\n| travel|  35|\n| ransom|  55|\n|  hope|  366|\n|  By|  816|\n|  some|  1169|\n| those|  508|\n| still|  567|\n|  art|  893|\n| feign|  10|\n+---------+----------+\nonly showing top 20 rows\nroot\n |-- word: string (nullable = false)\n |-- word_count: long (nullable = true)\n```\u5982\u9700\u9810\u89bd\u8f38\u51fa\u8868\uff0c\u8acb\u6253\u958b [BigQuery](https://console.cloud.google.com/bigquery?hl=zh-cn) \u9801\u9762\uff0c\u9078\u64c7`wordcount_output`\u8868\uff0c\u7136\u5f8c\u9ede\u64ca **\u9810\u89bd** \u3002## \u5982\u9700\u6df1\u5165\u77ad\u89e3\n- [BigQuery Storage \u548c Spark SQL-Python](https://github.com/tfayyaz/cloud-dataproc/blob/master/notebooks/python/1.2.%20BigQuery%20Storage%20%26%20Spark%20SQL%20-%20Python.ipynb) \n- [\u7232\u5916\u90e8\u6578\u64da\u6e90\u5275\u5efa\u8868\u5b9a\u7fa9\u6587\u4ef6](https://cloud.google.com/bigquery/external-table-definition?hl=zh-cn) \n- [\u67e5\u8a62\u5916\u90e8\u5206\u5340\u6578\u64da](https://cloud.google.com/bigquery/docs/hive-partitioned-queries-gcs?hl=zh-cn) \n- [Spark \u4f5c\u696d\u8abf\u7bc0\u63d0\u793a](https://cloud.google.com/dataproc/docs/support/spark-job-tuning?hl=zh-cn)", "guide": "Dataproc"}