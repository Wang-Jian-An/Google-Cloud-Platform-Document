{"title": "Dataproc - Supported machine types", "url": "https://cloud.google.com/dataproc/docs/concepts/compute/supported-machine-types", "abstract": "# Dataproc - Supported machine types\nDataproc clusters are built on [Compute Engine](/compute) instances. [Machine types](/compute/docs/machine-types) define the virtualized hardware resources available to an instance. Compute Engine offers both [predefinedmachine types](/compute/docs/machine-types#predefined_machine_types) and [custom machine types](/compute/docs/machine-types#custom_machine_types) . Dataproc clusters can use both predefined and custom types for both master and/or worker nodes.\nDataproc clusters support the following Compute Engine predefined machine types (machine type availability varies by [region](/compute/docs/regions-zones#available) ):\n- [General purpose machine types](/compute/docs/machine-types#general_purpose) , which include N1, N2, N2D, and E2 machine types (Dataproc also supports N1, N2, N2D, and E2 [custom machine types](#custom_machine_types) ). **Limitations:** - the n1-standard-1 machine type is **not supported** for 2.0+ images (the n1-standard-1 machine type is **not recommended** for pre-2.0 images\u2014instead, use a machine type with higher memory.\n- Shared-core machine types are **not supported** , which include the following unsupported machine types:- E2: e2-micro, e2-small, and e2-medium shared-core machine types, and\n- N1: f1-micro and g1-small shared-core machine types.\n- [Compute-optimized machine types](/compute/docs/machine-types#compute-optimized_machine_type_family) , which include [C2](/compute/docs/compute-optimized-machines#c2_machine_types) and [C2D](/compute/docs/compute-optimized-machines#c2d_machine_types) machine types.\n- [Memory-optimized machine types](/compute/docs/machine-types#memory-optimized_machine_type_family) , which include M1 and M2 machine types.\n- [ARM machine types](#arm_machine_types) , which include [T2A](/compute/docs/instances/arm-on-compute#tau_t2a_machine_series) machine types.\nFor help in choosing a machine type, see [Optimize Dataproc costs using VM machine type](/blog/products/data-analytics/optimize-dataproc-costs-using-vm-machine-type) .\n", "content": "## Custom machine types\nDataproc supports **N1 series**  [custom machine types](/compute/docs/instances/creating-instance-with-custom-machine-type) .\nCustom machine types are ideal for the following workloads:\n- Workloads that are not a good fit for the predefined machine types.\n- Workloads that require more processing power or more memory, but don't need all of the upgrades that are provided by the next machine type level.\nFor example, if you have a workload that needs more processing power than that provided by an `n1-standard-4` instance, but the next step up, an `n1-standard-8` instance, provides too much capacity. With custom machine types, you can create Dataproc clusters with master and/or worker nodes in the middle range, with 6 virtual CPUs and 25 GB of memory.\n### Specify a custom machine type\nCustom machine types use a special `machine type` specification and are subject to [limitations](/compute/docs/instances/creating-instance-with-custom-machine-type#specifications) . For example, the custom machine type specification for a custom VM with 6 virtual CPUs and 22.5 GB of memory is `custom-6-23040` .\nThe numbers in the machine type specification correspond to the number of virtual CPUs (vCPUs)in the machine ( `6` ) and the amount of memory ( `23040` ). The amount of memory is calculated by multiplying the amount of memory in gigabytes by `1024` (see [Expressing memory in GB or MB](/compute/docs/instances/creating-instance-with-custom-machine-type#memory_units) ). In this example, 22.5 (GB) is multiplied by 1024: `22.5 * 1024 = 23040` .\n**Note:** Dataproc requires machine types to have a minimum of 3.5GB (3584) memory.\nYou use the above syntax to specify the custom machine type with your clusters. You can set the machine type for either master or worker nodes or both when you create a cluster. If you set both, the master node can use a custom machine type that is different from the custom machine type used by workers. The machine type used by any secondary workers follow the settings for primary workers and cannot be separately set (see [Secondary workers - preemptible and non-preemptible VMs](/dataproc/docs/concepts/compute/secondary-vms) ).\nSee [Create a Dataproc cluster with custom machine type with extended memory](#create_a_cluster_with_custom_machine_type_with_extended_memory) to increase CPU memory above the standard limits.\n### Custom machine type pricing\n[Custom machine type pricing](/compute/pricing#custommachinetypepricing) is based on the resources used in a custom machine. [Dataproc pricing](/dataproc/pricing) is added to the cost of compute resources, and is based on the total number of virtual CPUs (vCPUs) used in a cluster.\n### Create a Dataproc cluster with a specified machine type\nFrom the **Configure nodes** panel of the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console, select machine family, series and type for the cluster's master and worker nodes.Run the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command with the following flags to create a Dataproc cluster with master and/or worker machine types:- The`--master-machine-type` ``flag allows you to set the predefined or custom machine type used by the master VM instance in your cluster (or master instances if you create a [HA cluster](/dataproc/docs/concepts/configuring-clusters/high-availability) )\n- The`--worker-machine-type` ``flag allows you to set the predefined or custom machine type used by the worker VM instances in your cluster\n **Example** :\n```\ngcloud dataproc clusters create test-cluster /\n\u00a0\u00a0\u00a0\u00a0--master-machine-type custom-6-23040 /\n\u00a0\u00a0\u00a0\u00a0--worker-machine-type custom-6-23040 /\n\u00a0\u00a0\u00a0\u00a0other args\n```\nAn easy way to examine and construct a`gcloud cluster create`command is to open the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console, fill in the applicable fields on the page, then click **Equivalent command line** at the bottom of the left pane of the Create a cluster page to view, copy, and paste the completed`gcloud`command.\nOnce the Dataproc cluster starts, cluster details are displayed in the terminal window. The following is a partial sample listing of cluster properties displayed in the terminal window:\n```\n...\nproperties:\n distcp:mapreduce.map.java.opts: -Xmx1638m\n distcp:mapreduce.map.memory.mb: '2048'\n distcp:mapreduce.reduce.java.opts: -Xmx4915m\n distcp:mapreduce.reduce.memory.mb: '6144'\n mapred:mapreduce.map.cpu.vcores: '1'\n mapred:mapreduce.map.java.opts: -Xmx1638m\n...\n```To create a cluster with custom machine types, set the `machineTypeUri` in the `masterConfig` and/or `workerConfig` [InstanceGroupConfig](/dataproc/docs/reference/rest/v1/ClusterConfig#InstanceGroupConfig.FIELDS.machine_type_uri) in the [cluster.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) API request.\n **Example** :\n```\nPOST /v1/projects/my-project-id/regions/is-central1/clusters/\n{\n \"projectId\": \"my-project-id\",\n \"clusterName\": \"test-cluster\",\n \"config\": {\n \"configBucket\": \"\",\n \"gceClusterConfig\": {\n  \"subnetworkUri\": \"default\",\n  \"zoneUri\": \"us-central1-a\"\n },\n \"masterConfig\": {\n  \"numInstances\": 1,\n  \"machineTypeUri\": \"n1-highmem-4\",\n  \"diskConfig\": {\n  \"bootDiskSizeGb\": 500,\n  \"numLocalSsds\": 0\n  }\n },\n \"workerConfig\": {\n  \"numInstances\": 2,\n  \"machineTypeUri\": \"n1-highmem-4\",\n  \"diskConfig\": {\n  \"bootDiskSizeGb\": 500,\n  \"numLocalSsds\": 0\n  }\n }\n }\n}\n```\nAn easy way to examine and construct the JSON body of a Dataproc API clusters create request is to open the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console, fill in the applicable fields on the page, then click **Equivalent REST** at the bottom of the left pane of the Create a cluster page to view, copy, and paste the POST request with the completed JSON request body.\n### Create a Dataproc cluster with custom machine type with extended memory\nDataproc supports custom machine types with [extended memory](/compute/docs/instances/creating-instance-with-custom-machine-type#extendedmemory) beyond the [6.5GB per vCPU limit](/compute/docs/instances/creating-instance-with-custom-machine-type#create) (see [Extended Memory Pricing](/compute/pricing#extendedmemory) ).\nAlthough there is no limit on the amount of extended memory per CPU, there is a limit on the total [extended memory per VM instance](/compute/docs/instances/creating-instance-with-custom-machine-type?hl=en_US&_ga=2.43164131.-736957322.1515206173#limitations) .\nClick **Extend memory** when customizing Machine type memory in the Master node and/or Worker nodes section from the **Configure nodes** panel on the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console.To create a cluster from the gcloud command line with custom CPUs with extended memory, add a `-ext` suffix to the `\u2011\u2011master-machine-type` and/or `\u2011\u2011worker-machine-type` flags.\n **Example** \nThe following gcloud command-line sample creates a Dataproc cluster with 1 CPU and 50 GB memory (50 * 1024 = 51200) in each node:\n```\ngcloud dataproc clusters create test-cluster /\n\u00a0\u00a0\u00a0\u00a0--master-machine-type custom-1-51200-ext /\n\u00a0\u00a0\u00a0\u00a0--worker-machine-type custom-1-51200-ext /\n\u00a0\u00a0\u00a0\u00a0other args\n```The following sample [](/dataproc/docs/reference/rest/v1/ClusterConfig#InstanceGroupConfig) JSON snippet from a Dataproc REST API [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request specifies 1 CPU and 50 GB memory (50 * 1024 = 51200) in each node:\n```\n...\n \"masterConfig\": {\n  \"numInstances\": 1,\n  \"machineTypeUri\": \"custom-1-51200-ext\",\n ...\n },\n \"workerConfig\": {\n  \"numInstances\": 2,\n  \"machineTypeUri\": \"custom-1-51200-ext\",\n  ...\n...\n```\n## ARM machine types\nDataproc supports creating a cluster with nodes that use [ARM machine types](/dataproc/docs/concepts/compute/supported-machine-types) , such as the [T2A machine type](/compute/docs/machine-resource#arm) .\nRequirements and limitations:\n- The Dataproc image must be compatible with ARM chipset (currently, only the Dataproc **2.1-ubuntu20-arm** image is compatible with the ARM CHIPSET). Note that this image does not support many optional and initialization-action components (see [2.1.x release versions](/dataproc/docs/concepts/versioning/dataproc-release-2.1) ).\n- Since one image must be specified for a cluster, the master, worker, and secondary-worker nodes must use an ARM machine type that is compatible with the selected Dataproc ARM image.\n- Dataproc features that are not compatible with ARM machine types are not available (for example, [local SSDs](/dataproc/docs/concepts/compute/dataproc-local-ssds) are not supported by T2A machine types).## Create a Dataproc cluster with an ARM machine type\nCurrently, the Google Cloud console does not support the creation of a Dataproc ARM machine type cluster.To create a Dataproc cluster that uses the ARM `t2a-standard-4` machine type, run the following `gcloud` command locally in a terminal window or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) .\n```\ngcloud dataproc clusters create cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--image-version=2.1-ubuntu20-arm \\\n\u00a0\u00a0\u00a0\u00a0--master-machine-type=t2a-standard-4 \\\n\u00a0\u00a0\u00a0\u00a0--worker-machine-type=t2a-standard-4\n```\nNotes:- : The [region](/compute/docs/regions-zones#available) where the cluster will be located.\n- ARM images are available starting with `2.1.18-ubuntu20-arm` .\n- See the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) reference documentation for information on additional command-line flags you can use to customize your cluster.\n- `*-arm images` support only the installed components and the following optional components listed on the [2.1.x release versions](/dataproc/docs/concepts/versioning/dataproc-release-2.1) page (the remaining 2.1 optional components and all initialization actions` listed on that page are unsupported):- Apache Hive WebHCat\n- Docker\n- Zookeeper (installed in [HA clusters](/dataproc/docs/concepts/configuring-clusters/high-availability) ; optional component in non-HA clusters)\nThe following sample Dataproc REST API [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request creates an ARM machine type cluster.\n```\nPOST /v1/projects/my-project-id/regions/is-central1/clusters/\n{\n \"projectId\": \"my-project-id\",\n \"clusterName\": \"sample-cluster\",\n \"config\": {\n \"configBucket\": \"\",\n \"gceClusterConfig\": {\n  \"subnetworkUri\": \"default\",\n  \"zoneUri\": \"us-central1-a\"\n },\n \"masterConfig\": {\n  \"numInstances\": 1,\n  \"machineTypeUri\": \"t2a-standard-4\",\n  \"diskConfig\": {\n  \"bootDiskSizeGb\": 500,\n  }\n },\n \"workerConfig\": {\n  \"numInstances\": 2,\n  \"machineTypeUri\": \"t2a-standard-4\",\n  \"diskConfig\": {\n  \"bootDiskSizeGb\": 500,\n  \"numLocalSsds\": 0\n  }\n },\n \"softwareConfig\": {\n  \"imageVersion\": \"2.1-ubuntu20-arm\"\n }\n }\n}\n```\n **\n** \n **\n**\n**\nFor more information\nSee Creating a VM Instance with a Custom Machine Type.\nSee Creating and starting an Arm VM instance.\n**", "guide": "Dataproc"}