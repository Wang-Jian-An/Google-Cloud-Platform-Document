{"title": "Dataproc - Customer managed encryption keys (CMEK)", "url": "https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption", "abstract": "# Dataproc - Customer managed encryption keys (CMEK)\nWhen you use Dataproc, cluster and job data is stored on persistent disks associated with the Compute Engine VMs in your cluster and in a Cloud Storage [staging bucket](/dataproc/docs/concepts/configuring-clusters/staging-bucket) . This persistent disk and bucket data is encrypted using a Google-generated data encryption key (DEK) and key encryption key (KEK).\nThe CMEK feature lets you create, use, and revoke the key encryption key (KEK). Google still controls the data encryption key (DEK). For more information on Google data encryption keys, see [Encryption at Rest](/security/encryption/default-encryption) .\n**Note:** The key (CMEK) must be located in the same location as the encrypted resource, For example, the CMEK used to encrypt a resource in the `us-central1` region must also be located in the `us-central1` region.\nCMEK differs from CustomerEncryption Keys (CSEK), a feature that lets users to specify the contents of the key encryption key. (see [Customer-Supplied Encryption Keys](/docs/security/encryption/customer-supplied-encryption-keys) ).\n", "content": "## Use CMEK with cluster data\nYou can use customer-managed encryption keys (CMEK) to encrypt the following cluster data:\n- Data on the persistent disks attached to VMs in your Dataproc cluster\n- Job argument data submitted to your cluster, such as a query string submitted with a Spark SQL job\n- Cluster metadata, [job driver output](/dataproc/docs/guides/dataproc-job-output#job_driver_output) , and other data written to a Dataproc [staging bucket](/dataproc/docs/concepts/configuring-clusters/staging-bucket#create_your_own_staging_and_temp_buckets) that you create\n**Note:** You can also use CMEK with [encryption of workflow template job arguments](#use_cmek_with_workflow_template_data) .\nFollow these steps to use CMEK with the encryption of cluster data:\n- Create one or more keys using the [Cloud Key Management Service](/kms/docs/creating-keys) . The resource name, also called the resource ID of a key, which you use in the next steps, is constructed as follows:```\nprojects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME\n```Use the **Cryptographic Keys** page in the Google Cloud console to copy a key resource ID to the clipboard.\n- Assign the following roles to the following service accounts:- Follow item #5 in [Compute Engine\u2192Protecting Resources with Cloud KMS Keys\u2192Before you begin](/compute/docs/disks/customer-managed-encryption#before_you_begin) to assign the Cloud KMS [CryptoKey Encrypter/Decrypter](/kms/docs/reference/permissions-and-roles#cloudkms.cryptoKeyEncrypterDecrypter) role to the [Compute Engine service agent](/compute/docs/access/service-accounts#compute_engine_service_account) service account.If the Compute Engine service agent service account is not visible on the [IAM](https://console.cloud.google.com/iam-admin/iam) page in the Google Cloud console, click \"Include Google-provided role grants\" on the page.\n- Assign the Cloud KMS [CryptoKey Encrypter/Decrypter](/kms/docs/reference/permissions-and-roles#cloudkms.cryptoKeyEncrypterDecrypter) role to the [Cloud Storage service agent](/storage/docs/encryption/using-customer-managed-keys#service-agent-access) service account.\n- Assign the Cloud KMS [CryptoKey Encrypter/Decrypter](/kms/docs/reference/permissions-and-roles#cloudkms.cryptoKeyEncrypterDecrypter) and the Service Usage [Service Usage Consumer](/service-usage/docs/access-control#predefined_roles) roles to the [Dataproc service agent](/dataproc/docs/concepts/configuring-clusters/service-accounts#service_agent_account) service account.\n- Pass the resource ID of your key to the Google Cloud CLI or the Dataproc API to use with cluster data encryption.- To encrypt cluster persistent disk data using your key, pass  the resource ID of your key to the`--gce-pd-kms-key`flag when you create  the cluster.```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--gce-pd-kms-key='projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME' \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```You can verify the key setting from the `gcloud` command-line tool.```\ngcloud dataproc clusters describe CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```Command output snippet:```\n...\nconfigBucket: dataproc- ...\nencryptionConfig:\ngcePdKmsKeyName: projects/project-id/locations/region/keyRings/key-ring-name/cryptoKeys/key-name\n...\n```\n- To encrypt cluster persistent disk data and job argument data using your key, pass the resource ID of the key to the`--kms-key`flag when you create the cluster.  See [Cluster.EncryptionConfig.kmsKey](/dataproc/docs/reference/rest/v1/ClusterConfig#EncryptionConfig.FIELDS.kms_key) for a list of job types and arguments that are encrypted with the`--kms-key`flag.```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--kms-key='projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME' \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n \n```You can verify key settings with the gcloud CLI `dataproc clusters describe` command. The key resource ID is set on `gcePdKmsKeyName` and `kmsKey` to use your key with the encryption of cluster persistent disk and job argument data.```\ngcloud dataproc clusters describe CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n \n```Command output snippet:```\n...\nconfigBucket: dataproc- ...\nencryptionConfig:\ngcePdKmsKeyName: projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME\nkmsKey: projects/PROJECT_ID/locations/REGION/keyRings/key-KEY_RING_NAME-name/cryptoKeys/KEY_NAME\n...\n```You can use either the`--gce-pd-kms-key`or the`--kms-key`flag, but not both, to encrypt cluster data using your key.\n- To encrypt cluster metadata, job driver, and other output data written to your  Dataproc staging bucket in Cloud Storage:- [Create your own bucket with CMEK](/storage/docs/encryption/using-customer-managed-keys) . When [adding the key to the bucket](/storage/docs/encryption/using-customer-managed-keys#set-default-key) ,  use a key that you created in Step 1.\n- Pass the bucket name to the `--bucket` flag when you create the cluster.\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--bucket=CMEK_BUCKET_NAME \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n \n```You can also pass CMEK-enabled buckets to the `gcloud dataproc jobs submit` command if your job takes bucket arguments, as shown in the following `cmek-bucket` example:```\ngcloud dataproc jobs submit pyspark gs://cmek-bucket/wordcount.py \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--cluster=cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--\u00a0gs://cmek-bucket/shakespeare.txt\u00a0gs://cmek-bucket/counts\n \n```\n- Dataproc doesn't manage customer managed encryption keys on your Cloud Storage bucket.\n- Using a bucket with a customer managed encryption key can slow write times to large files.\n- To encrypt cluster VM persistent disk data using your key, include the [ClusterConfig.EncryptionConfig.gcePdKmsKeyName](/dataproc/docs/reference/rest/v1/ClusterConfig#encryptionconfig) field as part of a [cluster.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request.You can verify the key setting with the gcloud CLI `dataproc clusters describe` command.```\ngcloud dataproc clusters describe CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```Command output snippet:```\n...\nconfigBucket: dataproc- ...\nencryptionConfig:\ngcePdKmsKeyName: projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME\n...\n```\n- To encrypt cluster VM persistent disk data and job argument data using your key, include the`Cluster.EncryptionConfig.kmsKey`field as part of a [cluster.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request. See [Cluster.EncryptionConfig.kmsKey](/dataproc/docs/reference/rest/v1/ClusterConfig#EncryptionConfig.FIELDS.kms_key) for a list of job types and arguments that are encrypted with the`--kms-key`field.You can include either the`Cluster.EncryptionConfig.gcePdKmsKeyName`field or the`Cluster.EncryptionConfig.kmsKey`field, but not both, with your cluster creation request.You can verify key settings with the gcloud CLI `dataproc clusters describe` command. The key resource ID is set on `gcePdKmsKeyName` and `kmsKey` to use your key with the encryption of cluster persistent disk and job argument data.```\ngcloud dataproc clusters describe CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```Command output snippet:```\n...\nconfigBucket: dataproc- ...\nencryptionConfig:\ngcePdKmsKeyName: projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME\nkmsKey: projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME\n```\n- To encrypt cluster metadata, job driver, and other output data written to your Dataproc staging bucket in Cloud Storage:- [Create your own bucket with CMEK](/storage/docs/encryption/using-customer-managed-keys) . When [adding the key to the bucket](/storage/docs/encryption/using-customer-managed-keys#set-default-key) ,  use a key that you created in Step 1.\n- Pass the bucket name to the [ClusterConfig.configBucket](/dataproc/docs/reference/rest/v1/ClusterConfig#FIELDS.config_bucket) field as part of a [cluster.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request.\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--bucket=CMEK_BUCKET_NAMEt \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```\n- Dataproc doesn't manage customer managed encryption keys on your Cloud Storage bucket.\n- Using a bucket with a customer managed encryption key can slow write times to large files.\nYou can also pass CMEK-enabled buckets to the `gcloud dataproc jobs submit` command if your job takes bucket arguments, as shown in the following `cmek-bucket` example:```\ngcloud dataproc jobs submit pyspark gs://cmek-bucket/wordcount.py \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--cluster=cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--\u00a0gs://cmek-bucket/shakespeare.txt\u00a0gs://cmek-bucket/counts\n \n```## Use CMEK with workflow template data\nDataproc workflow template job argument data, such as the query string of a Spark SQL job, can be encrypted using CMEK. Follow steps 1, 2, and 3 in this section to use CMEK with your Dataproc workflow template. See [WorkflowTemplate.EncryptionConfig.kmsKey](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates#encryptionconfig) for a list of workflow template job types and arguments that are encrypted using CMEK when this feature is enabled.\n- Create a key using the [Cloud Key Management Service (Cloud KMS)](/kms/docs/creating-keys) . The resource name of the key, which you use in the next steps, name is constructed as follows:```\nprojects/project-id/locations/region/keyRings/key-ring-name/cryptoKeys/key-name\n```Use the **Cryptographic Keys** page of the Google Cloud console to copy a key resource ID to the clipboard.\n- To enable the Dataproc service accounts to use your key:- Assign the Cloud KMS`CryptoKey Encrypter/Decrypter`role to the [DataprocService Agent service account](/dataproc/docs/concepts/iam/dataproc-principals#service_agent_control_plane_identity) .\n- Assign the Service Usage`Service Usage Consumer`role to the [DataprocService Agent service account](/dataproc/docs/concepts/iam/dataproc-principals#service_agent_control_plane_identity) .\n- You can use the Google Cloud CLI or the Dataproc API to set the key you created in Step 1 on a workflow. Once the key is set on a workflow, all the workflow job args and queries are encrypted using the key for any of the job types and arguments listed in [WorkflowTemplate.EncryptionConfig.kmsKey](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates#encryptionconfig) .\nPass resource ID of your key to the `--kms-key` flag when you create the workflow template with the [gcloud dataproc workflow-templates create](/sdk/gcloud/reference/dataproc/workflow-templates/create) command.\n **Example:** \n```\ngcloud dataproc workflow-templates create my-template-name \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--kms-key='projects/project-id/locations/region/keyRings/key-ring-name/cryptoKeys/key-name' \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```\nYou can verify the key setting from the\n`gcloud`\ncommand-line tool.\n```\ngcloud dataproc workflow-templates describe TEMPLATE_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```\n```\n...\nid: my-template-name\nencryptionConfig:\nkmsKey: projects/PROJECT_ID/locations/REGION/keyRings/KEY_RING_NAME/cryptoKeys/KEY_NAME\n...\n```Use [WorkflowTemplate.EncryptionConfig.kmsKey](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates#encryptionconfig) as part of a [workflowTemplates.create request](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/create) .\nYou can verify the key setting by issuing a [workflowTemplates.get](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/get) request. The returned JSON contains lists the `kmsKey` :\n```\n...\n\"id\": \"my-template-name\",\n\"encryptionConfig\": {\n \"kmsKey\": \"projects/project-id/locations/region/keyRings/key-ring-name/cryptoKeys/key-name\"\n},\n```\n## Cloud External Key Manager\n[Cloud External Key Manager (Cloud EKM) (EKM)](/kms/docs/ekm) lets you protect Dataproc data using keys managed by a [supported external key management partner](/kms/docs/ekm#supported_partners) . The steps you follow to use EKM in Dataproc are the same as as those you use to [set up CMEK keys](/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#using_cmek) , with the following difference: your key points to a URI for the **externally managed key** (see [Cloud EKM Overview](/kms/docs/ekm#overview) ).\n### Cloud EKM errors\nWhen you use Cloud EKM, an attempt to create a cluster can fail due to errors associated with inputs, Cloud EKM, the external key management partner system, or communications between EKM and the external system. If you use the REST API or the Google Cloud console, errors are logged in [Logging](/logging) . You can examine the failed cluster's errors from the **View Log** tab.\nIf you use [Cloud Shell](/shell) to create a cluster, errors are displayed in the Cloud Shell terminal and in Logging.", "guide": "Dataproc"}