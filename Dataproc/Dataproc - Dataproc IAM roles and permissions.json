{"title": "Dataproc - Dataproc IAM roles and permissions", "url": "https://cloud.google.com/dataproc/docs/concepts/iam/iam", "abstract": "# Dataproc - Dataproc IAM roles and permissions\n", "content": "## Overview\n[Identity and Access Management (IAM)](/iam) lets you control user and group access to project resources. This document focuses on the IAM relevant to Dataproc and the IAM that grant those permissions.\n## Dataproc Permissions\n**Security requirement beginning August 3, 2020: ** Dataproc users are required to have [service account ActAs permission](/iam/docs/service-accounts-actas) to deploy Dataproc resources, for example, to create clusters and instantiate workflows. See [Roles for service account authentication](/iam/docs/service-account-permissions) for detailed information about service account permissions. **Opt-in for existing Dataproc users: ** Existing Dataproc users as of August 3, 2020 can opt in to this security requirement (see [Securing Dataproc,Dataflow, and Cloud Data Fusion](/iam/docs/service-accounts-actas#dataproc-dataflow-datafusion) ).\nDataproc permissions allow users, including [service accounts](/compute/docs/access/service-accounts) , to perform actions on Dataproc clusters, jobs, operations, and workflow templates. For example, the `dataproc.clusters.create` permission allows a user to create Dataproc clusters in a project. Typically, you don't grant permissions; instead, you grant [roles](#roles) , which include one or more permissions.\nThe following tables list the permissions necessary to call Dataproc APIs (methods). The tables are organized according to the APIs associated with each Dataproc resource (clusters, jobs, operations, and workflow templates). [](None)\n**Permission Scope:** The scope of Dataproc permissions listed in the following tables is the containing Google Cloud project (`cloud-platform`scope). See [Service account permissions](/compute/docs/access/service-accounts#service_account_permissions) ).Examples:\n- `dataproc.clusters.create`permits the creation of Dataproc clusters in the containing project\n- `dataproc.jobs.create`permits the submission of Dataproc jobs to Dataproc clusters in the containing project\n- `dataproc.clusters.list`permits the listing of details of Dataproc clusters in the containing project### Clusters permissions\n| Method         | Required Permissions   |\n|:----------------------------------------|:-------------------------------|\n| projects.regions.clusters.create 1, 2 | dataproc.clusters.create  |\n| projects.regions.clusters.get   | dataproc.clusters.get   |\n| projects.regions.clusters.list   | dataproc.clusters.list   |\n| projects.regions.clusters.patch 1, 2, 3 | dataproc.clusters.update  |\n| projects.regions.clusters.delete 1  | dataproc.clusters.delete  |\n| projects.regions.clusters.start   | dataproc.clusters.start  |\n| projects.regions.clusters.stop   | dataproc.clusters.stop   |\n| projects.regions.clusters.getIamPolicy | dataproc.clusters.getIamPolicy |\n| projects.regions.clusters.setIamPolicy | dataproc.clusters.setIamPolicy |\nNotes:\n- The`dataproc.operations.get`permission is also required to get status updates from Google Cloud CLI.\n- The`dataproc.clusters.get`permission is also required to get the result of the operation from Google Cloud CLI.\n- `dataproc.autoscalingPolicies.use`permission is also required to enable an autoscaling policy on a cluster.\n### Jobs permissions\n| Method        | Required Permissions      |\n|:-----------------------------------|:-------------------------------------------|\n| projects.regions.jobs.submit 1, 2 | dataproc.jobs.create dataproc.clusters.use |\n| projects.regions.jobs.get   | dataproc.jobs.get       |\n| projects.regions.jobs.list   | dataproc.jobs.list       |\n| projects.regions.jobs.cancel 1  | dataproc.jobs.cancel      |\n| projects.regions.jobs.patch 1  | dataproc.jobs.update      |\n| projects.regions.jobs.delete 1  | dataproc.jobs.delete      |\n| projects.regions.jobs.getIamPolicy | dataproc.jobs.getIamPolicy     |\n| projects.regions.jobs.setIamPolicy | dataproc.jobs.setIamPolicy     |\nNotes:\n- The Google Cloud CLI also requires `dataproc.jobs.get` permission for the `jobs submit` , `jobs wait` , `jobs update` , `jobs delete` , and `jobs kill` commands.\n- The gcloud CLI also requires `dataproc.clusters.get` permission to submit jobs. For an example of setting the permissions necessary for a user to run `gcloud dataproc jobs submit` on a cluster using Dataproc Granular IAM (see [Submitting Jobs with Granular IAM](/dataproc/docs/concepts/iam/granular-iam#submitting_jobs_with_granular_iam) ).\n### Operations permissions\n| Method         | Required Permissions    |\n|:-----------------------------------------|:---------------------------------|\n| projects.regions.operations.get   | dataproc.operations.get   |\n| projects.regions.operations.list   | dataproc.operations.list   |\n| projects.regions.operations.cancel  | dataproc.operations.cancel  |\n| projects.regions.operations.delete  | dataproc.operations.delete  |\n| projects.regions.operations.getIamPolicy | dataproc.operations.getIamPolicy |\n| projects.regions.operations.setIamPolicy | dataproc.operations.setIamPolicy |\n### Workflow template permissions\n| Method            | Required Permissions       |\n|:-----------------------------------------------------|:---------------------------------------------|\n| projects.regions.workflowTemplates.instantiate  | dataproc.workflowTemplates.instantiate  |\n| projects.regions.workflowTemplates.instantiateInline | dataproc.workflowTemplates.instantiateInline |\n| projects.regions.workflowTemplates.create   | dataproc.workflowTemplates.create   |\n| projects.regions.workflowTemplates.get    | dataproc.workflowTemplates.get    |\n| projects.regions.workflowTemplates.list    | dataproc.workflowTemplates.list    |\n| projects.regions.workflowTemplates.update   | dataproc.workflowTemplates.update   |\n| projects.regions.workflowTemplates.delete   | dataproc.workflowTemplates.delete   |\n| projects.regions.workflowTemplates.getIamPolicy  | dataproc.workflowTemplates.getIamPolicy  |\n| projects.regions.workflowTemplates.setIamPolicy  | dataproc.workflowTemplates.setIamPolicy  |\nNotes:\n- Workflow Template permissions are independent of Cluster and Job permissions. A user without `create cluster` or `submit job` permissions may create and instantiate a Workflow Template.\n- The Google Cloud CLI additionally requires `dataproc.operations.get` permission to poll for workflow completion.\n- The `dataproc.operations.cancel` permission is required to cancel a running workflow.\n### Autoscaling policies permissions\n| Method           | Required Permissions      |\n|:--------------------------------------------------|:------------------------------------------|\n| projects.regions.autoscalingPolicies.create  | dataproc.autoscalingPolicies.create  |\n| projects.regions.autoscalingPolicies.get   | dataproc.autoscalingPolicies.get   |\n| projects.regions.autoscalingPolicies.list   | dataproc.autoscalingPolicies.list   |\n| projects.regions.autoscalingPolicies.update  | dataproc.autoscalingPolicies.update  |\n| projects.regions.autoscalingPolicies.delete  | dataproc.autoscalingPolicies.delete  |\n| projects.regions.autoscalingPolicies.getIamPolicy | dataproc.autoscalingPolicies.getIamPolicy |\n| projects.regions.autoscalingPolicies.setIamPolicy | dataproc.autoscalingPolicies.setIamPolicy |\nNotes:\n- `dataproc.autoscalingPolicies.use`permission is required to enable an autoscaling policy on a cluster with a`clusters.patch`method request.\n### Node groups Permissions\n| Method        | Required Permissions  |\n|:-----------------------------------|:---------------------------|\n| projects.regions.nodeGroups.create | dataproc.nodeGroups.create |\n| projects.regions.nodeGroups.get | dataproc.nodeGroups.get |\n| projects.regions.nodeGroups.resize | dataproc.nodeGroups.update |\n## Dataproc roles\n[Dataproc IAM roles](/iam/docs/understanding-roles#dataproc-roles) are a bundle of one or more [permissions](#permissions) . You grant roles to users or groups to allow them to perform actions on the Dataproc resources in a project. For example, the **Dataproc Viewer** role contains the `dataproc.*.get` and `dataproc.*.list` permissions, which allow a user to get and list Dataproc clusters, jobs, and operations in a project.\nThe following table lists the Dataproc IAM roles and the permissions associated with each role:\n| Role ID           | Permissions                                                                                                                                         |\n|:--------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| roles/dataproc.admin        | dataproc.*.getIamPolicy dataproc.*.setIamPolicy dataproc.*.create dataproc.*.get dataproc.*.list dataproc.*.delete dataproc.*.update dataproc.clusters.use dataproc.clusters.start dataproc.clusters.stop dataproc.jobs.cancel dataproc.workflowTemplates.instantiate dataproc.workflowTemplates.instantiateInline compute.machineTypes.get compute.machineTypes.list compute.networks.get compute.networks.list compute.projects.get compute.regions.get compute.regions.list compute.zones.get compute.zones.list resourcemanager.projects.get resourcemanager.projects.list |\n| roles/dataproc.editor        | dataproc.*.create dataproc.*.get dataproc.*.list dataproc.*.delete dataproc.*.update dataproc.clusters.use dataproc.clusters.start dataproc.clusters.stop dataproc.jobs.cancel dataproc.workflowTemplates.instantiate dataproc.workflowTemplates.instantiateInline compute.machineTypes.get compute.machineTypes.list compute.networks.get compute.networks.list compute.projects.get compute.regions.get compute.regions.list compute.zones.get compute.zones.list resourcemanager.projects.get resourcemanager.projects.list             |\n| roles/dataproc.viewer        | dataproc.*.get dataproc.*.list compute.machineTypes.get compute.regions.get compute.regions.list compute.zones.get resourcemanager.projects.get resourcemanager.projects.list                                                                                                 |\n| roles/dataproc.worker (for service accounts only) | dataproc.agents.* dataproc.tasks.* logging.logEntries.create monitoring.metricDescriptors.create monitoring.metricDescriptors.get monitoring.metricDescriptors.list monitoring.monitoredResourceDescriptors.get monitoring.monitoredResourceDescriptors.list monitoring.timeSeries.create storage.buckets.get storage.objects.create storage.objects.get storage.objects.list storage.objects.update storage.objects.delete storage.objects.getIamPolicy storage.objects.setIamPolicy                       |\nNotes:\n- \"*\" signifies \"clusters,\" \"jobs,\" or \"operations,\" except the only permissions associated with`dataproc.operations.`are`get`,`list`, and`delete`.\n- The`compute`permissions listed earlier are needed or recommended to create and view Dataproc clusters when using the Google Cloud console or the gcloud CLI Google Cloud CLI.\n- To allow a user to upload files, grant the`Storage Object Creator`role. To allow a user to view job output, grant the`Storage Object Viewer`role. Granting either of these Cloud Storage roles gives the user the ability to access any bucket in the project.\n- A user must have`monitoring.timeSeries.list`permission in order to view graphs on the Google Cloud console\u2192Dataproc\u2192 **Cluster details** Overview tab.\n- A user must have`compute.instances.list`permission in order to view instance status and the master instance SSH menu on the Google Cloud console\u2192Dataproc\u2192 **Cluster details** VM Instances tab. For information on Compute Engine roles, see [Compute Engine\u2192Available IAM roles](/compute/docs/access/iam#iam_roles) ).\n- To create a cluster with a user-specified service account, the specified service account must have all permissions granted by the`Dataproc Worker`role. Additional roles may be required depending on configured features. See [Service Accounts](/dataproc/docs/concepts/service-accounts) for more information.## Project roles\nYou can also set permissions at the project level by using the IAM **Project** roles. The following table lists permissions associated with IAM Project roles:\n| Project Role | Permissions                                 |\n|:---------------|:---------------------------------------------------------------------------------------------------------------------------------------------|\n| Project Viewer | All project permissions for read-only actions that preserve state (get, list)                |\n| Project Editor | All Project Viewer permissions plus all project permissions for actions that modify state (create, delete, update, use, cancel, stop, start) |\n| Project Owner | All Project Editor permissions plus permissions to manage access control for the project (get/set IamPolicy) and to set up project billing |\n## IAM roles and Dataproc operations summary\nThe following table lists Dataproc operations associated with project and Dataproc roles.\n| Operation      | Project Editor | Project Viewer | Dataproc Admin | Dataproc Editor | Dataproc Viewer |\n|:---------------------------------|:-----------------|:-----------------|:-----------------|:------------------|:------------------|\n| Get/Set Dataproc IAM permissions | No    | No    | Yes    | No    | No    |\n| Create cluster     | Yes    | No    | Yes    | Yes    | No    |\n| List clusters     | Yes    | Yes    | Yes    | Yes    | Yes    |\n| Get cluster details    | Yes    | Yes    | Yes 1, 2   | Yes 1, 2   | Yes 1, 2   |\n| Update cluster     | Yes    | No    | Yes    | Yes    | No    |\n| Delete cluster     | Yes    | No    | Yes    | Yes    | No    |\n| Start/Stop cluster    | Yes    | No    | Yes    | Yes    | No    |\n| Submit job      | Yes    | No    | Yes 3   | Yes 3    | No    |\n| List jobs      | Yes    | Yes    | Yes    | Yes    | Yes    |\n| Get job details     | Yes    | Yes    | Yes 4   | Yes 4    | Yes 4    |\n| Cancel job      | Yes    | No    | Yes    | Yes    | No    |\n| Delete job      | Yes    | No    | Yes    | Yes    | No    |\n| List operations     | Yes    | Yes    | Yes    | Yes    | Yes    |\n| Get operation details   | Yes    | Yes    | Yes    | Yes    | Yes    |\n| Delete operation     | Yes    | No    | Yes    | Yes    | No    |\nNotes:\n- The performance graph is not available unless the user also has a role with the`monitoring.timeSeries.list`permission.\n- The list of VMs in the cluster will not include status information or an SSH link for the master instance unless the user also has a role with the`compute.instances.list`permission.\n- Jobs that upload files require the user to have the`Storage Object Creator`role or write access to the Dataproc [staging bucket](/dataproc/docs/concepts/configuring-clusters/staging-bucket) .\n- Job output is not available unless the user also has the Storage Object Viewer role or has been granted read access to the staging bucket for the project.## Service accounts\nWhen you call Dataproc APIs to perform actions in a project, such as creating VM instances, Dataproc performs the actions on your behalf by using a service account that has the permissions required to perform the actions. For more information, see [Dataproc service accounts](/dataproc/docs/concepts/configuring-clusters/service-accounts) .\n## IAM management\nYou can get and set IAM policies using the Google Cloud console, the IAM API, or the Google Cloud CLI.\n- For the Google Cloud console, see [Access control using the Google Cloud console](/iam/docs/managing-policies#access_control_via_console) .\n- For the API, see [Access control using the API](/iam/docs/managing-policies#access_control_via_api) .\n- For the Google Cloud CLI, see [Access control using the Google Cloud CLI](/iam/docs/managing-policies#access_control_via_the_gcloud_tool) .## What's next\n- [Learn about Dataproc principals and roles](/dataproc/docs/concepts/iam/dataproc-principals) \n- [Learn about Dataproc Granular IAM](/dataproc/docs/concepts/iam/granular-iam) \n- [Learn more about IAM](/iam) .\n- [Learn about Service accounts in Dataproc](/dataproc/docs/concepts/configuring-clusters/service-accounts#service_accounts_in_dataproc)", "guide": "Dataproc"}