{"title": "Dataproc - Dataproc on GKE IAM Roles and Identity", "url": "https://cloud.google.com/dataproc/docs/guides/dpgke/dataproc-gke-iam", "abstract": "# Dataproc - Dataproc on GKE IAM Roles and Identity\n", "content": "## Data plane Identity\nDataproc on GKE uses [GKE workload identity](/kubernetes-engine/docs/how-to/workload-identity) to allow pods within the Dataproc on GKE cluster to act with the authority of the default [Dataproc VM service account (data plane identity)](/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity) . Workload identity requires the following permissions to update IAM policies on the GSA used by your Dataproc on GKE virtual cluster:\n- `compute.projects.get`\n- `iam.serviceAccounts.getIamPolicy`\n- `iam.serviceAccounts.setIamPolicy`\n**Note:** You can use workload identity with a different GSA: see [Custom IAM configuration](#custom_iam_configuration) .\nGKE workload identity links the following GKE Service Accounts (KSAs) to the Dataproc VM Service Account: [](None)\n- `agent`KSA (interacts with Dataproc control plane):`serviceAccount:${PROJECT}.svc.id.goog[${DPGKE_NAMESPACE}/agent]`\n- `spark-driver`KSA (runs Spark drivers):`serviceAccount:${PROJECT}.svc.id.goog[${DPGKE_NAMESPACE}/spark-driver]`\n- `spark-executor`KSA (runs Spark executors):`serviceAccount:${PROJECT}.svc.id.goog[${DPGKE_NAMESPACE}/spark-executor]`\nUse the`gcloud dataproc clusters gke create --setup-workload-identity`flag when you [create a Dataproc on GKE cluster](/dataproc/docs/guides/dpgke/quickstarts/dataproc-gke-quickstart-create-cluster) to create the workload identity bindings required for the cluster.\n### Assign roles\nGrant permissions to the [Dataproc VM service account](/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity) to allow the `spark-driver` and `spark-executor` to access project resources, data sources, data sinks, and any other services required by your workload.\nExample:\nThe following command assigns roles to the [default Dataproc VM service account](/dataproc/docs/concepts/configuring-clusters/service-accounts#dataproc_service_accounts_2) to allow Spark workloads running on Dataproc on GKE cluster VMs to access Cloud Storage buckets and BigQuery data sets in the project.\n```\ngcloud projects add-iam-policy-binding \\\n\u00a0\u00a0\u00a0\u00a0--role=roles/storage.objectAdmin \\\n\u00a0\u00a0\u00a0\u00a0--role=roles/bigquery.dataEditor \\\n\u00a0\u00a0\u00a0\u00a0--member=\"project-number-compute@developer.gserviceaccount.com\" \\\n\u00a0\u00a0\u00a0\u00a0\"${PROJECT}\"\n```\n## Custom IAM configuration\nDataproc on GKE uses [GKE workload identity](/kubernetes-engine/docs/how-to/workload-identity) to link the default [Dataproc VM service account (data plane identity)](/dataproc/docs/concepts/iam/dataproc-principals#vm_service_account_data_plane_identity) to the three [GKE service accounts (KSAs)](#ksa-sas) .\nTo create and use a different Google service account (GSA) to link to the KSAs:\n- Create the GSA (see [Creating and managing service accounts](/iam/docs/creating-managing-service-accounts) ).gcloud CLI example:```\ngcloud iam service-accounts create \"dataproc-${USER}\" \\\n\u00a0\u00a0\u00a0\u00a0--description \"Used by Dataproc on GKE workloads.\"\n```Notes:- The example sets the GSA name as \"dataproc-${USER}\", but you can use a different name.\n- Set environmental variables:```\nPROJECT=project-id \\\n\u00a0\u00a0DPGKE_GSA=\"dataproc-${USER}@${PROJECT}.iam.gserviceaccount.com\"\n\u00a0\u00a0DPGKE_NAMESPACE=GKE namespace\n```Notes:- `DPGKE_GSA`: The examples set and use`DPGKE_GSA`as the name of the variable that contains the email address of your GSA. You can set and use a different variable name.\n- `DPGKE_NAMESPACE`: The default [GKE namespace](/dataproc/docs/reference/rest/v1/GkeClusterConfig#NamespacedGkeDeploymentTarget.FIELDS.cluster_namespace) is the name of your Dataproc on GKE cluster.\n- When you create the Dataproc on GKE cluster, add the following properties for Dataproc to use your GSA instead of the default GSA:```\n--properties \"dataproc:dataproc.gke.agent.google-service-account=${DPGKE_GSA}\" \\\n--properties \"dataproc:dataproc.gke.spark.driver.google-service-account=${DPGKE_GSA}\" \\\n--properties \"dataproc:dataproc.gke.spark.executor.google-service-account=${DPGKE_GSA}\" \\\n```\n- Run the following commands to assign necessary [Workload Identity](/kubernetes-engine/docs/how-to/workload-identity) permissions to the service accounts:- Assign your GSA the`dataproc.worker`role to allow it to act as agent:```\ngcloud projects add-iam-policy-binding \\\n\u00a0\u00a0\u00a0\u00a0--role=roles/dataproc.worker \\\n\u00a0\u00a0\u00a0\u00a0--member=\"serviceAccount:${DPGKE_GSA}\" \\\n\u00a0\u00a0\u00a0\u00a0\"${PROJECT}\"\n```\n- Assign the `agent` KSA the `iam.workloadIdentityUser` role to allow it to act as your GSA:```\ngcloud iam service-accounts add-iam-policy-binding \\\n\u00a0\u00a0\u00a0\u00a0--role=roles/iam.workloadIdentityUser \\\n\u00a0\u00a0\u00a0\u00a0--member=\"serviceAccount:${PROJECT}.svc.id.goog[${DPGKE_NAMESPACE}/agent]\" \\\n\u00a0\u00a0\u00a0\u00a0\"${DPGKE_GSA}\"\n```\n- Grant the `spark-driver` KSA the `iam.workloadIdentityUser` role to allow it to act as your GSA:```\ngcloud iam service-accounts add-iam-policy-binding \\\n\u00a0\u00a0\u00a0\u00a0--role=roles/iam.workloadIdentityUser \\\n\u00a0\u00a0\u00a0\u00a0--member=\"serviceAccount:${PROJECT}.svc.id.goog[${DPGKE_NAMESPACE}/spark-driver]\" \\\n\u00a0\u00a0\u00a0\u00a0\"${DPGKE_GSA}\"\n```\n- Grant the `spark-executor` KSA the `iam.workloadIdentityUser` role to allow it to act as your GSA:```\ngcloud iam service-accounts add-iam-policy-binding \\\n\u00a0\u00a0\u00a0\u00a0--role=roles/iam.workloadIdentityUser \\\n\u00a0\u00a0\u00a0\u00a0--member=\"serviceAccount:${PROJECT}.svc.id.goog[${DPGKE_NAMESPACE}/spark-executor]\" \\\n\u00a0\u00a0\u00a0\u00a0\"${DPGKE_GSA}\"\n```", "guide": "Dataproc"}