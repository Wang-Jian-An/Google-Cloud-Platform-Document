{"title": "Dataproc - Dataproc optional HBase component", "url": "https://cloud.google.com/dataproc/docs/concepts/components/hbase", "abstract": "# Dataproc - Dataproc optional HBase component\n**Deprecated:** Starting with Dataproc [version 2.1](/dataproc/docs/concepts/versioning/dataproc-release-2.1) , you can no longer use the optional HBase component. Dataproc [version 1.5](/dataproc/docs/concepts/versioning/dataproc-release-1.5) and Dataproc [version 2.0](/dataproc/docs/concepts/versioning/dataproc-release-2.0) offer a Beta version of HBase with no support. However, due to the ephemeral nature of Dataproc clusters, using HBase is not recommended.\nInstallation of the optional HBase component is limited to Dataproc clusters created with image version [1.5](/dataproc/docs/concepts/versioning/dataproc-release-1.5) or [2.0](/dataproc/docs/concepts/versioning/dataproc-release-2.0) .\nWhile Google Cloud provides many services that let you deploy self-managed Apache HBase, [Bigtable](/bigtable/docs/overview) is often the best option as it provides an open API with HBase and workload portability. HBase database tables can be migrated to Bigtable for management of the underlying data, while applications that previously interoperated with HBase, such as Spark, may remain on Dataproc and securely connect with Bigtable. In this guide, we provide the high-level steps for getting started with Bigtable and provide references for migrating data to Bigtable from Dataproc HBase deployments.\n", "content": "## Get started with Bigtable\nCloud Bigtable is a highly scalable and performant NoSQL platform that provides [Apache HBase API client compatibility](https://cloud.google.com/bigtable/docs/hbase-bigtable) and portability for HBase workloads. The client is compatible with HBase API versions 1.x and 2.x and may be included with the existing application to read and write to Bigtable. Existing HBase applications may add the Bigtable HBase client library to read and write data stored in Bigtable.\nSee [Bigtable and the HBase API](https://cloud.google.com/bigtable/docs/hbase-bigtable) for more information on configuring your HBase application with Bigtable.\n## Create a Bigtable cluster\nYou can get started using Bigtable by creating a cluster and tables for storing data that was previously stored in HBase. Follow the steps in the Bigtable documentation for [creating an instance](/bigtable/docs/creating-instance#creating-instance) , a cluster, and [tables](/bigtable/docs/managing-tables) with the same schema as the HBase tables. For automated creation of tables from HBase table DDLs, refer to the [schema translator tool](/bigtable/docs/migrate-hbase-on-google-cloud-to-bigtable#create-destination-table) .\nOpen the Bigtable instance in Google Cloud console to view the table and server-side monitoring charts, including rows per second, latency, and throughput, to manage the newly provisioned table. For additional information, see [Monitoring](/bigtable/docs/monitoring-instance) .\n## Migrate data from Dataproc to Bigtable\nAfter you create the tables in Bigtable, you can import and validate your data by following the guidance at [Migrate HBase on Google Cloud to Bigtable](/bigtable/docs/migrate-hbase-on-google-cloud-to-bigtable) . After you migrate the data, you can update applications to send reads and writes to Bigtable.\n## What's next\n- See [Wordcount Spark examples](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/main/bigtable/spark) for running Spark with the Bigtable.\n- Review online migration options with [live replication from HBase to Bigtable](/bigtable/docs/hbase-replication) .\n- Watch [How Box modernized their NoSQL databases](https://www.youtube.com/watch?v=DteQ09WFhaU) to understand other benefits.", "guide": "Dataproc"}