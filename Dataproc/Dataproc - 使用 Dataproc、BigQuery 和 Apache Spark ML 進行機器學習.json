{"title": "Dataproc - \u4f7f\u7528 Dataproc\u3001BigQuery \u548c Apache Spark ML \u9032\u884c\u6a5f\u5668\u5b78\u7fd2", "url": "https://cloud.google.com/dataproc/docs/tutorials/bigquery-sparkml?hl=zh-cn", "abstract": "# Dataproc - \u4f7f\u7528 Dataproc\u3001BigQuery \u548c Apache Spark ML \u9032\u884c\u6a5f\u5668\u5b78\u7fd2\n\u9069\u7528\u65bc [Apache Spark](http://spark.apache.org/) \u7684 [BigQuery \u9023\u63a5\u5668](https://cloud.google.com/hadoop/bigquery-connector?hl=zh-cn) \u8b93\u6578\u64da\u79d1\u5b78\u5bb6\u80fd\u5920\u5c07 [BigQuery](https://cloud.google.com/bigquery/what-is-bigquery?hl=zh-cn) \u7684\u7121\u7e2b\u53ef\u64f4\u7e2e SQL \u5f15\u64ce\u7684\u5f37\u5927\u529f\u80fd\u8207 [Apache Spark \u7684\u6a5f\u5668\u5b78\u7fd2](https://spark.apache.org/docs/2.0.0/ml-guide.html) \u529f\u80fd\u76f8\u7d50\u5408\u3002\u5728\u672c\u6559\u7a0b\u4e2d\uff0c\u6211\u5011\u5c07\u4ecb\u7d39\u5982\u4f55\u4f7f\u7528 Dataproc\u3001BigQuery \u548c Apache Spark ML \u5728 [\u6578\u64da\u96c6](http://spark.apache.org/docs/latest/sql-programming-guide.html#datasets-and-dataframes) \u4e0a\u57f7\u884c\u6a5f\u5668\u5b78\u7fd2\u3002\n", "content": "## \u76ee\u6a19\n\u4f7f\u7528\u7dda\u6027\u8ff4\u6b78\u69cb\u5efa\u51fa\u751f\u9ad4\u91cd\u6a21\u578b\uff08\u53d6\u6c7a\u65bc\u4ee5\u4e0b\u4e94\u500b\u56e0\u7d20\uff09\uff1a\n- \u598a\u5a20\u9031\u6578\n- \u6bcd\u89aa\u7684\u5e74\u9f61\n- \u7236\u89aa\u7684\u5e74\u9f61\n- \u6bcd\u89aa\u5728\u61f7\u5b55\u671f\u9593\u589e\u52a0\u7684\u9ad4\u91cd\n- [Apgar \u5f97\u5206](https://en.wikipedia.org/wiki/Apgar_score) \n\u4f7f\u7528\u4ee5\u4e0b\u5de5\u5177\uff1a- BigQuery\uff0c\u7528\u65bc\u6e96\u5099\u7dda\u6027\u8ff4\u6b78\u8f38\u5165\u8868\uff0c\u8a72\u8868\u5c07\u5beb\u5165\u60a8\u7684 Google Cloud \u9805\u76ee\n- \u7528\u65bc\u5728 BigQuery \u4e2d\u67e5\u8a62\u548c\u7ba1\u7406\u6578\u64da\u7684 Python\n- Apache Spark\uff0c\u7528\u65bc\u8a2a\u554f\u751f\u6210\u7684\u7dda\u6027\u8ff4\u6b78\u8868\n- Spark ML\uff0c\u7528\u65bc\u69cb\u5efa\u548c\u8a55\u4f30\u6a21\u578b\n- Dataproc PySpark \u4f5c\u696d\uff0c\u7528\u65bc\u8abf\u7528 Spark ML \u51fd\u6578\n## \u8cbb\u7528\nTitles in dynamic includes are not used anywhere, and we should avoid paying to translate them\u5728\u672c\u6587\u6a94\u4e2d\uff0c\u60a8\u5c07\u4f7f\u7528 Google Cloud \u7684\u4ee5\u4e0b\u6536\u8cbb\u7d44\u4ef6\uff1a- Compute Engine\n- Dataproc\n- BigQuery\n\u60a8\u53ef\u4f7f\u7528 [\u50f9\u683c\u8a08\u7b97\u5668](https://cloud.google.com/products/calculator?hl=zh-cn) \u6839\u64da\u60a8\u7684\u9810\u8a08\u4f7f\u7528\u60c5\u6cc1\u4f86\u4f30\u7b97\u8cbb\u7528\u3002 \n## \u6e96\u5099\u5de5\u4f5cDataproc \u96c6\u7fa3\u5b89\u88dd\u4e86 Spark \u7d44\u4ef6\uff0c\u5305\u62ec Spark ML\u3002\u8981\u8a2d\u7f6e Dataproc \u96c6\u7fa3\u4e26\u904b\u884c\u6b64\u793a\u4f8b\u4e2d\u7684\u4ee3\u78bc\uff0c\u60a8\u9700\u8981\u57f7\u884c\uff08\u6216\u5df2\u5b8c\u6210\uff09\u4ee5\u4e0b\u5404\u9805\uff1a\n- Titles in dynamic includes are not used anywhere, and we should avoid paying to translate them\n- \u5728\u9805\u76ee\u4e2d\u5275\u5efa [Dataproc \u96c6\u7fa3](https://cloud.google.com/dataproc/docs/guides/create-cluster?hl=zh-cn) \u3002\u60a8\u7684\u96c6\u7fa3\u61c9\u5728 Spark 2.0 \u6216\u66f4\u9ad8\u7248\u672c\u4e0a\u904b\u884c [Dataproc \u7248\u672c](https://cloud.google.com/dataproc/docs/concepts/dataproc-versions?hl=zh-cn) \uff08\u5305\u62ec\u6a5f\u5668\u5b78\u7fd2\u5eab\uff09\u3002\n## \u5275\u5efa BigQuery natality \u6578\u64da\u7684\u5b50\u96c6\u5728\u672c\u90e8\u5206\u4e2d\uff0c\u4f60\u5728\u9805\u76ee\u4e2d\u5275\u5efa\u4e00\u500b\u6578\u64da\u96c6\uff0c\u7136\u5f8c\u5728\u6578\u64da\u96c6\u4e2d\u5275\u5efa\u4e00\u500b\u8868\uff0c\u4f60\u53ef\u5f9e\u516c\u958b\u53ef\u7528\u7684 [\u51fa\u751f\u7387](https://cloud.google.com/bigquery/sample-tables?hl=zh-cn) BigQuery \u8cc7\u6599\u96c6\u4e2d\u8907\u88fd\u51fa\u751f\u7387\u6578\u64da\u5b50\u96c6\u81f3\u8a72\u8868\u3002\u5728\u672c\u6559\u7a0b\u7684\u5f8c\u534a\u90e8\uff0c\u60a8\u5c07\u4f7f\u7528\u6b64\u8868\u4e2d\u7684\u5b50\u96c6\u6578\u64da\u4f86\u9810\u6e2c\u51fa\u751f\u9ad4\u91cd\u8207\u7522\u5a66\u5e74\u9f61\u3001\u7236\u89aa\u5e74\u9f61\u548c\u598a\u5a20\u9031\u6578\u7684\u51fd\u6578\u95dc\u4fc2\u3002\n\u60a8\u53ef\u4ee5\u4f7f\u7528 Google Cloud \u63a7\u5236\u6aaf\u6216\u8005\u5728\u672c\u5730\u6a5f\u5668\u4e0a\u904b\u884c Python \u8173\u672c\u4f86\u5275\u5efa\u6578\u64da\u5b50\u96c6\u3002\n- \u5728\u9805\u76ee\u4e2d\u5275\u5efa\u6578\u64da\u96c6\u3002- [\u8f49\u5230 BigQuery \u7db2\u9801\u754c\u9762](https://console.cloud.google.com/bigquery?hl=zh-cn) \u3002\n- \u5728\u5de6\u5074\u5c0e\u822a\u7a97\u683c\u4e2d\uff0c\u9ede\u64ca\u60a8\u7684\u9805\u76ee\u540d\u7a31\uff0c\u7136\u5f8c\u9ede\u64ca **\u5275\u5efa\u6578\u64da\u96c6** \u3002\n- \u5728 **\u5275\u5efa\u6578\u64da\u96c6** \u5c0d\u8a71\u6846\u4e2d\u57f7\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a- \u5c0d\u65bc **\u6578\u64da\u96c6 ID** \uff0c\u8f38\u5165\u201cnatality_regression\u201d\u3002\n- \u5c0d\u65bc **\u6578\u64da\u4f4d\u7f6e** \uff0c\u60a8\u53ef\u4ee5\u9078\u64c7\u6578\u64da\u96c6\u7684 [\u4f4d\u7f6e](https://cloud.google.com/bigquery/docs/dataset-locations?hl=zh-cn) \u3002\u9ed8\u8a8d\u4f4d\u7f6e\u503c\u7232`US multi-region`\u3002 \u5275\u5efa\u6578\u64da\u96c6\u5f8c\uff0c\u5c31\u7121\u6cd5\u518d\u66f4\u6539\u6b64\u4f4d\u7f6e\u3002\n- \u5c0d\u65bc **\u9ed8\u8a8d\u8868\u5230\u671f\u6642\u9593** \uff0c\u8acb\u9078\u64c7\u4ee5\u4e0b\u4efb\u4e00\u9078\u9805\uff1a- **\u5f9e\u4e0d** \uff08\u9ed8\u8a8d\u503c\uff09\uff1a\u60a8\u5fc5\u9808\u624b\u52d5\u522a\u9664\u8868\u683c\u3002\n- **\u5929\u6578** \uff1a\u8868\u683c\u5c07\u5728\u5275\u5efa\u4e4b\u6642\u8d77\u7684\u6307\u5b9a\u5929\u6578\u5f8c\u522a\u9664\u3002\n- \u5c0d\u65bc **\u52a0\u5bc6** \uff0c\u8acb\u9078\u64c7\u4ee5\u4e0b\u4efb\u4e00\u9078\u9805\uff1a- **\u7531 Google \u7ba1\u7406\u7684\u5bc6\u9470** \uff08\u9ed8\u8a8d\u503c\uff09\u3002\n- **\u5ba2\u6236\u7ba1\u7406\u7684\u5bc6\u9470** \uff1a\u8acb\u53c3\u95b1 [\u4f7f\u7528 Cloud KMS \u5bc6\u9470\u4fdd\u8b77\u6578\u64da](https://cloud.google.com/bigquery/docs/customer-managed-encryption?hl=zh-cn) \u3002\n- \u9ede\u64ca **\u5275\u5efa\u6578\u64da\u96c6** \u3002\u4f7f\u7528\u7db2\u9801\u754c\u9762\u5275\u5efa\u6578\u64da\u96c6\u6642\uff0c\u7121\u6cd5\u6dfb\u52a0\u8aaa\u660e\u6216\u6a19\u7c64\u3002\u5275\u5efa\u6578\u64da\u96c6\u5f8c\uff0c\u60a8\u53ef\u4ee5 [\u6dfb\u52a0\u8aaa\u660e](https://cloud.google.com/bigquery/docs/managing-datasets?hl=zh-cn#update-dataset-description) \uff0c\u4e5f\u53ef\u4ee5 [\u6dfb\u52a0\u6a19\u7c64](https://cloud.google.com/bigquery/docs/labels?hl=zh-cn#creating_and_updating_dataset_labels) \u3002\n- \u91dd\u5c0d\u516c\u5171\u51fa\u751f\u7387\u6578\u64da\u96c6\u904b\u884c\u67e5\u8a62\uff0c\u7136\u5f8c\u5c07\u67e5\u8a62\u7d50\u679c\u4fdd\u5b58\u5728\u6578\u64da\u96c6\u7684\u65b0\u8868\u4e2d\u3002- \u5c07\u4ee5\u4e0b\u67e5\u8a62\u8907\u88fd\u4e26\u7c98\u8cbc\u5230\u67e5\u8a62\u7de8\u8f2f\u5668\u4e2d\uff0c\u7136\u5f8c\u9ede\u64ca\u201c\u904b\u884c\u201d\u3002```\nSELECT\nweight_pounds,\nmother_age,\nfather_age,\ngestation_weeks,\nweight_gain_pounds,\napgar_5min\nFROM\n`bigquery-public-data.samples.natality`\nWHERE\nweight_pounds IS NOT NULL\nAND mother_age IS NOT NULL\nAND father_age IS NOT NULL\nAND gestation_weeks IS NOT NULL\nAND weight_gain_pounds IS NOT NULL\nAND apgar_5min IS NOT NULL\n```\n- \u67e5\u8a62\u5b8c\u6210\u5f8c\uff08\u5927\u7d04 1 \u5206\u9418\u5f8c\uff09\uff0c\u9ede\u64ca **\u4fdd\u5b58\u7d50\u679c** \uff0c\u7136\u5f8c\u9078\u64c7\u4fdd\u5b58\u9078\u9805\uff0c\u5c07\u7d50\u679c\u53e6\u5b58\u7232\u201cregression_input\u201dBigQuery \u8868\u4e26\u4fdd\u5b58\u5230\u9805\u76ee\u7684`natality_regression`\u6578\u64da\u96c6\u4e2d\u3002\n- \u8acb\u53c3\u95b1 [\u8a2d\u7f6e Python \u958b\u767c\u74b0\u5883](https://cloud.google.com/python/docs/setup?hl=zh-cn) \uff0c\u77ad\u89e3\u95dc\u65bc\u5b89\u88dd Python \u548c\u9069\u7528\u65bc Python \u7684 Google Cloud \u5ba2\u6236\u7aef\u5eab\uff08\u904b\u884c\u4ee3\u78bc\u6240\u9700\u7684\u8cc7\u6e90\uff09\u7684\u8aaa\u660e\u3002\u5efa\u8b70\u60a8\u5b89\u88dd\u548c\u4f7f\u7528 Python `virtualenv` \u3002\n- \u5c07\u4ee5\u4e0b `natality_tutorial.py` \u4ee3\u78bc\u8907\u88fd\u4e26\u7c98\u8cbc\u5230\u672c\u5730\u6a5f\u5668\u7684 `python` Shell \u4e2d\u3002 \u5728 Shell \u4e2d\u6309\u4e0b `<return>` \u9375\u904b\u884c\u4ee3\u78bc\uff0c\u4ee5\u5728\u9ed8\u8a8d Google Cloud \u9805\u76ee\u4e2d\u5275\u5efa\u201cnatality_regression\u201dBigQuery \u6578\u64da\u96c6\uff0c\u5176\u4e2d\u7684\u201cregression_input\u201d\u8868\u586b\u5145\u4e86\u516c\u958b `natality` \u6578\u64da\u7684\u5b50\u96c6\u3002 **\u8a2d\u7f6e\u4ee5\u5728\u672c\u5730\u904b\u884c\u61c9\u7528\u4ee3\u78bc** \uff1a\n- \u904b\u884c`gcloud config list project`\u4ee5\u67e5\u770b\u9ed8\u8a8d\u9805\u76ee\u7684\u540d\u7a31\u3002\n- \u904b\u884c`gcloud config set project` ``\u4ee5\u66f4\u6539\u9ed8\u8a8d\u9805\u76ee\u3002\n- \u904b\u884c`gcloud auth application-default login`\u4ee5\u5c07\u61c9\u7528\u6191\u64da\u8a2d\u7f6e\u7232\u60a8\u7684\u7528\u6236\u5e33\u865f\u3002\n [  samples/snippets/natality_tutorial.py ](https://github.com/googleapis/python-bigquery/blob/HEAD/samples/snippets/natality_tutorial.py) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/googleapis/python-bigquery/blob/HEAD/samples/snippets/natality_tutorial.py) ```\n\"\"\"Create a Google BigQuery linear regression input table.In the code below, the following actions are taken:* A new dataset is created \"natality_regression.\"* A query is run against the public dataset,\u00a0 \u00a0 bigquery-public-data.samples.natality, selecting only the data of\u00a0 \u00a0 interest to the regression, the output of which is stored in a new\u00a0 \u00a0 \"regression_input\" table.* The output table is moved over the wire to the user's default project via\u00a0 \u00a0 the built-in BigQuery Connector for Spark that bridges BigQuery and\u00a0 \u00a0 Cloud Dataproc.\"\"\"from google.cloud import bigquery# Create a new Google BigQuery client using Google Cloud Platform project# defaults.client = bigquery.Client()# Prepare a reference to a new dataset for storing the query results.dataset_id = \"natality_regression\"dataset_id_full = f\"{client.project}.{dataset_id}\"dataset = bigquery.Dataset(dataset_id_full)# Create the new BigQuery dataset.dataset = client.create_dataset(dataset)# Configure the query job.job_config = bigquery.QueryJobConfig()# Set the destination table to where you want to store query results.# As of google-cloud-bigquery 1.11.0, a fully qualified table ID can be# used in place of a TableReference.job_config.destination = f\"{dataset_id_full}.regression_input\"# Set up a query in Standard SQL, which is the default for the BigQuery# Python client library.# The query selects the fields of interest.query = \"\"\"\u00a0 \u00a0 SELECT\u00a0 \u00a0 \u00a0 \u00a0 weight_pounds, mother_age, father_age, gestation_weeks,\u00a0 \u00a0 \u00a0 \u00a0 weight_gain_pounds, apgar_5min\u00a0 \u00a0 FROM\u00a0 \u00a0 \u00a0 \u00a0 `bigquery-public-data.samples.natality`\u00a0 \u00a0 WHERE\u00a0 \u00a0 \u00a0 \u00a0 weight_pounds IS NOT NULL\u00a0 \u00a0 \u00a0 \u00a0 AND mother_age IS NOT NULL\u00a0 \u00a0 \u00a0 \u00a0 AND father_age IS NOT NULL\u00a0 \u00a0 \u00a0 \u00a0 AND gestation_weeks IS NOT NULL\u00a0 \u00a0 \u00a0 \u00a0 AND weight_gain_pounds IS NOT NULL\u00a0 \u00a0 \u00a0 \u00a0 AND apgar_5min IS NOT NULL\"\"\"# Run the query.query_job = client.query(query, job_config=job_config)query_job.result() \u00a0# Waits for the query to finish\n```\n- \u78ba\u8a8d\u5275\u5efa `natality_regression` \u6578\u64da\u96c6\u548c `regression_input` \u8868\u3002\n## \u904b\u884c\u7dda\u6027\u8ff4\u6b78\u5728\u672c\u90e8\u5206\u4e2d\uff0c\u60a8\u5c07\u4f7f\u7528 Google Cloud \u63a7\u5236\u6aaf\u6216\u901a\u904e\u5f9e\u672c\u5730\u7d42\u7aef\u904b\u884c `gcloud` \u547d\u4ee4\uff0c\u5c07\u4f5c\u696d\u63d0\u4ea4\u81f3 Dataproc \u670d\u52d9\u4ee5\u904b\u884c PySpark \u7dda\u6027\u8ff4\u6b78\u3002\n- \u5c07\u4ee5\u4e0b\u4ee3\u78bc\u8907\u88fd\u4e26\u7c98\u8cbc\u5230\u672c\u5730\u6a5f\u5668\u4e0a\u7684\u65b0 `natality_sparkml.py` \u6587\u4ef6\u4e2d\u3002```\n\"\"\"Run a linear regression using Apache Spark ML.In the following PySpark (Spark Python API) code, we take the following actions:\u00a0 * Load a previously created linear regression (BigQuery) input table\u00a0 \u00a0 into our Cloud Dataproc Spark cluster as an RDD (Resilient\u00a0 \u00a0 Distributed Dataset)\u00a0 * Transform the RDD into a Spark Dataframe\u00a0 * Vectorize the features on which the model will be trained\u00a0 * Compute a linear regression using Spark ML\"\"\"from pyspark.context import SparkContextfrom pyspark.ml.linalg import Vectorsfrom pyspark.ml.regression import LinearRegressionfrom pyspark.sql.session import SparkSession# The imports, above, allow us to access SparkML features specific to linear# regression as well as the Vectors types.# Define a function that collects the features of interest# (mother_age, father_age, and gestation_weeks) into a vector.# Package the vector in a tuple containing the label (`weight_pounds`) for that# row.def vector_from_inputs(r):\u00a0 return (r[\"weight_pounds\"], Vectors.dense(float(r[\"mother_age\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"father_age\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"gestation_weeks\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"weight_gain_pounds\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"apgar_5min\"])))sc = SparkContext()spark = SparkSession(sc)# Read the data from BigQuery as a Spark Dataframe.natality_data = spark.read.format(\"bigquery\").option(\u00a0 \u00a0 \"table\", \"natality_regression.regression_input\").load()# Create a view so that Spark SQL queries can be run against the data.natality_data.createOrReplaceTempView(\"natality\")# As a precaution, run a query in Spark SQL to ensure no NULL values exist.sql_query = \"\"\"SELECT *from natalitywhere weight_pounds is not nulland mother_age is not nulland father_age is not nulland gestation_weeks is not null\"\"\"clean_data = spark.sql(sql_query)# Create an input DataFrame for Spark ML using the above function.training_data = clean_data.rdd.map(vector_from_inputs).toDF([\"label\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"features\"])training_data.cache()# Construct a new LinearRegression object and fit the training data.lr = LinearRegression(maxIter=5, regParam=0.2, solver=\"normal\")model = lr.fit(training_data)# Print the model summary.print(\"Coefficients:\" + str(model.coefficients))print(\"Intercept:\" + str(model.intercept))print(\"R^2:\" + str(model.summary.r2))model.summary.residuals.show()\n```\n- \u5c07\u672c\u5730 `natality_sparkml.py` \u6587\u4ef6\u8907\u88fd\u5230\u9805\u76ee\u4e2d\u7684 Cloud Storage \u5b58\u5132\u6876\u3002```\ngsutil cp natality_sparkml.py gs://bucket-name\n```\u60a8\u53ef\u4ee5\u8907\u88fd Dataproc \u5275\u5efa\u96c6\u7fa3\u6642\u5275\u5efa\u7684 [\u66ab\u5b58\u5b58\u5132\u6876](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket?hl=zh-cn) \uff0c\u800c\u7121\u9700\u5c07\u6587\u4ef6\u8907\u88fd\u5230\u9805\u76ee\u4e2d\u7684\u7528\u6236\u5b58\u5132\u6876\u3002\n- \u5f9e Dataproc [\u63d0\u4ea4\u4f5c\u696d](https://console.cloud.google.com/dataproc/jobs/jobsSubmit?hl=zh-cn) \u9801\u9762\u904b\u884c\u8ff4\u6b78\u3002- \u5728 **\u4e3b Python \u6587\u4ef6** \u5b57\u6bb5\u4e2d\uff0c\u63d2\u5165\u60a8\u7684 `natality_sparkml.py` \u6587\u4ef6\u526f\u672c\u6240\u5728\u7684 Cloud Storage \u5b58\u5132\u6876\u7684 `gs://` URI\u3002\n- \u9078\u64c7 `PySpark` \u4f5c\u7232 **\u4f5c\u696d\u985e\u578b** \u3002\n- \u5728 **Jar \u6587\u4ef6** \u5b57\u6bb5\u4e2d\u63d2\u5165 `gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar` \u3002\u9019\u53ef\u8b93 PySpark \u61c9\u7528\u5728\u904b\u884c\u6642\u4f7f\u7528 spark-bigquery-connector \u5c07 BigQuery \u6578\u64da\u8b80\u53d6\u5230 Spark DataFrame \u4e2d\u30022.12 jar \u8207\u4f7f\u7528 1.5 \u6216\u66f4\u9ad8\u7248\u672c\u6620\u50cf\u5275\u5efa\u7684 Dataproc \u96c6\u7fa3\u517c\u5bb9\u3002\u5982\u679c\u60a8\u7684 Dataproc \u96c6\u7fa3\u662f\u4f7f\u7528 1.3 \u6216 1.4 \u6620\u50cf\u5275\u5efa\u7684\uff0c\u8acb\u6539\u7232\u6307\u5b9a 2.11 jar (`gs://spark-lib/bigquery/spark-bigquery-latest_2.11.jar`)\u3002\n- \u586b\u5beb **\u4f5c\u696d ID** \u3001 **\u5340\u57df** \u548c **\u96c6\u7fa3** \u5b57\u6bb5\u3002\n- \u9ede\u64ca **\u63d0\u4ea4** \u4ee5\u5728\u96c6\u7fa3\u4e0a\u904b\u884c\u4f5c\u696d\u3002\n\u4f5c\u696d\u5b8c\u6210\u5f8c\uff0cDataproc \u4f5c\u696d\u8a73\u60c5\u7a97\u53e3\u5c07\u986f\u793a\u7dda\u6027\u8ff4\u6b78\u8f38\u51fa\u6a21\u578b\u5f59\u7e3d\u3002\n **\u6a21\u578b\u5f59\u7e3d\u8853\u8a9e\uff1a** - **R^2\uff1a** \u7528\u65bc\u8861\u91cf\u6a21\u578b\u6355\u7372\u4e86\u591a\u5c11\u201c\u4fe1\u865f\u201d\u7684\u6307\u6a19\u3002\n- **\u6b98\u5dee\uff1a** \u6a21\u578b\u9810\u6e2c\u8207\u7528\u65bc\u64ec\u5408\u6a21\u578b\u7684\u6bcf\u500b\u9ede\u7684\u5be6\u969b\u503c\u4e4b\u9593\u7684\u5dee\u7570\u3002\n- \u5c07\u4ee5\u4e0b\u4ee3\u78bc\u8907\u88fd\u4e26\u7c98\u8cbc\u5230\u672c\u5730\u6a5f\u5668\u4e0a\u7684\u65b0 `natality_sparkml.py` \u6587\u4ef6\u4e2d\u3002```\n\"\"\"Run a linear regression using Apache Spark ML.In the following PySpark (Spark Python API) code, we take the following actions:\u00a0 * Load a previously created linear regression (BigQuery) input table\u00a0 \u00a0 into our Cloud Dataproc Spark cluster as an RDD (Resilient\u00a0 \u00a0 Distributed Dataset)\u00a0 * Transform the RDD into a Spark Dataframe\u00a0 * Vectorize the features on which the model will be trained\u00a0 * Compute a linear regression using Spark ML\"\"\"from pyspark.context import SparkContextfrom pyspark.ml.linalg import Vectorsfrom pyspark.ml.regression import LinearRegressionfrom pyspark.sql.session import SparkSession# The imports, above, allow us to access SparkML features specific to linear# regression as well as the Vectors types.# Define a function that collects the features of interest# (mother_age, father_age, and gestation_weeks) into a vector.# Package the vector in a tuple containing the label (`weight_pounds`) for that# row.def vector_from_inputs(r):\u00a0 return (r[\"weight_pounds\"], Vectors.dense(float(r[\"mother_age\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"father_age\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"gestation_weeks\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"weight_gain_pounds\"]),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 float(r[\"apgar_5min\"])))sc = SparkContext()spark = SparkSession(sc)# Read the data from BigQuery as a Spark Dataframe.natality_data = spark.read.format(\"bigquery\").option(\u00a0 \u00a0 \"table\", \"natality_regression.regression_input\").load()# Create a view so that Spark SQL queries can be run against the data.natality_data.createOrReplaceTempView(\"natality\")# As a precaution, run a query in Spark SQL to ensure no NULL values exist.sql_query = \"\"\"SELECT *from natalitywhere weight_pounds is not nulland mother_age is not nulland father_age is not nulland gestation_weeks is not null\"\"\"clean_data = spark.sql(sql_query)# Create an input DataFrame for Spark ML using the above function.training_data = clean_data.rdd.map(vector_from_inputs).toDF([\"label\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"features\"])training_data.cache()# Construct a new LinearRegression object and fit the training data.lr = LinearRegression(maxIter=5, regParam=0.2, solver=\"normal\")model = lr.fit(training_data)# Print the model summary.print(\"Coefficients:\" + str(model.coefficients))print(\"Intercept:\" + str(model.intercept))print(\"R^2:\" + str(model.summary.r2))model.summary.residuals.show()\n```\n- \u5c07\u672c\u5730 `natality_sparkml.py` \u6587\u4ef6\u8907\u88fd\u5230\u9805\u76ee\u4e2d\u7684 Cloud Storage \u5b58\u5132\u6876\u3002```\ngsutil cp natality_sparkml.py gs://bucket-name\n```\u60a8\u53ef\u4ee5\u8907\u88fd Dataproc \u5275\u5efa\u96c6\u7fa3\u6642\u5275\u5efa\u7684 [\u66ab\u5b58\u5b58\u5132\u6876](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/staging-bucket?hl=zh-cn) \uff0c\u800c\u7121\u9700\u5c07\u6587\u4ef6\u8907\u88fd\u5230\u9805\u76ee\u4e2d\u7684\u7528\u6236\u5b58\u5132\u6876\u3002\n- \u901a\u904e\u5f9e\u672c\u5730\u6a5f\u5668\u7684\u7d42\u7aef\u7a97\u53e3\u4e2d\u904b\u884c\u5982\u4e0b\u6240\u793a\u7684 `gcloud` \u547d\u4ee4\uff0c\u5c07 Pyspark \u4f5c\u696d\u63d0\u4ea4\u5230 Dataproc \u670d\u52d9\u3002- **--jars** \u6a19\u8a8c\u503c\u53ef\u8b93 PySpark jobv \u5728\u904b\u884c\u6642\u4f7f\u7528 spark-bigquery-connector \u5c07 BigQuery \u6578\u64da\u8b80\u53d6\u5230 Spark DataFrame \u4e2d\u3002```\ngcloud dataproc jobs submit pyspark \\\n\u00a0\u00a0\u00a0\u00a0gs://your-bucket/natality_sparkml.py \\\n\u00a0\u00a0\u00a0\u00a0--cluster=cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_SCALA_VERSION-CONNECTOR_VERSION.jar\n```2.12 jar \u8207\u4f7f\u7528 1.5 \u6216\u66f4\u9ad8\u7248\u672c\u6620\u50cf\u5275\u5efa\u7684 Dataproc \u96c6\u7fa3\u517c\u5bb9\u3002\u5982\u679c\u60a8\u7684 Dataproc \u96c6\u7fa3\u662f\u4f7f\u7528 1.3 \u6216 1.4 \u6620\u50cf\u5275\u5efa\u7684\uff0c\u8acb\u6539\u7232\u6307\u5b9a 2.11 JAR\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u5c07\u8a72\u9023\u63a5\u5668\u63d0\u4f9b\u7d66\u60a8\u7684\u61c9\u7528](https://cloud.google.com/dataproc/docs/tutorials/bigquery-connector-spark-example?hl=zh-cn#make_the_connector_available_to_your_application) \u3002\n\u4f5c\u696d\u5b8c\u6210\u6642\uff0c\u7dda\u6027\u8ff4\u6b78\u8f38\u51fa\uff08\u6a21\u578b\u5f59\u7e3d\uff09\u5c07\u986f\u793a\u5728\u7d42\u7aef\u7a97\u53e3\u4e2d\u3002\n **\u6a21\u578b\u5f59\u7e3d\u8853\u8a9e\uff1a** \n- **R^2\uff1a** \u7528\u65bc\u8861\u91cf\u6a21\u578b\u6355\u7372\u4e86\u591a\u5c11\u201c\u4fe1\u865f\u201d\u7684\u6307\u6a19\u3002\n- **\u6b98\u5dee\uff1a** \u6a21\u578b\u9810\u6e2c\u8207\u7528\u65bc\u64ec\u5408\u6a21\u578b\u7684\u6bcf\u500b\u9ede\u7684\u5be6\u969b\u503c\u4e4b\u9593\u7684\u5dee\u7570\u3002\n```\n<<< # Print the model summary.\n... print \"Coefficients:\" + str(model.coefficients)\nCoefficients:[0.0166657454602,-0.00296751984046,0.235714392936,0.00213002070133,-0.00048577251587]\n<<< print \"Intercept:\" + str(model.intercept)\nIntercept:-2.26130330748\n<<< print \"R^2:\" + str(model.summary.r2)\nR^2:0.295200579035\n<<< model.summary.residuals.show()\n+--------------------+\n|   residuals|\n+--------------------+\n| -0.7234737533344147|\n| -0.985466980630501|\n| -0.6669710598385468|\n| 1.4162434829714794|\n|-0.09373154375186754|\n|-0.15461747949235072|\n| 0.32659061654192545|\n| 1.5053877697929803|\n| -0.640142797263989|\n| 1.229530260294963|\n|-0.03776160295256...|\n| -0.5160734239126814|\n| -1.5165972740062887|\n| 1.3269085258245008|\n| 1.7604670124710626|\n| 1.2348130901905972|\n| 2.318660276655887|\n| 1.0936947030883175|\n| 1.0169768511417363|\n| -1.7744915698181583|\n+--------------------+\nonly showing top 20 rows.\n```\n## \u6e05\u7406\n\u5b8c\u6210\u672c\u6559\u7a0b\u5f8c\uff0c\u60a8\u53ef\u4ee5\u6e05\u7406\u60a8\u5275\u5efa\u7684\u8cc7\u6e90\uff0c\u8b93\u5b83\u5011\u505c\u6b62\u4f7f\u7528\u914d\u984d\uff0c\u4ee5\u514d\u7522\u751f\u8cbb\u7528\u3002\u4ee5\u4e0b\u90e8\u5206\u4ecb\u7d39\u5982\u4f55\u522a\u9664\u6216\u95dc\u9589\u9019\u4e9b\u8cc7\u6e90\u3002\n### \u522a\u9664\u9805\u76ee\n\u82e5\u8981\u907f\u514d\u7522\u751f\u8cbb\u7528\uff0c\u6700\u7c21\u55ae\u7684\u65b9\u6cd5\u662f\u522a\u9664\u60a8\u7232\u672c\u6559\u7a0b\u5275\u5efa\u7684\u9805\u76ee\u3002\n\u8981\u522a\u9664\u9805\u76ee\uff0c\u8acb\u57f7\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a\n- Titles in dynamic includes are not used anywhere, and we should avoid paying to translate them\n- **\u8b66\u544a** \uff1a\u522a\u9664\u9805\u76ee\u6703\u7522\u751f\u4ee5\u4e0b\u5f71\u97ff- **\u9805\u76ee\u4e2d\u7684\u6240\u6709\u5167\u5bb9\u90fd\u6703\u88ab\u522a\u9664\u3002** \u5982\u679c\u60a8\u5c07\u73fe\u6709\u9805\u76ee\u7528\u65bc\u672c\u6587\u6a94\u4e2d\u7684\u4efb\u52d9\uff0c\u5247\u522a\u9664\u8a72\u9805\u76ee\u5f8c\uff0c\u9084\u5c07\u522a\u9664\u60a8\u5df2\u5728\u8a72\u9805\u76ee\u4e2d\u5b8c\u6210\u7684\u4efb\u4f55\u5176\u4ed6\u5de5\u4f5c\u3002\n- **\u81ea\u5b9a\u7fa9\u9805\u76ee ID \u4e1f\u5931\u3002** \u5275\u5efa\u6b64\u9805\u76ee\u6642\uff0c\u60a8\u53ef\u80fd\u5275\u5efa\u4e86\u8981\u5728\u5c07\u4f86\u4f7f\u7528\u7684\u81ea\u5b9a\u7fa9\u9805\u76ee ID\u3002\u8981\u4fdd\u7559\u4f7f\u7528\u8a72\u9805\u76ee ID \u7684\u7db2\u5740\uff08\u4f8b\u5982`appspot.com`\u7db2\u5740\uff09\uff0c\u8acb\u522a\u9664\u9805\u76ee\u5167\u7684\u6240\u9078\u8cc7\u6e90\uff0c\u800c\u4e0d\u662f\u522a\u9664\u6574\u500b\u9805\u76ee\u3002\n\u5982\u679c\u60a8\u6253\u7b97\u63a2\u7d22\u591a\u500b\u67b6\u69cb\u3001\u6559\u7a0b\u6216\u5feb\u901f\u5165\u9580\uff0c\u5247\u91cd\u8907\u4f7f\u7528\u9805\u76ee\u53ef\u4ee5\u5e6b\u52a9\u60a8\u907f\u514d\u8d85\u51fa\u9805\u76ee\u914d\u984d\u9650\u5236\u3002\n- \u5728 Google Cloud \u63a7\u5236\u6aaf\u4e2d\uff0c\u9032\u5165 **\u7ba1\u7406\u8cc7\u6e90** \u9801\u9762\u3002 [\u8f49\u5230\u201c\u7ba1\u7406\u8cc7\u6e90\u201d](https://console.cloud.google.com/iam-admin/projects?hl=zh-cn) \n- \u5728\u9805\u76ee\u5217\u8868\u4e2d\uff0c\u9078\u64c7\u8981\u522a\u9664\u7684\u9805\u76ee\uff0c\u7136\u5f8c\u9ede\u64ca **\u522a\u9664** \u3002\n- \u5728\u5c0d\u8a71\u6846\u4e2d\u8f38\u5165\u9805\u76ee ID\uff0c\u7136\u5f8c\u9ede\u64ca **\u95dc\u9589** \u4ee5\u522a\u9664\u9805\u76ee\u3002\n### \u522a\u9664 Dataproc \u96c6\u7fa3\u8acb\u53c3\u95b1 [\u522a\u9664\u96c6\u7fa3](https://cloud.google.com/dataproc/docs/guides/manage-cluster?hl=zh-cn#delete_a_cluster) \u3002## \u5f8c\u7e8c\u6b65\u9a5f\n- \u8acb\u53c3\u95b1 [Spark \u4f5c\u696d\u5fae\u8abf\u63d0\u793a](https://cloud.google.com/dataproc/docs/support/spark-job-tuning?hl=zh-cn)", "guide": "Dataproc"}