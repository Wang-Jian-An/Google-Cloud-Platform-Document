{"title": "Dataproc - Dataproc optional Flink component", "url": "https://cloud.google.com/dataproc/docs/concepts/components/flink", "abstract": "# Dataproc - Dataproc optional Flink component\nYou can activate additional components like Flink when you create a Dataproc cluster using the [Optional components](/dataproc/docs/concepts/components/overview#available_optional_components) feature. This page shows you how to create a Dataproc cluster with the [Apache Flink](https://flink.apache.org/) optional component activated (a Flink cluster), and then run Flink jobs on the cluster.\nYou can use your Flink cluster to:\n- [Run Flink jobs using the Dataproc Jobs resource](#run_flink_jobs_using_the_jobs_resource) from the Google Cloud console, Google Cloud CLI, or the Dataproc API.\n- [Run Flink jobs using the flink CLI](#run_flink_jobs_using_the_flink_cli) running on the Flink cluster master node.\n- [Run Apache Beam jobs on Flink](#run_apache_beam_jobs_on_flink) \n- Run [Flink on a Kerberized cluster](#run_flink_on_a_kerberized_cluster) ", "content": "## Create a Dataproc Flink cluster\nYou can use the Google Cloud console, Google Cloud CLI, or the Dataproc API to create a Dataproc cluster that has the Flink component activated on the cluster.\n**Recommendation:** Use a standard 1-master VM cluster with the Flink component. [Dataproc High Availability mode clusters](/dataproc/docs/concepts/configuring-clusters/high-availability) (with 3 master VMs) do not support [Flink high-availability mode](https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/ha/overview/) .\nTo create a Dataproc Flink cluster using the Google Cloud console, perform the following steps:- Open the Dataproc [Create a Dataproc cluster on Compute Engine](https://console.cloud.google.com/dataproc/clustersAdd) page.- The **Set up cluster** panel is selected.- In the **Versioning** section, confirm or change the **Image Type and Version** . The cluster image version determines the version of the Flink component installed on the cluster.- The image version must be 1.5 or higher to activate the Flink component on the cluster (See [Supported Dataproc versions](/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions) to view listings of the component versions included in each Dataproc image release).\n- The image version must be [TBD] or higher to run Flink jobs through the Dataproc Jobs API (see [Run Dataproc Flink jobs](#run_flink_jobs) ).\n- In the **Components** section:- Under **Component Gateway** , select **Enable component gateway** . You must enable the [Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways#console_1) to activate the Component Gateway link to the Flink History Server UI. Enabling the Component Gateway also enables access to the [Flink Job Manager web interface](#flink-job-manager-ui) running on the Flink cluster.\n- Under **Optional components** , select **Flink** and other optional components to activate on your cluster.\n- Click the **Customize cluster (optional)** panel.- In the **Cluster properties** section, click **Add Properties** for each optional [cluster property](/dataproc/docs/concepts/configuring-clusters/cluster-properties) to add to your cluster. You can add `flink` prefixed properties to configure Flink properties in `/etc/flink/conf/flink-conf.yaml` that will act as defaults for Flink applications that you run on the cluster.Examples:- Set`flink:historyserver.archive.fs.dir`to specify the Cloud Storage location to write Flink job history files (this location will be used by the Flink History Server running on the Flink cluster).\n- Set Flink task slots with`flink:taskmanager.numberOfTaskSlots=` ``.\n- In the **Custom cluster metadata** section, click **Add Metadata** to add optional metadata. For example, add `flink-start-yarn-session` `true` to run the Flink YARN daemon ( `/usr/bin/flink-yarn-daemon` ) in the background on the cluster master node to start a Flink YARN session (see [Flink session mode](#session_mode) ).\n- If you are using Dataproc image version 2.0 or earlier, click the **Manage security (optional)** panel, then, under **Project access** , select `Enables the cloud-platform scope for this cluster` . `cloud-platform` scope is enabled by default when you create a cluster that uses Dataproc image version 2.1 or later.\n- Click **Create** to create the cluster.\nTo create a Dataproc Flink cluster using the gcloud CLI, run the following [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command locally in a terminal window or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) :\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\u00a0 \u00a0 --region=REGION \\\u00a0 \u00a0 --image-version=DATAPROC_IMAGE_VERSION \\\u00a0 \u00a0 --optional-components=FLINK \\\u00a0 \u00a0 --enable-component-gateway \\\u00a0 \u00a0 --properties=PROPERTIES\u00a0 \u00a0 ... other flags\n```\nNotes:- : Specify the name of the cluster.\n- : Specify a [Compute Engine region](/compute/docs/regions-zones#available) where the cluster will be located.\n- : Optionally specify the image version to use on the cluster. The cluster image version determines the version of the Flink component installed on the cluster.- The image version must be 1.5 or higher to activate the Flink component on the cluster (See [Supported Dataproc versions](/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions) to view listings of the component versions included in each Dataproc image release).\n- The image version must be [TBD] or higher to run Flink jobs through the Dataproc Jobs API (see [Run Dataproc Flink jobs](#run_flink_jobs) ).\n- `--optional-components` : You must specify the `FLINK` component to run Flink jobs and the Flink HistoryServer Web Service on the cluster.\n- `--enable-component-gateway` : You must enable the [Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways#console_1) to activate the Component Gateway link to Flink History Server UI. Enabling the Component Gateway also enables access to the [Flink Job Manager web interface](#flink-job-manager-ui) running on the Flink cluster.\n- . Optionally specify one or more [cluster properties](/dataproc/docs/concepts/configuring-clusters/cluster-properties) .- When creating Dataproc clusters with image versions `2.0.67` + and `2.1.15` +, you can use the `--properties` flag to to configure Flink properties in `/etc/flink/conf/flink-conf.yaml` that will act as defaults for Flink applications that you run on the cluster.\n- You can set `flink:historyserver.archive.fs.dir` to specify the Cloud Storage location to write Flink job history files (this location will be used by the Flink History Server running on the Flink cluster).\n- Multiple properties example:\n```\n--properties=flink:historyserver.archive.fs.dir=gs://my-bucket/my-flink-cluster/completed-jobs,flink:taskmanager.numberOfTaskSlots=2\n```\n- Other flags:- You can add the optional`--metadata flink-start-yarn-session=true`flag to run the Flink YARN daemon (`/usr/bin/flink-yarn-daemon`) in the background on the cluster master node to start a Flink YARN session (see [Flink session mode](#session_mode) ).\n- When using 2.0 or earlier image versions, you can add the `--scopes=https://www.googleapis.com/auth/cloud-platform` flag to enable access to Google Cloud APIs by your cluster (see [Scopes best practice](/compute/docs/access/service-accounts#scopes_best_practice) ). `cloud-platform` scope is enabled by default when you create a cluster that uses Dataproc image version 2.1 or later.\nTo create a Dataproc Flink cluster using the Dataproc API, submit a [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request, as follows:\nNotes:- Set the [SoftwareConfig.Component](/dataproc/docs/reference/rest/v1/ClusterConfig#SoftwareConfig.FIELDS.optional_components) to `FLINK` .\n- You can optionally set [SoftwareConfig.imageVersion](/dataproc/docs/reference/rest/v1/ClusterConfig#softwareconfig) to specify the image version to use on the cluster. The cluster image version determines the version of the Flink component installed on the cluster.- The image version must be 1.5 or higher to activate the Flink component on the cluster (See [Supported Dataproc versions](/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions) to view listings of the component versions included in each Dataproc image release).\n- The image version must be [TBD] or higher to run Flink jobs through the Dataproc Jobs API (see [Run Dataproc Flink jobs](#run_flink_jobs) ).\n- Set [EndpointConfig.enableHttpPortAccess](/dataproc/docs/reference/rest/v1/ClusterConfig#endpointconfig) to `true` to [enable the Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways#console_1) link to Flink History Server UI. Enabling the Component Gateway also enables access to the [Flink Job Manager web interface](#flink-job-manager-ui) running on the Flink cluster.\n- You can optionally set [SoftwareConfig.properties](/dataproc/docs/reference/rest/v1/ClusterConfig#softwareconfig) to specify one or more [cluster properties](/dataproc/docs/concepts/configuring-clusters/cluster-properties) .- You can specify Flink properties that will act as defaults for Flink applications that you run on the cluster. For example, you can set the`flink:historyserver.archive.fs.dir`to specify the Cloud Storage location to write Flink job history files (this location will be used by the Flink History Server running on the Flink cluster).\n- You can optionally set:- [GceClusterConfig.metadata](/dataproc/docs/reference/rest/v1/ClusterConfig#GceClusterConfig.FIELDS.metadata) . for example, to specify`flink-start-yarn-session``true`to run the Flink YARN daemon (`/usr/bin/flink-yarn-daemon`) in the background on the cluster master node to start a Flink YARN session (see [Flink session mode](#session_mode) ).\n- [GceClusterConfig.serviceAccountScopes](/dataproc/docs/reference/rest/v1/ClusterConfig#GceClusterConfig.FIELDS.service_account_scopes) to`https://www.googleapis.com/auth/cloud-platform`(`cloud-platform`scope) when using 2.0 or earlier image versions to enable access to Google Cloud APIs by your cluster (see [Scopes best practice](/compute/docs/access/service-accounts#scopes_best_practice) ).`cloud-platform`scope is enabled by default when you create a cluster that uses Dataproc image version 2.1 or later.\n### After you create a Flink cluster\n- Use the`Flink History Server`link in the [Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways#viewing_and_accessing_component_gateway_urls) to view the Flink History Server running on the Flink cluster.\n- Use the`YARN ResourceManager link`in the Component Gateway to view the [Flink Job Manager web interface](#flink-job-manager-ui) running on the Flink cluster  .\n- Create a [Dataproc Persistent History Server](/dataproc/docs/concepts/jobs/history-server) to view Flink job history files written by existing and deleted Flink clusters.## Run Flink jobs using the Dataproc Jobs resource\nYou can run Flink jobs using the Dataproc `Jobs` resource from the Google Cloud console, Google Cloud CLI, or Dataproc API.\n**Note:** This feature is available in Dataproc on Compute Engine 2.0.71+, 2.1.19+, and later image versions.\n**    Private preview     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .For information about access to this  release, see the [  access request page](/dataproc/docs/support/getting-support#dataproc-allowlist) .\nTo submit a sample Flink wordcount job from the console:- Open the Dataproc [Submit a job](https://console.cloud.google.com/dataproc/jobs/jobsSubmit) page in the Google Cloud console in your browser.\n- Fill in the fields on the **Submit a job** page:- Select your **Cluster** name from the cluster list.\n- Set **Job type** to`Flink`.\n- Set **Main class or jar** to`org.apache.flink.examples.java.wordcount.WordCount`.\n- Set **Jar files** to`file:///usr/lib/flink/examples/batch/WordCount.jar`.- `file:///`denotes a file located on the cluster. Dataproc installed the`WordCount.jar`when it created the Flink cluster.\n- This field also accepts a Cloud Storage path (`gs://` `` `/` ``) or a Hadoop Distributed File System (HDFS) path (`hdfs://` ``).\n- Click **Submit** .- Job driver output is displayed on the **Job details** page.\n- Flink jobs are listed on the Dataproc [Jobs](https://console.cloud.google.com/dataproc/jobs) page in the Google Cloud console.\n- Click **Stop** or **Delete** from the **Jobs** or **Job details** page to stop or delete a job.\nTo submit a Flink job to a Dataproc Flink cluster, run the gcloud CLI [gcloud dataproc jobs submit](/sdk/gcloud/reference/dataproc/jobs/submit) command locally in a terminal window or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) .\n```\ngcloud dataproc jobs submit flink \\\u00a0 \u00a0 --cluster=CLUSTER_NAME \\\u00a0 \u00a0 --region=REGION \\\u00a0 \u00a0 --class=MAIN_CLASS \\\u00a0 \u00a0 --jar=JAR_FILE \\\u00a0 \u00a0 -- JOB_ARGS\n```\nNotes:- : Specify the name of the Dataproc Flink cluster to submit the job to.\n- : Specify a [Compute Engine region](/compute/docs/regions-zones#available) where the cluster is located.\n- : Specify the`main`class of your Flink application, such as:- `org.apache.flink.examples.java.wordcount.WordCount`\n- : Specify the Flink application jar file. You can specify:- A jar file installed on the cluster, using thefile:///` prefix:- `file:///usr/lib/flink/examples/streaming/TopSpeedWindowing.jar`\n- `file:///usr/lib/flink/examples/batch/WordCount.jar`\n- A jar file in Cloud Storage:`gs://` `` `/` ``\n- A jar file in HDFS:`hdfs://` ``\n- : Optionally, add job arguments after the double dash ( `--` ).\n- After submitting the job, job driver output is displayed in the local or Cloud Shell terminal.```\nProgram execution finishedJob with JobID 829d48df4ebef2817f4000dfba126e0f has finished.Job Runtime: 13610 ms...(after,1)(and,12)(arrows,1)(ay,1)(be,4)(bourn,1)(cast,1)(coil,1)(come,1)\n```\n **Note:** You can stop a job with the [gcloud dataproc jobs kill JOB_ID](/sdk/gcloud/reference/dataproc/jobs/kill) command, and delete a job with the [gcloud dataproc jobs delete JOB_ID](/sdk/gcloud/reference/dataproc/jobs/delete) command.\nThis section shows how to submit a Flink job to a Dataproc Flink cluster using the Dataproc [jobs.submit](/dataproc/docs/reference/rest/v1/projects.regions.jobs/submit) API.\nYou can add the`clusterLabels`field to the API request shown below to specify one or more cluster labels. Dataproc will submit the job to a cluster that matches a specified cluster label (see the [jobs.submit](/dataproc/docs/reference/rest/v1/projects.regions.jobs#JobPlacement.FIELDS.cluster_labels) API for more information).\nBefore using any of the request data, make the following replacements:- : Google Cloud project ID\n- : [cluster region](/dataproc/docs/guides/create-cluster#cluster-region) \n- : Specify the name of the Dataproc Flink cluster to submit the job to\nHTTP method and URL:\n```\nPOST https://dataproc.googleapis.com/v1/projects/PROJECT_ID/regions/REGION/jobs:submit\n```\nRequest JSON body:\n```\n{\n \"job\": {\n \"placement\": {\n  \"clusterName\": \"CLUSTER_NAME\"\n },\n \"flinkJob\": {\n  \"mainClass\": \"org.apache.flink.examples.java.wordcount.WordCount\",\n  \"jarFileUris\": [  \"file:///usr/lib/flink/examples/batch/WordCount.jar\"\n  ]\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"reference\": {\n \"projectId\": \"PROJECT_ID\",\n \"jobId\": \"JOB_ID\"\n },\n \"placement\": {\n \"clusterName\": \"CLUSTER_NAME\",\n \"clusterUuid\": \"CLUSTER_UUID\"\n },\n \"flinkJob\": {\n \"mainClass\": \"org.apache.flink.examples.java.wordcount.WordCount\",\n \"args\": [  \"1000\"\n ],\n \"jarFileUris\": [  \"file:///usr/lib/flink/examples/batch/WordCount.jar\"\n ]\n },\n \"status\": {\n \"state\": \"PENDING\",\n \"stateStartTime\": \"2020-10-07T20:16:21.759Z\"\n },\n \"jobUuid\": \"JOB_UUID\"\n}\n```\n **Note:** You can click the **Equivalent REST** link at the bottom of the Dataproc Google Cloud console [Submit a job](https://console.cloud.google.com/dataproc/jobs/jobsSubmit) page to have the Google Cloud console construct an equivalent API REST request to use in your code to submit a job to your cluster.- Flink jobs are listed on the Dataproc [Jobs](https://console.cloud.google.com/dataproc/jobs) page in the Google Cloud console.\n- You can click **Stop** or **Delete** from the **Jobs** or **Job details** page in the Google Cloud console to stop or delete a job.\n## Run Flink jobs using the flink CLI\nInstead of [running Flink jobs using the Dataproc Jobs resource](#run_flink_jobs_using_the_jobs_resource) , you can run Flink jobs on the master node of your Flink cluster using the `flink` CLI.\n**Note:** To use the `flink` cli on yuor cluster, you must have activated the Flink optional component when you created your cluster\u2014see [Create a Dataproc Flink cluster](#create_a_flink_cluster) ).\nThe following sections describe different ways you can run a `flink` CLI job on your Dataproc Flink cluster.\n- **SSH into the master node:** Use the [SSH](/dataproc/docs/concepts/accessing/ssh) utility to open a terminal window on the cluster master VM.\n- **Set the classpath:** Initialize the Hadoop classpath from the SSH terminal window on the Flink cluster master VM:```\nexport HADOOP_CLASSPATH=$(hadoop classpath)\n``` **Note:** Flink command syntax can differ according to the Flink version installed on the Dataproc cluster. See the [Dataproc Image version list](/dataproc/docs/concepts/versioning/dataproc-versions) or run `flink --version` on your cluster to check the Flink component version installed on your Flink cluster. Run `flink` command help for additional flag information.\n- **Run Flink jobs:** You can run Flink jobs in different [deployment modes on YARN](https://nightlies.apache.org/flink/flink-docs-stable/docs/deployment/resource-providers/yarn/#deployment-modes-supported-by-flink-on-yarn) : application, per-job, and session mode.- **Application mode:** Flink Application mode is supported by Dataproc image version 2.0 and later. This mode executes the job's `main()` method on the YARN Job Manager. The cluster shuts down after the job finishes.Job submission example:```\nflink run-application \\\n\u00a0\u00a0\u00a0\u00a0-t yarn-application \\\n\u00a0\u00a0\u00a0\u00a0-Djobmanager.memory.process.size=1024m \\\n\u00a0\u00a0\u00a0\u00a0-Dtaskmanager.memory.process.size=2048m \\\n\u00a0\u00a0\u00a0\u00a0-Djobmanager.heap.mb=820 \\\n\u00a0\u00a0\u00a0\u00a0-Dtaskmanager.heap.mb=1640 \\\n\u00a0\u00a0\u00a0\u00a0-Dtaskmanager.numberOfTaskSlots=2 \\\n\u00a0\u00a0\u00a0\u00a0-Dparallelism.default=4 \\\n\u00a0\u00a0\u00a0\u00a0/usr/lib/flink/examples/batch/WordCount.jar\n```List running jobs:```\n./bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY\n```Cancel a running job:```\n./bin/flink cancel -t yarn-application -Dyarn.application.id=application_XXXX_YY <jobId>\n```\n- **Per-job mode:** This Flink mode executes the job's `main()` method on the client side.Job submission example:```\nflink run \\\n\u00a0\u00a0\u00a0\u00a0-m yarn-cluster \\\n\u00a0\u00a0\u00a0\u00a0-p 4 \\\n\u00a0\u00a0\u00a0\u00a0-ys 2 \\\n\u00a0\u00a0\u00a0\u00a0-yjm 1024m \\\n\u00a0\u00a0\u00a0\u00a0-ytm 2048m \\\n\u00a0\u00a0\u00a0\u00a0/usr/lib/flink/examples/batch/WordCount.jar\n```\n- **Session mode:** Start a long-running Flink YARN session, then submit one or more jobs to the session.- **Start a session:** You can start a Flink session in one of the following ways:- [Create a Flink cluster](#install_the_component) , adding the `--metadata flink-start-yarn-session=true` flag to the `gcloud dataproc clusters create` command (See [Create a Dataproc Flink cluster](#create_a_flink_cluster) ). With this flag enabled, after the cluster is created, Dataproc runs `/usr/bin/flink-yarn-daemon` to start a Flink session on the cluster.The session's YARN application ID is saved in `/tmp/.yarn-properties-${USER}` . You can list the ID with the `yarn application -list` command.\n- Run the Flink [yarn-session.sh](https://github.com/apache/flink/blob/master/flink-dist/src/main/flink-bin/yarn-bin/yarn-session.sh) script, which is pre-installed on the cluster master VM, with custom settings:Example with custom settings:```\n/usr/lib/flink/bin/yarn-session.sh \\\n\u00a0\u00a0\u00a0\u00a0-s 1 \\\n\u00a0\u00a0\u00a0\u00a0-jm 1024m \\\n\u00a0\u00a0\u00a0\u00a0-tm 2048m \\\n\u00a0\u00a0\u00a0\u00a0-nm flink-dataproc \\\n\u00a0\u00a0\u00a0\u00a0--detached\n```\n- Run the Flink the `/usr/bin/flink-yarn-daemon` wrapper script with default settings:```\n. /usr/bin/flink-yarn-daemon\n```\n- **Submit a job to a session:** Run the following command to submit a Flink job to the session.```\nflink run -m <var>FLINK_MASTER_URL</var>/usr/lib/flink/examples/batch/WordCount.jar\n```- : the URL, including host and port, of the Flink master VM where jobs are executed. **Remove the http:// prefix from\nthe URL.** This URL is listed in the command output when you start a Flink session. You can run the following command to list this URL in the`Tracking-URL`field:\n```\nyarn application -list -appId=<yarn-app-id> | sed 's#http://\n##'\n ```\n```\n- **List jobs in a session:** To list Flink jobs in a session, do one of the following:- Run `flink list` without arguments. The command looks for the the session's YARN application ID in `/tmp/.yarn-properties-${USER}` .\n- Obtain the YARN application ID of the session from `/tmp/.yarn-properties-${USER}` or the output of `yarn application -list` , and then run `<code>` flink list -yid .\n- Run `flink list -m` `` .\n- **Stop a session:** To stop the session, obtain the YARN application ID of the session from `/tmp/.yarn-properties-${USER}` or the output of `yarn application -list` , then run either of the following commands:```\necho \"stop\" | /usr/lib/flink/bin/yarn-session.sh -id YARN_APPLICATION_ID\n``````\nyarn application -kill YARN_APPLICATION_ID\n```## Run Apache Beam jobs on Flink\nYou can run [Apache Beam](https://beam.apache.org/) jobs on Dataproc using the [FlinkRunner](https://beam.apache.org/documentation/runners/flink/) .\n**Note:** In pre-2.18 Beam versions, a separate Beam Job Service was required to package and submit jobs written in Python to Flink. Starting with Beam 2.18, the Beam Job Service is no longer needed.\nYou can run Beam jobs on Flink in the following ways:\n- Java Beam jobs\n- Portable Beam jobs\n### Java Beam jobs\n[Package your Beam jobs into a JAR file](https://beam.apache.org/documentation/runners/flink/#executing-a-beam-pipeline-on-a-flink-cluster) . Supply the bundled JAR file with the dependencies needed to run the job.\nThe following example runs a Java Beam job from the Dataproc cluster's master node.\n**Note:** This example executes successfully with Dataproc 1.5, Flink 1.9 and the [compatible Beam versions](https://beam.apache.org/documentation/runners/flink/#flink-version-compatibility) . However, with Dataproc 2.0, Flink 1.12, and Beam >=2.30, see this JIRA issue [BEAM-10430](https://issues.apache.org/jira/browse/BEAM-10430) .\n- Create a Dataproc cluster with the [Flink component](/dataproc/docs/concepts/components/flink) enabled.```\ngcloud dataproc clusters create CLUSTER_NAME \\\n --optional-components=FLINK \\\n --image-version=DATAPROC_IMAGE_VERSION \\\n --region=REGION \\\n --enable-component-gateway \\\n --scopes=https://www.googleapis.com/auth/cloud-platform\n```- `--optional-components`: Flink.\n- `--image-version`: the [cluster's image version](/dataproc/docs/concepts/versioning/dataproc-versions#supported_cloud_dataproc_versions) , which determines the Flink version installed on the cluster (for example, see the Apache Flink component versions listed for the latest and previous four [2.0.x image release versions](/dataproc/docs/concepts/versioning/dataproc-release-2.0) ).\n- `--region`: a supported Dataproc [region](/dataproc/docs/concepts/regional-endpoints#regional_endpoint_semantics) .\n- `--enable-component-gateway`: enable access to the Flink Job Manager UI.\n- `--scopes`: enable access to Google Cloud APIs by your cluster (see [Scopes best practice](/compute/docs/access/service-accounts#scopes_best_practice) ).`cloud-platform`scope is enabled by default (you do not need to include this flag setting) when you create a cluster that uses Dataproc image version 2.1 or later.\n- Use the [SSH utility](/dataproc/docs/concepts/accessing/cluster-web-interfaces#create_an_ssh_tunnel) to open a terminal window on the Flink cluster master node.\n- Start a Flink YARN session on the Dataproc cluster master node.```\n. /usr/bin/flink-yarn-daemon\n```Take note of the Flink version on your Dataproc cluster.```\nflink --version\n```\n- On your local machine, [generate the canonical Beam word count example in Java](https://beam.apache.org/get-started/quickstart-java/) .Choose a Beam version that is compatible with the Flink version on your Dataproc cluster. See the [Flink Version Compatibility](https://beam.apache.org/documentation/runners/flink/#flink-version-compatibility) table that lists Beam-Flink version compatibility.Open the generated POM file. Check the Beam Flink runner version specified by the tag `<flink.artifact.name>` . If the Beam Flink runner version in the Flink artifact name does not match the Flink version on your cluster, update the version number to match.```\nmvn archetype:generate \\\n -DarchetypeGroupId=org.apache.beam \\\n -DarchetypeArtifactId=beam-sdks-java-maven-archetypes-examples \\\n -DarchetypeVersion=BEAM_VERSION \\\n -DgroupId=org.example \\\n -DartifactId=word-count-beam \\\n -Dversion=\"0.1\" \\\n -Dpackage=org.apache.beam.examples \\\n -DinteractiveMode=false\n```\n- Package the word count example.```\nmvn package -Pflink-runner\n```\n- Upload the packaged uber JAR file, `word-count-beam-bundled-0.1.jar` (~135 MB) to your Dataproc cluster's master node. You can use [gsutil cp](https://cloud.google.com/storage/docs/gsutil/commands/cp) for faster file transfers to your Dataproc cluster from Cloud Storage.- On your local terminal, create a Cloud Storage bucket, and upload the uber JAR.```\ngsutil mb BUCKET_NAME\ngsutil cp target/word-count-beam-bundled-0.1.jar gs://BUCKET_NAME/\n```\n- On your Dataproc's master node, download the uber JAR.```\ngsutil cp gs://BUCKET_NAME/word-count-beam-bundled-0.1.jar .\n```\n- Run the Java Beam job on the Dataproc cluster's master node.```\nflink run -c org.apache.beam.examples.WordCount word-count-beam-bundled-0.1.jar \\\n --runner=FlinkRunner \\\n --output=gs://BUCKET_NAME/java-wordcount-out\n```\n- Check that the results were written to your Cloud Storage bucket.```\ngsutil cat gs://BUCKET_NAME/java-wordcount-out-SHARD_ID\n```\n- Stop the Flink YARN session.```\nyarn application -list\nyarn application -kill YARN_APPLICATION_ID\n```\n### Portable Beam Jobs\nTo run Beam jobs written in Python, Go, and other supported languages, you can use the `FlinkRunner` and `PortableRunner` as described on the Beam's [Flink Runner](https://beam.apache.org/documentation/runners/flink/) page (also see [Portability Framework Roadmap](https://beam.apache.org/roadmap/portability/) ).\nThe following example runs a portable Beam job in Python from the Dataproc cluster's master node.\n**Note:** This example executes successfully with Dataproc 1.5, Flink 1.9 and the [compatible Beam versions](https://beam.apache.org/documentation/runners/flink/#flink-version-compatibility) . However, with Dataproc 2.0, Flink 1.12, and Beam >=2.30, see this JIRA issue [BEAM-10430](https://issues.apache.org/jira/browse/BEAM-10430) .\n- Create a Dataproc cluster with both the [Flink](/dataproc/docs/concepts/components/flink) and [Docker](/dataproc/docs/concepts/components/docker) components enabled.```\ngcloud dataproc clusters create CLUSTER_NAME \\\n --optional-components=FLINK,DOCKER \\\n --image-version=DATAPROC_IMAGE_VERSION \\\n --region=REGION \\\n --enable-component-gateway \\\n --scopes=https://www.googleapis.com/auth/cloud-platform\n```Notes:- `--optional-components`: Flink and Docker.\n- `--image-version`: The [cluster's image version](/dataproc/docs/concepts/versioning/dataproc-versions#supported_cloud_dataproc_versions) , which determines the Flink version installed on the cluster (for example, see the Apache Flink component versions listed for the latest and previous four [2.0.x image release versions](/dataproc/docs/concepts/versioning/dataproc-release-2.0) ).\n- `--region`: An available Dataproc [region](/dataproc/docs/concepts/regional-endpoints#regional_endpoint_semantics) .\n- `--enable-component-gateway`: Enable access to the Flink Job Manager UI.\n- `--scopes`: Enable access to Google Cloud APIs by your cluster (see [Scopes best practice](/compute/docs/access/service-accounts#scopes_best_practice) ).`cloud-platform`scope is enabled by default (you do not need to include this flag setting) when you create a cluster that uses Dataproc image version 2.1 or later.\n- Use `gsutil` locally or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) to create a Cloud Storage bucket. You will specify the when you run a sample wordcount program.```\ngsutil mb BUCKET_NAME\n```\n- In a terminal window on the cluster VM, start a Flink YARN session. Note the Flink master URL, the address of the Flink master where jobs are executed.. You will specify the when you run a sample wordcount program.```\n. /usr/bin/flink-yarn-daemon\n```Display and **note the Flink version** running the Dataproc cluster. You will specify the when you run a sample wordcount program.```\nflink --version\n```\n- Install Python libraries needed for the job on the cluster master node.\n- Install a [Beam version](https://beam.apache.org/documentation/runners/flink/#flink-version-compatibility) that is compatible with the Flink version on the cluster.```\npython -m pip install apache-beam[gcp]==BEAM_VERSION\n```\n- Run the word count example on the cluster master node.```\npython -m apache_beam.examples.wordcount \\\n --runner=FlinkRunner \\\n --flink_version=FLINK_VERSION \\\n --flink_master=FLINK_MASTER_URL\n --flink_submit_uber_jar \\\n --output=gs://BUCKET_NAME/python-wordcount-out\n```Notes:- `--runner`:`FlinkRunner`.\n- `--flink_version`:, noted earlier.\n- `--flink_master`:, noted earlier.\n- `--flink_submit_uber_jar`: Use the uber JAR to execute the Beam job.\n- `--output`:, created earlier.\n- Verify that results were written to your bucket.```\ngsutil cat gs://BUCKET_NAME/python-wordcount-out-SHARD_ID\n```\n- Stop the Flink YARN session.- Get the application ID.\n```\nyarn application -list\n1. Insert the <var>YARN_APPLICATION_ID</var>, then stop the session.\nyarn application -kill \n```## Run Flink on a Kerberized cluster\nThe Dataproc Flink component supports [Kerberized clusters](/dataproc/docs/concepts/configuring-clusters/security) . A valid Kerberos ticket is needed to submit and persist a Flink job or to start a Flink cluster. By default, a Kerberos ticket remains valid for seven days.\n## Access the Flink Job Manager UI\nThe Flink Job Manager web interface is available while a Flink job or Flink session cluster is running. To use the web interface:\n- [Create a Dataproc Flink cluster](#create_a_flink_cluster) .\n- After cluster creation, click the **Component Gateway** [YARN ResourceManager link](/dataproc/docs/concepts/accessing/dataproc-gateways#console_1) on the Web Interface tab on the **Cluster details** page in the Google Cloud console.\n- On the **YARN Resource Manager** UI, identify the Flink cluster application entry. Depending on a job's completion status, an **ApplicationMaster** or **History** link will be listed.\n- For a long-running streaming job, click the **ApplicationManager** link to open the Flink dashboard; for a completed job, click the **History** link to view job details.", "guide": "Dataproc"}