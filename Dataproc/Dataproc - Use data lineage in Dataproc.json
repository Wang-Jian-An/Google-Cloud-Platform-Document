{"title": "Dataproc - Use data lineage in Dataproc", "url": "https://cloud.google.com/dataproc/docs/guides/lineage", "abstract": "# Dataproc - Use data lineage in Dataproc\nData lineage is a Dataplex feature that lets you track how data moves through your systems: where it comes from, where it is passed to, and what transformations are applied to it.\nData lineage is available for all Dataproc Spark jobs except SparkR, with Dataproc Compute Engine 2.0.74+ and 2.1.22+ images. Lineage is available for BigQuery and Cloud Storage data sources.\nOnce you enable the feature in your Dataproc cluster, Dataproc Spark jobs capture lineage events and publish them to the Dataplex [Data Lineage API](/dataplex/docs/reference/rest) . Dataproc integrates with the Data Lineage API through [OpenLineage](/data-catalog/docs/concepts/open-lineage) , using the [OpenLineage Spark plugin](https://github.com/OpenLineage/OpenLineage) .\nYou can access lineage information through Dataplex, using the following:\n- [Lineage visualization graphs](/data-catalog/docs/concepts/about-data-lineage#lineage-feature-graph) \n- [Data Lineage API](/data-catalog/docs/reference/data-lineage/rest) ", "content": "## Limitations\nLineage is not supported for the following:\n- BigQuery Connector version 2 (data source API version 2 of Spark)\n- Spark streaming workload## Before you begin\n- In the Google Cloud console, on the project selector page, select the project that contains the Dataproc cluster for which you want to track lineage. [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- Enable Data Lineage API and Data Catalog API. [Enable the APIs](https://console.cloud.google.com/apis/enableflow?apiid=datalineage.googleapis.com,datacatalog.googleapis.com) ## Required roles\nTo get the permissions that you need to use data lineage in Dataproc,   ask your administrator to grant you the  following IAM roles on the Dataproc cluster VM service account:\n- View lineage visualization in Data Catalog or to use the Data Lineage API: [Data Lineage Viewer ](https://cloud.google.com/iam/docs/understanding-roles#datalineage.viewer) (`roles/datalineage.viewer`)\n- Produce lineage manually using the API: [Data Lineage Events Producer ](https://cloud.google.com/iam/docs/understanding-roles#datalineage.producer) (`roles/datalineage.producer`)\n- Edit lineage using the API: [Data Lineage Editor ](https://cloud.google.com/iam/docs/understanding-roles#datalineage.editor) (`roles/datalineage.editor`)\n- Perform all operations on lineage: [Data Lineage Administrator ](https://cloud.google.com/iam/docs/understanding-roles#datalineage.admin) (`roles/datalineage.admin`)\nFor more information about granting roles, see [Manage access](/iam/docs/granting-changing-revoking-access) .\nYou might also be able to get  the required permissions through [custom  roles](/iam/docs/creating-custom-roles) or other [predefined  roles](/iam/docs/understanding-roles) .\n## Enable data lineage in Dataproc\nEnable lineage at the cluster level, so that all submitted Spark jobs in the cluster report lineage information to the Data Lineage API.\n### Create a Dataproc cluster\n[Create a Dataproc cluster](/dataproc/docs/guides/create-cluster#creating_a_cloud_dataproc_cluster) with the property `dataproc:dataproc.lineage.enabled` set to `true` .\n**Note:** If you are using Dataproc image version 2.0, then set the cluster scope to `cloud-platform` .\n```\ngcloud dataproc clusters create CLUSTER_NAME \\--region REGION \\--zone ZONE \\--project PROJECT_ID \\--properties 'dataproc:dataproc.lineage.enabled=true' \\--scopes https://www.googleapis.com/auth/cloud-platform\n```\n### Submit a Spark job\nWhen you [submit a Spark job](/dataproc/docs/guides/submit-job#how_to_submit_a_job) on a Dataproc cluster that was created with lineage enabled, Dataproc captures and reports the lineage information to the Data Lineage API.\n```\ngcloud dataproc jobs submit spark \\--project PROJECT_ID \\--cluster=CLUSTER_NAME \\--region REGION \\--class CLASS \\--jars=gs://APPLICATION_BUCKET/spark-application.jar \\--properties=spark.openlineage.namespace=CUSTOM_NAMESPACE,spark.openlineage.appName=CUSTOM_APPNAME\n```\nThe properties `spark.openlineage.namespace` and `spark.openlineage.appName` are optional, and are used to uniquely identify the job. If you don't pass these properties, Dataproc uses the following default values:\n- Default value for`spark.openlineage.namespace`:\n- Default value for`spark.openlineage.appName`:`spark.app.name`\n### View lineage graphs in Dataplex\nA lineage visualization graph displays the relations between your project resources and the processes that created them. You can view data lineage information in the form of a graph visualization in the Google Cloud console, or retrieve it from the Data Lineage API in the form of JSON data.\nFor more information, see [View lineage graphs in Dataplex UI](/data-catalog/docs/how-to/lineage-gcp#view-lineage-graphs) .\n### Example\nConsider the following Spark job that reads data from a BigQuery table and writes to another BigQuery table:\n```\n#!/usr/bin/env pythonfrom pyspark.sql import SparkSessionimport sysspark = SparkSession \\\u00a0 .builder \\\u00a0 .appName('LINEAGE_BQ_TO_BQ') \\\u00a0 .getOrCreate()bucket = lineage-ol-testspark.conf.set('temporaryGcsBucket', bucket)source = sample.sourcewords = spark.read.format('bigquery') \\\u00a0 .option('table', source) \\\u00a0 .load()words.createOrReplaceTempView('words')word_count = spark.sql('SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word')destination = sample.destinationword_count.write.format('bigquery') \\\u00a0 .option('table', destination) \\\u00a0 .save()\n```\nThis Spark job creates the following lineage graph in the Dataplex UI:\n## Disable data lineage in Dataproc\nAfter you enable linage when you [create a cluster](#create-cluster) , you cannot disable lineage at the cluster level. To disable lineage in a Dataproc cluster, recreate the cluster without the `dataproc:dataproc.lineage.enabled` property.\nTo disable lineage for a particular job on a cluster that was created with lineage enabled, you must pass the `spark.extraListeners` property with empty value when submitting the job.\n## What's next\n- Learn more about [data lineage](/data-catalog/docs/concepts/about-data-lineage) .", "guide": "Dataproc"}