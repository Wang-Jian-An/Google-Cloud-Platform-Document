{"title": "Dataproc - Dataproc best practices for production", "url": "https://cloud.google.com/dataproc/docs/guides/dataproc-best-practices", "abstract": "# Dataproc - Dataproc best practices for production\nThis document discusses Dataproc best practices that can help you run reliable, efficient, and insightful data processing jobs on Dataproc clusters in production environments.\n", "content": "## Specify cluster image versions\nDataproc uses [image versions](/dataproc/docs/concepts/versioning/dataproc-versions) to bundle operating system, big data [components](/dataproc/docs/concepts/components/overview) , and Google Cloud connectors into a package that is deployed on a cluster. If you don't specify an image version when creating a cluster, Dataproc defaults to the most recent stable image version.\nFor production environments, associate your cluster with a specific `major.minor` Dataproc image version, as shown in the following gcloud CLI command.\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--image-version=2.0\n```\nDataproc resolves the `major.minor` version to the latest sub-minor version version ( `2.0` is resolved to `2.0.x` ). Note: if you need to rely on a specific sub-minor version for your cluster, you can specify it: for example, `--image-version=2.0.x` . See [How versioning works](/dataproc/docs/concepts/versioning/overview#how_versioning_works) for more information.\nEach supported minor image version page, such as [2.0.x release versions](/dataproc/docs/concepts/versioning/dataproc-release-2.0) , lists the component versions available with the current and previous four sub-minor image releases.\n### Dataproc preview image versions\nNew minor versions of Dataproc images are available in a `preview` version prior to release in the standard minor image version track. Use a preview image to test and validate your jobs against a new minor image version prior to adopting the standard minor image version in production. See [Dataproc versioning](/dataproc/docs/concepts/versioning/overview) for more information.\n## Use custom images when necessary\nIf you have dependencies to add to the cluster, such as native Python libraries, or security hardening or virus protection software, [create a custom image](/dataproc/docs/guides/dataproc-images) from the **latest image** in your target minor image version track. This practice allows you to meet dependency requirements when you create clusters using your custom image. When you rebuild your custom image to update dependency requirements, use the latest available sub-minor image version within the minor image track.\n## Submit jobs to the Dataproc service\nSubmit jobs to the Dataproc service with a [jobs.submit](/dataproc/docs/reference/rest/v1/projects.regions.jobs/submit) call using the [gcloud CLI](/sdk/gcloud/reference/dataproc/jobs/submit) or the Google Cloud console. Set job and cluster permissions by granting [Dataproc roles](/dataproc/docs/concepts/iam/iam#roles) . Use custom roles to separate cluster access from job submit permissions.\nBenefits of submitting jobs to the Dataproc service:\n- No complicated networking settings required - the API is widely reachable\n- Easy to manage IAM permissions and roles\n- Track job status easily - no Dataproc job metadata to complicate results.\nIn production, run jobs that only depend on cluster-level dependencies at a fixed minor image version, (for example, `--image-version=2.0` ). Bundle dependencies with jobs when the jobs are submitted. Submitting an [uber jar](https://imagej.net/Uber-JAR) to Spark or MapReduce is a common way to do this.\n- Example: If a job jar depends on`args4j`and`spark-sql`, with`args4j`specific to the job and`spark-sql`a cluster-level dependency, bundle`args4j`in the job's uber jar.## Control initialization action locations\n[Initialization actions](/dataproc/docs/concepts/configuring-clusters/init-actions) allow you to automatically run scripts or install components when you create a Dataproc cluster (see the [dataproc-initialization-actions](https://github.com/GoogleCloudPlatform/dataproc-initialization-actions) GitHub repository for common Dataproc initialization actions). When using cluster initialization actions in a production environment, copy initialization scripts to Cloud Storage rather than sourcing them from a public repository. This practice avoids running initialization scripts that are subject to modification by others.\n## Monitor Dataproc release notes\nDataproc regularly releases new sub-minor image versions. View or subscribe to [Dataproc release notes](/dataproc/docs/release-notes) to be aware of the latest Dataproc image version releases and other announcements, changes, and fixes.\n## View the staging bucket to investigate failures\n- Look at your cluster's [staging bucket](/dataproc/docs/concepts/configuring-clusters/staging-bucket) to investigate cluster and job error messages. Typically, the staging bucket Cloud Storage location is shown in error messages, as shown in the **bold** text in the following sample error message:```\nERROR:\n(gcloud.dataproc.clusters.create) Operation ... failed:\n...\n- Initialization action failed. Failed action ... see output in: \ngs://dataproc-<BUCKETID>-us-central1/google-cloud-dataproc-metainfo/CLUSTERID/<CLUSTER_ID>\\dataproc-initialization-script-0_output\n \n```\n- Use `gsutil` to view staging bucket contents:```\ngsutil cat gs://STAGING_BUCKET\n```Sample output:```\n+ readonly RANGER_VERSION=1.2.0\n... Ranger admin password not set. Please use metadata flag - default-password\n```## Get support\nGoogle Cloud supports your production OSS workloads and helps you meet your business SLAs through [tiers of support](/support) . Also, Google Cloud [Consulting Services](/consulting) can provide guidance on best practices for your team's production deployments.\n## For more information\n- Read the Google Cloud blog [Dataproc best practices guide](https://cloud.google.com/blog/topics/developers-practitioners/dataproc-best-practices-guide) .\n- View [Democratizing Dataproc](https://www.youtube.com/watch?v=2ksD7udWFys) on YouTube.", "guide": "Dataproc"}