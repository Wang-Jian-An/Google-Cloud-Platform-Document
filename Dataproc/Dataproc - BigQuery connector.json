{"title": "Dataproc - BigQuery connector", "url": "https://cloud.google.com/dataproc/docs/concepts/connectors/bigquery", "abstract": "# Dataproc - BigQuery connector\nYou can use a BigQuery connector to enable programmatic read/write access to [BigQuery](/bigquery) . This is an ideal way to process data that is stored in BigQuery. Command-line access is not exposed. The BigQuery connector is a library that enables Spark and Hadoop applications to process data from BigQuery and write data to BigQuery using its native terminology.\nThe [GoogleCloudDataproc/spark-bigquery-connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) is also available for reading data from BigQuery. It takes advantage of the [BigQueryStorage API](/bigquery/docs/reference/storage) .\n", "content": "## Pricing considerations\nWhen using the connector, charges include [BigQuery usage fees](/bigquery/pricing) . The following service-specific charges may also apply:\n- [Cloud Storage](/storage) - the connector downloads data into a Cloud Storage bucket before or during job execution. After the job successfully completes, the data is deleted from Cloud Storage. You are charged for this storage according to [Cloud Storage pricing](/storage/pricing) . To avoid excess charges, check your Cloud Storage account and remove unneeded temporary files.\n- [BigQuery Storage API](/bigquery/docs/reference/storage) - to achieve better performance, the connector reads data using the BigQuery Storage API. You are charged for this usage according to [BigQuery Storage API pricing](/bigquery/pricing#storage-api) .## Available connectors\nThe following BigQuery connectors are available for use in the Hadoop ecosystem:\n- The [Spark BigQuery Connector](https://github.com/GoogleCloudDataproc/spark-bigquery-connector) adds a Spark data source, which allows DataFrames to interact directly with BigQuery tables using Spark's`read`and`write`operations.\n- The [Hive BigQuery Connector](https://github.com/GoogleCloudDataproc/hive-bigquery-connector) adds a Storage Handler, which allows Apache Hive to interact directly with BigQuery tables using HiveQL syntax.\n- The [Hadoop BigQuery Connector](https://github.com/GoogleCloudDataproc/hadoop-connectors) allows Hadoop mappers and reducers to interact with BigQuery tables using abstracted versions of the [InputFormat](http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/InputFormat.html) and [OutputFormat](http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/OutputFormat.html) classes.## Using the connectors\nFor a quick start using the BigQuery connector, see the following examples:\n- [Spark example](/dataproc/docs/tutorials/bigquery-connector-spark-example) \n- [Java MapReduce example](/dataproc/docs/tutorials/bigquery-connector-mapreduce-example) \n- [Connect Dataproc cluster to BigQuery](https://console.cloud.google.com/?walkthrough_id=dataproc--dataproc-bq-spark-connector) ## What's next\n- Learn more about [BigQuery](/bigquery) \n- Follow the [BigQuery example for Spark](/dataproc/docs/tutorials/bigquery-connector-spark-example) \n- Learn more about the [Hive BigQuery Connector]() \n- Follow the [BigQuery example for Java MapReduce](/dataproc/docs/tutorials/bigquery-connector-mapreduce-example)", "guide": "Dataproc"}