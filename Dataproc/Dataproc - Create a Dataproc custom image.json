{"title": "Dataproc - Create a Dataproc custom image", "url": "https://cloud.google.com/dataproc/docs/guides/dataproc-images", "abstract": "# Dataproc - Create a Dataproc custom image\nDataproc clusters can be provisioned with a [custom image](/compute/docs/images#custom_images) that includes a user's pre-installed packages. The following steps explain how to create a custom image and install it on a Dataproc cluster.\n**Using hosted custom images:** If you use a custom image hosted in another project, the [Dataproc Service Agent service account](/dataproc/docs/concepts/configuring-clusters/service-accounts#service_agent_account) in your project must have`compute.images.get`permission on the image in the host project. You can do this by granting the [roles/compute.imageUser](/compute/docs/access/iam#compute.imageUser) role on the hosted image to your project's Dataproc Service Agent service account (see [Sharing custom images within an organization)](/compute/docs/images/managing-access-custom-images#share-images-within-organization) .\nNotes:\n- The instructions in this document apply to **Linux operating\nsystems only** . Other operating systems may be supported in future Dataproc [releases](/dataproc/docs/release-notes) .\n- Custom image builds require starting from a Dataproc base image ( [Debian, Rocky Linux, and Ubuntu base images](/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions) are supported). **Custom image limitation:** New images announced in [Dataproc Release Notes](/dataproc/docs/release-notes) are not available for use as the base for custom images until one week from their announcement date.\n- **Using optional components** : By default, custom images inherit all of the [Dataproc optional components](/dataproc/docs/concepts/components/overview#available_optional_components) (OS packages and configs) from their base images, You can customize the default OS package versions and configs, but you must specify the optional component name when you create your cluster (for example, by running the`gcloud dataproc clusters create --optional-components=` ``command\u2014see [Adding optional components](/dataproc/docs/concepts/components/overview#adding_optional_components) ). If the component name is not specified when you create the cluster, the component (including any custom OS packages and configs) will be deleted.To help ensure that clusters receive the latest service updates and bug fixes, the creation of clusters with a custom image is limited to **365 days** from the image creation date (existing custom-image clusters can run indefinitely). Automation to continuously build a custom image may be necessary if you want to create clusters with a custom image for a period greater than 365 days (see [How to create a cluster with an expired custom image](#how_to_create_a_cluster_with_an_expired_custom_image) for additional information).", "content": "## Before you begin\n### Set up your project\n- [Install Python 3.11+](https://www.python.org/downloads/) \n- Prepare a customization script that installs custom packages and/or  updates configurations, for example:```\n #! /usr/bin/bash\n apt-get -y update\n apt-get install python-dev\n apt-get install python-pip\n pip install numpy\n \n```### Create a Cloud Storage bucket in your project\n- In the Google Cloud console, go to the Cloud Storage **Buckets** page. [Go to Buckets page](https://console.cloud.google.com/storage/browser) \n- Click **Create bucket** .\n- On the **Create a bucket** page, enter your bucket information. To go to the next step, click **Continue** .- For **Name your bucket** , enter a name that meets the [bucket naming requirements](/storage/docs/bucket-naming#requirements) .\n- For **Choose where to store your data** , do the following:- Select a **Location type** option.\n- Select a **Location** option.\n- For **Choose a default storage class for your data** , select a [storage class](/storage/docs/storage-classes) .\n- For **Choose how to control access to objects** , select an **Access control** option.\n- For **Advanced settings (optional)** , specify  an [encryption method](/storage/docs/encryption) ,  a [retention policy](/storage/docs/bucket-lock) ,  or [bucket labels](/storage/docs/tags-and-labels#bucket-labels) .\n- Click **Create** .\n## Generate a custom image\nYou will use [generate_custom_image.py](https://github.com/GoogleCloudDataproc/custom-images/blob/master/generate_custom_image.py) , a Python program to create a Dataproc custom image.\n### How it works\nThe `generate_custom_image.py` program launches a temporary Compute Engine VM instance with the specified Dataproc base image, then runs the customization script inside the VM instance to install custom packages and/or update configurations. After the customization script finishes, it shuts down the VM instance and creates a Dataproc custom image from the disk of the VM instance. The temporary VM is deleted after the custom image is created. The custom image is saved and can be used to [create Dataproc clusters](#using_a_custom_image) .\nThe `generate_custom_image.py` program uses gcloud CLI to run multi-step workflows on Compute Engine.\nYou will incur Google Cloud charges for the temporary Compute Engine VM and your Cloud Storage bucket. See the [Google Cloud Pricing Calculator](/products/calculator) .\n### Run the code\nFork or clone the files on GitHub at [Dataproc custom images](https://github.com/GoogleCloudDataproc/custom-images) . Then, run the `generate_custom_image.py` program to have Dataproc generate and save your custom image.\n```\npython3 generate_custom_image.py \\\n\u00a0\u00a0\u00a0\u00a0--image-name=CUSTOM_IMAGE_NAME \\\n\u00a0\u00a0\u00a0\u00a0[--family=CUSTOM_IMAGE_FAMILY_NAME] \\\n\u00a0\u00a0\u00a0\u00a0--dataproc-version=IMAGE_VERSION \\\n\u00a0\u00a0\u00a0\u00a0--customization-script=LOCAL_PATH \\\n\u00a0\u00a0\u00a0\u00a0--zone=ZONE \\\n\u00a0\u00a0\u00a0\u00a0--gcs-bucket=gs://BUCKET_NAME \\ \u00a0\u00a0\u00a0\u00a0[--no-smoke-test]\n```\n**Required flags**\n- `--image-name`: the output name for your custom image. **Note:** the image name must match regex`[a-z](?:[-a-z0-9]{0,61}[a-z0-9])`\u2014 for example, no underscores or spaces, less than 64 characters.\n- `--dataproc-version`: the [Dataproc image version](/dataproc/docs/concepts/versioning/dataproc-versions#supported_dataproc_versions) to use in your custom image. Specify the version in \"x.y.z-os\" or \"x.y.z-rc-os\" format, for example, \"2.0.69-debian10\". **Custom image limitation:** New images announced in [Dataproc Release Notes](/dataproc/docs/release-notes) are not available for use as the base for custom images until one week from their announcement date.\n- `--customization-script`: a local path to your script that the tool will run to install your custom packages or perform other customizations. Note that this script is only run on the temporary VM used to create the custom image. You can specify a different initialization script for any other initialization actions you want to perform when you [create a cluster with your custom image](#using_a_custom_image) .\n- `--zone`: the [Compute Engine zone](/compute/docs/regions-zones#available) where`generate_custom_image.py`will create a temporary VM to use to create your custom image.\n- `--gcs-bucket`: a URI, in the format`gs://` ``, which points to the Cloud Storage bucket that you created in [Create a Cloud Storage bucket in your project](#create_a_cloud_storage_bucket_in_your_project) .`generate_custom_image.py`will write log files to this bucket.\n**Optional flags**\n- `--family`: the image family for the image. Image families are used to group similar images together, and can be used when creating a cluster as a pointer to the most recent image in the family. For example, \"custom-1-5-debian10\".\n- `--no-smoke-test`: This is an optional flag that disables smoke testing the newly built custom image. The smoke test creates a Dataproc test cluster with the newly built image, runs a small job, and then deletes the cluster at the end of the test. The smoke test runs by default to verify that the newly built custom image can create a functional Dataproc cluster. Disabling this step by using the`--no-smoke-test`flag will speed up the custom image build process, but its use is not recommended.\n- `--subnet`: The subnetwork to use to create the VM that builds the custom Dataproc image. If your project is part of a [shared VPC](/vpc/docs/shared-vpc) , you must specify the full subnetwork URL in the following format:`projects/` `` `/regions/` `` `/subnetworks/` ``.\nFor a listing of additional optional flags, see [Optional Arguments](https://github.com/GoogleCloudDataproc/custom-images#optional-arguments) on GitHub.\nIf `generate_custom_image.py` is successful, the `imageURI` of the custom image will be listed in the terminal window output (the full `imageUri` is shown in **bold** below):\n```\n...\nmanagedCluster:\n clusterName: verify-image-20180614213641-8308a4cd\n config:\n  gceClusterConfig:\n  zoneUri: ZONE\n  masterConfig:\n  imageUri: https://www.googleapis.com/compute/beta/projects/PROJECT_ID/global/images/CUSTOM_IMAGE_NAME\n...\nINFO:__main__:Successfully built Dataproc custom image: CUSTOM_IMAGE_NAME\nINFO:__main__:\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n###\n WARNING: DATAPROC CUSTOM IMAGE 'CUSTOM_IMAGE_NAME'\n   WILL EXPIRE ON 2018-07-14 21:35:44.133000.\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n##\n###\n```\n**Confirm image creation in the Google Cloud console** . Your custom image will be listed in the Google Cloud console [Images](https://console.cloud.google.com/compute/images) page.\n### Custom image version labels for advanced users\nWhen using Dataproc's standard custom image tool, the tool automatically sets a required `goog-dataproc-version` label on the created custom image. The label reflects the feature capabilities and protocols used by Dataproc to manage the software on the image.\n**Note:** If a **base image** does not have the `goog-dataproc-version` label, it is not considered finalized, and a different base image must be used to create the custom image.\nAdvanced users who using their own process to create a custom Dataproc image must add the label manually to their custom image, as follows:\n- Extract the `goog-dataproc-version` label from the base Dataproc image used to create the custom image.```\ngcloud compute images describe ${BASE_DATAPROC_IMAGE} \\\n\u00a0\u00a0\u00a0\u00a0--project cloud-dataproc \\\n\u00a0\u00a0\u00a0\u00a0--format=\"value(labels.goog-dataproc-version)\"\n```\n- Set the label on the custom image.```\ngcloud compute images add-labels IMAGE_NAME --labels=[KEY=VALUE,...]\n```## Use a custom image\nYou specify the custom image when you create a Dataproc cluster. A custom image is saved in [Cloud Compute Images](/compute/docs/images#custom_images) , and is valid to create a Dataproc cluster for 365 days from its creation date (see [How to create a cluster with an expired custom image](#how_to_create_a_cluster_with_an_expired_custom_image) to use a custom image after its 365-day expiration date).\n### Custom image URI\nYou pass the `imageUri` of the custom image to the cluster create operation. This URI can be specified in one of three ways:\n- Full URI:`https://www.googleapis.com/compute/beta/projects/` `` `/global/images/` ``\n- Partial URI:`projects/` `` `/global/images/` ``\n- Short name:\nCustom images can also be specified by their family URI, which always chooses the most recent image within the image family.\n- Full URI:`https://www.googleapis.com/compute/beta/projects/` `` `/global/images/family/` ``\n- Partial URI:`projects/` `` `/global/images/family/` ``Run the following `gcloud` command to list the names of your custom images:\n```\ngcloud compute images list\n```\nPass the name of your custom image to the following `gcloud` command to list the URI ( `selfLink` ) of your custom image:\n```\ngcloud compute images describe custom-image-name\n```\n```\n...\nname: CUSTOM_IMAGE_NAME\nselfLink: https://www.googleapis.com/compute/v1/projects/PROJECT_ID/global/images/CUSTOM_IMAGE_NAME\n...\n```\n- Open the [Compute Engine\u2192Images](https://console.cloud.google.com/compute/images) page in the Google Cloud console and click the image name.  You can insert a query in the filter-images text box to limit the number  of displayed images.\n- The Images details page opens. Click **Equivalent REST** .\n- The REST response lists additional information about the image, including  the`selfLink`, which is the image URI.```\n{\n ...\n \"name\": \"my-custom-image\",\n \"selfLink\": \"projects/PROJECT_ID/global/images/CUSTOM_IMAGE_NAME\",\n \"sourceDisk\": ...,\n ...\n}\n```\n### Create a cluster with a custom image\nYou can [create a cluster](/dataproc/docs/guides/create-cluster) with master and worker nodes that use a custom image with the `gcloud` command-line tool, the Dataproc API, or the Google Cloud console.\nYou can create a Dataproc cluster with a custom image using the\n [dataproc clusters create command](/sdk/gcloud/reference/dataproc/clusters/create) \nwith the\n`--image`\nflag.\n **Example:** \n```\ngcloud dataproc clusters create CLUSTER-NAME \\\n\u00a0\u00a0\u00a0\u00a0--image=CUSTOM_IMAGE_URI \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0... other flags ...\n```\nYou can create a cluster with a custom image by specifying custom image URI in the\n [InstanceGroupConfig.imageUri](/dataproc/docs/reference/rest/v1/ClusterConfig#InstanceGroupConfig) \nfield in the\n`masterConfig`\n,\n`workerConfig`\n, and, if applicable,\n`secondaryWorkerConfig`\nobject included in a\n [cluster.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) \nAPI request.\n **Example:** REST request to create a standard  Dataproc cluster (one master, two worker nodes) with a custom  image.\n```\nPOST /v1/projects/PROJECT_ID/regions/REGION/clusters/\n{\n \"clusterName\": \"CLUSTER_NAME\",\n \"config\": {\n \"masterConfig\": {\n  \"imageUri\": \"projects/PROJECT_ID/global/images/CUSTOM_IMAGE_NAME\"\n },\n \"workerConfig\": {\n  \"imageUri\": \"projects/PROJECT_ID/global/images/CUSTOM_IMAGE_NAME\"\n }\n }\n}\n \n```\n- In the Google Cloud console, open the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page. The Set up cluster panel is selected.\n- In the Versioning section, click CHANGE.  Select the CUSTOM IMAGE tab, choose the custom image to use  for your Dataproc cluster, then click SELECT.\nWhen you submit the **Create a cluster** form, your cluster's VMs will be provisioned with the selected custom image.\n### Override Dataproc cluster properties with a custom image\nYou can use custom images to overwrite any [cluster properties](/dataproc/docs/concepts/configuring-clusters/cluster-properties) set during cluster creation. If a user creates a cluster with your custom image but sets cluster properties different from those you set with your custom image, your custom image cluster property settings will take precedence.\nTo set cluster properties with your custom image:\n- In your custom image [customization script](/dataproc/docs/guides/dataproc-images#running_the_code) , create a`dataproc.custom.properties`file in`/etc/google-dataproc`, then set cluster property values in the file.- Sample`dataproc.custom.properties`file contents:```\ndataproc.conscrypt.provider.enable=VALUE\ndataproc.logging.stackdriver.enable=VALUE\n```Sample customization script file-creation snippet to override two  cluster properties:\n```\n  cat <<EOF >/etc/google-dataproc/dataproc.custom.properties\n  dataproc.conscrypt.provider.enable=true\n  dataproc.logging.stackdriver.enable=false\n  EOF\n```### How to create a cluster with an expired custom image\nDataproc cannot guarantee support of issues that arise with clusters created with expired custom images.\nBy default, custom images expire 365 days from the date of creation of the image. You can create a cluster that uses an expired custom image by completing the following steps.\n- Attempt to create a Dataproc cluster with an expired custom image or a custom image that will expire within 10 days.```\ngcloud dataproc clusters create CLUSTER-NAME \\\n\u00a0\u00a0\u00a0\u00a0--image=CUSTOM-IMAGE-NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0... other flags ...\n```\n- The gcloud CLI will issue an error message that includes the cluster `dataproc:dataproc.custom.image.expiration.token` property name and token value.```\ndataproc:dataproc.custom.image.expiration.token=TOKEN_VALUE\n```Copy the \"token value\" string to the clipboard.\n- Use the gcloud CLI to create the Dataproc cluster again, adding the \"token value\" copied above as a cluster property.```\ngcloud dataproc clusters create CLUSTER-NAME \\\n\u00a0\u00a0\u00a0\u00a0--image=CUSTOM-IMAGE-NAME \\\n\u00a0\u00a0\u00a0\u00a0--properties=dataproc:dataproc.custom.image.expiration.token=TOKEN_VALUE \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0... other flags ...\n```\nCluster creation with the custom image should succeed.", "guide": "Dataproc"}