{"title": "Dataproc - Create a cluster", "url": "https://cloud.google.com/dataproc/docs/guides/create-cluster", "abstract": "# Dataproc - Create a cluster\nDataproc prevents the creation of clusters with image versions prior to 1.3.95, 1.4.77, 1.5.53, and 2.0.27, which were affected by [Apache Log4j security vulnerabilities](https://logging.apache.org/log4j/2.x/security.html) . Dataproc also prevents cluster creation for Dataproc image versions 0.x, 1.0.x, 1.1.x, and 1.2.x. Dataproc advises that, when possible, you create Dataproc clusters with the latest sub-minor image versions.| Image version         | log4j version | Customer guidance |\n|:-----------------------------------------------|:----------------|:---------------------|\n| 2.0.29, 1.5.55, and 1.4.79, or later of each | log4j.2.17.1 | Advised    |\n| 2.0.28, 1.5.54, and 1.4.78      | log4j.2.17.0 | Advised    |\n| 2.0.27, 1.5.53, and 1.4.77      | log4j.2.16.0 | Strongly recommended |\n| 2.0.26, 1.5.52, and 1.4.76, or earlier of each | Older version | Discontinue use  |See the [Dataproc release notes](/dataproc/docs/release-notes) for specific image and `log4j` update information.\n", "content": "## How to create a Dataproc cluster\nRequirements:\n- **Name:** The cluster name must start with a lowercase letter followed by up to 51 lowercase letters, numbers, and hyphens, and cannot end with a hyphen. [](None) \n- **Cluster region:** You must specify a Compute Engine region for the cluster, such as `us-east1` or `europe-west1` , to isolate cluster resources, such as VM instances and cluster metadata stored in Cloud Storage, within the region.- See [Regional endpoints](/dataproc/docs/concepts/regional-endpoints) for more information on regional endpoints.\n- See [Available regions & zones](/compute/docs/regions-zones/regions-zones#available) for information on selecting a region. You can also run the`gcloud compute regions list`command to display a listing of available regions.\n- **Connectivity:**  [Compute Engine Virtual Machine instances](/compute/docs/instances) (VMs) in a Dataproc cluster, consisting of master and worker VMs, require full internal IP networking cross connectivity. The [default VPC network](/vpc/docs/vpc#default-network) provides this connectivity (see [Dataproc Cluster Network Configuration](/dataproc/docs/concepts/network) ).\nAlso see:- [The Dataproc best practices guide.](/blog/topics/developers-practitioners/dataproc-best-practices-guide) \n- [Create a cluster with an ARM machine type](/dataproc/docs/concepts/compute/supported-machine-types#create_a_cluster_with_an_arm_machine_type) .\nTo create a Dataproc cluster on the command line, run the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command locally in a terminal window or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) .\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```\nThe command creates a cluster with default Dataproc service settings for your master and worker virtual machine instances, disk sizes and types, network type, region and zone where your cluster is deployed, and other cluster settings. See the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command for information on using command line flags to customize cluster settings.\n### Create a cluster with a YAML file- Run the following`gcloud`command to export the configuration of an existing Dataproc cluster into a`cluster.yaml`file.```\ngcloud dataproc clusters export EXISTING_CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--destination=cluster.yaml\n```\n- Create a new cluster by importing the YAML file configuration.```\ngcloud dataproc clusters import NEW_CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--source=cluster.yaml\n```\n **Note:** During the export operation, cluster-specific fields, such as cluster name, output-only fields, and automatically applied labels are filtered. These fields are disallowed in the imported YAML file used to create a cluster.\n **Note:** You can click the ** Equivalent REST\nor command line** links at the bottom of the left panel on the Dataproc Google Cloud console [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page to have the Console construct an equivalent API REST request or`gcloud`tool command to use in your code or from the command line to create a cluster.This section shows how to create a cluster with required values and the default configuration (1 master, 2 workers).\nBefore using any of the request data, make the following replacements:- : Google Cloud project ID\n- : [cluster region](/dataproc/docs/guides/create-cluster#cluster-region) \n- : cluster name\nHTTP method and URL:\n```\nPOST https://dataproc.googleapis.com/v1/projects/project-id/regions/region/clusters\n```\nRequest JSON body:\n```\n{\n \"clusterName\": \"cluster-name\",\n \"config\": {}\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n\"name\": \"projects/project-id/regions/region/operations/b5706e31......\",\n \"metadata\": {\n \"@type\": \"type.googleapis.com/google.cloud.dataproc.v1.ClusterOperationMetadata\",\n \"clusterName\": \"cluster-name\",\n \"clusterUuid\": \"5fe882b2-...\",\n \"status\": {\n  \"state\": \"PENDING\",\n  \"innerState\": \"PENDING\",\n  \"stateStartTime\": \"2019-11-21T00:37:56.220Z\"\n },\n \"operationType\": \"CREATE\",\n \"description\": \"Create cluster with 2 workers\",\n \"warnings\": [  \"For PD-Standard without local SSDs, we strongly recommend provisioning 1TB ...\"\"\n ]\n }\n}\n```\n **Note:** You can click the ** Equivalent REST\nor command line** links at the bottom of the left panel of the Dataproc Google Cloud console [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page to have the Console construct an equivalent API REST request or`gcloud`tool command to use in your code or from the command line to create a cluster.Open the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console in your browser, then click **Create** in the cluster on **Compute engine** row in the **Create a Dataproc cluster on Compute Engine** page. The Set up cluster panel is selected with fields filled in with default values. You can select each panel and confirm or change default values to customize your cluster.\nClick **Create** to create the cluster. The cluster name appears in the **Clusters** page, and its status is updated to Running after the cluster is provisioned. Click the cluster name to open the cluster details page where you can examine jobs, instances, and configuration settings for your cluster and connect to web interfaces running on your cluster.\n- [Install the client library.](/dataproc/docs/reference/libraries#installing_the_client_library) \n- [Set up application default credentials.](/dataproc/docs/reference/libraries#setting_up_authentication) \n- Run the code.See [Setting up your development environment](/go/docs/setup) . [  dataproc/create_cluster.go ](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/dataproc/create_cluster.go) [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/dataproc/create_cluster.go) ```\nimport (\u00a0 \u00a0 \u00a0 \u00a0 \"context\"\u00a0 \u00a0 \u00a0 \u00a0 \"fmt\"\u00a0 \u00a0 \u00a0 \u00a0 \"io\"\u00a0 \u00a0 \u00a0 \u00a0 dataproc \"cloud.google.com/go/dataproc/apiv1\"\u00a0 \u00a0 \u00a0 \u00a0 \"cloud.google.com/go/dataproc/apiv1/dataprocpb\"\u00a0 \u00a0 \u00a0 \u00a0 \"google.golang.org/api/option\")func createCluster(w io.Writer, projectID, region, clusterName string) error {\u00a0 \u00a0 \u00a0 \u00a0 // projectID := \"your-project-id\"\u00a0 \u00a0 \u00a0 \u00a0 // region := \"us-central1\"\u00a0 \u00a0 \u00a0 \u00a0 // clusterName := \"your-cluster\"\u00a0 \u00a0 \u00a0 \u00a0 ctx := context.Background()\u00a0 \u00a0 \u00a0 \u00a0 // Create the cluster client.\u00a0 \u00a0 \u00a0 \u00a0 endpoint := region + \"-dataproc.googleapis.com:443\"\u00a0 \u00a0 \u00a0 \u00a0 clusterClient, err := dataproc.NewClusterControllerClient(ctx, option.WithEndpoint(endpoint))\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"dataproc.NewClusterControllerClient: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 defer clusterClient.Close()\u00a0 \u00a0 \u00a0 \u00a0 // Create the cluster config.\u00a0 \u00a0 \u00a0 \u00a0 req := &dataprocpb.CreateClusterRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ProjectId: projectID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Region: \u00a0 \u00a0region,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Cluster: &dataprocpb.Cluster{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ProjectId: \u00a0 projectID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ClusterName: clusterName,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Config: &dataprocpb.ClusterConfig{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MasterConfig: &dataprocpb.InstanceGroupConfig{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 NumInstances: \u00a0 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MachineTypeUri: \"n1-standard-2\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 WorkerConfig: &dataprocpb.InstanceGroupConfig{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 NumInstances: \u00a0 2,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MachineTypeUri: \"n1-standard-2\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 // Create the cluster.\u00a0 \u00a0 \u00a0 \u00a0 op, err := clusterClient.CreateCluster(ctx, req)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"CreateCluster: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 resp, err := op.Wait(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"CreateCluster.Wait: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 // Output a success message.\u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Cluster created successfully: %s\", resp.ClusterName)\u00a0 \u00a0 \u00a0 \u00a0 return nil}\n```\n- [Install the client library.](/dataproc/docs/reference/libraries#installing_the_client_library) \n- [Set up application default credentials.](/dataproc/docs/reference/libraries#setting_up_authentication) \n- Run the code.See [Setting Up a Java Development Environment](/java/docs/setup) . [  dataproc/src/main/java/CreateCluster.java ](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/dataproc/src/main/java/CreateCluster.java) [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/dataproc/src/main/java/CreateCluster.java) ```\nimport com.google.api.gax.longrunning.OperationFuture;import com.google.cloud.dataproc.v1.Cluster;import com.google.cloud.dataproc.v1.ClusterConfig;import com.google.cloud.dataproc.v1.ClusterControllerClient;import com.google.cloud.dataproc.v1.ClusterControllerSettings;import com.google.cloud.dataproc.v1.ClusterOperationMetadata;import com.google.cloud.dataproc.v1.InstanceGroupConfig;import java.io.IOException;import java.util.concurrent.ExecutionException;public class CreateCluster {\u00a0 public static void createCluster() throws IOException, InterruptedException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String projectId = \"your-project-id\";\u00a0 \u00a0 String region = \"your-project-region\";\u00a0 \u00a0 String clusterName = \"your-cluster-name\";\u00a0 \u00a0 createCluster(projectId, region, clusterName);\u00a0 }\u00a0 public static void createCluster(String projectId, String region, String clusterName)\u00a0 \u00a0 \u00a0 throws IOException, InterruptedException {\u00a0 \u00a0 String myEndpoint = String.format(\"%s-dataproc.googleapis.com:443\", region);\u00a0 \u00a0 // Configure the settings for the cluster controller client.\u00a0 \u00a0 ClusterControllerSettings clusterControllerSettings =\u00a0 \u00a0 \u00a0 \u00a0 ClusterControllerSettings.newBuilder().setEndpoint(myEndpoint).build();\u00a0 \u00a0 // Create a cluster controller client with the configured settings. The client only needs to be\u00a0 \u00a0 // created once and can be reused for multiple requests. Using a try-with-resources\u00a0 \u00a0 // closes the client, but this can also be done manually with the .close() method.\u00a0 \u00a0 try (ClusterControllerClient clusterControllerClient =\u00a0 \u00a0 \u00a0 \u00a0 ClusterControllerClient.create(clusterControllerSettings)) {\u00a0 \u00a0 \u00a0 // Configure the settings for our cluster.\u00a0 \u00a0 \u00a0 InstanceGroupConfig masterConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 InstanceGroupConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMachineTypeUri(\"n1-standard-2\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setNumInstances(1)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 InstanceGroupConfig workerConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 InstanceGroupConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMachineTypeUri(\"n1-standard-2\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setNumInstances(2)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 ClusterConfig clusterConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ClusterConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMasterConfig(masterConfig)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setWorkerConfig(workerConfig)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // Create the cluster object with the desired cluster config.\u00a0 \u00a0 \u00a0 Cluster cluster =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Cluster.newBuilder().setClusterName(clusterName).setConfig(clusterConfig).build();\u00a0 \u00a0 \u00a0 // Create the Cloud Dataproc cluster.\u00a0 \u00a0 \u00a0 OperationFuture<Cluster, ClusterOperationMetadata> createClusterAsyncRequest =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 clusterControllerClient.createClusterAsync(projectId, region, cluster);\u00a0 \u00a0 \u00a0 Cluster response = createClusterAsyncRequest.get();\u00a0 \u00a0 \u00a0 // Print out a success message.\u00a0 \u00a0 \u00a0 System.out.printf(\"Cluster created successfully: %s\", response.getClusterName());\u00a0 \u00a0 } catch (ExecutionException e) {\u00a0 \u00a0 \u00a0 System.err.println(String.format(\"Error executing createCluster: %s \", e.getMessage()));\u00a0 \u00a0 }\u00a0 }}\n```\n- [Install the client library.](/dataproc/docs/reference/libraries#installing_the_client_library) \n- [Set up application default credentials.](/dataproc/docs/reference/libraries#setting_up_authentication) \n- Run the code.See [Setting up a Node.js development environment](/nodejs/docs/setup) . [  dataproc/createCluster.js ](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/dataproc/createCluster.js) [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/dataproc/createCluster.js) ```\nconst dataproc = require('@google-cloud/dataproc');// TODO(developer): Uncomment and set the following variables// projectId = 'YOUR_PROJECT_ID'// region = 'YOUR_CLUSTER_REGION'// clusterName = 'YOUR_CLUSTER_NAME'// Create a client with the endpoint set to the desired cluster regionconst client = new dataproc.v1.ClusterControllerClient({\u00a0 apiEndpoint: `${region}-dataproc.googleapis.com`,\u00a0 projectId: projectId,});async function createCluster() {\u00a0 // Create the cluster config\u00a0 const request = {\u00a0 \u00a0 projectId: projectId,\u00a0 \u00a0 region: region,\u00a0 \u00a0 cluster: {\u00a0 \u00a0 \u00a0 clusterName: clusterName,\u00a0 \u00a0 \u00a0 config: {\u00a0 \u00a0 \u00a0 \u00a0 masterConfig: {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 numInstances: 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 machineTypeUri: 'n1-standard-2',\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 workerConfig: {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 numInstances: 2,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 machineTypeUri: 'n1-standard-2',\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 },\u00a0 };\u00a0 // Create the cluster\u00a0 const [operation] = await client.createCluster(request);\u00a0 const [response] = await operation.promise();\u00a0 // Output a success message\u00a0 console.log(`Cluster created successfully: ${response.clusterName}`);\n```\n- [Install the client library.](/dataproc/docs/reference/libraries#installing_the_client_library) \n- [Set up application default credentials.](/dataproc/docs/reference/libraries#setting_up_authentication) \n- Run the code.See [Setting Up a Python Development Environment](/python/docs/setup) . [  dataproc/snippets/create_cluster.py ](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/dataproc/snippets/create_cluster.py) [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/dataproc/snippets/create_cluster.py) ```\nfrom google.cloud import dataproc_v1 as dataprocdef create_cluster(project_id, region, cluster_name):\u00a0 \u00a0 \"\"\"This sample walks a user through creating a Cloud Dataproc cluster\u00a0 \u00a0 using the Python client library.\u00a0 \u00a0 Args:\u00a0 \u00a0 \u00a0 \u00a0 project_id (string): Project to use for creating resources.\u00a0 \u00a0 \u00a0 \u00a0 region (string): Region where the resources should live.\u00a0 \u00a0 \u00a0 \u00a0 cluster_name (string): Name to use for creating a cluster.\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 # Create a client with the endpoint set to the desired cluster region.\u00a0 \u00a0 cluster_client = dataproc.ClusterControllerClient(\u00a0 \u00a0 \u00a0 \u00a0 client_options={\"api_endpoint\": f\"{region}-dataproc.googleapis.com:443\"}\u00a0 \u00a0 )\u00a0 \u00a0 # Create the cluster config.\u00a0 \u00a0 cluster = {\u00a0 \u00a0 \u00a0 \u00a0 \"project_id\": project_id,\u00a0 \u00a0 \u00a0 \u00a0 \"cluster_name\": cluster_name,\u00a0 \u00a0 \u00a0 \u00a0 \"config\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"master_config\": {\"num_instances\": 1, \"machine_type_uri\": \"n1-standard-2\"},\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"worker_config\": {\"num_instances\": 2, \"machine_type_uri\": \"n1-standard-2\"},\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 }\u00a0 \u00a0 # Create the cluster.\u00a0 \u00a0 operation = cluster_client.create_cluster(\u00a0 \u00a0 \u00a0 \u00a0 request={\"project_id\": project_id, \"region\": region, \"cluster\": cluster}\u00a0 \u00a0 )\u00a0 \u00a0 result = operation.result()\u00a0 \u00a0 # Output a success message.\u00a0 \u00a0 print(f\"Cluster created successfully: {result.cluster_name}\")\n```", "guide": "Dataproc"}