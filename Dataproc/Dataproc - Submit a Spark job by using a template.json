{"title": "Dataproc - Submit a Spark job by using a template", "url": "https://cloud.google.com/dataproc/docs/quickstarts/submit-spark-job-template", "abstract": "# Dataproc - Submit a Spark job by using a template\n# Submit a Spark job by using a template\nThis page shows you how to use an [Google APIs Explorer](https://developers.google.com/apis-explorer/#p/) template to run a simple Spark job on an existing Dataproc cluster.\nFor other ways to submit a job to a Dataproc cluster, see:- [Create a Dataproc cluster by using the Google Cloud console](/dataproc/docs/quickstarts/create-cluster-console#submit_a_job) \n- [Create a Dataproc cluster by using the Google Cloud CLI](/dataproc/docs/quickstarts/create-cluster-gcloud#submit_a_job) \n- [Create a Dataproc cluster by using client libraries](/dataproc/docs/quickstarts/create-cluster-client-libraries) \n", "content": "## Before you begin\nBefore you can run a Dataproc job, you must create a cluster of one or more virtual machines (VMs) to run it on. You can use the\n [APIs Explorer](/dataproc/docs/quickstarts/create-cluster-template) \n, the\n [Google Cloud console](/dataproc/docs/quickstarts/update-cluster-console#create_a_cluster) \n, the gcloud CLI\n [gcloud](/dataproc/docs/quickstarts/update-cluster-gcloud#create_a_cluster) \ncommand-line tool, or the\n [Quickstarts using Cloud Client Libraries](/dataproc/docs/quickstarts/create-cluster-client-libraries) \nto create a cluster.\n## Submit a jobTo submit a sample [Apache Spark](http://spark.apache.org/) job that calculates a rough value for [pi](https://en.wikipedia.org/wiki/Pi) , fill in and execute the Google APIs Explorer **Try this API** template.\n **Note:** The `region` , `clusterName` and `job` parameter values are filled in for you. Confirm or replace the `region` and `clusterName` parameter values to match your cluster's region and name. The `job` parameter values are required to run the a Spark job that is pre-installed on the Dataproc cluster's master node.- **Request parameters:** - Insert your [projectId](https://console.cloud.google.com/) .\n- Specify the [region](/compute/docs/regions-zones/regions-zones#available) where your cluster is located (confirm or replace \"us-central1\"). Your cluster's region is listed on the Dataproc [Clusters](https://console.cloud.google.com/dataproc/clusters) page in the Google Cloud console.\n- **Request body:** - [job.placement.clusterName](/dataproc/docs/reference/rest/v1/SparkJob#JobPlacement.FIELDS.cluster_name) : The name of the cluster where the job will run (confirm or replace \"example-cluster\").\n- [job.sparkJob.args](/dataproc/docs/reference/rest/v1/SparkJob#FIELDS.args) : \"1000\", the number of job tasks.\n- [job.sparkJob.jarFileUris](/dataproc/docs/reference/rest/v1/SparkJob#FIELDS.jar_file_uris) : \"file:///usr/lib/spark/examples/jars/spark-examples.jar\". This is the local file path on the Dataproc cluster's master node where the jar that contains the Spark Scala job code is installed.\n- [job.sparkJob.mainClass](/dataproc/docs/reference/rest/v1/SparkJob#FIELDS.main_class) : \"org.apache.spark.examples.SparkPi\". The is the main method of the job's pi calculation Scala application.\n- Click **EXECUTE** . The first time you run the API template, you may be asked to choose and sign into your Google account, then authorize the Google APIs Explorer to access your account. If the request is successful, the JSON response shows that job submission request is pending.\n- To view job output, open the [Dataproc Jobs](https://console.cloud.google.com/dataproc/jobs) page in the Google Cloud console, then click the top (most recent) Job ID. Click \"LINE WRAP\" to ON to bring lines that exceed the right margin into view.```\n...\nPi is roughly 3.141804711418047\n...\n```\n## Clean upTo avoid incurring charges to your Google Cloud account for   the resources used on this page, follow these steps.- If you don't need the cluster to explore the other quickstarts or to run other jobs, use the [APIs Explorer](/dataproc/docs/quickstarts/quickstart-explorer-delete) , the [Google Cloud console](/dataproc/docs/quickstarts/update-cluster-console#delete_a_cluster) , the gcloud CLI [gcloud](/dataproc/docs/quickstarts/update-cluster-gcloud#delete_a_cluster) command-line tool, or the [Cloud Client Libraries](/dataproc/docs/quickstarts/create-cluster-client-libraries) to delete the cluster.\n## What's next\n- Learn how to [update a Dataproc cluster by using a template](/dataproc/docs/quickstarts/update-cluster-template) .", "guide": "Dataproc"}