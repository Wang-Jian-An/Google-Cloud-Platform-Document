{"title": "Dataproc - Cluster properties", "url": "https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/cluster-properties", "abstract": "# Dataproc - Cluster properties\n", "content": "## Apache Hadoop YARN, HDFS, Spark, and related properties\nThe open source components installed on Dataproc clusters contain many configuration files. For example, Apache Spark and Apache Hadoop have several XML and plain text configuration files. You can use the `\u2011\u2011properties` flag of the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command to modify many common configuration files when creating a cluster.\n### Formatting\nThe `gcloud dataproc clusters create --properties` flag accepts the following string format:\n```\nfile_prefix1:property1=value1,file_prefix2:property2=value2,...\n```\n- The maps to a predefined configuration file as shown in the table below, and the maps to a property within the file.\n- The default delimiter used to separate multiple cluster properties is the comma (,). However, if a comma is included in a property value, you must change the delimiter by specifying a \"^ ^\" at the beginning of the property list (see [gcloud topic escaping](/sdk/gcloud/reference/topic/escaping) for more information).- Example using a \"#\" delimiter:```\n--properties ^#^file_prefix1:property1=part1,part2#file_prefix2:property2=value2\n```\n### Examples\nTo change the `spark.master` setting in the `spark-defaults.conf` file, add the following `gcloud dataproc clusters create --properties` flag:\n```\n--properties 'spark:spark.master=spark://example.com'\n```\nYou can change several properties at once, in one or more configuration files, by using a comma separator. Each property must be specified in the full `file_prefix:property=value` format. For example, to change the `spark.master` setting in the `spark-defaults.conf` file and the `dfs.hosts` setting in the `hdfs-site.xml` file, use the following `--properties` flag when creating a cluster:\n```\n--properties 'spark:spark.master=spark://example.com,hdfs:dfs.hosts=/foo/bar/baz'\n```To set `spark.executor.memory` to `10g` , insert the  following `properties` setting in the [SoftwareConfig](/static/dataproc/docs/reference/rest/v1/ClusterConfig#SoftwareConfig.FIELDS.properties) section of your [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request:\n```\n\"properties\": {\n \"spark:spark.executor.memory\": \"10g\"\n}\n```\nAn easy way to see how to construct the JSON body of a Dataproc API clusters REST request is to initiate the equivalent `gcloud` command using the `--log-http` flag. Here is a sample `gcloud dataproc clusters create` command, which sets cluster properties with the `--properties spark:spark.executor.memory=10g` flag. The stdout log shows the resulting REST request body (the `properties` snippet is shown below):\n```\ngcloud dataproc clusters create my-cluster \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--properties=spark:spark.executor.memory=10g \\\n\u00a0\u00a0\u00a0\u00a0--log-http \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```\n **Output:** \n```\n...\n== body start ==\n{\"clusterName\": \"my-cluster\", \"config\": {\"gceClusterConfig\": ...\n\"masterConfig\": {... \"softwareConfig\": {\"properties\": {\"spark:spark.executor.memory\": \"10g\"}},\n...\n== body end ==\n...\n```\n **Make sure to cancel the command** after the JSON body  appears in the output if you do not want the command to take effect.To change the `spark.master` setting in the `spark-defaults.conf` file:- In the Google Cloud console, open the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page. Click the Customize cluster panel, then scroll to the Cluster properties  section.\n- Click **+ ADD PROPERTIES** .   Select **spark** in the Prefix list, then add   \"spark.master\" in the Key field and the setting in the Value field.\n### Cluster vs. job properties\nThe Apache Hadoop YARN, HDFS, Spark, and other file-prefixed properties are applied at the cluster level when you create a cluster. These properties cannot be applied to a cluster after cluster creation. However, many of these properties can also be applied to specific jobs. **When applying a property to a job, the file prefix is not used** .\nThe following example sets Spark executor memory to 4g for a Spark job ( `spark:` prefix omitted).\n```\ngcloud dataproc jobs submit spark \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--properties=spark.executor.memory=4g \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\nJob properties can be submitted in a file using the `gcloud dataproc jobs submit` `` `--properties-file` flag (see, for example, the [--properties-file](/sdk/gcloud/reference/dataproc/jobs/submit/hadoop#--properties-file) description for an Hadoop job submission).\n```\ngcloud dataproc jobs submit JOB_TYPE \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--properties-file=PROPERTIES_FILE \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\nThe `` is a set of line-delimited `key` = `value` pairs. The property to be set is the `key` , and the value to set the property to is the `value` . See the [java.util.Properties](https://docs.oracle.com/javase/7/docs/api/java/util/Properties.html#load(java.io.Reader) class for a detailed description of the properties file format.\nThe following is an example of a properties file that can be passed to the `--properties-file` flag when submitting a Dataproc job.\n```\n dataproc:conda.env.config.uri=gs://some-bucket/environment.yaml\n spark:spark.history.fs.logDirectory=gs://some-bucket\n spark:spark.eventLog.dir=gs://some-bucket\n capacity-scheduler:yarn.scheduler.capacity.root.adhoc.capacity=5\n```\n### File-prefixed properties table\n| File prefix  | File      | File purpose              |\n|:-------------------|:--------------------------|:------------------------------------------------------------------|\n| capacity-scheduler | capacity-scheduler.xml | Hadoop YARN Capacity Scheduler configuration      |\n| core    | core-site.xml    | Hadoop general configuration          |\n| distcp    | distcp-default.xml  | Hadoop Distributed Copy configuration        |\n| flink    | flink-conf.yaml   | Flink configuration            |\n| flink-log4j  | log4j.properties   | Log4j settings file            |\n| hadoop-env   | hadoop-env.sh    | Hadoop specific environment variables        |\n| hadoop-log4j  | log4j.properties   | Log4j settings file            |\n| hbase    | hbase-site.xml   | HBase configuration            |\n| hbase-log4j  | log4j.properties   | Log4j settings file            |\n| hdfs    | hdfs-site.xml    | Hadoop HDFS configuration           |\n| hive    | hive-site.xml    | Hive configuration            |\n| hive-log4j2  | hive-log4j2.properties | Log4j settings file            |\n| hudi    | hudi-default.conf   | Hudi configuration            |\n| mapred    | mapred-site.xml   | Hadoop MapReduce configuration         |\n| mapred-env   | mapred-env.sh    | Hadoop MapReduce specific environment variables     |\n| pig    | pig.properties   | Pig configuration             |\n| pig-log4j   | log4j.properties   | Log4j settings file            |\n| presto    | config.properties   | Presto configuration            |\n| presto-jvm   | jvm.config    | Presto specific JVM configuration         |\n| spark    | spark-defaults.conf  | Spark configuration            |\n| spark-env   | spark-env.sh    | Spark specific environment variables        |\n| spark-log4j  | log4j.properties   | Log4j settings file            |\n| tez    | tez-site.xml    | Tez configuration             |\n| webcat-log4j  | webhcat-log4j2.properties | Log4j settings file            |\n| yarn    | yarn-site.xml    | Hadoop YARN configuration           |\n| yarn-env   | yarn-env.sh    | Hadoop YARN specific environment variables      |\n| zeppelin   | zeppelin-site.xml   | Zeppelin configuration           |\n| zeppelin-env  | zeppelin-env.sh   | Zeppelin specific environment variables (Optional Component only) |\n| zeppelin-log4j  | log4j.properties   | Log4j settings file            |\n| zookeeper   | zoo.cfg     | Zookeeper configuration           |\n| zookeeper-log4j | log4j.properties   | Log4j settings file            |\n**Notes**\n- Some properties are reserved and cannot be overridden because they impact the functionality of the Dataproc cluster. If you try to change a reserved property, you will receive an error message when creating your cluster.\n- You can specify multiple changes by separating each with a comma.\n- The`--properties`flag cannot modify configuration files not shown above.\n- Changes to properties will be applied **before** the daemons on your cluster start.\n- If the specified property exists, it will be updated. If the specified property does not exist, it will be added to the configuration file.\n[](None)\n## Dataproc service properties\nThe properties listed in this section are specific to Dataproc. These properties can be used to further configure the functionality of your Dataproc cluster.\n**Note:** These cluster properties are specified at cluster creation. They cannot be specified or updated after cluster creation.\n### Formatting\nThe `gcloud dataproc clusters create --properties` flag accepts the following string format:\n```\nproperty_prefix1:property1=value1,property_prefix2:property2=value2,...\n```\n- The default delimiter used to separate multiple cluster properties is the comma (,). However, if a comma is included in a property value, you must change the delimiter by specifying \"^ ^\" at the beginning of the property list (see [gcloud topic escaping](/sdk/gcloud/reference/topic/escaping) for more information).- Example using a \"#\" delimiter:```\n--properties ^#^property_prefix1:property1=part1,part2#property_prefix2:property2=value2\n```**Example:**\nCreate a cluster and set [Enhanced Flexibility Mode](/dataproc/docs/concepts/configuring-clusters/flex) to Spark primary worker shuffle.\n```\ngcloud dataproc jobs submit spark \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--properties=dataproc:efm.spark.shuffle=primary-worker \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\n### Dataproc service properties table\n| Property prefix | Property              | Values         | Description                                                                                                                                                                                    |\n|:------------------|:---------------------------------------------------------------|:------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| dataproc   | agent.process.threads.job.min         | number         | Dataproc runs user job drivers concurrently in a thread pool. This property controls the minimum number of threads in the thread pool for fast startup even when no jobs are running (default: 10).                                                                                                                                      |\n| dataproc   | agent.process.threads.job.max         | number         | Dataproc runs user job drivers concurrently in a thread pool. This property controls the maximum number of threads in the thread pool, therefore limiting the maximum concurrency of user jobs. Increase this value for higher concurrency (default: 100).                                                                                                                         |\n| dataproc   | am.primary_only            | true or false        | Set this property to true to prevent application master from running on Dataproc cluster preemptible workers. Note: This feature is only available with Dataproc 1.2 and higher. The default value is false.                                                                                                                                    |\n| dataproc   | conda.env.config.uri           | gs://<path>        | Location in Cloud Storage of the Conda environment config file. A new Conda environment will be created and activated based on this file. For more information, see Using Conda related Cluster properties. (default: empty).                                                                                                                                |\n| dataproc   | conda.packages             | Conda packages       | This property takes a list of comma-separated Conda packages with specific versions to be installed in the base Conda environment. For more information, see Using Conda related Cluster properties. (default: empty).                                                                                                                                  |\n| dataproc   | dataproc.allow.zero.workers         | true or false        | Set this SoftwareConfig property to true in a Dataproc clusters.create API request to create a Single node cluster, which changes default number of workers from 2 to 0, and places worker components on the master host. A Single node cluster can also be created from the Google Cloud console or with the Google Cloud CLI by setting the number of workers to 0.                                                                                              |\n| dataproc   | dataproc.alpha.master.nvdimm.size.gb       | 1500-6500         | Setting a value creates a Dataproc master with Intel Optane DC Persistent memory. Note: Optane VMs can only be created in us-central1-f zones, only with n1-highmem-96-aep machine type and only under whitelisted projects.                                                                                                                                |\n| dataproc:   | dataproc.alpha.worker.nvdimm.size.gb       | 1500-6500         | Setting a value creates a Dataproc worker with Intel Optane DC Persistent memory. Note: Optane VMs can only be created in us-central1-f zones, only with n1-highmem-96-aep machine type and only under whitelisted projects.                                                                                                                                |\n| dataproc:   | dataproc.await-new-workers-service-registration    | true or false        | This property is available in images 2.0.49+. Default value is false. Set this property to true to wait for new primary workers to register service leaders, such as HDFS NameNode and YARN ResourceManager, during cluster creation or cluster scale-up (only HDFS and YARN services are monitored). When set to true, if a new worker fails to register to a service, the worker is assigned a FAILED status. A failed worker is removed if the cluster is scaling up. If the cluster is being created, a failed worker is removed if the gcloud dataproc clusters create --action-on-failed-primary-workers=DELETE flag or the API actionOnFailedPrimaryWorkers=DELETE field was specified as part of the gcloud command or API cluster create request. |\n| dataproc:   | dataproc.beta.secure.multi-tenancy.user.mapping    | user-to-service account mappings   | This property takes a list of user-to-service account mappings. Mapped users can submit interactive workloads to the cluster with isolated user identities (see Dataproc Service Account Based Secure Multi-tenancy).                                                                                                                                  |\n| dataproc:   | dataproc.cluster.caching          | true or false        | When the cluster caching is enabled, the cluster caches Cloud Storage data accessed by Spark jobs, which improves job performance without compromising consistency. (default: false).                                                                                                                                          |\n| dataproc   | dataproc.cluster-ttl.consider-yarn-activity     | true or false        | For image versions 1.4.64+, 1.5.39+, and 2.0.13+, the default value of true for this property results in Cluster Scheduled Deletion considering YARN activity, in addition to Dataproc Jobs API activity, when determining cluster idle time. When set to false for image versions 1.4.64+, 1.5.39+, and 2.0.13+, or when using images with lower version numbers, only Dataproc Jobs API activity is considered. The default value is true for image versions 1.4.64+, 1.5.39+, and 2.0.13+.                                                                |\n| dataproc   | dataproc.conscrypt.provider.enable        | true or false        | Enables (true) or disables (false) Conscrypt as the primary Java security provider. Note: Conscrypt is enabled by default in Dataproc 1.2 and higher, but disabled in 1.0/1.1.                                                                                                                                            |\n| dataproc   | dataproc.cooperative.multi-tenancy.user.mapping    | user-to-service account mappings   | This property takes a list of comma-separated user-to-service account mappings. If a cluster is created with this property set, when a user submits a job, the cluster will attempt to impersonate the corresponding service account when accessing Cloud Storage through the Cloud Storage connector. This feature requires Cloud Storage connector version 2.1.4 or higher. For more information, see Dataproc cooperative multi-tenancy. (default: empty).                                                                        |\n| dataproc   | dataproc:hudi.version           | Hudi version        | Sets the Hudi version used with the optional Dataproc Hudi component. Note: This version is set by Dataproc to be compatible with the cluster image version. If it is set by the user, cluster creation can fail if the specified version is not compatible with the cluster image.                                                                                                                  |\n| dataproc   | dataproc.lineage.enabled          | true          | Enables data lineage in a Dataproc cluster for Spark jobs.                                                                                                                                                                         |\n| dataproc   | dataproc.localssd.mount.enable         | true or false        | Whether to mount local SSDs as Hadoop/Spark temp directories and HDFS data directories (default: true).                                                                                                                                                             |\n| dataproc   | dataproc.logging.stackdriver.enable       | true or false        | Enables (true) or disables (false) Cloud Logging (default: true). See Cloud Logging Pricing for associated charges.                                                                                                                                                          |\n| dataproc   | dataproc.logging.stackdriver.job.driver.enable     | true or false        | Enables (true) or disables (false) Dataproc job driver logs in Cloud Logging. See Dataproc job output and logs (default: false).                                                                                                                                                       |\n| dataproc   | dataproc.logging.stackdriver.job.yarn.container.enable   | true or false        | Enables (true) or disables (false) YARN container logs in Cloud Logging. See Spark job output options. (default: false).                                                                                                                                                         |\n| dataproc   | dataproc.master.custom.init.actions.mode      | RUN_BEFORE_SERVICES or RUN_AFTER_SERVICES | For 2.0+ image clusters, when set to RUN_AFTER_SERVICES, initialization actions on the master will run after HDFS and any services that depend on HDFS are initialized. Examples of HDFS-dependent services include: HBase, Hive Server2, Ranger, Solr, and the Spark and MapReduce history servers. (default: RUN_BEFORE_SERVICES).                                                                                                      |\n| dataproc   | dataproc.monitoring.stackdriver.enable       | true or false        | Enables (true) or disables (false) the Monitoring agent (default: false). This property is deprecated. See Enable custom metric collection to enable the collection of Dataproc OSS metric collection in Monitoring.                                                                                                                                  |\n| dataproc   | dataproc.scheduler.driver-size-mb        | number         | The average driver memory footprint, which determines the maximum number of concurrent jobs a cluster will run. The default value is 1GB. A smaller value, such as 256, may be appropriate for Spark jobs.                                                                                                                                     |\n| dataproc   | dataproc.scheduler.job-submission-rate       | number         | Jobs are throttled if this rate is exceeded. The default rate is 1.0 QPS.                                                                                                                                                                     |\n| dataproc   | dataproc.scheduler.max-concurrent-jobs       | number         | The maximum number of concurrent jobs. If this value is not set when the cluster is created, the upper limit on concurrent jobs is calculated as max((masterMemoryMb - 3584) / masterMemoryMbPerJob, 5). masterMemoryMb is determined by the master VM's machine type. masterMemoryMbPerJob is 1024 by default, but is configurable at cluster creation with thedataproc:dataproc.scheduler.driver-size-mb cluster property.                                                                                |\n| dataproc   | dataproc.scheduler.max-memory-used        | number         | The maximum amount of the RAM that can be used. If current usage is above this threshold, new jobs cannot be scheduled. The default is 0.9 (90%). If set to 1.0, master-memory-utilization job throttling is disabled.                                                                                                                                  |\n| dataproc   | dataproc.scheduler.min-free-memory.mb       | number         | The minimum amount of free memory in megabytes needed by the Dataproc job driver to schedule another job on the cluster. The default is 256 MB.                                                                                                                                                   |\n| dataproc   | dataproc.snap.enabled           | true or false        | Enables or disables Ubuntu Snap daemon. The default value is true. If set tofalse, pre-installed Snap packages in the image are not affected, but auto refresh is disabled. Applies to 1.4.71, 1.5.46, 2.0.20 and newer Ubuntu images.                                                                                                                              |\n| dataproc   | dataproc.worker.custom.init.actions.mode      | RUN_BEFORE_SERVICES      | For pre-2.0 image clusters, RUN_BEFORE_SERVICES is not set, but can be set by the user when the cluster is created. For 2.0+ image clusters, RUN_BEFORE_SERVICES is set, and the property cannot be passed to the cluster (it cannot be changed by the user). For information on the effect of this setting, see Important considerations and guidelines\u2014Initialization processing.                                                                                          |\n| dataproc   | dataproc.yarn.orphaned-app-termination.enable     | true or false        | Default value is true. Set to false to prevent Dataproc from terminating \"orphaned\" YARN apps. Dataproc considers a YARN app to be orphaned if the job driver that submitted the YARN app has exited. Warning: If you use Spark cluster mode (spark.submit.deployMode=cluster) and you set spark.yarn.submit.waitAppCompletion=false, the Spark driver exits without waiting for YARN apps to complete; in this case, set dataproc:dataproc.yarn.orphaned-app-termination.enable=false. Also set this property to false if you submit Hive jobs.                                                   |\n| dataproc   | efm.spark.shuffle            | primary-worker       | If set to primary-worker, Spark shuffle data is written to primary workers\". See Dataproc Enhanced Flexibility Mode for more information.                                                                                                                                                     |\n| dataproc   | job.history.to-gcs.enabled          | true or false        | Allows persisting MapReduce and Spark history files to the Dataproc temp bucket (default: true for image versions 1.5+). Users can overwrite the locations of job history file persistence through the following properties: mapreduce.jobhistory.done-dir, mapreduce.jobhistory.intermediate-done-dir, spark.eventLog.dir, and spark.history.fs.logDirectory. See Dataproc Persistent History Server for information on these and other cluster properties associated with the Dataproc job history and event files.                                                          |\n| dataproc   | jobs.file-backed-output.enable         | true or false        | Configures Dataproc jobs to pipe their output to temporary files in the /var/log/google-dataproc-job directory. Must be set to true to enable job driver logging in Cloud Logging (default: true).                                                                                                                                       |\n| dataproc   | jupyter.listen.all.interfaces         | true or false        | To reduce the risk of remote code execution over unsecured notebook server APIs, the default setting for image versions 1.3+ is false, which restricts connections to localhost (127.0.0.1) when Component Gateway is enabled (Component Gateway activation is not required for 2.0+ images). This default setting can be overridden by setting this property to true to allow all connections.                                                                                       |\n| dataproc   | jupyter.notebook.gcs.dir          | gs://<dir-path>       | Location in Cloud Storage to save Jupyter notebooks.                                                                                                                                                                          |\n| dataproc   | kerberos.beta.automatic-config.enable       | true or false        | When set to true, users do not need to specify the Kerberos root principal password with the --kerberos-root-principal-password and --kerberos-kms-key-uri flags (default: false). See Enabling Hadoop Secure Mode via Kerberos for more information.                                                                                                                          |\n| dataproc   | kerberos.cross-realm-trust.admin-server      | hostname/address       | hostname/address of remote admin server (often the same as the KDC server).                                                                                                                                                                    |\n| dataproc   | kerberos.cross-realm-trust.kdc         | hostname/address       | hostname/address of remote KDC.                                                                                                                                                                               |\n| dataproc   | kerberos.cross-realm-trust.realm        | realm name        | Realm names can consist of any UPPERCASE ASCII string. Usually, the realm name is the same as your DNS domain name (in UPPERCASE). Example: If machines are named \"machine-id.example.west-coast.mycompany.com\", the associated realm may be designated as \"EXAMPLE.WEST-COAST.MYCOMPANY.COM\".                                                                                                                |\n| dataproc   | kerberos.cross-realm-trust.shared-password.uri     | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted shared password.                                                                                                                                                                       |\n| dataproc   | kerberos.kdc.db.key.uri          | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted file containing the KDC database master key.                                                                                                                                                                |\n| dataproc   | kerberos.key.password.uri          | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted file that contains the password of the key in the keystore file.                                                                                                                                                           |\n| dataproc   | kerberos.keystore.password.uri         | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted file containing the keystore password.                                                                                                                                                                  |\n| dataproc   | kerberos.keystore.uri1           | gs://<dir-path>       | Location in Cloud Storage of the keystore file containing the wildcard certificate and the private key used by cluster nodes.                                                                                                                                                        |\n| dataproc   | kerberos.kms.key.uri           | KMS key URI        | The URI of the KMS key used to decrypt root password, for example projects/project-id/locations/region/keyRings/key-ring/cryptoKeys/key (see Key resource ID).                                                                                                                                                |\n| dataproc   | kerberos.root.principal.password.uri       | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted password for Kerberos root principal.                                                                                                                                                                  |\n| dataproc   | kerberos.tgt.lifetime.hours         | hours          | Max life time of the ticket granting ticket.                                                                                                                                                                            |\n| dataproc   | kerberos.truststore.password.uri        | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted file that contains the password to the truststore file.                                                                                                                                                              |\n| dataproc   | kerberos.truststore.uri2          | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted trust store file containing trusted certificates.                                                                                                                                                               |\n| dataproc   | pip.packages             | Pip packages        | This property takes a list of comma-separated Pip packages with specific versions, to be installed in the base Conda environment. For more information, see Conda related Cluster properties. (default: empty).                                                                                                                                   |\n| dataproc   | ranger.kms.key.uri            | KMS key URI        | The URI of the KMS key used to decrypt Ranger admin user password, for example projects/project-id/locations/region/keyRings/key-ring/cryptoKeys/key (see Key resource ID).                                                                                                                                            |\n| dataproc   | ranger.admin.password.uri          | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted password for Ranger admin user.                                                                                                                                                                    |\n| dataproc   | ranger.db.admin.password.uri         | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted password for Ranger database admin user.                                                                                                                                                                 |\n| dataproc   | ranger.cloud-sql.instance.connection.name      | cloud sql instance connection name  | The connection name of the Cloud SQL instance, for example project-id:region:name.                                                                                                                                                                   |\n| dataproc   | ranger.cloud-sql.root.password.uri        | gs://<dir-path>       | Location in Cloud Storage of the KMS-encrypted password for the root user of the Cloud SQL instance.                                                                                                                                                              |\n| dataproc   | ranger.cloud-sql.use-private-ip        | true or false        | Whether the communication between cluster instances and the Cloud SQL instance should be over private IP (default value is false).                                                                                                                                                       |\n| dataproc   | solr.gcs.path             | gs://<dir-path>       | Cloud Storage path to act as Solr home directory.                                                                                                                                                                           |\n| dataproc   | startup.component.service-binding-timeout.hadoop-hdfs-namenode | seconds         | The amount of time the Dataproc startup script will wait for the hadoop-hdfs-namenode to bind to ports before deciding that its startup has succeeded. The maximum recognized value is 1800 seconds (30 minutes).                                                                                                                                   |\n| dataproc   | startup.component.service-binding-timeout.hive-metastore  | seconds         | The amount of time the Dataproc startup script will wait for the hive-metastore service to bind to ports before deciding that its startup has succeeded. The maximum recognized value is 1800 seconds (30 minutes).                                                                                                                                  |\n| dataproc   | startup.component.service-binding-timeout.hive-server2   | seconds         | The amount of time the Dataproc startup script will wait for the hive-server2 to bind to ports before deciding that its startup has succeeded. The maximum recognized value is 1800 seconds (30 minutes).                                                                                                                                     |\n| dataproc   | user-attribution.enabled          | true or false        | Set this property to true to attribute a Dataproc job to the identity of the user who submitted it (default value is false).                                                                                                                                                        |\n| dataproc   | yarn.docker.enable            | true or false        | Set to true to enable the Dataproc Docker on YARN feature (default value is false).                                                                                                                                                                  |\n| dataproc   | yarn.docker.image            | docker image        | When enabling the Dataproc Docker on YARN feature (dataproc:yarn.docker.enable=true), you can use this optional property to specify your docker image (for example, dataproc:yarn.docker.image=gcr.io/project-id/image:1.0.1). If specified, the image is download and cached in all nodes of the cluster during cluster creation.                                                                                                       |\n| dataproc   | yarn.log-aggregation.enabled         | true or false        | Allows (true) turning on YARN log aggregation to the cluster's temp bucket. The bucket name is of the following form: dataproc-temp-<REGION>-<PROJECT_NUMBER>-<RANDOM_STRING>. (default: true for image versions 1.5+). Note: The cluster's temp bucket is not deleted when the cluster is deleted. Users can also set the location of aggregated YARN logs by overwriting the yarn.nodemanager.remote-app-log-dir YARN property.                                                                               |\n| knox    | gateway.host             | ip address        | To reduce the risk of remote code execution over unsecured notebook server APIs, the default setting for image versions 1.3+ is 127.0.0.1, which restricts connections to localhost when Component Gateway is enabled. The default setting can be overridden, for example by setting this property to 0.0.0.0 to allow all connections.                                                                                                     |\n| zeppelin   | zeppelin.notebook.gcs.dir          | gs://<dir-path>       | Location in Cloud Storage to save Zeppelin notebooks.                                                                                                                                                                          |\n| zeppelin   | zeppelin.server.addr           | ip address        | To reduce the risk of remote code execution over unsecured notebook server APIs, the default setting for image versions 1.3+ is 127.0.0.1, which restricts connections to localhost when Component Gateway is enabled. This default setting can be overridden, for example by setting this property to 0.0.0.0 to allow all connections.                                                                                                     |\n**1** Keystore file: The keystore file contains the SSL certificate. It should be in Java KeyStore (JKS) format. When copied to VMs, it is renamed to `keystore.jks` . The SSL certificate should be a wildcard certificate that applies to each node in the cluster.\n**2** Truststore file: The truststore file should be in Java KeyStore (JKS) format. When copied to VMs, it is renamed to `truststore.jks` .", "guide": "Dataproc"}