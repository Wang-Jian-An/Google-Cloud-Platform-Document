{"title": "Dataproc - Dataproc secondary workers", "url": "https://cloud.google.com/dataproc/docs/concepts/compute/secondary-vms", "abstract": "# Dataproc - Dataproc secondary workers\nIn addition to using standard Compute Engine VMs as Dataproc workers (called \"primary\" workers), Dataproc clusters can use `secondary` workers.\nThe following characteristics apply to all secondary workers in a Dataproc cluster:\n- **Processing only** \u2014Secondary workers do not store data. They only function as processing nodes. Therefore, you can use secondary workers to scale compute without scaling storage.\n- **No secondary-worker-only clusters** \u2014Your cluster must have primary workers. If you create a cluster and you do not specify the number of primary workers, Dataproc adds two primary workers to the cluster.\n- **Machine type** \u2014By default, secondary workers use the [machine type](/compute/docs/machine-types) of the cluster's primary workers. For example, if you create a cluster with primary workers that use `n1-standard-4` machine types, all secondary workers added to the cluster will also use `n1-standard-4` machines.Instead of using the default primary worker machine type for secondary workers, you can specify one or more ranked lists of machine types for secondary workers. See [Dataproc Flexible VMs](/dataproc/docs/concepts/configuring-clusters/flexible-vms) for more information.\n- **Persistent disk size** \u2014As a default, secondary workers are created with the smaller of 100GB or the primary worker boot disk size. This disk space is used for local caching of data and is not available through HDFS. You can override the default disk size with the [gcloud dataproc clusters create --secondary-worker-boot-disk-size](/sdk/gcloud/reference/dataproc/clusters/create) command at cluster creation. You can specify this flag even if the cluster won't have secondary workers when it is created.\n- **Asynchronous Creation** \u2014When you add secondary workers by creating or scaling up a cluster, the secondary workers may not be provisioned by the time the create or update operation finishes. This is because Dataproc manages secondary workers using Managed Instance Groups (MIGs), which create VMs asynchronously as soon as they can be provisioned (see [Checking the status of managed instances](/compute/docs/instance-groups/getting-info-about-migs#verify_instances) ).", "content": "## Preemptible and non-preemptible secondary workers\nThere are three types of secondary workers: [spot VMs](/compute/docs/instances/spot) , standard [preemptible VMs](/compute/docs/instances/preemptible) , and [non-preemptible VMs](/compute/docs/instances) . **If you specify secondary workersfor your cluster, they must be the same type.** The default Dataproc secondary worker type is the standard preemptible VM.\nExample: If you select three secondary workers when you create a cluster, you can specify that all three will be Spot VMs, or all three will be (standard) preemptible VMS, or all three will be non-preemptible VMs, but you cannot specify that each will be a different type.\nA **spot VM** is the latest type of Compute Engine preemptible VM. It shares the lower-cost pricing model of standard preemptible VMs, but unlike the standard preemptible VM with a 24-hour maximum lifetime, the spot VM has no maximum lifetime. Both spot and standard preemptible VM workers are reclaimed and removed from a Dataproc cluster if they are required by Google Cloud for other tasks.\n### Preemptible workers\n**Note:** When the term \"preemptible\" is used in the following sections to refer to a VM, worker, or node, it refers to both the standard preemptible and spot preemptible VM types unless it is used to expressly refer to the \"standard preemptible\" VM type only.\n- Although the potential removal of preemptible workers can affect job stability, you may decide to use preemptible instances to lower per-hour compute costs for non-critical data processing or to create very large clusters at a lower total cost (you can use the [Google Cloud pricing calculator](/products/calculator) to estimate costs).\n- For best results, the number of preemptible workers in your cluster should be less than 50% of the total number of all workers (primary plus all secondary workers) in your cluster.\n- When using preemptible workers, your jobs will most likely experience a greater number of transient single-worker task failures compared to jobs run on non-preemptible workers. To increase job tolerance to low-level task failures, you can set cluster property values similar to the [default property values used with autoscaling clusters](/dataproc/docs/concepts/configuring-clusters/autoscaling#autoscaling_default_sparkhadoop_property_settings) to increase the maximum number of task retries and help avoid job failures.Consider using [EnhancedFlexibility Mode](/dataproc/docs/concepts/configuring-clusters/flex) if you are using preemptible VMs with Spark.\n- **A cost-savings consideration:** Using preemptible VMs does not always save costs since preemptions can cause longer job execution with resulting higher job costs. Although using [Enhanced Flexibility Mode (EFM)](/dataproc/docs/concepts/configuring-clusters/flex) with preemptible VMs can help mitigate this result, the overall cost savings of preemptible VMs will vary with each use case. Generally, short-lived jobs are more suitable for preemptible VM use, since the probability of preemptions during job execution will be lower. Try different job options, such as no preemptible VMs and preemptible VMs with EFM, to estimate costs and arrive at the best solution.\n### Non-preemptible workers\n- You can create a cluster with non-preemptible secondary workers to scale compute without sacrificing job stability. To do this, specify \"non-preemptible\" as the secondary worker type.## Using secondary workers\nYou can specify the number and type of secondary workers when you create a cluster using the [Google Cloud console](https://console.cloud.google.com/dataproc/clusters) , [gcloud CLI](/sdk/gcloud/reference/dataproc/clusters/update) or the [Dataproc API](/dataproc/docs/reference) .\n- Secondary workers must be the same type.\n- You can [update your cluster](/dataproc/docs/guides/manage-cluster#updating_a_cluster) after it is created to change the number, but not the type, of secondary workers in your cluster.\n- [Label updates](/dataproc/docs/guides/creating-managing-labels) propagate to all preemptible secondary workers within 24 hours. Label updates do not propagate to existing non-preemptible secondary workers. Label updates propagate to all workers added to a cluster **after** a label update. For example, if you scale up the cluster, all new primary and secondary workers will have the new labels.\n**If you plan to add secondary workers to\n a cluster later.** You can specify 0 secondary workers (gcloud command flag example:`--num-secondary-workers=0`) when you create your cluster, then update the cluster later to specify a positive number and type of secondary workers. **If you plan to\n update your cluster later to include secondary workers, you must specify\n the \"secondary-worker-type\" when you create the cluster.**\nYou can specify the number of secondary workers when creating a Dataproc cluster from the Google Cloud console. After a cluster has been created, you can add and remove secondary workers by editing the cluster configuration from the Google Cloud console.You can set the number and type of secondary workers to apply to a new cluster from the Secondary worker nodes section of the Configure nodes panel on the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page of the Google Cloud console. Specify the number and type of secondary workers in the Secondary worker nodes and Preemptibility fields, respectively.To update the number of secondary workers in a cluster, click the name of the cluster on the [Clusters](https://console.cloud.google.com/dataproc/clusters) page of the Google Cloud console. On the **Cluster details** page. Click the CONFIGURATION tab, then click EDIT and update the number in the Secondary worker nodes field.To remove all secondary workers from a cluster, update the cluster configuration as explained earlier, specifying `0` in the Secondary worker nodes field.Use the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command to add secondary workers to a cluster when the cluster is created. After a cluster is created, you can add or remove secondary workers to or from the cluster with the [gcloud dataproc clusters update](/sdk/gcloud/reference/dataproc/clusters/update) command (the number but not type of secondary workers can be updated).To create a cluster with secondary workers, use the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command with the `--num-secondary-workers` argument. Note that secondary workers are standard preemptible VMs by default. You can specify non-preemptible secondary workers when you create a cluster by setting `--secondary-worker-type=non-preemptible` (the `dataproc:secondary-workers.is-preemptible.override` property is no longer used to specify the type of the secondary worker).\n **Example 1** \nThe following command creates \"cluster1\" with two standard preemptible (default type) secondary workers.\n```\ngcloud dataproc clusters create cluster1 \\\n\u00a0\u00a0\u00a0\u00a0--num-secondary-workers=2 \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n```\n **Example 2** \nThe following command uses the `secondary-worker-type` flag to create \"cluster2\" with two spot (preemptible) secondary workers.\n```\ngcloud dataproc clusters create cluster2 \\\n\u00a0\u00a0\u00a0\u00a0--num-secondary-workers=2 \\\n\u00a0\u00a0\u00a0\u00a0--secondary-worker-type=spot \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n```\n **Example 3** \nThe following command uses the `secondary-worker-type` flag to create \"cluster3\" with two **non-preemptible** secondary workers.\n```\ngcloud dataproc clusters create cluster3 \\\n\u00a0\u00a0\u00a0\u00a0--num-secondary-workers=2 \\\n\u00a0\u00a0\u00a0\u00a0--secondary-worker-type=non-preemptible \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n```\n **To change the secondary worker boot disk size** : As a default, all secondary workers are created with the smaller of 100GB or the primary worker boot disk size. This disk space is used for local caching of data and is not available through HDFS. You can override the default disk size with the [gcloud dataproc clusters create --secondary-worker-boot-disk-size](/sdk/gcloud/reference/dataproc/clusters/create) command at cluster creation. This flag can be specified even if the cluster does not have any secondary workers at creation time.\n **Let the Google Cloud console construct your\ncluster create request.** You can click the ** Equivalent REST or command line** links at the bottom of the left panel of the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page to have the Google Cloud console construct an equivalent API REST request or gcloud tool command.To update a cluster to add or remove secondary workers, use the [gcloud dataproc clusters update](/sdk/gcloud/reference/dataproc/clusters/update) command with the `--num-secondary-workers` argument.\n **Example** \nThe following command updates \"example-cluster\" to use four secondary workers (of the default type or type specified when you created the cluster).\n```\ngcloud dataproc clusters update example-cluster \\\n\u00a0\u00a0\u00a0\u00a0--num-secondary-workers=4 \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n```To remove all secondary workers from a cluster, use the [gcloud dataproc clusters update](/sdk/gcloud/reference/dataproc/clusters/update) command with `--num-secondary-workers` set to `0` .\n **Example** \nThe following command removes all secondary workers from \"example-cluster\".\n```\ngcloud dataproc clusters update example-cluster \\\n\u00a0\u00a0\u00a0\u00a0--num-secondary-workers=0 \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n```Use the Dataproc [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) API add secondary workers to a cluster when the cluster is created. Note that secondary workers are standard [preemptible](/dataproc/docs/reference/rest/v1/ClusterConfig#Preemptibility.ENUM_VALUES.PREEMPTIBLE) VMs by default.\n **Example 1** \nThe following POST request creates a \"cluster1\" with two standard preemptible (default type) VM workers.\n```\nPOST https://dataproc.googleapis.com/v1/projects/project-id/regions/region/clusters\n{\n \"clusterName\": \"cluster1\",\n \"config\": {\n \"secondaryWorkerConfig\": {\n  \"numInstances\": 2\n }\n }\n}\n```\n **Example 2** \nThe following POST request creates a \"cluster2\" with two spot (preemptible) VM workers.\n```\nPOST https://dataproc.googleapis.com/v1/projects/project-id/regions/region/clusters\n{\n \"clusterName\": \"cluster2\",\n \"config\": {\n \"secondaryWorkerConfig\": {\n  \"numInstances\": 2,\n  \"preemptibility\": \"SPOT\"\n }\n }\n}\n```\n **Example 3** \nThe following POST request creates \"cluster3\" with two **non-preemptible** secondary workers.\n```\nPOST https://dataproc.googleapis.com/v1/projects/project-id/regions/region/clusters\n{\n \"clusterName\": \"cluster3\",\n \"config\": {\n \"secondaryWorkerConfig\": {\n  \"numInstances\": 2,\n  \"preemptibility\": \"NON_PREEMPTIBLE\"\n }\n }\n}\n```Use the Dataproc [clusters.patch](/dataproc/docs/reference/rest/v1/projects.regions.clusters/patch) API to add and remove secondary workers.\n **Example** \nThe following PATCH request updates a cluster to have four secondary workers (of the default type or type specified when you created the cluster).\n```\nPATCH /v1/projects/project-id/regions/region/clusters/cluster-name?updateMask=config.secondary_worker_config.num_instances\n{\n \"config\": {\n \"secondaryWorkerConfig\": {\n  \"numInstances\": 4\n }\n }\n}\n```\n **Let the Google Cloud console construct your\ncluster create request.** You can click the ** Equivalent REST or command line** links at the bottom of the left panel of the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page to have the Google Cloud console construct an equivalent API REST request or gcloud tool command.\n## Troubleshooting secondary workers\n**Service account permission issues:** Secondary workers are created through a [managed instance group](/compute/docs/access/iam#managed-instance-groups-and-iam) and Compute Engine uses your project's [Google APIs Service Agent](/compute/docs/access/service-accounts#google_apis_service_agent) service account to perform managed instance group operations. This service account name is formatted as follows: `` `@cloudservices.gserviceaccount.com` .\nIf there is a permission issue with this service account, Dataproc logs will not report the failure to create secondary workers, but failed workers will be listed under the VM INSTANCES tab of the **Cluster details** page in the Google Cloud console without a green checkmark (open the Dataproc [Clusters](https://console.cloud.google.com/dataproc/clusters) page, then click the cluster name to open the **Cluster details** page for the cluster).\n- **Managed instance group permissions issues:** To check if there is an issue with managed instance group permissions, view the logs in [Logs Explorer](/logging/docs/write-query-log-entries-gcloud#explore) for \"Google Compute Engine Instance Group\" resource type, and filter for the corresponding instance group ID. The instance group ID filter will display the instance group name in the format of `dataproc-` `` `-sw` and the instance group ID will be auto-populated in the logging query. Instead of using the dropdown filters, you can also apply a logging filter for `resource.type=\"gce_instance_group\"` and `resource.labels.instance_group_name=\"dataproc-` `` `-sw\"` .\n- **Custom image permission issues:** If Dataproc cluster VMs are created with custom images fetched from another project, the `Compute Image User` role must be assigned to your project's `` `@cloudservices.gserviceaccount.com` service account (see [Grant a managed instance group access to images](/compute/docs/images/managing-access-custom-images#grant_a_managed_instance_group_access_to_images) ). If the correct role is not assigned, this error message will appear in the logs: `Required 'compute.images.useReadOnly' permission for 'projects/[IMAGE PROJECT]/global/images/[IMAGE NAME]`", "guide": "Dataproc"}