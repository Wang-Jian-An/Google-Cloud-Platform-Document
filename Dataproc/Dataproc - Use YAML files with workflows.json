{"title": "Dataproc - Use YAML files with workflows", "url": "https://cloud.google.com/dataproc/docs/concepts/workflows/use-yamls", "abstract": "# Dataproc - Use YAML files with workflows\nYou can define a workflow template in a YAML file, then instantiate the template to run the workflow. You can also import and export a workflow template YAML file to create and update a Dataproc workflow template resource.\nAlso see [Using inline Dataproc workflows](/dataproc/docs/concepts/workflows/inline-workflows) for other ways to run a workflow without creating a workflow template resource.\n#", "content": "## Run a workflow using a YAML file\nTo run a workflow without first creating a workflow template resource, use the [gcloud dataproc workflow-templates instantiate-from-file](/sdk/gcloud/reference/dataproc/workflow-templates/instantiate-from-file) command.\n- Define your workflow template in a YAML file. The YAML file must include all required [WorkflowTemplate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates) fields except the`id`field, and it must also exclude the`version`field and all output-only fields. In the following workflow example, the`prerequisiteStepIds`list in the`terasort`step ensures the`terasort`step will only begin after the`teragen`step completes successfully.```\njobs:\n- hadoopJob:\n args:\n - teragen\n - '1000'\n - hdfs:///gen/\n mainJarFileUri: file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\n stepId: teragen\n- hadoopJob:\n args:\n - terasort\n - hdfs:///gen/\n - hdfs:///sort/\n mainJarFileUri: file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\n stepId: terasort\n prerequisiteStepIds:\n - teragen\nplacement:\n managedCluster:\n clusterName: my-managed-cluster\n config:\n  gceClusterConfig:\n  zoneUri: us-central1-a\n```\n- Run the workflow:```\ngcloud dataproc workflow-templates instantiate-from-file \\\n\u00a0\u00a0\u00a0\u00a0--file=TEMPLATE_YAML \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```\n### Instantiate a workflow using a YAML file with Dataproc Auto Zone Placement\n- Define your workflow template in a YAML file. This YAML file is the same as the previous YAML file, except the`zoneUri`field is set to the empty string ('') to allow Dataproc [Auto Zone Placement](/dataproc/docs/concepts/configuring-clusters/auto-zone) to select the zone for the cluster.```\njobs:\n- hadoopJob:\n args:\n - teragen\n - '1000'\n - hdfs:///gen/\n mainJarFileUri: file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\n stepId: teragen\n- hadoopJob:\n args:\n - terasort\n - hdfs:///gen/\n - hdfs:///sort/\n mainJarFileUri: file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar\n stepId: terasort\n prerequisiteStepIds:\n - teragen\nplacement:\n managedCluster:\n clusterName: my-managed-cluster\n config:\n  gceClusterConfig:\n  zoneUri: ''\n```\n- Run the workflow. When using Auto Placement, you must pass a [region](/dataproc/docs/concepts/regional-endpoints) to the`gcloud`command.```\ngcloud dataproc workflow-templates instantiate-from-file \\\n\u00a0\u00a0\u00a0\u00a0--file=TEMPLATE_YAML \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```\n### Import and export a workflow template YAML file\nYou can import and export workflow template YAML files. Typically, a workflow template is first exported as a YAML file, then the YAML is edited, and then the edited YAML file is imported to update the template.\n- [Export the workflow template](/sdk/gcloud/reference/dataproc/workflow-templates/export) to a YAML file. During the export operation, the `id` and `version` fields, and all output-only fields are filtered from the output and do not appear in the exported YAML file.```\ngcloud dataproc workflow-templates export TEMPLATE_ID or TEMPLATE_NAME \\\n\u00a0\u00a0\u00a0\u00a0--destination=TEMPLATE_YAML \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```You can pass either the [WorkflowTemplate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates#resource-workflowtemplate) `id`or the fully qualified template resource`name`(\"projects//regions//workflowTemplates/\") to the command.If you omit the`--destination`flag, the output is directed to`stdout`, so the following command will also export the template to a YAML file:```\ngcloud dataproc workflow-templates export TEMPLATE_ID or TEMPLATE_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION > TEMPLATE_YAML\n```\n- Edit the YAML file locally. Note that the `id` , `version` , and output-only fields, which were filtered from the YAML file when the template was exported, are disallowed in the imported YAML file.\n- [Import the updated workflow template](/sdk/gcloud/reference/dataproc/workflow-templates/import) YAML file:```\ngcloud dataproc workflow-templates import TEMPLATE_ID or TEMPLATE_NAME \\\n\u00a0\u00a0\u00a0\u00a0--source=TEMPLATE_YAML \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```You can pass either the [WorkflowTemplate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates#resource-workflowtemplate) `id`or the fully qualified template resource`name`(\"projects//regions//workflowTemplates/\") to the command. The template resource with the same template name will be overwritten (updated) and its version number will be incremented. If a template with the same template name does not exist, it will be created.", "guide": "Dataproc"}