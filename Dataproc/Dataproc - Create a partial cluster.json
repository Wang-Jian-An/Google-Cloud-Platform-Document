{"title": "Dataproc - Create a partial cluster", "url": "https://cloud.google.com/dataproc/docs/guides/create-partial-cluster", "abstract": "# Dataproc - Create a partial cluster\nTo mitigate the effects of the unavailability of user-specified VMs in specific regions at specific times ( [stockouts](https://en.wikipedia.org/wiki/Stockout) ), Dataproc allows you to request the creation of a `partial cluster` by specifying a **minimum number** of primary workers that is acceptable to allow cluster creation.\n**Note:** See [Dataproc secondary workers](/dataproc/docs/concepts/compute/secondary-vms) to understand the difference between primary and secondary workers.\n| Standard cluster                                         | Partial cluster                                                                              |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| If one or more primary workers cannot be created and initialized, cluster creation fails. Workers that are created continue to run and incur charges until deleted by the user. | If the specified minimum number of workers can be created, the cluster is created. Failed (uninitialized) workers are deleted and do not incur charges. If the specified minimum number of workers cannot be created and initialized, the cluster is not created. Workers that are created are not deleted to allow for debugging. |\n| Cluster creation time is optimized.                                    | Longer cluster creation time can occur since all nodes must report provisioning status.                                                            |\n| Single node clusters are available for creation.                                 | Single node clusters are not available for creation.                                                                     |\n#", "content": "## Autoscaling:\nUse [autoscaling](/dataproc/docs/concepts/configuring-clusters/autoscaling) with partial cluster creation to help ensure that the target (full) number of primary workers is created. Autoscaling will try to acquire failed workers in the background if the workload requires them.\nThe following is a sample autoscaling policy that retries until the total number of primary worker instances reaches a target size of 10. The policy's `minInstances` and `maxInstances` match the minimum and total number of primary workers specified at cluster creation time (see [How to create a partial cluster](#how_to_create_a_partial_cluster) ). Setting the `scaleDownFactor` to 0 prevents the cluster from scaling down from 10 to 8, and will help keep the number of workers at the maximum 10-worker limit.\n```\nworkerConfig:\u00a0 minInstances: 8\u00a0 maxInstances: 10basicAlgorithm:\u00a0 cooldownPeriod: 2m\u00a0 yarnConfig:\u00a0 \u00a0 scaleUpFactor: 1\u00a0 \u00a0 scaleDownFactor: 0\u00a0 \u00a0 gracefulDecommissionTimeout: 1h\n```\n## How to create a partial cluster\nYou can use the Google Cloud CLI or the Dataproc API to create a Dataproc partial cluster.\n**Note:** Dataproc partial cluster creation is not available in the Google Cloud console.\nTo create a Dataproc partial cluster on the command line, run the following [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create#--min-num-workers) command locally in a terminal window or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) .\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--project=PROJECT \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--num-workers=NUM_WORKERS \\\n\u00a0\u00a0\u00a0\u00a0--min-num-workers=MIN_NUM_WORKERS \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```- : The cluster name must start with a lowercase letter followed by up to 51 lowercase letters, numbers, and hyphens, and cannot end with a hyphen.\n- : Specify the project associated with the job cluster.\n- : Specify the [Compute Engine region](/compute/docs/regions-zones#available) where the job cluster will be located.\n- : The total number of primary workers in the cluster to create if available.\n- : The minimum number of primary workers to create if the specified total number of workers (`NUM_WORKERS`) cannot be created. Cluster creation fails if this minimum number of primary workers cannot be created (workers that are created are not deleted to allow for debugging). If this flag is omitted, standard cluster creation with the total number of primary workers (`NUM_WORKERS`) is attempted.To create a Dataproc partial cluster, specify the minimum number of primary workers in the [workerConfig.minNumInstances](/dataproc/docs/reference/rest/v1/InstanceGroupConfig#FIELDS.min_num_instances) field as part of a [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request.\n **Note:** You can click the ** Equivalent REST\nor command line** links at the bottom of the left panel of the Dataproc Google Cloud console [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page to have the Console construct an equivalent API REST request or gcloud CLI command to use in your code or from the command line to create a cluster.### Display the number of provisioned workers\nAfter creating a cluster, you can run the following gcloud CLI command to list the number of workers, including any secondary workers, provisioned in your cluster.\n```\ngcloud dataproc clusters list \\\n\u00a0\u00a0\u00a0\u00a0--project=PROJECT \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0--filter=clusterName=CLUSTER_NAME\n```", "guide": "Dataproc"}