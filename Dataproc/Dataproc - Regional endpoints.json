{"title": "Dataproc - Regional endpoints", "url": "https://cloud.google.com/dataproc/docs/concepts/regional-endpoints", "abstract": "# Dataproc - Regional endpoints\nDataproc supports regional endpoints based on [Compute Engine regions](/compute/docs/regions-zones#available) . You must specify a region, such as \"us-east1\" or \"europe-west1\", when you create a Dataproc cluster. Dataproc will isolate cluster resources, such as VM instances and Cloud Storage and metadata storage, within a zone within the specified region.\nYou can optionally specify a zone within the specified cluster region, such as \"us-east1-a\" or \"europe-west1-b\", when you create a cluster. If you do not specify the zone, [Dataproc Auto Zone Placement](/dataproc/docs/concepts/auto-zone) will choose a zone within your specified cluster region to locate clusters resources.\nThe regional namespace corresponds to the `/regions/` `` segment of Dataproc resource URIs (see, for example, the cluster [networkUri](/dataproc/docs/reference/rest/v1/ClusterConfig#GceClusterConfig.FIELDS.network_uri) ).\n", "content": "## Regional endpoint semantics\nRegional endpoint names follow a standard naming convention based on [Compute Engine regions](/compute/docs/regions-zones/regions-zones#available) . For example, the name for the Central US region is `us-central1` , and the name of the Western Europe region is `europe-west1` . Run the `gcloud compute regions list` command to see a listing of available regions.\n**Note:** When new regions are added to Compute Engine, they become available for use with Dataproc.\n## Create a cluster\nWhen you create a cluster, specify a region using the required `--region` flag.\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```Use the `REGION` URL parameter in a [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request to specify the cluster region.Set the client transport address to the regional endpoint using the following pattern:\n`` `-dataproc.googleapis.com`\n **Python (google-cloud-python) example:** \n```\nfrom google.cloud import dataproc_v1from google.cloud.dataproc_v1.gapic.transports import cluster_controller_grpc_transporttransport = cluster_controller_grpc_transport.ClusterControllerGrpcTransport(\u00a0 \u00a0 address='us-central1-dataproc.googleapis.com:443')client = dataproc_v1.ClusterControllerClient(transport)project_id = 'my-project'region = 'us-central1'cluster = {...}\n```\n **Java (google-cloud-java) example:** \n```\nClusterControllerSettings settings =\u00a0 \u00a0 \u00a0ClusterControllerSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-dataproc.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0try (ClusterControllerClient clusterControllerClient = ClusterControllerClient.create(settings)) {\u00a0 \u00a0String projectId = \"my-project\";\u00a0 \u00a0String region = \"us-central1\";\u00a0 \u00a0Cluster cluster = Cluster.newBuilder().build();\u00a0 \u00a0Cluster response =\u00a0 \u00a0 \u00a0 \u00a0clusterControllerClient.createClusterAsync(projectId, region, cluster).get();\u00a0}\n```Specify a Dataproc region in the Location section of the **Set up cluster** panel on the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console.\n## What's next\n- [Geography and Regions](/docs/geography-and-regions) \n- [Compute Engine Engine\u2192Regions and Zones](/compute/docs/regions-zones/regions-zones) \n- [Compute Engine\u2192Global, Regional, and Zonal Resources](/compute/docs/regions-zones/global-regional-zonal-resources) \n- [Dataproc Auto Zone Placement](/dataproc/docs/concepts/auto-zone)", "guide": "Dataproc"}