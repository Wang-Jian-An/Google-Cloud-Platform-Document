{"title": "Dataproc - \u4f7f\u7528 DataprocFileOutputCommitter \u904b\u884c Spark \u4f5c\u696d", "url": "https://cloud.google.com/dataproc/docs/guides/dataproc-fileoutput-committer?hl=zh-cn", "abstract": "# Dataproc - \u4f7f\u7528 DataprocFileOutputCommitter \u904b\u884c Spark \u4f5c\u696d\n**DataprocFileOutputCommitter** \u529f\u80fd\u662f\u958b\u6e90 `FileOutputCommitter` \u7684\u589e\u5f37\u7248\u672c\u3002\u5b83\u652f\u6301 Apache Spark \u4f5c\u696d\u5c0d\u8f38\u51fa\u4f4d\u7f6e\u9032\u884c\u4f75\u767c\u5beb\u5165\u3002\n", "content": "## \u9650\u5236\n`DataprocFileOutputCommitter` \u529f\u80fd\u652f\u6301\u5728\u4f7f\u7528\u4ee5\u4e0b\u6620\u50cf\u7248\u672c\u5275\u5efa\u7684 Dataproc Compute Engine \u96c6\u7fa3\u4e0a\u904b\u884c\u7684 Spark \u4f5c\u696d\uff1a\n- 2.1 \u6620\u50cf\u7248\u672c 2.1.10 \u53ca\u66f4\u9ad8\u7248\u672c\n- 2.0 \u6620\u50cf\u7248\u672c 2.0.62 \u53ca\u66f4\u9ad8\u7248\u672c## \u4f7f\u7528 DataprocFileOutputCommitter\n\u8981\u4f7f\u7528\u6b64\u529f\u80fd\uff0c\u9700\u8981\u6eff\u8db3\u4ee5\u4e0b\u524d\u63d0\u689d\u4ef6\uff1a\n- \u4f7f\u7528\u6620\u50cf\u7248\u672c `2.1.10` \u3001 `2.0.62` \u6216\u66f4\u9ad8\u7248\u672c [\u5275\u5efa Dataproc on Compute Engine \u96c6\u7fa3](https://cloud.google.com/dataproc/docs/guides/create-cluster?hl=zh-cn#creating_a_cloud_dataproc_cluster) \u3002\n- \u5728\u5411\u96c6\u7fa3 [\u63d0\u4ea4 Spark \u4f5c\u696d](https://cloud.google.com/dataproc/docs/guides/submit-job?hl=zh-cn#how_to_submit_a_job) \u6642\uff0c\u5c07 `spark.hadoop.mapreduce.outputcommitter.factory.class=org.apache.hadoop.mapreduce.lib.output.DataprocFileOutputCommitterFactory` \u548c `spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs=false` \u8a2d\u7f6e\u7232\u4f5c\u696d\u5c6c\u6027\u3002- Google Cloud CLI \u793a\u4f8b\uff1a\n```\ngcloud dataproc jobs submit spark \\\n\u00a0\u00a0\u00a0\u00a0--properties=spark.hadoop.mapreduce.outputcommitter.factory.class=org.apache.hadoop.mapreduce.lib.output.DataprocFileOutputCommitterFactory,spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs=false \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0other args ...\n```- \u4ee3\u78bc\u793a\u4f8b\uff1a\n```\nsc.hadoopConfiguration.set(\"spark.hadoop.mapreduce.outputcommitter.factory.class\",\"org.apache.hadoop.mapreduce.lib.output.DataprocFileOutputCommitterFactory\")\nsc.hadoopConfiguration.set(\"spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs\",\"false\")\n```Dataproc \u6587\u4ef6\u8f38\u51fa\u63d0\u4ea4\u5668\u5fc5\u9808\u8a2d\u7f6e`spark.hadoop.mapreduce.fileoutputcommitter.marksuccessfuljobs=false`\uff0c\u4ee5\u907f\u514d\u5728\u4f75\u767c\u5beb\u5165\u671f\u9593\u5275\u5efa\u7684\u6210\u529f\u6a19\u8a18\u6587\u4ef6\u4e4b\u9593\u767c\u751f\u885d\u7a81\u3002\u60a8\u4e5f\u53ef\u4ee5\u5728`spark-defaults.conf`\u4e2d\u8a2d\u7f6e\u6b64\u5c6c\u6027\u3002", "guide": "Dataproc"}