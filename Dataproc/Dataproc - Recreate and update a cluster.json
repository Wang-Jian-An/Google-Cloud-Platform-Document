{"title": "Dataproc - Recreate and update a cluster", "url": "https://cloud.google.com/dataproc/docs/guides/recreate-cluster", "abstract": "# Dataproc - Recreate and update a cluster\nDataproc prevents the creation of clusters with image versions prior to 1.3.95, 1.4.77, 1.5.53, and 2.0.27, which were affected by [Apache Log4j security vulnerabilities](https://logging.apache.org/log4j/2.x/security.html) . Dataproc also prevents cluster creation for Dataproc image versions 0.x, 1.0.x, 1.1.x, and 1.2.x. Dataproc advises that, when possible, you create Dataproc clusters with the latest sub-minor image versions.| Image version         | log4j version | Customer guidance |\n|:-----------------------------------------------|:----------------|:---------------------|\n| 2.0.29, 1.5.55, and 1.4.79, or later of each | log4j.2.17.1 | Advised    |\n| 2.0.28, 1.5.54, and 1.4.78      | log4j.2.17.0 | Advised    |\n| 2.0.27, 1.5.53, and 1.4.77      | log4j.2.16.0 | Strongly recommended |\n| 2.0.26, 1.5.52, and 1.4.76, or earlier of each | Older version | Discontinue use  |See the [Dataproc release notes](/dataproc/docs/release-notes) for specific image and `log4j` update information.\n", "content": "## Steps to recreate and update a cluster\nYou can use the `gcloud` command-line tool or the Dataproc API to copy configuration from an existing cluster, update the copied configuration, and then create a new cluster with the updated configuration.\nThe example instructions show updating the image version setting in a cluster configuration. You can change the example to update different cluster configuration settings.\nThe recommended practice is to specify the`major.minor`image version for production environments or when compatibility with specific component versions is important. The sub-minor and OS distributions are automatically set to the latest weekly release.- Set variables.```\nexport PROJECT=project-id\nexport REGION=region\nexport OLD_CLUSTER=old-cluster-name\nexport NEW_CLUSTER=new-cluster-name\nexport NEW_IMAGE_VERSION=image-version (for example, '2.2-debian12')\n```\n- Export the existing (old) cluster configuration to a YAML file.```\ngcloud dataproc clusters export $OLD_CLUSTER \\\n\u00a0\u00a0\u00a0\u00a0--project=$PROJECT \\\n\u00a0\u00a0\u00a0\u00a0--region=$REGION > \"${OLD_CLUSTER}-config.yaml\"\n```\n- Update the configuration. The following example uses`sed`to update the image version.```\nsed -E \"s|(^[[:blank:]]+)imageVersion: .+|\\1imageVersion: ${NEW_IMAGE_VERSION}|g\" \"${OLD_CLUSTER}-config.yaml\" | sed -E '/^[[:blank:]]+imageUri: /d' > \"${NEW_CLUSTER}-config-updated.yaml\"\n```\n- Create a new cluster with a new name and the updated configuration.```\ngcloud dataproc clusters import $NEW_CLUSTER \\\n\u00a0\u00a0\u00a0\u00a0--project=$PROJECT \\\n\u00a0\u00a0\u00a0\u00a0--region=$REGION \\\n\u00a0\u00a0\u00a0\u00a0--source=\"${NEW_CLUSTER}-config-updated.yaml\"\n```\n- After confirming your workloads run in the new cluster without issues, delete the existing (old) cluster. **IMPORTANT:** This step deletes all data stored in HDFS and on local disk in your cluster.```\ngcloud dataproc clusters delete $OLD_CLUSTER \\\n\u00a0\u00a0\u00a0\u00a0--project=$PROJECT \\\n\u00a0\u00a0\u00a0\u00a0--region=$REGION\n```\nThe example instructions show updating the cluster name and the image version settings in a cluster configuration. You can change the example variables to update different cluster configuration settings.\nThe recommended practice is to specify the`major.minor`image version for production environments or when compatibility with specific component versions is important. The sub-minor and OS distributions are automatically set to the latest weekly release.- Set variables.```\nexport PROJECT=project-id\nexport REGION=region\nexport OLD_CLUSTER=old-cluster-name\nexport NEW_CLUSTER=new-cluster-name\nexport NEW_IMAGE_VERSION=image-version (for example, '2.2-debian12')\n```\n- Export the existing (old) cluster configuration to a JSON file.```\ncurl -X GET -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \"https://dataproc.googleapis.com/v1/projects/${PROJECT}/regions/${REGION}/clusters/${OLD_CLUSTER}?alt=json\" > \"${OLD_CLUSTER}-config.json\"\n```\n- Update the configuration. The following example uses`jq`to update the cluster name and the image version.```\njq \".clusterName = \\\"${NEW_CLUSTER}\\\" | .config.softwareConfig.imageVersion=\\\"${NEW_IMAGE_VERSION}\\\" | del(.config.workerConfig.imageUri) | del(.config.masterConfig.imageUri)\" \"${OLD_CLUSTER}-config.json\" > \"${NEW_CLUSTER}-config-updated.json\"\n```\n- Import the updated cluster configuration to create a new cluster with the updated configuration.```\ncurl -i -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json; charset=utf-8\" -d \"@${NEW_CLUSTER}-config-updated.json\" \"https://dataproc.googleapis.com/v1/projects/${PROJECT}/regions/${REGION}/clusters?alt=json\"\n```\n- After confirming your workloads run in the new cluster without issues, delete the existing (old) cluster. **IMPORTANT:** This step deletes all data stored in HDFS and on local disk in your cluster.```\ncurl -X DELETE -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \"https://dataproc.googleapis.com/v1/projects/${PROJECT}/regions/${REGION}/clusters/${OLD_CLUSTER}\"\n```\nThe console does not support recreating a cluster by importing a cluster configuration.", "guide": "Dataproc"}