{"title": "Dataproc - Use workflows", "url": "https://cloud.google.com/dataproc/docs/concepts/workflows/use-workflows", "abstract": "# Dataproc - Use workflows\nYou set up and run a workflow by:\n- Creating a workflow template\n- Configuring a managed (ephemeral) cluster or selecting an existing cluster\n- Adding jobs\n- Instantiating the template to run the workflow\nYou can [parameterize a workflow template](/dataproc/docs/concepts/workflows/workflow-parameters) to use it dynamically for different workflows. You can also [use YAML files](/dataproc/docs/concepts/workflows/using-yamls) or call the [InstantiateInline](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/instantiateInline) API to define and run an [inline](/dataproc/docs/concepts/workflows/overview#inline) workflow that does not create or modify workflow template resources.\n", "content": "## Creating a template\nRun the following `command` to create a Dataproc workflow template resource.\n```\ngcloud dataproc workflow-templates create TEMPLATE_ID \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION\n```\nNotes:- : Specify the [region](/dataproc/docs/concepts/workflows/compute/docs/regions-zones#available) where your template will run.\n- : Provide an ID for your template, such as, \"workflow-template-1\".\n- CMEK encryption. You can add the [--kms-key](/sdk/gcloud/reference/dataproc/workflow-templates/create#--kms-key) flag to use [CMEK encryption](/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_workflow_template_data) on workflow template job arguments.\nSubmit a [WorkflowTemplate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates#resource-workflowtemplate) as part of a [workflowTemplates.create](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/create) request. You can add the [WorkflowTemplate.EncryptionConfig.kmsKey](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates#encryptionconfig) field to use [CMEK encryption](/dataproc/docs/concepts/configuring-clusters/customer-managed-encryption#use_cmek_with_workflow_template_data) on workflow template job arguments. kmsKeyYou can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\n### Configuring or selecting a cluster\nDataproc can create and use a new, \"managed\" cluster for your workflow or an existing cluster.\n- **Existing cluster:** See [Using cluster selectors with workflows](/dataproc/docs/concepts/workflows/cluster-selectors) to select an existing cluster for your workflow.\n- **Managed cluster:** You must configure a managed cluster for your workflow. Dataproc will create this new cluster to run workflow jobs, then delete the cluster at the end of the workflow. You can configure a managed cluster for your workflow using the `gcloud` command-line tool or the Dataproc API.\nUse flags inherited from [gcloud dataproc clustercreate](/sdk/gcloud/reference/dataproc/clusters/create) to configure the managed cluster, such as the number of workers and the master and worker machine type. Dataproc will add a suffix to the cluster name to ensure uniqueness.\n```\ngcloud dataproc workflow-templates set-managed-cluster template-id \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--master-machine-type=machine-type \\\n\u00a0\u00a0\u00a0\u00a0--worker-machine-type=machine-type \\\n\u00a0\u00a0\u00a0\u00a0--num-workers=number \\\n\u00a0\u00a0\u00a0\u00a0--cluster-name=cluster-name\n```See [WorkflowTemplatePlacement.ManagedCluster](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates#managedcluster) . This field is provided as part of a completed [WorkflowTemplate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates#resource-workflowtemplate) submitted with a [workflowTemplates.create](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/create) or [workflowTemplates.update](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/update) request.You can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\n## Adding jobs to a template\nAll jobs run concurrently unless you specify one or more job dependencies. A job's dependencies are expressed as a list of other jobs that must finish successfully before the ultimate job can start. You must provide a `step-id` for each job. The ID must be unique within the workflow, but does not need to be unique globally.\nUse job type and flags inherited from [gcloud dataproc jobs submit](/sdk/gcloud/reference/dataproc/jobs/submit) to define the job to add to the template. You can optionally use the `\u2011\u2011start-after` `` flag to have the job start after the completion of one or more other jobs in the workflow.\nCurrently, the`--max-failures-per-hour`and`--max-failures-per-hour` [restartable job flags](/dataproc/docs/concepts/jobs/restartable-jobs#creating_and_using_restartable_jobs) are not supported in Dataproc workflow template jobs.\n **Examples:** \nAdd Hadoop job \"foo\" to the \"my-workflow\" template.\n```\ngcloud dataproc workflow-templates add-job hadoop \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--step-id=foo \\\n\u00a0\u00a0\u00a0\u00a0--workflow-template=my-workflow \\\n\u00a0\u00a0\u00a0\u00a0-- space separated job args\n```\nAdd job \"bar\" to the \"my-workflow\" template, which will be run after workflow job \"foo\" has completed successfully.\n```\ngcloud dataproc workflow-templates add-job job-type \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--step-id=bar \\\n\u00a0\u00a0\u00a0\u00a0--start-after=foo \\\n\u00a0\u00a0\u00a0\u00a0--workflow-template=my-workflow \\\n\u00a0\u00a0\u00a0\u00a0-- space separated job args\n```\nAdd another job \"baz\" to \"my-workflow\" template to be run after the successful completion of both \"foo\" and \"bar\" jobs.\n```\ngcloud dataproc workflow-templates add-job job-type \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--step-id=baz \\\n\u00a0\u00a0\u00a0\u00a0--start-after=foo,bar \\\n\u00a0\u00a0\u00a0\u00a0--workflow-template=my-workflow \\\n\u00a0\u00a0\u00a0\u00a0-- space separated job args\n```See [WorkflowTemplate.OrderedJob](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates#orderedjob) . This field is provided as part of a completed [WorkflowTemplate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates#resource-workflowtemplate) submitted with a [workflowTemplates.create](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/create) or [workflowTemplates.update](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/update) request.\nCurrently, the`maxFailuresPerHour`and`maxFailuresTotal` [OrderedJob.JobScheduling](/dataproc/docs/reference/rest/v1/JobScheduling) fields are not supported in Dataproc workflow template jobs.You can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\nCurrently, the`Max restarts per hour` [restartable job option](/dataproc/docs/concepts/jobs/restartable-jobs#creating_and_using_restartable_jobs) is not supported in Dataproc workflow template jobs.\n## Running a workflow\nThe instantiation of a workflow template runs the workflow defined by the template. Multiple instantiations of a template are supported\u2014you can run a workflow multiple times.\n```\ngcloud dataproc workflow-templates instantiate template-id \\\n\u00a0\u00a0\u00a0\u00a0--region=region\n```\nThe command returns an operation ID, which you can use to track workflow status.\n **Example command and output:** \n```\ngcloud beta dataproc workflow-templates instantiate my-template-id \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n...\nWorkflowTemplate [my-template-id] RUNNING\n...\nCreated cluster: my-template-id-rg544az7mpbfa.\nJob ID teragen-rg544az7mpbfa RUNNING\nJob ID teragen-rg544az7mpbfa COMPLETED\nJob ID terasort-rg544az7mpbfa RUNNING\nJob ID terasort-rg544az7mpbfa COMPLETED\nJob ID teravalidate-rg544az7mpbfa RUNNING\nJob ID teravalidate-rg544az7mpbfa COMPLETED\n...\nDeleted cluster: my-template-id-rg544az7mpbfa.\nWorkflowTemplate [my-template-id] DONE\n```\nSee\n [workflowTemplates.instantiate](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/instantiate) \n.\nYou can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\n## Workflow job failures\nA failure in any job in a workflow will cause the workflow to fail. Dataproc will seek to mitigate the effect of failures by causing all concurrently executing jobs to fail and preventing subsequent jobs from starting.\n## Monitoring and listing a workflow\nTo monitor a workflow:\n```\ngcloud dataproc operations describe operation-id \\\n\u00a0\u00a0\u00a0\u00a0--region=region\n```\n **Note:** The operation-id is returned when you instantiate the workflow with `gcloud dataproc workflow-templates instantiate` (see [Running a workflow](#running_a_workflow) ).\nTo list workflow status:\n```\ngcloud dataproc operations list \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0--filter=\"labels.goog-dataproc-operation-type=WORKFLOW AND status.state=RUNNING\"\n```To monitor a workflow, use the Dataproc [operations.get](/dataproc/docs/reference/rest/v1/projects.regions.operations/get) API.\nTo list running workflows, use the Dataproc [operations.list](/dataproc/docs/reference/rest/v1/projects.regions.operations/list) API with a label filter.You can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\n## Terminating a workflow\nYou can end a workflow using the Google Cloud CLI or by calling the Dataproc API.\n**Note:** Ending a workflow cancels running workflow jobs and, if the workflow runs on a managed (ephemeral) cluster, deletes the managed cluster.\n```\ngcloud dataproc operations cancel operation-id \\\n\u00a0\u00a0\u00a0\u00a0--region=region\n```\n **Note:** \nThe operation-id that is returned when you instantiate the workflow with\n`gcloud dataproc workflow-templates instantiate`\n(see\n [Running a workflow](#running_a_workflow) \n).\nSee [operations.cancel](/dataproc/docs/reference/rest/v1/projects.regions.operations/cancel) API.You can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\n## Updating a workflow template\nUpdates do not affect running workflows. The new template version will only apply to new workflows.\nWorkflow templates can be updated by issuing new `gcloud workflow-templates` commands that reference an existing workflow template-id:- [gcloud dataproc workflow-templates add job](#adding_jobs_to_a_template) \n- [gcloud dataproc workflow-templates set-managed-cluster](#configuring_or_selecting_a_cluster) \n- [gcloud dataproc workflow-templates set-cluster-selector](/dataproc/docs/concepts/workflows/cluster-selectors#adding_a_cluster_selector_to_a_template) to an existing workflow template.\nTo make an update to a template with the REST API:- Call [workflowTemplates.get](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/get) , which returns the current template with the`version`field filled in with the current server version.\n- Make updates to the fetched template.\n- Call [workflowTemplates.update](/dataproc/docs/reference/rest/v1/projects.locations.workflowTemplates/update) with the updated template.\nAs a guard against concurrent modifications, a request to update a template must specify the current server version in the`workflowTemplate.version`field.You can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.\n## Deleting a workflow template\n```\ngcloud dataproc workflow-templates delete template-id \\\n\u00a0\u00a0\u00a0\u00a0--region=region\n```\n **Note:** The operation-id that is returned when you instantiate the workflow with `gcloud dataproc workflow-templates instantiate` (see [Running a workflow](#running_a_workflow) ).\nSee\n [workflowTemplates.delete](/dataproc/docs/reference/rest/v1/projects.regions.workflowTemplates/delete) \n.\nYou can view existing workflow templates and instantiated workflows from the Dataproc [Workflows](https://console.cloud.google.com/dataproc/workflows/instances) page in Google Cloud console.", "guide": "Dataproc"}