{"title": "Dataproc - Cluster web interfaces", "url": "https://cloud.google.com/dataproc/docs/concepts/accessing/cluster-web-interfaces", "abstract": "# Dataproc - Cluster web interfaces\n**Avoid Security Vulnerabilities.** Open ports and improperly configured firewall rules on a public network can allow unauthorized users to execute arbitrary code. Review [Specify a source IP range for subnet firewall rules](/dataproc/docs/concepts/configuring-clusters/network#specify_a_source_ip_range_for_subnet_firewall_rules)  [Create an SSH tunnel](#create_an_ssh_tunnel) to establish a secure connection to your cluster's master instance. Apache Hadoop YARN provides REST APIs that share the same ports as the YARN web interfaces (default port 8088). By default, users who can reach the YARN web interface can create applications, submit jobs, and may be able to perform Cloud Storage operations.See [Allowed YARN Resource Manager REST APIs](#allowed_yarn_resourcemanager_rest_apis) for information on setting allowed YARN Resource Manager REST API methods.\nSome of the core open source components included with Dataproc clusters, such as [Apache Hadoop](https://hadoop.apache.org/) and [Apache Spark](http://spark.apache.org/) , provide web interfaces. These interfaces can be used to manage and monitor cluster resources and facilities, such as the YARN resource manager, the Hadoop Distributed File System (HDFS), MapReduce, and Spark. Other components or applications that you install on your cluster may also provide web interfaces (see, for example, [Install and run a Jupyter notebook on a Dataproc cluster](/dataproc/docs/tutorials/jupyter-notebook) ).\n**Objective:** The steps and examples shown below show you how to securely connect to web interfaces running on your Dataproc cluster using an SSH tunnel from your local network or Google Cloud Cloud Shell to your cluster's Compute Engine network.\n**Use the Component Gateway to connect to core\nand optional component web interfaces.** Clusters created with Dataproc image [version 1.3.29](/dataproc/docs/concepts/versioning/dataproc-release-1.3) and later can install and enable access to [component](/dataproc/docs/concepts/components/overview#available_components) web interfaces, including YARN, HDFS, Jupyter, and Zeppelin UIs, without relying on [SSH tunnels](#create_an_ssh_tunnel) or [modifying firewall rules](/dataproc/docs/concepts/configuring-clusters/network) to allow inbound traffic. See [Dataproc Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways) for more information.See **SSH into a Dataproc cluster** to open an SSH session on a Dataproc cluster's master node.\n", "content": "## Available interfaces\nThe following interfaces are available on a Dataproc cluster master node (replace `master-host-name` with the name of your master node).\nThe cluster **master-host-name** is the name of your Dataproc cluster followed by an`-m`suffix\u2014for example, if your cluster is named \"my-cluster\", the master-host-name would be \"my-cluster-m\".\n| Web UI    | Port | URL       |\n|:----------------------|-------:|:-----------------------------|\n| YARN ResourceManager1 | 80882 | http://master-host-name:8088 |\n| HDFS NameNode   | 987034 | http://master-host-name:9870 |\nThe Yarn ResourceManager UI is not supported on Dataproc [High Availability (HA) clusters](/dataproc/docs/concepts/configuring-clusters/high-availability) .\nOn Kerberos enabled clusters, the YARN ResourceManager web UI port is 8090, and it runs on HTTPS.\nOn Kerberos enabled clusters, the HDFS Namenode web UI port is 9871, and it runs on HTTPS.\nIn earlier Dataproc releases (pre-1.2), the HDFS Namenode web UI port was 50070.\nThe YARN ResourceManager has links for all currently running and completed MapReduce and Spark Applications web interfaces under the \"Tracking UI\" column.\n### Allowed YARN ResourceManager REST APIs\nWhen you create a cluster, Dataproc sets the yarn-site.xml `yarn.resourcemanager.webapp.methods-allowed` [property](/dataproc/docs/concepts/configuring-clusters/cluster-properties) to \"GET,HEAD\". which restricts the HTTP methods that can be called on the YARN Resource Manager web UI and [REST APIs](https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/ResourceManagerRest.html) to the `GET` and `HEAD` methods. This default setting also disables job submission and modifications via the YARN REST API.\nYou can override the default values to enable specific HTTP methods on port 8088 by setting this property to one or more comma-separated HTTP method names. An `ALL` value will allow all HTTP methods on the port.\nExample:\n```\ngcloud dataproc clusters create cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--properties=^#^yarn:yarn.resourcemanager.webapp.methods-allowed=GET,POST,DELETE \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n```\n**Recommendation:** If you set this property to allow non-default HTTP methods, make sure to configure firewall rules and other security settings to restrict access to port 8088.\n## Connecting to web interfaces\nYou can connect to web interfaces running on a Dataproc cluster using the [Dataproc Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways) , your project's [Cloud Shell](/shell) , or the Google Cloud CLI [gcloud](/sdk/gcloud) command-line tool:\n- Component Gateway: Connect with one click to Hadoop, Spark, and other component Web UI interfaces from the Google Cloud console. You enable the [Component Gateway](/dataproc/docs/concepts/accessing/dataproc-gateways) when you create your cluster.\n- Cloud Shell: The Cloud Shell in the Google Cloud console has the gcloud CLI commands and utilities pre-installed, and it provides a [Web Preview](/shell/docs/using-web-preview) feature that allows you to quickly connect through an SSH tunnel to a web interface port on a cluster. However, a connection to the cluster from Cloud Shell uses local port forwarding, which opens a connection to only one port on a cluster web interface\u2014multiple commands are needed to connect to multiple ports. Also, Cloud Shell sessions automatically exit after a period of inactivity (30 minutes).\n- Google Cloud CLI: The `gcloud compute ssh` command with [dynamic port forwarding](https://en.wikipedia.org/wiki/Port_forwarding#Dynamic_port_forwarding%20class=%22external%22) allows you to establish an SSH tunnel and run a [SOCKS](https://en.wikipedia.org/wiki/SOCKS) proxy server on top of the tunnel. After issuing this command, you must configure your local browser to use the SOCKS proxy. This connection method allows you to connect to multiple ports on a cluster web interface. See [Can I use local port forwarding instead of a SOCKS proxy?](#can_i_use_local_port_forwarding_instead_of_a_socks_proxy) for more information.\n### Set commonly used command variables\nTo make copying and running command-line examples on your local machine or in [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) easier, set `gcloud dataproc` command variables. Additional variables may need to be set for some of the command examples shown on this page.\n```\nexport PROJECT=project;export HOSTNAME=hostname;export ZONE=zone\n``````\nset PROJECT=project && set HOSTNAME=hostname && set ZONE=zone\n```\n- Set **PROJECT** to your Google Cloud [project ID](https://console.cloud.google.com/) \n- Set **HOSTNAME** to the name of [master node](https://console.cloud.google.com/compute/instances) in your Dataproc cluster (the master name ends with a`-m`suffix)\n- Set **ZONE** to the [zone](https://console.cloud.google.com/compute/instances) of the VMs in your Dataproc cluster (for example, \"us-central1-b\")\n### Create an SSH tunnel\nRun the following `gcloud` command on your local machine to  set up an SSH tunnel from an open port on your local machine to the  master instance of your cluster, and run a local SOCKS proxy server  listening on the port.\nBefore running the command, on your local machine:- [Set commonly used command variables](#set_commonly_used_command_variables) \n- Set a **PORT** variable to an open port on your local machine.   Port`1080`is an arbitrary but typical choice since it is   likely to be open.```\nPORT=number\n```\n```\ngcloud compute ssh ${HOSTNAME} \\\n\u00a0\u00a0\u00a0\u00a0--project=${PROJECT} --zone=${ZONE} -- \\\n\u00a0\u00a0\u00a0\u00a0-D ${PORT} -N\n``````\ngcloud compute ssh %HOSTNAME% ^\n\u00a0\u00a0\u00a0\u00a0--project=%PROJECT% --zone=%ZONE% -- ^\n\u00a0\u00a0\u00a0\u00a0-D %PORT% -N\n```\nThe `--` separator allows you to add [SSH](https://www.freebsd.org/cgi/man.cgi?query=ssh&sektion=1) arguments to the `gcloud compute ssh` command, as follows:- `-D`specifies dynamic application-level port forwarding.\n- `-N`instructs`gcloud`not to open a remote shell.\nThis `gcloud` command creates an SSH tunnel that operates independently from other SSH shell sessions, keeps tunnel-related errors out of the shell output, and helps prevent inadvertent closures of the tunnel.\nIf the ssh command fails with the error message `bind: Cannot assign requested address` , a likely cause is that the requested port is in use. Try running the command with a different **PORT** variable value.\nThe above command runs in the foreground, and must continue running to keep the tunnel active. The command should exit automatically if and when the you delete the cluster.\n **Opt to run the command in the background** . You can run the command as a background process by adding the `-n` flag  (`-- -D ${PORT} -N -n`), which redirects`stdin`from`/dev/null`. Note that the`-n`flag may not be supported in all operating systems.\n- Open Google Cloud [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) . **Cloud Shell Session Timeout:** Cloud Shell sessions automatically exit after a period of inactivity (30 minutes).\n- Run the `gcloud` command, below, in Cloud Shell  to set up an SSH tunnel from a  Cloud Shell preview port to a web interface port on the master node on  your cluster. Before running the command, in Cloud Shell :\n- [Set commonly used command variables](#set_commonly_used_command_variables) \n- Set a **PORT1** variable to a Cloud Shell port   in the port range 8080 - 8084, and set a **PORT2** variable   to the web interface port on the master node on your   Dataproc cluster.```\nPORT1=number\nPORT2=number\n```\n```\ngcloud compute ssh ${HOSTNAME} \\\n\u00a0\u00a0\u00a0\u00a0--project=${PROJECT} --zone=${ZONE} -- \\\n\u00a0\u00a0\u00a0\u00a0-4 -N -L ${PORT1}:${HOSTNAME}:${PORT2}\n```The `--` separator allows you to add [SSH](https://www.freebsd.org/cgi/man.cgi?query=ssh&sektion=1) arguments to the `gcloud compute ssh` command, as follows:- `-4`instructs ssh to only use IPv4.\n- `-N`instructs`gcloud`not to open a remote shell.\n- `-L ${PORT1}:${HOSTNAME}:${PORT2}`specifies local port forwarding from the specified Cloud Shell **PORT1** to cluster **HOSTNAME** : **PORT2** .\nThis `gcloud` command creates an SSH tunnel that operates independently from other SSH shell sessions, keeps tunnel-related errors out of the shell output, and helps prevent inadvertent closures of the tunnel.\n### Configure your browser\nYour SSH tunnel supports traffic proxying using the SOCKS protocol.  To configure your browser to use the proxy, start a new browser session with  proxy server parameters. Here's an example that uses the Google Chrome browser. `HOSTNAME` is the name of the cluster's master node (see [Set commonly used command variables](#set_commonly_used_command_variables) ).```\n/usr/bin/google-chrome \\\n\u00a0\u00a0\u00a0\u00a0--proxy-server=\"socks5://localhost:${PORT}\" \\\n\u00a0\u00a0\u00a0\u00a0--user-data-dir=/tmp/${HOSTNAME}\n``````\n\"/Applications/Google Chrome.app/Contents/MacOS/Google Chrome\" \\\n\u00a0\u00a0\u00a0\u00a0--proxy-server=\"socks5://localhost:${PORT}\" \\\n\u00a0\u00a0\u00a0\u00a0--user-data-dir=/tmp/${HOSTNAME}\n``````\n\"%ProgramFiles(x86)%\\Google\\Chrome\\Application\\chrome.exe\" ^\n\u00a0\u00a0\u00a0\u00a0--proxy-server=\"socks5://localhost:%PORT%\" ^\n\u00a0\u00a0\u00a0\u00a0--user-data-dir=\"%Temp%\\%HOSTNAME%\"\n```\n **Windows 32 bit Users:** Change`%ProgramFiles(x86)%`to`%ProgramFiles%`in the command  above.\nThis command uses the following Chrome browser flags:- `-proxy-server=\"socks5://localhost:1080\"`tells Chrome to send all`http://`and`https://`URL requests through the SOCKS proxy server`localhost:${PORT}`, using version 5 of the SOCKS protocol. **${PORT}** is the port variable you set in [Create an SSH tunnel](#create_an_ssh_tunnel) . Hostnames for URLs are resolved by the proxy server, not locally by Chrome.\n- `--user-data-dir=/tmp/${HOSTNAME}`forces Chrome to open a new window that is not tied to an existing Chrome session. Without this flag, Chrome may open a new window attached to an existing Chrome session, ignoring your`--proxy-server`setting. The value set for`--user-data-dir`can be any non-existent path.\n **Proxy extensions:** Proxy management extensions that simplify management and use of the proxy in your browser are available for Chrome, Firefox, and other web browsers.You do not need to configure your local browser when using Cloud Shell.  After [creating an SSH tunnel](#create_an_ssh_tunnel) , use Cloud Shell  web preview to [connect to the cluster interface](#connect_to_the_cluster_interface) .\n### Connect to the cluster interface\nOnce your local browser is configured to use the proxy, you can navigate to the web interface URL on your Dataproc cluster (see [Available interfaces](#interfaces) ). The browser URL has the following format and content: `http://` `` `-m:` `` (cluster interface port)Click the Cloud Shell [Web Preview](/shell/docs/using-web-preview) button ,  and then select either:- \"Preview on port 8080\", or\n- \"Change port\" and insert the port number in the dialog\naccording to the Cloud Shell\n **PORT1** \nnumber  (port 8080 - 8084) you passed to the\n`gcloud compute ssh`\ncommand in\n [Create an SSH tunnel](#create_an_ssh_tunnel) \n.\nA browser window opens that connects to the web interface port on the  cluster master node.\nChrome Browser Messages: When using a Chrome browser, you may see messages of the following type in the terminal window or Cloud Shell that you used to [create an SSH tunnel](#create_an_ssh_tunnel) .```\nchannel 15: open failed: administratively prohibited: open failed\nchannel 16: open failed: administratively prohibited: open failed\nchannel 17: open failed: administratively prohibited: open failed\n```These are not fatal error messages. The Chrome browser issues these messages when it is unable to load a page, and you may see these messages even when you can successfully connect to the application interface on your cluster.\n## FAQ And debugging tips\n### What if I don't see the UI in my browser?\nIf you don't see the UIs in your browser, the two most common reasons are:\n- You have a network connectivity issue, possibly due to a firewall. Run the following command (after [setting local variables](#set_commonly_used_command_variables) ) to see if you can SSH to the master instance. If you can't, it signals a connectivity issue.\n```\ngcloud compute ssh ${HOSTNAME}-m \\\n\u00a0\u00a0\u00a0\u00a0--project=${PROJECT}\n``````\ngcloud compute ssh %HOSTNAME%-m ^\n\u00a0\u00a0\u00a0\u00a0--project=%PROJECT%\n```\n- Another proxy is interfering with the SOCKS proxy. To check the proxy, run the following `curl` command (available on Linux and macOS):\n```\ncurl -Is --socks5-hostname localhost:1080 http://cluster-name-m:8088\n``````\ncurl.exe -Is --socks5-hostname localhost:1080 http://cluster-name-m:8088\n```\nIf you see an HTTP response, the proxy is working, so it's possible that the SOCKS proxy is being interrupted by another proxy or browser extension.\n### Can I use local port forwarding instead of a SOCKS proxy?\nInstead of the SOCKS proxy, it's possible to access web application UIs running on your master instance with SSH local port forwarding, which forwards the master's port to a local port. For example, the following command lets you access `localhost:1080` to reach `cluster-name-m:8088` without SOCKS (see [Set commonly used command variables](#set_commonly_used_command_variables) ):\n```\ngcloud compute ssh ${HOSTNAME}-m \\\n\u00a0\u00a0\u00a0\u00a0--project=${PROJECT} -- \\\n\u00a0\u00a0\u00a0\u00a0-L 1080:${HOSTNAME}-m:8088 -N -n\n``````\ngcloud compute ssh %HOSTNAME%-m ^ \n\u00a0\u00a0\u00a0\u00a0--project=%PROJECT% -- ^ \n\u00a0\u00a0\u00a0\u00a0-L 1080:%HOSTNAME%-m:8088 -N -n\n```\nWith a SOCKS proxy, you access the remote UI interface running on the master instance with`http://cluster-name-m:port`, but with local port forwarding you access the master instance's web application UI at`http://localhost:port`.\nUsing a SOCKS proxy may be preferable to using local port forwarding since the proxy:\n- allows you to access all web application ports without having to set up a port forward tunnel for each UI port\n- allows the Spark and Hadoop web UIs to correctly resolve DNS hosts", "guide": "Dataproc"}