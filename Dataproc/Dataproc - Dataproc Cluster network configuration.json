{"title": "Dataproc - Dataproc Cluster network configuration", "url": "https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network", "abstract": "# Dataproc - Dataproc Cluster network configuration\nThis page explains Dataproc cluster network configuration requirements and options.\n", "content": "## Dataproc connectivity requirements\nDataproc cluster [Virtual Machines (VMs)](/compute/docs/instances) must be able to communicate with each other using ICMP, TCP (all ports), and UDP (all ports) protocols.\nThe `default` VPC network's [default-allow-internal](/vpc/docs/firewalls#more_rules_default_vpc) firewall rule meets Dataproc cluster connectivity requirements and allows ingress from the `10.128.0.0/9` source range from **all** VMs on the VPC network as follows:\n| Rule     | Network | Direction | Priority | Source range | Protocols:Ports    |\n|:-----------------------|:----------|:------------|-----------:|:---------------|:-----------------------------|\n| default-allow-internal | default | ingress  |  65534 | 10.128.0.0/9 | tcp:0-65535,udp:0-65535,icmp |\n- If you delete the `default-allow-internal` firewall rule, ingress traffic on the `default` network is blocked by the [implied deny ingress rule](/vpc/docs/firewalls#default_firewall_rules) .\n- If you delete the `default-allow-internal` firewall rule or don't use the `default` VPC network, you must create your own rule that meets Dataproc connectivity requirements, and then apply it to your cluster's VPC network.\n**Best practice:**  [Create an ingress firewall rule](#create_an_ingress_firewall_rule) for your cluster VPC network that allows ingress connectivity only among cluster VMs by using a source IP range or by identifying cluster VMs by network tag or service account.\n**Note:** Using tags or service accounts to identify cluster VMs eliminates the need to identify cluster VMs by source IP address range.\n## Create an ingress firewall rule\nIf you or your network or security administrator create an [ingress firewall rule](/vpc/docs/using-firewalls#creating_firewall_rules) to apply to a Dataproc cluster VPC network, it must have the following characteristics:\n- The [sources](/vpc/docs/firewalls#sources_for_the_rule) parameter specifies the sources for packets. All Dataproc cluster VMs must be able to communicate with each other. You can identify the VMs in the cluster by IP address range, source tags, or service accounts associated with the VMs.- **Don't omit a source parameter specification.** If you omit specifying source IP ranges, source tags, or source service accounts, the firewall rule will use the IP address range`0.0.0.0/0`(any IP address) as the source. If your Dataproc VMs have external IP addresses, this means they can accept traffic from **anywhere** on the internet. Therefore, **define the source to be as narrow as possible** to meet your needs and secure your cluster.\n- The [target](/vpc/docs/firewalls#rule_assignment) for the rule must identify the cluster VMs. The target can be all VMs in the VPC network, or you can identify VMs by IP address range, target tag, or target service account.\n- The rule must include the following [protocols and ports](/vpc/docs/firewalls#protocols_and_ports) :- TCP (all ports, 0 through 65535)\n- UDP (all ports, 0 through 65535)\n- ICMP\nDataproc uses services that run on multiple ports. Specifying all ports helps the services run successfully.\n### Diagnose your VPC firewall rules\nTo audit packets not processed by higher priority firewall rules, you can create two low priority (65534) deny firewall rules. Unlike the implied firewall rules, you can enable [firewall rules logging](/vpc/docs/firewall-rules-logging) on each of these low priority rules:\n- An ingress deny rule (sources `0.0.0.0/0` , all protocols, all targets in the VPC network)\n- An egress deny rule (destinations `0.0.0.0/0` , all protocols, all targets in the VPC network)\n- With these low priority rules and firewall rules logging, you can log packets not processed by higher priority, and potentially more specific, firewall rules. These two low priority rules also align with security best practices by implementing a \"final drop packets\" strategy.\n- Examine the firewall rules logs for these rules to determine if you need to create or amend higher priority rules to permit packets. For example, if packets sent between Dataproc cluster VMs are dropped, this can be a signal that your firewall rules need to be adjusted.## Create a VPC network\nInstead of using the `default` VPC network, you can create your own [auto mode](/vpc/docs/create-modify-vpc-networks#create-auto-network) or [custom](/vpc/docs/create-modify-vpc-networks#create-custom-network) VPC network. When you create the cluster, you associate your network with the cluster.\n**Assured Workloads environment:** When you use an [Assured Workloads environment](/assured-workloads/docs/deploy-resource) for regulatory compliance, the cluster, its VPC network, and its Cloud Storage buckets must be contained within the Assured Workloads environment.\n## Create a cluster that uses your VPC network\nUse [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) with the `\u2011\u2011network` or `\u2011\u2011subnet` flag to create a cluster on a subnet in your network. If you use the \u2011\u2011network flag, the cluster will use a subnetwork with the same name as the specified network in the region where the cluster is created.\n`--network example` . Since auto networks are created with subnets in each region, with each subnet given the network name, you can pass the auto mode VPC network name to the `\u2011\u2011network` flag. The cluster will use the auto mode VPC subnetwork in the region specified with the \u2011\u2011region flag.\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--network NETWORK_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\n`--subnet example` . You can use the `\u2011\u2011subnet` flag to create a cluster that uses an auto mode or custom VPC network subnet in the cluster region. Specify the full resource path of the subnet.\n```\ngcloud dataproc clusters create CLUSTER_NAMEW \\\n\u00a0\u00a0\u00a0\u00a0--subnet projects/PROJECT_ID/regions/REGION/subnetworks/SUBNET_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\n **Let the Google Cloud console construct your\ncluster create request.** : You can click the ** Equivalent Command Line \u2192 Equivalent REST** links on the [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console to have the Google Cloud console construct an equivalent gcloud CLI or API REST request.You can specify either the [networkUri or subnetworkUri](/dataproc/docs/reference/rest/v1/ClusterConfig#GceClusterConfig) `GceClusterConfig` field as part of a [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request.\n **Example** \n```\nPOST /v1/projects/my-project-id/regions/us-central1/clusters/\n{\n \"projectId\": \"PROJECT_ID\",\n \"clusterName\": CLUSTER_NAME,\n \"config\": {\n \"configBucket\": \"\",\n \"gceClusterConfig\": {\n  \"subnetworkUri\": SUBNET_NAME,\n },\n ...\n```\n **Let the Google Cloud console construct your\ncluster create request.** : You can click the ** Equivalent Command Line \u2192 Equivalent REST** links on the [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console to have the Google Cloud console construct an equivalent gcloud CLI or API REST request.Select your network in the Network configuration section on the **Customize cluster** panel. After you choose the network, the **Subnetwork** selector displays subnetworks(s) available in the region that you selected for the cluster.\n### Create a cluster that uses a VPC network in another project\nA Dataproc cluster can use a [shared VPC network](/vpc/docs/shared-vpc) that is defined in a **host project** . The project where the Dataproc cluster is created is referred to as the **service project** .\n- Find the Dataproc cluster project number:- Open the **IAM & Admin** [Settings](https://console.cloud.google.com/iam-admin/settings/project) page in the Google Cloud console. Select the project where you will create the Dataproc cluster. Copy the project ID.\n- A principal with the [Shared VPC Admin role](/vpc/docs/provisioning-shared-vpc#permissions) must perform the following steps. See [directions for setting up Shared VPC](/vpc/docs/provisioning-shared-vpc#setting_up_shared_vpc) for background information.- Make sure that the Shared VPC host project [is enabled](/vpc/docs/provisioning-shared-vpc#enable-shared-vpc-host) .\n- [Attach the project with the Dataproc cluster](/vpc/docs/provisioning-shared-vpc#create-shared) to the host project.\n- Follow the instructions in this substep to configure both of the following service accounts to have the [Network User](/compute/docs/access/iam#network_user_role) role for the host project:- [Dataproc service agent service account](/dataproc/docs/concepts/iam/dataproc-principals#service_agent_control_plane_identity) :`service-[project-number]@dataproc-accounts.iam.gserviceaccount.com`\n- [Google APIs service account](/iam/docs/service-accounts#google-managed_service_accounts) :`[project-number]@cloudservices.gserviceaccount.com`\nDataproc attempts to use the Dataproc service agent service account, falling back to the Google APIs service account, when and if required, to perform actions in a project.- Open the [IAM & Admin](https://console.cloud.google.com/iam-admin/iam/) page in the Google Cloud console.\n- Use the project selector to select the new host project.\n- Click **Grant Access** .\n- Fill in the Grant Access form. Repeat these steps to add both service accounts:- **Add principals** : Input the service account.\n- **Assign roles** : Insert \"Compute Network\" In the filter box, then select the **Compute Network User** role.\n- Click **Save** .\n- After both service accounts have the `Network User` role for the host project, [create a cluster](/dataproc/docs/concepts/configuring-clusters/network#create_a_cluster_that_uses_your_network) that uses the shared VPC network.\n### Create a cluster that uses a VPC subnetwork in another project\n**Note:** The previous section explained how your Dataproc cluster can use another project's VPC **network** . To set permissions at a more granular level, this section shows you how your Dataproc cluster can use another project's VPC **subnetwork** .\nA Dataproc cluster can use a [shared VPC subnetwork](/vpc/docs/shared-vpc) that is defined in a **host project** . The project where the Dataproc cluster is created is referred to as the **service project** .\n- Find the Dataproc cluster project number:- Open the **IAM & Admin** [Settings](https://console.cloud.google.com/iam-admin/settings/project) page in the Google Cloud console. Select the project where you will create the Dataproc cluster. Copy the project ID.\n- A principal with the [Shared VPC Admin role](/vpc/docs/provisioning-shared-vpc#permissions) must perform the following steps. See [directions for setting up Shared VPC](/vpc/docs/provisioning-shared-vpc#setting_up_shared_vpc) for background information.- Make sure that the Shared VPC host project [is enabled](/vpc/docs/provisioning-shared-vpc#enable-shared-vpc-host) .\n- [Attach the project with the Dataproc cluster](/vpc/docs/provisioning-shared-vpc#create-shared) to the host project.\n- Follow the instructions in this step to configure both of the following service accounts to have the [Network User](/compute/docs/access/iam#network_user_role) role for the host project:- [Dataproc service agent service account](/dataproc/docs/concepts/iam/dataproc-principals#service_agent_control_plane_identity) :`service-[project-number]@dataproc-accounts.iam.gserviceaccount.com`\n- [Google APIs service account](/iam/docs/service-account-types#google-managed_service_accounts) :`[project-number]@cloudservices.gserviceaccount.com`\nDataproc attempts to use the Dataproc service agent service account, falling back to the Google APIs service account, when and if required, to perform actions in a project.- Open the [VPC networks](https://console.cloud.google.com/networking/networks/list) page in the Google Cloud console.\n- Use the project selector to select the host project.\n- Click the network that contains the subnetwork that your Dataproc cluster will use.\n- In the **VPC Network Details** page, click the checkbox next to the name of the subnetwork that your cluster will use.\n- If the Info Panel is not open, click **Show Info Panel** .\n- Perform the following steps for each service account:- In the Info Panel, click **Add Principal** .\n- FIll in the Grant Access form:- **Add principals** : Input the service account.\n- **Assign roles** : Insert \"Compute Network\" In the filter box, then select the **Compute Network User** role. **Recommendation: ** Also grant the **Compute Network Viewer** role to each service account. This role includes the`compute.subnetworks.list`permission, which allows Dataproc to validate the existence of necessary service account permissions and to provide meaningful messages if needed permissions are missing.\n- Click **Save** .\n- After both service accounts have the `Network User` role for the host project, [create a cluster](/dataproc/docs/concepts/configuring-clusters/network#create_a_cluster_that_uses_your_network) that uses the shared VPC subnetwork.## Create a Dataproc cluster with internal IP addresses only\nYou can create a Dataproc cluster that is isolated from the public internet whose VM instances communicate over a private IP subnetwork (cluster VMs are not assigned public IP addresses). To do this, the subnetwork must have [Private Google Access enabled](/vpc/docs/configure-private-google-access#configuring_access_to_google_services_from_internal_ips) to allow cluster nodes to access Google APIs and services, such as [Cloud Storage](/storage) , from internal IPs.\nYou can create a Dataproc cluster with internal IP addresses only by using the [gcloud dataproc clusters create](/sdk/gcloud/reference/dataproc/clusters/create) command with the `\u2011\u2011no-address` flag.\n **Use the \u2011\u2011no-address and \u2011\u2011network flags** : Use the `\u2011\u2011no-address` flag with the `\u2011\u2011network` flag to create a cluster that will use a subnetwork with the same name as the network in the region where the cluster is created.\nInternal addresses only (`no-address`) is set by default when creating a Dataproc [2.2 image version](/dataproc/docs/concepts/versioning/dataproc-release-2.2) cluster. You can use the [gcloud dataproc clusters create --public-ip-address](/sdk/gcloud/reference/dataproc/clusters/create#--public-ip-address) flag to enable public IP addresses.\n```\ngcloud dataproc clusters create CLUSTER_NAME \\\n\u00a0\u00a0\u00a0\u00a0--no-address \\\n\u00a0\u00a0\u00a0\u00a0--network NETWORK_NAME \\\n\u00a0\u00a0\u00a0\u00a0--region=REGION \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\nFor example, since auto networks are created with subnets in each region with the same name as the auto network, you can pass the auto network name to the `\u2011\u2011network flag` to create a cluster that will use the auto subnetwork in the cluster's region.\n **Use the \u2011\u2011no-address and \u2011\u2011subnet flags** : Use the `\u2011\u2011no-address` flag with the `\u2011\u2011subnet` flags to create a cluster that will use an auto or custom subnetwork in the region where the cluster will be created. Pass the `\u2011\u2011subnet` flag the full resource path of the subnet.\n```\ngcloud dataproc clusters create cluster-name \\\n\u00a0\u00a0\u00a0\u00a0--no-address \\\n\u00a0\u00a0\u00a0\u00a0--subnet projects/project-id/regions/region/subnetworks/subnetwork-name \\\n\u00a0\u00a0\u00a0\u00a0--region=region \\\n\u00a0\u00a0\u00a0\u00a0... other args ...\n```\n **Let the Google Cloud console construct your\ncluster create request.** : You can click the ** Equivalent Command Line \u2192 Equivalent REST** links on the [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console to have the Google Cloud console construct an equivalent gcloud CLI or API REST request.You can set the `GceClusterConfig` [internalIpOnly](/dataproc/docs/reference/rest/v1/ClusterConfig#GceClusterConfig.FIELDS.internal_ip_only) field to `true` as part of a [clusters.create](/dataproc/docs/reference/rest/v1/projects.regions.clusters/create) request to enable internal IP addresses only.\n`internalIpOnly`is set to`true`by default when creating a Dataproc [2.2 image version](/dataproc/docs/concepts/versioning/dataproc-release-2.2) cluster. You can set this field value to`false`to enable public IP addresses.\n **Example:** \n```\nPOST /v1/projects/my-project-id/regions/us-central1/clusters/\n{\n \"projectId\": \"my-project-id\",\n \"clusterName\": \"example-cluster\",\n \"config\": {\n \"configBucket\": \"\",\n \"gceClusterConfig\": {\n  \"subnetworkUri\": \"custom-subnet-1\",\n  \"zoneUri\": \"us-central1-b\",\n  \"internalIpOnly\": true\n },\n ...\n```\n **Let the Google Cloud console construct your\ncluster create request.** : You can click the ** Equivalent REST API or command line** links at the bottom of the left panel on the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console to have the Google Cloud console construct an equivalent API REST request or`gcloud`command.You can create a Dataproc cluster with Private Google Access enabled from the Dataproc [Create a cluster](https://console.cloud.google.com/dataproc/clustersAdd) page in the Google Cloud console. Click **Internal IP only** on the **Customize cluster** panel to enable this feature for your cluster.\n **Internal IP only** is enabled by default when creating a Dataproc [2.2 image version](/dataproc/docs/concepts/versioning/dataproc-release-2.2) cluster.\nSince, by default, internal-ip-only clusters don't have access to the internet, jobs that download dependencies from the internet, for example jobs that download Spark dependency packages from Maven Central, will fail. There are several workarounds to avoid the problem:\n- Use [Cloud NAT](/solutions/building-internet-connectivity-for-private-vms#deploying_cloud_nat_for_fetching) to enable cluster access to the internet.\n- Create a [custom image](/dataproc/docs/guides/dataproc-images) that includes the dependencies (for example, Spark dependency packages in `/usr/lib/spark/jars/` ).\n- Upload the dependencies to a Cloud Storage bucket, then use an [initialization action](/dataproc/docs/concepts/configuring-clusters/init-actions) to download the dependencies from the bucket during cluster creation.## Dataproc and VPC Service Controls networks\nWith [VPC Service Controls](/vpc-service-controls/docs) , administrators can define a security perimeter around resources of Google-managed services to control communication to and between those services.\nNote the following limitations and strategies when using VPC Service Controls networks with Dataproc clusters:\n- To install components outside the VPC Service Controls perimeter, create a Dataproc [custom image](/dataproc/docs/guides/dataproc-images) that pre-installs the components, then create the cluster using the custom image.\n- See [Dataproc special steps to protect using VPC Service Controls](/vpc-service-controls/docs/supported-products#table_dataproc) .", "guide": "Dataproc"}