{"title": "Dataproc - Pub/Sub Lite with Dataproc", "url": "https://cloud.google.com/dataproc/docs/concepts/connectors/pubsub-lite", "abstract": "# Dataproc - Pub/Sub Lite with Dataproc\n[Pub/Sub Lite](/pubsub/lite/docs) is a real-time messaging service built for low cost and offers lower reliability compared to Pub/Sub. Pub/Sub Lite offers zonal and regional topics for storage.\nThe [Pub/Sub Lite Spark Connector](https://github.com/googleapis/java-pubsublite-spark) supports Pub/Sub Lite as an input source to Apache Spark Structured Streaming in the default micro-batch processing and experimental continuous processing modes.\n", "content": "## Using Pub/Sub Lite with Dataproc\nThe `samples` directory in the [java-pubsublite-spark repository onGitHub](https://github.com/googleapis/java-pubsublite-spark) contains a Spark example in Java that uses Pub/Sub Lite with Dataproc. To run the example, follow the [directions in the Spark example](https://github.com/googleapis/java-pubsublite-spark/tree/master/samples) .- To get started, clone the`java-pubsublite-spark`GitHub repository:```\ngit clone https://github.com/googleapis/java-pubsublite-spark\ncd java-pubsublite-spark/samples\n```\nThe connector is available from the [Maven Central repository](https://search.maven.org/artifact/com.google.cloud/pubsublite-spark-sql-streaming) . You can download and provide it via the `--packages` option when using the spark-submit command or set it via the spark.jars.packages [configuration property](https://spark.apache.org/docs/latest/configuration.html#available-properties) .\n## For more information\n- See [Using Pub/Sub Lite with Apache Spark](/pubsub/lite/docs/write-messages-apache-spark) , a quickstart that runs a Python script on a Dataproc cluster to read and write data from and to Pub/Sub Lite.\n- Select the version of the Pub/Sub Lite Spark Connector [here](https://search.maven.org/artifact/com.google.cloud/pubsublite-spark-sql-streaming) , then download its JAR on the linked page.", "guide": "Dataproc"}