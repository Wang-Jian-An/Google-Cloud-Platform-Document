{"title": "Dataproc - \u4f7f\u7528 Cloud Composer \u7684\u5de5\u4f5c\u6d41", "url": "https://cloud.google.com/dataproc/docs/tutorials/workflow-composer?hl=zh-cn", "abstract": "# Dataproc - \u4f7f\u7528 Cloud Composer \u7684\u5de5\u4f5c\u6d41\n**\u76ee\u6a19** \uff1a - \u5275\u5efa\u904b\u884c [Spark PI \u4f5c\u696d](https://spark.apache.org/examples.html) \u7684 Dataproc \u5de5\u4f5c\u6d41\u6a21\u677f- - \u5275\u5efa\u4e00\u500b Apache Airflow DAG\uff0c [Cloud Composer](https://cloud.google.com/composer/docs?hl=zh-cn) \u5c07\u4f7f\u7528\u8a72\u6a21\u677f\u5728\u7279\u5b9a\u6642\u9593\u5553\u52d5\u5de5\u4f5c\u6d41\u3002\nTitles in dynamic includes are not used anywhere, and we should avoid paying to translate them\n\u5728\u672c\u6587\u6a94\u4e2d\uff0c\u60a8\u5c07\u4f7f\u7528 Google Cloud \u7684\u4ee5\u4e0b\u6536\u8cbb\u7d44\u4ef6\uff1a- Dataproc\n- Compute Engine\n- Cloud Composer\n\u60a8\u53ef\u4f7f\u7528 [\u50f9\u683c\u8a08\u7b97\u5668](https://cloud.google.com/products/calculator?hl=zh-cn) \u6839\u64da\u60a8\u7684\u9810\u8a08\u4f7f\u7528\u60c5\u6cc1\u4f86\u4f30\u7b97\u8cbb\u7528\u3002\n", "content": "## \u6e96\u5099\u5de5\u4f5c\n### \u8a2d\u7f6e\u9805\u76ee\n- Titles in dynamic includes are not used anywhere, and we should avoid paying to translate them\n## \u5275\u5efa Dataproc \u5de5\u4f5c\u6d41\u6a21\u677f\n\u5728\u672c\u5730\u7d42\u7aef\u7a97\u53e3\u6216 [Cloud Shell](https://console.cloud.google.com/?cloudshell=true&hl=zh-cn) \u4e2d\u8907\u88fd\u4e26\u904b\u884c\u4e0b\u9762\u5217\u51fa\u7684\u547d\u4ee4\uff0c\u4ee5\u5275\u5efa\u548c\u5b9a\u7fa9 [\u5de5\u4f5c\u6d41\u6a21\u677f](https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows?hl=zh-cn) \u3002\n- \u5275\u5efa`sparkpi`\u5de5\u4f5c\u6d41\u6a21\u677f\u3002```\ngcloud dataproc workflow-templates create sparkpi \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n  \n```\n- \u5c07 Spark \u4f5c\u696d\u6dfb\u52a0\u5230`sparkpi`\u5de5\u4f5c\u6d41\u6a21\u677f\u3002\u201ccompute\u201d`step-id`\u6a19\u8a8c\u7528\u65bc\u8b58\u5225 SparkPi \u4f5c\u696d\u3002```\ngcloud dataproc workflow-templates add-job spark \\\n\u00a0\u00a0\u00a0\u00a0--workflow-template=sparkpi \\\n\u00a0\u00a0\u00a0\u00a0--step-id=compute \\\n\u00a0\u00a0\u00a0\u00a0--class=org.apache.spark.examples.SparkPi \\\n\u00a0\u00a0\u00a0\u00a0--jars=file:///usr/lib/spark/examples/jars/spark-examples.jar \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1 \\\n\u00a0\u00a0\u00a0\u00a0-- 1000\n  \n```\n- \u4f7f\u7528 [\u8a17\u7ba1](https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=zh-cn#managed_cluster) [\u55ae\u7bc0\u9ede](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/single-node-clusters?hl=zh-cn) \u96c6\u7fa3\u904b\u884c\u5de5\u4f5c\u6d41\u3002Dataproc \u5c07\u5275\u5efa\u96c6\u7fa3\uff0c\u5c0d\u5176\u904b\u884c\u5de5\u4f5c\u6d41\uff0c\u7136\u5f8c\u5728\u5de5\u4f5c\u6d41\u5b8c\u6210\u6642\u522a\u9664\u96c6\u7fa3\u3002```\ngcloud dataproc workflow-templates set-managed-cluster sparkpi \\\n\u00a0\u00a0\u00a0\u00a0--cluster-name=sparkpi \\\n\u00a0\u00a0\u00a0\u00a0--single-node \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1\n  \n```\n- \u78ba\u8a8d\u5275\u5efa\u5de5\u4f5c\u6d41\u6a21\u677f\u3002\n\u5728 Google Cloud \u63a7\u5236\u6aaf\u4e2d\uff0c\u9ede\u64ca Dataproc [\u5de5\u4f5c\u6d41](https://console.cloud.google.com/dataproc/workflows/templates?hl=zh-cn) \u9801\u9762\u4e0a\u7684 `sparkpi` \u540d\u7a31\uff0c\u4ee5\u6253\u958b **\u5de5\u4f5c\u6d41\u6a21\u677f\u8a73\u60c5** \u9801\u9762\u3002\u9ede\u64ca\u5de5\u4f5c\u6d41\u6a21\u677f\u7684\u540d\u7a31\u4ee5\u78ba\u8a8d `sparkpi` \u6a21\u677f\u7279\u6027\u3002\u904b\u884c\u4ee5\u4e0b\u547d\u4ee4\uff1a\n```\ngcloud dataproc workflow-templates describe sparkpi --region=us-central1\n \n```\n## \u5275\u5efa DAG \u4e26\u5c07\u5176\u4e0a\u50b3\u5230 Cloud Storage\n- \u5275\u5efa\u6216\u4f7f\u7528\u73fe\u6709\u7684 [Cloud Composer \u74b0\u5883](https://cloud.google.com/composer/docs/how-to/managing/creating?hl=zh-cn#creating_a_new_environment) \u3002\n- \u8a2d\u7f6e\u74b0\u5883\u8b8a\u91cf\u3002- \u5728\u5de5\u5177\u6b04\u4e2d\uff0c\u4f9d\u6b21\u9ede\u64ca **Admin > Variables** \u3002\n- \u9ede\u64ca **\u5275\u5efa** \u3002\n- \u8acb\u8f38\u5165\u4ee5\u4e0b\u4fe1\u606f\uff1a- Key\uff1a`project_id`\n- Val\uff1a- \u60a8\u7684 Google Cloud \u9805\u76ee ID- \u9ede\u64ca **\u4fdd\u5b58** \u3002\n\u8f38\u5165\u4ee5\u4e0b\u547d\u4ee4\uff1a- `ENVIRONMENT`\u662f Cloud Composer \u74b0\u5883\u7684\u540d\u7a31\n- `LOCATION`\u662f Cloud Composer \u74b0\u5883\u6240\u5728\u7684\u5730\u5340\n- `PROJECT_ID`\u662f\u5305\u542b Cloud Composer \u74b0\u5883\u7684\u9805\u76ee\u7684 ID\n```\n gcloud composer environments run ENVIRONMENT --location LOCATION variables set -- project_id PROJECT_ID\n \n```\n- \u5c07\u4ee5\u4e0b DAG \u4ee3\u78bc\u5f9e\u672c\u5730\u8907\u88fd\u5230\u540d\u7232\u201ccomposer-dataproc-dag.py\u201d\u7684\u6587\u4ef6\u4e2d\uff0c\u8a72\u6587\u4ef6\u4f7f\u7528 [DataprocInstantiateWorkflowTemplateOperator](https://airflow.apache.org/docs/apache-airflow-providers-google/stable/_api/airflow/providers/google/cloud/operators/dataproc/index.html#airflow.providers.google.cloud.operators.dataproc.DataprocInstantiateWorkflowTemplateOperator) \u3002 [](None) \n [  composer/workflows/dataproc_workflow_template_instantiate_operator_tutorial.py ](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/composer/workflows/dataproc_workflow_template_instantiate_operator_tutorial.py) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/composer/workflows/dataproc_workflow_template_instantiate_operator_tutorial.py) \n```\n\"\"\"Example Airflow DAG that kicks off a Cloud Dataproc Template that runs aSpark Pi Job.This DAG relies on an Airflow variablehttps://airflow.apache.org/docs/apache-airflow/stable/concepts/variables.html* project_id - Google Cloud Project ID to use for the Cloud Dataproc Template.\"\"\"import datetimefrom airflow import modelsfrom airflow.providers.google.cloud.operators.dataproc import (\u00a0 \u00a0 DataprocInstantiateWorkflowTemplateOperator,)from airflow.utils.dates import days_agoproject_id = \"{{var.value.project_id}}\"default_args = {\u00a0 \u00a0 # Tell airflow to start one day ago, so that it runs as soon as you upload it\u00a0 \u00a0 \"start_date\": days_ago(1),\u00a0 \u00a0 \"project_id\": project_id,}# Define a DAG (directed acyclic graph) of tasks.# Any task you create within the context manager is automatically added to the# DAG object.with models.DAG(\u00a0 \u00a0 # The id you will see in the DAG airflow page\u00a0 \u00a0 \"dataproc_workflow_dag\",\u00a0 \u00a0 default_args=default_args,\u00a0 \u00a0 # The interval with which to schedule the DAG\u00a0 \u00a0 schedule_interval=datetime.timedelta(days=1), \u00a0# Override to match your needs) as dag:\u00a0 \u00a0 start_template_job = DataprocInstantiateWorkflowTemplateOperator(\u00a0 \u00a0 \u00a0 \u00a0 # The task id of your job\u00a0 \u00a0 \u00a0 \u00a0 task_id=\"dataproc_workflow_dag\",\u00a0 \u00a0 \u00a0 \u00a0 # The template id of your workflow\u00a0 \u00a0 \u00a0 \u00a0 template_id=\"sparkpi\",\u00a0 \u00a0 \u00a0 \u00a0 project_id=project_id,\u00a0 \u00a0 \u00a0 \u00a0 # The region for the template\u00a0 \u00a0 \u00a0 \u00a0 region=\"us-central1\",\u00a0 \u00a0 )\n``` [  composer/airflow_1_samples/dataproc_workflow_template_instantiate_operator_tutorial.py ](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/composer/airflow_1_samples/dataproc_workflow_template_instantiate_operator_tutorial.py) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/composer/airflow_1_samples/dataproc_workflow_template_instantiate_operator_tutorial.py) \n```\n\"\"\"Example Airflow DAG that kicks off a Cloud Dataproc Template that runs aSpark Pi Job.This DAG relies on an Airflow variablehttps://airflow.apache.org/docs/apache-airflow/stable/concepts/variables.html* project_id - Google Cloud Project ID to use for the Cloud Dataproc Template.\"\"\"import datetimefrom airflow import modelsfrom airflow.contrib.operators import dataproc_operatorfrom airflow.utils.dates import days_agoproject_id = \"{{var.value.project_id}}\"default_args = {\u00a0 \u00a0 # Tell airflow to start one day ago, so that it runs as soon as you upload it\u00a0 \u00a0 \"start_date\": days_ago(1),\u00a0 \u00a0 \"project_id\": project_id,}# Define a DAG (directed acyclic graph) of tasks.# Any task you create within the context manager is automatically added to the# DAG object.with models.DAG(\u00a0 \u00a0 # The id you will see in the DAG airflow page\u00a0 \u00a0 \"dataproc_workflow_dag\",\u00a0 \u00a0 default_args=default_args,\u00a0 \u00a0 # The interval with which to schedule the DAG\u00a0 \u00a0 schedule_interval=datetime.timedelta(days=1), \u00a0# Override to match your needs) as dag:\u00a0 \u00a0 start_template_job = dataproc_operator.DataprocWorkflowTemplateInstantiateOperator(\u00a0 \u00a0 \u00a0 \u00a0 # The task id of your job\u00a0 \u00a0 \u00a0 \u00a0 task_id=\"dataproc_workflow_dag\",\u00a0 \u00a0 \u00a0 \u00a0 # The template id of your workflow\u00a0 \u00a0 \u00a0 \u00a0 template_id=\"sparkpi\",\u00a0 \u00a0 \u00a0 \u00a0 project_id=project_id,\u00a0 \u00a0 \u00a0 \u00a0 # The region for the template\u00a0 \u00a0 \u00a0 \u00a0 # For more info on regions where Dataflow is available see:\u00a0 \u00a0 \u00a0 \u00a0 # https://cloud.google.com/dataflow/docs/resources/locations\u00a0 \u00a0 \u00a0 \u00a0 region=\"us-central1\",\u00a0 \u00a0 )\n```\n- [\u5c07 DAG \u4e0a\u50b3](https://cloud.google.com/composer/docs/how-to/using/managing-dags?hl=zh-cn) \u5230 Cloud Storage \u4e2d\u7684\u74b0\u5883\u6587\u4ef6\u593e\u3002\u4e0a\u50b3\u6210\u529f\u5b8c\u6210\u5f8c\uff0c\u9ede\u64ca Cloud Composer \u74b0\u5883\u9801\u9762\u4e0a\u7684 **DAGs \u6587\u4ef6\u593e** \u93c8\u63a5\u3002\n### \u67e5\u770b\u4efb\u52d9\u7684\u72c0\u614b\n- \u6253\u958b [Airflow \u7db2\u9801\u754c\u9762](https://cloud.google.com/composer/docs/how-to/accessing/airflow-web-interface?hl=zh-cn#accessing_the_web_interface) \u3002\n- \u5728 DAG \u9801\u9762\u4e0a\uff0c\u9ede\u64ca DAG \u540d\u7a31\uff08\u4f8b\u5982`dataproc_workflow_dag`\uff09\u3002\n- \u5728 DAG \u8a73\u7d30\u4fe1\u606f\u9801\u9762\u4e0a\uff0c\u9ede\u64ca **Graph View** \u3002\n- \u67e5\u770b\u72c0\u614b\uff1a- \u5931\u6557\uff1a\u4efb\u52d9\u88ab\u7d05\u8272\u6846\u5708\u8d77\u3002  \u60a8\u9084\u53ef\u4ee5\u5c07\u6307\u91dd\u61f8\u505c\u5728\u4efb\u52d9\u4e0a\uff0c\u7136\u5f8c\u67e5\u770b **State: Failed** \u3002\n- \u6210\u529f\uff1a\u4efb\u52d9\u88ab\u7da0\u8272\u6846\u5708\u8d77\u3002\u60a8\u9084\u53ef\u4ee5\u5c07\u6307\u91dd\u61f8\u505c\u5728\u4efb\u52d9\u4e0a\uff0c\u7136\u5f8c\u67e5\u770b **State: Success** \u3002\u9ede\u64ca\u201c\u5de5\u4f5c\u6d41\u201d\u6a19\u7c64\u9801\u4ee5\u67e5\u770b\u5de5\u4f5c\u6d41\u72c0\u614b\u3002```\ngcloud dataproc operations list \\\n\u00a0\u00a0\u00a0\u00a0--region=us-central1 \\\n\u00a0\u00a0\u00a0\u00a0--filter=\"labels.goog-dataproc-workflow-template-id=sparkpi\"\n \n```\n## \u6e05\u7406\n\u7232\u907f\u514d\u7cfb\u7d71\u5411\u60a8\u7684 Google Cloud \u8cec\u865f\u6536\u53d6\u8cbb\u7528\uff0c\u60a8\u53ef\u4ee5\u522a\u9664\u672c\u6559\u7a0b\u4e2d\u4f7f\u7528\u7684\u8cc7\u6e90\uff1a\n- [\u522a\u9664 Cloud Composer \u74b0\u5883\u3002](https://console.cloud.google.com/composer/environments?hl=zh-cn) \n- [\u522a\u9664\u5de5\u4f5c\u6d41\u6a21\u677f\u3002](https://cloud.google.com/dataproc/docs/concepts/workflows/using-workflows?hl=zh-cn#deleting_a_workflow_template) ## \u5f8c\u7e8c\u6b65\u9a5f\n- \u8acb\u53c3\u95b1 [Dataproc \u5de5\u4f5c\u6d41\u6a21\u677f\u6982\u89bd](https://cloud.google.com/dataproc/docs/concepts/workflows/overview?hl=zh-cn) \n- \u8acb\u53c3\u95b1 [\u5de5\u4f5c\u6d41\u5b89\u6392\u89e3\u6c7a\u65b9\u6848](https://cloud.google.com/dataproc/docs/concepts/workflows/workflow-schedule-solutions?hl=zh-cn)", "guide": "Dataproc"}