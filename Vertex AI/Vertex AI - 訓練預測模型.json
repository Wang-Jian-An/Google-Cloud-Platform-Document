{"title": "Vertex AI - \u8a13\u7df4\u9810\u6e2c\u6a21\u578b", "url": "https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/train-model?hl=zh-cn", "abstract": "# Vertex AI - \u8a13\u7df4\u9810\u6e2c\u6a21\u578b\n\u672c\u9801\u9762\u4ecb\u7d39\u5982\u4f55\u4f7f\u7528 Google Cloud \u63a7\u5236\u6aaf\u6216 Vertex AI API \u901a\u904e\u8868\u5f0f\u6578\u64da\u96c6\u8a13\u7df4\u9810\u6e2c\u6a21\u578b\u3002\n", "content": "## \u6e96\u5099\u5de5\u4f5c\n\u5728\u8a13\u7df4\u9810\u6e2c\u6a21\u578b\u4e4b\u524d\uff0c\u60a8\u5fc5\u9808\u5148\u5b8c\u6210\u4ee5\u4e0b\u64cd\u4f5c\uff1a\n- [\u6e96\u5099\u8a13\u7df4\u6578\u64da](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn) \n- [\u5275\u5efa Vertex AI \u6578\u64da\u96c6](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/create-dataset?hl=zh-cn) ## \u8a13\u7df4\u6a21\u578b\n- \u5728 Google Cloud \u63a7\u5236\u6aaf\u7684 Vertex AI \u90e8\u5206\u4e2d\uff0c\u524d\u5f80 **\u6578\u64da\u96c6** \u9801\u9762\u3002 [\u8f49\u5230\u201c\u6578\u64da\u96c6\u201d\u9801\u9762](https://console.cloud.google.com/vertex-ai/datasets?hl=zh-cn) \n- \u9ede\u64ca\u8981\u7528\u65bc\u8a13\u7df4\u6a21\u578b\u7684\u6578\u64da\u96c6\u7684\u540d\u7a31\uff0c\u4ee5\u6253\u958b\u5176\u8a73\u60c5\u9801\u9762\u3002\n- \u5982\u679c\u60a8\u7684\u6578\u64da\u985e\u578b\u4f7f\u7528\u8a3b\u91cb\u96c6\uff0c\u8acb\u9078\u64c7\u8981\u7528\u65bc\u6b64\u6a21\u578b\u7684\u8a3b\u91cb\u96c6\u3002\n- \u9ede\u64ca **\u8a13\u7df4\u65b0\u6a21\u578b** \u3002\n- \u9078\u64c7 **\u5176\u4ed6** \u3002\n- \u5728 **\u8a13\u7df4\u65b9\u6cd5** \u9801\u9762\u4e2d\uff0c\u6309\u5982\u4e0b\u65b9\u5f0f\u914d\u7f6e\uff1a- \u9078\u64c7\u6a21\u578b\u8a13\u7df4\u65b9\u6cd5\u3002 \u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u6a21\u578b\u8a13\u7df4\u65b9\u6cd5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#training-methods) \u3002\n- \u9ede\u64ca **\u7e7c\u7e8c** \u3002\n- \u5728 **\u6a21\u578b\u8a73\u60c5** \u9801\u9762\u4e2d\uff0c\u6309\u5982\u4e0b\u65b9\u5f0f\u914d\u7f6e\uff1a- \u8f38\u5165\u65b0\u6a21\u578b\u7684\u986f\u793a\u540d\u3002\n- \u9078\u64c7\u76ee\u6a19\u5217\u3002\u76ee\u6a19\u5217\u662f\u6a21\u578b\u5c07\u9810\u6e2c\u7684\u503c\u3002 \u8a73\u7d30\u77ad\u89e3 [\u76ee\u6a19\u5217\u8981\u6c42](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn#data-structure) \u3002\n- \u5982\u679c\u60a8\u5c1a\u672a\u5c0d\u6578\u64da\u96c6\u8a2d\u7f6e [\u5e8f\u5217\u6a19\u8b58\u7b26](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn#data-structure) \u548c **\u6642\u9593\u6233** \u5217\uff0c\u8acb\u7acb\u5373\u9078\u64c7\u5b83\u5011\u3002\n- \u9078\u64c7\u60a8\u7684 **\u6578\u64da\u7c92\u5ea6** \u3002\u5982\u679c\u60a8\u60f3\u4f7f\u7528\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\uff0c\u8acb\u9078\u64c7 `Daily` \u3002 [\u77ad\u89e3\u5982\u4f55\u9078\u64c7\u6578\u64da\u7c92\u5ea6](https://cloud.google.com/vertex-ai/docs/tabular-data/bp-tabular?hl=zh-cn#granularity) \u3002\n- **\u53ef\u9078** \uff1a\u5728 **\u7bc0\u5047\u65e5\u5340\u57df** \u4e0b\u62c9\u5217\u8868\u4e2d\uff0c\u9078\u64c7\u4e00\u500b\u6216\u591a\u500b\u5730\u7406\u5340\u57df\u4f86\u5553\u7528\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\u3002 \u5728\u8a13\u7df4\u671f\u9593\uff0cVertex AI \u6703\u6839\u64da **\u6642\u9593\u6233** \u5217\u4e2d\u7684\u65e5\u671f\u548c\u6307\u5b9a\u7684\u5730\u7406\u5340\u57df\u5728\u6a21\u578b\u4e2d\u5275\u5efa\u7bc0\u5047\u65e5\u5206\u985e\u7279\u5fb5\u3002\u53ea\u6709\u7576 **\u6578\u64da\u7c92\u5ea6** \u8a2d\u7f6e\u7232 `Daily` \u6642\uff0c\u624d\u80fd\u9078\u64c7\u6b64\u9078\u9805\u3002\u9ed8\u8a8d\u60c5\u6cc1\u4e0b\uff0c\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\u8655\u65bc\u505c\u7528\u72c0\u614b\u3002 \u5982\u9700\u77ad\u89e3\u7528\u65bc\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\u7684\u5730\u7406\u5340\u57df\uff0c\u8acb\u53c3\u95b1 [\u7bc0\u5047\u65e5\u5340\u57df](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#holiday-regions) \u3002\n- \u8f38\u5165\u60a8\u7684 **\u4e0a\u4e0b\u6587\u7a97\u53e3** \u548c **\u9810\u6e2c\u7bc4\u570d** \u3002\u9810\u6e2c\u7bc4\u570d\u78ba\u5b9a\u6a21\u578b\u9810\u6e2c\u6bcf\u884c\u9810\u6e2c\u6578\u64da\u7684\u76ee\u6a19\u503c\u7684\u672a\u4f86\u6642\u9593\u3002 **\u9810\u6e2c\u7bc4\u570d** \u4ee5 **\u6578\u64da\u7c92\u5ea6** \u7232\u55ae\u4f4d\u6307\u5b9a\u3002\u4e0a\u4e0b\u6587\u7a97\u53e3\u8a2d\u7f6e\u6a21\u578b\u5728\u8a13\u7df4\u671f\u9593\u7684\u56de\u6eaf\u6642\u9593\uff08\u7528\u65bc\u9810\u6e2c\uff09\u3002\u63db\u53e5\u8a71\u8aaa\uff0c\u5c0d\u65bc\u6bcf\u500b\u6578\u64da\u9ede\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3\u6703\u78ba\u5b9a\u6a21\u578b\u67e5\u627e\u56de\u6eaf\u6a21\u5f0f\u7684\u6642\u9593\u3002 **\u4e0a\u4e0b\u6587\u7a97\u53e3** \u4ee5 **\u6578\u64da\u7c92\u5ea6** \u7232\u55ae\u4f4d\u6307\u5b9a\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#forecast-window) \u3002\n- \u5982\u679c\u60a8\u8981\u5c07\u6e2c\u8a66\u6578\u64da\u96c6\u5c0e\u51fa\u5230 BigQuery\uff0c\u8acb\u52fe\u9078 **\u5c07\u6e2c\u8a66\u6578\u64da\u96c6\u5c0e\u51fa\u5230 BigQuery** (Export test dataset to BigQuery) \u4e26\u63d0\u4f9b\u8868\u7684\u540d\u7a31\u3002\n- \u5982\u679c\u60a8\u60f3\u8981\u624b\u52d5\u63a7\u5236\u6578\u64da\u62c6\u5206\u6216\u914d\u7f6e\u9810\u6e2c\u7a97\u53e3\uff0c\u8acb\u6253\u958b **\u9ad8\u7d1a\u9078\u9805** \u3002\n- \u9ed8\u8a8d\u6578\u64da\u62c6\u5206\u6309\u6642\u9593\u9806\u5e8f\uff0c\u6a19\u6e96\u7232 80/10/10 \u767e\u5206\u6bd4\u3002\u5982\u679c\u60a8\u60f3\u624b\u52d5\u6307\u5b9a\u5c07\u54ea\u4e9b\u884c\u5206\u914d\u7d66\u54ea\u500b\u62c6\u5206\uff0c\u8acb\u9078\u64c7 **\u624b\u52d5** \u4e26\u6307\u5b9a\u6578\u64da\u62c6\u5206\u5217\u3002\u8a73\u7d30\u77ad\u89e3 [\u6578\u64da\u62c6\u5206](https://cloud.google.com/vertex-ai/docs/tabular-data/data-splits?hl=zh-cn) \u3002\n- \u9078\u64c7\u7528\u65bc\u751f\u6210\u9810\u6e2c\u7a97\u53e3\u7684\u6efe\u52d5\u7a97\u53e3\u7b56\u7565\u3002\u9ed8\u8a8d\u7b56\u7565\u662f **\u8a08\u6578** \u3002- **\u8a08\u6578** \uff1a\u5728\u63d0\u4f9b\u7684\u6587\u672c\u6846\u4e2d\u8a2d\u7f6e\u6700\u5927\u7a97\u53e3\u6578\u7684\u503c\u3002\n- **\u6b65\u9577** \uff1a\u5728\u63d0\u4f9b\u7684\u6587\u672c\u6846\u4e2d\u8a2d\u7f6e\u6b65\u5e45\u7684\u503c\u3002\n- **\u5217** \uff1a\u5f9e\u63d0\u4f9b\u7684\u4e0b\u62c9\u5217\u8868\u4e2d\u9078\u64c7\u9069\u7576\u7684\u5217\u540d\u3002\n\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u6efe\u52d5\u7a97\u53e3\u7b56\u7565](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#rolling_window_strategies) \u3002\n- \u9ede\u64ca **\u7e7c\u7e8c** \u3002\n- \u5728 **\u8a13\u7df4\u9078\u9805** \u9801\u9762\u4e2d\uff0c\u6309\u5982\u4e0b\u65b9\u5f0f\u914d\u7f6e\uff1a- \u9ede\u64ca **\u751f\u6210\u7d71\u8a08\u4fe1\u606f** \uff08\u5982\u679c\u60a8\u5c1a\u672a\u751f\u6210\uff09\u3002\u751f\u6210\u7d71\u8a08\u4fe1\u606f\u6703\u586b\u5145 **\u8f49\u63db** \u4e0b\u62c9\u83dc\u55ae\u3002\n- \u6aa2\u67e5\u60a8\u7684\u5217\u5217\u8868\uff0c\u4e26\u5f9e\u8a13\u7df4\u4e2d\u6392\u9664\u4efb\u4f55\u4e0d\u61c9\u7528\u65bc\u8a13\u7df4\u6a21\u578b\u7684\u5217\u3002\u5982\u679c\u60a8\u8981\u4f7f\u7528\u6578\u64da\u62c6\u5206\u5217\uff0c\u5247\u61c9\u5305\u542b\u8a72\u5217\u3002\n- \u67e5\u770b\u7232\u5305\u542b\u7684\u7279\u5fb5\u9078\u64c7\u7684\u8f49\u63db\uff0c\u4e26\u9032\u884c\u4efb\u4f55\u6240\u9700\u66f4\u65b0\u3002\u7cfb\u7d71\u6703\u5f9e\u8a13\u7df4\u4e2d\u6392\u9664\u5305\u542b\u6240\u9078\u8f49\u63db\u7121\u6548\u6578\u64da\u7684\u884c\u3002\u8a73\u7d30\u77ad\u89e3 [\u8f49\u63db](https://cloud.google.com/vertex-ai/docs/datasets/data-types-tabular?hl=zh-cn#transformations) \u3002\n- \u5c0d\u65bc\u5305\u542b\u7528\u65bc\u8a13\u7df4\u7684\u6bcf\u4e00\u5217\uff0c\u8acb\u6307\u5b9a **\u7279\u5fb5\u985e\u578b** \u4ee5\u7372\u53d6\u8a72\u7279\u5fb5\u8207\u5176\u6642\u5e8f\u7684\u95dc\u4fc2\uff0c\u4ee5\u53ca\u5b83\u5728\u9810\u6e2c\u6642\u662f\u5426\u53ef\u7528\u3002\u8a73\u7d30\u77ad\u89e3 [\u7279\u5fb5\u985e\u578b\u548c\u53ef\u7528\u6027](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#feature-type) \u3002\n- \u5982\u679c\u60a8\u60f3\u6307\u5b9a\u6b0a\u91cd\u5217\u3001\u66f4\u6539\u9ed8\u8a8d\u7684\u512a\u5316\u76ee\u6a19\u6216\u5553\u7528\u5206\u5c64\u9810\u6e2c\uff0c\u8acb\u6253\u958b **\u9ad8\u7d1a\u9078\u9805** \u3002\n- **\u53ef\u9078** \u3002\u5982\u679c\u60a8\u60f3\u6307\u5b9a\u6b0a\u91cd\u5217\uff0c\u8acb\u5f9e\u4e0b\u62c9\u5217\u8868\u4e2d\u9078\u64c7\u3002\u8a73\u7d30\u77ad\u89e3 [\u6b0a\u91cd\u5217](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn#weight) \u3002\n- **\u53ef\u9078** \u3002\u5982\u679c\u60a8\u60f3\u9078\u64c7\u512a\u5316\u76ee\u6a19\uff0c\u8acb\u5f9e\u5217\u8868\u4e2d\u9078\u64c7\u3002\u8a73\u7d30\u77ad\u89e3 [\u512a\u5316\u76ee\u6a19](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#optimization-objectives) \u3002\n- **\u53ef\u9078** \u3002\u5982\u679c\u60a8\u60f3\u4f7f\u7528\u5206\u5c64\u9810\u6e2c\uff0c\u8acb\u9078\u64c7 **\u5553\u7528\u5206\u5c64\u9810\u6e2c** \u3002\u60a8\u53ef\u4ee5\u5f9e\u4e09\u500b\u5206\u7d44\u9078\u9805\u4e2d\u9032\u884c\u9078\u64c7\uff1a- `No grouping`\n- `Group by columns`\n- `Group all`\n\u60a8\u9084\u53ef\u4ee5\u9078\u64c7\u8a2d\u7f6e\u4ee5\u4e0b\u5f59\u7e3d\u640d\u5931\u6b0a\u91cd\uff1a- `Group total weight`\u3002\u53ea\u6709\u5728\u9078\u64c7`Group by columns`\u6216`Group all`\u9078\u9805\u6642\u624d\u80fd\u8a2d\u7f6e\u6b64\u5b57\u6bb5\u3002\n- `Temporal total weight`\u3002\n- `Group temporal total weight`\u3002\u53ea\u6709\u5728\u9078\u64c7`Group by columns`\u6216`Group all`\u9078\u9805\u6642\u624d\u80fd\u8a2d\u7f6e\u6b64\u5b57\u6bb5\u3002\n\u8a73\u7d30\u77ad\u89e3 [\u5206\u5c64\u9810\u6e2c](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/hierarchical?hl=zh-cn) \u3002\n- \u9ede\u64ca **\u7e7c\u7e8c** \u3002\n- \u5728 **\u8a08\u7b97\u548c\u50f9\u683c** \u9801\u9762\u4e2d\uff0c\u914d\u7f6e\u5982\u4e0b\uff1a- \u8f38\u5165\u6a21\u578b\u8a13\u7df4\u7684\u6700\u5927\u5c0f\u6642\u6578\u3002\u6b64\u8a2d\u7f6e\u6709\u52a9\u65bc\u9650\u5236\u8a13\u7df4\u8cbb\u7528\u3002\u5be6\u969b\u6240\u7528\u7684\u6642\u9593\u53ef\u80fd\u8d85\u904e\u6b64\u503c\uff0c\u56e0\u7232\u5275\u5efa\u65b0\u6a21\u578b\u6d89\u53ca\u5176\u4ed6\u64cd\u4f5c\u3002\u5efa\u8b70\u7684\u8a13\u7df4\u6642\u9593\u8207\u9810\u6e2c\u7bc4\u570d\u548c\u8a13\u7df4\u6578\u64da\u7684\u5927\u5c0f\u6709\u95dc\u3002\u4e0b\u8868\u63d0\u4f9b\u4e00\u4e9b\u9810\u6e2c\u8a13\u7df4\u904b\u884c\u793a\u4f8b\uff0c\u4ee5\u53ca\u8a13\u7df4\u9ad8\u8cea\u91cf\u6a21\u578b\u6240\u9700\u7684\u8a13\u7df4\u6642\u9593\u7bc4\u570d\u3002| \u884c  | \u529f\u80fd | \u9810\u6e2c\u7bc4\u570d | \u8a13\u7df4\u6642\u9593 |\n|:--------|-------:|-----------:|:-----------|\n| 1200 \u842c |  10 |   6 | 3-6 \u5c0f\u6642 |\n| 2000 \u842c |  50 |   13 | 6-12 \u5c0f\u6642 |\n| 1600 \u842c |  30 |  365 | 24-48 \u5c0f\u6642 |\u5982\u9700\u77ad\u89e3\u8a13\u7df4\u50f9\u683c\uff0c\u8acb\u53c3\u95b1 [\u50f9\u683c\u9801\u9762](https://cloud.google.com/vertex-ai/pricing?hl=zh-cn#tabular-data) \u3002\n- \u9ede\u64ca **\u958b\u59cb\u8a13\u7df4** \u3002\u6a21\u578b\u8a13\u7df4\u53ef\u80fd\u9700\u8981\u5e7e\u500b\u5c0f\u6642\uff0c\u5177\u9ad4\u53d6\u6c7a\u65bc\u6578\u64da\u7684\u5927\u5c0f\u548c\u8907\u96dc\u6027\uff0c\u4ee5\u53ca\u8a13\u7df4\u9810\u7b97\uff08\u5982\u679c\u6307\u5b9a\uff09\u3002\u60a8\u53ef\u4ee5\u95dc\u9589\u6b64\u6a19\u7c64\u9801\uff0c\u7a0d\u5f8c\u518d\u8fd4\u56de\u3002\u6a21\u578b\u5b8c\u6210\u8a13\u7df4\u5f8c\uff0c\u60a8\u6703\u6536\u5230\u96fb\u5b50\u90f5\u4ef6\u3002Cloud Storage \u6216 BigQuery \u4e2d\u7684\u8868\u683c\u8a13\u7df4\u6578\u64da\u4e0d\u6703\u5c0e\u5165 Vertex AI\u3002\uff08\u5f9e\u672c\u5730\u6587\u4ef6\u5c0e\u5165\u6642\uff0c\u7cfb\u7d71\u6703\u5c07\u5176\u5c0e\u5165\u5230 Cloud Storage \u4e2d\u3002\uff09\u7576\u60a8\u4f7f\u7528\u8868\u683c\u6578\u64da\u5275\u5efa\u6578\u64da\u96c6\u6642\uff0c\u6578\u64da\u6703\u8207\u6578\u64da\u96c6\u95dc\u806f\u3002\u5275\u5efa\u6578\u64da\u96c6\u5f8c\uff0c\u60a8\u5c0d Cloud Storage \u6216 BigQuery \u4e2d\u7684\u6578\u64da\u6e90\u6240\u505a\u7684\u66f4\u6539\u6703\u7d0d\u5165\u4f7f\u7528\u8a72\u6578\u64da\u96c6\u8a13\u7df4\u7684\u6a21\u578b\u4e2d\u3002\u5728\u6a21\u578b\u8a13\u7df4\u958b\u59cb\u6642\uff0c\u5c07\u622a\u53d6\u6578\u64da\u96c6\u7684\u5feb\u7167\u3002\nCloud Storage \u6216 BigQuery \u4e2d\u7684\u8868\u683c\u8a13\u7df4\u6578\u64da\u4e0d\u6703\u5c0e\u5165 Vertex AI\u3002\uff08\u5f9e\u672c\u5730\u6587\u4ef6\u5c0e\u5165\u6642\uff0c\u7cfb\u7d71\u6703\u5c07\u5176\u5c0e\u5165\u5230 Cloud Storage \u4e2d\u3002\uff09\u7576\u60a8\u4f7f\u7528\u8868\u683c\u6578\u64da\u5275\u5efa\u6578\u64da\u96c6\u6642\uff0c\u6578\u64da\u6703\u8207\u6578\u64da\u96c6\u95dc\u806f\u3002\u5275\u5efa\u6578\u64da\u96c6\u5f8c\uff0c\u60a8\u5c0d Cloud Storage \u6216 BigQuery \u4e2d\u7684\u6578\u64da\u6e90\u6240\u505a\u7684\u66f4\u6539\u6703\u7d0d\u5165\u4f7f\u7528\u8a72\u6578\u64da\u96c6\u8a13\u7df4\u7684\u6a21\u578b\u4e2d\u3002\u5728\u6a21\u578b\u8a13\u7df4\u958b\u59cb\u6642\uff0c\u5c07\u622a\u53d6\u6578\u64da\u96c6\u7684\u5feb\u7167\u3002\n\u9078\u64c7\u8a9e\u8a00\u6216\u74b0\u5883\u6a19\u7c64\u9801\uff1a\u60a8\u53ef\u4ee5\u4f7f\u7528 [trainingPipelines.create](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines/create?hl=zh-cn) \u547d\u4ee4\u8a13\u7df4\u6a21\u578b\u3002\n\u5728\u4f7f\u7528\u4efb\u4f55\u8acb\u6c42\u6578\u64da\u4e4b\u524d\uff0c\u8acb\u5148\u9032\u884c\u4ee5\u4e0b\u66ff\u63db\uff1a- \uff1a\u60a8\u7684\u5340\u57df\u3002\n- \uff1a\u60a8\u7684 [\u9805\u76ee ID](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#identifiers) \u3002\n- \uff1a\u7232\u6b64\u64cd\u4f5c\u5275\u5efa\u7684\u8a13\u7df4\u6d41\u6c34\u7dda\u7684\u986f\u793a\u540d\u7a31\u3002\n- \uff1a\u6a21\u578b\u8a13\u7df4\u65b9\u6cd5\u3002\n- \u6642\u5e8f\u5bc6\u96c6\u7de8\u78bc\u5668 (TiDE)`gs://google-cloud-aiplatform/schema/trainingjob/definition/time_series_dense_encoder_forecasting_1.0.0.yaml`\n- Temporal Fusion Transformer (TFT)`gs://google-cloud-aiplatform/schema/trainingjob/definition/temporal_fusion_transformer_time_series_forecasting_1.0.0.yaml`\n- AutoML (L2L)`gs://google-cloud-aiplatform/schema/trainingjob/definition/automl_forecasting_1.0.0.yaml`\n- Seq2Seq+`gs://google-cloud-aiplatform/schema/trainingjob/definition/seq2seq_plus_time_series_forecasting_1.0.0.yaml`\n\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u6a21\u578b\u8a13\u7df4\u65b9\u6cd5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#training-methods) \u3002\n- \uff1a\u60a8\u5e0c\u671b\u6b64\u6a21\u578b\u9810\u6e2c\u7684\u5217\uff08\u503c\uff09\u3002\n- \uff1a\u6642\u9593\u5217\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn#data-structure) \u3002\n- \uff1a\u6642\u5e8f\u6a19\u8b58\u7b26\u5217\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn#data-structure) \u3002\n- \uff1a\uff08\u53ef\u9078\uff09\u6b0a\u91cd\u5217\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/prepare-data?hl=zh-cn#weight) \u3002\n- \uff1a\u60a8\u5e0c\u671b\u6a21\u578b\u8a13\u7df4\u7684\u6700\u9577\u6642\u9593\uff0c\u4ee5\u6beb\u7bc0\u9ede\u6642\u7232\u55ae\u4f4d\uff081,000 \u6beb\u7bc0\u9ede\u6642\u7b49\u65bc\u4e00\u7bc0\u9ede\u6642\uff09\u3002\n- \uff1a\u7528\u65bc\u8a13\u7df4\u6578\u64da\u7c92\u5ea6\u4ee5\u53ca\u9810\u6e2c\u6c34\u5e73\u548c\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u55ae\u5143\u3002\u53ef\u4ee5\u662f`minute`\u3001`hour`\u3001`day`\u3001`week`\u3001`month`\u6216`year`\u3002 \u5982\u679c\u60a8\u60f3\u4f7f\u7528\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\uff0c\u8acb\u9078\u64c7`day`\u3002 [\u77ad\u89e3\u5982\u4f55\u9078\u64c7\u6578\u64da\u7c92\u5ea6](https://cloud.google.com/vertex-ai/docs/tabular-data/bp-tabular?hl=zh-cn#granularity) \u3002\n- \uff1a\u8a13\u7df4\u6578\u64da\u5169\u6b21\u89c0\u5bdf\u6240\u9593\u9694\u7684\u7c92\u5ea6\u55ae\u4f4d\u6578\u3002\u5c0d\u65bc\u6240\u6709\u55ae\u4f4d\uff08\u5206\u9418\u9664\u5916\uff09\uff0c\u90fd\u5fc5\u9808\u7232 1\u30015\u300110\u300115 \u6216 30\u3002 [\u77ad\u89e3\u5982\u4f55\u9078\u64c7\u6578\u64da\u7c92\u5ea6](https://cloud.google.com/vertex-ai/docs/tabular-data/bp-tabular?hl=zh-cn#granularity) \u3002\n- \uff1a\u8a13\u7df4\u8f38\u5165\u8868\u4e2d\u7528\u65bc\u6a19\u8b58\u5c64\u6b21\u7d50\u69cb\u7d1a\u5225\u5206\u7d44\u7684\u5217\u540d\u3002\u9019\u4e9b\u5217\u5fc5\u9808\u662f\u201ctime_series_attributes_columns\u201d\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/hierarchical?hl=zh-cn) \u3002\n- \uff1a\u7d44\u5f59\u7e3d\u640d\u5931\u76f8\u5c0d\u65bc\u55ae\u500b\u640d\u5931\u7684\u6b0a\u91cd\u3002\u5982\u679c\u8a2d\u7f6e\u7232\u201c0.0\u201d\u6216\u672a\u8a2d\u7f6e\uff0c\u5247\u505c\u7528\u3002\u5982\u679c\u672a\u8a2d\u7f6e\u7d44\u5217\uff0c\u5247\u6240\u6709\u6642\u5e8f\u5c07\u88ab\u8996\u7232\u540c\u4e00\u7d44\uff0c\u4e26\u6309\u6240\u6709\u6642\u5e8f\u5f59\u7e3d\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/hierarchical?hl=zh-cn) \u3002\n- \uff1a\u6642\u9593\u5f59\u7e3d\u640d\u5931\u76f8\u5c0d\u65bc\u55ae\u500b\u640d\u5931\u7684\u6b0a\u91cd\u3002\u5982\u679c\u8a2d\u7f6e\u7232\u201c0.0\u201d\u6216\u672a\u8a2d\u7f6e\uff0c\u5247\u505c\u7528\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/hierarchical?hl=zh-cn) \u3002\n- \uff1a\u7e3d\uff08\u7d44 x \u6642\u9593\uff09\u5f59\u7e3d\u640d\u5931\u76f8\u5c0d\u65bc\u55ae\u500b\u640d\u5931\u7684\u6b0a\u91cd\u3002\u5982\u679c\u8a2d\u7f6e\u7232\u201c0.0\u201d\u6216\u672a\u8a2d\u7f6e\uff0c\u5247\u505c\u7528\u3002\u5982\u679c\u672a\u8a2d\u7f6e\u7d44\u5217\uff0c\u5247\u6240\u6709\u6642\u5e8f\u5c07\u88ab\u8996\u7232\u540c\u4e00\u7d44\uff0c\u4e26\u6309\u6240\u6709\u6642\u5e8f\u5f59\u7e3d\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/hierarchical?hl=zh-cn) \u3002\n- \uff1a\uff08\u53ef\u9078\uff09\u60a8\u53ef\u4ee5\u9078\u64c7\u4e00\u500b\u6216\u591a\u500b\u5730\u7406\u5340\u57df\u4ee5\u5553\u7528\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\u3002\u5728\u8a13\u7df4\u671f\u9593\uff0cVertex AI \u6703\u6839\u64da\u4e2d\u7684\u65e5\u671f\u548c\u6307\u5b9a\u7684\u5730\u7406\u5340\u57df\u5728\u6a21\u578b\u4e2d\u5275\u5efa\u7bc0\u5047\u65e5\u5206\u985e\u7279\u5fb5\u3002\u5982\u9700\u5553\u7528\u6b64\u529f\u80fd\uff0c\u8acb\u5c07\u8a2d\u7f6e\u7232`day`\uff0c\u4e26\u5728\u5b57\u6bb5\u4e2d\u6307\u5b9a\u4e00\u500b\u6216\u591a\u500b\u5340\u57df\u3002\u9ed8\u8a8d\u60c5\u6cc1\u4e0b\uff0c\u7bc0\u5047\u65e5\u6548\u61c9\u5efa\u6a21\u8655\u65bc\u505c\u7528\u72c0\u614b\u3002 \u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u7bc0\u5047\u65e5\u5340\u57df](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#holiday-regions) \u3002\n- \uff1a\u9810\u6e2c\u7bc4\u570d\u78ba\u5b9a\u6a21\u578b\u9810\u6e2c\u6bcf\u884c\u9810\u6e2c\u6578\u64da\u7684\u76ee\u6a19\u503c\u7684\u672a\u4f86\u6642\u9593\u3002\u9810\u6e2c\u7bc4\u570d\u4ee5\u6578\u64da\u7c92\u5ea6\u7232\u55ae\u4f4d () \u6307\u5b9a\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#forecast-window) \u3002\n- \uff1a\u4e0a\u4e0b\u6587\u7a97\u53e3\u8a2d\u7f6e\u4e86\u6a21\u578b\u5728\u8a13\u7df4\u671f\u9593\u7684\u56de\u6eaf\u6642\u9593\uff08\u7528\u65bc\u9810\u6e2c\uff09\u3002\u63db\u53e5\u8a71\u8aaa\uff0c\u5c0d\u65bc\u6bcf\u500b\u6578\u64da\u9ede\uff0c\u4e0a\u4e0b\u6587\u7a97\u53e3\u6703\u78ba\u5b9a\u6a21\u578b\u67e5\u627e\u56de\u6eaf\u6a21\u5f0f\u7684\u6642\u9593\u3002 \u4e0a\u4e0b\u6587\u7a97\u53e3\u4ee5\u6578\u64da\u7c92\u5ea6\u7232\u55ae\u4f4d () \u6307\u5b9a\u3002 [\u77ad\u89e3\u8a73\u60c5](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#forecast-window) \u3002\n- \uff1a\u9ed8\u8a8d\u60c5\u6cc1\u4e0b\uff0cVertex AI \u6703\u6700\u5927\u9650\u5ea6\u5730\u964d\u4f4e\u5747\u65b9\u6839\u8aa4\u5dee (RMSE)\u3002\u5982\u679c\u60a8\u8981\u7232\u9810\u6e2c\u6a21\u578b\u4f7f\u7528\u5176\u4ed6\u512a\u5316\u76ee\u6a19\uff0c\u8acb\u9078\u64c7 [\u9810\u6e2c\u6a21\u578b\u7684\u512a\u5316\u76ee\u6a19](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#optimization-objectives) \u4e2d\u7684\u4e00\u500b\u9078\u9805\u3002\u5982\u679c\u60a8\u9078\u64c7\u6700\u5927\u9650\u5ea6\u5730\u6e1b\u5c11\u5206\u4f4d\u6578\u640d\u5931\uff0c\u5247\u9084\u5fc5\u9808\u7232\u6307\u5b9a\u503c\u3002\n- \uff1a\uff08\u53ef\u9078\uff09\u5982\u679c\u8a2d\u7f6e\u7232`true`\uff0c\u5247 Vertex AI \u6703\u5c0d\u9810\u6e2c\u7684\u6982\u7387\u5206\u4f48\u5efa\u6a21\u3002\u6982\u7387\u63a8\u7406\u53ef\u4ee5\u901a\u904e\u8655\u7406\u566a\u8072\u6578\u64da\u4e26\u91cf\u5316\u4e0d\u78ba\u5b9a\u6027\u4f86\u63d0\u9ad8\u6a21\u578b\u8cea\u91cf\u3002\u5982\u679c\u6307\u5b9a\u4e86\uff0c\u5247 Vertex AI \u9084\u6703\u8fd4\u56de\u6982\u7387\u5206\u4f48\u7684\u5206\u4f4d\u6578\u3002\u6982\u7387\u63a8\u7406\u50c5\u8207`Time series Dense Encoder (TiDE)` ``and the` ``AutoML (L2L)`` `training  methods. It is incompatible with hierarchical forecasting and the` ``minimize-quantile-loss`` `optimization objective.``\u517c\u5bb9\n- ``` `: Quantiles to use for the`minimize-quantile-loss`optimization  objective and probabilistic inference. Provide a list of up to five unique numbers between`0`and`1`, exclusive.` `` `: The name or names of the columns that are time series  attributes. [Learn more](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#feature-type) .` `` `: The name or names of the covariate columns whose value  is known at forecast time. [Learn more](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#feature-type) .` `` `: The name or names of the covariate columns whose value  is unknown at forecast time. [Learn more](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#feature-type) .` `` `: The transformation type is provided for each column used to  train the model. [Learn more](https://cloud.google.com/vertex-ai/docs/datasets/data-types-tabular?hl=zh-cn#transformations) .` `` `: The name of the column with the specified transformation type. Every  column used to train the model must be specified.` `` `: Display name for the newly trained model.` `` `: ID for the training Dataset.` `` `You can provide a`Split`object to control your data split. For information about  controlling data split, see [Control the data split using REST](#data-split) .` `` `You can provide a`windowConfig`object to configure a rolling window strategy for  forecast window generation. For further information, see [Configure the rolling window strategy using REST](#rolling-window) .` `` `: Your project's automatically generated [project number](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#identifiers) ` ```\n``` `HTTP method and URL:` `` `\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/trainingPipelines\n```\n` `` `Request JSON body:` `` `\n```\n{\n \"displayName\": \"TRAINING_PIPELINE_DISPLAY_NAME\",\n \"trainingTaskDefinition\": \"TRAINING_TASK_DEFINITION\",\n \"trainingTaskInputs\": {\n  \"targetColumn\": \"TARGET_COLUMN\",\n  \"timeColumn\": \"TIME_COLUMN\",\n  \"timeSeriesIdentifierColumn\": \"TIME_SERIES_IDENTIFIER_COLUMN\",\n  \"weightColumn\": \"WEIGHT_COLUMN\",\n  \"trainBudgetMilliNodeHours\": TRAINING_BUDGET,\n  \"dataGranularity\": {\"unit\": \"GRANULARITY_UNIT\", \"quantity\": GRANULARITY_QUANTITY},\n  \"hierarchyConfig\": {\"groupColumns\": GROUP_COLUMNS, \"groupTotalWeight\": GROUP_TOTAL_WEIGHT, \"temporalTotalWeight\": TEMPORAL_TOTAL_WEIGHT, \"groupTemporalTotalWeight\": GROUP_TEMPORAL_TOTAL_WEIGHT}\n  \"holidayRegions\" : [\"HOLIDAY_REGIONS_1\", \"HOLIDAY_REGIONS_2\", ...]\n  \"forecast_horizon\": FORECAST_HORIZON,\n  \"context_window\": CONTEXT_WINDOW,\n  \"optimizationObjective\": \"OPTIMIZATION_OBJECTIVE\",\n  \"quantiles\": \"QUANTILES\",\n  \"enableProbabilisticInference\": \"PROBABILISTIC_INFERENCE\",\n  \"time_series_attribute_columns\": [\"TIME_SERIES_ATTRIBUTE_COL_1\", \"TIME_SERIES_ATTRIBUTE_COL_2\", ...]\n  \"available_at_forecast_columns\": [\"AVAILABLE_AT_FORECAST_COL_1\", \"AVAILABLE_AT_FORECAST_COL_2\", ...]\n  \"unavailable_at_forecast_columns\": [\"UNAVAILABLE_AT_FORECAST_COL_1\", \"UNAVAILABLE_AT_FORECAST_COL_2\", ...]\n  \"transformations\": [   {\"TRANSFORMATION_TYPE_1\": {\"column_name\" : \"COLUMN_NAME_1\"} },\n   {\"TRANSFORMATION_TYPE_2\": {\"column_name\" : \"COLUMN_NAME_2\"} },\n   ...\n },\n \"modelToUpload\": {\"displayName\": \"MODEL_DISPLAY_NAME\"},\n \"inputDataConfig\": {\n  \"datasetId\": \"DATASET_ID\",\n }\n}\n```\n` `` `To send your request, expand one of these options:` `` `` `` `` `` `You should receive a JSON response similar to the following:` `` `\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION/trainingPipelines/TRAINING_PIPELINE_ID\",\n \"displayName\": \"myModelName\",\n \"trainingTaskDefinition\": \"gs://google-cloud-aiplatform/schema/trainingjob/definition/automl_tabular_1.0.0.yaml\",\n \"modelToUpload\": {\n \"displayName\": \"myModelName\"\n },\n \"state\": \"PIPELINE_STATE_PENDING\",\n \"createTime\": \"2020-08-18T01:22:57.479336Z\",\n \"updateTime\": \"2020-08-18T01:22:57.479336Z\"\n}\n```\n` ```\n``` `### PythonTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk?hl=zh-cn) .   For more information, see the [   Python API reference documentation](https://cloud.google.com/python/docs/reference/aiplatform/latest?hl=zh-cn) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_training_pipeline_forecasting_tide_sample.py) \n```\ndef create_training_pipeline_forecasting_time_series_dense_encoder_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 dataset_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 model_display_name: str = \"my_model\",\u00a0 \u00a0 target_column: str = \"target_column\",\u00a0 \u00a0 time_column: str = \"date\",\u00a0 \u00a0 time_series_identifier_column: str = \"time_series_id\",\u00a0 \u00a0 unavailable_at_forecast_columns: List[str] = [],\u00a0 \u00a0 available_at_forecast_columns: List[str] = [],\u00a0 \u00a0 forecast_horizon: int = 1,\u00a0 \u00a0 data_granularity_unit: str = \"week\",\u00a0 \u00a0 data_granularity_count: int = 1,\u00a0 \u00a0 training_fraction_split: float = 0.8,\u00a0 \u00a0 validation_fraction_split: float = 0.1,\u00a0 \u00a0 test_fraction_split: float = 0.1,\u00a0 \u00a0 budget_milli_node_hours: int = 8000,\u00a0 \u00a0 timestamp_split_column_name: str = \"timestamp_split\",\u00a0 \u00a0 weight_column: str = \"weight\",\u00a0 \u00a0 time_series_attribute_columns: List[str] = [],\u00a0 \u00a0 context_window: int = 0,\u00a0 \u00a0 export_evaluated_data_items: bool = False,\u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri: Optional[str] = None,\u00a0 \u00a0 export_evaluated_data_items_override_destination: bool = False,\u00a0 \u00a0 quantiles: Optional[List[float]] = None,\u00a0 \u00a0 enable_probabilistic_inference: bool = False,\u00a0 \u00a0 validation_options: Optional[str] = None,\u00a0 \u00a0 predefined_split_column_name: Optional[str] = None,\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 # Create training job\u00a0 \u00a0 forecasting_tide_job = aiplatform.TimeSeriesDenseEncoderForecastingTrainingJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 optimization_objective=\"minimize-rmse\",\u00a0 \u00a0 )\u00a0 \u00a0 # Retrieve existing dataset\u00a0 \u00a0 dataset = aiplatform.TimeSeriesDataset(dataset_id)\u00a0 \u00a0 # Run training job\u00a0 \u00a0 model = forecasting_tide_job.run(\u00a0 \u00a0 \u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 \u00a0 \u00a0 target_column=target_column,\u00a0 \u00a0 \u00a0 \u00a0 time_column=time_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_identifier_column=time_series_identifier_column,\u00a0 \u00a0 \u00a0 \u00a0 unavailable_at_forecast_columns=unavailable_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 available_at_forecast_columns=available_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 forecast_horizon=forecast_horizon,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_unit=data_granularity_unit,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_count=data_granularity_count,\u00a0 \u00a0 \u00a0 \u00a0 training_fraction_split=training_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 validation_fraction_split=validation_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 test_fraction_split=test_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 predefined_split_column_name=predefined_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 timestamp_split_column_name=timestamp_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 weight_column=weight_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_attribute_columns=time_series_attribute_columns,\u00a0 \u00a0 \u00a0 \u00a0 context_window=context_window,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items=export_evaluated_data_items,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri=export_evaluated_data_items_bigquery_destination_uri,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_override_destination=export_evaluated_data_items_override_destination,\u00a0 \u00a0 \u00a0 \u00a0 quantiles=quantiles,\u00a0 \u00a0 \u00a0 \u00a0 enable_probabilistic_inference=enable_probabilistic_inference,\u00a0 \u00a0 \u00a0 \u00a0 validation_options=validation_options,\u00a0 \u00a0 \u00a0 \u00a0 budget_milli_node_hours=budget_milli_node_hours,\u00a0 \u00a0 \u00a0 \u00a0 model_display_name=model_display_name,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 model.wait()\u00a0 \u00a0 print(model.display_name)\u00a0 \u00a0 print(model.resource_name)\u00a0 \u00a0 print(model.uri)\u00a0 \u00a0 return model\n```\n` `` `### PythonTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk?hl=zh-cn) .   For more information, see the [   Python API reference documentation](https://cloud.google.com/python/docs/reference/aiplatform/latest?hl=zh-cn) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_training_pipeline_forecasting_tft_sample.py) \n```\ndef create_training_pipeline_forecasting_temporal_fusion_transformer_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 dataset_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 model_display_name: str = \"my_model\",\u00a0 \u00a0 target_column: str = \"target_column\",\u00a0 \u00a0 time_column: str = \"date\",\u00a0 \u00a0 time_series_identifier_column: str = \"time_series_id\",\u00a0 \u00a0 unavailable_at_forecast_columns: List[str] = [],\u00a0 \u00a0 available_at_forecast_columns: List[str] = [],\u00a0 \u00a0 forecast_horizon: int = 1,\u00a0 \u00a0 data_granularity_unit: str = \"week\",\u00a0 \u00a0 data_granularity_count: int = 1,\u00a0 \u00a0 training_fraction_split: float = 0.8,\u00a0 \u00a0 validation_fraction_split: float = 0.1,\u00a0 \u00a0 test_fraction_split: float = 0.1,\u00a0 \u00a0 budget_milli_node_hours: int = 8000,\u00a0 \u00a0 timestamp_split_column_name: str = \"timestamp_split\",\u00a0 \u00a0 weight_column: str = \"weight\",\u00a0 \u00a0 time_series_attribute_columns: List[str] = [],\u00a0 \u00a0 context_window: int = 0,\u00a0 \u00a0 export_evaluated_data_items: bool = False,\u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri: Optional[str] = None,\u00a0 \u00a0 export_evaluated_data_items_override_destination: bool = False,\u00a0 \u00a0 validation_options: Optional[str] = None,\u00a0 \u00a0 predefined_split_column_name: Optional[str] = None,\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 # Create training job\u00a0 \u00a0 forecasting_tft_job = aiplatform.TemporalFusionTransformerForecastingTrainingJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 optimization_objective=\"minimize-rmse\",\u00a0 \u00a0 )\u00a0 \u00a0 # Retrieve existing dataset\u00a0 \u00a0 dataset = aiplatform.TimeSeriesDataset(dataset_id)\u00a0 \u00a0 # Run training job\u00a0 \u00a0 model = forecasting_tft_job.run(\u00a0 \u00a0 \u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 \u00a0 \u00a0 target_column=target_column,\u00a0 \u00a0 \u00a0 \u00a0 time_column=time_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_identifier_column=time_series_identifier_column,\u00a0 \u00a0 \u00a0 \u00a0 unavailable_at_forecast_columns=unavailable_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 available_at_forecast_columns=available_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 forecast_horizon=forecast_horizon,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_unit=data_granularity_unit,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_count=data_granularity_count,\u00a0 \u00a0 \u00a0 \u00a0 training_fraction_split=training_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 validation_fraction_split=validation_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 test_fraction_split=test_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 predefined_split_column_name=predefined_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 timestamp_split_column_name=timestamp_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 weight_column=weight_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_attribute_columns=time_series_attribute_columns,\u00a0 \u00a0 \u00a0 \u00a0 context_window=context_window,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items=export_evaluated_data_items,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri=export_evaluated_data_items_bigquery_destination_uri,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_override_destination=export_evaluated_data_items_override_destination,\u00a0 \u00a0 \u00a0 \u00a0 validation_options=validation_options,\u00a0 \u00a0 \u00a0 \u00a0 budget_milli_node_hours=budget_milli_node_hours,\u00a0 \u00a0 \u00a0 \u00a0 model_display_name=model_display_name,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 model.wait()\u00a0 \u00a0 print(model.display_name)\u00a0 \u00a0 print(model.resource_name)\u00a0 \u00a0 print(model.uri)\u00a0 \u00a0 return model\n```\n` `` `### PythonTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk?hl=zh-cn) .   For more information, see the [   Python API reference documentation](https://cloud.google.com/python/docs/reference/aiplatform/latest?hl=zh-cn) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_training_pipeline_forecasting_sample.py) \n```\ndef create_training_pipeline_forecasting_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 dataset_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 model_display_name: str = \"my_model\",\u00a0 \u00a0 target_column: str = \"target_column\",\u00a0 \u00a0 time_column: str = \"date\",\u00a0 \u00a0 time_series_identifier_column: str = \"time_series_id\",\u00a0 \u00a0 unavailable_at_forecast_columns: List[str] = [],\u00a0 \u00a0 available_at_forecast_columns: List[str] = [],\u00a0 \u00a0 forecast_horizon: int = 1,\u00a0 \u00a0 data_granularity_unit: str = \"week\",\u00a0 \u00a0 data_granularity_count: int = 1,\u00a0 \u00a0 training_fraction_split: float = 0.8,\u00a0 \u00a0 validation_fraction_split: float = 0.1,\u00a0 \u00a0 test_fraction_split: float = 0.1,\u00a0 \u00a0 budget_milli_node_hours: int = 8000,\u00a0 \u00a0 timestamp_split_column_name: str = \"timestamp_split\",\u00a0 \u00a0 weight_column: str = \"weight\",\u00a0 \u00a0 time_series_attribute_columns: List[str] = [],\u00a0 \u00a0 context_window: int = 0,\u00a0 \u00a0 export_evaluated_data_items: bool = False,\u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri: Optional[str] = None,\u00a0 \u00a0 export_evaluated_data_items_override_destination: bool = False,\u00a0 \u00a0 quantiles: Optional[List[float]] = None,\u00a0 \u00a0 enable_probabilistic_inference: bool = False,\u00a0 \u00a0 validation_options: Optional[str] = None,\u00a0 \u00a0 predefined_split_column_name: Optional[str] = None,\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 # Create training job\u00a0 \u00a0 forecasting_job = aiplatform.AutoMLForecastingTrainingJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name, optimization_objective=\"minimize-rmse\"\u00a0 \u00a0 )\u00a0 \u00a0 # Retrieve existing dataset\u00a0 \u00a0 dataset = aiplatform.TimeSeriesDataset(dataset_id)\u00a0 \u00a0 # Run training job\u00a0 \u00a0 model = forecasting_job.run(\u00a0 \u00a0 \u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 \u00a0 \u00a0 target_column=target_column,\u00a0 \u00a0 \u00a0 \u00a0 time_column=time_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_identifier_column=time_series_identifier_column,\u00a0 \u00a0 \u00a0 \u00a0 unavailable_at_forecast_columns=unavailable_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 available_at_forecast_columns=available_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 forecast_horizon=forecast_horizon,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_unit=data_granularity_unit,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_count=data_granularity_count,\u00a0 \u00a0 \u00a0 \u00a0 training_fraction_split=training_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 validation_fraction_split=validation_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 test_fraction_split=test_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 predefined_split_column_name=predefined_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 timestamp_split_column_name=timestamp_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 weight_column=weight_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_attribute_columns=time_series_attribute_columns,\u00a0 \u00a0 \u00a0 \u00a0 context_window=context_window,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items=export_evaluated_data_items,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri=export_evaluated_data_items_bigquery_destination_uri,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_override_destination=export_evaluated_data_items_override_destination,\u00a0 \u00a0 \u00a0 \u00a0 quantiles=quantiles,\u00a0 \u00a0 \u00a0 \u00a0 enable_probabilistic_inference=enable_probabilistic_inference,\u00a0 \u00a0 \u00a0 \u00a0 validation_options=validation_options,\u00a0 \u00a0 \u00a0 \u00a0 budget_milli_node_hours=budget_milli_node_hours,\u00a0 \u00a0 \u00a0 \u00a0 model_display_name=model_display_name,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 model.wait()\u00a0 \u00a0 print(model.display_name)\u00a0 \u00a0 print(model.resource_name)\u00a0 \u00a0 print(model.uri)\u00a0 \u00a0 return model\n```\n` `` `### PythonTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk?hl=zh-cn) .   For more information, see the [   Python API reference documentation](https://cloud.google.com/python/docs/reference/aiplatform/latest?hl=zh-cn) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_training_pipeline_forecasting_seq2seq_sample.py) \n```\ndef create_training_pipeline_forecasting_seq2seq_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 dataset_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 model_display_name: str = \"my_model\",\u00a0 \u00a0 target_column: str = \"target_column\",\u00a0 \u00a0 time_column: str = \"date\",\u00a0 \u00a0 time_series_identifier_column: str = \"time_series_id\",\u00a0 \u00a0 unavailable_at_forecast_columns: List[str] = [],\u00a0 \u00a0 available_at_forecast_columns: List[str] = [],\u00a0 \u00a0 forecast_horizon: int = 1,\u00a0 \u00a0 data_granularity_unit: str = \"week\",\u00a0 \u00a0 data_granularity_count: int = 1,\u00a0 \u00a0 training_fraction_split: float = 0.8,\u00a0 \u00a0 validation_fraction_split: float = 0.1,\u00a0 \u00a0 test_fraction_split: float = 0.1,\u00a0 \u00a0 budget_milli_node_hours: int = 8000,\u00a0 \u00a0 timestamp_split_column_name: str = \"timestamp_split\",\u00a0 \u00a0 weight_column: str = \"weight\",\u00a0 \u00a0 time_series_attribute_columns: List[str] = [],\u00a0 \u00a0 context_window: int = 0,\u00a0 \u00a0 export_evaluated_data_items: bool = False,\u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri: Optional[str] = None,\u00a0 \u00a0 export_evaluated_data_items_override_destination: bool = False,\u00a0 \u00a0 validation_options: Optional[str] = None,\u00a0 \u00a0 predefined_split_column_name: Optional[str] = None,\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 # Create training job\u00a0 \u00a0 forecasting_seq2seq_job = aiplatform.SequenceToSequencePlusForecastingTrainingJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name, optimization_objective=\"minimize-rmse\"\u00a0 \u00a0 )\u00a0 \u00a0 # Retrieve existing dataset\u00a0 \u00a0 dataset = aiplatform.TimeSeriesDataset(dataset_id)\u00a0 \u00a0 # Run training job\u00a0 \u00a0 model = forecasting_seq2seq_job.run(\u00a0 \u00a0 \u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 \u00a0 \u00a0 target_column=target_column,\u00a0 \u00a0 \u00a0 \u00a0 time_column=time_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_identifier_column=time_series_identifier_column,\u00a0 \u00a0 \u00a0 \u00a0 unavailable_at_forecast_columns=unavailable_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 available_at_forecast_columns=available_at_forecast_columns,\u00a0 \u00a0 \u00a0 \u00a0 forecast_horizon=forecast_horizon,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_unit=data_granularity_unit,\u00a0 \u00a0 \u00a0 \u00a0 data_granularity_count=data_granularity_count,\u00a0 \u00a0 \u00a0 \u00a0 training_fraction_split=training_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 validation_fraction_split=validation_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 test_fraction_split=test_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 predefined_split_column_name=predefined_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 timestamp_split_column_name=timestamp_split_column_name,\u00a0 \u00a0 \u00a0 \u00a0 weight_column=weight_column,\u00a0 \u00a0 \u00a0 \u00a0 time_series_attribute_columns=time_series_attribute_columns,\u00a0 \u00a0 \u00a0 \u00a0 context_window=context_window,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items=export_evaluated_data_items,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_bigquery_destination_uri=export_evaluated_data_items_bigquery_destination_uri,\u00a0 \u00a0 \u00a0 \u00a0 export_evaluated_data_items_override_destination=export_evaluated_data_items_override_destination,\u00a0 \u00a0 \u00a0 \u00a0 validation_options=validation_options,\u00a0 \u00a0 \u00a0 \u00a0 budget_milli_node_hours=budget_milli_node_hours,\u00a0 \u00a0 \u00a0 \u00a0 model_display_name=model_display_name,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 model.wait()\u00a0 \u00a0 print(model.display_name)\u00a0 \u00a0 print(model.resource_name)\u00a0 \u00a0 print(model.uri)\u00a0 \u00a0 return model\n```\n` ```\n``` `\n## Control the data split using REST\n` `` `You can control how your training data is split between the training, validation, and test sets. Use a split column to manually specify the data split for each row and provide it as part of a `PredefinedSplit` [Split object](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.trainingPipelines?hl=zh-cn#InputDataConfig) in the `inputDataConfig` of the JSON request.` `` ` is the column containing the data split values ( `TRAIN` , `VALIDATION` , `TEST` ).` `` ````\n\u00a0\"predefinedSplit\": {\u00a0 \u00a0\"key\": DATA_SPLIT_COLUMN\u00a0},\n```` `` ` [Learn more](https://cloud.google.com/vertex-ai/docs/tabular-data/data-splits?hl=zh-cn) about data splits.` `` `\n## Configure the rolling window strategy using REST\n` `` `You can provide a `windowConfig` object to configure a rolling window strategy for forecast window generation. The default strategy is `maxCount` .` `` `- To use the `maxCount` option, add the following to `trainingTaskInputs` of the JSON request. refers to the maximum number of windows.```\n\u00a0\"windowConfig\": {\u00a0 \u00a0\"maxCount\": MAX_COUNT_VALUE\u00a0},\u00a0```\n```\n- To use the `strideLength` option, add the following to `trainingTaskInputs` of the JSON request. refers to the value of the stride length.```\n\u00a0\"windowConfig\": {\u00a0 \u00a0\"strideLength\": STRIDE_LENGTH_VALUE\u00a0},\u00a0```\n```\n- To use the `column` option, add the following to `trainingTaskInputs` of the JSON request. refers to the name of the column with `True` or `False` values.```\n\u00a0\"windowConfig\": {\u00a0 \u00a0\"column\": \"COLUMN_NAME\"\u00a0},\u00a0```\n```\n` `` `To learn more, see [Rolling window strategies](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting-parameters?hl=zh-cn#rolling-window-strategies) .``\n````\n``` `\n## What's next\n` `` `- [Evaluate your model](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/evaluate-model?hl=zh-cn) .\n` ```", "guide": "Vertex AI"}