{"title": "Vertex AI - Train a model with Tabular Workflow for Forecasting", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Train a model with Tabular Workflow for Forecasting\nTo see an example of how to train a forecasting model,  run the \"Tabular Workflow for Forecasting\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_forecasting_on_vertex_pipelines.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fautoml%2Fautoml_forecasting_on_vertex_pipelines.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_forecasting_on_vertex_pipelines.ipynb)\nThis page shows you how to train a forecasting model from a tabular dataset with Tabular Workflow for Forecasting.\nTo learn about the service accounts used by this workflow, see [Service accounts for Tabular Workflows](/vertex-ai/docs/tabular-data/tabular-workflows/service-accounts#forecasting) .\nIf you receive an error related to quotas while running Tabular Workflow for Forecasting, you might need to request a higher quota. To learn more, see [Manage quotas for Tabular Workflows](/vertex-ai/docs/tabular-data/tabular-workflows/quotas) .\nTabular Workflow for Forecasting does not support model export.\n", "content": "## Workflow APIs\nThis workflow uses the following APIs:\n- Vertex AI\n- Dataflow\n- Compute Engine\n- Cloud Storage## Get the URI of the previous hyperparameter tuning result\nIf you have previously completed a Tabular Workflow for Forecasting run, you can use the hyperparameter tuning result from the previous run to save training time and resources. You can find the previous hyperparameter tuning result by using the Google Cloud console or by loading it programmatically with the API.\nTo find the hyperparameter tuning result URI by using the Google Cloud console, perform the following steps:- In the Google Cloud console, in the Vertex AI section, go to the **Pipelines** page. [Go to the Pipelines page](https://console.cloud.google.com/vertex-ai/pipelines) \n- Select the **Runs** tab.\n- Select the pipeline run you want to use.\n- Select **Expand Artifacts** .\n- Click on component **exit-handler-1** .\n- Click on component **stage_1_tuning_result_artifact_uri_empty** .\n- Find component **automl-forecasting-stage-1-tuner** .\n- Click on the associated artifact **tuning_result_output** .\n- Select the **Node Info** tab.\n- Copy the URI for use in the [Train a model](#train-model) step.\nThe following sample code demonstrates how you can load the hyperparameter tuning result by using the API. The variable `job` refers to the previous model training pipeline run.\n```\ndef get_task_detail(\u00a0 task_details: List[Dict[str, Any]], task_name: str) -> List[Dict[str, Any]]:\u00a0 for task_detail in task_details:\u00a0 \u00a0 \u00a0 if task_detail.task_name == task_name:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return task_detailpipeline_task_details = job.gca_resource.job_detail.task_detailsstage_1_tuner_task = get_task_detail(\u00a0 \u00a0 pipeline_task_details, \"automl-forecasting-stage-1-tuner\")stage_1_tuning_result_artifact_uri = (\u00a0 \u00a0 stage_1_tuner_task.outputs[\"tuning_result_output\"].artifacts[0].uri)\n```\n## Train a model\nThe following sample code demonstrates how you can run a model training pipeline:\n```\njob = aiplatform.PipelineJob(\u00a0 \u00a0 ...\u00a0 \u00a0 template_path=template_path,\u00a0 \u00a0 parameter_values=parameter_values,\u00a0 \u00a0 ...)job.run(service_account=SERVICE_ACCOUNT)\n```\nThe optional `service_account` parameter in `job.run()` lets you set the Vertex AI Pipelines service account to an account of your choice.\nVertex AI supports the following methods for training your model:\n- **Time series Dense Encoder (TiDE)** . To use this model training method, define your pipeline and parameter values by using the following function:```\ntemplate_path, parameter_values = automl_forecasting_utils.get_time_series_dense_encoder_forecasting_pipeline_and_parameters(...)\n```\n- **Temporal Fusion Transformer (TFT)** . To use this model training method, define your pipeline and parameter values by using the following function:```\ntemplate_path, parameter_values = automl_forecasting_utils.get_temporal_fusion_transformer_forecasting_pipeline_and_parameters(...)\n```\n- **AutoML (L2L)** . To use this model training method, define your pipeline and parameter values by using the following function:```\ntemplate_path, parameter_values = automl_forecasting_utils.get_learn_to_learn_forecasting_pipeline_and_parameters(...)\n```\n- **Seq2Seq+** . To use this model training method, define your pipeline and parameter values by using the following function:```\ntemplate_path, parameter_values = automl_forecasting_utils.get_sequence_to_sequence_forecasting_pipeline_and_parameters(...)\n```\nTo learn more, see [Model training methods](/vertex-ai/docs/tabular-data/forecasting-parameters#training-methods) .\nThe training data can be either a CSV file in Cloud Storage or a table in BigQuery.\nThe following is a subset of model training parameters:\n| Parameter name     | Type  | Definition                                                                                                                         |\n|:---------------------------------|:------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| optimization_objective   | String  | By default, Vertex AI minimizes the root-mean-squared error (RMSE). If you want a different optimization objective for your forecast model, choose one of the options in Optimization objectives for forecasting models. If you choose to minimize the quantile loss, you must also specify a value for quantiles.                                               |\n| enable_probabilistic_inference | Boolean  | If set to true, Vertex AI models the probability distribution of the forecast. Probabilistic inference can improve model quality by handling noisy data and quantifying uncertainty. If quantiles are specified, then Vertex AI also returns the quantiles of the distribution. Probabilistic inference is compatible only with the Time series Dense Encoder (TiDE) and the AutoML (L2L) training methods. Probabilistic inference is incompatible with the minimize-quantile-loss optimization objective. |\n| quantiles      | List[float] | Quantiles to use for minimize-quantile-loss optimization objective and probabilistic inference. Provide a list of up to five unique numbers between 0 and 1, exclusive.                                                                                  |\n| time_column      | String  | The time column. To learn more, see Data structure requirements.                                                                                                           |\n| time_series_identifier_columns | List[str] | The time series identifier columns. To learn more, see Data structure requirements.                                                                                                       |\n| weight_column     | String  | (Optional) The weight column. To learn more, see Add weights to your training data.                                                                                                       |\n| time_series_attribute_columns | List[str] | (Optional) The name or names of the columns that are time series attributes. To learn more, see Feature type and availability at forecast.                                                                                         |\n| available_at_forecast_columns | List[str] | (Optional) The name or names of the covariate columns whose value is known at forecast time. To learn more, see Feature type and availability at forecast.                                                                                     |\n| unavailable_at_forecast_columns | List[str] | (Optional) The name or names of the covariate columns whose value is unknown at forecast time. To learn more, see Feature type and availability at forecast.                                                                                    |\n| forecast_horizon     | Integer  | (Optional) The forecast horizon determines how far into the future the model forecasts the target value for each row of prediction data. To learn more, see Forecast horizon, context window, and forecast window.                                                                       |\n| context_window     | Integer  | (Optional) The context window sets how far back the model looks during training (and for forecasts). In other words, for each training datapoint, the context window determines how far back the model looks for predictive patterns. To learn more, see Forecast horizon, context window, and forecast window.                                               |\n| window_max_count     | Integer  | (Optional) Vertex AI generates forecast windows from the input data using a rolling window strategy. The default strategy is Count. The default value for the maximum number of windows is 100,000,000. Set this parameter to provide a custom value for the maximum number of windows. To learn more, see Rolling window strategies.                                          |\n| window_stride_length    | Integer  | (Optional) Vertex AI generates forecast windows from the input data using a rolling window strategy. To select the Stride strategy, set this parameter to the value of the stride length. To learn more, see Rolling window strategies.                                                                  |\n| window_predefined_column   | String  | (Optional) Vertex AI generates forecast windows from the input data using a rolling window strategy. To select the Column strategy, set this parameter to the name of the column with True or False values. To learn more, see Rolling window strategies.                                                             |\n| holiday_regions     | List[str] | (Optional) You can select one or more geographical regions to enable holiday effect modeling. During training, Vertex AI creates holiday categorical features within the model based on the date from time_column and the specified geographical regions. By default, holiday effect modeling is disabled. To learn more, see Holiday regions.                                        |\n| predefined_split_key    | String  | (Optional) By default, Vertex AI uses a chronological split algorithm to separate your forecasting data into the three data splits. If you want to control which training data rows are used for which split, provide the name of the column containing the data split values (TRAIN, VALIDATION, TEST). To learn more, see Data splits for forecasting.                                     |\n| training_fraction    | Float  | (Optional) By default, Vertex AI uses a chronological split algorithm to separate your forecasting data into the three data splits. 80% of the data is assigned to the training set, 10% is assigned to the validation split, and 10% is assigned to the test split. Set this parameter if you want to customize the fraction of the data that is assigned to the training set. To learn more, see Data splits for forecasting.                    |\n| validation_fraction    | Float  | (Optional) By default, Vertex AI uses a chronological split algorithm to separate your forecasting data into the three data splits. 80% of the data is assigned to the training set, 10% is assigned to the validation split, and 10% is assigned to the test split. Set this parameter if you want to customize the fraction of the data that is assigned to the validation set. To learn more, see Data splits for forecasting.                   |\n| test_fraction     | Float  | (Optional) By default, Vertex AI uses a chronological split algorithm to separate your forecasting data into the three data splits. 80% of the data is assigned to the training set, 10% is assigned to the validation split, and 10% is assigned to the test split. Set this parameter if you want to customize the fraction of the data that is assigned to the test set. To learn more, see Data splits for forecasting.                     |\n| data_source_csv_filenames  | String  | A URI for a CSV stored in Cloud Storage.                                                                                                                 |\n| data_source_bigquery_table_path | String  | A URI for a BigQuery table.                                                                                                                     |\n| dataflow_service_account   | String  | (Optional) Custom service account to run Dataflow jobs. The Dataflow job can be configured to use private IPs and a specific VPC subnet. This parameter acts as an override for the default Dataflow worker service account.                                                                    |\n| run_evaluation     | Boolean  | If set to True, Vertex AI evaluates the ensembled model on the test split.                                                                                                         |\n| evaluated_examples_bigquery_path | String  | The path of the BigQuery dataset used during model evaluation. The dataset serves as a destination for the predicted examples. The parameter value must be set if run_evaluation is set to True and must have the following format: bq://[PROJECT].[DATASET].                                                            |\n**Transformations**\nYou can provide a dictionary mapping of auto- or type-resolutions to feature columns. The supported types are: auto, numeric, categorical, text, and timestamp.\n| Parameter name | Type     | Definition          |\n|:-----------------|:---------------------|:------------------------------------------------|\n| transformations | Dict[str, List[str]] | Dictionary mapping of auto- or type-resolutions |\nThe following code provides a helper function for populating the `transformations` parameter. It also demonstrates how you can use this function to apply automatic transformations to a set of columns defined by a `features` variable.\n```\ndef generate_transformation(\u00a0 \u00a0 \u00a0 auto_column_names: Optional[List[str]]=None,\u00a0 \u00a0 \u00a0 numeric_column_names: Optional[List[str]]=None,\u00a0 \u00a0 \u00a0 categorical_column_names: Optional[List[str]]=None,\u00a0 \u00a0 \u00a0 text_column_names: Optional[List[str]]=None,\u00a0 \u00a0 \u00a0 timestamp_column_names: Optional[List[str]]=None,\u00a0 \u00a0 ) -> List[Dict[str, Any]]:\u00a0 \u00a0 if auto_column_names is None:\u00a0 \u00a0 \u00a0 auto_column_names = []\u00a0 \u00a0 if numeric_column_names is None:\u00a0 \u00a0 \u00a0 numeric_column_names = []\u00a0 \u00a0 if categorical_column_names is None:\u00a0 \u00a0 \u00a0 categorical_column_names = []\u00a0 \u00a0 if text_column_names is None:\u00a0 \u00a0 \u00a0 text_column_names = []\u00a0 \u00a0 if timestamp_column_names is None:\u00a0 \u00a0 \u00a0 timestamp_column_names = []\u00a0 \u00a0 return {\u00a0 \u00a0 \u00a0 \u00a0 \"auto\": auto_column_names,\u00a0 \u00a0 \u00a0 \u00a0 \"numeric\": numeric_column_names,\u00a0 \u00a0 \u00a0 \u00a0 \"categorical\": categorical_column_names,\u00a0 \u00a0 \u00a0 \u00a0 \"text\": text_column_names,\u00a0 \u00a0 \u00a0 \u00a0 \"timestamp\": timestamp_column_names,\u00a0 \u00a0 }transformations = generate_transformation(auto_column_names=features)\n```\nTo learn more about transformations, see [Data types and transformations](/vertex-ai/docs/datasets/data-types-tabular) .\n**Workflow customization options**\nYou can customize the Tabular Workflow for Forecasting by defining argument values that are passed in during pipeline definition. You can customize your workflow in the following ways:\n- Configure hardware\n- Skip architecture search\n**Configure hardware**\nThe following model training parameter lets you configure the machine types and the number of machines for training. This option is a good choice if you have a large dataset and want to optimize the machine hardware accordingly.\n| Parameter name       | Type    | Definition                                            |\n|:-----------------------------------------|:------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| stage_1_tuner_worker_pool_specs_override | Dict[String, Any] | (Optional) Custom configuration of the machine types and the number of machines for training. This parameter configures the automl-forecasting-stage-1-tuner component of the pipeline. |\nThe following code demonstrates how to set `n1-standard-8` machine type for the TensorFlow chief node and `n1-standard-4` machine type for the TensorFlow evaluator node:\n```\nworker_pool_specs_override = [\u00a0 {\"machine_spec\": {\"machine_type\": \"n1-standard-8\"}}, # override for TF chief node\u00a0 {}, \u00a0# override for TF worker node, since it's not used, leave it empty\u00a0 {}, \u00a0# override for TF ps node, since it's not used, leave it empty\u00a0 {\u00a0 \u00a0 \"machine_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \"machine_type\": \"n1-standard-4\" # override for TF evaluator node\u00a0 \u00a0 }\u00a0 }]\n```\n**Skip architecture search**\nThe following model training parameter lets you run the pipeline without the architecture search and provide a set of [hyperparameters from a previous pipeline run](#previous-result) instead.\n| Parameter name      | Type | Definition                  |\n|:-----------------------------------|:-------|:---------------------------------------------------------------------------------|\n| stage_1_tuning_result_artifact_uri | String | (Optional) URI of the hyperparameter tuning result from a previous pipeline run. |\n## What's next\n- Learn about [batch predictions](/vertex-ai/docs/tabular-data/tabular-workflows/forecasting-batch-predictions) for forecasting models.\n- Learn about [pricing for model training](/vertex-ai/docs/tabular-data/tabular-workflows/pricing) .", "guide": "Vertex AI"}