{"title": "Vertex AI - Streaming import", "url": "https://cloud.google.com/vertex-ai/docs/featurestore/ingesting-stream", "abstract": "# Vertex AI - Streaming import\nTo learn more,  run the \"Example Feature Store workflow with sample data\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ffeature_store%2Fsdk-feature-store.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store.ipynb)\nStreaming import lets you make real-time updates to feature values. This method is useful when having the latest available data for online serving is a priority. For example, you can import streaming event data and, within a few seconds, Vertex AI Feature Store (Legacy) makes that data available for online serving scenarios.\nIf you must backfill data or if you compute feature values in batch, use [batchimport](/vertex-ai/docs/featurestore/ingesting-batch) . Compared to streaming import requests, [batchimport](/vertex-ai/docs/featurestore/ingesting-batch) requests can handle larger payloads but take longer to complete.\nFor information about the oldest feature value timestamp that you can import, see [Vertex AI Feature Store (Legacy)](/vertex-ai/docs/quotas#featurestore) in [Quotas and limits](/vertex-ai/docs/quotas) . You can't import feature values for which the timestamps indicate future dates or times.\n", "content": "## Example use case\nAn online retail organization might provide a personalized shopping experience by using the current activity of a user. As users navigate through the website, you can capture their activity into a featurestore and then, soon after, serve all that information for online predictions. This real-time import and serving can help you show useful and relevant recommendations to customers during their shopping session.\n## Online storage node usage\nWriting feature values to an online store uses the featurestore's CPU resources (online storage nodes). [Monitor](/vertex-ai/docs/featurestore/monitoring#featurestore) your CPU usage to check that demand doesn't exceed supply, which can lead to serving errors. We recommend around a 70% usage rate or lower to avoid these errors. If you regularly exceed that value, you can update your featurestore to increase the number of nodes or use autoscaling. For more information, see [Managefeaturestores](/vertex-ai/docs/featurestore/managing-featurestores) .\n## Streaming import\nWrite a value to a particular feature. The feature value must be included as part of the import request. You can't stream data directly from a data source.\nIf you're writing to recently created features, wait a few minutes before you do so because the new features might not have propagated yet. If you don't, you might see a `resource not found` error.\nYou can import feature values for only one entity per write. For any specific project and region, you can simultaneously write feature values for multiple entities within a maximum of ten different entity types. This limit includes streaming import requests to all featurestores in a given project and region. If you exceed this limit, Vertex AI Feature Store (Legacy) might not write all of your data to the offline store. If this occurs, Vertex AI Feature Store (Legacy) logs the error in the **Logs Explorer** . For more information, see [Monitor offline storage write errors for streaming import](/vertex-ai/docs/featurestore/monitoring#monitor_offline_storage_write_errors) .\nTo import feature values for existing features, send a POST request by using the [featurestores.entityTypes.writeFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/writeFeatureValues) method. If the names of the source data columns and the destination feature IDs are different, include the `sourceField` parameter. Note that [featurestores.entityTypes.writeFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes/writeFeatureValues) lets you import feature values for only one entity at a time.\nBefore using any of the request data, make the following replacements:- : Region where the featurestore is created. For example,`us-central1`.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : ID of the featurestore.\n- : ID of the entity type.\n- : ID of an existing feature in the featurestore to  write values for.\n- : The [value  type](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores.entityTypes.features#ValueType) of the feature.\n- : Value for the feature.\n- (optional): The time at which the feature was  generated. The timestamp must be in the RFC3339 UTC format.\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/featurestores/FEATURESTORE_ID/entityTypes/ENTITY_TYPE_ID:writeFeatureValues\n```\nRequest JSON body:\n```\n{\n \"payloads\": [ {\n  \"entityId\": \"ENTITY_ID\",\n  \"featureValues\": {\n  \"FEATURE_ID\": {\n   \"VALUE_TYPE\": VALUE,\n   \"metadata\": {\"generate_time\": \"TIME_STAMP\"}\n  }\n  }\n }\n ]\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/featurestores/FEATURESTORE_ID/entityTypes/ENTITY_TYPE_ID:writeFeatureValues\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/featurestores/FEATURESTORE_ID/entityTypes/ENTITY_TYPE_ID:writeFeatureValues\" | Select-Object -Expand Content\n```\nYou should receive a successful status code (2xx) and an empty response.To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/write_feature_values_sample.py) \n```\nfrom google.cloud import aiplatformdef write_feature_values_sample(\u00a0 \u00a0 project: str, location: str, entity_type_id: str, featurestore_id: str):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 my_entity_type = aiplatform.featurestore.EntityType(\u00a0 \u00a0 \u00a0 \u00a0 entity_type_name=entity_type_id, featurestore_id=featurestore_id\u00a0 \u00a0 )\u00a0 \u00a0 my_data = {\u00a0 \u00a0 \u00a0 \u00a0 \"movie_01\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"title\": \"The Shawshank Redemption\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"average_rating\": 4.7,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"genre\": \"Drama\",\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 }\u00a0 \u00a0 my_entity_type.write_feature_values(instances=my_data)\n```You can [install](/vertex-ai/docs/start/client-libraries) and use the following Vertex AI client libraries to call the Vertex AI API. Cloud Client Libraries provide an optimized developer experience by using the natural conventions and styles of each supported language.- [Java](/java/docs/reference/google-cloud-aiplatform/latest/overview) \n- [Node.js](/nodejs/docs/reference/aiplatform/latest) \n## What's next\n- Learn how to [monitor offline storage write errors for streaming import](/vertex-ai/docs/featurestore/monitoring#monitor_offline_storage_write_errors) .\n- Learn how to serve features through [onlineserving](/vertex-ai/docs/featurestore/serving-online) or [batchserving](/vertex-ai/docs/featurestore/serving-batch) .\n- [Troubleshoot](/vertex-ai/docs/general/troubleshooting#feature-store) common Vertex AI Feature Store (Legacy) issues.", "guide": "Vertex AI"}