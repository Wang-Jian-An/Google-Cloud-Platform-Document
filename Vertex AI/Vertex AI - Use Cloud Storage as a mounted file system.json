{"title": "Vertex AI - Use Cloud Storage as a mounted file system", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Use Cloud Storage as a mounted file system\n[Cloud Storage FUSE](/storage/docs/gcs-fuse)- Training data is streamed to your training job instead of downloaded to replicas, which can make data loading and setup tasks faster when the job starts running.\n- Training jobs can handle input and output at scale without making API calls, handling responses, or integrating with client-side libraries.\n- Cloud Storage FUSE provides high throughput for large file sequential reads and in distributed training scenarios.", "content": "## Use cases\nWe recommend using Cloud Storage for storing training data in the following situations:\n- Your training data is unstructured data, such as image, text, and video.\n- Your training data is structured data in a format such as TFRecord.\n- Your training data contains large files, such as raw video.\n- You use distributed training.## How it works\nCustom training jobs can access your Cloud Storage buckets as subdirectories of the root `/gcs` directory. For example, if your training data is located at `gs://example-bucket/data.csv` , you can read and write to the bucket from your Python training application as follows:\n**Read to the bucket**\n```\nwith open('/gcs/example-bucket/data.csv', 'r') as f:\u00a0 lines = f.readlines()\n```\n**Write to the bucket**\n```\nwith open('/gcs/example-bucket/epoch3.log', 'a') as f:\u00a0 f.write('success!\\n')\n```\n## Bucket access permissions\nBy default, a custom training job can access any Cloud Storage bucket within the same Google Cloud project by using the [Vertex AI Custom Code Service Agent](/vertex-ai/docs/general/access-control#service-agents) . To control access to buckets, you can assign a [custom service account](/vertex-ai/docs/general/custom-service-account) to the job. In this case, access to a Cloud Storage bucket is granted based on the permissions associated with the Cloud Storage roles of the custom service account.\nFor example, if you want to give the custom training job read and write access to Bucket-A but only read access to Bucket-B, you can assign a custom service account that has the following roles to the job:\n- `roles/storage.objectAdmin`for Bucket-A\n- `roles/storage.objectViewer`for Bucket-B\nIf the training job attempts to write to Bucket-B, a \"permission denied\" error is returned.\nFor more information on Cloud Storage roles, see [IAM roles for Cloud Storage](/storage/docs/access-control/iam-roles) .\n## Best practices\n- Avoid renaming directories. A renaming operation is not atomic in Cloud Storage FUSE. If the operation is interrupted, some files remain in the old directory.\n- Avoid unnecessarily closing (`close()`) or flushing files (`flush()`). Closing or flushing files pushes the file to Cloud Storage, which incurs a cost.\n### Performance optimization guidelines\nTo get optimal read throughput when using Cloud Storage as a file system, we recommend implementing the following guidelines:\n- To reduce the latency introduced by looking up and opening objects in a bucket, store data in larger and fewer files.\n- Use parallel training to maximize bandwidth utilization.\n- Cache frequently accessed files to improve read performance.## Limitations\nTo learn about the limitations of Cloud Storage FUSE, including the differences between Cloud Storage FUSE and POSIX file systems, see [Differences from other file systems](/storage/docs/gcs-fuse#differences-and-limitations) .\n## Load data to Cloud Storage\nTo learn about options for transferring data to Cloud Storage, see [Data transfer options](/storage-transfer/docs/transfer-options) .\n## What's next\n- [Learn about Cloud Storage FUSE pricing](https://cloud.google.com/storage/docs/gcs-fuse#charges) .\n- [Prepare your training application](/vertex-ai/docs/training/code-requirements) for use on Vertex AI.", "guide": "Vertex AI"}