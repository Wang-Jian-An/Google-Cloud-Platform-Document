{"title": "Vertex AI - Train a model with End-to-End AutoML", "url": "https://cloud.google.com/vertex-ai/docs/tabular-data/tabular-workflows/e2e-automl-train", "abstract": "# Vertex AI - Train a model with End-to-End AutoML\nTo see an example of how to train a model with End-to-End AutoML,  run the \"AutoML Tabular Workflow pipelines\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_tabular_on_vertex_pipelines.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fautoml%2Fautoml_tabular_on_vertex_pipelines.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/automl_tabular_on_vertex_pipelines.ipynb)\nThis page shows you how to train a classification or regression model from a tabular dataset with Tabular Workflow for End-to-End AutoML.\n", "content": "## Before you begin\nBefore you can train a model, you must complete the following:\n- [Prepare your training data](/vertex-ai/docs/tabular-data/classification-regression/prepare-data) \n- [Create a Vertex AI dataset](/vertex-ai/docs/tabular-data/classification-regression/create-dataset) .\n- Enable the following APIs: Vertex AI, Dataflow, Compute Engine, Cloud Storage. [Enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,dataflow.googleapis.com,compute_component,storage-component.googleapis.com) \n- Make sure that your project's service accounts have the [necessary roles](/vertex-ai/docs/tabular-data/tabular-workflows/service-accounts) assigned to them. To view the service accounts and their associated roles, go to the **IAM** page and check the \"Include Google-provided role grants\" checkbox. [Go to IAM](https://console.cloud.google.com/iam-admin/iam) \nIf you receive an error related to quotas while running Tabular Workflow for End-to-End AutoML, you might need to request a higher quota. To learn more, see [Manage quotas for Tabular Workflows](/vertex-ai/docs/tabular-data/tabular-workflows/quotas) .\n## Get the URI of the previous hyperparameter tuning result\nIf you have previously completed an End-to-End AutoML workflow run, you can use the hyperparameter tuning result from the previous run to save training time and resources. You can find the previous hyperparameter tuning result by using the Google Cloud console or by loading it programmatically with the API.\nTo find the hyperparameter tuning result URI by using the Google Cloud console, perform the following steps:- In the Google Cloud console, in the Vertex AI section, go to the **Pipelines** page. [Go to the Pipelines page](https://console.cloud.google.com/vertex-ai/pipelines) \n- Select the **Runs** tab.\n- Select the pipeline run you want to use.\n- Select **Expand Artifacts** .\n- Click on component **exit-handler-1** .\n- Click on component **stage_1_tuning_result_artifact_uri_empty** .\n- Find component **automl-tabular-cv-trainer-2** .\n- Click on the associated artifact **tuning_result_output** .\n- Select the **Node Info** tab.\n- Copy the URI for use in the [Train a model](#train-model) step.\nThe following sample code demonstrates how you can load the hyperparameter tuning result by using the API. The variable `job` refers to the previous model training pipeline run.\n```\ndef get_task_detail(\u00a0 task_details: List[Dict[str, Any]], task_name: str) -> List[Dict[str, Any]]:\u00a0 for task_detail in task_details:\u00a0 \u00a0 \u00a0 if task_detail.task_name == task_name:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return task_detailpipeline_task_details = job.gca_resource.job_detail.task_detailsstage_1_tuner_task = get_task_detail(\u00a0 \u00a0 pipeline_task_details, \"automl-tabular-stage-1-tuner\")stage_1_tuning_result_artifact_uri = (\u00a0 \u00a0 stage_1_tuner_task.outputs[\"tuning_result_output\"].artifacts[0].uri)\n```\n## Train a model\nTo train a model by using the Google Cloud console, perform the following steps:- In the Google Cloud console, in the Vertex AI section, go to the **Pipelines** page. [Go to the Pipelines page](https://console.cloud.google.com/vertex-ai/pipelines) \n- Select the **Template Gallery** tab.\n- In the **AutoML for Tabular Classification / Regression** card, click **Create run** .\n- In the **Run details** page, configure as follows:- Enter a pipeline run name.\n- **Optional:** If you want to set the **Vertex AI Pipelines service account** or the **Dataflow worker service account** , open the **Advanced options** . [Learn more](#service-accounts) about service accounts.\n- Click **Continue** .\n- In the **Runtime configuration** page, configure as follows:- Enter a Cloud Storage bucket or a folder within the bucket to use as the root output  directory. This directory will be used to save intermediate files, such as the  materialized dataset and the model. Remember to clean up the directory after training is  complete and the model and other important artifacts are copied to another Cloud Storage bucket.  Alternately, set a [Time to Live (TTL)](/storage/docs/lifecycle) for the  Cloud Storage bucket.The buckets for your project are listed in the Cloud Storage section of Google Cloud console. [Go to the Buckets page](https://console.cloud.google.com/storage/browser) \n- Click **Continue** .\n- In the **Training method** page, configure as follows:- Select the name of the dataset you want to use to train your model.\n- Select your target column. The target column is the value that the model will predict.  Learn more about [target column requirements](/vertex-ai/docs/tabular-data/classification-regression/prepare-data#data-structure) .\n- Enter the display name for your new model.\n- **Optional** : To choose how to split the data between training, test, and  validation sets, open the **Advanced options** . You can choose between the  following data split options:- **Random** (Default): Vertex AI randomly selects the rows associated with   each of the data sets. By default, Vertex AI selects 80% of your data rows for   the training set, 10% for the validation set, and 10% for the test set. Set the percentage   of data rows that you want to be associated with each of the data sets.\n- **Manual** : Vertex AI selects data rows for each of the data sets based on   the values in a data split column. Provide the name of the data split column.\n- **Chronological** : Vertex AI splits data based on the timestamp in a time   column. Provide the name of the time column. You can also set the percentage of data rows   that you want to be associated with the training set, the validation set, and the test set.\n- **Stratified** : Vertex AI randomly selects the rows associated with   each of the data sets, but preserves the distribution of target column values. Provide the   name of the target column. You can also set the percentage of data rows that you want to be   associated with the training set, the validation set, and the test set.\nLearn more about [data splits](/vertex-ai/docs/tabular-data/classification-regression/prepare-data#split) .\n- **Optional:** You can run the pipeline without the architecture search. If you choose **Skip architecture search** , you will be prompted to provide a set of hyperparameters from a  previous pipeline run in the **Training options** page.\n- Click **Continue** .\n- In the **Training options** page, configure as follows:- **Optional:** Click **Generate statistics** . Generating statistics populates the **Transformation** dropdown menus.\n- Review your column list and exclude any columns from training that should not be used to train  the model.\n- Review the transformations selected for your included features, along with whether invalid  data is allowed, and make any required updates. Learn more about [transformations](/vertex-ai/docs/datasets/data-types-tabular#transformations) and [invalid data](/vertex-ai/docs/datasets/data-types-tabular#null-values) .\n- If you chose to skip the architecture search in the **Training method** page, provide  the path to the [hyperparameter tuning result](/vertex-ai/docs/tabular-data/tabular-workflows/e2e-automl-train#previous-result) from a previous pipeline run.\n- **Optional:** If you want to specify the weight column, open the **Advanced options** and make your selection. Learn more about [weight columns](/vertex-ai/docs/tabular-data/classification-regression/prepare-data#weight) .\n- **Optional:** If you want to change your optimization objective from the default,  open the **Advanced options** and make your selection. Learn more about [optimization objectives](#optimization-objectives) .\n- **Optional:** If you choose to perform the architecture search in the **Training method** page, you can specify the number of parallel trials. Open the **Advanced options** and enter  your value.\n- **Optional:** You can provide fixed values for a subset of the hyperparameters.  Vertex AI searches for the optimal values of the remaining unfixed hyperparameters.  This option is a good choice if you have a strong preference for the model type. You can choose  between neural networks and boosted trees for your model type. Open the **Advanced options** and provide a study spec override in JSON format.For example, if you want to set the model type  to Neural Networks (NN), enter the following: ```\n[ {\n \"parameter_id\": \"model_type\",\n \"categorical_value_spec\": {\n  \"values\": [\"nn\"]\n }\n }\n]\n```\n- Click **Continue** .\n- In the **Compute and pricing** page, configure as follows:- Enter the maximum number of hours you want your model to train for. Learn more about [pricing](/vertex-ai/docs/tabular-data/tabular-workflows/pricing) .\n- **Optional:** In the **Compute Settings** section, you can configure the machine types  and the number of machines for each stage of the workflow. This option is a good choice if you  have a large dataset and want to optimize the machine hardware accordingly.\n- Click **Submit** .\nThe following sample code demonstrates how you can run a model training pipeline:\n```\njob = aiplatform.PipelineJob(\u00a0 \u00a0 ...\u00a0 \u00a0 template_path=template_path,\u00a0 \u00a0 parameter_values=parameter_values,\u00a0 \u00a0 ...)job.run(service_account=SERVICE_ACCOUNT)\n```\nThe optional `service_account` parameter in `job.run()` lets you set the Vertex AI Pipelines service account to an account of your choice.\nThe pipeline and the parameter values are defined by the following function. The training data can be either a CSV file in Cloud Storage or a table in BigQuery.\n```\ntemplate_path, parameter_values = automl_tabular_utils.get_automl_tabular_pipeline_and_parameters(...)\n```\nThe following is a subset of `get_automl_tabular_pipeline_and_parameters` parameters:\n| Parameter name     | Type  | Definition                                                                                |\n|:--------------------------------|:------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| data_source_csv_filenames  | String  | A URI for a CSV stored in Cloud Storage.                                                                         |\n| data_source_bigquery_table_path | String  | A URI for a BigQuery table.                                                                            |\n| dataflow_service_account  | String  | (Optional) Custom service account to run Dataflow jobs. The Dataflow job can be configured to use private IPs and a specific VPC subnet. This parameter acts as an override for the default Dataflow worker service account.                            |\n| prediction_type     | String  | Choose classification to train a classification model or regression to train a regression model.                                                           |\n| optimization_objective   | String  | If you are training a binary classification model, the default objective is AUC ROC. If you are training a regression model, the default objective is RMSE. If you want a different optimization objective for your model, choose one of the options in Optimization objectives for classification or regression models.     |\n| enable_probabilistic_inference | Boolean  | If you are training a regression model and you set this value to true, Vertex AI models the probability distribution of the prediction. Probabilistic inference can improve model quality by handling noisy data and quantifying uncertainty. If quantiles are specified, then Vertex AI also returns the quantiles of the distribution. |\n| quantiles      | List[float] | Quantiles to use for probabilistic inference. A quantile indicates the likelihood that a target is less than a given value. Provide a list of up to five unique numbers between 0 and 1, exclusive.                                  |\n **Workflow customization options** \nYou can customize the End-to-End AutoML workflow by defining argument values that are passed in during pipeline definition. You can customize your workflow in the following ways:- Override search space\n- Configure hardware\n- Distill the model\n- Skip architecture search\n **Override search space** \nThe following `get_automl_tabular_pipeline_and_parameters` parameter lets you provide fixed values for a subset of the hyperparameters. Vertex AI searches for the optimal values of the remaining unfixed hyperparameters. Use this parameter if you want to choose between neural networks and boosted trees for your model type.\n| Parameter name     | Type     | Definition                               |\n|:-------------------------------|:------------------------|:-----------------------------------------------------------------------------------------------------------------------------------|\n| study_spec_parameters_override | List[Dict[String, Any]] | (Optional) Custom subset of hyperparameters. This parameter configures the automl-tabular-stage-1-tuner component of the pipeline. |\nThe following code demonstrates how to set the model type to Neural Networks (NN):\n```\nstudy_spec_parameters_override = [\u00a0 {\u00a0 \u00a0 \"parameter_id\": \"model_type\",\u00a0 \u00a0 \"categorical_value_spec\": {\u00a0 \u00a0 \u00a0 \"values\": [\"nn\"] # The default value is [\"nn\", \"boosted_trees\"], this reduces the search space\u00a0 \u00a0 }\u00a0 }]\n```\n **Configure hardware** \nThe following `get_automl_tabular_pipeline_and_parameters` parameters lets you configure the machine types and the number of machines for training. This option is a good choice if you have a large dataset and want to optimize the machine hardware accordingly.\n| Parameter name       | Type    | Definition                                           |\n|:-----------------------------------------|:------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| stage_1_tuner_worker_pool_specs_override | Dict[String, Any] | (Optional) Custom configuration of the machine types and the number of machines for training. This parameter configures the automl-tabular-stage-1-tuner component of the pipeline. |\n| cv_trainer_worker_pool_specs_override | Dict[String, Any] | (Optional) Custom configuration of the machine types and the number of machines for training. This parameter configures the automl-tabular-stage-1-tuner component of the pipeline. |\nThe following code demonstrates how to set `n1-standard-8` machine type for the TensorFlow chief node and `n1-standard-4` machine type for the TensorFlow evaluator node:\n```\nworker_pool_specs_override = [\u00a0 {\"machine_spec\": {\"machine_type\": \"n1-standard-8\"}}, # override for TF chief node\u00a0 {}, \u00a0# override for TF worker node, since it's not used, leave it empty\u00a0 {}, \u00a0# override for TF ps node, since it's not used, leave it empty\u00a0 {\u00a0 \u00a0 \"machine_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \"machine_type\": \"n1-standard-4\" # override for TF evaluator node\u00a0 \u00a0 }\u00a0 }]\n```\n **Distill the model** \nThe following `get_automl_tabular_pipeline_and_parameters` parameter lets you create a smaller version of the ensemble model. A smaller model reduces latency and cost for prediction.\n| Parameter name | Type | Definition            |\n|:-----------------|:--------|:----------------------------------------------------------|\n| run_distillation | Boolean | If TRUE, creates a smaller version of the ensemble model. |\n **Skip architecture search** \nThe following `get_automl_tabular_pipeline_and_parameters` parameter lets you run the pipeline without the architecture search and provide a set of [hyperparameters from a previous pipeline run](/vertex-ai/docs/tabular-data/tabular-workflows/e2e-automl-train#previous-result) instead.\n| Parameter name      | Type | Definition                  |\n|:-----------------------------------|:-------|:---------------------------------------------------------------------------------|\n| stage_1_tuning_result_artifact_uri | String | (Optional) URI of the hyperparameter tuning result from a previous pipeline run. |\n## Optimization objectives for classification or regression models\nWhen you train a model, Vertex AI selects a default optimization objective based on your model type and the data type used for your target column.\n| Optimization objective | API value     | Use this objective if you want to...                            |\n|:-------------------------|:-----------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------|\n| AUC ROC     | maximize-au-roc    | Maximize the area under the receiver operating characteristic (ROC) curve. Distinguishes between classes. Default value for binary classification. |\n| Log loss     | minimize-log-loss   | Keep prediction probabilities as accurate as possible. Only supported objective for multi-class classification.         |\n| AUC PR     | maximize-au-prc    | Maximize the area under the precision-recall curve. Optimizes results for predictions for the less common class.         |\n| Precision at Recall  | maximize-precision-at-recall | Optimize precision at a specific recall value.                          |\n| Recall at Precision  | maximize-recall-at-precision | Optimize recall at a specific precision value.                          |\n| Optimization objective | API value  | Use this objective if you want to...                                  |\n|:-------------------------|:---------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| RMSE      | minimize-rmse | Minimize root-mean-squared error (RMSE). Captures more extreme values accurately. Default value.                   |\n| MAE      | minimize-mae | Minimize mean-absolute error (MAE). Views extreme values as outliers with less impact on model.                    |\n| RMSLE     | minimize-rmsle | Minimize root-mean-squared log error (RMSLE). Penalizes error on relative size rather than absolute value. Useful when both predicted and actual values can be quite large. |\n## What's next\n- Learn about [online predictions](/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions) for classification and regression models.\n- Learn about [batch predictions](/vertex-ai/docs/tabular-data/classification-regression/get-batch-predictions) for classification and regression models.\n- Learn about [pricing for model training](/vertex-ai/docs/tabular-data/tabular-workflows/pricing) .", "guide": "Vertex AI"}