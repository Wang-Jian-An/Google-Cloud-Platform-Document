{"title": "Vertex AI - Configure container settings for custom training", "url": "https://cloud.google.com/vertex-ai/docs/training/configure-container-settings", "abstract": "# Vertex AI - Configure container settings for custom training\nWhen you perform custom training, you must specify what machine learning (ML) code you want Vertex AI to run. To do this, configure training container settings for either a [custom container](/vertex-ai/docs/training/create-custom-container) or a [Python training application that runs on a prebuiltcontainer](/vertex-ai/docs/training/create-python-pre-built-container) .\nTo determine whether you want to use a custom container or a prebuilt container, read [Training code requirements](/vertex-ai/docs/training/code-requirements) .\nThis document describes the fields of the Vertex AI API that you must specify in either of the preceding cases.\n", "content": "## Where to specify container settings\nSpecify configuration details within a [WorkerPoolSpec](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#workerpoolspec) . Depending on how you perform custom training, put this `WorkerPoolSpec` in one of the following API fields:\n- **If you are creating a CustomJobresource,** specify the `WorkerPoolSpec` in `CustomJob.jobSpec.workerPoolSpecs` .If you are using the Google Cloud CLI, then you can use the `--worker-pool-spec` flag or the `--config` flag on the [gcloud ai custom-jobs createcommand](/sdk/gcloud/reference/ai/custom-jobs/create) to specify worker pool options.Learn more about [creating a CustomJob](/vertex-ai/docs/training/create-custom-job) .\n- **If you are creating a HyperparameterTuningJobresource,** specify the `WorkerPoolSpec` in `HyperparameterTuningJob.trialJobSpec.workerPoolSpecs` .If you are using the gcloud CLI, then you can use the `--config` flag on the [gcloud ai hpt-tuning-jobs createcommand](/sdk/gcloud/reference/ai/hp-tuning-jobs/create) to specify worker pool options.Learn more about [creating aHyperparameterTuningJob](/vertex-ai/docs/training/using-hyperparameter-tuning) .\n- **If you are creating a TrainingPipelineresource withouthyperparameter tuning,** specify the `WorkerPoolSpec` in `TrainingPipeline.trainingTaskInputs.workerPoolSpecs` .Learn more about [creating a customTrainingPipeline](/vertex-ai/docs/training/create-training-pipeline) .\n- **If you are creating a TrainingPipeline with hyperparameter tuning** , specify the `WorkerPoolSpec` in `TrainingPipeline.trainingTaskInputs.trialJobSpec.workerPoolSpecs` .\nIf you are performing [distributedtraining](/vertex-ai/docs/training/code-requirements#distributed) , you can use different settings for each worker pool.\n## Configure container settings\nDepending on whether you are using a prebuilt container or a custom container, you must specify different fields within the `WorkerPoolSpec` . Select the tab for your scenario:\n- Select a [prebuilt container](/vertex-ai/docs/training/pre-built-containers) that supports the ML framework you plan to use for training. Specify one of the container image's URIs in the [pythonPackageSpec.executorImageUrifield](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#PythonPackageSpec.FIELDS.executor_image_uri) .\n- Specify the Cloud Storage URIs of your [Python trainingapplication](/vertex-ai/docs/training/create-python-pre-built-container) in the [pythonPackageSpec.packageUrisfield](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#PythonPackageSpec.FIELDS.package_uris) .\n- Specify your training application's entry point module in the [pythonPackageSpec.pythonModulefield](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#PythonPackageSpec.FIELDS.python_module) .\n- Optionally, specify a list of command-line arguments to pass to your training application's entry point module in the [pythonPackageSpec.argsfield](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#PythonPackageSpec.FIELDS.args) .\nThe following examples highlight where you specify these container settings when you create a `CustomJob` :In the Google Cloud console, you can't create a `CustomJob` directly. However, you can [create a TrainingPipeline that creates aCustomJob](/vertex-ai/docs/training/create-custom-job#create) . When you create a `TrainingPipeline` in the Google Cloud console, you can specify prebuilt container settings in certain fields on the **Training container** step:- `pythonPackageSpec.executorImageUri` : Use the **Model framework** and **Model framework version** drop-down lists.\n- `pythonPackageSpec.packageUris` : Use the **Package location** field.\n- `pythonPackageSpec.pythonModule` : Use the **Python module** field.\n- `pythonPackageSpec.args` : Use the **Arguments** field.\n```\ngcloud ai custom-jobs create \\\u00a0 --region=LOCATION \\\u00a0 --display-name=JOB_NAME \\\u00a0 --python-package-uris=PYTHON_PACKAGE_URIS \\\u00a0 --worker-pool-spec=machine-type=MACHINE_TYPE,replica-count=REPLICA_COUNT,executor-image-uri=PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,python-module=PYTHON_MODULE\n```\nFor more context, read the [guide to creating aCustomJob](/vertex-ai/docs/training/create-custom-job) .- Specify the Artifact Registry or Docker Hub URI of your [custom container](/vertex-ai/docs/training/create-custom-container) in the [containerSpec.imageUrifield](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#ContainerSpec.FIELDS.image_uri) .\n- Optionally, if you want to override the [ENTRYPOINT](https://docs.docker.com/engine/reference/builder/#entrypoint) or [CMD](https://docs.docker.com/engine/reference/builder/#cmd) instructions in your container, specify the [containerSpec.command orcontainerSpec.args fields](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#containerspec) . These fields affect how your container runs according to the following rules:- **If you specify neither field:** Your container runs according to its `ENTRYPOINT` instruction and `CMD` instruction (if it exists). Refer to the [Docker documentation about how CMD and ENTRYPOINTinteract](https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact) .\n- **If you specify only containerSpec.command:** Your container runs with the value of `containerSpec.command` replacing its `ENTRYPOINT` instruction. If the container has a `CMD` instruction, it is ignored.\n- **If you specify only containerSpec.args:** Your container runs according to its `ENTRYPOINT` instruction, with the value of `containerSpec.args` replacing its `CMD` instruction.\n- **If you specify both fields:** Your container runs with `containerSpec.command` replacing its `ENTRYPOINT` instruction and `containerSpec.args` replacing its `CMD` instruction.\nThe following example highlights where you can specify some of these container settings when you create a `CustomJob` :In the Google Cloud console, you can't create a `CustomJob` directly. However, you can [create a TrainingPipeline that creates aCustomJob](/vertex-ai/docs/training/create-custom-job#create) . When you create a `TrainingPipeline` in the Google Cloud console, you can specify custom container settings in certain fields on the **Training container** step:- `containerSpec.imageUri` : Use the **Container image** field.\n- `containerSpec.command` : This API field is not configurable in the Google Cloud console.\n- `containerSpec.args` : Use the **Arguments** field.\n```\ngcloud ai custom-jobs create \\\u00a0 --region=LOCATION \\\u00a0 --display-name=JOB_NAME \\\u00a0 --worker-pool-spec=machine-type=MACHINE_TYPE,replica-count=REPLICA_COUNT,container-image-uri=CUSTOM_CONTAINER_IMAGE_URI\n```Before trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/CreateCustomJobSample.java) \n```\nimport com.google.cloud.aiplatform.v1.AcceleratorType;import com.google.cloud.aiplatform.v1.ContainerSpec;import com.google.cloud.aiplatform.v1.CustomJob;import com.google.cloud.aiplatform.v1.CustomJobSpec;import com.google.cloud.aiplatform.v1.JobServiceClient;import com.google.cloud.aiplatform.v1.JobServiceSettings;import com.google.cloud.aiplatform.v1.LocationName;import com.google.cloud.aiplatform.v1.MachineSpec;import com.google.cloud.aiplatform.v1.WorkerPoolSpec;import java.io.IOException;// Create a custom job to run machine learning training code in Vertex AIpublic class CreateCustomJobSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String project = \"PROJECT\";\u00a0 \u00a0 String displayName = \"DISPLAY_NAME\";\u00a0 \u00a0 // Vertex AI runs your training application in a Docker container image. A Docker container\u00a0 \u00a0 // image is a self-contained software package that includes code and all dependencies. Learn\u00a0 \u00a0 // more about preparing your training application at\u00a0 \u00a0 // https://cloud.google.com/vertex-ai/docs/training/overview#prepare_your_training_application\u00a0 \u00a0 String containerImageUri = \"CONTAINER_IMAGE_URI\";\u00a0 \u00a0 createCustomJobSample(project, displayName, containerImageUri);\u00a0 }\u00a0 static void createCustomJobSample(String project, String displayName, String containerImageUri)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 JobServiceSettings settings =\u00a0 \u00a0 \u00a0 \u00a0 JobServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests.\u00a0 \u00a0 try (JobServiceClient client = JobServiceClient.create(settings)) {\u00a0 \u00a0 \u00a0 MachineSpec machineSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MachineSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMachineType(\"n1-standard-4\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setAcceleratorType(AcceleratorType.NVIDIA_TESLA_K80)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setAcceleratorCount(1)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 ContainerSpec containerSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ContainerSpec.newBuilder().setImageUri(containerImageUri).build();\u00a0 \u00a0 \u00a0 WorkerPoolSpec workerPoolSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 WorkerPoolSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMachineSpec(machineSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setReplicaCount(1)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setContainerSpec(containerSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 CustomJobSpec customJobSpecJobSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 CustomJobSpec.newBuilder().addWorkerPoolSpecs(workerPoolSpec).build();\u00a0 \u00a0 \u00a0 CustomJob customJob =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 CustomJob.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDisplayName(displayName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setJobSpec(customJobSpecJobSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 LocationName parent = LocationName.of(project, location);\u00a0 \u00a0 \u00a0 CustomJob response = client.createCustomJob(parent, customJob);\u00a0 \u00a0 \u00a0 System.out.format(\"response: %s\\n\", response);\u00a0 \u00a0 \u00a0 System.out.format(\"Name: %s\\n\", response.getName());\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/create-custom-job.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\\\u00a0* (Not necessary if passing values as arguments)\u00a0*/// const customJobDisplayName = 'YOUR_CUSTOM_JOB_DISPLAY_NAME';// const containerImageUri = 'YOUR_CONTAINER_IMAGE_URI';// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';// Imports the Google Cloud Job Service Client libraryconst {JobServiceClient} = require('@google-cloud/aiplatform');// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};// Instantiates a clientconst jobServiceClient = new JobServiceClient(clientOptions);async function createCustomJob() {\u00a0 // Configure the parent resource\u00a0 const parent = `projects/${project}/locations/${location}`;\u00a0 const customJob = {\u00a0 \u00a0 displayName: customJobDisplayName,\u00a0 \u00a0 jobSpec: {\u00a0 \u00a0 \u00a0 workerPoolSpecs: [\u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 machineSpec: {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 machineType: 'n1-standard-4',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 acceleratorType: 'NVIDIA_TESLA_K80',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 acceleratorCount: 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 replicaCount: 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 containerSpec: {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 imageUri: containerImageUri,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 command: [],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 args: [],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 ],\u00a0 \u00a0 },\u00a0 };\u00a0 const request = {parent, customJob};\u00a0 // Create custom job request\u00a0 const [response] = await jobServiceClient.createCustomJob(request);\u00a0 console.log('Create custom job response:\\n', JSON.stringify(response));}createCustomJob();\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/snippets/job_service/create_custom_job_sample.py) \n```\nfrom google.cloud import aiplatformdef create_custom_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 container_image_uri: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",):\u00a0 \u00a0 # The AI Platform services require regional API endpoints.\u00a0 \u00a0 client_options = {\"api_endpoint\": api_endpoint}\u00a0 \u00a0 # Initialize client that will be used to create and send requests.\u00a0 \u00a0 # This client only needs to be created once, and can be reused for multiple requests.\u00a0 \u00a0 client = aiplatform.gapic.JobServiceClient(client_options=client_options)\u00a0 \u00a0 custom_job = {\u00a0 \u00a0 \u00a0 \u00a0 \"display_name\": display_name,\u00a0 \u00a0 \u00a0 \u00a0 \"job_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"worker_pool_specs\": [\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"machine_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"machine_type\": \"n1-standard-4\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_type\": aiplatform.gapic.AcceleratorType.NVIDIA_TESLA_K80,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"replica_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"container_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"image_uri\": container_image_uri,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"command\": [],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"args\": [],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ]\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 }\u00a0 \u00a0 parent = f\"projects/{project}/locations/{location}\"\u00a0 \u00a0 response = client.create_custom_job(parent=parent, custom_job=custom_job)\u00a0 \u00a0 print(\"response:\", response)\n```\nFor more context, read the [guide to creating aCustomJob](/vertex-ai/docs/training/create-custom-job) .\n## What's next\n- Learn how to perform custom training by [creating aCustomJob](/vertex-ai/docs/training/create-custom-job) .", "guide": "Vertex AI"}