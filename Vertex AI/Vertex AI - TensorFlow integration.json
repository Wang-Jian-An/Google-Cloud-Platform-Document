{"title": "Vertex AI - TensorFlow integration", "url": "https://cloud.google.com/vertex-ai/docs/start/tensorflow", "abstract": "# Vertex AI - TensorFlow integration\nThis page explains Vertex AI's TensorFlow integration and provides resources that show you how to use TensorFlow on Vertex AI. Vertex AI's TensorFlow integration makes it easier for you to train, deploy, and orchestrate TensorFlow models in production.\n", "content": "## Run code in notebooks\nVertex AI provides two options for running your code in notebooks, Colab Enterprise and Vertex AI Workbench. To learn more about these options, see [choose a notebook solution](/vertex-ai/docs/workbench/notebook-solution) .\n## Prebuilt containers for training\nVertex AI provides prebuilt Docker container images for model training. These containers are organized by machine learning frameworks and framework versions and include common dependencies that you might want to use in your training code.\nTo learn about which TensorFlow versions have prebuilt training containers and how to train models with a prebuilt training container, see [Prebuilt containers for custom training](/vertex-ai/docs/training/pre-built-containers#tensorflow) .\n## Distributed training\nYou can run distributed training of TensorFlow models on Vertex AI. For multi-worker training, you can use Reduction Server to optimize performance even further for all-reduce collective operations. To learn more about distributed training on Vertex AI, see [Distributed training](/vertex-ai/docs/training/distributed-training) .\n## Prebuilt containers for predictions\nSimilar to prebuilt containers for training, Vertex AI provides prebuilt container images for serving predictions and explanations from TensorFlow models that you either created within or outside of Vertex AI. These images provide HTTP predictions servers that you can use to serve predictions with minimal configuration.\nTo learn about which TensorFlow versions have prebuilt training containers and how to train models with a prebuilt training container, see [Prebuilt containers for custom training](/vertex-ai/docs/predictions/pre-built-containers#tensorflow) .\n### Optimized TensorFlow runtime\n**    Preview     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nThe [optimized TensorFlow runtime](/vertex-ai/docs/predictions/optimized-tensorflow-runtime) uses model optimizations and new proprietary Google technologies to improve the speed and lower the cost of predictions compared to Vertex AI's standard prebuilt prediction containers for TensorFlow.\n## TensorFlow Profiler integration\nTrain models cheaper and faster by monitoring and optimizing the performance of your training job using Vertex AI's TensorFlow Profiler integration. TensorFlow Profiler helps you understand the resource consumption of training operations so you can identify and eliminate performance bottlenecks.\nTo learn more about Vertex AI TensorFlow Profiler, see [Profile model training performance using Profiler](/vertex-ai/docs/training/tensorboard-profiler) .\n## Resources for using TensorFlow on Vertex AI\nTo learn more and start using TensorFlow in Vertex AI, see the following resources.\n- [Prototype to Production](https://www.youtube.com/playlist?list=PLIivdWyY5sqJAyUJbbsc8ZyGLNT4isnuB) : A video series that provides and end-to-end example of developing and deploying a custom TensorFlow model on Vertex AI.\n- [Optimize training performance with Reduction Server on Vertex AI](/blog/topics/developers-practitioners/optimize-training-performance-reduction-server-vertex-ai) : A blog post on optimizing distributed training on Vertex AI by using Reduction Server.\n- [How to optimize training performance with the TensorFlow Profiler on Vertex AI](/blog/topics/developers-practitioners/how-optimize-training-performance-tensorflow-profiler-vertex-ai) : A blog post that shows you how to identify performance bottlenecks in your training job by using Vertex AI TensorFlow Profiler.\n- [Custom model batch prediction with feature filtering](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/custom_batch_prediction_feature_filter.ipynb) : A notebook tutorial that shows you how to use the Vertex AI SDK for Python to train a custom tabular classification model and perform batch prediction with feature filtering.\n- [Vertex AI Pipelines: Custom training with prebuilt Google Cloud Pipeline Components](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/custom_model_training_and_batch_prediction.ipynb) : A notebook tutorial that shows you how to use Vertex AI Pipelines with prebuilt Google Cloud Pipeline Components for custom training.\n- [Co-host TensorFlow models on the same VM for predictions](https://codelabs.developers.google.com/vertex-cohost-prediction#0) : A codelab that shows you how to use the co-hosting model feature in Vertex AI to host multiple models on the same VM for online predictions.", "guide": "Vertex AI"}