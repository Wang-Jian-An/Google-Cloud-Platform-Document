{"title": "Vertex AI - Monitor feature attribution skew and drift", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Monitor feature attribution skew and drift\nThis page describes how to use Vertex AI Model Monitoring with [Vertex Explainable AI](/vertex-ai/docs/explainable-ai) to detect skew and drift for the feature attributions of categorical and numerical input features.\n", "content": "## Overview of feature attribution-based monitoring\nindicate how much each feature in your model contributed to the predictions for each given instance. When you request predictions, you get predicted values as appropriate for your model. When you request , you get the predictions along with feature attribution information.\nAttribution scores are proportional to the contribution of the feature to a model's prediction. They are typically signed, indicating whether a feature helps push the prediction up or down. Attributions across all features must add up to the model's prediction score.\nBy monitoring feature attributions, Model Monitoring tracks changes in a feature's contributions to a model's predictions over time. A change in a key feature's attribution score often signals that the feature has changed in a way that can impact the accuracy of the model's predictions.\nFor information on how a feature attribution score is calculated, see [Featureattribution methods](/vertex-ai/docs/explainable-ai/overview#feature-attribution-methods) .\n### Feature attribution training-serving skew and prediction drift\nWhen you create a monitoring job for a model with Vertex Explainable AI enabled, Model Monitoring monitors skew or drift for both feature distributions and feature attributions. For information on feature distribution skew and drift, see [Introduction toVertex AI Model Monitoring](/vertex-ai/docs/model-monitoring/overview) .\nFor feature attributions:\n- occurs when a feature's attribution score in production deviates from the feature's attribution score in the original training data.\n- occurs when a feature's attribution score in production changes significantly over time.\nYou can enable skew detection if you provide the original training dataset for your model; otherwise, you should enable drift detection. You can also enable both skew and drift detection.\n## Prerequisites\nTo use Model Monitoring with Vertex Explainable AI, complete the following:\n- If you are enabling skew detection, upload your training data or output of a [batch explanation job](/vertex-ai/docs/explainable-ai/getting-explanations#batch) for your training dataset to [Cloud Storage](/storage/docs/uploading-objects) or [BigQuery](/bigquery/docs/loading-data) . Obtain the URI link to the data. For drift detection, training data or explanation baseline isn't required.\n- Have an available model in Vertex AI that is either a [tabularAutoML](/vertex-ai/docs/start/automl-model-types#tabular) or imported tabular [custom training](/vertex-ai/docs/training/overview) type:- An AutoML tabular model has Vertex Explainable AI automatically configured, so you can skip to [enabling skew or drift detection](#create-model-monitoring-job) . Note that only classification and regression models are supported.\n- An imported custom-trained model must be [configured forVertex Explainable AI](#enable-feature-attribution-skew-or-drift-detection) when you create, import, or deploy the model.\n- [Configure your model](/vertex-ai/docs/explainable-ai/configuring-explanations) to use Vertex Explainable AI when you create, import, or deploy the model. The [ExplanationSpec.ExplanationParameters](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationparameters) field must be populated for your model.\n- Optional: For custom-trained models, upload the [analysis instanceschema](/vertex-ai/docs/model-monitoring/schemas) for your model to Cloud Storage. Model Monitoring requires the schema to begin the monitoring process and calculate the baseline distribution for skew detection. If you don't provide the schema during job creation, the job remains in a pending state until Model Monitoring can automatically parse the schema from the first 1000 prediction requests the model receives.## Enable skew or drift detection\nTo set up either skew detection or drift detection, create a model deployment monitoring job:\nTo create a model deployment monitoring job using the Google Cloud console, create an endpoint:\n **Note:** To enable model monitoring for an existing endpoint, [edit the endpoint'ssettings](/vertex-ai/docs/model-monitoring/using-model-monitoring#update-model-monitoring-job) .\n- In the Google Cloud console, go to the **Vertex AI Endpoints** page. [Go to Endpoints](https://console.cloud.google.com/vertex-ai/endpoints/) \n- Click **Create Endpoint** .\n- In the **New endpoint** pane, name your endpoint and set a region.\n- Click **Continue** .\n- In the **Model name** field, select an imported custom training or tabular AutoML model.\n- In the **Version** field, select a version for your model.\n- Click **Continue** .\n- In the **Model monitoring** pane, make sure **Enable model monitoring forthis endpoint** is toggled on. Any monitoring settings you configure apply to all models deployed to the endpoint.\n- Enter a **Monitoring job display name** .\n- Enter a **Monitoring window length** .\n- For **Notification emails** , enter one or more comma-separated email addresses to receive alerts when a model exceeds an alerting threshold.\n- (Optional) For **Notification channels** , select [Cloud Monitoring](/monitoring/support/notification-options) channels to receive alerts when a model exceeds an alerting threshold. You can select existing Cloud Monitoring channels or create a new one by clicking **Manage notification channels** . The Console supports PagerDuty, Slack, and Pub/Sub notification channels.\n- Enter a **Sampling rate** .\n- Optional: Enter the **Prediction input schema** and **Analysis input schema** .\n- Click **Continue** . The **Monitoring objective** pane opens, with options for skew or drift detection:\n- Select **Training-serving skew detection** .\n- Under **Training data source** , provide a training data source.\n- Under **Target column** , enter the column name from the training data that the model is trained to predict. This field is excluded from the monitoring analysis.\n- Optional: Under **Alert thresholds** , specify thresholds at which to trigger alerts. For information about how to format the thresholds, hold the pointer over thehelpHelp icon.\n- Click **Create** .\n- Select **Prediction drift detection** .\n- Optional: Under **Alert thresholds** , specify thresholds at which to trigger alerts. For information about how to format the thresholds, hold the pointer over thehelpHelp icon.\n- Click **Create** .To create a model deployment monitoring job using the gcloud CLI, first [deploy your model to an endpoint](/vertex-ai/docs/predictions/deploy-model-api#aiplatform_create_endpoint_sample-gcloud) .\nA monitoring job configuration applies to all deployed models under an endpoint.\nRun the [gcloud ai model-monitoring-jobs create](/sdk/gcloud/reference/ai/model-monitoring-jobs/create) command:\n```\ngcloud ai model-monitoring-jobs create \\\n --project=PROJECT_ID \\\n --region=REGION \\\n --display-name=MONITORING_JOB_NAME \\\n --emails=EMAIL_ADDRESS_1,EMAIL_ADDRESS_2 \\\n --endpoint=ENDPOINT_ID \\\n --feature-thresholds=FEATURE_1=THRESHOLD_1,FEATURE_2=THRESHOLD_2 \\\n --prediction-sampling-rate=SAMPLING_RATE \\\n --monitoring-frequency=MONITORING_FREQUENCY \\\n --target-field=TARGET_FIELD \\\n --bigquery-uri=BIGQUERY_URI\n```\nwhere:- is the ID of your Google Cloud project. For example, `my-project` .\n- is the location for your monitoring job. For example, `us-central1` .\n- is the name of your monitoring job. For example, `my-job` .\n- is the email address where you want to receive alerts from Model Monitoring. For example, `example@example.com` .\n- is the ID of the endpoint under which your model is deployed. For example, `1234567890987654321` .\n- Optional: is the alerting threshold for each feature you want to monitor. For example, if you specify `Age=0.4` , Model Monitoring logs an alert when the [statistical distance][stat-distance] between the input and baseline distributions for the `Age` feature exceeds 0.4.\n- Optional: is the fraction of the incoming prediction requests you want to log. For example, `0.5` . If not specified, Model Monitoring logs all prediction requests.\n- Optional: is the frequency at which you want the monitoring job to run on recently logged inputs. The minimum granularity is 1 hour. The default is 24 hours. For example, `2` .\n- (required only for skew detection) is the field that is being predicted by the model. This field is excluded from the monitoring analysis. For example, `housing-price` .\n- (required only for skew detection) is the link to the training dataset stored in BigQuery, using the following format:```\nbq://\\PROJECT.\\DATASET.\\TABLE\n```For example, `bq://\\my-project.\\housing-data.\\san-francisco` .You can replace the `bigquery-uri` flag with alternative links to your training dataset:- For a CSV file stored in a Cloud Storage bucket, use `--data-format=csv --gcs-uris=gs://` `` `/` `` .\n- For a TFRecord file stored in a Cloud Storage bucket, use `--data-format=tf-record --gcs-uris=gs://` `` `/` `` .\n- For a [tabular AutoML managed dataset][dataset-id], use `--dataset=` `` .\nFor information about the full end-to-end Model Monitoring API workflow, see the [example notebook](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) .- If you haven't done so already, [deploy your model to an endpoint](/vertex-ai/docs/predictions/deploy-model-api#aiplatform_create_endpoint_sample-gcloud) .\n- Retrieve the deployed model ID for your model by [getting the endpointinformation](/vertex-ai/docs/predictions/deploy-model-api#retrieve_the_endpoint_id) . Note the , which is the `deployedModels.id` value in the response.\n- Create a model monitoring job request. The instructions below show how to create a basic monitoring job for drift detection with attributions. For skew detection, add the [explanationBaseline](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs#explanationconfig) object to the `explanationConfig` field in the request JSON body and provide one of the following:- The output of a [batch explanation job](/vertex-ai/docs/explainable-ai/getting-explanations#batch) for your training dataset.\n- A [TrainingDataset](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs#trainingdataset) on which the service runs a `BatchExplain` job to generate a baseline.\nFor more details, see the [Monitoring job reference](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs) .Before using any of the request data, make the following replacements:- : is the ID of your Google Cloud project. For  example,`my-project`.\n- : is the location for your monitoring job. For example,`us-central1`.\n- : is the name of your monitoring job. For  example,`my-job`.\n- : is the number for your Google Cloud project. For  example,`1234567890`.\n- is the ID for the endpoint to which your model is deployed. For  example,`1234567890`.\n- : is the ID for the deployed model.\n- :is the alerting threshold  for each feature you want to monitor. For example,`\"housing-latitude\": {\"value\": 0.4}`.  An alert is logged when the [statistical distance](/vertex-ai/docs/model-monitoring/overview#stat-distance) between  the input feature distribution and its corresponding baseline exceeds the  specified threshold. By default, every categorical and numerical feature  is monitored, with threshold values of 0.3.\n- : is the email address where you want to receive  alerts from Model Monitoring. For example,`example@example.com`.\n- :  a list of [Cloud Monitoring notification channels](/monitoring/support/notification-options) where you want to receive alerts from Model Monitoring. Use the resource names  for the notification channels, which you can retrieve by [listing the notification channels  in your project](/monitoring/alerts/using-channels-api#api-list-channels) . For example,`\"projects/my-project/notificationChannels/1355376463305411567\",  \"projects/my-project/notificationChannels/1355376463305411568\"`.\nRequest JSON body:\n```\n{\n \"displayName\":\"MONITORING_JOB_NAME\",\n \"endpoint\":\"projects/PROJECT_NUMBER/locations/LOCATION/endpoints/ENDPOINT_ID\",\n \"modelDeploymentMonitoringObjectiveConfigs\": {\n  \"deployedModelId\": \"DEPLOYED_MODEL_ID\",\n  \"objectiveConfig\": {\n  \"predictionDriftDetectionConfig\": {\n   \"driftThresholds\": {\n    \"FEATURE_1\": {\n    \"value\": VALUE_1\n    },\n    \"FEATURE_2\": {\n    \"value\": VALUE_2\n    }\n   }\n   },\n  \"explanationConfig\": {\n   \"enableFeatureAttributes\": true\n  }\n  }\n },\n \"loggingSamplingStrategy\": {\n  \"randomSampleConfig\": {\n  \"sampleRate\": 0.5,\n  },\n },\n \"modelDeploymentMonitoringScheduleConfig\": {\n  \"monitorInterval\": {\n  \"seconds\": 3600,\n  },\n },\n \"modelMonitoringAlertConfig\": {\n  \"emailAlertConfig\": {\n  \"userEmails\": [\"EMAIL_ADDRESS\"],\n  },\n  \"notificationChannels\": [NOTIFICATION_CHANNELS]\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION/modelDeploymentMonitoringJobs/MONITORING_JOB_NUMBER\",\n ...\n \"state\": \"JOB_STATE_PENDING\",\n \"scheduleState\": \"OFFLINE\",\n ...\n \"bigqueryTables\": [ {\n  \"logSource\": \"SERVING\",\n  \"logType\": \"PREDICT\",\n  \"bigqueryTablePath\": \"bq://PROJECT_ID.model_deployment_monitoring_8451189418714202112.serving_predict\"\n }\n ],\n ...\n}\n```Once the monitoring job is created, Model Monitoring logs incoming prediction requests in a generated BigQuery table named `` `.model_deployment_monitoring_` `` `.serving_predict` . If [request-response logging](/vertex-ai/docs/predictions/online-prediction-logging#model-monitoring) is enabled, Model Monitoring logs incoming requests in the same BigQuery table that is used for request-response logging.\nSee [Using Model Monitoring](/vertex-ai/docs/model-monitoring/using-model-monitoring) for instructions on how to do the following optional tasks:\n- Update a Model Monitoring job.\n- Configure alerts for the Model Monitoring job\n- Configure alerts for anomalies.## Analyze feature attribution skew and drift data\nYou can use the Google Cloud console to visualize the feature attributions of each monitored feature and learn which changes led to skew or drift. For information about analyzing feature distribution data, see [Analyze skew anddrift data](/vertex-ai/docs/model-monitoring/using-model-monitoring#analyzing-skew-drift) .\nIn a stable machine learning system, features' relative importance generally remains relatively stable over time. If an important feature drops in importance, it might signal that something about that feature has changed. Common causes of feature importance drift or skew include the following:\n- Data source changes.\n- Data schema and logging changes.\n- Changes in end-user mix or behavior (for example, due to seasonal changes or outlier events).\n- Upstream changes in features generated by another machine learning model. Some examples are:- Model updates that cause an increase or decrease in coverage (overall or for an individual classification value).\n- A change in performance of the model (which changes the meaning of the feature).\n- Updates to the data pipeline, which can cause a decrease in overall coverage.In addition, consider the following when analyzing feature attribution skew and drift data:\n- **Track the most important features.** A large change in attribution to a feature means that the feature's contribution to the prediction has changed. Because the prediction score is equal to the sum of the feature contributions, large attribution drift of the most important features usually indicates large drift in the model predictions.\n- **Monitor all feature representations.** Feature attributions are always numeric, regardless of the underlying feature type. Due to their additive nature, attributions to a multi-dimensional feature such as embeddings can be reduced to a single numeric value by adding up the attributions across dimensions. This lets you use standard univariate drift detection methods for all feature types.\n- **Account for feature interactions.** Attribution to a feature accounts for the feature's contribution to the prediction, both individually and by its interactions with other features. If a feature's interactions with other features changes, distributions of attributions to a feature change, even if the marginal distribution of the feature remains the same.\n- **Monitor feature groups.** Because attributions are additive, you can add up attributions to related features to obtain the attribution of a feature group. For example, in a credit lending model, combine the attribution to all features related to the loan type (for example, \"grade\", \"sub_grade\", \"purpose\") to obtain a single loan attribution. This group-level attribution can then be tracked to monitor for changes in the feature group.## What's next\n- Work with Model Monitoring following the [API docs](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs) .\n- Work with Model Monitoring following the [gcloud CLI docs](/sdk/gcloud/reference/ai/model-monitoring-jobs) .\n- Try the example notebook [in Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) or [view it onGitHub](https://www.github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) .\n- Learn how Model Monitoring [calculates training-servingskew and prediction drift](/vertex-ai/docs/model-monitoring/overview) .", "guide": "Vertex AI"}