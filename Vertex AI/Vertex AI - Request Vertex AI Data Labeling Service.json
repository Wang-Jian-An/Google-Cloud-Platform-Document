{"title": "Vertex AI - Request Vertex AI Data Labeling Service", "url": "https://cloud.google.com/vertex-ai/docs/datasets/data-labeling-job", "abstract": "# Vertex AI - Request Vertex AI Data Labeling Service\n**Caution:** Vertex AI Data Labeling Service (requesting human labelers) is deprecated and will no longer be available on Google Cloud after July 1, 2024. For new labeling tasks, you can use [add labels using the Google Cloud console](/vertex-ai/docs/datasets/label-using-console) or access data labeling solutions from our partners in the [Google Cloud Console Marketplace](https://console.cloud.google.com/marketplace/) , such as Labelbox and Snorkel.\nThe quality of your training data strongly affects the effectiveness of the model you create, and by extension, the quality of the predictions returned from that model. The key to high-quality training data is ensuring that you have training items that [accurately represent the domain you want to make predictionsabout](/vertex-ai/docs/beginner/beginners-guide) and that the training items are accurately labeled.\nThere are three ways to assign labels to your training data items:\n- Add the data items to your dataset with their labels already assigned, for example using a commercially available dataset\n- Assign labels to the data items using the Google Cloud console\n- Request to have human labelers add labels to the data items\nVertex AI data labeling tasks let you work with human labelers to generate highly accurate labels for a collection of data that you can use to train your machine learning models.\nFor information about pricing of data labeling, see [Datalabeling](/vertex-ai/pricing#labeling) .\nTo request data labeling by human labelers, you create a that provides the human labelers with:\n- The dataset containing the representative data items to label\n- A list of all possible labels to apply to the data items\n- A PDF file containing instructions guiding the human labelers through labeling tasks\nUsing these resources, the human labelers annotate the items in the dataset according to your instructions. When they are done, you can use the annotation set to train a Vertex AI model or export the labeled data items to use in another machine learning environment.\n", "content": "## Create a dataset\nYou provide the human labelers with the data items to label by [creating a dataset](/vertex-ai/docs/training-overview) and importing data items into it. The data items need not be labeled. The data type (image, video, or text) and objective (for example, classification or object tracking) determines the type of annotations the human labelers apply to the data items.\n## Provide labels\nWhen you create a data labeling task, you list the set of labels you want the human labelers to use to label your images. For example, if you want to classify images based on whether they contain a dog or a cat, you create a label set with two labels: \"Dog\" and \"Cat\". And, as noted in the following list, you might also want labels for \"Neither\" and \"Both\".\nHere are some guidelines for creating a high-quality label set.\n- Make each label's display name a meaningful word, such as \"dog\", \"cat\", or \"building\". Do not use abstract names like \"label1\" and \"label2\" or unfamiliar acronyms. The more meaningful the label names, the easier it is for human labelers to apply them accurately and consistently.\n- Make sure the labels are easily distinguishable from one another. For classification tasks where a single label is applied to each data item, try not to use labels whose meanings overlap. For example, don't have labels for \"Sports\" and \"Baseball\".\n- For classification tasks, it is usually a good idea to include a label named \"other\" or \"none\", to use for data that don't match the other labels. If the only available labels are \"dog\" and \"cat\", for example, labelers must label every image with one of those labels. Your custom model is typically more robust if you include images other than dogs or cats in its training data.\n- Keep in mind that labelers are most efficient and accurate when you have at most 20 labels defined in the label set. You can include up to 100 labels.## Create instructions\nInstructions give the human labelers information about how to apply labels to your data. The instructions should contain sample labeled data and other explicit directions.\nInstructions are PDF files. PDF instructions can provide sophisticated directions such as positive and negative examples or descriptions for each case. PDF is also a convenient format for providing instructions for complicated tasks such as image bounding boxes or video object tracking.\nWrite the instructions, create a PDF file, and save the PDF file in your Cloud Storage bucket.\n### Provide good instructions\nGood instructions are the most important factor in getting good human labeling results. Because you know your use case best, you need to let the human labelers know what you want them to do. Here are some guidelines for creating good instructions:\n- The human labelers do not have your domain knowledge. The distinctions you ask labelers to make should be easy to understand for someone unfamiliar with your use case.\n- Avoid making the instructions too long. It is best if a labeler can review and understand the instructions within 20 minutes.\n- Instructions should describe the concept of the task and provide details about how to label the data. For example, for a bounding box task, describe how you want labelers to draw the bounding box. Should it be a tight box or a loose box? If there are multiple instances of the object, should they draw one bounding box or multiple boxes?\n- If your instructions have a corresponding label set, they should cover all labels in that set. The label name in the instructions should match the name in the label set.\n- It often takes several iterations to create good instructions. We recommend having the human labelers work on a small dataset first, then adjust your instructions based on how well the labelers' work matches your expectations.\nA good instructions file includes the following sections:\n- Label list and description: A list of all the labels you would like to use and the meaning of each label.\n- Examples: For each label, give at least three positive examples and one negative example. These examples should cover different cases.\n- Cover edge cases. To reduce the need for the labeler to interpret the label, clarify as many edge cases as you can. For example, if you need to draw a bounding box for a person, it is better to clarify:- If there are multiple people, do you need a box for each person?\n- If a person is occluded, do you need a box?\n- If a person is partially shown in the image, do you need a box?\n- If a person is in a picture or painting, do you need a box?\n- Describe how to add annotations. For example:- For a bounding box, do you need a tight box or loose box?\n- For text entity extraction, where should the interested entity start and end?\n- Clarification on labels. If two labels are similar or easy to mix up, give examples to clarify the difference.\nThe following examples show what the PDF instructions might include. Labelers will review the instructions before they start the task.## Create a data labeling task\nYou can request data labeling from the Google Cloud console.- In the Google Cloud console, go to the **Labeling tasks** page. [Go to Labeling tasks](https://console.cloud.google.com/vertex-ai/labeling-tasks) \n- Click **Create** .\nThe **New labeling task** pane opens.- Enter a name for the labeling task.\n- Select the dataset whose items you want to have labeled.If you opened the **New labeling task** pane from the dataset detail screen, you cannot select a different dataset.\n- Confirm that the objective is correct.The **Objective** box shows the objective for the selected dataset, as determined by its default annotation set. To change the objective, choose a different annotation set.\n- Choose the annotation set to use for the labeled data.The labels applied by the human labelers are saved to the selected annotation set. You can choose an existing annotation set or [create a newone](/vertex-ai/docs/datasets/create-annotation-set) . If you create a new one, you need to provide a name for it.\n- Specify whether to use active learning.Active learning expedites the labeling process by having a human labeler label part of your dataset, then applying machine learning to automatically label the rest. **Note:** Active learning is available only for and objectives.\n- Click **Continue** .\n- Enter the labels for the human labelers to apply. For information about creating a high-quality set of labels, see [Designing a label set](#label-set) .\n- Click **Continue** .\n- Enter the path to the instructions for the human labelers. The instructions must be a PDF file stored in a Cloud Storage bucket. For information about creating high-quality instructions, see [Designing instructions for humanlabelers](#instructions) .\n- Click **Continue** .\n- Choose whether to use **Google-managed labelers** or **Provide your own labelers** .- If you chose to use Google-managed labelers, click the checkbox to confirm that you have read the pricing guide to understand the cost of labeling.\n- If you are providing your own labelers, you need to create labeler groups and manage their activities by using the DataCompute Console. Otherwise, choose the labeler group to use for this labeling task.Choose an existing labeler group from the drop-down list, or choose **Newlabeler group** and enter a group name and comma-separated list of email addresses for the group's managers in the text boxes below the drop-down list. Click the checkbox to grant the specified managers access to see your data labeling information.\n- Specify how many labelers you want to review each item.By default, one human labeler annotates each data item. However, you can request to have multiple labelers annotate and review each item. Select the number of labelers from the **Specialists per data item** box.\n- Click **Start Task** .If **Start Task** is unavailable, review the pages within the **New labelingtask** pane to verify that you've entered all the required information.\nYou can review the progress of the data labeling task in the Google Cloud console from the **Labeling tasks** page.\n [Go to Labeling tasks](https://console.cloud.google.com/vertex-ai/labeling-tasks) \nThe page shows the status of each requested labeling task. When the **Progress** column shows 100%, the corresponding dataset is labeled and ready for training a model.Before using any of the request data, make the following replacements:- : Your project ID\n- : Name for the data labeling job\n- : ID of the dataset containing the items to label\n- : The number of human labelers you want to have review each data item; valid values are 1, 3, and 5.\n- : The path to the PDF file containing instructions for the human labelers; the file must be in a Cloud Storage bucket accessible from your project\n- : Path to the schema file for the data item type:\n- Image classification single label:`gs://google-cloud-aiplatform/schema/dataset/ioformat/image_classification_single_label_io_format_1.0.0.yaml`\n- Image classification multi-label:`gs://google-cloud-aiplatform/schema/dataset/ioformat/image_classification_multi_label_io_format_1.0.0.yaml`\n- Image object detection:`gs://google-cloud-aiplatform/schema/dataset/ioformat/image_bounding_box_io_format_1.0.0.yaml`\n- Text classification single-label:`gs://google-cloud-aiplatform/schema/dataset/ioformat/text_classification_single_label_io_format_1.0.0.yaml`\n- Text classification multi-label:`gs://google-cloud-aiplatform/schema/dataset/ioformat/text_classification_multi_label_io_format_1.0.0.yaml`\n- Text entity extraction:`gs://google-cloud-aiplatform/schema/dataset/ioformat/text_extraction_io_format_1.0.0.yaml`\n- Text sentiment analysis:`gs://google-cloud-aiplatform/schema/dataset/ioformat/text_sentiment_io_format_1.0.0.yaml`\n- Video classification:`gs://google-cloud-aiplatform/schema/dataset/ioformat/video_classification_io_format_1.0.0.yaml`\n- Video object tracking:`gs://google-cloud-aiplatform/schema/dataset/ioformat/video_object_tracking_io_format_1.0.0.yaml`\n- : A comma-separated list of strings, enumerating the labels available to apply to a data item\n- : The name of the annotation set for the labeled data\nHTTP method and URL:\n```\nPOST https://us-central1-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/us-central1/dataLabelingJobs\n```\nRequest JSON body:\n```\n{\n \"displayName\":\"DISPLAY_NAME\",\n \"datasets\":\"DATASET_ID\",\n \"labelerCount\":LABELERS,\n \"instructionUri\":\"INSTRUCTIONS\",\n \"inputsSchemaUri\":\"INPUT_SCHEMA_URI\",\n \"inputs\": {\n  \"annotation_specs\": [LABEL_LIST]\n },\n \"annotationLabels\": {\n  \"aiplatform.googleapis.com/annotation_set_name\": \"ANNOTATION_SET\"\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_ID/locations/us-central1/dataLabelingJobs/JOB_ID\",\n \"displayName\": \"DISPLAY_NAME\",\n \"datasets\": [ \"DATASET_ID\"\n ],\n \"labelerCount\": LABELERS,\n \"instructionUri\": \"INSTRUCTIONS\",\n \"inputsSchemaUri\": \"INPUT_SCHEMA_URI\",\n \"inputs\": {\n \"annotationSpecs\": [  LABEL_LIST\n ]\n },\n \"state\": \"JOB_STATE_PENDING\",\n \"labelingProgress\": \"0\",\n \"createTime\": \"2020-05-30T23:13:49.121133Z\",\n \"updateTime\": \"2020-05-30T23:13:49.121133Z\",\n \"savedQuery\": {\n \"name\": \"projects/PROJECT_ID/locations/us-central1/datasets/DATASET_ID/savedQueries/ANNOTATION_SET_ID\"\n },\n \"annotationSpecCount\": 2\n}\n```\nThe response is a\n [DataLabelingJob](/vertex-ai/docs/reference/rest/v1/projects.locations.dataLabelingJobs#resource:-datalabelingjob) \n. You can check the progress of the job by monitoring the\n`\"labelingProgress\"`\nelement, whose value is the percentage completed.\nAdditional code samples:\n- Using [active learning](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/master/aiplatform/src/main/java/aiplatform/CreateDataLabelingJobActiveLearningSample.java) \n- Using a [custom labeler pool](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/master/aiplatform/src/main/java/aiplatform/CreateDataLabelingJobSpecialistPoolSample.java) \n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/CreateDataLabelingJobSample.java) \n```\nimport com.google.cloud.aiplatform.v1.DataLabelingJob;import com.google.cloud.aiplatform.v1.DatasetName;import com.google.cloud.aiplatform.v1.JobServiceClient;import com.google.cloud.aiplatform.v1.JobServiceSettings;import com.google.cloud.aiplatform.v1.LocationName;import com.google.protobuf.Value;import com.google.protobuf.util.JsonFormat;import com.google.type.Money;import java.io.IOException;import java.util.Map;public class CreateDataLabelingJobSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String displayName = \"YOUR_DATA_LABELING_DISPLAY_NAME\";\u00a0 \u00a0 String datasetId = \"YOUR_DATASET_ID\";\u00a0 \u00a0 String instructionUri =\u00a0 \u00a0 \u00a0 \u00a0 \"gs://YOUR_GCS_SOURCE_BUCKET/path_to_your_data_labeling_source/file.pdf\";\u00a0 \u00a0 String inputsSchemaUri = \"YOUR_INPUT_SCHEMA_URI\";\u00a0 \u00a0 String annotationSpec = \"YOUR_ANNOTATION_SPEC\";\u00a0 \u00a0 createDataLabelingJob(\u00a0 \u00a0 \u00a0 \u00a0 project, displayName, datasetId, instructionUri, inputsSchemaUri, annotationSpec);\u00a0 }\u00a0 static void createDataLabelingJob(\u00a0 \u00a0 \u00a0 String project,\u00a0 \u00a0 \u00a0 String displayName,\u00a0 \u00a0 \u00a0 String datasetId,\u00a0 \u00a0 \u00a0 String instructionUri,\u00a0 \u00a0 \u00a0 String inputsSchemaUri,\u00a0 \u00a0 \u00a0 String annotationSpec)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 JobServiceSettings jobServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 JobServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (JobServiceClient jobServiceClient = JobServiceClient.create(jobServiceSettings)) {\u00a0 \u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 \u00a0 LocationName locationName = LocationName.of(project, location);\u00a0 \u00a0 \u00a0 String jsonString = \"{\\\"annotation_specs\\\": [ \" + annotationSpec + \"]}\";\u00a0 \u00a0 \u00a0 Value.Builder annotationSpecValue = Value.newBuilder();\u00a0 \u00a0 \u00a0 JsonFormat.parser().merge(jsonString, annotationSpecValue);\u00a0 \u00a0 \u00a0 DatasetName datasetName = DatasetName.of(project, location, datasetId);\u00a0 \u00a0 \u00a0 DataLabelingJob dataLabelingJob =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DataLabelingJob.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDisplayName(displayName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setLabelerCount(1)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInstructionUri(instructionUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputsSchemaUri(inputsSchemaUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addDatasets(datasetName.toString())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputs(annotationSpecValue)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .putAnnotationLabels(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"aiplatform.googleapis.com/annotation_set_name\", \"my_test_saved_query\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 DataLabelingJob dataLabelingJobResponse =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 jobServiceClient.createDataLabelingJob(locationName, dataLabelingJob);\u00a0 \u00a0 \u00a0 System.out.println(\"Create Data Labeling Job Response\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\tName: %s\\n\", dataLabelingJobResponse.getName());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tDisplay Name: %s\\n\", dataLabelingJobResponse.getDisplayName());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tDatasets: %s\\n\", dataLabelingJobResponse.getDatasetsList());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tLabeler Count: %s\\n\", dataLabelingJobResponse.getLabelerCount());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tInstruction Uri: %s\\n\", dataLabelingJobResponse.getInstructionUri());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tInputs Schema Uri: %s\\n\", dataLabelingJobResponse.getInputsSchemaUri());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tInputs: %s\\n\", dataLabelingJobResponse.getInputs());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tState: %s\\n\", dataLabelingJobResponse.getState());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tLabeling Progress: %s\\n\", dataLabelingJobResponse.getLabelingProgress());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tCreate Time: %s\\n\", dataLabelingJobResponse.getCreateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tUpdate Time: %s\\n\", dataLabelingJobResponse.getUpdateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tLabels: %s\\n\", dataLabelingJobResponse.getLabelsMap());\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\tSpecialist Pools: %s\\n\", dataLabelingJobResponse.getSpecialistPoolsList());\u00a0 \u00a0 \u00a0 for (Map.Entry<String, String> annotationLabelMap :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dataLabelingJobResponse.getAnnotationLabelsMap().entrySet()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"\\tAnnotation Level\");\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tkey: %s\\n\", annotationLabelMap.getKey());\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tvalue: %s\\n\", annotationLabelMap.getValue());\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 Money money = dataLabelingJobResponse.getCurrentSpend();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tCurrent Spend\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tCurrency Code: %s\\n\", money.getCurrencyCode());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tUnits: %s\\n\", money.getUnits());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tNanos: %s\\n\", money.getNanos());\u00a0 \u00a0 }\u00a0 }}\n```\nAdditional code samples:\n- Using [active learning](https://github.com/googleapis/python-aiplatform/blob/master/samples/snippets/job_service/create_data_labeling_job_active_learning_sample.py) \n- Using a [custom labeler pool](https://github.com/googleapis/python-aiplatform/blob/master/samples/snippets/job_service/create_data_labeling_job_specialist_pool_sample.py) \n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/snippets/job_service/create_data_labeling_job_sample.py) \n```\nfrom google.cloud import aiplatformfrom google.protobuf import json_formatfrom google.protobuf.struct_pb2 import Valuedef create_data_labeling_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 dataset_name: str,\u00a0 \u00a0 instruction_uri: str,\u00a0 \u00a0 inputs_schema_uri: str,\u00a0 \u00a0 annotation_spec: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",):\u00a0 \u00a0 # The AI Platform services require regional API endpoints.\u00a0 \u00a0 client_options = {\"api_endpoint\": api_endpoint}\u00a0 \u00a0 # Initialize client that will be used to create and send requests.\u00a0 \u00a0 # This client only needs to be created once, and can be reused for multiple requests.\u00a0 \u00a0 client = aiplatform.gapic.JobServiceClient(client_options=client_options)\u00a0 \u00a0 inputs_dict = {\"annotation_specs\": [annotation_spec]}\u00a0 \u00a0 inputs = json_format.ParseDict(inputs_dict, Value())\u00a0 \u00a0 data_labeling_job = {\u00a0 \u00a0 \u00a0 \u00a0 \"display_name\": display_name,\u00a0 \u00a0 \u00a0 \u00a0 # Full resource name: projects/{project_id}/locations/{location}/datasets/{dataset_id}\u00a0 \u00a0 \u00a0 \u00a0 \"datasets\": [dataset_name],\u00a0 \u00a0 \u00a0 \u00a0 # labeler_count must be 1, 3, or 5\u00a0 \u00a0 \u00a0 \u00a0 \"labeler_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \"instruction_uri\": instruction_uri,\u00a0 \u00a0 \u00a0 \u00a0 \"inputs_schema_uri\": inputs_schema_uri,\u00a0 \u00a0 \u00a0 \u00a0 \"inputs\": inputs,\u00a0 \u00a0 \u00a0 \u00a0 \"annotation_labels\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"aiplatform.googleapis.com/annotation_set_name\": \"my_test_saved_query\"\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 }\u00a0 \u00a0 parent = f\"projects/{project}/locations/{location}\"\u00a0 \u00a0 response = client.create_data_labeling_job(\u00a0 \u00a0 \u00a0 \u00a0 parent=parent, data_labeling_job=data_labeling_job\u00a0 \u00a0 )\u00a0 \u00a0 print(\"response:\", response)\n```\n**Note:** The maximum turnaround time for a data labeling job is 63 days. If your data is not labeled within that time, the job expires and is deleted along with the tasks assigned to labelers.\n## What's next\n- [Train a model by using AutoML](/vertex-ai/docs/training-overview#automl) .\n- [Train a model by using your custom training code](/vertex-ai/docs/training-overview#custom_training) .", "guide": "Vertex AI"}