{"title": "Vertex AI - Monitor feature skew and drift", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Monitor feature skew and drift\nTo learn more,  run the \"Use Model Monitoring to detect drift and training-prediction skew.\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fmodel_monitoring%2Fmodel_monitoring.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb)\nThis page describes how to create, manage, and interpret the results of Model Monitoring jobs for models deployed to online prediction endpoints. Vertex AI Model Monitoring supports feature skew and drift detection for categorical and numerical input features.\nWhen a model is deployed in production with Model Monitoring enabled, incoming prediction requests are logged in a BigQuery table in your Google Cloud project. The input feature values contained in the logged requests are then analyzed for skew or drift.\nYou can enable skew detection if you provide the original training dataset for your model; otherwise, you should enable drift detection. For more information, see [Introduction to Vertex AI Model Monitoring](/vertex-ai/docs/model-monitoring/overview) .\n", "content": "## Prerequisites\nTo use Model Monitoring, complete the following:\n- Have an available model in Vertex AI that is either a [tabularAutoML](/vertex-ai/docs/start/automl-model-types#tabular) or imported tabular [custom training](/vertex-ai/docs/training/overview) type.- If you are using an existing endpoint, make sure all the models deployed under the endpoint are tabular AutoML or imported custom training types.\n- If you are enabling skew detection, upload your training data to [Cloud Storage](/storage/docs/uploading-objects) or [BigQuery](/bigquery/docs/loading-data) and obtain the URI link to the data. For drift detection, training data is not required.\n- Optional: For custom-trained models, upload the [analysis instanceschema](/vertex-ai/docs/model-monitoring/schemas) for your model to Cloud Storage. Model Monitoring requires the schema to begin the monitoring process and calculate the baseline distribution for skew detection. If you don't provide the schema during job creation, the job remains in a pending state until Model Monitoring can automatically parse the schema from the first 1000 prediction requests the model receives.## Create a Model Monitoring job\nTo set up either skew detection or drift detection, create a model deployment monitoring job:\nTo create a model deployment monitoring job using the Google Cloud console, create an endpoint:\n **Note:** To enable model monitoring for an existing endpoint, [edit the endpoint'ssettings](/vertex-ai/docs/model-monitoring/using-model-monitoring#update-model-monitoring-job) .\n- In the Google Cloud console, go to the **Vertex AI Endpoints** page. [Go to Endpoints](https://console.cloud.google.com/vertex-ai/endpoints/) \n- Click **Create Endpoint** .\n- In the **New endpoint** pane, name your endpoint and set a region.\n- Click **Continue** .\n- In the **Model name** field, select an imported custom training or tabular AutoML model.\n- In the **Version** field, select a version for your model.\n- Click **Continue** .\n- In the **Model monitoring** pane, make sure **Enable model monitoring forthis endpoint** is toggled on. Any monitoring settings you configure apply to all models deployed to the endpoint.\n- Enter a **Monitoring job display name** .\n- Enter a **Monitoring window length** .\n- For **Notification emails** , enter one or more comma-separated email addresses to receive alerts when a model exceeds an alerting threshold.\n- (Optional) For **Notification channels** , add [Cloud Monitoring](/monitoring/support/notification-options) channels to receive alerts when a model exceeds an alerting threshold. You can select existing Cloud Monitoring channels or create a new one by clicking **Manage notification channels** . The Console supports PagerDuty, Slack, and Pub/Sub notification channels.\n- Enter a **Sampling rate** .\n- Optional: Enter the **Prediction input schema** and **Analysis input schema** .\n- Click **Continue** . The **Monitoring objective** pane opens, with options for skew or drift detection:\n- Select **Training-serving skew detection** .\n- Under **Training data source** , provide a training data source.\n- Under **Target column** , enter the column name from the training data that the model is trained to predict. This field is excluded from the monitoring analysis.\n- Optional: Under **Alert thresholds** , specify thresholds at which to trigger alerts. For information about how to format the thresholds, hold the pointer over thehelpHelp icon.\n- Click **Create** .\n- Select **Prediction drift detection** .\n- Optional: Under **Alert thresholds** , specify thresholds at which to trigger alerts. For information about how to format the thresholds, hold the pointer over thehelpHelp icon.\n- Click **Create** .To create a model deployment monitoring job using the gcloud CLI, first deploy your model to an endpoint:- [Deploy an AutoML tabular classification/regression model](/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#deploy-model) .\n- [Deploy a custom tabular model](/vertex-ai/docs/general/deployment) .\nA monitoring job configuration applies to all deployed models under an endpoint.\nRun the [gcloud ai model-monitoring-jobs create](/sdk/gcloud/reference/ai/model-monitoring-jobs/create) command.\n```\ngcloud ai model-monitoring-jobs create \\\n --project=PROJECT_ID \\\n --region=REGION \\\n --display-name=MONITORING_JOB_NAME \\\n --emails=EMAIL_ADDRESS_1,EMAIL_ADDRESS_2 \\\n --endpoint=ENDPOINT_ID \\\n [--feature-thresholds=FEATURE_1=THRESHOLD_1, FEATURE_2=THRESHOLD_2] \\\n [--prediction-sampling-rate=SAMPLING_RATE] \\\n [--monitoring-frequency=MONITORING_FREQUENCY] \\\n [--analysis-instance-schema=ANALYSIS_INSTANCE_SCHEMA] \\\n --target-field=TARGET_FIELD \\\n --bigquery-uri=BIGQUERY_URI\n```\nwhere:- is the ID of your Google Cloud project. For example, `my-project` .\n- is the location for your monitoring job. For example, `us-central1` .\n- is the name of your monitoring job. For example, `my-job` .\n- is the email address where you want to receive alerts from Model Monitoring. For example, `example@example.com` .\n- is the ID of the endpoint under which your model is deployed. For example, `1234567890987654321` .\n- Optional: is the alerting threshold for each feature you want to monitor. For example, if you specify `Age=0.4` , Model Monitoring logs an alert when the [statisticaldistance](/vertex-ai/docs/model-monitoring/overview#stat-distance) between the input and baseline distributions for the `Age` feature exceeds 0.4. By default, every categorical and numerical feature is monitored with threshold values of 0.3.\n- Optional: is the fraction of the incoming prediction requests you want to log. For example, `0.5` . If not specified, Model Monitoring logs all prediction requests.\n- Optional: is the frequency at which you want the monitoring job to run on recently logged inputs. The minimum granularity is 1 hour. The default is 24 hours. For example, `2` .\n- Optional: is the Cloud Storage URI for the schema file that describes the format of your input data. For example, `gs://test-bucket/schema.yaml` .\n- (required only for skew detection) is the field that is being predicted by the model. This field is excluded from the monitoring analysis. For example, `housing-price` .\n- (required only for skew detection) is the link to the training dataset stored in BigQuery, using the following format:```\nbq://\\PROJECT.\\DATASET.\\TABLE\n```For example, `bq://\\my-project.\\housing-data.\\san-francisco` .You can replace the `bigquery-uri` flag with alternative links to your training dataset:- For a CSV file stored in a Cloud Storage bucket, use `--data-format=csv --gcs-uris=gs://` `` `/` `` .\n- For a TFRecord file stored in a Cloud Storage bucket, use `--data-format=tf-record --gcs-uris=gs://` `` `/` `` .\n- For a [tabular AutoML managed dataset](/vertex-ai/docs/datasets/export-metadata-annotations#exporting_a_dataset_using_the_or_the_api) , use `--dataset=` `` .\nFor information about the full end-to-end Model Monitoring API workflow, see the [example notebook](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) .- If you haven't done so already, deploy your model to an endpoint. During the **Get the endpoint ID** step in the model deployment instructions, note the `deployedModels.id` value in the JSON response for later use:- [Deploy an AutoML tabular classification/regression model](/vertex-ai/docs/tabular-data/classification-regression/get-online-predictions#deploy-model) .\n- [Deploy a custom tabular model](/vertex-ai/docs/general/deployment) .\n- Create a model monitoring job request. The instructions below show how to create a basic monitoring job for drift detection. To customize the JSON request, see the [Monitoring job reference](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs) .Before using any of the request data, make the following replacements:- : is the ID of your Google Cloud project. For  example,`my-project`.\n- : is the location for your monitoring job. For example,`us-central1`.\n- : is the name of your monitoring job. For  example,`my-job`.\n- : is the number for your Google Cloud project. For  example,`1234567890`.\n- is the ID for the endpoint to which your model is deployed. For  example,`1234567890`.\n- : is the ID for the deployed model.\n- :is the alerting threshold  for each feature you want to monitor. For example, if you specify`\"Age\": {\"value\": 0.4}`,  Model Monitoring logs an alert when the [statistical distance](/vertex-ai/docs/model-monitoring/overview#stat-distance) between the input and baseline distributions for the`Age`feature exceeds 0.4. By default,  every categorical and numerical feature is monitored with threshold values of 0.3.\n- : is the email address where you want to receive  alerts from Model Monitoring. For example,`example@example.com`.\n- :  a list of [Cloud Monitoring notification channels](/monitoring/support/notification-options) where you want to receive alerts from Model Monitoring. Use the resource names  for the notification channels, which you can retrieve by [listing the notification channels  in your project](/monitoring/alerts/using-channels-api#api-list-channels) . For example,`\"projects/my-project/notificationChannels/1355376463305411567\",  \"projects/my-project/notificationChannels/1355376463305411568\"`.\n- Optional:is the Cloud Storage URI  for the schema file that describes the format of your input data. For example,`gs://test-bucket/schema.yaml`.\nRequest JSON body:\n```\n{\n \"displayName\":\"MONITORING_JOB_NAME\",\n \"endpoint\":\"projects/PROJECT_NUMBER/locations/LOCATION/endpoints/ENDPOINT_ID\",\n \"modelDeploymentMonitoringObjectiveConfigs\": {\n  \"deployedModelId\": \"DEPLOYED_MODEL_ID\",\n  \"objectiveConfig\": {\n  \"predictionDriftDetectionConfig\": {\n   \"driftThresholds\": {\n    \"FEATURE_1\": {\n    \"value\": VALUE_1\n    },\n    \"FEATURE_2\": {\n    \"value\": VALUE_2\n    }\n   }\n   },\n  },\n },\n \"loggingSamplingStrategy\": {\n  \"randomSampleConfig\": {\n  \"sampleRate\": 0.5,\n  },\n },\n \"modelDeploymentMonitoringScheduleConfig\": {\n  \"monitorInterval\": {\n  \"seconds\": 3600,\n  },\n },\n \"modelMonitoringAlertConfig\": {\n  \"emailAlertConfig\": {\n  \"userEmails\": [\"EMAIL_ADDRESS\"],\n  },\n  \"notificationChannels\": [NOTIFICATION_CHANNELS]\n },\n \"analysisInstanceSchemaUri\": ANALYSIS_INSTANCE_SCHEMA\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION/modelDeploymentMonitoringJobs/MONITORING_JOB_NUMBER\",\n ...\n \"state\": \"JOB_STATE_PENDING\",\n \"scheduleState\": \"OFFLINE\",\n ...\n \"bigqueryTables\": [ {\n  \"logSource\": \"SERVING\",\n  \"logType\": \"PREDICT\",\n  \"bigqueryTablePath\": \"bq://PROJECT_ID.model_deployment_monitoring_8451189418714202112.serving_predict\"\n }\n ],\n ...\n}\n```After the monitoring job is created, Model Monitoring logs incoming prediction requests in a generated BigQuery table named `` `.model_deployment_monitoring_` `` `.serving_predict` . If [request-response logging](/vertex-ai/docs/predictions/online-prediction-logging#model-monitoring) is enabled, Model Monitoring logs incoming requests in the same BigQuery table that is used for request-response logging.\n### (Optional) Configure alerts for the Model Monitoring job\nYou can monitor and debug your Model Monitoring job through alerts. Model Monitoring automatically notifies you of job updates through email, but you can also set up alerts through Cloud Logging and Cloud Monitoring notification channels.\nFor the following events, Model Monitoring sends an email notification to each email address you specified when creating the Model Monitoring job:- Each time skew or drift detection is set up.\n- Each time an existing Model Monitoring job configuration is updated.\n- Each time a scheduled monitoring pipeline run fails.\nTo enable logs for scheduled monitoring pipeline runs, set the `enableMonitoringPipelineLogs` field in your [modelDeploymentMonitoringJobs](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs) configuration to `true` . Debugging logs are written to Cloud Logging when the monitoring job is set up and at each monitoring interval.\nThe debugging logs are written to Cloud Logging with the log name: `model_monitoring` . For example:\n```\nlogName=\"projects/model-monitoring-demo/logs/aiplatform.googleapis.com%2Fmodel_monitoring\" resource.labels.model_deployment_monitoring_job=6680511704087920640\n```\nHere is an example of a job progress log entry:\n```\n{\"insertId\": \"e2032791-acb9-4d0f-ac73-89a38788ccf3@a1\",\"jsonPayload\": {\u00a0 \"@type\": \"type.googleapis.com/google.cloud.aiplatform.logging.ModelMonitoringPipelineLogEntry\",\u00a0 \"statusCode\": {\u00a0 \u00a0 \"message\": \"Scheduled model monitoring pipeline finished successfully for job projects/677687165274/locations/us-central1/modelDeploymentMonitoringJobs/6680511704087920640\"\u00a0 },\u00a0 \"modelDeploymentMonitoringJob\": \"projects/677687165274/locations/us-central1/modelDeploymentMonitoringJobs/6680511704087920640\"},\"resource\": {\u00a0 \"type\": \"aiplatform.googleapis.com/ModelDeploymentMonitoringJob\",\u00a0 \"labels\": {\u00a0 \u00a0 \"model_deployment_monitoring_job\": \"6680511704087920640\",\u00a0 \u00a0 \"location\": \"us-central1\",\u00a0 \u00a0 \"resource_container\": \"projects/677687165274\"\u00a0 }},\"timestamp\": \"2022-02-04T15:33:54.778883Z\",\"severity\": \"INFO\",\"logName\": \"projects/model-monitoring-demo/logs/staging-aiplatform.sandbox.googleapis.com%2Fmodel_monitoring\",\"receiveTimestamp\": \"2022-02-04T15:33:56.343298321Z\"}\n```\nEach time a scheduled monitoring pipeline run fails, Model Monitoring sends a notification to the Cloud Monitoring notification channels you specified when creating the Model Monitoring job.\n## Configure alerts for feature anomalies\nModel Monitoring detects an anomaly when the threshold set for a feature is exceeded. Model Monitoring automatically notifies you of detected anomalies through email, but you can also set up alerts through Cloud Logging and Cloud Monitoring notification channels.\nAt each monitoring interval, if the threshold of at least one feature exceeds the threshold, Model Monitoring sends an email alert to each email address you specified when creating the Model Monitoring job. The email message includes the following:- The time at which the monitoring job ran.\n- The name of the feature that has skew or drift.\n- The alerting threshold as well as the recorded statistical distance measure.\nTo enable Cloud Logging alerts, set the `enableLogging` field of your [ModelMonitoringAlertConfig](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs#ModelMonitoringAlertConfig) configuration to `true` .\nAt each monitoring interval, an anomaly log is written to Cloud Logging if the distribution of at least one feature exceeds the threshold for that feature. You can forward logs to any service that Cloud Logging supports, such as Pub/Sub.\nAnomalies are written to Cloud Logging with the log name: `model_monitoring_anomaly` . For example:\n```\nlogName=\"projects/model-monitoring-demo/logs/aiplatform.googleapis.com%2Fmodel_monitoring_anomaly\" resource.labels.model_deployment_monitoring_job=6680511704087920640\n```\nHere is an example of an anomaly log entry:\n```\n{\"insertId\": \"b0e9c0e9-0979-4aff-a5d3-4c0912469f9a@a1\",\"jsonPayload\": {\u00a0 \"anomalyObjective\": \"RAW_FEATURE_SKEW\",\u00a0 \"endTime\": \"2022-02-03T19:00:00Z\",\u00a0 \"featureAnomalies\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"featureDisplayName\": \"age\",\u00a0 \u00a0 \u00a0 \"deviation\": 0.9,\u00a0 \u00a0 \u00a0 \"threshold\": 0.7\u00a0 \u00a0 },\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"featureDisplayName\": \"education\",\u00a0 \u00a0 \u00a0 \"deviation\": 0.6,\u00a0 \u00a0 \u00a0 \"threshold\": 0.3\u00a0 \u00a0 }\u00a0 ],\u00a0 \"totalAnomaliesCount\": 2,\u00a0 \"@type\": \"type.googleapis.com/google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry\",\u00a0 \"startTime\": \"2022-02-03T18:00:00Z\",\u00a0 \"modelDeploymentMonitoringJob\": \"projects/677687165274/locations/us-central1/modelDeploymentMonitoringJobs/6680511704087920640\",\u00a0 \"deployedModelId\": \"1645828169292316672\"},\"resource\": {\u00a0 \"type\": \"aiplatform.googleapis.com/ModelDeploymentMonitoringJob\",\u00a0 \"labels\": {\u00a0 \u00a0 \"model_deployment_monitoring_job\": \"6680511704087920640\",\u00a0 \u00a0 \"location\": \"us-central1\",\u00a0 \u00a0 \"resource_container\": \"projects/677687165274\"\u00a0 }},\"timestamp\": \"2022-02-03T19:00:00Z\",\"severity\": \"WARNING\",\"logName\": \"projects/model-monitoring-demo/logs/staging-aiplatform.sandbox.googleapis.com%2Fmodel_monitoring_anomaly\",\"receiveTimestamp\": \"2022-02-03T19:59:52.121398388Z\"}\n```\nAt each monitoring interval, if the threshold of at least one feature exceeds the threshold, Model Monitoring sends an alert to the Cloud Monitoring notification channels you specified when creating the Model Monitoring job. The alert includes information about the Model Monitoring job that triggered the alert.\n## Update a Model Monitoring job\nYou can view, update, pause, and delete a Model Monitoring job. You must pause a job before you can delete it.\nPausing and deleting are not supported in the Google Cloud console; use the gcloud CLI instead.\nTo update parameters for a Model Monitoring job:- In the Google Cloud console, go to the **Vertex AI Endpoints** page. [Go to Endpoints](https://console.cloud.google.com/vertex-ai/endpoints/) \n- Click the name of the endpoint you want to edit.\n- Click **Edit settings** .\n- In the **Edit endpoint** pane, select **Model monitoring** or **Monitoringobjectives** . **Note:** To enable Model Monitoring for an existing endpoint, make sure **Enable model monitoring for this endpoint** is toggled on under **Model monitoring** .\n- Update the fields you want to change.\n- Click **Update** .\nTo view metrics, alerts, and monitoring properties for a model:- In the Google Cloud console, go to the **Vertex AI Endpoints** page. [Go to Endpoints](https://console.cloud.google.com/vertex-ai/endpoints/) \n- Click the name of the endpoint.\n- In the **Monitoring** column for the model you want to view, click **Enabled** .\nRun the following command:\n```\ngcloud ai model-monitoring-jobs COMMAND MONITORING_JOB_ID \\\n --PARAMETER=VALUE --project=PROJECT_ID --region=LOCATION\n```\nwhere:- is the command you want to perform on the monitoring job. For example, `update` , `pause` , `resume` , or `delete` . For more information, see the [gcloud CLI reference](/sdk/gcloud/reference/ai/model-monitoring-jobs) .\n- is the ID of your monitoring job. For example, `123456789` . You can find the ID by [retrieving the endpoint information][retrieve-id] or viewing **Monitoring properties** for a model in the Google Cloud console. The ID is included in the monitoring job resource name in the format `projects/` `` `/locations/` `` `/modelDeploymentMonitoringJobs/` `` .\n- (optional) is the parameter you want to update. This flag is required only when using the `update` command. For example, `monitoring-frequency=2` . For a list of parameters you can update, see the [gcloud CLI reference](/sdk/gcloud/reference/ai/model-monitoring-jobs/update) .\n- is the ID for your Google Cloud project. For example, `my-project` .\n- is the location for your monitoring job. For example, `us-central1` .\n### Pause a job\nBefore using any of the request data, make the following replacements:- : The number of your Google Cloud project. For  example,`1234567890`.\n- : Location for your monitoring job. For example,`us-central1`.\n- : ID of your monitoring job. For  example,`0987654321`.\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{}\n```\n### Delete a job\nBefore using any of the request data, make the following replacements:- : The number of your Google Cloud project. For  example,`my-project`.\n- : Location for your monitoring job. For example,`us-central1`.\n- : ID of your monitoring job. For  example,`0987654321`.\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION/operations/MONITORING_JOB_ID\",\n ...\n \"done\": true,\n ...\n}\n```\n## Analyze skew and drift data\nYou can use the Google Cloud console to visualize the distributions of each monitored feature and learn which changes led to skew or drift over time. You can view the feature value distributions as a histogram.\n- To navigate to the feature distribution histograms in the Google Cloud console, go to the **Endpoints** page. [Go to Endpoints](https://console.cloud.google.com/vertex-ai/endpoints/) \n- On the **Endpoints** page, click the endpoint you want to analyze.\n- On the detail page for the endpoint you selected, there is a list of all the models deployed on that endpoint. Click the name of a model to analyze.\n- The details page for the model lists the model's input features, along with pertinent information, such as the alert threshold for each feature and the number of prior alerts for the feature.\n- To analyze a feature, click the name of the feature. A page shows the feature distribution histograms for that feature.For each monitored feature, you can view the distributions of the 50 most recent monitoring jobs in the Google Cloud console. For skew detection, the training data distribution is displayed right next to the input data distribution:Visualizing data distribution as histograms lets you quickly focus on the changes that occurred in the data. Afterward, you might decide to adjust your feature generation pipeline or retrain the model.## What's next\n- Work with Model Monitoring following the [API docs](/vertex-ai/docs/reference/rest/v1/projects.locations.modelDeploymentMonitoringJobs) .\n- Work with Model Monitoring following the [gcloud CLI docs](/sdk/gcloud/reference/ai/model-monitoring-jobs) .\n- Try the example notebook [in Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) or [view it onGitHub](https://www.github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) .\n- Learn how Model Monitoring [calculates training-servingskew and prediction drift](/vertex-ai/docs/model-monitoring/overview) .", "guide": "Vertex AI"}