{"title": "Vertex AI - Run a pipeline", "url": "https://cloud.google.com/vertex-ai/docs/pipelines/run-pipeline", "abstract": "# Vertex AI - Run a pipeline\nVertex AI Pipelines lets you run machine learning (ML) pipelines that were built using the Kubeflow Pipelines SDK or TensorFlow Extended in a serverless manner. This document describes how to run an ML pipeline.\nYou can also create pipeline runs using prebuilt templates in the **Template Gallery** . For more information about the **Template Gallery** , see [Use a prebuilt template from the Template Gallery](/vertex-ai/docs/pipelines/use-template-gallery) .\n", "content": "## Before you begin\nBefore you run a pipeline with Vertex AI Pipelines, use the following instructions to set up your Google Cloud project and development environment:\n- [Build a pipeline.](/vertex-ai/docs/pipelines/build-pipeline) \n- To run a pipeline using the Vertex AI SDK for Python, install the Vertex SDK.- Install the [Vertex AI SDK](https://github.com/googleapis/python-aiplatform) .\n## Create a pipeline run\nUse the following instructions to run an ML pipeline using Google Cloud console or Python.\nUse the following instructions to run an ML pipeline using Google Cloud console.- In the Google Cloud console, in the **Vertex AI** section, go to the **Pipelines** page. [Go to Pipelines](https://console.cloud.google.com/vertex-ai/pipelines) \n- In the **Region** drop-down list, select the region to create the pipeline run.\n- Click **add_boxCreate run** to open the **Create pipeline run** pane.\n- In the **Run details** section, do the following:- Click a **Run source** . The following options are available:- **Select from existing pipelines** : To create a pipeline run based on an existing pipeline template, click **Select from existing pipelines** and enter the following details:- Select the **Repository** containing the pipeline or component definition file.\n- Select the **Pipeline or component** and **Version** .\n- Specify a **Run name** to uniquely identify the pipeline run.\n- **Select a Template Gallery pipeline** : To create a pipeline run based on a Google-authored pipeline template from the **Template Gallery** , click **Select a Template Gallery pipeline** and enter the following details:- In the **Template Gallery pipeline** list, select the pipeline template.\n- Optional: Modify the default **Run name** that uniquely identifies the pipeline run.\n **Note:** These instructions describe how to create a pipeline run using the default interface of the **Create pipeline run** page, which includes the **Run details** and the **Runtime configuration** sections. For some templates from the **Template gallery** , this page has additional sections. For example, the **AutoML for Tabular Classification / Regression** template also includes the **Training Method** , **Training options** , and **Compute and pricing** sections.\n- **Upload file** : To upload a compiled pipeline definition, click **Upload file** and enter the following details:- Click **Browse** to open the file selector. Navigate to the compiled pipeline YAML file that you want to run, select the pipeline, and click **Open** .\n- The **Pipeline or component name** shows the name specified in the pipeline definition, by default. Optionally, specify a different Pipeline name.\n- Specify a **Run name** to uniquely identify the pipeline run.\n- **Import from Cloud Storage** : To import a pipeline definition file from Cloud Storage, click **Import from Cloud Storage** and enter the following details:- Click **Browse** to navigate to the Cloud Storage bucket containing the pipeline definition object, select the file, and then click **Select** .\n- Specify the **Pipeline or component name** .\n- Specify a **Run name** to uniquely identify the pipeline run.\n- Optional: To schedule recurring pipeline runs, specify the **Run schedule** , as follows:- Select **Recurring** .\n- Under **Start time** , specify when the schedule becomes active.- To schedule the first run to occur immediately after schedule creation, select **Immediately** .\n- To schedule the first run to occur at a specific time and date, select **On** .\n- In the **Frequency** field, specify the frequency to schedule and execute the pipeline runs, using a cron schedule expression based on [unix-cron](https://man7.org/linux/man-pages/man5/crontab.5.html) .\n- Under **Ends** , specify when the schedule ends.- To indicate that the schedule creates pipeline runs indefinitely, select **Never** .\n- To indicate that the schedule ends on a specific date and time, select **On** , and specify the end date and time for the schedule.\n- Optional: To specify that the pipeline run uses a custom service account, a customer-managed encryption key (CMEK), or a peered VPC network, click **Advanced options** , and then follow these instructions:- To specify a service account, select a service account from the **Service account** drop-down list.If you don't specify a service account, Vertex AI Pipelines runs your pipeline using the default Compute Engine service account.Learn more about [configuring a service account for use withVertex AI Pipelines](/vertex-ai/docs/pipelines/configure-project#service-account) .\n- To use a CMEK, select **Use a customer-managed encryption key** . The **Select a customer-managed key** drop-down list appears. In the **Select a customer-managed key** drop-down list, select the key that you want to use.\n- To use a peered VPC network in this pipeline run, enter the VPC network name in the **Peered VPC network** box.\n- Click **Continue** .\n- In the **Runtime configuration** section, configure the pipeline run, as follows:- Under **Cloud storage location** , click **Browse** to select the Cloud Storage bucket for storing the pipeline output artifacts, and then click **Select** .\n- Optional: To configure the failure policy and the cache for the pipeline run, click **Advanced options** , and then use the following instructions:- Under **Failure policy** , specify the failure policy for the entire pipeline. [Learn more about pipeline failure policies.](/vertex-ai/docs/pipelines/configure-failure-policy) - To configure the pipeline to continue scheduling tasks after one task fails, select **Run all steps to completion** . This option is selected, by default.\n- To configure the pipeline to fail after one task fails, select **Fail this run as soon as one step fails** .\n- Under **Caching configuration** , specify the cache configuration for the entire pipeline.- To use the task-level cache configuration for task in the pipeline, select **Do not override task-level cache configuration** .\n- To turn on caching for all the tasks in the pipeline and override any task-level cache configuration, select **Enable read from cache for all steps (fastest)** .\n- To turn off caching for all the tasks in the pipeline and override any task-level cache configuration, select **Disable read from cache for all steps (fastest)** .\n- Optional: If your pipeline has parameters, under **Pipeline parameters** , specify your pipeline run parameters.\n- To create your pipeline run, click **Submit** .\nUse the following instructions to run an ML pipeline using the Vertex AI SDK for Python. Before you run the following code sample, you must set up authentication.\n### Set up authentication\nTo set up authentication, you must create a service account key, and set an environment variable for the path to the service account key.- Create a service account:- In the Google Cloud console, go to the **Create service account** page. [Go to Create service account](https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts/create?supportedpurview=project) \n- In the **Service account name** field, enter a name.\n- Optional: In the **Service account description** field, enter a description.\n- Click **Create** .\n- Click the **Select a role** field. Under **All roles** , select **Vertex AI** > **Vertex AI User** .\n- **Note** : The roles you select allow your service account to access resources. You can   view and change these roles later by using the [Google Cloud console](https://console.cloud.google.com/) . For more information, see [access control for   Vertex AI](/vertex-ai/docs/general/access-control#predefined_roles) .\n- Click **Done** to create the service account.Do not close your browser window. You will use it in the next step.\n- Create a service account key for authentication:- In the Google Cloud console, click the email address for the service account that you   created.\n- Click **Keys** .\n- Click **Add key** , then **Create new key** .\n- Click **Create** . A JSON key file is downloaded to your computer.\n- Click **Close** .\n- Grant your new service account access to the service account that you use to run pipelines.- Clickarrow_backto return to the   list of service accounts.\n- Click the name of the service account that you use to run pipelines. The **Service account details** page appears.If you followed the instructions in the guide to configuring your project for   Vertex AI Pipelines, this is the same service account that you created in the [Configure a service account   with granular permissions](/vertex-ai/docs/pipelines/configure-project#service-account) section. Otherwise, Vertex AI uses the   Compute Engine default service account to run pipelines. The Compute Engine default   service account is named like the following: `` `-compute@developer.gserviceaccount.com`\n- Click the **Permissions** tab.\n- Click **Grant access** . The **Add principals** panel   appears.\n- In the **New principals** box, enter the email address for the service   account you created in a previous step.\n- In the **Role** drop-down list, select **Service accounts** > **Service account user** .\n- Click **Save** \n- Set the environment variable to the path of the JSON file that contains your service account key.   This variable only applies to your current shell session, so if you open   a new session, set the variable again. **Example:** Linux or macOSReplace with the path of the JSON file that    contains your service account key.```\nexport GOOGLE_APPLICATION_CREDENTIALS=\"[PATH]\"\n```For example:```\nexport GOOGLE_APPLICATION_CREDENTIALS=\"/home/user/Downloads/service-account-file.json\"\n``` **Example:** WindowsReplace with the path of the JSON file that    contains your service account key, and with the    filename.With PowerShell:```\n$env:GOOGLE_APPLICATION_CREDENTIALS=\"[PATH]\"\n```For example:```\n$env:GOOGLE_APPLICATION_CREDENTIALS=\"C:\\Users\\username\\Downloads\\[FILE_NAME].json\"\n```With command prompt:```\nset GOOGLE_APPLICATION_CREDENTIALS=[PATH]\n```\n### Run a pipelineRunning a Vertex AI `PipelineJob` requires you to create a `PipelineJob` object, and then invoke the `submit` method.While creating a pipeline run, you can also pass the following placeholders supported by the KFP SDK as inputs:- `{{$.pipeline_job_name_placeholder}}`\n- `{{$.pipeline_job_resource_name_placeholder}}`\n- `{{$.pipeline_job_id_placeholder}}`\n- `{{$.pipeline_task_name_placeholder}}`\n- `{{$.pipeline_task_id_placeholder}}`\n- `{{$.pipeline_job_create_time_utc_placeholder}}`\n- `{{$.pipeline_root_placeholder}}`\nFor more information, see [Special input types](https://www.kubeflow.org/docs/components/pipelines/v2/pipelines/pipeline-basics/#special-input-types) in the [Kubeflow Pipelines v2 documentation](https://www.kubeflow.org/docs/components/pipelines/v2/introduction/) .```\nfrom google.cloud import aiplatformjob = aiplatform.PipelineJob(display_name = DISPLAY_NAME,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0template_path = COMPILED_PIPELINE_PATH,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0job_id = JOB_ID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0pipeline_root = PIPELINE_ROOT_PATH,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0parameter_values = PIPELINE_PARAMETERS,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0enable_caching = ENABLE_CACHING,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0encryption_spec_key_name = CMEK,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0labels = LABELS,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0credentials = CREDENTIALS,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0project = PROJECT_ID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0location = LOCATION,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0failure_policy = FAILURE_POLICY)job.submit(service_account=SERVICE_ACCOUNT,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0network=NETWORK)\n```\nReplace the following:- : The name of the pipeline, this will show up in the Google Cloud console.\n- : The path to your compiled pipeline YAML file. It can be a local path or a Cloud Storage URI. Optional: To specify a particular version of a compiled pipeline, include the version tag in any one of the following formats:- `` `:` `` , where is the version tag.\n- `` `@` `` , where is the `sha256` hash value of the pipeline version.\n- : ( ) A unique identifier for this pipeline run. If the job ID is not specified, Vertex AI Pipelines creates a job ID for you using the pipeline name and the timestamp of when the pipeline run was started.\n- : ( ) To override the pipeline root path specified in the pipeline definition, specify a path that your pipeline job can access, such as a Cloud Storage bucket URI.\n- : ( ) The pipeline parameters to pass to this run. For example, create a `dict()` with the parameter names as the dictionary keys and the parameter values as the dictionary values.\n- : ( ) Specifies if this pipeline run uses execution caching. Execution caching reduces costs by skipping pipeline tasks where the output is known for the current set of inputs. If the enable caching argument is not specified, execution caching is used in this pipeline run. [Learn more about execution caching](/vertex-ai/docs/pipelines/build-pipeline#caching) .\n- : ( ) The name of the customer-managed encryption key that you want to use for this pipeline run.\n- : ( ) The user defined labels to organize this `PipelineJob` . For more information about resource labels, see [Creating and managing labels](/resource-manager/docs/creating-managing-labels) in the [Resource Manager documentation](/resource-manager/docs) .Vertex AI Pipelines automatically attaches the following label to your pipeline run:`vertex-ai-pipelines-run-billing-id: pipeline_run_id`where `pipeline_run_id` is the unique ID of the pipeline run.This label connects the usage of Google Cloud resources generated by the pipeline run in billing reports.\n- : ( ) Custom credentials to use to create this `PipelineJob` . Overrides credentials set in `aiplatform.init` .\n- : ( ) The Google Cloud project that you want to run the pipeline in. If you don't set this parameter, the project set in `aiplatform.init` is used.\n- : ( ) The region that you want to run the pipeline in. For more information about the regions that Vertex AI Pipelines is available in, see the [Vertex AI locations guide](/vertex-ai/docs/general/locations#feature-availability) . If you don't set this parameter, the default location set in `aiplatform.init` is used.\n- : ( ) Specify the failure policy for the entire pipeline. The following configurations are available:- To configure the pipeline to fail after one task fails, enter `fast` .\n- To configure the pipeline to continue scheduling tasks after one task fails, enter `slow` .\nIf you don't set this parameter, the failure policy configuration is set to `slow` , by default. [Learn more about pipeline failure policies.](/vertex-ai/docs/pipelines/configure-failure-policy) \n- : ( ) The name of the service account to use for this pipeline run. If you don't specify a service account, Vertex AI Pipelines runs your pipeline using the default Compute Engine service account.\n- : ( ) :The name of the VPC peered network to use for this pipeline run.", "guide": "Vertex AI"}