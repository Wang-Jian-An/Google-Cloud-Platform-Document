{"title": "Vertex AI - Vector Search quickstart", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Vector Search quickstart\nIn the Vertex AI Vector Search quickstart, learn how to create an index out of a sample dataset from a fictitious ecommerce clothing site. For the purpose of this quickstart, the embeddings have already been created. This quickstart is intended to be a way to get started creating and deploying an index in under 30 minutes.\n", "content": "## Prerequisites\nThis tutorial requires a Google Cloud project that is linked with a billing account. To create a new project, see [Set up a project and development environment](/vertex-ai/docs/start/cloud-environment) . You need to create a project and set up your billing account.\n### Choose the runtime environment\nThis tutorial can be run on either Colab or Vertex AI Workbench.\n- **Colab** : Open this tutorial in [Colab](https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/embeddings/vector-search-quickstart.ipynb) \n- **Vertex AI Workbench** : Open this tutorial in [Vertex AI Workbench](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/embeddings/vector-search-quickstart.ipynb) . If this is the first time you're using Vertex AI Workbench in your Google Cloud project, go to the Vertex AI Workbench section of the Google Cloud console and click **Enable** to enable the Notebooks API.\nTo view this notebook in GitHub, see [GitHub](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/vector-search-quickstart.ipynb) .\n### Cost to complete this quickstart\nTo complete this tutorial costs roughly a few US dollars. The pricing of the Google Cloud services used in this tutorial are available in the following pages:\n- [Vertex AI Vector Search](/vertex-ai/pricing#matchingengine) \n- [Cloud Storage](https://cloud.google.com/storage/pricing) \n- [Vertex AI Workbench](/vertex-ai/pricing#notebooks) \nYou can also use the [pricing calculator](/vertex-ai/pricing#generative_ai_models) to generate a cost estimate based on your projected usage.\n**Important:** Delete your objects after the tutorial. Make sure to delete all of the indexes, index endpoints, Cloud Storage buckets, and the Vertex AI Workbench instance if you use one after finishing this tutorial. If these object are not deleted, these remaining assets can incur unexpected costs.\n## Setup\nBefore you get started with Vertex AI, you need to set up the following:\n- [Install the Vertex AI SDK for Python](#install-sdk) \n- [Set environment variables](#variables) \n- [Authenticate (Colab only)](#authentication) \n- [Set IAM permissions](#permissions) \n- [Enable APIs](#enable-apis) \n### Install the Vertex AI SDK for Python\nVertex AI and Cloud Storage APIs can be accessed multiple ways, including REST API and Vertex AI SDK for Python. In this tutorial, the Vertex AI SDK for Python is used.\n```\n!pip install --upgrade --user google-cloud-aiplatform>=1.29.0 google-cloud-storage\n```\nTo use the newly installed packages in this Jupyter runtime, you need to restart the runtime, as shown in the following code snippet.\n```\n# Restart kernel after installs so that your environment can access the new packagesimport IPythonapp = IPython.Application.instance()app.kernel.do_shutdown(True)\n```\n### Environment variables\nSet the environment variables. If asked, replace `your-project-id` with your project ID and run the cell.\n```\n# get project IDPROJECT_ID = ! gcloud config get-value projectPROJECT_ID = PROJECT_ID[0]LOCATION = \"us-central1\"if PROJECT_ID == \"(unset)\":\u00a0 \u00a0 print(f\"Please set the project ID manually below\")\n```\n```\n# define project informationif PROJECT_ID == \"(unset)\":\u00a0 PROJECT_ID = \"[your-project-id]\"# generate a unique id for this sessionfrom datetime import datetimeUID = datetime.now().strftime(\"%m%d%H%M\")\n```\nIf you are running this notebook on Colab, you need to run the following cell authentication. This step is not required if you are using Vertex AI Workbench as it is pre-authenticated.\n```\nimport sys# if it's Colab runtime, authenticate the user with Google Cloudif 'google.colab' in sys.modules:\u00a0 \u00a0 from google.colab import auth\u00a0 \u00a0 auth.authenticate_user()\n```\n### Set IAM permissions\nYou need to add access permissions to the default service account for using the services.\n- Go to the IAM page in the Google Cloud console.\n- Look for the principal for default compute service account. It should look like:``\n- Click the edit button and grant the default compute service account with the following roles: Vertex AI User and Storage Admin and Service Usage Admin.\n### Enable APIs\nRun the following command to enable APIs for Compute Engine, Vertex AI, and Cloud Storage with this Google Cloud project.\n```\n! gcloud services enable compute.googleapis.com aiplatform.googleapis.com storage.googleapis.com --project {PROJECT_ID}\n```\n## Prepare the sample data\nIn this tutorial, we use the [TheLook dataset](https://console.cloud.google.com/marketplace/product/bigquery-public-data/thelook-ecommerce) that has a products table with about 30,000 rows of synthetic product data for a fictitious ecommerce clothing site.\nFrom this table, we have prepared the `product-embs.json` file.\nThis file is in JSONL format and each row has ID for the product ID, name for the product name, and embedding for the embedding of the product name in 768 dimensions which was generated previously with Vertex AI embeddings for text.\nThe text embeddings represent the meaning of the clothing product names. In this tutorial, we use Vector Search for completing a semantic search of the items. This sample code can be used as a basis for other quick recommendation systems where you can quickly find \"other products similar to this one\".\nTo learn more about how to create the embeddings from the data on a BigQuery table and store them in a JSON file, see [Getting Started with Text Embeddings + Vertex AI Vector Search](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/embeddings/intro-textemb-vectorsearch.ipynb) .\n### Prepare the data on Cloud Storage\nFor building an index with Vertex AI, place the embedding file in a Cloud Storage bucket. The following code completes two tasks:\n- Creates a Cloud Storage bucket.\n- Copies the example file to your Cloud Storage bucket.\n```\nBUCKET_URI = f\"gs://{PROJECT_ID}-vs-quickstart-{UID}\"\n```\n```\n! gsutil mb -l $LOCATION -p $PROJECT_ID $BUCKET_URI! gsutil cp \"gs://github-repo/data/vs-quickstart/product-embs.json\" $BUCKET_URI\n```\nFor using Vector Search to run queries, you also need to copy the embedding file to local directory:\n```\n! gsutil cp \"gs://github-repo/data/vs-quickstart/product-embs.json\" . # for query tests\n```\n## Build and deploy a Vector Search index\nLearn how to create an index, create an index endpoint, and then deploy your index to the endpoint.\n### Create an index\nNow it's time to load the embeddings to Vector Search. The APIs are available under the `aiplatform` package of the SDK.\n```\n# init the aiplatform packagefrom google.cloud import aiplatformaiplatform.init(project=PROJECT_ID, location=LOCATION)\n```\nCreate a [MatchingEngineIndex](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.MatchingEngineIndex) with its `create_tree_ah_index` function (Matching Engine is the previous name of Vector Search).\n```\n# create Indexmy_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\u00a0 \u00a0 display_name = f\"vs-quickstart-index-{UID}\",\u00a0 \u00a0 contents_delta_uri = BUCKET_URI,\u00a0 \u00a0 dimensions = 768,\u00a0 \u00a0 approximate_neighbors_count = 10,)\n```\nThe `MatchingEngineIndex.create_tree_ah_index()` method builds an index. This takes under 10 minutes if the dataset is small, otherwise about 60 minutes or more depending on the size of the dataset. You can check status of the index creation on the Vector Search Google Cloud console\n[See Indexes](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)\nThe parameters for creating index:\n- `contents_delta_uri`: the URI of Cloud Storage directory where you stored the embedding JSON files\n- `dimensions`: dimension size of each embedding. In this case, it is 768 as you are using the embeddings from the text embeddings API.\n- `approximate_neighbors_count`: how many similar items you want to retrieve in typical cases\nTo learn more about creating the index and the available parameters, see [Create and manage your index](/vertex-ai/docs/vector-search/create-manage-index)\n### Create index endpoint and deploy the index\nTo use the index, you need to create an index endpoint. It works as a server instance accepting query requests for your index.\n```\n## create `IndexEndpoint`my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\u00a0 \u00a0 display_name = f\"vs-quickstart-index-endpoint-{UID}\",\u00a0 \u00a0 public_endpoint_enabled = True)\n```\nWith the index endpoint, deploy the index by specifying a unique deployed index ID.\n```\nDEPLOYED_INDEX_ID = f\"vs_quickstart_deployed_{UID}\"\n```\n```\n# deploy the Index to the Index Endpointmy_index_endpoint.deploy_index(\u00a0 \u00a0 index = my_index, deployed_index_id = DEPLOYED_INDEX_ID)\n```\nIf it is the first time deploying this index to an index endpoint, it can take around 30 minutes to automatically build and initiate the backend. To see the status of the index deployment, in the Vertex AI section of the Google Cloud console, go to the **Deploy and Use** section. Select **Indexes**\n[See Indexes](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)\n## Run a query with Vector Search\nIn the following code, it finds an embedding for a specified product name, and finds similar product names with the Vector Search.\n### Get an embedding to run a query\nFirst, load the embedding JSON file to build a `dict` of product names and embeddings.\n```\nimport json# build dicts for product names and embsproduct_names = {}product_embs = {}with open('product-embs.json') as f:\u00a0 \u00a0 for l in f.readlines():\u00a0 \u00a0 \u00a0 \u00a0 p = json.loads(l)\u00a0 \u00a0 \u00a0 \u00a0 id = p['id']\u00a0 \u00a0 \u00a0 \u00a0 product_names[id] = p['name']\u00a0 \u00a0 \u00a0 \u00a0 product_embs[id] = p['embedding']\n```\nWith the `product_embs` dictionary, you can specify a product ID to get an embedding for it.\n```\n\u00a0# Get the embedding for ID 6523 \"cloudveil women's excursion short\"\u00a0you can also try with other IDs such as 12711, 18090, 19536 and 11863query_emb = product_embs['6523']\n```\n### Run a query\nPass the embedding to `Endpoint.find_neighbors()` method to find similar product names.\n```\n# run queryresponse = my_index_endpoint.find_neighbors(\u00a0 \u00a0 deployed_index_id = DEPLOYED_INDEX_ID,\u00a0 \u00a0 queries = [query_emb],\u00a0 \u00a0 num_neighbors = 10)# show the resultsfor idx, neighbor in enumerate(response[0]):\u00a0 \u00a0 print(f\"{neighbor.distance:.2f} {product_names[neighbor.id]}\")\n```\nThe `find_neighbors()` method only takes milliseconds to fetch the similar items even when you have billions of items on the index, thanks to the [ScaNN algorithm](https://blog.research.google/2020/07/announcing-scann-efficient-vector.html) . Vector Search also supports autoscaling which can automatically resize the number of nodes based on the demands of your workloads.\n## Cleaning up\nIn case you are using your own Cloud project, not a temporary project on Qwiklabs, make sure to delete all of the indexes, index endpoints, and Cloud Storage buckets after finishing this tutorial. Otherwise, you might incur unexpected costs from the remaining resources.\nIf you used Workbench, you might also need to delete the notebooks from the console.\n```\n# wait for a confirmationinput(\"Press Enter to delete Index Endpoint, Index and Cloud Storage bucket:\")# delete Index Endpointmy_index_endpoint.undeploy_all()my_index_endpoint.delete(force = True)# delete Indexmy_index.delete()# delete Cloud Storage bucket! gsutil rm -r {BUCKET_URI}\n```\n## Utilities\nIt can take some time to create or deploy indexes, and in that time you might lose connection with the Colab runtime. If you lose connection, instead of creating or deploying your new index again, you can check the Vector Search Google Cloud console and use the existing ones to continue.\n### Get an existing index\nTo get an index object that already exists, replace the following `your-index-id` with the index ID and run the cell. You can get the index ID by checking the Vector Search Google Cloud console. In the Vertex AI section of the Google Cloud console, go to the **Deploy and Use** section. Select **Indexes**\n[See Indexes](https://console.cloud.google.com/vertex-ai/matching-engine/indexes)\n```\nmy_index_id = \"[your-index-id]\"my_index = aiplatform.MatchingEngineIndex(my_index_id)\n```\n### Get an existing index endpoint\nTo get an index endpoint object that already exists, replace the following `your-index-endpoint-id` with the index endpoint ID and run the cell. You can get the index endpoint by checking the Vector Search Google Cloud console. In the Vertex AI section of the Google Cloud console, go to the **Deploy and Use** section. Select **Index Endpoints**\n[See Index Endpoints](https://console.cloud.google.com/vertex-ai/matching-engine/index-endpoints)\n```\nmy_index_endpoint_id = \"[your-index-endpoint-id]\"my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(my_index_endpoint_id)\n```", "guide": "Vertex AI"}