{"title": "Vertex AI - Query data in BigQuery from within JupyterLab", "url": "https://cloud.google.com/vertex-ai/docs/workbench/managed/bigquery", "abstract": "# Vertex AI - Query data in BigQuery from within JupyterLab\n# Query data in BigQuery from within JupyterLab\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\nThis page shows you how to query data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench managed notebooks instance.\n", "content": "## Methods for querying BigQuery data in notebook (IPYNB) files\nTo query BigQuery data from within a JupyterLab notebook file, you can use the `%%bigquery` magic command and the BigQuery client library for Python.\nManaged notebooks instances also include a BigQuery integration that lets you browse and query data from within the JupyterLab interface.\nThis page describes how to use each of these methods.\n## Before you begin\nIf you haven't already, [createa managed notebooks instance](/vertex-ai/docs/workbench/managed/create-instance#create) .\n## Open JupyterLab\n- In the Google Cloud console, go to the **Managed notebooks** page. [Go to Managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/managed) \n- Next to your managed notebooks instance's name, click **Open JupyterLab** .Your managed notebooks instance opens JupyterLab.## Browse BigQuery resources\nThe BigQuery integration provides a pane for browsing the BigQuery resources that you have access to.\n- In the JupyterLab navigation menu, click **BigQuery in Notebooks** .The **BigQuery** pane lists available projects and datasets, where you can perform tasks as follows:- To view a description of a dataset, double-click the dataset name.\n- To show a dataset's tables, views, and models, expand the dataset.\n- To open a summary description as a tab in JupyterLab, double-click a table, view, or model.\n **Note:** On the summary description for a table, click the **Preview** tab to preview a table's data. The following image shows a preview of the [international_top_terms table](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=google_trends&t=international_top_terms&page=table) found in the `google_trends` dataset in the `bigquery-public-data` project: ## Query data by using the %%bigquery magic command\nIn this section, you write SQL directly in notebook cells and read data from BigQuery into the Python notebook.\nMagic commands that use a single or double percentage character ( `%` or `%%` ) let you use minimal syntax to interact with BigQuery within the notebook. The BigQuery client library for Python is automatically installed in a managed notebooks instance. Behind the scenes, the `%%bigquery` magic command uses the BigQuery client library for Python to run the given query, convert the results to a pandas DataFrame, optionally save the results to a variable, and then display the results.\n**Note** : As of version 1.26.0 of the `google-cloud-bigquery` Python package, the [BigQuery Storage API](/bigquery/docs/reference/storage) is used by default to download results from the `%%bigquery` magics.\n- To open a notebook file, select **File > New >Notebook** .\n- In the **Select Kernel** dialog, select **Python (Local)** , and then click **Select** .Your new IPYNB file opens.\n- To get the number of regions by country in the `international_top_terms` dataset, enter the following statement:```\n%%bigquerySELECT\u00a0 country_code,\u00a0 country_name,\u00a0 COUNT(DISTINCT region_code) AS num_regionsFROM\u00a0 `bigquery-public-data.google_trends.international_top_terms`WHERE\u00a0 refresh_date = DATE_SUB(CURRENT_DATE, INTERVAL 1 DAY)GROUP BY\u00a0 country_code,\u00a0 country_nameORDER BY\u00a0 num_regions DESC;\n```\n- Click play_circle_filled **Run cell** .The output is similar to the following:```\nQuery complete after 0.07s: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 1440.60query/s]\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:02<00:00, 20.21rows/s]\ncountry_code  country_name num_regions\n0 TR Turkey   81\n1 TH Thailand  77\n2 VN Vietnam  63\n3 JP Japan   47\n4 RO Romania  42\n5 NG Nigeria  37\n6 IN India   36\n7 ID Indonesia  34\n8 CO Colombia  33\n9 MX Mexico   32\n10 BR Brazil   27\n11 EG Egypt   27\n12 UA Ukraine  27\n13 CH Switzerland 26\n14 AR Argentina  24\n15 FR France   22\n16 SE Sweden   21\n17 HU Hungary  20\n18 IT Italy   20\n19 PT Portugal  20\n20 NO Norway   19\n21 FI Finland  18\n22 NZ New Zealand 17\n23 PH Philippines 17\n...\n``` **Note:** Your results might differ from what is above as the `google_trends` dataset being queried is refreshed with new data on an ongoing basis.\n- In the next cell (below the output from the previous cell), enter the following command to run the same query, but this time save the results to a new pandas DataFrame that's named `regions_by_country` . You provide that name by using an argument with the `%%bigquery` magic command.```\n%%bigquery regions_by_countrySELECT\u00a0 country_code,\u00a0 country_name,\u00a0 COUNT(DISTINCT region_code) AS num_regionsFROM\u00a0 `bigquery-public-data.google_trends.international_top_terms`WHERE\u00a0 refresh_date = DATE_SUB(CURRENT_DATE, INTERVAL 1 DAY)GROUP BY\u00a0 country_code, country_nameORDER BY\u00a0 num_regions DESC;\n``` **Note:** For more information about available arguments for the `%%bigquery` command, see the [client library magics documentation](/python/docs/reference/bigquery/latest/magics) .\n- Click play_circle_filled **Run cell** .\n- In the next cell, enter the following command to look at the first few rows of the query results that you just read in:```\nregions_by_country.head()\n```\n- Click play_circle_filled **Run cell** .The pandas DataFrame `regions_by_country` is ready to plot.## Query data by using the BigQuery client library directly\nIn this section, you use the BigQuery client library for Python directly to read data into the Python notebook.\nThe client library gives you more control over your queries and lets you use more complex configurations for queries and jobs. The library's integrations with pandas enable you to combine the power of declarative SQL with imperative code (Python) to help you analyze, visualize, and transform your data.\n**Note:** You can use a number of Python data analysis, data wrangling, and visualization libraries, such as `numpy` , `pandas` , `matplotlib` , and many others. Several of these libraries are built on top of a DataFrame object.\n- In the next cell, enter the following Python code to import the BigQuery client library for Python and initialize a client:```\nfrom google.cloud import bigqueryclient = bigquery.Client()\n```The BigQuery client is used to send and receive messages from the BigQuery API.\n- Click play_circle_filled **Run cell** .\n- In the next cell, enter the following code to retrieve the percentage of daily top terms in the US [top_terms](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=google_trends&t=top_terms&page=table) that overlap across time by number of days apart. The idea here is to look at each day's top terms and see what percentage of them overlap with the top terms from the day before, 2 days prior, 3 days prior, and so on (for all pairs of dates over about a month span).```\nsql = \"\"\"WITH\u00a0 TopTermsByDate AS (\u00a0 \u00a0 SELECT DISTINCT refresh_date AS date, term\u00a0 \u00a0 FROM `bigquery-public-data.google_trends.top_terms`\u00a0 ),\u00a0 DistinctDates AS (\u00a0 \u00a0 SELECT DISTINCT date\u00a0 \u00a0 FROM TopTermsByDate\u00a0 )SELECT\u00a0 DATE_DIFF(Dates2.date, Date1Terms.date, DAY)\u00a0 \u00a0 AS days_apart,\u00a0 COUNT(DISTINCT (Dates2.date || Date1Terms.date))\u00a0 \u00a0 AS num_date_pairs,\u00a0 COUNT(Date1Terms.term) AS num_date1_terms,\u00a0 SUM(IF(Date2Terms.term IS NOT NULL, 1, 0))\u00a0 \u00a0 AS overlap_terms,\u00a0 SAFE_DIVIDE(\u00a0 \u00a0 SUM(IF(Date2Terms.term IS NOT NULL, 1, 0)),\u00a0 \u00a0 COUNT(Date1Terms.term)\u00a0 \u00a0 ) AS pct_overlap_termsFROM\u00a0 TopTermsByDate AS Date1TermsCROSS JOIN\u00a0 DistinctDates AS Dates2LEFT JOIN\u00a0 TopTermsByDate AS Date2Terms\u00a0 ON\u00a0 \u00a0 Dates2.date = Date2Terms.date\u00a0 \u00a0 AND Date1Terms.term = Date2Terms.termWHERE\u00a0 Date1Terms.date <= Dates2.dateGROUP BY\u00a0 days_apartORDER BY\u00a0 days_apart;\"\"\"pct_overlap_terms_by_days_apart = client.query(sql).to_dataframe()pct_overlap_terms_by_days_apart.head()\n```The SQL being used is encapsulated in a Python string and then passed to the [query() method](/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_query) to run a query. The [to_dataframe method](/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJob#google_cloud_bigquery_job_QueryJob_to_dataframe) waits for the query to finish and downloads the results to a pandas DataFrame by using the BigQuery Storage API.\n- Click play_circle_filled **Runcell** .The first few rows of query results appear below the code cell.```\n days_apart num_date_pairs num_date1_terms overlap_terms pct_overlap_terms\n 0   0    32    800   800   1.000000\n 1   1    31    775   203   0.261935\n 2   2    30    750    73   0.097333\n 3   3    29    725    31   0.042759\n 4   4    28    700    23   0.032857\n``` **Note:** Your results might differ from what is above as the `google_trends` dataset being queried is refreshed with new data on an ongoing basis.\nFor more information about using BigQuery client libraries, see the quickstart [Using client libraries](/bigquery/docs/quickstarts/quickstart-client-libraries) .\n## Query data by using the BigQuery integration in managed notebooks\nThe BigQuery integration provides two additional methods for querying data. These methods are different from using the `%%bigquery` magic command.\n- The **In-cell query editor** is a cell type that you can use within your notebook files.\n- The **Stand-alone query editor** opens as a separate tab in JupyterLab.\nTo use the in-cell query editor to query data in a BigQuery table, complete the following steps:- In JupyterLab, open a notebook (IPYNB) file or [create anew one](/vertex-ai/docs/workbench/managed/create-managed-notebooks-instance#open-a-new-notebook-file) .\n- To create an in-cell query editor, click the cell, and then to the right of the cell, click the **BigQuery Integration** button. Or in a markdown cell, enter `#@BigQuery` .The BigQuery integration converts the cell into an in-cell query editor.\n- On a new line below `#@BigQuery` , write your query using the [supported statements and SQL dialects ofBigQuery](/bigquery/docs/reference/standard-sql/introduction) . If errors are detected in your query, an error message appears in the top right corner of the query editor. If the query is valid, the estimated number of bytes to be processed appears.\n- Click **Submit Query** . Your query results appear. By default, query results are paginated at 100 rows per page and limited to 1,000 rows total, but you can change these settings at the bottom of the results table. In the query editor, keep the query limited to only the data you need to verify your query. You'll run this query again in a notebook cell, where you can adjust the limit to retrieve the full results set if you want. **Note:** Query text and results persist after closing and reopening the notebook file.\n- You can click **Query and load as DataFrame** to automatically add a new cell that contains a code segment that imports the BigQuery client library for Python, runs your query in a notebook cell, and stores the results in a pandas dataframe named `df` .\nTo use the stand-alone query editor to query data in a BigQuery table, complete the following steps:- In JupyterLab, in the **BigQuery in Notebooks** pane, right-click a table, and select **Query table** , or double-click a table to open a description in a separate tab, and then click the **Query table** link.\n- Write your query using the [supported statements and SQL dialects ofBigQuery](/bigquery/docs/reference/standard-sql/introduction) . If errors are detected in your query, an error message appears in the top right corner of the query editor. If the query is valid, the estimated number of bytes to be processed appears.\n- Click **Submit Query** . Your query results appear. By default, query results are paginated at 100 rows per page and limited to 1,000 rows total, but you can change these settings at the bottom of the results table. In the query editor, keep the query limited to only the data you need to verify your query. You'll run this query again in a notebook cell, where you can adjust the limit to retrieve the full results set if you want.\n- You can click **Copy code for DataFrame** to copy a code segment that imports the BigQuery client library for Python, runs your query in a notebook cell, and stores the results in a pandas dataframe named `df` . Paste this code into a notebook cell where you want to run it.## View query history and reuse queries\nTo view your query history as a tab in JupyterLab, perform the following steps:\n- In the JupyterLab navigation menu, click **BigQuery in Notebooks** to open the **BigQuery** pane.\n- In the **BigQuery** pane, scroll down and click **Query history** . A list of your queries opens in a new tab, where you can perform tasks such as the following:- To view the details of a query such as its Job ID, when the query was run, and how long it took, click the query.\n- To revise the query, run it again, or copy it into your notebook for future use, click **Open query in editor** .**Note:** If you run queries after opening this tab, click refresh **Refresh** to show the most recent queries.\n## What's next\n- To see examples of how to visualize the data from your BigQuery tables, see [Explore and visualize datain BigQuery fromwithin JupyterLab](/vertex-ai/docs/workbench/managed/visualize-data-bigquery) .\n- To learn more about writing queries for BigQuery, see [Running interactive and batch query jobs](/bigquery/docs/running-queries) .\n- Learn how to [control access toBigQuery datasets](/bigquery/docs/control-access-to-resources-iam) .\n- Learn how to [access Cloud Storage buckets and filesfrom within JupyterLab](/vertex-ai/docs/workbench/managed/cloud-storage) .", "guide": "Vertex AI"}