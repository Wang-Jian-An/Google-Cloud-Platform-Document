{"title": "Vertex AI - Data bias metrics for Vertex AI", "url": "https://cloud.google.com/vertex-ai/docs/evaluation/data-bias-metrics", "abstract": "# Vertex AI - Data bias metrics for Vertex AI\n**    Preview     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nThis page describes evaluation metrics you can use to detect , which can appear in raw data and ground truth values even before you train the model. For the examples and notation on this page, we use a hypothetical college application dataset that we describe in detail in [Introduction to modelevaluation for fairness](/vertex-ai/docs/evaluation/intro-evaluation-fairness) .\nFor descriptions of metrics that are generated from post-training data, see [Model bias metrics](/vertex-ai/docs/evaluation/model-bias-metrics) .\n", "content": "## Overview\nIn our example college application dataset, we have 200 applicants from California in slice 1, and 100 Florida applicants in slice 2, labeled as follows:\n| Slice  | Reject | Accept |\n|:-----------|---------:|---------:|\n| California |  140 |  60 |\n| Florida |  80 |  20 |\nYou can generally interpret the sign for most metrics as follows:\n- Positive value: indicates a potential bias favoring slice 1 over slice 2.\n- Zero value: indicates no bias in between slice 1 and slice 2.\n- Negative value: indicates a potential bias in favoring slice 2 over slice 1.\nWe make a note where this doesn't apply to a metric.\n## Difference in Population Size\nmeasures whether there are more examples in slice 1 versus slice 2, normalized by total population of the two slices:\nn 1 \u2212 n 2 n 1 + n 2\n(total population of slice 1 - total population of slice 2) / (sum of populations in slice 1 and 2)\n**In our example dataset** :\n(200 California applicants - 100 Florida applicants)/ 300 total applicants = 100/300 = 0.33.\nThe positive value of the Difference in Population Size indicates that there are disproportionately more California applicants than Florida applicants. The positive value may or may not indicate bias by itself, but when a model is trained on this data, the model might learn to perform better for California applicants.\n## Difference in Positive Proportions in True Labels (DPPTL)\nThe measures whether a dataset has disproportionately more positive ground truth labels for one slice over the other. This metric calculates the difference in Positive Proportions in True Labels between slice 1 and slice 2, where Positive Proportions in True Labels for a slice is (Labeled positive outcomes / Total population size). This metric is also known as :\n**Note:** This metric is analogous to the [model bias metric](/vertex-ai/docs/evaluation/model-bias-metrics) of , which focuses on predicted positive outcomes instead of labeled positive outcomes.\nl 1 1 n 1 \u2212 l 1 2 n 2\n(Labeled positive outcomes for slice 1/Total population size of slice 1) - (Labeled positive outcomes for slice 2/Total population size of slice 2)\n**In our example dataset** :\n(60 accepted California applicants/200 California applicants) - (20 accepted Florida applicants/100 Florida applicants) = 60/200 - 20/100 = 0.1.\nThe positive value of the DPPTL indicates that the dataset has disproportionately higher positive outcomes for California applicants compared to Florida applicants. The positive value may or may not indicate bias by itself, but when a model is trained on this data, the model might learn to predict disproportionately more positive outcomes for California applicants.\n## What's next\n- Learn about the [model bias metrics](/vertex-ai/docs/evaluation/model-bias-metrics) supported by Vertex AI.\n- Read the [model evaluation pipeline component reference](/vertex-ai/docs/pipelines/model-evaluation-component#fairness) .", "guide": "Vertex AI"}