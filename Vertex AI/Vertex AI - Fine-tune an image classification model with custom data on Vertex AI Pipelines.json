{"title": "Vertex AI - Fine-tune an image classification model with custom data on Vertex AI Pipelines", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Fine-tune an image classification model with custom data on Vertex AI Pipelines\nThis tutorial shows you how to use Vertex AI Pipelines to run an end-to-end ML workflow, including the following tasks:\n- Import and transform data.\n- Fine-tune an [image classification model from TFHub](https://tfhub.dev/s?module-type=image-classification) using the transformed data.\n- Import the trained model to Vertex AI Model Registry.\n- **Optional** : Deploy the model for online serving with Vertex AI Prediction.", "content": "## Before you begin\n- Ensure that you've completed steps 1-3 in [Set up a Google Cloud project and a developmentenvironment](/vertex-ai/docs/start/cloud-environment) .\n- Create an isolated Python environment and install the [Vertex AI SDK for Python](/vertex-ai/docs/start/install-sdk) .\n- Install the Kubeflow Pipelines SDK:```\npython3 -m pip install \"kfp<2.0.0\" \"google-cloud-aiplatform>=1.16.0\" --upgrade --quiet\n```## Run the ML model training pipeline\nThe sample code does the following:\n- Loads components from a [component repository](https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/main/community-content/pipeline_components) to be used as pipeline building blocks.\n- Composes a pipeline by creating component tasks and passing data between them using arguments.\n- Submits the pipeline for execution on Vertex AI Pipelines. See [Vertex AI Pipelines pricing](/vertex-ai/pricing#pipelines) .\nCopy the following sample code into your development environment and run it.\n[Open in Editor](https://ide.cloud.google.com/?git_repo=https://github.com/GoogleCloudPlatform/vertex-ai-samples&page=editor&cloudshell_workspace=community-content/pipeline_components/image_ml_model_training&cloudshell_open_in_editor=pipeline.py) [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/community-content/pipeline_components/image_ml_model_training/pipeline.py) \n```\n# python3 -m pip install \"kfp<2.0.0\" \"google-cloud-aiplatform>=1.16.0\" --upgrade --quietfrom kfp import componentsfrom kfp.v2 import dsl# %% Loading componentsupload_Tensorflow_model_to_Google_Cloud_Vertex_AI_op = components.load_component_from_url('https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/399405402d95f4a011e2d2e967c96f8508ba5688/community-content/pipeline_components/google-cloud/Vertex_AI/Models/Upload_Tensorflow_model/component.yaml')deploy_model_to_endpoint_op = components.load_component_from_url('https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/399405402d95f4a011e2d2e967c96f8508ba5688/community-content/pipeline_components/google-cloud/Vertex_AI/Models/Deploy_to_endpoint/component.yaml')transcode_imagedataset_tfrecord_from_csv_op = components.load_component_from_url('https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/community-content/pipeline_components/image_ml_model_training/transcode_tfrecord_image_dataset_from_csv/component.yaml')load_image_classification_model_from_tfhub_op = components.load_component_from_url('https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/b5b65198a6c2ffe8c0fa2aa70127e3325752df68/community-content/pipeline_components/image_ml_model_training/load_image_classification_model/component.yaml')preprocess_image_data_op = components.load_component_from_url('https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/community-content/pipeline_components/image_ml_model_training/preprocess_image_data/component.yaml')train_tensorflow_image_classification_model_op = components.load_component_from_url('https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/community-content/pipeline_components/image_ml_model_training/train_image_classification_model/component.yaml')# %% Pipeline definitiondef image_classification_pipeline():\u00a0 \u00a0 class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\u00a0 \u00a0 csv_image_data_path = 'gs://cloud-samples-data/ai-platform/flowers/flowers.csv'\u00a0 \u00a0 deploy_model = False\u00a0 \u00a0 image_data = dsl.importer(\u00a0 \u00a0 \u00a0 \u00a0 artifact_uri=csv_image_data_path, artifact_class=dsl.Dataset).output\u00a0 \u00a0 image_tfrecord_data = transcode_imagedataset_tfrecord_from_csv_op(\u00a0 \u00a0 \u00a0 \u00a0 csv_image_data_path=image_data,\u00a0 \u00a0 \u00a0 \u00a0 class_names=class_names\u00a0 \u00a0 ).outputs['tfrecord_image_data_path']\u00a0 \u00a0 loaded_model_outputs = load_image_classification_model_from_tfhub_op(\u00a0 \u00a0 \u00a0 \u00a0 class_names=class_names,\u00a0 \u00a0 ).outputs\u00a0 \u00a0 preprocessed_data = preprocess_image_data_op(\u00a0 \u00a0 \u00a0 \u00a0 image_tfrecord_data,\u00a0 \u00a0 \u00a0 \u00a0 height_width_path=loaded_model_outputs['image_size_path'],\u00a0 \u00a0 ).outputs\u00a0 \u00a0 trained_model = (train_tensorflow_image_classification_model_op(\u00a0 \u00a0 \u00a0 \u00a0 preprocessed_training_data_path = preprocessed_data['preprocessed_training_data_path'],\u00a0 \u00a0 \u00a0 \u00a0 preprocessed_validation_data_path = preprocessed_data['preprocessed_validation_data_path'],\u00a0 \u00a0 \u00a0 \u00a0 model_path=loaded_model_outputs['loaded_model_path']).\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0set_cpu_limit('96').\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0set_memory_limit('128G').\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0add_node_selector_constraint('cloud.google.com/gke-accelerator', 'NVIDIA_TESLA_A100').\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0set_gpu_limit('8').\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0outputs['trained_model_path'])\u00a0 \u00a0 vertex_model_name = upload_Tensorflow_model_to_Google_Cloud_Vertex_AI_op(\u00a0 \u00a0 \u00a0 \u00a0 model=trained_model,\u00a0 \u00a0 ).outputs['model_name']\u00a0 \u00a0 # Deploying the model might incur additional costs over time\u00a0 \u00a0 if deploy_model:\u00a0 \u00a0 \u00a0 \u00a0 vertex_endpoint_name = deploy_model_to_endpoint_op(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 model_name=vertex_model_name,\u00a0 \u00a0 \u00a0 \u00a0 ).outputs['endpoint_name']pipeline_func = image_classification_pipeline# %% Pipeline submissionif __name__ == '__main__':\u00a0 \u00a0 from google.cloud import aiplatform\u00a0 \u00a0 aiplatform.PipelineJob.from_pipeline_func(pipeline_func=pipeline_func).submit()\n```\nNote the following about the sample code provided:\n- A Kubeflow pipeline is defined as a Python function.\n- The pipeline's workflow steps are created using Kubeflow pipeline components. By using the outputs of a component as an input of another component, you define the pipeline's workflow as a graph. For example, the`preprocess_image_data_op`component task depends on the`tfrecord_image_data_path`output from the`transcode_imagedataset_tfrecord_from_csv_op`component task.\n- You create a pipeline run on Vertex AI Pipelines using the Vertex AI SDK for Python.## Monitor the pipeline\nIn the Google Cloud console, in the Vertex AI section, go to the **Pipelines** page and open the **Runs** tab.\n[Go to Pipeline runs](https://console.cloud.google.com/vertex-ai/pipelines/runs)\n## What's next\n- To learn more about Vertex AI Pipelines, see [Introduction to Vertex AI Pipelines](/vertex-ai/docs/pipelines/introduction) .", "guide": "Vertex AI"}