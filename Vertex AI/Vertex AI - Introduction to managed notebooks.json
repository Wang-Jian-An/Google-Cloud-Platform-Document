{"title": "Vertex AI - Introduction to managed notebooks", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Introduction to managed notebooks\n# Introduction to managed notebooks\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\nVertex AI Workbench managed notebooks instances are Google-managed environments with integrations and capabilities that help you set up and work in an end-to-end Jupyter notebook-based production environment.\nManaged notebooks instances are prepackaged with [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html) and have a preinstalled suite of deep learning packages, including support for the TensorFlow and PyTorch frameworks. Managed notebooks instances support GPU accelerators and the ability to sync with a [GitHub](https://github.com/) repository. Your managed notebooks instances are protected by Google Cloud authentication and authorization.\n", "content": "## Google-managed compute infrastructure\nA Vertex AI Workbench managed notebooks instance is a Google-managed, Jupyter notebook-based, compute infrastructure.\nWhen you create a managed notebooks instance, it is deployed as a Google-managed virtual machine (VM) instance in a [tenant project](/service-infrastructure/docs/manage-tenant-projects) .\nYour managed notebooks instance includes many common data science framework environments, such as TensorFlow and PyTorch. You can also add your own custom container images to your managed notebooks instance. These environments are available as kernels that you can run your notebook file in.\nWhen you run a notebook in one of the kernels, Vertex AI Workbench starts the corresponding container, creates a Jupyter session on it, and uses that Jupyter session to run your notebook on the container.\nThis Google-managed compute infrastructure includes integrations and capabilities that help you implement data science and machine learning workflows from start to finish. See the following sections for details.\n## Use custom containers\nYou can add custom Docker container images to your managed notebooks instance to run your notebook code in an environment customized for your needs.\nThese custom containers are available to use directly from the JupyterLab user interface, alongside the preinstalled frameworks. For more information, see [Add a custom container toa managed notebooks instance](/vertex-ai/docs/workbench/managed/custom-container) .\n## Notebook-based workflow\nManaged notebooks instances let you perform workflow-oriented tasks without leaving the JupyterLab user interface.\n### Control your hardware and framework from JupyterLab\nIn a managed notebooks instance, your JupyterLab user interface is where you specify what compute resources your code will run on. For example, you can configure how many vCPUs or GPUs you want, how much RAM you want, and what framework you want to run the code in. You can write your code first, and then choose how to run it without leaving JupyterLab or restarting your instance. For quick tests of your code, you can scale your hardware down and then scale it back up to run your code against more data.\n### Access to data\nYou can access your data without leaving the JupyterLab user interface.\nIn JupyterLab's navigation menu on a managed notebooks instance, you can use the Cloud Storage integration to browse data and other files that you have access to. See [Access Cloud Storage buckets and filesfrom within JupyterLab](/vertex-ai/docs/workbench/managed/cloud-storage) .\nYou can also use the BigQuery integration to browse tables that you have access to, write queries, preview results, and load data into your notebook. See [Query data in BigQuery tablesfrom within JupyterLab](/vertex-ai/docs/workbench/managed/bigquery) .\n## Execute notebook runs\nUse the executor to run a notebook file as a one-time execution or on a schedule. Choose the specific environment and hardware that you want your execution to run on. Your notebook's code will run on Vertex AI custom training, which can make it easier to do distributed training, optimize hyperparameters, or schedule continuous training jobs. See [Run notebook fileswith the executor](/vertex-ai/docs/workbench/managed/executor) .\nYou can [use parameters inyour execution](/vertex-ai/docs/workbench/managed/executor-parameters) to make specific changes to each run. For example, you might specify a different dataset to use, change the learning rate on your model, or change the version of the model.\nYou can also [set a notebook to run on a recurringschedule](/vertex-ai/docs/workbench/managed/quickstart-schedule-execution-console) . Even while your instance is shut down, Vertex AI Workbench will run your notebook file and save the results for you to look at and share with others.\n## Share insights\nExecuted notebook runs are stored in a Cloud Storage bucket, so you can share your insights with others by granting access to the results. See the [previous section on executingnotebook runs](#executor) .\n## Secure your instance\nYou can deploy your managed notebooks instance with the default Google-managed network, which uses a default VPC network and subnet. Instead of the default network, you can specify a VPC network to use with your instance. For more information, see [Set up a network](/vertex-ai/docs/workbench/managed/networking) . You can use [VPC Service Controls](/vpc-service-controls/docs/overview) to provide additional security for your managed notebooks instances.\nTo use managed notebooks within a service perimeter, see [Usea managed notebooks instance within a serviceperimeter](/vertex-ai/docs/workbench/managed/service-perimeter) .\nBy default, Google Cloud automatically [encrypts data when it is atrest](/security/encryption/default-encryption) using encryption keys managed by Google. If you have specific compliance or regulatory requirements related to the keys that protect your data, you can use customer-managed encryption keys (CMEK) with your managed notebooks instances. For more information, see [Use customer-managed encryption keys](/vertex-ai/docs/workbench/managed/cmek) .\n## Automated shutdown for idle instances\nTo help manage costs, managed notebooks instances shut down after being idle for a specific time period by default. You can change the amount of time or turn this feature off. For more information, see [Idle shutdown](/vertex-ai/docs/workbench/managed/idle-shutdown) .\n## Dataproc integration\nYou can process data quickly by running a notebook on a Dataproc cluster. After your cluster is set up, you can run a notebook file on it without leaving the JupyterLab user interface. For more information, see [Run a managed notebooks instanceon a Dataproc cluster](/vertex-ai/docs/workbench/managed/dataproc) .\n## Limitations\nConsider the following limitations of managed notebooks when planning your project:\n- Managed notebooks instances are Google-managed and therefore less customizable than Vertex AI Workbench user-managed notebooks instances. User-managed notebooks instances can be more ideal for users who need a lot of control over their environment. For more information, see [Introduction touser-managed notebooks](/vertex-ai/docs/workbench/user-managed/introduction) .\n- Third party JupyterLab extensions are not supported.\n- Managed notebooks instances do not allow users to have `sudo` access.\n- When you use [Access Context Manager](/access-context-manager/docs/create-basic-access-level#corporate-network-example) and [BeyondCorp Enterprise](/beyondcorp-enterprise/docs/access-levels) to protect managed notebooks instances with context-aware access controls, access is evaluated each time the user authenticates to the instance. For example, access is evaluated the first time the user accesses JupyterLab and whenever they access it thereafter if their web browser's cookie has expired.\n- To use accelerators with managed notebooks instances, the accelerator type that you want must be available in your instance's zone. To learn about accelerator availability by zone, see [GPU regions and zones availability](/compute/docs/gpus/gpu-regions-zones) .## What's next\n- [Create a managed notebooksinstance](/vertex-ai/docs/workbench/managed/create-instance) .\n- Learn more about the [networking options available for yourmanaged notebooks instance](/vertex-ai/docs/workbench/managed/networking) .", "guide": "Vertex AI"}