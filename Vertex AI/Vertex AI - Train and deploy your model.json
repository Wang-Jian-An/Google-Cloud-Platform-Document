{"title": "Vertex AI - Train and deploy your model", "url": "https://cloud.google.com/vertex-ai/docs/tutorials/tabular-bq-prediction/train-and-deploy-model", "abstract": "# Vertex AI - Train and deploy your model\n[CustomTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob)\nWhen you create a `CustomTrainingJob` , you define a training pipeline in the background. Vertex AI uses the training pipeline and the code in your Python training script to train and create your model. For more information, see [Create training pipelines](/vertex-ai/docs/training/create-training-pipeline) .\n", "content": "## Define your training pipeline\nTo create a training pipeline, you create a `CustomTrainingJob` object. In the next step, you use the `CustomTrainingJob` 's `run` command to create and train your model. To create a `CustomTrainingJob` , you pass the following parameters to its constructor:\n- `display_name` - The `JOB_NAME` variable you created when you defined the command arguments for the Python training script.\n- `script_path` - The path to the Python training script you created earlier in this tutorial.\n- `container_url` - The URI of a Docker container image that's used to train your model.\n- `requirements` - The list of the script's Python package dependencies.\n- `model_serving_container_image_uri` - The URI of a Docker container image that serves predictions for your model. This container can be prebuilt or your own custom image. This tutorial uses a prebuilt container.\nRun the following code to create your training pipeline. The [CustomTrainingJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob) method uses the Python training script in the `task.py` file to construct a [CustomTrainingJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob) .\n```\njob = aiplatform.CustomTrainingJob(\u00a0 \u00a0 display_name=JOB_NAME,\u00a0 \u00a0 script_path=\"task.py\",\u00a0 \u00a0 container_uri=\"us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-8:latest\",\u00a0 \u00a0 requirements=[\"google-cloud-bigquery>=2.20.0\", \"db-dtypes\", \"protobuf<3.20.0\"],\u00a0 \u00a0 model_serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest\",)\n```\n## Create and train your model\nIn the previous step you created a [CustomTrainingJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob) named `job` . To create and train your model, call the `run` method on your `CustomTrainingJob` object and pass it the following parameters:\n- `dataset` - The [tabular dataset you createdearlier](/vertex-ai/docs/tutorials/tabular-bq-prediction/create-dataset#create-tabular-dataset) in this tutorial. This parameter can be a tabular, image, video, or text dataset.\n- `model_display_name` - A name for your model.\n- `bigquery_destination` - A string that specifies the location of your BigQuery dataset.\n- `args` - The command-line arguments that are passed to the Python training script.\nTo start training your data and create your model, run the following code in your notebook:\n```\nMODEL_DISPLAY_NAME = \"penguins_model_unique\"# Start the training and create your modelmodel = job.run(\u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 model_display_name=MODEL_DISPLAY_NAME,\u00a0 \u00a0 bigquery_destination=f\"bq://{project_id}\",\u00a0 \u00a0 args=CMDARGS,)\n```\nBefore continuing with the next step, make sure the following appears in the `job.run` command's output to verify it's done:\n`CustomTrainingJob run completed` .\nAfter the training job completes, you can deploy your model.\n## Deploy your model\nWhen you deploy your model, you also create an `Endpoint` resource that's used to make predictions. To deploy your model and create an endpoint, run the following code in your notebook:\n```\nDEPLOYED_NAME = \"penguins_deployed_unique\"endpoint = model.deploy(deployed_model_display_name=DEPLOYED_NAME)\n```\nWait until your model deploys before you continue to the next step. After your model deploys, the output includes the text, `Endpoint model deployed` . You can also click **Endpoints** in the Vertex AI console's left navigation pane and monitor its value under **Models** . The value is `0` after the endpoint is created and before the model is deployed. After the model deploys, the value updates to `1` .\nThe following shows an endpoint after it's created and before a model is deployed to it.\nThe following shows an endpoint after it's created and after a model is deployed to it.", "guide": "Vertex AI"}