{"title": "Vertex AI - Migrate to Vertex AI", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Migrate to Vertex AI\nVertex AI brings together AI Platform and AutoML services under one unified UI and API to simplify the process of building, training, and deploying machine learning models. With Vertex AI, you can move from experimentation to production faster, efficiently discover patterns and anomalies, make better predictions and decisions, and stay agile in the face of changing priorities and market conditions. This page provides recommended steps and other information to help you plan and implement a migration to Vertex AI.\nVertex AI supports all features and models available in AutoML and AI Platform. However, the client libraries do not support client integration backward compatibility. In other words, you must plan to migrate your resources to benefit from Vertex AI features.\nIf you are planning a new project, you should build your code, job, dataset, or model with Vertex AI. This lets you take advantage of the new features and service improvements as they become available. AutoML and AI Platform remain available, but future improvements will be implemented on Vertex AI.\n", "content": "## Recommended steps for migrating to Vertex AI\nUse the following recommended steps to update your existing code, jobs, datasets, and models from AutoML and AI Platform to Vertex AI.\n**Note:** AutoML models have a maximum lifespan of 18 months. Models older than 18 months can't be migrated to Vertex AI.\nTo update your implementation from AutoML to Vertex AI, complete these steps:- Read about the major differences between AutoML and Vertex AI at [Vertex AI for AutoMLusers](/vertex-ai/docs/start/automl-users) .\n- Review any potential changes in pricing (see [Vertex AI migration pricing](#pricing) ).\n- Take inventory of your Google Cloud projects, code, jobs, datasets, models, and users with access to AutoML. Use this information to determine which resources to migrate and ensure that the correct users have access to the migrated resources.\n- Review the [changes to IAM roles](#changes-to-iam-roles) , and then update service accounts and authentication for your resources.\n- Review the list of [resources that you cannot migrate](#migration-exceptions) and [information about the migration process](#migration-info) .\n- Migrate your resources using either of these two methods:- [Use the migration tool](#migration-tool) .\n- [Use the Vertex AI client libraries andmethods](#client-libraries) .\n- Read about how Vertex AI uses [regionalendpoints](#regional-endpoints) .\n- [Identify usage ofAutoMLAPIs](#identifying-api-usage) to help determine which of your applications use them and to identify the method calls that you want to migrate.\n- [Update your applications and workflows to use the Vertex AI API andVertex AI features](/vertex-ai/docs/start/migrating-applications) .\n- Plan your request quota monitoring. See [Quotas andlimits](/vertex-ai/quotas) .\nTo update your implementation from AI Platform to Vertex AI, complete these steps:- Read about the major differences between AI Platform and Vertex AI at [Vertex AI for AI Platformusers](/vertex-ai/docs/start/ai-platform-users) .\n- Review any potential changes in pricing (see [Vertex AI migration pricing](#pricing) ).\n- Take inventory of your Google Cloud projects, code, jobs, datasets, models, and users with access to AI Platform. Use this information to determine which resources to migrate and ensure that the correct users have access to the migrated resources.\n- Review the [changes to IAM roles](#changes-to-iam-roles) , and then update service accounts and authentication for your resources.\n- Review the list of [resources that you cannot migrate](#migration-exceptions) and [information about the migration process](#migration-info) .\n- Migrate your resources using either of these two methods:- [Use the migration tool](#migration-tool) .\n- [Use the Vertex AI client libraries andmethods](#client-libraries) .\n- Read about how Vertex AI uses [regionalendpoints](#regional-endpoints) .\n- [Identify usage ofAI PlatformAPIs](#identifying-api-usage) to help determine which of your applications use them and to identify the method calls that you want to migrate.\n- [Update your applications and workflows to use the Vertex AI API andVertex AI features](/vertex-ai/docs/start/migrating-applications) .\n- Plan your request quota monitoring. See [Quotas andlimits](/vertex-ai/quotas) .## Vertex AI migration pricing\nMigration is free. Resources that are created as a result of migration incur standard charges (see [Vertex AI pricing](/vertex-ai/pricing) ). Datasets migrated from AI Platform Data Labeling Service, AutoML Vision, AutoML Video Intelligence, and AutoML Natural Language migrate to a Cloud Storage bucket, which will incur storage costs (see [Cloud Storagepricing](/storage/pricing) ).\nAfter migration, legacy resources are still available to use in AutoML and AI Platform. To avoid unnecessary costs, shut down or delete legacy resources after you have verified that your objects have migrated successfully.\nMigration is a copy operation. After you migrate a resource, changes to the legacy resource do not affect the migrated resource.\n## Vertex AI pricing compared to legacy product pricing\nThe costs for Vertex AI remain the same as they are for the legacy AI Platform and AutoML products that Vertex AI supersedes, with the following exceptions:\n- Legacy AI Platform Prediction and AutoML Tables predictions supported lower-cost, lower-performance machine types that aren't supported for Vertex AI Prediction and AutoML tabular.\n- Legacy AI Platform Prediction supported [scale-to-zero](/ai-platform/prediction/docs/machine-types-online-prediction#automatic_scaling) , which isn't supported for Vertex AI Prediction.\nVertex AI also offers more ways to optimize costs, such as the following:\n- [Optimized TensorFlow runtime](https://cloud.google.com/blog/topics/developers-practitioners/speed-model-inference-vertex-ai-predictions-optimized-tensorflow-runtime) .\n- Support for [co-hosting models](/vertex-ai/docs/predictions/model-co-hosting) .\n- No minimum usage duration for Training and Prediction. Instead, usage is charged in 30 second increments.## Identify usage of AutoML and AI Platform APIs\nYou can determine which of your applications use AutoML and AI Platform APIs, as well as which methods they are using. Use this information to help determine whether these API calls need to be migrated to Vertex AI.\nTo identify AutoML and AI Platform API calls that you might want to migrate, see the following options.\n- For each of your projects, go to the [APIs &Services Dashboard](https://console.cloud.google.com/apis/dashboard) to see a list of which products' API the project uses. To learn more, see [Monitoring API usage](/apis/docs/monitoring) .\n- If enabled, you can check the audit logs created by [AutoML](/automl/docs/audit-logging) , [AI Platform Training](/ai-platform/training/docs/audit-logs) , and [AI Platform Prediction](/ai-platform/prediction/docs/audit-logs) as part of [Cloud Audit Logs](/logging/docs/audit) .\n- To see usage of specific AI Platform Training and Prediction API methods, go to the [AI Platform Training and Prediction API Metricspage](https://console.cloud.google.com/apis/api/ml.googleapis.com/metrics) .## Manage changes to IAM roles and permissions\nVertex AI provides the following Identity and Access Management (IAM) roles:\n- `aiplatform.admin`\n- `aiplatform.user`\n- `aiplatform.viewer`\n- `aiplatform.migrator`\n**Note:** These roles are project-specific and grant permissions across all of Vertex AI, as opposed to the AutoML and AI Platform Training and Prediction API roles, which grant permissions specific to each service.\nOnly `aiplatform.admin` and `aiplatform.migrator` have the ability to migrate resources from AutoML and AI Platform to Vertex AI. `aiplatform.user` and `aiplatform.viewer` can't migrate resources.\n**Note:** Migration can make resources visible to people who did not have permission to see the resources before the migration. Specifically, `aiplatform.admin` and `aiplatform.migrator` can migrate AutoML and Data Labeling Service resources to Vertex AI and then view the copied resources, even though they might not have a role that lets them read or export data in AutoML or Data Labeling Service. For example, a user who does not have an `automl.datasets.*` role but does have the `aiplatform.migrator` role can migrate a dataset to Vertex AI and then view the migrated copy of the dataset.\nFor more information on IAM roles, see [Accesscontrol](/vertex-ai/docs/general/access-control) .\n## Resources that can't be migrated\nThe migration tool currently can't migrate all resources and in some cases migration is limited. Consider the following exceptions when you plan your migration.\n- PDF text is not supported in Vertex AI, so AutoML Natural Language's PDF text is migrated as plain text generated by optical character recognition.\n- Empty datasets can't be migrated.\n- Batch prediction jobs can't be migrated.\n- Models created in an alpha version of AutoML Tables can't be migrated.\n- Empty datasets can't be migrated.\n- Batch prediction jobs can't be migrated.\n- Models created in an alpha version of AutoML Video can't be migrated.\n- Empty datasets can't be migrated.\n- Batch prediction jobs can't be migrated.\n- Models created in an alpha version of AutoML Vision can't be migrated.\n- Empty datasets can't be migrated.\n- Batch prediction jobs can't be migrated.\n- Not all models can be migrated. Models that are migratable have these characteristics:- The [runtimeversion](/ai-platform/training/docs/runtime-version-list) must be 1.15 or higher.\n- The framework must be one of the following:- TensorFlow\n- scikit-learn\n- XGBoost\n- The Python version must be 3.7 or higher.\n- If an AI Platform model's `signature-name` flag has been changed from the default value, `serving_default` , it might migrate to Vertex AI but will not function.\n- Custom prediction routines are not migrated.\n- Jobs run on AI Platform are not migrated. You can download the metadata for your own records.\n- The Python scripts, packages, or Docker containers you run on AI Platform Training are not automatically migratable, but you can [update your scripts to enable them to run onVertex AI](#updating-scripts) .## About the migration process\nBefore migrating your resources, review the following information first.\n- The migration tool creates a copy of your resources.The migration tool creates a duplicate version of your AutoML and AI Platform datasets and models on Vertex AI. Your legacy resources are not deleted. If you want, you can migrate the same resource multiple times to create several copies.\n- Migrated models are undeployed.For data types that support online prediction, you must create an endpoint and deploy the model to that endpoint before the model can be used to serve online predictions.\n- When an AutoML model is migrated, the migration tool automatically creates a training job at the same time.\n- Migrated datasets for some data types and objectives might not contain the same data as the current dataset.Datasets for certain data types are reimported from the original data source, rather than copied over from the existing dataset. If the original data source has been changed, the migrated dataset will reflect those changes. This caveat applies to the following data types and objectives:- AutoML Natural Language entity extraction datasets\n- AutoML Video classification and object tracking datasets\n- AutoML Vision object detection datasets\n- Migrated tabular datasets are exported as part of the migration process.In Vertex AI, a tabular dataset's data source is referenced rather than imported ( [learn more](/vertex-ai/docs/start/automl-users#tables) ). A migrated tabular dataset is exported from the AutoML Tables dataset, stored as a CSV file in Cloud Storage or a BigQuery table in your project, and then referenced by the migrated dataset.## Use the migration tool\nVertex AI provides a migration tool to help you migrate your datasets and models from AutoML and AI Platform to Vertex AI.\n### Steps for using the migration tool\nTo use the migration tool to migrate your datasets and models to Vertex AI, complete the following steps.\n- If you haven't already enabled the Vertex AI API, on the [Vertex AI Dashboardpage](https://console.cloud.google.com/vertex-ai/) in the Google Cloud console, click **Enable the Vertex AI API** .\n- On the [Vertex AI Dashboardpage](https://console.cloud.google.com/vertex-ai/) in the Google Cloud console, under **Migrate to Vertex AI** , click **Set up migration** . **Note:** If you don't see an option to migrate to Vertex AI, you do not have resources that can be migrated using the tool.\n- Under **Select resources to migrate** , select up to 50 assets to migrate. If you need to, you can repeat these steps to migrate more assets later. **Note:** Some assets are not shown because they can't be migrated at this time. See the [resources that can'tbe migrated](#migration-exceptions) .\n- Click **Next** , and review the summary of the assets that you want to migrate.\n- Click **Migrate assets** . Migration might take an hour or more depending on the number of assets being migrated. The migration tool sends you an email when the migration is finished.## Use the client libraries and methods to migrate resources\nUse the [batchMigrateResources()](/vertex-ai/docs/reference/rest/v1/projects.locations.migratableResources/batchMigrate) method and related methods to migrate your resources.\nRefer to the [Vertex AI APIReference documentation](/vertex-ai/docs/reference/rest) if you need help.\n## Regional endpoints\nVertex AI API endpoints are regional. For example:\n```\nus-central1-aiplatform.googleapis.com\n```\nGlobal endpoints are not supported for Vertex AI.\n**Note:** AutoML resources located in the `eu` European Union region are migrated to the `europe-west4` region.\nSee the [list of supported endpoints in the referencedocumentation](/vertex-ai/docs/reference/rest#service-endpoint) .\n## Update training scripts to run in Vertex AI\nThe Python scripts, packages, or Docker containers you run on AI Platform Training require the following specific changes to run on Vertex AI.\n- For jobs that write outputs to Cloud Storage, in Vertex AI, you must indicate the Cloud Storage URI for different types of outputs through environment variables. In AI Platform, the Cloud Storage URI is typically indicated with the command line argument `--job-dir` .\n- In Vertex AI, the `TF_CONFIG` variable uses the term `chief` to refer to the primary machine. In AI Platform, in some cases, it uses the term `master` .\n- When submitting a custom training job in Vertex AI, specify the Artifact Registry URI of a [prebuilt container](/vertex-ai/docs/training/pre-built-containers) that corresponds to your framework and framework version. In AI Platform, you specify a runtime version that includes the framework and framework version that you want to use.\n- Not all machine types supported by AI Platform are supported by Vertex AI.- [Legacy machine types](/ai-platform/training/docs/machine-types#legacy-machine-types) and [scale tiers](/ai-platform/training/docs/machine-types#scale_tiers) from AI Platform Training are not supported in Vertex AI. Only the newer [Compute Engine machinetypes](/ai-platform/training/docs/machine-types#compute-engine-machine-types) are supported.\n- GPUs supported are P4, T4, K80, P100, and V100.\n- TPUs are not supported.\n## What's next\n- Read [Migrating your applications to Vertex AI](/vertex-ai/docs/start/migrating-applications) to help determine the changes you need to make when you migrate your applications from AutoML or AI Platform to Vertex AI.\n- To help you get started using Vertex AI, read the [Getting started documentation](/vertex-ai/docs/start) .\n- To learn how to train a new model on Vertex AI, try one of the [Vertex AI tutorials](/vertex-ai/docs/tutorials) .", "guide": "Vertex AI"}