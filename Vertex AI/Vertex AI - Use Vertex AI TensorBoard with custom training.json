{"title": "Vertex AI - Use Vertex AI TensorBoard with custom training", "url": "https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-training", "abstract": "# Vertex AI - Use Vertex AI TensorBoard with custom training\nTo see examples of how to enable TensorBoard for a custom training job that uses custom containers,  run the following Jupyter notebooks in the environment of your choice:\n- \"Vertex AI TensorBoard\u00a0custom training with prebuilt containers\": [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_custom_training_with_prebuilt_container.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftensorboard%2Ftensorboard_custom_training_with_prebuilt_container.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_custom_training_with_prebuilt_container.ipynb) \n- \"Vertex AI TensorBoard\u00a0custom training with custom containers\": [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_custom_training_with_custom_container.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftensorboard%2Ftensorboard_custom_training_with_custom_container.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_custom_training_with_custom_container.ipynb)\nWhen using custom training to train models, you can set up your training job to automatically upload your Vertex AI TensorBoard logs to Vertex AI TensorBoard.\nYou can use this integration to monitor your training in near real time as Vertex AI TensorBoard streams in Vertex AI TensorBoard logs as they are written to Cloud Storage.\nFor initial setup see [Set up for Vertex AI TensorBoard](/vertex-ai/docs/experiments/tensorboard-setup) .\n#", "content": "## Changes to your training script\nYour training script must be configured to write TensorBoard logs to the Cloud Storage bucket, the location of which the Vertex AI Training Service will automatically make available through a predefined environment variable ` **AIP_TENSORBOARD_LOG_DIR** ` .\nThis can usually be done by providing `os.environ['AIP_TENSORBOARD_LOG_DIR']` as the log directory to the open source TensorBoard log writing APIs. The location of the `AIP_TENSORBOARD_LOG_DIR` is typically set with the `staging_bucket` variable.\nTo configure your training script in TensorFlow 2.x, create a TensorBoard callback and set the `log_dir` variable to `os.environ['AIP_TENSORBOARD_LOG_DIR']` The TensorBoard callback is then included in the TensorFlow `model.fit` callbacks list.\n```\n\u00a0 tensorboard_callback = tf.keras.callbacks.TensorBoard(\u00a0 \u00a0 \u00a0 \u00a0log_dir=os.environ['AIP_TENSORBOARD_LOG_DIR'],\u00a0 \u00a0 \u00a0 \u00a0histogram_freq=1\u00a0 )\u00a0 \u00a0 model.fit(\u00a0 \u00a0 \u00a0 \u00a0x=x_train,\u00a0 \u00a0 \u00a0 \u00a0y=y_train,\u00a0 \u00a0 \u00a0 \u00a0epochs=epochs,\u00a0 \u00a0 \u00a0 \u00a0validation_data=(x_test, y_test),\u00a0 \u00a0 \u00a0 \u00a0callbacks=[tensorboard_callback],\u00a0 )\u00a0 \n```\nLearn more about [how Vertex AI](/vertex-ai/docs/training/code-requirements#environment-variables) sets environment variables in your custom training environment.\n### Create a custom training job\nThe following example shows how to create your own custom training job.\nFor a detailed example of how to create a custom training job, see [Hello custom training](/vertex-ai/docs/tutorials/image-classification-custom/overview) . For steps to build custom training containers, see [Create a custom container image for training](/vertex-ai/docs/training/create-custom-container) .\nTo create a custom training job use either Vertex AI SDK for Python or REST.\n### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_training_pipeline_custom_job_sample.py) \n```\ndef create_training_pipeline_custom_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 staging_bucket: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 script_path: str,\u00a0 \u00a0 container_uri: str,\u00a0 \u00a0 model_serving_container_image_uri: str,\u00a0 \u00a0 dataset_id: Optional[str] = None,\u00a0 \u00a0 model_display_name: Optional[str] = None,\u00a0 \u00a0 args: Optional[List[Union[str, float, int]]] = None,\u00a0 \u00a0 replica_count: int = 0,\u00a0 \u00a0 machine_type: str = \"n1-standard-4\",\u00a0 \u00a0 accelerator_type: str = \"ACCELERATOR_TYPE_UNSPECIFIED\",\u00a0 \u00a0 accelerator_count: int = 0,\u00a0 \u00a0 training_fraction_split: float = 0.8,\u00a0 \u00a0 validation_fraction_split: float = 0.1,\u00a0 \u00a0 test_fraction_split: float = 0.1,\u00a0 \u00a0 sync: bool = True,\u00a0 \u00a0 tensorboard_resource_name: Optional[str] = None,\u00a0 \u00a0 service_account: Optional[str] = None,):\u00a0 \u00a0 aiplatform.init(project=project, location=location, staging_bucket=staging_bucket)\u00a0 \u00a0 job = aiplatform.CustomTrainingJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 script_path=script_path,\u00a0 \u00a0 \u00a0 \u00a0 container_uri=container_uri,\u00a0 \u00a0 \u00a0 \u00a0 model_serving_container_image_uri=model_serving_container_image_uri,\u00a0 \u00a0 )\u00a0 \u00a0 # This example uses an ImageDataset, but you can use another type\u00a0 \u00a0 dataset = aiplatform.ImageDataset(dataset_id) if dataset_id else None\u00a0 \u00a0 model = job.run(\u00a0 \u00a0 \u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 \u00a0 \u00a0 model_display_name=model_display_name,\u00a0 \u00a0 \u00a0 \u00a0 args=args,\u00a0 \u00a0 \u00a0 \u00a0 replica_count=replica_count,\u00a0 \u00a0 \u00a0 \u00a0 machine_type=machine_type,\u00a0 \u00a0 \u00a0 \u00a0 accelerator_type=accelerator_type,\u00a0 \u00a0 \u00a0 \u00a0 accelerator_count=accelerator_count,\u00a0 \u00a0 \u00a0 \u00a0 training_fraction_split=training_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 validation_fraction_split=validation_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 test_fraction_split=test_fraction_split,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 \u00a0 \u00a0 tensorboard=tensorboard_resource_name,\u00a0 \u00a0 \u00a0 \u00a0 service_account=service_account,\u00a0 \u00a0 )\u00a0 \u00a0 model.wait()\u00a0 \u00a0 print(model.display_name)\u00a0 \u00a0 print(model.resource_name)\u00a0 \u00a0 print(model.uri)\u00a0 \u00a0 return model\n```\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: The region to run the CustomJob in. This should be the same region as the provided TensorBoard instance.\n- `staging_bucket`: The Cloud Storage bucket to stage artifacts during API calls, including TensorBoard logs.\n- `display_name`: Display name of the custom training job.\n- `script_path`: The path, relative to the working directory  on your local file system, to the script that is the entry point  for your training code.\n- `container_uri`: The URI of the training container image  can be Vertex AI. [prebuilt training container](/vertex-ai/docs/training/pre-built-containers) or a [custom container](/vertex-ai/docs/training/containers-overview) .\n- `model_serving_container_image_uri`: The URI of the model serving container suitable for serving the model produced by the training script.\n- `dataset_id`: The ID number for the dataset to use for training.\n- `model_display_name`: Display name of the trained model.\n- `args`: Command line arguments to be passed to the Python script.\n- `replica_count`: The number of worker replicas to use.  In most cases, set this to 1 for your [first worker pool](/vertex-ai/docs/training/create-custom-job#configure_distributed_training) .\n- `machine_type`: The type of VM to use. For a list of  supported VMs,  see [Machine types](/vertex-ai/docs/training/configure-compute#machine-types) \n- `accelerator_type`: The type of GPU to attach to each VM  in the resource pool. For a list of supported GPUs, see [GPUs](/vertex-ai/docs/training/configure-compute#specifying_gpus) .\n- `accelerator_count`The number of GPUs to attach to each  VM in the resource pool. The default the value is`1`.\n- `training_fraction_split`: The fraction of the dataset to use to train your model.\n- `validation_fraction_split`: The fraction of the dataset to use to validate your model.\n- `test_fraction_split`: The fraction of the dataset to use to evaluate your model.\n- `sync`: Whether to execute this method synchronously.\n- `tensorboard_resource_name`: The resource name of the Vertex TensorBoard instance to which CustomJob will upload TensorBoard logs.\n- `service_account`: Required when running with TensorBoard. See [Create a service account with required permissions](/vertex-ai/docs/experiments/tensorboard-setup#create-service-account) .\nBefore using any of the request data, make the following replacements:- : Your region.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : (Obligatory) The full name  of the existing Vertex AI TensorBoard instance storing your Vertex AI TensorBoard logs:`projects/` ``PROJECT_ID`` `/locations/` ``LOCATION_ID`` `/tensorboards/TENSORBOARD_INSTANCE_ID`Note: If the tensorboard instance is not an existing one, the customJobs  creation throws a 404.\n- : \"${PROJECT_ID}-tensorboard-logs-${LOCATION}\"\n- : (Obligatory) The service account created in previous steps,  or your own service account. \"USER_SA_NAME@${PROJECT_ID}.iam.gserviceaccount.com\"\n- : TRAINING_CONTAINER.\n- : \"$(date +'%Y%m%d-%H%M%S')\"\n- : \"tensorboard-example-job-${INVOCATION_TIMESTAMP}\"\n- : (Obligatory) the Google Cloud path where all the output of the  training is written to. \"gs://$GCS_BUCKET_NAME/$JOB_NAME\"\nHTTP method and URL:\n```\nPOST https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/customJobs\n```\nRequest JSON body:\n```\n{\n\"displayName\": JOB_NAME,\n\"jobSpec\":{\n\"workerPoolSpecs\":[ {\n \"replicaCount\": \"1\",\n  \"machineSpec\": {\n  \"machineType\": \"n1-standard-8\",\n  },\n  \"containerSpec\": {\n  \"imageUri\": TRAINING_CONTAINER,\n  }\n }\n ],\n \n \"base_output_directory\": {\n \"output_uri_prefix\": BASE_OUTPUT_DIR,\n },\n \"serviceAccount\": USER_SA_EMAIL,\n \"tensorboard\": TENSORBOARD_INSTANCE_NAME,\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_ID/locations/LOCATION_ID/customJobs/CUSTOM_JOB_ID\",\n \"displayName\": \"DISPLAY_NAME\",\n \"jobSpec\": {\n \"workerPoolSpecs\": [  {\n  \"machineSpec\": {\n   \"machineType\": \"n1-standard-8\"\n  },\n  \"replicaCount\": \"1\",\n  \"diskSpec\": {\n   \"bootDiskType\": \"pd-ssd\",\n   \"bootDiskSizeGb\": 100\n  },\n  \"containerSpec\": {\n   \"imageUri\": \"IMAGE_URI\"\n  }\n  }\n ],\n \"serviceAccount\": \"SERVICE_ACCOUNT\",\n \"baseOutputDirectory\": {\n  \"outputUriPrefix\": \"OUTPUT_URI_PREFIX\"\n },\n \"tensorboard\": \"projects//locations/LOCATION_ID/tensorboards/tensorboard-id\"\n },\n \"state\": \"JOB_STATE_PENDING\",\n \"createTime\": \"CREATE-TIME\",\n \"updateTime\": \"UPDATE-TIME\"\n}\n```\n## What's next\n- Check out [View Vertex AI TensorBoard](/vertex-ai/docs/experiments/tensorboard-view#custom-training) .\n- Learn how to optimize the performance of your custom training jobs using [Vertex AI TensorBoard Profiler](/vertex-ai/docs/training/tensorboard-profiler) .", "guide": "Vertex AI"}