{"title": "Vertex AI - Log models to an experiment run", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Log models to an experiment run\nIn order for a model to be easily tracked, shared, and analyzed, the Vertex AI SDK for Python provides an API that serializes a machine learning model into an [ExperimentModel](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.metadata.schema.google.artifact_schema.ExperimentModel) class and logs the model to Vertex AI Experiments.\nAfter selecting the best model to use, you can register that model from Vertex AI Experiments to Vertex AI Model Registry.\nSupported frameworks are scikit-learn, XGBoost, and Tensorflow.\n#", "content": "## Save and log ML model\nThe Vertex AI SDK provides the [save_model](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_save_model) method to serialize an ML model,   upload the model to Cloud Storage, and represent the model as a   Vertex ML Metadata   artifact.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/save_model_sample.py) \n```\ndef save_model_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 model: Union[\u00a0 \u00a0 \u00a0 \u00a0 \"sklearn.base.BaseEstimator\", \"xgb.Booster\", \"tf.Module\" \u00a0# noqa: F821\u00a0 \u00a0 ],\u00a0 \u00a0 artifact_id: Optional[str] = None,\u00a0 \u00a0 uri: Optional[str] = None,\u00a0 \u00a0 input_example: Optional[\u00a0 \u00a0 \u00a0 \u00a0 Union[list, dict, \"pd.DataFrame\", \"np.ndarray\"] \u00a0# noqa: F821\u00a0 \u00a0 ] = None,\u00a0 \u00a0 display_name: Optional[str] = None,) -> None:\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 aiplatform.save_model(\u00a0 \u00a0 \u00a0 \u00a0 model=model,\u00a0 \u00a0 \u00a0 \u00a0 artifact_id=artifact_id,\u00a0 \u00a0 \u00a0 \u00a0 uri=uri,\u00a0 \u00a0 \u00a0 \u00a0 input_example=input_example,\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 )\n```\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) \n- `model`: (Required). A machine learning model.`(Union[\"sklearn.base.BaseEstimator\", \"xgb.Booster\", \"tf.Module\"])`\n- `artifact_id`: Optional. The resource ID of the artifact. This ID must be   globally unique in a metadataStore. It might be up to 63 characters, and valid characters   are`[a-z0-9_-]`. The first character can't be a number or a hyphen.\n- `uri`: Optional. A gcs directory in which to save the model file. If a uri   isn't provided,`gs://default-bucket/timestamp-uuid-frameworkName-model`is   used. If a default staging bucket isn't set, a new bucket is created.\n- `input_example`: Optional. Each model takes input data and then produces   a prediction. Each model accepts one particular format of input (for example, a number,   a string, 2d array) and is stored as a yaml file in the gcs uri.   Accepts list, dict, pd.DataFrame, and np.ndarray The value inside a list must be a scalar   or list. The value inside a dict must be a scalar, list, or np.ndarray.`(Union[list, dict, pd.DataFrame, np.ndarray])`.\n- `display_name`: The display name of the artifact.\nThe Vertex AI SDK provides a [log_model](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_model) method, which orchestrates [save_model](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_save_model) and an additional step to log the Vertex ML Metadata   artifact to the current experiment run. The `log_model` method to manage and   analyze multiple ML models in Vertex AI Experiments.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/log_model_sample.py) \n```\ndef log_model_sample(\u00a0 \u00a0 experiment_name: str,\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 model: Union[\u00a0 \u00a0 \u00a0 \u00a0 \"sklearn.base.BaseEstimator\", \"xgb.Booster\", \"tf.Module\" \u00a0# noqa: F821\u00a0 \u00a0 ],\u00a0 \u00a0 artifact_id: Optional[str] = None,\u00a0 \u00a0 uri: Optional[str] = None,\u00a0 \u00a0 input_example: Optional[\u00a0 \u00a0 \u00a0 \u00a0 Union[list, dict, \"pd.DataFrame\", \"np.ndarray\"] \u00a0# noqa: F821\u00a0 \u00a0 ] = None, \u00a0# noqa: F821\u00a0 \u00a0 display_name: Optional[str] = None,) -> None:\u00a0 \u00a0 aiplatform.init(experiment=experiment_name, project=project, location=location)\u00a0 \u00a0 aiplatform.start_run(run=run_name, resume=True)\u00a0 \u00a0 aiplatform.log_model(\u00a0 \u00a0 \u00a0 \u00a0 model=model,\u00a0 \u00a0 \u00a0 \u00a0 artifact_id=artifact_id,\u00a0 \u00a0 \u00a0 \u00a0 uri=uri,\u00a0 \u00a0 \u00a0 \u00a0 input_example=input_example,\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 )\n```\n- `experiment_name`: Provide the name of your experiment. You can find your   list of experiments in the Google Cloud console by selecting \"Experiments\" in the section nav.\n- `run_name`: Specify a run name.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\n- `model`: Required. A machine learning model.`(Union[\"sklearn.base.BaseEstimator\", \"xgb.Booster\", \"tf.Module\"])`\n- `uri`: Optional. A gcs directory in which to save the model file. If a   uri is   not provided,`gs://default-bucket/timestamp-uuid-frameworkName-model`is used.   If a default staging bucket is not set, a new bucket is created.\n- `input_example`: Optional. Each model takes input data and then produces   a prediction. Each model accepts one particular format of input   (for example, a number, a string, 2d array) and is stored as a yaml file in the gcs uri.   Accepts list, dict, pd.DataFrame, and np.ndarray The value inside a list must be a   scalar or list. The value inside a dict must be a scalar, list, or np.ndarray.`(Union[list, dict, pd.DataFrame, np.ndarray])`.\n- `display_name`: Optional. The display name of the artifact.\n### Track ExperimentModel\nTo use [get_experiment_model](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_get_experiment_model) to return a saved model, pass it the saved model's artifact ID.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_model_sample.py) \n```\ndef get_experiment_model_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 artifact_id: str,) -> \"ExperimentModel\": \u00a0# noqa: F821\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 experiment_model = aiplatform.get_experiment_model(artifact_id=artifact_id)\u00a0 \u00a0 return experiment_model\n```\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\n- `artifact_id`: Required: The resource ID of the existing   model.\nThe [get_experiment_models](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.ExperimentRun#google_cloud_aiplatform_ExperimentRun_get_experiment_models) method gets a list of all the `ExperimentModel` 's that are logged to a particular experiment run.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_run_models_sample.py) \n```\ndef get_experiment_run_models_sample(\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 experiment: Union[str, aiplatform.Experiment],\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> List[\"ExperimentModel\"]: \u00a0# noqa: F821\u00a0 \u00a0 experiment_run = aiplatform.ExperimentRun(\u00a0 \u00a0 \u00a0 \u00a0 run_name=run_name, experiment=experiment, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_run.get_experiment_models()\n```\n- `run_name`: Specify a run name.\n- `experiment`: Provide the name of your experiment. You can find your list   of experiments in the Google Cloud console by selecting \"Experiments\" in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\nThe `get_model_info` method returns the model's metadata of a given `ExperimentModel` instance, for example, model class, framework type.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_model_info_sample.py) \n```\ndef get_model_info_sample(\u00a0 \u00a0 artifact_id: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> Dict[str, Any]:\u00a0 \u00a0 experiment_model = aiplatform.get_experiment_model(\u00a0 \u00a0 \u00a0 \u00a0 artifact_id=artifact_id, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_model.get_model_info()\n```\n- `artifact_id`: Required The resource ID of the existing`ExperimentModel`.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\n### Load ExperimentModel\nThe `load_experiment_model` method helps you deserialize an `ExperimentModel` instance back to the original ML model.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/load_experiment_model_sample.py) \n```\ndef load_experiment_model_sample(\u00a0 \u00a0 artifact_id: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> Union[\"sklearn.base.BaseEstimator\", \"xgb.Booster\", \"tf.Module\"]: \u00a0# noqa: F821:\u00a0 \u00a0 experiment_model = aiplatform.get_experiment_model(\u00a0 \u00a0 \u00a0 \u00a0 artifact_id=artifact_id, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_model.load_model()\n```\n- `artifact_id`: (Required). The resource ID of the existing`ExperimentModel`.  Example:`artifact_id=\"my-sklearn-model\"`\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\n### Register ExperimentModel\nThe `register_experiment_model` API enables registering the model that was deemed the best, in Vertex AI Model Registry with a minimum amount of configuration. The API automatically chooses a [prebuilt prediction container](/vertex-ai/docs/predictions/pre-built-containers) based on the model's framework and version.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/register_experiment_model_sample.py) \n```\ndef register_experiment_model_sample(\u00a0 \u00a0 artifact_id: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 display_name: str,) -> aiplatform.models.Model:\u00a0 \u00a0 experiment_model = aiplatform.get_experiment_model(\u00a0 \u00a0 \u00a0 \u00a0 artifact_id=artifact_id, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_model.register_model(display_name=display_name)\n```\n- `artifact_id`: (Required). The resource ID of the existing`ExperimentModel`.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available   locations](/vertex-ai/docs/general/locations) .\n- `display_name`: Optional. The user-defined name of the   registered model.## View experiment runs list in the Google Cloud console\n- In the Google Cloud console, go to the **Experiments** page. [Go to Experiments](https://console.cloud.google.com/vertex-ai/experiments) A list of experiments appears.\n- Select the experiment that you want to check.A list   of runs appears.\n## What's next\n- [Compare and analyze runs](/vertex-ai/docs/experiments/compare-analyze-runs) \n### Relevant notebook sample\n- [Compare models trained and evaluated locally](/vertex-ai/docs/experiments/user-journey/uj-compare-models) \n### Blog post\n- [Machine Learning Experiments in Gaming and Why it Matters](https://cloud.google.com/blog/topics/developers-practitioners/machine-learning-experiments-gaming-and-why-it-matters)", "guide": "Vertex AI"}