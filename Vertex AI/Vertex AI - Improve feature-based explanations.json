{"title": "Vertex AI - Improve feature-based explanations", "url": "https://cloud.google.com/vertex-ai/docs/explainable-ai/improving-explanations", "abstract": "# Vertex AI - Improve feature-based explanations\nWhen you are working with custom-trained models, you can configure specific parameters to improve your explanations. This guide describes how to inspect the explanations that you get from Vertex Explainable AI for error, and it describes how to adjust your Vertex Explainable AI configuration to mitigate error.\nIf you want to use Vertex Explainable AI with an AutoML tabular model, then you don't need to perform any configuration; Vertex AI automatically configures the model for Vertex Explainable AI. Skip this document and read [Getting explanations](/vertex-ai/docs/explainable-ai/getting-explanations) .\nThe [Vertex Explainable AI feature attributionmethods](/vertex-ai/docs/explainable-ai/overview#compare-methods) are all based on variants of Shapley values. Because Shapley values are very computationally expensive, Vertex Explainable AI provides approximations instead of the exact values.\nYou can reduce the approximation error and get closer to the exact values by changing the following inputs:\n- Increasing the number of integral steps or number of paths.\n- Changing the input baseline(s) you select.\n- Adding more input baselines. With the integrated gradients and XRAI methods, using additional baselines increases latency. Using additional baselines with the sampled Shapley method does not increase latency.", "content": "## Inspect explanations for error\nAfter you have [requested and received explanations fromVertex Explainable AI](/vertex-ai/docs/explainable-ai/getting-explanations) , you can check the explanations for approximation error. If the explanations have high approximation error, then the explanations might not be reliable. This section describes several ways to check for error.\n### Check the approximationError field\nFor each [Attribution](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations#attribution) , Vertex Explainable AI returns approximation error in the `approximationError` field. If your approximation error exceeds 0.05, consider adjusting your Vertex Explainable AI configuration.\nFor the integrated gradients technique, we calculate the approximation error by comparing the sum of the feature attributions to the difference between the predicted values for the input score and the baseline score. For the integrated gradients technique, the feature attribution is an approximation of the integral of gradient values between the baseline and the input. We use the [Gaussian quadrature](https://en.wikipedia.org/wiki/Gaussian_quadrature) rule to approximate the integral because it is more accurate than Riemann Sum methods.\n### Check the difference between predictions and baseline output\nFor each [Attribution](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations#attribution) , Vertex Explainable AI returns an `instanceOutputValue` , which represents the part of the prediction output that feature attributions are for, and a `baselineOutputValue` , which represents what this part of the prediction output would be if the prediction was performed on an input baseline rather than the actual input instance.\nIf the difference between `instanceOutputValue` and `baselineOutputValue` is less than 0.05 for any attributions, then you might need to [change yourinput baselines](#baselines) .\n## Adjust your configuration\nThe following sections describe ways to adjust your Vertex Explainable AI configuration to reduce error. To make any of the following changes, you must [configure a newModel resource with an updatedExplanationSpec](/vertex-ai/docs/explainable-ai/configuring-explanations) or [override theExplanationSpec of your existingModel](/vertex-ai/docs/explainable-ai/configuring-explanations#override) by redeploying it to an `Endpoint` resource or by getting new batch predictions.\n### Increase steps or paths\nTo reduce approximation error, you can increase:\n- the number of paths for sampled Shapley ( [SampledShapleyAttribution.pathCount](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#sampledshapleyattribution) )\n- the number of integral steps for integrated gradients ( [IntegratedGradientsAttribution.stepCount](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#integratedgradientsattribution) ) or XRAI ( [XraiAttribution.stepCount](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#xraiattribution) )\n### Adjust baselines\nInput baselines represent a feature that provides no additional information. Baselines for tabular models can be median, minimum, maximum, or random values in relation to your training data. Similarly, for image models, your baselines can be a black image, a white image, a gray image, or an image with random pixel values.\nWhen you configure Vertex Explainable AI, you can optionally specify the [input_baselines field](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#inputmetadata) . Otherwise, Vertex AI chooses input baselines for you. If you are encountering the problems described in previous sections of this guide, then you might want to adjust the `input_baselines` for each input of your `Model` .\nIn general:\n- Start with one baseline representing median values.\n- Change this baseline to one representing random values.\n- Try two baselines, representing the minimum and maximum values.\n- Add another baseline representing random values.The following Python code creates a [ExplanationMetadatamessage](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata) for a hypothetical TensorFlow model trained on tabular data.\nNotice that `input_baselines` is a list where you can specify multiple baselines. This example sets just one baseline. The baseline is a list of median values for the training data ( `train_data` in this example).\n```\nexplanation_metadata = {\u00a0 \u00a0 \"inputs\": {\u00a0 \u00a0 \u00a0 \u00a0 \"FEATURE_NAME\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"input_tensor_name\": \"INPUT_TENSOR_NAME\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"input_baselines\": [train_data.median().values.tolist()],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"encoding\": \"bag_of_features\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"index_feature_mapping\": train_data.columns.tolist()\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 },\u00a0 \u00a0 \"outputs\": {\u00a0 \u00a0 \u00a0 \u00a0 \"OUTPUT_NAME\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"output_tensor_name\": \"OUTPUT_TENSOR_NAME\"\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }}\n```\nSee [Configuring explanations for custom-trainedmodels](/vertex-ai/docs/explainable-ai/configuring-explanations) for more context on how to use this `ExplanationMetadata`\nTo set two baselines representing minimum and maximum values, set `input_baselines` as follows: `[train_data.min().values.tolist(), train_data.max().values.tolist()]`\nThe following Python code creates a [ExplanationMetadatamessage](/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata) for a hypothetical TensorFlow model trained on image data.\nNotice that `input_baselines` is a list where you can specify multiple baselines. This example sets just one baseline. The baseline is a list of random values. Using random values for an image baseline is a good approach if the images in your training dataset contain a lot of black and white.\nOtherwise, set `input_baselines` to `[0, 1]` to represent black and white images.\n```\nrandom_baseline = np.random.rand(192,192,3)explanation_metadata = {\u00a0 \u00a0 \"inputs\": {\u00a0 \u00a0 \u00a0 \u00a0 \"FEATURE_NAME\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"input_tensor_name\": \"INPUT_TENSOR_NAME\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"modality\": \"image\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"input_baselines\": [random_baseline.tolist()]\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 },\u00a0 \u00a0 \"outputs\": {\u00a0 \u00a0 \u00a0 \u00a0 \"OUTPUT_NAME\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"output_tensor_name\": \"OUTPUT_TENSOR_NAME\"\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }}\n```\n## What's next\n- Follow the guide to [configuringexplanations](/vertex-ai/docs/explainable-ai/configuring-explanations) to implement any configuration changes described on this page.", "guide": "Vertex AI"}