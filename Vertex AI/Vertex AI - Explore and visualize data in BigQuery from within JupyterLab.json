{"title": "Vertex AI - Explore and visualize data in BigQuery from within JupyterLab", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Explore and visualize data in BigQuery from within JupyterLab\n# Explore and visualize data in BigQuery from within JupyterLab\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\nThis page shows you some examples of how to explore and visualize data that is stored in BigQuery from within the JupyterLab interface of your Vertex AI Workbench managed notebooks instance.\nTo see an example of exploring and visualizing BigQuery data as part of a comprehensive workflow in managed notebooks,  run the \"Interactive exploratory analysis of BigQuery data in a notebook\" Jupyter notebook in one of the following  environments: [Openin Vertex AI Workbench managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-managed-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fworkbench%2Fexploratory_data_analysis%2Fexplore_data_in_bigquery_with_workbench.ipynb) | [Openin Colab Enterprise](https://console.cloud.google.com/vertex-ai/colab/import/https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fworkbench%2Fexploratory_data_analysis%2Fexplore_data_in_bigquery_with_workbench.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/workbench/exploratory_data_analysis/explore_data_in_bigquery_with_workbench.ipynb)\n", "content": "## Before you begin\nIf you haven't already, [createa managed notebooks instance](/vertex-ai/docs/workbench/managed/create-instance#create) .\n## Open JupyterLab\n- In the Google Cloud console, go to the **Managed notebooks** page. [Go to Managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/managed) \n- Next to your managed notebooks instance's name, click **Open JupyterLab** .Your managed notebooks instance opens JupyterLab.## Read data from BigQuery\nIn the next two sections, you read data from BigQuery that you will use to visualize later. These steps are identical to those in [Query data in BigQuery fromwithin JupyterLab](/vertex-ai/docs/workbench/managed/bigquery) , so if you've completed them already, you can skip to [Get a summary of data in a BigQuery table](#summary) .\n### Query data by using the %%bigquery magic command\nIn this section, you write SQL directly in notebook cells and read data from BigQuery into the Python notebook.\nMagic commands that use a single or double percentage character ( `%` or `%%` ) let you use minimal syntax to interact with BigQuery within the notebook. The BigQuery client library for Python is automatically installed in a managed notebooks instance. Behind the scenes, the `%%bigquery` magic command uses the BigQuery client library for Python to run the given query, convert the results to a pandas DataFrame, optionally save the results to a variable, and then display the results.\n**Note** : As of version 1.26.0 of the `google-cloud-bigquery` Python package, the [BigQuery Storage API](/bigquery/docs/reference/storage) is used by default to download results from the `%%bigquery` magics.\n- To open a notebook file, select **File > New >Notebook** .\n- In the **Select Kernel** dialog, select **Python (Local)** , and then click **Select** .Your new IPYNB file opens.\n- To get the number of regions by country in the `international_top_terms` dataset, enter the following statement:```\n%%bigquerySELECT\u00a0 country_code,\u00a0 country_name,\u00a0 COUNT(DISTINCT region_code) AS num_regionsFROM\u00a0 `bigquery-public-data.google_trends.international_top_terms`WHERE\u00a0 refresh_date = DATE_SUB(CURRENT_DATE, INTERVAL 1 DAY)GROUP BY\u00a0 country_code,\u00a0 country_nameORDER BY\u00a0 num_regions DESC;\n```\n- Click play_circle_filled **Run cell** .The output is similar to the following:```\nQuery complete after 0.07s: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00, 1440.60query/s]\nDownloading: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 41/41 [00:02<00:00, 20.21rows/s]\ncountry_code  country_name num_regions\n0 TR Turkey   81\n1 TH Thailand  77\n2 VN Vietnam  63\n3 JP Japan   47\n4 RO Romania  42\n5 NG Nigeria  37\n6 IN India   36\n7 ID Indonesia  34\n8 CO Colombia  33\n9 MX Mexico   32\n10 BR Brazil   27\n11 EG Egypt   27\n12 UA Ukraine  27\n13 CH Switzerland 26\n14 AR Argentina  24\n15 FR France   22\n16 SE Sweden   21\n17 HU Hungary  20\n18 IT Italy   20\n19 PT Portugal  20\n20 NO Norway   19\n21 FI Finland  18\n22 NZ New Zealand 17\n23 PH Philippines 17\n...\n``` **Note:** Your results might differ from what is above as the `google_trends` dataset being queried is refreshed with new data on an ongoing basis.\n- In the next cell (below the output from the previous cell), enter the following command to run the same query, but this time save the results to a new pandas DataFrame that's named `regions_by_country` . You provide that name by using an argument with the `%%bigquery` magic command.```\n%%bigquery regions_by_countrySELECT\u00a0 country_code,\u00a0 country_name,\u00a0 COUNT(DISTINCT region_code) AS num_regionsFROM\u00a0 `bigquery-public-data.google_trends.international_top_terms`WHERE\u00a0 refresh_date = DATE_SUB(CURRENT_DATE, INTERVAL 1 DAY)GROUP BY\u00a0 country_code, country_nameORDER BY\u00a0 num_regions DESC;\n``` **Note:** For more information about available arguments for the `%%bigquery` command, see the [client library magics documentation](/python/docs/reference/bigquery/latest/magics) .\n- Click play_circle_filled **Run cell** .\n- In the next cell, enter the following command to look at the first few rows of the query results that you just read in:```\nregions_by_country.head()\n```\n- Click play_circle_filled **Run cell** .The pandas DataFrame `regions_by_country` is ready to plot.\n### Query data by using the BigQuery client library directly\nIn this section, you use the BigQuery client library for Python directly to read data into the Python notebook.\nThe client library gives you more control over your queries and lets you use more complex configurations for queries and jobs. The library's integrations with pandas enable you to combine the power of declarative SQL with imperative code (Python) to help you analyze, visualize, and transform your data.\n**Note:** You can use a number of Python data analysis, data wrangling, and visualization libraries, such as `numpy` , `pandas` , `matplotlib` , and many others. Several of these libraries are built on top of a DataFrame object.\n- In the next cell, enter the following Python code to import the BigQuery client library for Python and initialize a client:```\nfrom google.cloud import bigqueryclient = bigquery.Client()\n```The BigQuery client is used to send and receive messages from the BigQuery API.\n- Click play_circle_filled **Run cell** .\n- In the next cell, enter the following code to retrieve the percentage of daily top terms in the US [top_terms](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=google_trends&t=top_terms&page=table) that overlap across time by number of days apart. The idea here is to look at each day's top terms and see what percentage of them overlap with the top terms from the day before, 2 days prior, 3 days prior, and so on (for all pairs of dates over about a month span).```\nsql = \"\"\"WITH\u00a0 TopTermsByDate AS (\u00a0 \u00a0 SELECT DISTINCT refresh_date AS date, term\u00a0 \u00a0 FROM `bigquery-public-data.google_trends.top_terms`\u00a0 ),\u00a0 DistinctDates AS (\u00a0 \u00a0 SELECT DISTINCT date\u00a0 \u00a0 FROM TopTermsByDate\u00a0 )SELECT\u00a0 DATE_DIFF(Dates2.date, Date1Terms.date, DAY)\u00a0 \u00a0 AS days_apart,\u00a0 COUNT(DISTINCT (Dates2.date || Date1Terms.date))\u00a0 \u00a0 AS num_date_pairs,\u00a0 COUNT(Date1Terms.term) AS num_date1_terms,\u00a0 SUM(IF(Date2Terms.term IS NOT NULL, 1, 0))\u00a0 \u00a0 AS overlap_terms,\u00a0 SAFE_DIVIDE(\u00a0 \u00a0 SUM(IF(Date2Terms.term IS NOT NULL, 1, 0)),\u00a0 \u00a0 COUNT(Date1Terms.term)\u00a0 \u00a0 ) AS pct_overlap_termsFROM\u00a0 TopTermsByDate AS Date1TermsCROSS JOIN\u00a0 DistinctDates AS Dates2LEFT JOIN\u00a0 TopTermsByDate AS Date2Terms\u00a0 ON\u00a0 \u00a0 Dates2.date = Date2Terms.date\u00a0 \u00a0 AND Date1Terms.term = Date2Terms.termWHERE\u00a0 Date1Terms.date <= Dates2.dateGROUP BY\u00a0 days_apartORDER BY\u00a0 days_apart;\"\"\"pct_overlap_terms_by_days_apart = client.query(sql).to_dataframe()pct_overlap_terms_by_days_apart.head()\n```The SQL being used is encapsulated in a Python string and then passed to the [query() method](/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_query) to run a query. The [to_dataframe method](/python/docs/reference/bigquery/latest/google.cloud.bigquery.job.QueryJob#google_cloud_bigquery_job_QueryJob_to_dataframe) waits for the query to finish and downloads the results to a pandas DataFrame by using the BigQuery Storage API.\n- Click play_circle_filled **Runcell** .The first few rows of query results appear below the code cell.```\n days_apart num_date_pairs num_date1_terms overlap_terms pct_overlap_terms\n 0   0    32    800   800   1.000000\n 1   1    31    775   203   0.261935\n 2   2    30    750    73   0.097333\n 3   3    29    725    31   0.042759\n 4   4    28    700    23   0.032857\n``` **Note:** Your results might differ from what is above as the `google_trends` dataset being queried is refreshed with new data on an ongoing basis.\nFor more information about using BigQuery client libraries, see the quickstart [Using client libraries](/bigquery/docs/quickstarts/quickstart-client-libraries) .\n## Get a summary of data in a BigQuery table\nIn this section, you use a notebook shortcut to get summary statistics and visualizations for all fields of a BigQuery table. This can be a fast way to profile your data before exploring further.\nThe BigQuery client library provides a magic command, `%bigquery_stats` , that you can call with a specific table name to provide an overview of the table and detailed statistics on each of the table's columns.\n- In the next cell, enter the following code to run that analysis on the US [top_terms table](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=google_trends&t=top_terms&page=table) :```\n%bigquery_stats bigquery-public-data.google_trends.top_terms\n```\n- Click play_circle_filled **Run cell** .After running for some time, an image appears with various statistics on each of the 7 variables in the `top_terms` table. The following image shows part of some example output: \n**Note:** Your results might differ from what is above as the `google_trends` dataset being queried is refreshed with new data on an ongoing basis.\n## Visualize BigQuery data\nIn this section, you use plotting capabilities to visualize the results from the queries that you previously ran in your Jupyter notebook.\n- In the next cell, enter the following code to use the pandas `DataFrame.plot()` method to create a bar chart that visualizes the results of the query that returns the number of regions by country:```\nregions_by_country.plot(kind=\"bar\", x=\"country_name\", y=\"num_regions\", figsize=(15, 10))\n```\n- Click play_circle_filled **Run cell** .The chart is similar to the following: \n- In the next cell, enter the following code to use the pandas `DataFrame.plot()` method to create a scatter plot that visualizes the results from the query for the percentage of overlap in the top search terms by days apart:```\npct_overlap_terms_by_days_apart.plot(\u00a0 kind=\"scatter\",\u00a0 x=\"days_apart\",\u00a0 y=\"pct_overlap_terms\",\u00a0 s=len(pct_overlap_terms_by_days_apart[\"num_date_pairs\"]) * 20,\u00a0 figsize=(15, 10)\u00a0 )\n```\n- Click play_circle_filled **Run cell** .The chart is similar to the following. The size of each point reflects the number of date pairs that are that many days apart in the data. For example, there are more pairs that are 1 day apart than 30 days apart because the top search terms are surfaced daily over about a month's time. \nFor more information about data visualization, see the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/visualization.html) .", "guide": "Vertex AI"}