{"title": "Vertex AI - Training classes", "url": "https://cloud.google.com/vertex-ai/docs/python-sdk/training-classes", "abstract": "# Vertex AI - Training classes\nThe Vertex AI SDK includes several classes that you use when you train your model. Most of the training classes are used to create, train, and return your model. Use the [HyperparameterTuningJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob) to tune the training job's hyperparameters. Use the [PipelineJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob) manage your machine learning (ML) workflow so you can you automate and monitor your ML systems.\nThe following topics provide a high-level description of each training-related class in the Vertex AI SDK.\n", "content": "## AutoML training classes for structured data\nVertex AI SDK includes the following classes that are used to train a structured AutoML model.\n### AutoMLForecastingTrainingJob\nThe [AutoMLForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLForecastingTrainingJob) class uses the `AutoML` training method to train and run a forecasting model. The `AutoML` training method is a good choice for most forecasting use cases. If your use case doesn't benefit from the `Seq2seq` or the `Temporal fusion transformer` training method offered by the [SequenceToSequencePlusForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.SequenceToSequencePlusForecastingTrainingJob) and [TemporalFusionTransformerForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.TemporalFusionTransformerForecastingTrainingJob) classes respectively, then `AutoML` is likely the best training method for your forecasting predictions.\nFor sample code that shows you how to use [AutoMLForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLForecastingTrainingJob) , see the [Create a training pipeline forecasting sample](https://github.com/googleapis/python-aiplatform/blob/8ddc062669044ac0889d9f27c93a8b36c1140433/samples/model-builder/create_training_pipeline_forecasting_sample.py) on GitHub.\n### AutoMLTabularTrainingJob\nThe [AutoMLTabularTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLTabularTrainingJob) class represents a job that creates, trains, and returns an `AutoML` tabular model. For more information about training tabular models and Vertex AI, see [Tabular data](/vertex-ai/docs/training-overview#tabular_data) and [Tabular dataoverview](/vertex-ai/docs/tabular-data/overview) .\nThe following sample code snippet shows how you might use the Vertex AI SDK to create and run an `AutoML` tabular model:\n```\ndataset = aiplatform.TabularDataset('projects/my-project/location/us-central1/datasets/{DATASET_ID}')job = aiplatform.AutoMLTabularTrainingJob(\u00a0 display_name=\"train-automl\",\u00a0 optimization_prediction_type=\"regression\",\u00a0 optimization_objective=\"minimize-rmse\",)model = job.run(\u00a0 \u00a0 dataset=dataset,\u00a0 \u00a0 target_column=\"target_column_name\",\u00a0 \u00a0 training_fraction_split=0.6,\u00a0 \u00a0 validation_fraction_split=0.2,\u00a0 \u00a0 test_fraction_split=0.2,\u00a0 \u00a0 budget_milli_node_hours=1000,\u00a0 \u00a0 model_display_name=\"my-automl-model\",\u00a0 \u00a0 disable_early_stopping=False,)\n```\n### SequenceToSequencePlusForecastingTrainingJob\nThe [SequenceToSequencePlusForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.SequenceToSequencePlusForecastingTrainingJob) class uses the `Seq2seq+` training method to train and run a forecasting model. The `Seq2seq+` training method is a good choice for experimentation. Its algorithm is simpler and uses a smaller search space than the `AutoML` option. `Seq2seq+` is a good option if you want fast results and your datasets are smaller than 1 GB.\nFor sample code that shows you how to use [SequenceToSequencePlusForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.SequenceToSequencePlusForecastingTrainingJob) , see the [Create a training pipeline forecasting Seq2seq sample](https://github.com/googleapis/python-aiplatform/blob/8ddc062669044ac0889d9f27c93a8b36c1140433/samples/model-builder/create_training_pipeline_forecasting_seq2seq_sample.py) on GitHub.\n### TemporalFusionTransformerForecastingTrainingJob\nThe [TemporalFusionTransformerForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.TemporalFusionTransformerForecastingTrainingJob) class uses the Temporal Fusion Transformer (TFT) training method to train and run a forecasting model. The TFT training method implements an attention-based deep neural network (DNN) model that uses a multi-horizon forecasting task to produce predictions.\nFor sample code that shows you how to use [TemporalFusionTransformerForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.TemporalFusionTransformerForecastingTrainingJob) , see the [Create a training pipeline forecasting temporal fusion transformersample](https://github.com/googleapis/python-aiplatform/blob/8ddc062669044ac0889d9f27c93a8b36c1140433/samples/model-builder/create_training_pipeline_forecasting_tft_sample.py) on GitHub.\n### TimeSeriesDenseEncoderForecastingTrainingJob\nThe [TimeSeriesDenseEncoderForecastingTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.TimeSeriesDenseEncoderForecastingTrainingJob) class uses the Time-series Dense Encoder (TiDE) training method to train and run a forecasting model. TiDE uses a [multi-layer perceptron](https://arxiv.org/abs/2304.08424) (MLP) to provide the speed of forecasting linear models with covariates and non-linear dependencies. For more information about TiDE, see [Recent advances in deep long-horizon forecasting](https://blog.research.google/2023/04/recent-advances-in-deep-long-horizon.html) and this [TiDE blog post](https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-forecasting) .\n## AutoML training classes for unstructured data\nThe Vertex AI SDK includes the following classes to train unstructured image, text, and video models:\n### AutoMLImageTrainingJob\nUse the [AutoMLImageTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLImageTrainingJob) class to create, train, and return an image model. For more information about working with image data models in Vertex AI, see [Image data](/vertex-ai/docs/training-overview#image_data) .\nFor an example of how to use the [AutoMLImageTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLImageTrainingJob) class, see the tutorial in the [AutoML imageclassification](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-automl-text-classification-batch-prediction.ipynb) notebook.\n### AutoMLTextTrainingJob\nUse the [AutoMLTextTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLTextTrainingJob) class to create, train, and return a text model. For more information about working with text data models in Vertex AI, see [Text data](/vertex-ai/docs/training-overview#text_data) .\nFor an example of how to use the [AutoMLTextTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLTextTrainingJob) class, see the tutorial in the [AutoML training text entity extraction model for onlineprediction](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_text_entity_extraction_online.ipynb) notebook.\n### AutoMLVideoTrainingJob\nUse the [AutoMLVideoTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLVideoTrainingJob) class to create, train, and return a video model. For more information about working with video data models in Vertex AI, see [Video data](/vertex-ai/docs/training-overview#video_data) .\nFor an example of how to use the [AutoMLVideoTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.AutoMLVideoTrainingJob) class, see the tutorial in the [AutoML training video action recognition model for batchprediction](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/automl/sdk_automl_video_action_recognition_batch.ipynb) notebook.\n## Custom data training classes\nYou can use the Vertex AI SDK to automate a custom training workflow. For information about using Vertex AI to run custom training applications, see [Custom training overview](/vertex-ai/docs/training/overview) .\nThe Vertex AI SDK includes three classes that create a custom training pipeline. A training pipeline accepts an input Vertex AI managed dataset that it uses to train a model. Next, it returns the model after the training job completes. Each of the three custom training pipeline classes creates a training pipeline differently. [CustomTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob) uses a Python script, [CustomContainerTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob) uses a custom container, and [CustomPythonPackageTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob) uses a Python package and a prebuilt container.\nThe [CustomJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob) class creates a custom training job but is not a pipeline. Unlike a custom training pipeline, the [CustomJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob) class can use a dataset that's not a Vertex AI managed dataset to train a model, and it doesn't return the trained model. Because the class accepts different types of datasets and doesn't return a trained model, it's less automated and more flexible than a custom training pipeline.\n### CustomContainerTrainingJob\nUse the [CustomContainerTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob) class to use a container to launch a custom training pipeline in Vertex AI.\nFor an example of how to use the [CustomContainerTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob) class, see the tutorial in the [PyTorch Image Classification Multi-Node DistributedData Parallel Training on GPU using Vertex AI Training with Custom Container](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/multi_node_ddp_nccl_vertex_training_with_custom_container.ipynb) notebook.\n### CustomJob\nUse the [CustomJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob) class to use a script to launch a custom training job in Vertex AI.\nA training job is more flexible than a training pipeline because you aren't restricted to loading your data in a Vertex AI managed dataset and a reference to your model isn't registered after the training job completes. For example, you might want to use the [CustomJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob) class, its [from_local_script](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script) method, and a script to load a dataset from [scikit-learn](https://scikit-learn.org/) or [TensorFlow](https://www.tensorflow.org/) . Or, you might want to analyze or test your trained model before it's registered to Vertex AI.\nFor more information about custom training jobs, including requirements before submitting a custom training job, what a custom job includes, and a Python code sample, see [Create custom training jobs](/vertex-ai/docs/training/create-custom-job#create_custom_job-python) .\nBecause the [CustomJob.run](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_run) doesn't return the trained model, you need to use a script to write the model artifact to a location, such as a Cloud Storage bucket. For more information, see [Export a trained ML model](/vertex-ai/docs/training/code-requirements#export) .\nThe following sample code demonstrates how to create and run a custom job using a sample worker pool specification. The code writes the trained model to a Cloud Storage bucket named .\n```\n# Create a worker pool spec that specifies a TensorFlow cassava dataset and# includes the machine type and Docker image. The Google Cloud project ID# is 'project-id'.worker_pool_specs=[\u00a0 \u00a0 \u00a0{\u00a0 \u00a0 \u00a0 \u00a0 \"replica_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \"machine_spec\": { \"machine_type\": \"n1-standard-8\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_type\": \"NVIDIA_TESLA_V100\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_count\": 1\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \"container_spec\": {\"image_uri\": \"gcr.io/{project-id}/multiworker:cassava\"}\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \"replica_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \"machine_spec\": { \"machine_type\": \"n1-standard-8\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_type\": \"NVIDIA_TESLA_V100\", \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_count\": 1\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \"container_spec\": {\"image_uri\": \"gcr.io/{project-id}/multiworker:cassava\"}\u00a0 \u00a0 \u00a0 }]# Use the worker pool spec to create a custom training job. The custom training # job artifacts are stored in the Cloud Storage bucket# named 'artifact-bucket'.your_custom_training_job = aiplatform.CustomJob(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 display_name='multiworker-cassava-sdk',\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 worker_pool_specs=worker_pool_specs,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 staging_bucket='gs://{artifact-bucket}')# Run the training job. This method doesn't return the trained model.my_multiworker_job.run()\n```\n### CustomPythonPackageTrainingJob\nUse the [CustomPythonPackageTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob) class to use a Python package to launch a custom training pipeline in Vertex AI.\nFor an example of how to use the [CustomPythonPackageTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomPythonPackageTrainingJob) class, see the tutorial in the [Custom training using Python package, managedtext dataset, and TensorFlow servingcontainer](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/sdk/SDK_Custom_Training_Python_Package_Managed_Text_Dataset_Tensorflow_Serving_Container.ipynb) notebook.\n### CustomTrainingJob\nUse the [CustomTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob) class to launch a custom training pipeline in Vertex AI with a script.\nFor an example of how to use the [CustomTrainingJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomTrainingJob) class, see the tutorial in the [Custom training image classification model for online prediction withexplainability](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/explainable_ai/sdk_custom_image_classification_online_explain.ipynb) notebook.\n## Hyperparameter training class\nThe Vertex AI SDK includes a class for hyperparameter tuning. Hyperparameter tuning maximizes your model's predictive accuracy by optimizing variables (known as ) that govern the training process. For more information, see [Overview of hyperparametertuning](/vertex-ai/docs/training/hyperparameter-tuning-overview) .\n### HyperparameterTuningJob\nUse the [HyperparameterTuningJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob) class to automate hyperparameter tuning on a training application.\nTo learn how to use the [HyperparameterTuningJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob) class create and tune a custom trained model, see the [Hyperparameter tuning](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/migration/sdk-hyperparameter-tuning.ipynb) tutorial on GitHub.\nTo learn how to use the [HyperparameterTuningJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.HyperparameterTuningJob) class to run a Vertex AI hyperparameter tuning job for a TensorFlow model, see the [Run hyperparameter tuning for a TensorFlow model](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/hyperparameter_tuning_tensorflow.ipynb) tutorial on GitHub.\n## Pipeline training class\nA pipeline orchestrates your ML workflow in Vertex AI. You can use a pipeline to automate, monitor, and govern your machine learning systems. To learn more about pipelines in Vertex AI, see [Introduction to Vertex AI pipelines](/vertex-ai/docs/pipelines/introduction) .\n### PipelineJob\nAn instance of the [PipelineJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob) class represents a Vertex AI pipeline.\nThere are several tutorial notebooks that demonstrate how to use the [PipelineJob](/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.PipelineJob) class:\n- To learn how to run a [Kubeflow Pipelines (KFP)](https://www.kubeflow.org/docs/components/pipelines/) pipeline, see the [Pipeline control structures using the KFP SDK](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/control_flow_kfp.ipynb) tutorial on GitHub.\n- To learn how to train a [scikit-learn](https://scikit-learn.org/stable/) tabular classification model and create a batch prediction job with a Vertex AI pipeline, see the [Training and batch prediction with BigQuery source and destination for a custom tabular classification model](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/custom_tabular_train_batch_pred_bq_pipeline.ipynb) tutorial on GitHub.\n- To learn how to build an AutoML image classification model and use a Vertex AI pipeline, see the [AutoML image classification pipelines using google-cloud-pipeline-components](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cloud_pipeline_components_automl_images.ipynb) tutorial on GitHub.\n- To learn how to use a pipeline to build an AutoML text classification model, see the [AutoML text classification pipelines using google-cloud-pipeline-components](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/google_cloud_pipeline_components_automl_text.ipynb) tutorial on GitHub.\nFor more tutorial notebooks, see [Vertex AI notebook tutorials](/vertex-ai/docs/tutorials/jupyter-notebooks) .\n## What's next\n- Learn about the [Vertex AI SDK](/vertex-ai/docs/python-sdk/use-vertex-ai-python-sdk) .", "guide": "Vertex AI"}