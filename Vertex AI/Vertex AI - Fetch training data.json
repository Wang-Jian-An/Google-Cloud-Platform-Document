{"title": "Vertex AI - Fetch training data", "url": "https://cloud.google.com/vertex-ai/docs/featurestore/serving-batch", "abstract": "# Vertex AI - Fetch training data\nTo learn more,  run the \"Example Feature Store workflow with sample data\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ffeature_store%2Fsdk-feature-store.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/feature_store/sdk-feature-store.ipynb)\nTo fetch feature data for model training, use batch serving. If you need to export feature values for archiving or ad-hoc analysis, [export featurevalues](/vertex-ai/docs/featurestore/export-features) instead.\n", "content": "## Fetch feature values for model training\nFor model training, you need a training data set that contains examples of your prediction task. These examples consist of that include their features and . The instance is the thing about which you want to make a prediction. For example, an instance might be a home, and you want to determine its market value. Its features might include its location, age, and the average price of nearby homes that were recently sold. A label is an answer for the prediction task, such as the home eventually sold for $100K.\nBecause each label is an observation at a specific point in time, you need to fetch feature values that correspond to that point in time when the observation was made\u2014for example, the prices of nearby homes when a particular home was sold. As labels and feature values are collected over time, those feature values change. Vertex AI Feature Store (Legacy) can perform a point-in-time lookup so that you can fetch the feature values at a particular time.\n## Example point-in-time lookup\nThe following example involves retrieving feature values for two training instances with labels `L1` and `L2` . The two labels are observed at `T1` and `T2` , respectively. Imagine freezing the state of the feature values at those timestamps. Hence, for the point-in-time lookup at `T1` , Vertex AI Feature Store (Legacy) returns the latest feature values up to time `T1` for `Feature 1` , `Feature 2` , and `Feature 3` and doesn't leak any values past `T1` . As time progresses, the feature values change and the label also changes. So, at `T2` , Feature Store returns different feature values for that point in time.\n## Batch serving inputs\nAs part of a batch serving request, the following information is required:\n- A list of existing features to get values for.\n- Athat contains information for each training example. It lists observations at a particular point in time. This can be either a CSV file or a BigQuery table. The list must include the following information:- **Timestamps** : the times at which labels were observed or measured. The timestamps are required so that Vertex AI Feature Store (Legacy) can perform a point-in-time lookup.\n- **Entity IDs** : one or more IDs of the entities that correspond to the label.\n- The destination URI and format where the output is written. In the output, Vertex AI Feature Store (Legacy) essentially joins the table from the read instances list and the feature values from the featurestore. Specify one of the following formats and locations for the output:- BigQuery table in a regional or multi-regional dataset.\n- CSV file in a regional or multi-regional Cloud Storage bucket. But if your feature values include arrays, you must choose another format.\n- [Tfrecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) file in a Cloud Storage bucket.\n### Region Requirements\nFor both read instances and destination, the source dataset or bucket must be in the same region or in the same multi-regional location as your featurestore. For example, a featurestore in `us-central1` can only read data from or serve data to Cloud Storage buckets or BigQuery datasets that are in `us-central1` or in the US multi-region location. You can't use data from, for example, `us-east1` . Also, reading or serving data using dual-region buckets isn't supported.\n## Read-instance list\nThe read-instance list specifies the entities and timestamps for the feature values that you want to retrieve. The CSV file or BigQuery table must contain the following columns, in any order. Each column requires a column header.\n- You must include a timestamp column, where the header name is`timestamp`and the column values are timestamps in the RFC 3339 format.\n- You must include one or more entity type columns, where the header is the entity type ID and the column values are the entity IDs.\n- Optional: You can include pass-through values (additional columns), which are passed as-is to the output. This is useful if you have data that isn't in Vertex AI Feature Store (Legacy) but want to include that data in the output.\n### Example (CSV)\nImagine a featurestore that contains the entity types `users` and `movies` along with their features. For example, features for `users` might include `age` and `gender` while features for `movies` might include `ratings` and `genre` .\nFor this example, you want to gather training data about users' movie preferences. You retrieve feature values for the two user entities `alice` and `bob` along with features from the movies they watched. From a separate dataset, you know that `alice` watched `movie_01` and liked it. `bob` watched `movie_02` and didn't like it. So, the read-instance list might look like the following example:\n```\nusers,movies,timestamp,liked\n\"alice\",\"movie_01\",2021-04-15T08:28:14Z,true\n\"bob\",\"movie_02\",2021-04-15T08:28:14Z,false\n```\nVertex AI Feature Store (Legacy) retrieves feature values for the listed entities at or before the given timestamps. You specify the specific features to get as part of the batch serving request, not in the read-instance list.\nThis example also includes a column called `liked` , which indicates whether a user liked a movie. This column isn't included in the featurestore, but you can still pass these values to your batch serving output. In the output, these pass-through values are joined together with the values from the featurestore.\n## Null values\nIf, at a given timestamp, a feature value is null, Vertex AI Feature Store (Legacy) returns the previous non-null feature value. If there are no previous values, Vertex AI Feature Store (Legacy) returns null.\n## Batch serve feature values\nBatch serve feature values from a featurestore to get data, as determined by your read instances list file.\nIf you want to lower offline storage usage costs by reading recent training data and excluding old data, specify a start time. To learn how to lower the offline storage usage cost by specifying a start time, see [Specify a start time to optimize offline storage costs during batch serve and batch export](/vertex-ai/docs/featurestore/best-practices#starttime_batch_serving) .\nUse another method. You cannot batch serve features from the Google Cloud console.To batch serve feature values, send a POST request by using the [featurestores.batchReadFeatureValues](/vertex-ai/docs/reference/rest/v1/projects.locations.featurestores/batchReadFeatureValues) method.\nThe following sample outputs a BigQuery table that contains feature values for the `users` and `movies` entity types. Note that each output destination might have some prerequisites before you can submit a request. For example, if you specify a table name for the `bigqueryDestination` field, you must have an existing dataset. These requirements are documented in the API reference.\nBefore using any of the request data, make the following replacements:- : Region where the featurestore is created. For example,`us-central1`.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : ID of the featurestore.\n- : Name of the destination BigQuery dataset.\n- : Name of the destination BigQuery table.\n- : Cloud Storage URI to the read-instances CSV file.\nHTTP method and URL:\n```\nPOST https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/featurestores/FEATURESTORE_ID:batchReadFeatureValues\n```\nRequest JSON body:\n```\n{\n \"destination\": {\n \"bigqueryDestination\": {\n  \"outputUri\": \"bq://PROJECT_ID.DATASET_NAME.TABLE_NAME\"\n }\n },\n \"csvReadInstances\": {\n \"gcsSource\": {\n  \"uris\": [\"STORAGE_LOCATION\"]\n }\n },\n \"entityTypeSpecs\": [ {\n  \"entityTypeId\": \"users\",\n  \"featureSelector\": {\n  \"idMatcher\": {\n   \"ids\": [\"age\", \"liked_genres\"]\n  }\n  }\n },\n {\n  \"entityTypeId\": \"movies\",\n  \"featureSelector\": {\n  \"idMatcher\": {\n   \"ids\": [\"title\", \"average_rating\", \"genres\"]\n  }\n  }\n }\n ],\n \"passThroughFields\": [ {\n  \"fieldName\": \"liked\"\n }\n ]\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/featurestores/FEATURESTORE_ID:batchReadFeatureValues\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/featurestores/FEATURESTORE_ID:batchReadFeatureValues\" | Select-Object -Expand Content\n```\nYou should see output similar to the following. You can use the in the response to [get the status](/vertex-ai/docs/general/long-running-operations) of the operation.\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION_ID/featurestores/FEATURESTORE_ID/operations/OPERATION_ID\",\n \"metadata\": {\n \"@type\": \"type.googleapis.com/google.cloud.aiplatform.v1.BatchReadFeatureValuesOperationMetadata\",\n \"genericMetadata\": {\n  \"createTime\": \"2021-03-02T00:03:41.558337Z\",\n  \"updateTime\": \"2021-03-02T00:03:41.558337Z\"\n }\n }\n}\n```\nTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/batch_serve_features_to_bq_sample.py) \n```\nfrom google.cloud import aiplatformdef batch_serve_features_to_bq_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 featurestore_name: str,\u00a0 \u00a0 bq_destination_output_uri: str,\u00a0 \u00a0 read_instances_uri: str,\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 fs = aiplatform.featurestore.Featurestore(featurestore_name=featurestore_name)\u00a0 \u00a0 SERVING_FEATURE_IDS = {\u00a0 \u00a0 \u00a0 \u00a0 \"users\": [\"age\", \"gender\", \"liked_genres\"],\u00a0 \u00a0 \u00a0 \u00a0 \"movies\": [\"title\", \"average_rating\", \"genres\"],\u00a0 \u00a0 }\u00a0 \u00a0 fs.batch_serve_to_bq(\u00a0 \u00a0 \u00a0 \u00a0 bq_destination_output_uri=bq_destination_output_uri,\u00a0 \u00a0 \u00a0 \u00a0 serving_feature_ids=SERVING_FEATURE_IDS,\u00a0 \u00a0 \u00a0 \u00a0 read_instances_uri=read_instances_uri,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\n```You can [install](/vertex-ai/docs/start/client-libraries) and use the following Vertex AI client libraries to call the Vertex AI API. Cloud Client Libraries provide an optimized developer experience by using the natural conventions and styles of each supported language.- [Java](/java/docs/reference/google-cloud-aiplatform/latest/overview) \n- [Node.js](/nodejs/docs/reference/aiplatform/latest) \n## View batch serving jobs\nUse the Google Cloud console to view batch serving jobs in a Google Cloud project.\n- In the Vertex AI section of the Google Cloud console, go to  the **Features** page. [Go to the Features page](https://console.cloud.google.com/vertex-ai/features) \n- Select a region from the **Region** drop-down list.\n- From the action bar, click **View batch serving jobs** to list the batch serving jobs for all featurestores.\n- Click the ID of a batch serving job to view its details, such as the read instance source that was used and the output destination.\n## What's next\n- Learn how to [batch ingest feature values](/vertex-ai/docs/featurestore/ingesting-batch) .\n- Learn how to serve features through [onlineserving](/vertex-ai/docs/featurestore/serving-online) .\n- View the Vertex AI Feature Store (Legacy) [concurrent batch jobquota](/vertex-ai/quotas#featurestore) .\n- [Troubleshoot](/vertex-ai/docs/general/troubleshooting#feature-store) common Vertex AI Feature Store (Legacy) issues.", "guide": "Vertex AI"}