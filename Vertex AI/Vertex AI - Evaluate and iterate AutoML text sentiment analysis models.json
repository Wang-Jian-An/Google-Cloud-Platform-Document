{"title": "Vertex AI - Evaluate and iterate AutoML text sentiment analysis models", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Evaluate and iterate AutoML text sentiment analysis models\nVertex AI provides model evaluation metrics to help you determine the performance of your models, such as precision and recall metrics. Vertex AI calculates evaluation metrics by using the [testset](/vertex-ai/docs/general/ml-use) .\n", "content": "## How you use model evaluation metrics\nModel evaluation metrics provide quantitative measurements of how your model performed on the test set. How you interpret and use those metrics depends on your business need and the problem your model is trained to solve. For example, you might have a lower tolerance for false positives than for false negatives or the other way around. These kinds of questions affect which metrics you would focus on.\nFor more information about iterating on your model to improve its performance, see [Iterating on your model](#iterate) .\n## Evaluation metrics returned by Vertex AI\nVertex AI returns several different evaluation metrics such as precision, recall, and confidence thresholds. The metrics that Vertex AI returns depend on your model's objective. For example, Vertex AI provides different evaluation metrics for an image classification model compared to an image object detection model.\nA schema file, downloadable from a Cloud Storage location, determines which evaluation metrics Vertex AI provides for each objective. The following tabs provide links to the schema files and describes the evaluation metrics for each model objective.\nYou can view and download schema files from the following Cloud Storage location:  [gs://google-cloud-aiplatform/schema/modelevaluation/](https://console.cloud.google.com/storage/browser/google-cloud-aiplatform/schema/modelevaluation)\n- **Recall** : The fraction of predictions with this class that the model correctly predicted. Also called.\n- **Precision** : The fraction of classification predictions produced by the model that were correct.\n- **F1 score** : The harmonic mean of precision and recall. F1 is a useful metric if you're looking for a balance between precision and recall and there's an uneven class distribution.\n- **MAE** : The mean absolute error (MAE) is the average absolute difference between the target values and the predicted values. This metric ranges from zero to infinity; a lower value indicates a higher quality model.\n- **MSE** : The mean squared error (MSE) measures the differences between the values predicted by a model or an estimator and the values observed. Lower values indicate more accurate models.\n- **Linear-weighted kappa and Quadratic-weighted kappa** : measure how closely the sentiment values assigned by the model agree with values assigned by human raters. Higher values indicate more accurate models.\n- **Confusion matrix** : A [confusionmatrix](https://developers.google.com/machine-learning/glossary#confusion-matrix) shows how often a model correctly predicted a result. For incorrectly predicted results, the matrix shows what the model predicted instead. The confusion matrix helps you understand where your model is \"confusing\" two results.\n## Getting evaluation metrics\nYou can get an aggregate set of evaluation metrics for your model and, for some objectives, evaluation metrics for a particular class or label. Evaluation metrics for a particular class or label is also known as an . The following content describes how to get aggregate evaluation metrics and evaluation slices by using the Google Cloud console or API.\n- In the Google Cloud console, in the Vertex AI section, go to the **Models** page. [Go to the Models page](https://console.cloud.google.com/vertex-ai/models) \n- In the **Region** drop-down, select the region where your model located.\n- From the list of models, click your model, which opens the model's **Evaluate** tab.In the **Evaluate** tab, you can view your model's aggregate evaluation metrics, such as the **Average precision** and **Recall** .If the model objective has evaluation slices, the console shows a list of labels. You can click a label to view evaluation metrics for that label, as shown in the following example:\nAPI requests for getting evaluation metrics is the same for each data type and objective, but the outputs are different. The following samples show the same request but different responses.The aggregate model evaluation metrics provide information about the model as a whole. To see information about a specific slice, list the [modelevaluation slices](#list-slices) .\nTo view aggregate model evaluation metrics, use the [projects.locations.models.evaluations.get](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations) method.\nSelect a tab that corresponds to your language or environment:Before using any of the request data, make the following replacements:- : Region where your model is stored.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : The ID of the.\n- : Your project's automatically generated [project number](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : ID for the model evaluation (appears in the response).\nHTTP method and URL:\n```\nGET https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nExecute the following command:\n```\ncurl -X GET \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nExecute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method GET ` -Headers $headers ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:Before trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/GetModelEvaluationTextSentimentAnalysisSample.java) \n```\nimport com.google.cloud.aiplatform.v1.ModelEvaluation;import com.google.cloud.aiplatform.v1.ModelEvaluationName;import com.google.cloud.aiplatform.v1.ModelServiceClient;import com.google.cloud.aiplatform.v1.ModelServiceSettings;import java.io.IOException;public class GetModelEvaluationTextSentimentAnalysisSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 // To obtain evaluationId run the code block below after setting modelServiceSettings.\u00a0 \u00a0 //\u00a0 \u00a0 // try (ModelServiceClient modelServiceClient = ModelServiceClient.create(modelServiceSettings))\u00a0 \u00a0 // {\u00a0 \u00a0 // \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // \u00a0 ModelName modelFullId = ModelName.of(project, location, modelId);\u00a0 \u00a0 // \u00a0 ListModelEvaluationsRequest modelEvaluationsrequest =\u00a0 \u00a0 // \u00a0 ListModelEvaluationsRequest.newBuilder().setParent(modelFullId.toString()).build();\u00a0 \u00a0 // \u00a0 for (ModelEvaluation modelEvaluation :\u00a0 \u00a0 // \u00a0 \u00a0 modelServiceClient.listModelEvaluations(modelEvaluationsrequest).iterateAll()) {\u00a0 \u00a0 // \u00a0 \u00a0 \u00a0 System.out.format(\"Model Evaluation Name: %s%n\", modelEvaluation.getName());\u00a0 \u00a0 // \u00a0 }\u00a0 \u00a0 // }\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String modelId = \"YOUR_MODEL_ID\";\u00a0 \u00a0 String evaluationId = \"YOUR_EVALUATION_ID\";\u00a0 \u00a0 getModelEvaluationTextSentimentAnalysisSample(project, modelId, evaluationId);\u00a0 }\u00a0 static void getModelEvaluationTextSentimentAnalysisSample(\u00a0 \u00a0 \u00a0 String project, String modelId, String evaluationId) throws IOException {\u00a0 \u00a0 ModelServiceSettings modelServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 ModelServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (ModelServiceClient modelServiceClient = ModelServiceClient.create(modelServiceSettings)) {\u00a0 \u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 \u00a0 ModelEvaluationName modelEvaluationName =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ModelEvaluationName.of(project, location, modelId, evaluationId);\u00a0 \u00a0 \u00a0 ModelEvaluation modelEvaluation = modelServiceClient.getModelEvaluation(modelEvaluationName);\u00a0 \u00a0 \u00a0 System.out.println(\"Get Model Evaluation Text Sentiment Analysis Response\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\tModel Name: %s\\n\", modelEvaluation.getName());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tMetrics Schema Uri: %s\\n\", modelEvaluation.getMetricsSchemaUri());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tMetrics: %s\\n\", modelEvaluation.getMetrics());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tCreate Time: %s\\n\", modelEvaluation.getCreateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tSlice Dimensions: %s\\n\", modelEvaluation.getSliceDimensionsList());\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/get-model-evaluation-text-sentiment-analysis.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample\u00a0* (not necessary if passing values as arguments). To obtain evaluationId,\u00a0* instantiate the client and run the following the commands.\u00a0*/// const parentName = `projects/${project}/locations/${location}/models/${modelId}`;// const evalRequest = {// \u00a0 parent: parentName// };// const [evalResponse] = await modelServiceClient.listModelEvaluations(evalRequest);// console.log(evalResponse);// const modelId = 'YOUR_MODEL_ID';// const evaluationId = 'YOUR_EVALUATION_ID';// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';// Imports the Google Cloud Model Service Client libraryconst {ModelServiceClient} = require('@google-cloud/aiplatform');// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};// Instantiates a clientconst modelServiceClient = new ModelServiceClient(clientOptions);async function getModelEvaluationTextSentimentAnalysis() {\u00a0 // Configure the resources\u00a0 const name = `projects/${project}/locations/${location}/models/${modelId}/evaluations/${evaluationId}`;\u00a0 const request = {\u00a0 \u00a0 name,\u00a0 };\u00a0 // Get model evaluation request\u00a0 const [response] = await modelServiceClient.getModelEvaluation(request);\u00a0 console.log('Get model evaluation text sentiment analysis response :');\u00a0 console.log(`\\tName : ${response.name}`);\u00a0 console.log(`\\tMetrics schema uri : ${response.metricsSchemaUri}`);\u00a0 console.log(`\\tMetrics : ${JSON.stringify(response.metrics)}`);\u00a0 const modelExplanation = response.modelExplanation;\u00a0 console.log('\\tModel explanation');\u00a0 if (modelExplanation === null) {\u00a0 \u00a0 console.log('\\t\\t{}');\u00a0 } else {\u00a0 \u00a0 const meanAttributions = modelExplanation.meanAttributions;\u00a0 \u00a0 if (meanAttributions === null) {\u00a0 \u00a0 \u00a0 console.log('\\t\\t\\t []');\u00a0 \u00a0 } else {\u00a0 \u00a0 \u00a0 for (const meanAttribution of meanAttributions) {\u00a0 \u00a0 \u00a0 \u00a0 console.log('\\t\\tMean attribution');\u00a0 \u00a0 \u00a0 \u00a0 console.log(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `\\t\\t\\tBaseline output value : \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ${meanAttribution.baselineOutputValue}`\u00a0 \u00a0 \u00a0 \u00a0 );\u00a0 \u00a0 \u00a0 \u00a0 console.log(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `\\t\\t\\tInstance output value : \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ${meanAttribution.instanceOutputValue}`\u00a0 \u00a0 \u00a0 \u00a0 );\u00a0 \u00a0 \u00a0 \u00a0 console.log(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `\\t\\t\\tFeature attributions : \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ${JSON.stringify(meanAttribution.featureAttributions)}`\u00a0 \u00a0 \u00a0 \u00a0 );\u00a0 \u00a0 \u00a0 \u00a0 console.log(`\\t\\t\\tOutput index : ${meanAttribution.outputIndex}`);\u00a0 \u00a0 \u00a0 \u00a0 console.log(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `\\t\\t\\tOutput display name : \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ${meanAttribution.outputDisplayName}`\u00a0 \u00a0 \u00a0 \u00a0 );\u00a0 \u00a0 \u00a0 \u00a0 console.log(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `\\t\\t\\tApproximation error : \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ${meanAttribution.approximationError}`\u00a0 \u00a0 \u00a0 \u00a0 );\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}getModelEvaluationTextSentimentAnalysis();\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/snippets/model_service/get_model_evaluation_text_sentiment_analysis_sample.py) \n```\nfrom google.cloud import aiplatformdef get_model_evaluation_text_sentiment_analysis_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 model_id: str,\u00a0 \u00a0 evaluation_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",):\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 To obtain evaluation_id run the following commands where LOCATION\u00a0 \u00a0 is the region where the model is stored, PROJECT is the project ID,\u00a0 \u00a0 and MODEL_ID is the ID of your model.\u00a0 \u00a0 model_client = aiplatform.gapic.ModelServiceClient(\u00a0 \u00a0 \u00a0 \u00a0 client_options={\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'api_endpoint':'LOCATION-aiplatform.googleapis.com'\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 evaluations = model_client.list_model_evaluations(parent='projects/PROJECT/locations/LOCATION/models/MODEL_ID')\u00a0 \u00a0 print(\"evaluations:\", evaluations)\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 # The AI Platform services require regional API endpoints.\u00a0 \u00a0 client_options = {\"api_endpoint\": api_endpoint}\u00a0 \u00a0 # Initialize client that will be used to create and send requests.\u00a0 \u00a0 # This client only needs to be created once, and can be reused for multiple requests.\u00a0 \u00a0 client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\u00a0 \u00a0 name = client.model_evaluation_path(\u00a0 \u00a0 \u00a0 \u00a0 project=project, location=location, model=model_id, evaluation=evaluation_id\u00a0 \u00a0 )\u00a0 \u00a0 response = client.get_model_evaluation(name=name)\u00a0 \u00a0 print(\"response:\", response)\n```\nThe [projects.locations.models.evaluations.slices.list](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations.slices/list) method lists all evaluation slices for your model. You must have the model's evaluation ID, which you can get when you [view the aggregated evaluationmetrics](#aggregate) .\nYou can use model evaluation slices to determine how the model performed on a specific label. The `value` field tells you which label the metrics are for.Before using any of the request data, make the following replacements:- : Region where Model is located. For example,`us-central1`.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : The ID of your model.\n- : ID of the model evaluation that contains the  evaluation slices to list.\nHTTP method and URL:\n```\nGET https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations/EVALUATION_ID/slices\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nExecute the following command:\n```\ncurl -X GET \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations/EVALUATION_ID/slices\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nExecute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method GET ` -Headers $headers ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations/EVALUATION_ID/slices\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:Before trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/ListModelEvaluationSliceSample.java) \n```\nimport com.google.cloud.aiplatform.v1.ModelEvaluationName;import com.google.cloud.aiplatform.v1.ModelEvaluationSlice;import com.google.cloud.aiplatform.v1.ModelEvaluationSlice.Slice;import com.google.cloud.aiplatform.v1.ModelServiceClient;import com.google.cloud.aiplatform.v1.ModelServiceSettings;import java.io.IOException;public class ListModelEvaluationSliceSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 // To obtain evaluationId run the code block below after setting modelServiceSettings.\u00a0 \u00a0 //\u00a0 \u00a0 // try (ModelServiceClient modelServiceClient = ModelServiceClient.create(modelServiceSettings))\u00a0 \u00a0 // {\u00a0 \u00a0 // \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // \u00a0 ModelName modelFullId = ModelName.of(project, location, modelId);\u00a0 \u00a0 // \u00a0 ListModelEvaluationsRequest modelEvaluationsrequest =\u00a0 \u00a0 // \u00a0 ListModelEvaluationsRequest.newBuilder().setParent(modelFullId.toString()).build();\u00a0 \u00a0 // \u00a0 for (ModelEvaluation modelEvaluation :\u00a0 \u00a0 // \u00a0 \u00a0 modelServiceClient.listModelEvaluations(modelEvaluationsrequest).iterateAll()) {\u00a0 \u00a0 // \u00a0 \u00a0 \u00a0 System.out.format(\"Model Evaluation Name: %s%n\", modelEvaluation.getName());\u00a0 \u00a0 // \u00a0 }\u00a0 \u00a0 // }\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String modelId = \"YOUR_MODEL_ID\";\u00a0 \u00a0 String evaluationId = \"YOUR_EVALUATION_ID\";\u00a0 \u00a0 listModelEvaluationSliceSample(project, modelId, evaluationId);\u00a0 }\u00a0 static void listModelEvaluationSliceSample(String project, String modelId, String evaluationId)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 ModelServiceSettings modelServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 ModelServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (ModelServiceClient modelServiceClient = ModelServiceClient.create(modelServiceSettings)) {\u00a0 \u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 \u00a0 ModelEvaluationName modelEvaluationName =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ModelEvaluationName.of(project, location, modelId, evaluationId);\u00a0 \u00a0 \u00a0 for (ModelEvaluationSlice modelEvaluationSlice :\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 modelServiceClient.listModelEvaluationSlices(modelEvaluationName).iterateAll()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Model Evaluation Slice Name: %s\\n\", modelEvaluationSlice.getName());\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Metrics Schema Uri: %s\\n\", modelEvaluationSlice.getMetricsSchemaUri());\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Metrics: %s\\n\", modelEvaluationSlice.getMetrics());\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Create Time: %s\\n\", modelEvaluationSlice.getCreateTime());\u00a0 \u00a0 \u00a0 \u00a0 Slice slice = modelEvaluationSlice.getSlice();\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Slice Dimensions: %s\\n\", slice.getDimension());\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"Slice Value: %s\\n\\n\", slice.getValue());\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/list-model-evaluation-slices.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample\u00a0* (not necessary if passing values as arguments). To obtain evaluationId,\u00a0* instantiate the client and run the following the commands.\u00a0*/// const parentName = `projects/${project}/locations/${location}/models/${modelId}`;// const evalRequest = {// \u00a0 parent: parentName// };// const [evalResponse] = await modelServiceClient.listModelEvaluations(evalRequest);// console.log(evalResponse);// const modelId = 'YOUR_MODEL_ID';// const evaluationId = 'YOUR_EVALUATION_ID';// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';// Imports the Google Cloud Model Service Client libraryconst {ModelServiceClient} = require('@google-cloud/aiplatform');// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};// Instantiates a clientconst modelServiceClient = new ModelServiceClient(clientOptions);async function listModelEvaluationSlices() {\u00a0 // Configure the parent resources\u00a0 const parent = `projects/${project}/locations/${location}/models/${modelId}/evaluations/${evaluationId}`;\u00a0 const request = {\u00a0 \u00a0 parent,\u00a0 };\u00a0 // Get and print out a list of all the evaluation slices for this resource\u00a0 const [response] =\u00a0 \u00a0 await modelServiceClient.listModelEvaluationSlices(request);\u00a0 console.log('List model evaluation response', response);\u00a0 console.log(response);}listModelEvaluationSlices();\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/snippets/model_service/list_model_evaluation_slices_sample.py) \n```\nfrom google.cloud import aiplatformdef list_model_evaluation_slices_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 model_id: str,\u00a0 \u00a0 evaluation_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",):\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 To obtain evaluation_id run the following commands where LOCATION\u00a0 \u00a0 is the region where the model is stored, PROJECT is the project ID,\u00a0 \u00a0 and MODEL_ID is the ID of your model.\u00a0 \u00a0 model_client = aiplatform.gapic.ModelServiceClient(\u00a0 \u00a0 \u00a0 \u00a0 client_options={\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'api_endpoint':'LOCATION-aiplatform.googleapis.com'\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 evaluations = model_client.list_model_evaluations(parent='projects/PROJECT/locations/LOCATION/models/MODEL_ID')\u00a0 \u00a0 print(\"evaluations:\", evaluations)\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 # The AI Platform services require regional API endpoints.\u00a0 \u00a0 client_options = {\"api_endpoint\": api_endpoint}\u00a0 \u00a0 # Initialize client that will be used to create and send requests.\u00a0 \u00a0 # This client only needs to be created once, and can be reused for multiple requests.\u00a0 \u00a0 client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\u00a0 \u00a0 parent = client.model_evaluation_path(\u00a0 \u00a0 \u00a0 \u00a0 project=project, location=location, model=model_id, evaluation=evaluation_id\u00a0 \u00a0 )\u00a0 \u00a0 response = client.list_model_evaluation_slices(parent=parent)\u00a0 \u00a0 for model_evaluation_slice in response:\u00a0 \u00a0 \u00a0 \u00a0 print(\"model_evaluation_slice:\", model_evaluation_slice)\n```\nTo view evaluation metrics for a single slice, use the [projects.locations.models.evaluations.slices.get](/vertex-ai/docs/reference/rest/v1/projects.locations.models.evaluations.slices/get) method. You must have the slice ID, which is provided when you [list allslices](#list-slices) . The following sample applies to all data types and objectives.\nBefore using any of the request data, make the following replacements:- : Region where Model is located. For example,  us-central1.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : The ID of your model.\n- : ID of the model evaluation that contains the  evaluation slice to retrieve.\n- : ID of an evaluation slice to get.\n- : Your project's automatically generated [project number](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : The name of a schema file  that defines the evaluation metrics to return such as`classification_metrics_1.0.0`.\nHTTP method and URL:\n```\nGET https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations/EVALUATION_ID/slices/SLICE_ID\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nExecute the following command:\n```\ncurl -X GET \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations/EVALUATION_ID/slices/SLICE_ID\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nExecute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method GET ` -Headers $headers ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/models/MODEL_ID/evaluations/EVALUATION_ID/slices/SLICE_ID\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\nBefore trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/GetModelEvaluationSliceSample.java) \n```\nimport com.google.cloud.aiplatform.v1.ModelEvaluationSlice;import com.google.cloud.aiplatform.v1.ModelEvaluationSlice.Slice;import com.google.cloud.aiplatform.v1.ModelEvaluationSliceName;import com.google.cloud.aiplatform.v1.ModelServiceClient;import com.google.cloud.aiplatform.v1.ModelServiceSettings;import java.io.IOException;public class GetModelEvaluationSliceSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 // To obtain evaluationId run the code block below after setting modelServiceSettings.\u00a0 \u00a0 //\u00a0 \u00a0 // try (ModelServiceClient modelServiceClient = ModelServiceClient.create(modelServiceSettings))\u00a0 \u00a0 // {\u00a0 \u00a0 // \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // \u00a0 ModelName modelFullId = ModelName.of(project, location, modelId);\u00a0 \u00a0 // \u00a0 ListModelEvaluationsRequest modelEvaluationsrequest =\u00a0 \u00a0 // \u00a0 ListModelEvaluationsRequest.newBuilder().setParent(modelFullId.toString()).build();\u00a0 \u00a0 // \u00a0 for (ModelEvaluation modelEvaluation :\u00a0 \u00a0 // \u00a0 \u00a0 modelServiceClient.listModelEvaluations(modelEvaluationsrequest).iterateAll()) {\u00a0 \u00a0 // \u00a0 \u00a0 \u00a0 System.out.format(\"Model Evaluation Name: %s%n\", modelEvaluation.getName());\u00a0 \u00a0 // \u00a0 }\u00a0 \u00a0 // }\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String modelId = \"YOUR_MODEL_ID\";\u00a0 \u00a0 String evaluationId = \"YOUR_EVALUATION_ID\";\u00a0 \u00a0 String sliceId = \"YOUR_SLICE_ID\";\u00a0 \u00a0 getModelEvaluationSliceSample(project, modelId, evaluationId, sliceId);\u00a0 }\u00a0 static void getModelEvaluationSliceSample(\u00a0 \u00a0 \u00a0 String project, String modelId, String evaluationId, String sliceId) throws IOException {\u00a0 \u00a0 ModelServiceSettings modelServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 ModelServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (ModelServiceClient modelServiceClient = ModelServiceClient.create(modelServiceSettings)) {\u00a0 \u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 \u00a0 ModelEvaluationSliceName modelEvaluationSliceName =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ModelEvaluationSliceName.of(project, location, modelId, evaluationId, sliceId);\u00a0 \u00a0 \u00a0 ModelEvaluationSlice modelEvaluationSlice =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 modelServiceClient.getModelEvaluationSlice(modelEvaluationSliceName);\u00a0 \u00a0 \u00a0 System.out.println(\"Get Model Evaluation Slice Response\");\u00a0 \u00a0 \u00a0 System.out.format(\"Model Evaluation Slice Name: %s\\n\", modelEvaluationSlice.getName());\u00a0 \u00a0 \u00a0 System.out.format(\"Metrics Schema Uri: %s\\n\", modelEvaluationSlice.getMetricsSchemaUri());\u00a0 \u00a0 \u00a0 System.out.format(\"Metrics: %s\\n\", modelEvaluationSlice.getMetrics());\u00a0 \u00a0 \u00a0 System.out.format(\"Create Time: %s\\n\", modelEvaluationSlice.getCreateTime());\u00a0 \u00a0 \u00a0 Slice slice = modelEvaluationSlice.getSlice();\u00a0 \u00a0 \u00a0 System.out.format(\"Slice Dimensions: %s\\n\", slice.getDimension());\u00a0 \u00a0 \u00a0 System.out.format(\"Slice Value: %s\\n\", slice.getValue());\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/get-model-evaluation-slice.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample\u00a0* (not necessary if passing values as arguments). To obtain evaluationId,\u00a0* instantiate the client and run the following the commands.\u00a0*/// const parentName = `projects/${project}/locations/${location}/models/${modelId}`;// const evalRequest = {// \u00a0 parent: parentName// };// const [evalResponse] = await modelServiceClient.listModelEvaluations(evalRequest);// console.log(evalResponse);// const modelId = 'YOUR_MODEL_ID';// const evaluationId = 'YOUR_EVALUATION_ID';// const sliceId = 'YOUR_SLICE_ID';// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';// Imports the Google Cloud Model Service client libraryconst {ModelServiceClient} = require('@google-cloud/aiplatform');// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};// Specifies the location of the api endpointconst modelServiceClient = new ModelServiceClient(clientOptions);async function getModelEvaluationSlice() {\u00a0 // Configure the parent resource\u00a0 const name = `projects/${project}/locations/${location}/models/${modelId}/evaluations/${evaluationId}/slices/${sliceId}`;\u00a0 const request = {\u00a0 \u00a0 name,\u00a0 };\u00a0 // Get and print out a list of all the endpoints for this resource\u00a0 const [response] =\u00a0 \u00a0 await modelServiceClient.getModelEvaluationSlice(request);\u00a0 console.log('Get model evaluation slice');\u00a0 console.log(`\\tName : ${response.name}`);\u00a0 console.log(`\\tMetrics_Schema_Uri : ${response.metricsSchemaUri}`);\u00a0 console.log(`\\tMetrics : ${JSON.stringify(response.metrics)}`);\u00a0 console.log(`\\tCreate time : ${JSON.stringify(response.createTime)}`);\u00a0 console.log('Slice');\u00a0 const slice = response.slice;\u00a0 console.log(`\\tDimension :${slice.dimension}`);\u00a0 console.log(`\\tValue :${slice.value}`);}getModelEvaluationSlice();\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/snippets/model_service/get_model_evaluation_slice_sample.py) \n```\nfrom google.cloud import aiplatformdef get_model_evaluation_slice_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 model_id: str,\u00a0 \u00a0 evaluation_id: str,\u00a0 \u00a0 slice_id: str,\u00a0 \u00a0 location: str = \"us-central1\",\u00a0 \u00a0 api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",):\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 To obtain evaluation_id run the following commands where LOCATION\u00a0 \u00a0 is the region where the model is stored, PROJECT is the project ID,\u00a0 \u00a0 and MODEL_ID is the ID of your model.\u00a0 \u00a0 model_client = aiplatform.gapic.ModelServiceClient(\u00a0 \u00a0 \u00a0 \u00a0 client_options={\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'api_endpoint':'LOCATION-aiplatform.googleapis.com'\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 evaluations = model_client.list_model_evaluations(parent='projects/PROJECT/locations/LOCATION/models/MODEL_ID')\u00a0 \u00a0 print(\"evaluations:\", evaluations)\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 # The AI Platform services require regional API endpoints.\u00a0 \u00a0 client_options = {\"api_endpoint\": api_endpoint}\u00a0 \u00a0 # Initialize client that will be used to create and send requests.\u00a0 \u00a0 # This client only needs to be created once, and can be reused for multiple requests.\u00a0 \u00a0 client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\u00a0 \u00a0 name = client.model_evaluation_slice_path(\u00a0 \u00a0 \u00a0 \u00a0 project=project,\u00a0 \u00a0 \u00a0 \u00a0 location=location,\u00a0 \u00a0 \u00a0 \u00a0 model=model_id,\u00a0 \u00a0 \u00a0 \u00a0 evaluation=evaluation_id,\u00a0 \u00a0 \u00a0 \u00a0 slice=slice_id,\u00a0 \u00a0 )\u00a0 \u00a0 response = client.get_model_evaluation_slice(name=name)\u00a0 \u00a0 print(\"response:\", response)\n```\n## Iterate on your model\nModel evaluation metrics provide a starting point for debugging your model when the model isn't meeting your expectations. For example, low precision and recall scores can indicate that your model needs additional training data or has inconsistent labels. Perfect precision and recall can indicate that the test data is too easy to predict and might not generalize well.\nYou can iterate on your training data and create a new model. After you create a new model, you can compare the evaluation metrics between the existing model and the new model.\nThe following suggestions can help you improve models that label items, such as classification or detection models:\n- Consider adding more examples or a wider range of examples in your training data. For example, for an image classification model, you might include wider angle images, higher or lower resolution images, or different points of view. For more guidance, see [Preparingdata](/vertex-ai/docs/training-overview) for your particular data type and objective.\n- Consider removing classes or labels that don't have a lot of examples. Insufficient examples prevent the model from consistently and confidently making predictions about those classes or labels.\n- Machines can't interpret the name of your classes or labels and don't understand the nuances between them, such as \"door\" and \"door_with_knob.\" You must provide data to help machines recognize such nuances.\n- Augment your data with more examples of true positives and true negatives, especially examples that are close to a decision boundary to mitigate model confusion.\n- Specify your own data split (training, validation, and test). Vertex AI randomly assigns items to each set. Therefore, near-duplicates can be allocated in the training and validation sets, which could lead to overfitting and then poor performance on the test set. For more information about setting your own data split, see [About data splits for AutoMLmodels](/vertex-ai/docs/general/ml-use) .\n- If your model's evaluation metrics include a confusion matrix, you can see if the model is confusing two labels, where the model is predicting a particular label significantly more than the true label. Review your data and make sure the examples are correctly labeled.\n- If you had a short training time (low maximum number of node hours), you might get a higher-quality model by allowing it to train for a longer period of time (higher maximum number of node hours).", "guide": "Vertex AI"}