{"title": "Vertex AI - Create a custom container image for training", "url": "https://cloud.google.com/vertex-ai/docs/training/create-custom-container", "abstract": "# Vertex AI - Create a custom container image for training\nUsing a custom container image provides the most flexibility for training on Vertex AI. To learn how using a custom container image differs from [using a Python training application with a prebuiltcontainer](/vertex-ai/docs/training/create-python-pre-built-container) , read [Trainingcode requirements](/vertex-ai/docs/training/code-requirements) .\nThe guide walks through the following steps:\n- Creating a custom container:- Writing a Dockerfile that sets up your container to work with Vertex AI and includes dependencies needed for your training application.\n- Building and running your Docker container locally.\n- Pushing the container image to Artifact Registry.\n**Note:** Vertex AI supports custom training with container images on Artifact Registry or Docker Hub. This guide focuses on using Artifact Registry with Vertex AI.\n", "content": "## Before you begin\nTo configure an Artifact Registry API repository and set up Docker in your development environment, follow [Artifact Registry's Quickstart forDocker](/artifact-registry/docs/docker/quickstart#before-you-begin) . Specifically, make sure to complete the following steps of the quickstart:\n- Before you begin\n- Choose a shell\n- Create a Docker repository\n- Configure authentication## Create a custom container image\nWe recommend two possible workflows for creating a custom container image:\n- Write your training code. Then, [use thegcloud CLI's local-run command to build and test a customcontainer image](/vertex-ai/docs/training/containerize-run-code-local) based on your training code without writing a Dockerfile yourself.This workflow can be more straightforward if you are not familiar with Docker. If you follow this workflow, you can skip the rest of this section.\n- Write your training code. Then, write a Dockerfile and build a container image based on it. Finally, test the container locally.This workflow offers more flexibility, because you can customize your container image as much as you want.\nThe rest of this section walks through an example of the latter workflow.\n### Training code\nYou can write training code using any dependencies in any programming language. Make sure your code meets the [training coderequirements](/vertex-ai/docs/training/code-requirements) . If you plan to use hyperparameter tuning, GPUs, or distributed training, make sure to read the corresponding sections of that document; these sections describe specific considerations for using the features with custom containers.\n### Create a Dockerfile\nCreate a [Dockerfile](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) to specify all the instructions needed to build your container image.\nThis section walks through creating a generic example of a Dockerfile to use for custom training. To learn more about creating a container image, read the [Docker documentation's quickstart](https://docs.docker.com/get-started/) .\nFor use with Vertex AI, your Dockerfile needs to include commands that cover the following tasks:\n- Choose a base image\n- Install additional dependencies\n- Copy your training code to the image\n- Configure the entrypoint for Vertex AI to invoke your training code\nYour Dockerfile can include additional logic, depending on your needs. For more information about each specific instruction, see the [Dockerfile reference](https://docs.docker.com/engine/reference/builder/) .\n| Dockerfile command    | Description                                                                                        | Example(s)                                |\n|:-------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------|\n| FROM image:tag     | Specifies a basic image and its tag.                                                                                  | Example base images with tags: pytorch/pytorch:latest tensorflow/tensorflow:nightly python:2.7.15-jessie nvidia/cuda:9.0-cudnn7-runtime |\n| WORKDIR /path/to/directory  | Specifies the directory on the image where subsequent instructions are run.                                                                        | /root                                 |\n| RUN pip install pkg1 pkg2 pkg3 | Installs additional packages using pip. Note: if your base image does not have pip, you must include a command to install it before you install other packages.                                                   | Example packages: google-cloud-storage cloudml-hypertune pandas                   |\n| COPY src/foo.py dest/foo.py | Copies the code for your training application into the image. Depending on how your training application is structured, this likely includes multiple files.                                                   | Example names of files in your training application: model.py task.py data_utils.py              |\n| ENTRYPOINT [\"exec\", \"file\"] | Sets up the entry point to invoke your training code to run. When you start custom training, you can override this entrypoint by specifying the command field in your ContainerSpec. You can also specify the args field in the ContainerSpec to provide additional arguments to the entrypoint (and override the container image's CMD instruction if it has one). | [\"python\", \"task.py\"]                             |\nThe logic in your Dockerfile may vary according to your needs, but in general it resembles this:\n```\n# Specifies base image and tagFROM image:tagWORKDIR /root# Installs additional packagesRUN pip install pkg1 pkg2 pkg3# Downloads training dataRUN curl https://example-url/path-to-data/data-filename --output /root/data-filename# Copies the trainer code to the docker image.COPY your-path-to/model.py /root/model.pyCOPY your-path-to/task.py /root/task.py# Sets up the entry point to invoke the trainer.ENTRYPOINT [\"python\", \"task.py\"]\n```\nIf you want to train on Vertex AI using a TPU VM, then you must adjust your Dockerfile to install specially built versions of the `tensorflow` and `libtpu` libraries. Learn more about [adjusting your container for use witha TPU VM](/vertex-ai/docs/training/configure-compute#tpu-requirements) .\n### Build the container image\nCreate the correct image URI by using environment variables, and then build the Docker image:\n```\nexport PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")export REPO_NAME=REPOSITORY_NAMEexport IMAGE_NAME=IMAGE_NAMEexport IMAGE_TAG=IMAGE_TAGexport IMAGE_URI=us-central1-docker.pkg.dev/${PROJECT_ID}/${REPO_NAME}/${IMAGE_NAME}:${IMAGE_TAG}docker build -f Dockerfile -t ${IMAGE_URI} ./\n```\nIn these commands replace the following:\n- : the name of the Artifact Registry repository that you created in the [Before you begin](#before-you-begin) section.\n- : a name of your choice for your container image.\n- : a tag of your choice for this version of your container image.\nLearn more about [Artifact Registry's requirements for naming your containerimage](/artifact-registry/docs/docker/pushing-and-pulling#tag) .\n### Run the container locally (optional)\nVerify the container image by running it as a container locally. You likely want to run your training code on a smaller dataset or for a shorter number of iterations than you plan to run on Vertex AI. For example, if the entrypoint script in your container image accepts an `--epochs` flag to control how many [epochs](https://developers.google.com/machine-learning/glossary#epoch) it runs for, you might run the following command:\n```\ndocker run ${IMAGE_URI} --epochs 1\n```\n## Push the container to Artifact Registry\nIf the local run works, you can push the container to Artifact Registry.\nFirst, run [gcloud auth configure-docker us-central1-docker.pkg.dev](/sdk/gcloud/reference/auth/configure-docker) if you have not already done so in your development environment. Then run the following command:\n```\ndocker push ${IMAGE_URI}\n```\n### Artifact Registry permissions\nIf you are using an Artifact Registry image from the same Google Cloud project where you're using Vertex AI, then there is no further need to configure permissions. You can immediately [create acustom training job](/vertex-ai/docs/training/create-custom-job) that uses your container image.\nHowever, if you have pushed your container image to Artifact Registry in a different Google Cloud project from the project where you plan to use Vertex AI, then you must grant the Vertex AI Service Agent for your Vertex AI project permission to pull the image from the other project. [Learn more about the Vertex AI Service Agent and how togrant it permissions.](/vertex-ai/docs/general/access-control#service-agents) .\nTo learn how to grant your Vertex AI Service Agent access to your Artifact Registry repository, read the Artifact Registry documentation about [grantingrepository-specificpermissions](/artifact-registry/docs/access-control#grant-repo) .\n## What's next\n- Learn more about [the concepts involved in usingcontainers](/vertex-ai/docs/training/containers-overview) .\n- Learn about additional [training coderequirements](/vertex-ai/docs/training/code-requirements) for custom training.\n- Learn how to [create a custom trainingjob](/vertex-ai/docs/training/create-custom-job) or a [trainingpipeline](/vertex-ai/docs/training/create-training-pipeline) that uses your custom container.", "guide": "Vertex AI"}