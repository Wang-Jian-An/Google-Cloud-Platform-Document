{"title": "Vertex AI - Use managed datasets", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Use managed datasets\nThis page shows you how to use Vertex AI managed datasets to train your custom models. Managed datasets offer the following benefits:\n- Manage your datasets in a central location.\n- Easily create labels and multiple annotation sets.\n- Create tasks for human labeling using integrated data labeling.\n- Track lineage to models for governance and iterative development.\n- Compare model performance by training AutoML and custom models using the same datasets.\n- Generate data statistics and visualizations.\n- Automatically split data into training, test, and validation sets.", "content": "## Before you begin\nBefore you can use a managed dataset in your training application, you must [create your dataset](/vertex-ai/docs/datasets/overview) . You must create the dataset and the training pipeline that you use for training in the same region. You must use a [regionwhere Dataset resources areavailable](/vertex-ai/docs/general/locations#feature-availability) .\n## Access a dataset from your training application\nTo see an example of using environment variables to access datasets as part of a more comprehensive workflow,  run the \"Vertex AI: Track parameters and metrics for custom training jobs\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ml_metadata/sdk-metric-parameter-tracking-for-custom-jobs.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fml_metadata%2Fsdk-metric-parameter-tracking-for-custom-jobs.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/ml_metadata/sdk-metric-parameter-tracking-for-custom-jobs.ipynb)\nWhen you [create a custom training pipeline](/vertex-ai/docs/training/create-training-pipeline) , you can specify that your training application uses a Vertex AI dataset.\nAt runtime, Vertex AI passes metadata about your dataset to your training application by setting the following environment variables in your training container.\n- `AIP_DATA_FORMAT`: The format that your dataset is exported in. Possible values include:`jsonl`,`csv`, or`bigquery`.\n- `AIP_TRAINING_DATA_URI`: The BigQuery URI of your training data or the Cloud Storage URI of your training data file.\n- `AIP_VALIDATION_DATA_URI`: The BigQuery URI for your validation data or the Cloud Storage URI of your validation data file.\n- `AIP_TEST_DATA_URI`: The BigQuery URI for your test data or the Cloud Storage URI of your test data file.\nIf the `AIP_DATA_FORMAT` of your dataset is `jsonl` or `csv` , the data URI values refer to Cloud Storage URIs, like `gs://` `` `/` `` `/training-*` . To keep the size of each data file relatively small, Vertex AI splits your dataset into multiple files. Because your training, validation, or test data may be split into multiple files, the URIs are provided in wildcard format.\n[Learn more about downloading objects using the Cloud Storage codesamples](/storage/docs/downloading-objects#code-samples) .\nIf your `AIP_DATA_FORMAT` is `bigquery` , the data URI values refer to BigQuery URIs, like `bq://` `` `.` `` `.` `` .\n[Learn more about paging through BigQuery data](/bigquery/docs/paging-results) .\n## Dataset format\nUse the following sections to learn more about how Vertex AI formats your data when passing a dataset to your training application.\n### Image datasets\nImage datasets are passed to your training application in [JSON Lines](https://jsonlines.org/) format. Select the tab for your dataset's objective, to learn more about how Vertex AI formats your dataset.\nVertex AI uses the following publicly accessible schema when exporting a single-label image classification dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/image_classification_single_label_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/image_classification_single_label_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"imageGcsUri\": \"gs://bucket/filename.ext\",\n \"classificationAnnotation\": {\n \"displayName\": \"LABEL\",\n \"annotationResourceLabels\": {\n  \"aiplatform.googleapis.com/annotation_set_name\": \"displayName\",\n  \"env\": \"prod\"\n  }\n },\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training/test/validation\"\n }\n}\n```\n **Field notes** :- `imageGcsUri`: The Cloud Storage URI of this  image.\n- `annotationResourceLabels`: Contains any number of  key-value string pairs. Vertex AI uses this field to  specify the annotation set.\n- `dataItemResourceLabels`- Contains any number of  key-value string pairs. Specifies the machine learning use of the  data item, such as training, test, or validation.\n```\n{\"imageGcsUri\": \"gs://bucket/filename1.jpeg\", \"classificationAnnotation\": {\"displayName\": \"daisy\"}, \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"test\"}}\n{\"imageGcsUri\": \"gs://bucket/filename2.gif\", \"classificationAnnotation\": {\"displayName\": \"dandelion\"}, \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename3.png\", \"classificationAnnotation\": {\"displayName\": \"roses\"}, \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename4.bmp\", \"classificationAnnotation\": {\"displayName\": \"sunflowers\"}, \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename5.tiff\", \"classificationAnnotation\": {\"displayName\": \"tulips\"}, \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"validation\"}}\n...\n```Vertex AI uses the following publicly accessible schema when exporting a multi-label image classification dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/image_classification_multi_label_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/image_classification_multi_label_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"imageGcsUri\": \"gs://bucket/filename.ext\",\n \"classificationAnnotations\": [ {\n  \"displayName\": \"LABEL1\",\n  \"annotationResourceLabels\": {\n  \"aiplatform.googleapis.com/annotation_set_name\":\"displayName\",\n  \"label_type\": \"flower_type\"\n  }\n },\n {\n  \"displayName\": \"LABEL2\",\n  \"annotationResourceLabels\": {\n  \"aiplatform.googleapis.com/annotation_set_name\":\"displayName\",\n  \"label_type\": \"image_shot_type\"\n  }\n }\n ],\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training/test/validation\"\n }\n}\n```\n **Field notes** :- `imageGcsUri`: The Cloud Storage URI of this  image.\n- `annotationResourceLabels`: Contains any number of  key-value string pairs. Vertex AI uses this field to  specify the annotation set.\n- `dataItemResourceLabels`- Contains any number of  key-value string pairs. Specifies the machine learning use of the  data item, such as training, test, or validation.\n```\n{\"imageGcsUri\": \"gs://bucket/filename1.jpeg\", \"classificationAnnotations\": [{\"displayName\": \"daisy\"}, {\"displayName\": \"full_shot\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"test\"}}\n{\"imageGcsUri\": \"gs://bucket/filename2.gif\", \"classificationAnnotations\": [{\"displayName\": \"dandelion\"}, {\"displayName\": \"medium_shot\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename3.png\", \"classificationAnnotations\": [{\"displayName\": \"roses\"}, {\"displayName\": \"extreme_closeup\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename4.bmp\", \"classificationAnnotations\": [{\"displayName\": \"sunflowers\"}, {\"displayName\": \"closeup\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename5.tiff\", \"classificationAnnotations\": [{\"displayName\": \"tulips\"}, {\"displayName\": \"extreme_closeup\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"validation\"}}\n...\n```Vertex AI uses the following publicly accessible schema when exporting an object detection dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/image_bounding_box_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/image_bounding_box_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"imageGcsUri\": \"gs://bucket/filename.ext\",\n \"boundingBoxAnnotations\": [ {\n  \"displayName\": \"OBJECT1_LABEL\",\n  \"xMin\": \"X_MIN\",\n  \"yMin\": \"Y_MIN\",\n  \"xMax\": \"X_MAX\",\n  \"yMax\": \"Y_MAX\",\n  \"annotationResourceLabels\": {\n  \"aiplatform.googleapis.com/annotation_set_name\": \"displayName\",\n  \"env\": \"prod\"\n  }\n },\n {\n  \"displayName\": \"OBJECT2_LABEL\",\n  \"xMin\": \"X_MIN\",\n  \"yMin\": \"Y_MIN\",\n  \"xMax\": \"X_MAX\",\n  \"yMax\": \"Y_MAX\"\n }\n ],\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"test/train/validation\"\n }\n}\n```\n **Field notes** :- `imageGcsUri`: The Cloud Storage URI of this  image.\n- `annotationResourceLabels`: Contains any number of  key-value string pairs. Vertex AI uses this field to  specify the annotation set.\n- `dataItemResourceLabels`- Contains any number of  key-value string pairs. Specifies the machine learning use of the  data item, such as training, test, or validation.\n```\n{\"imageGcsUri\": \"gs://bucket/filename1.jpeg\", \"boundingBoxAnnotations\": [{\"displayName\": \"Tomato\", \"xMin\": \"0.3\", \"yMin\": \"0.3\", \"xMax\": \"0.7\", \"yMax\": \"0.6\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"test\"}}\n{\"imageGcsUri\": \"gs://bucket/filename2.gif\", \"boundingBoxAnnotations\": [{\"displayName\": \"Tomato\", \"xMin\": \"0.8\", \"yMin\": \"0.2\", \"xMax\": \"1.0\", \"yMax\": \"0.4\"},{\"displayName\": \"Salad\", \"xMin\": \"0.0\", \"yMin\": \"0.0\", \"xMax\": \"1.0\", \"yMax\": \"1.0\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename3.png\", \"boundingBoxAnnotations\": [{\"displayName\": \"Baked goods\", \"xMin\": \"0.5\", \"yMin\": \"0.7\", \"xMax\": \"0.8\", \"yMax\": \"0.8\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"imageGcsUri\": \"gs://bucket/filename4.tiff\", \"boundingBoxAnnotations\": [{\"displayName\": \"Salad\", \"xMin\": \"0.1\", \"yMin\": \"0.2\", \"xMax\": \"0.8\", \"yMax\": \"0.9\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"validation\"}}\n...\n```\n### Tabular datasets\nVertex AI passes tabular data to your training application in CSV format or as a URI to a BigQuery table or view. For more information about the data source format and requirements, see [Preparing your import source](/vertex-ai/docs/datasets/overview#tabular_data) . Refer to the dataset in Google Cloud console for more information about the dataset schema.\n### Text datasets\nText datasets are passed to your training application in JSON Lines format. Select the tab for your dataset's objective, to learn more about how Vertex AI formats your dataset.\nVertex AI uses the following publicly accessible schema when exporting a single-label text classification dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/text_classification_single_label_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/text_classification_single_label_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"classificationAnnotation\": {\n \"displayName\": \"label\"\n },\n \"textContent\": \"inline_text\",\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n{\n \"classificationAnnotation\": {\n \"displayName\": \"label2\"\n },\n \"textGcsUri\": \"gcs_uri_to_file\",\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n```Vertex AI uses the following publicly accessible schema when exporting a multi-label text classification dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/text_classification_multi_label_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/text_classification_multi_label_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"classificationAnnotations\": [{\n \"displayName\": \"label1\"\n },{\n \"displayName\": \"label2\"\n }],\n \"textGcsUri\": \"gcs_uri_to_file\",\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n{\n \"classificationAnnotations\": [{\n \"displayName\": \"label2\"\n },{\n \"displayName\": \"label3\"\n }],\n \"textContent\": \"inline_text\",\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n```Vertex AI uses the following publicly accessible schema when exporting an entity extraction dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/text_extraction_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/text_extraction_io_format_1.0.0.yaml) .\nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"textSegmentAnnotations\": [  {\n  \"startOffset\":number,\n  \"endOffset\":number,\n  \"displayName\": \"label\"\n  },\n  ...\n ],\n \"textContent\": \"inline_text\",\n \"dataItemResourceLabels\": {\n  \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n{\n \"textSegmentAnnotations\": [  {\n  \"startOffset\":number,\n  \"endOffset\":number,\n  \"displayName\": \"label\"\n  },\n  ...\n ],\n \"textGcsUri\": \"gcs_uri_to_file\",\n \"dataItemResourceLabels\": {\n  \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n```Vertex AI uses the following publicly accessible schema when exporting a sentiment analysis dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/trainingjob/definition/automl_text_sentiment_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/automl_text_sentiment_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"sentimentAnnotation\": {\n \"sentiment\": number,\n \"sentimentMax\": number\n },\n \"textContent\": \"inline_text\",\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n{\n \"sentimentAnnotation\": {\n \"sentiment\": number,\n \"sentimentMax\": number\n },\n \"textGcsUri\": \"gcs_uri_to_file\",\n \"dataItemResourceLabels\": {\n \"aiplatform.googleapis.com/ml_use\": \"training|test|validation\"\n }\n}\n```\n### Video datasets\nVideo datasets are passed to your training application in JSON Lines format. Select the tab for your dataset's objective, to learn more about how Vertex AI formats your dataset.\nVertex AI uses the following publicly accessible schema when exporting an action recognition dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/video_action_recognition_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/video_action_recognition_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n \"videoGcsUri': \"gs://bucket/filename.ext\",\n \"timeSegments\": [{\n \"startTime\": \"start_time_of_fully_annotated_segment\",\n \"endTime\": \"end_time_of_segment\"}],\n \"timeSegmentAnnotations\": [{\n \"displayName\": \"LABEL\",\n \"startTime\": \"start_time_of_segment\",\n \"endTime\": \"end_time_of_segment\"\n }],\n \"dataItemResourceLabels\": {\n \"ml_use\": \"train|test\"\n }\n}\n```\nNote: The time segments here are used to calculate the timestamps of the actions. `startTime` and `endTime` of `timeSegmentAnnotations` can be equal, and corresponds to the key frame of the action.```\n{\"videoGcsUri\": \"gs://demo/video1.mp4\", \"timeSegmentAnnotations\": [{\"displayName\": \"cartwheel\", \"startTime\": \"1.0s\", \"endTime\": \"12.0s\"}], \"dataItemResourceLabels\": {\"ml_use\": \"training\"}}\n{\"videoGcsUri\": \"gs://demo/video2.mp4\", \"timeSegmentAnnotations\": [{\"displayName\": \"swing\", \"startTime\": \"4.0s\", \"endTime\": \"9.0s\"}], \"dataItemResourceLabels\": {\"ml_use\": \"test\"}}\n...\n```Vertex AI uses the following publicly accessible schema when exporting a classification dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/video_classification_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/video_classification_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n\t\"videoGcsUri\": \"gs://bucket/filename.ext\",\n\t\"timeSegmentAnnotations\": [{\n\t\t\"displayName\": \"LABEL\",\n\t\t\"startTime\": \"start_time_of_segment\",\n\t\t\"endTime\": \"end_time_of_segment\"\n\t}],\n\t\"dataItemResourceLabels\": {\n\t\t\"aiplatform.googleapis.com/ml_use\": \"train|test\"\n\t}\n}\n``````\n{\"videoGcsUri\": \"gs://demo/video1.mp4\", \"timeSegmentAnnotations\": [{\"displayName\": \"cartwheel\", \"startTime\": \"1.0s\", \"endTime\": \"12.0s\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{\"videoGcsUri\": \"gs://demo/video2.mp4\", \"timeSegmentAnnotations\": [{\"displayName\": \"swing\", \"startTime\": \"4.0s\", \"endTime\": \"9.0s\"}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"test\"}}\n...\n```Vertex AI uses the following publicly accessible schema when exporting an object tracking dataset. This schema dictates the format of the data export files. The schema's structure follows the [OpenAPI schema](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.2.md#schema) .\n [gs://google-cloud-aiplatform/schema/dataset/ioformat/object_tracking_io_format_1.0.0.yaml](https://storage.cloud.google.com/google-cloud-aiplatform/schema/dataset/ioformat/video_object_tracking_io_format_1.0.0.yaml) \nEach data item in your exported dataset uses the following format. This example includes line breaks for readability.\n```\n{\n\t\"videoGcsUri\": \"gs://bucket/filename.ext\",\n\t\"TemporalBoundingBoxAnnotations\": [{\n\t\t\"displayName\": \"LABEL\",\n\t\t\"xMin\": \"leftmost_coordinate_of_the_bounding box\",\n\t\t\"xMax\": \"rightmost_coordinate_of_the_bounding box\",\n\t\t\"yMin\": \"topmost_coordinate_of_the_bounding box\",\n\t\t\"yMax\": \"bottommost_coordinate_of_the_bounding box\",\n\t\t\"timeOffset\": \"timeframe_object-detected\"\n    \"instanceId\": \"instance_of_object\n    \"annotationResourceLabels\": \"resource_labels\"\n\t}],\n\t\"dataItemResourceLabels\": {\n\t\t\"aiplatform.googleapis.com/ml_use\": \"train|test\"\n\t}\n}\n``````\n{'videoGcsUri': 'gs://demo-data/video1.mp4', 'temporal_bounding_box_annotations': [{'displayName': 'horse', 'instance_id': '-1', 'time_offset': '4.000000s', 'xMin': '0.668912', 'yMin': '0.560642', 'xMax': '1.000000', 'yMax': '1.000000'}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"training\"}}\n{'videoGcsUri': 'gs://demo-data/video2.mp4', 'temporal_bounding_box_annotations': [{'displayName': 'horse', 'instance_id': '-1', 'time_offset': '71.000000s', 'xMin': '0.679056', 'yMin': '0.070957', 'xMax': '0.801716', 'yMax': '0.290358'}], \"dataItemResourceLabels\": {\"aiplatform.googleapis.com/ml_use\": \"test\"}}\n...\n```\n## What's next\n- Learn how to [use a managed dataset in custom training by creating atraining pipeline](/vertex-ai/docs/training/create-training-pipeline) .", "guide": "Vertex AI"}