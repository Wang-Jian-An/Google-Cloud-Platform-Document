{"title": "Vertex AI - Get predictions from a video object tracking model", "url": "https://cloud.google.com/vertex-ai/docs/video-data/object-tracking/get-predictions", "abstract": "# Vertex AI - Get predictions from a video object tracking model\nAutoML video models do not support online predictions.\n", "content": "## Get batch predictions\nTo make a batch prediction request, you specify an [input source](#input_data) and an [output format](#output_format) where Vertex AI stores predictions results.\n**Note:** To minimize processing time when you use the Google Cloud console to create batch predictions, we recommend that you select input and output locations that are in the same region as your model. If you use the API to create batch predictions, send requests to a service endpoint (such as `https://us-central1-aiplatform.googleapis.com` ) that is in the same region or geographically close to your input and output locations.\n### Input data requirements\nThe input for batch requests specifies the items to send to your model for prediction. Batch predictions for the AutoML video model type use a JSON Lines file to specify a list of videos to make predictions for, and then store the JSON Lines file in a Cloud Storage bucket. You can specify `Infinity` for the `timeSegmentEnd` field to specify the end of the video. The following sample shows a single line in an input JSON Lines file.\n```\n{'content': 'gs://sourcebucket/datasets/videos/source_video.mp4', 'mimeType': 'video/mp4', 'timeSegmentStart': '0.0s', 'timeSegmentEnd': '2.366667s'}\n```\n### Request a batch prediction\nFor batch prediction requests, you can use the Google Cloud console or the Vertex AI API. Depending on the number of input items that you've submitted, a batch prediction task can take some time to complete.\nUse the Google Cloud console to request a batch prediction.- In the Google Cloud console, in the Vertex AI section, go to the **Batch predictions** page. [Go to the Batch predictions page](https://console.cloud.google.com/vertex-ai/batch-predictions) \n- Click **Create** to open the **New batch prediction** window and complete the following steps:- Enter a name for the batch prediction.\n- For **Model name** , select the name of the model to use for this batch prediction.\n- For **Source path** , specify the Cloud Storage location where your JSON Lines input file is located.\n- For the **Destination path** , specify a Cloud Storage location where the batch prediction results are stored. The **Output** format is determined by your model's objective. AutoML models for image objectives output JSON Lines files.\nUse the Vertex AI API to send batch prediction requests.\nBefore using any of the request data, make the following replacements:- : Region where Model is stored and batch prediction job is executed. For example,`us-central1`.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : Display name for the batch job\n- : The ID for the model to use for making predictions\n- (optional): Vertex AI returns only  predictions that have confidence scores with at least this value. The  default is`0.0`.\n- : Cloud Storage URI where your input JSON Lines file is  located.\n- : Your Cloud Storage bucket\n- : Your project's automatically generated [project number](/resource-manager/docs/creating-managing-projects#identifiers) \nHTTP method and URL:\n```\nPOST https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/batchPredictionJobs\n```\nRequest JSON body:\n```\n{\n \"displayName\": \"BATCH_JOB_NAME\",\n \"model\": \"projects/PROJECT_ID/locations/LOCATION_ID/models/MODEL_ID\",\n \"modelParameters\": {\n  \"confidenceThreshold\": THRESHOLD_VALUE,\n },\n \"inputConfig\": {\n  \"instancesFormat\": \"jsonl\",\n  \"gcsSource\": {\n   \"uris\": [\"URI\"],\n  },\n },\n \"outputConfig\": {\n  \"predictionsFormat\": \"jsonl\",\n  \"gcsDestination\": {\n   \"outputUriPrefix\": \"OUTPUT_BUCKET\",\n  },\n },\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/batchPredictionJobs\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION_ID-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION_ID/batchPredictionJobs\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/us-central1/batchPredictionJobs/BATCH_JOB_ID\",\n \"displayName\": \"BATCH_JOB_NAME\",\n \"model\": \"projects/PROJECT_NUMBER/locations/us-central1/models/MODEL_ID\",\n \"inputConfig\": {\n \"instancesFormat\": \"jsonl\",\n \"gcsSource\": {\n  \"uris\": [  \"CONTENT\"\n  ]\n }\n },\n \"outputConfig\": {\n \"predictionsFormat\": \"jsonl\",\n \"gcsDestination\": {\n  \"outputUriPrefix\": \"BUCKET\"\n }\n },\n \"state\": \"JOB_STATE_PENDING\",\n \"createTime\": \"2020-05-30T02:58:44.341643Z\",\n \"updateTime\": \"2020-05-30T02:58:44.341643Z\",\n \"modelDisplayName\": \"MODEL_NAME\",\n \"modelObjective\": \"MODEL_OBJECTIVE\"\n}\n```\nYou can poll for the status of the batch job using the until the job `state` is `JOB_STATE_SUCCEEDED` .\nBefore trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/CreateBatchPredictionJobVideoObjectTrackingSample.java) \n```\nimport com.google.cloud.aiplatform.util.ValueConverter;import com.google.cloud.aiplatform.v1.BatchDedicatedResources;import com.google.cloud.aiplatform.v1.BatchPredictionJob;import com.google.cloud.aiplatform.v1.BatchPredictionJob.InputConfig;import com.google.cloud.aiplatform.v1.BatchPredictionJob.OutputConfig;import com.google.cloud.aiplatform.v1.BatchPredictionJob.OutputInfo;import com.google.cloud.aiplatform.v1.BigQueryDestination;import com.google.cloud.aiplatform.v1.BigQuerySource;import com.google.cloud.aiplatform.v1.CompletionStats;import com.google.cloud.aiplatform.v1.GcsDestination;import com.google.cloud.aiplatform.v1.GcsSource;import com.google.cloud.aiplatform.v1.JobServiceClient;import com.google.cloud.aiplatform.v1.JobServiceSettings;import com.google.cloud.aiplatform.v1.LocationName;import com.google.cloud.aiplatform.v1.MachineSpec;import com.google.cloud.aiplatform.v1.ManualBatchTuningParameters;import com.google.cloud.aiplatform.v1.ModelName;import com.google.cloud.aiplatform.v1.ResourcesConsumed;import com.google.cloud.aiplatform.v1.schema.predict.params.VideoObjectTrackingPredictionParams;import com.google.protobuf.Any;import com.google.protobuf.Value;import com.google.rpc.Status;import java.io.IOException;import java.util.List;public class CreateBatchPredictionJobVideoObjectTrackingSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String batchPredictionDisplayName = \"YOUR_VIDEO_OBJECT_TRACKING_DISPLAY_NAME\";\u00a0 \u00a0 String modelId = \"YOUR_MODEL_ID\";\u00a0 \u00a0 String gcsSourceUri =\u00a0 \u00a0 \u00a0 \u00a0 \"gs://YOUR_GCS_SOURCE_BUCKET/path_to_your_video_source/[file.csv/file.jsonl]\";\u00a0 \u00a0 String gcsDestinationOutputUriPrefix =\u00a0 \u00a0 \u00a0 \u00a0 \"gs://YOUR_GCS_SOURCE_BUCKET/destination_output_uri_prefix/\";\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 batchPredictionJobVideoObjectTracking(\u00a0 \u00a0 \u00a0 \u00a0 batchPredictionDisplayName, modelId, gcsSourceUri, gcsDestinationOutputUriPrefix, project);\u00a0 }\u00a0 static void batchPredictionJobVideoObjectTracking(\u00a0 \u00a0 \u00a0 String batchPredictionDisplayName,\u00a0 \u00a0 \u00a0 String modelId,\u00a0 \u00a0 \u00a0 String gcsSourceUri,\u00a0 \u00a0 \u00a0 String gcsDestinationOutputUriPrefix,\u00a0 \u00a0 \u00a0 String project)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 JobServiceSettings jobServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 JobServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (JobServiceClient jobServiceClient = JobServiceClient.create(jobServiceSettings)) {\u00a0 \u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 \u00a0 LocationName locationName = LocationName.of(project, location);\u00a0 \u00a0 \u00a0 ModelName modelName = ModelName.of(project, location, modelId);\u00a0 \u00a0 \u00a0 VideoObjectTrackingPredictionParams modelParamsObj =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 VideoObjectTrackingPredictionParams.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setConfidenceThreshold(((float) 0.5))\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 Value modelParameters = ValueConverter.toValue(modelParamsObj);\u00a0 \u00a0 \u00a0 GcsSource.Builder gcsSource = GcsSource.newBuilder();\u00a0 \u00a0 \u00a0 gcsSource.addUris(gcsSourceUri);\u00a0 \u00a0 \u00a0 InputConfig inputConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 InputConfig.newBuilder().setInstancesFormat(\"jsonl\").setGcsSource(gcsSource).build();\u00a0 \u00a0 \u00a0 GcsDestination gcsDestination =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 GcsDestination.newBuilder().setOutputUriPrefix(gcsDestinationOutputUriPrefix).build();\u00a0 \u00a0 \u00a0 OutputConfig outputConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 OutputConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setPredictionsFormat(\"jsonl\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setGcsDestination(gcsDestination)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 BatchPredictionJob batchPredictionJob =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 BatchPredictionJob.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDisplayName(batchPredictionDisplayName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setModel(modelName.toString())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setModelParameters(modelParameters)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputConfig(inputConfig)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setOutputConfig(outputConfig)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 BatchPredictionJob batchPredictionJobResponse =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 jobServiceClient.createBatchPredictionJob(locationName, batchPredictionJob);\u00a0 \u00a0 \u00a0 System.out.println(\"Create Batch Prediction Job Video Object Tracking Response\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\tName: %s\\n\", batchPredictionJobResponse.getName());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tDisplay Name: %s\\n\", batchPredictionJobResponse.getDisplayName());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tModel %s\\n\", batchPredictionJobResponse.getModel());\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\tModel Parameters: %s\\n\", batchPredictionJobResponse.getModelParameters());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tState: %s\\n\", batchPredictionJobResponse.getState());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tCreate Time: %s\\n\", batchPredictionJobResponse.getCreateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tStart Time: %s\\n\", batchPredictionJobResponse.getStartTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tEnd Time: %s\\n\", batchPredictionJobResponse.getEndTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tUpdate Time: %s\\n\", batchPredictionJobResponse.getUpdateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"\\tLabels: %s\\n\", batchPredictionJobResponse.getLabelsMap());\u00a0 \u00a0 \u00a0 InputConfig inputConfigResponse = batchPredictionJobResponse.getInputConfig();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tInput Config\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tInstances Format: %s\\n\", inputConfigResponse.getInstancesFormat());\u00a0 \u00a0 \u00a0 GcsSource gcsSourceResponse = inputConfigResponse.getGcsSource();\u00a0 \u00a0 \u00a0 System.out.println(\"\\t\\tGcs Source\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\t\\tUris %s\\n\", gcsSourceResponse.getUrisList());\u00a0 \u00a0 \u00a0 BigQuerySource bigQuerySource = inputConfigResponse.getBigquerySource();\u00a0 \u00a0 \u00a0 System.out.println(\"\\t\\tBigquery Source\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\t\\tInput_uri: %s\\n\", bigQuerySource.getInputUri());\u00a0 \u00a0 \u00a0 OutputConfig outputConfigResponse = batchPredictionJobResponse.getOutputConfig();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tOutput Config\");\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\t\\tPredictions Format: %s\\n\", outputConfigResponse.getPredictionsFormat());\u00a0 \u00a0 \u00a0 GcsDestination gcsDestinationResponse = outputConfigResponse.getGcsDestination();\u00a0 \u00a0 \u00a0 System.out.println(\"\\t\\tGcs Destination\");\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\t\\t\\tOutput Uri Prefix: %s\\n\", gcsDestinationResponse.getOutputUriPrefix());\u00a0 \u00a0 \u00a0 BigQueryDestination bigQueryDestination = outputConfigResponse.getBigqueryDestination();\u00a0 \u00a0 \u00a0 System.out.println(\"\\t\\tBig Query Destination\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\t\\tOutput Uri: %s\\n\", bigQueryDestination.getOutputUri());\u00a0 \u00a0 \u00a0 BatchDedicatedResources batchDedicatedResources =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 batchPredictionJobResponse.getDedicatedResources();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tBatch Dedicated Resources\");\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\t\\tStarting Replica Count: %s\\n\", batchDedicatedResources.getStartingReplicaCount());\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"\\t\\tMax Replica Count: %s\\n\", batchDedicatedResources.getMaxReplicaCount());\u00a0 \u00a0 \u00a0 MachineSpec machineSpec = batchDedicatedResources.getMachineSpec();\u00a0 \u00a0 \u00a0 System.out.println(\"\\t\\tMachine Spec\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\t\\tMachine Type: %s\\n\", machineSpec.getMachineType());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\t\\tAccelerator Type: %s\\n\", machineSpec.getAcceleratorType());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\t\\tAccelerator Count: %s\\n\", machineSpec.getAcceleratorCount());\u00a0 \u00a0 \u00a0 ManualBatchTuningParameters manualBatchTuningParameters =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 batchPredictionJobResponse.getManualBatchTuningParameters();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tManual Batch Tuning Parameters\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tBatch Size: %s\\n\", manualBatchTuningParameters.getBatchSize());\u00a0 \u00a0 \u00a0 OutputInfo outputInfo = batchPredictionJobResponse.getOutputInfo();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tOutput Info\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tGcs Output Directory: %s\\n\", outputInfo.getGcsOutputDirectory());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tBigquery Output Dataset: %s\\n\", outputInfo.getBigqueryOutputDataset());\u00a0 \u00a0 \u00a0 Status status = batchPredictionJobResponse.getError();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tError\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tCode: %s\\n\", status.getCode());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tMessage: %s\\n\", status.getMessage());\u00a0 \u00a0 \u00a0 List<Any> details = status.getDetailsList();\u00a0 \u00a0 \u00a0 for (Status partialFailure : batchPredictionJobResponse.getPartialFailuresList()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"\\tPartial Failure\");\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tCode: %s\\n\", partialFailure.getCode());\u00a0 \u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tMessage: %s\\n\", partialFailure.getMessage());\u00a0 \u00a0 \u00a0 \u00a0 List<Any> partialFailureDetailsList = partialFailure.getDetailsList();\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 ResourcesConsumed resourcesConsumed = batchPredictionJobResponse.getResourcesConsumed();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tResources Consumed\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tReplica Hours: %s\\n\", resourcesConsumed.getReplicaHours());\u00a0 \u00a0 \u00a0 CompletionStats completionStats = batchPredictionJobResponse.getCompletionStats();\u00a0 \u00a0 \u00a0 System.out.println(\"\\tCompletion Stats\");\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tSuccessful Count: %s\\n\", completionStats.getSuccessfulCount());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tFailed Count: %s\\n\", completionStats.getFailedCount());\u00a0 \u00a0 \u00a0 System.out.format(\"\\t\\tIncomplete Count: %s\\n\", completionStats.getIncompleteCount());\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/create-batch-prediction-job-video-object-tracking.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\\\u00a0* (Not necessary if passing values as arguments)\u00a0*/// const batchPredictionDisplayName = 'YOUR_BATCH_PREDICTION_DISPLAY_NAME';// const modelId = 'YOUR_MODEL_ID';// const gcsSourceUri = 'YOUR_GCS_SOURCE_URI';// const gcsDestinationOutputUriPrefix = 'YOUR_GCS_DEST_OUTPUT_URI_PREFIX';// \u00a0 \u00a0eg. \"gs://<your-gcs-bucket>/destination_path\"// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';const aiplatform = require('@google-cloud/aiplatform');const {params} = aiplatform.protos.google.cloud.aiplatform.v1.schema.predict;// Imports the Google Cloud Job Service Client libraryconst {JobServiceClient} = require('@google-cloud/aiplatform').v1;// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};// Instantiates a clientconst jobServiceClient = new JobServiceClient(clientOptions);async function createBatchPredictionJobVideoObjectTracking() {\u00a0 // Configure the parent resource\u00a0 const parent = `projects/${project}/locations/${location}`;\u00a0 const modelName = `projects/${project}/locations/${location}/models/${modelId}`;\u00a0 // For more information on how to configure the model parameters object, see\u00a0 // https://cloud.google.com/ai-platform-unified/docs/predictions/batch-predictions\u00a0 const modelParamsObj = new params.VideoObjectTrackingPredictionParams({\u00a0 \u00a0 confidenceThreshold: 0.5,\u00a0 });\u00a0 const modelParameters = modelParamsObj.toValue();\u00a0 const inputConfig = {\u00a0 \u00a0 instancesFormat: 'jsonl',\u00a0 \u00a0 gcsSource: {uris: [gcsSourceUri]},\u00a0 };\u00a0 const outputConfig = {\u00a0 \u00a0 predictionsFormat: 'jsonl',\u00a0 \u00a0 gcsDestination: {outputUriPrefix: gcsDestinationOutputUriPrefix},\u00a0 };\u00a0 const batchPredictionJob = {\u00a0 \u00a0 displayName: batchPredictionDisplayName,\u00a0 \u00a0 model: modelName,\u00a0 \u00a0 modelParameters,\u00a0 \u00a0 inputConfig,\u00a0 \u00a0 outputConfig,\u00a0 };\u00a0 const request = {\u00a0 \u00a0 parent,\u00a0 \u00a0 batchPredictionJob,\u00a0 };\u00a0 // Create batch prediction job request\u00a0 const [response] = await jobServiceClient.createBatchPredictionJob(request);\u00a0 console.log('Create batch prediction job video object tracking response');\u00a0 console.log(`Name : ${response.name}`);\u00a0 console.log('Raw response:');\u00a0 console.log(JSON.stringify(response, null, 2));}createBatchPredictionJobVideoObjectTracking();\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_batch_prediction_job_sample.py) \n```\ndef create_batch_prediction_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 model_resource_name: str,\u00a0 \u00a0 job_display_name: str,\u00a0 \u00a0 gcs_source: Union[str, Sequence[str]],\u00a0 \u00a0 gcs_destination: str,\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 my_model = aiplatform.Model(model_resource_name)\u00a0 \u00a0 batch_prediction_job = my_model.batch_predict(\u00a0 \u00a0 \u00a0 \u00a0 job_display_name=job_display_name,\u00a0 \u00a0 \u00a0 \u00a0 gcs_source=gcs_source,\u00a0 \u00a0 \u00a0 \u00a0 gcs_destination_prefix=gcs_destination,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 batch_prediction_job.wait()\u00a0 \u00a0 print(batch_prediction_job.display_name)\u00a0 \u00a0 print(batch_prediction_job.resource_name)\u00a0 \u00a0 print(batch_prediction_job.state)\u00a0 \u00a0 return batch_prediction_job\n```\n### Retrieve batch prediction results\nVertex AI sends batch prediction output to your specified destination.\nWhen a batch prediction task is complete, the output of the prediction is stored in the Cloud Storage bucket that you specified in your request.### Example batch prediction results\nThe following an example batch prediction results from a video object tracking model.\n```\n{\n \"instance\": {\n \"content\": \"gs://bucket/video.mp4\",\n \"mimeType\": \"video/mp4\",\n \"timeSegmentStart\": \"1s\",\n \"timeSegmentEnd\": \"5s\"\n }\n \"prediction\": [{\n \"id\": \"1\",\n \"displayName\": \"cat\",\n \"timeSegmentStart\": \"1.2s\",\n \"timeSegmentEnd\": \"3.4s\",\n \"frames\": [{\n  \"timeOffset\": \"1.2s\",\n  \"xMin\": 0.1,\n  \"xMax\": 0.2,\n  \"yMin\": 0.3,\n  \"yMax\": 0.4\n }, {\n  \"timeOffset\": \"3.4s\",\n  \"xMin\": 0.2,\n  \"xMax\": 0.3,\n  \"yMin\": 0.4,\n  \"yMax\": 0.5,\n }],\n \"confidence\": 0.7\n }, {\n \"id\": \"1\",\n \"displayName\": \"cat\",\n \"timeSegmentStart\": \"4.8s\",\n \"timeSegmentEnd\": \"4.8s\",\n \"frames\": [{\n  \"timeOffset\": \"4.8s\",\n  \"xMin\": 0.2,\n  \"xMax\": 0.3,\n  \"yMin\": 0.4,\n  \"yMax\": 0.5,\n }],\n \"confidence\": 0.6\n }, {\n \"id\": \"2\",\n \"displayName\": \"dog\",\n \"timeSegmentStart\": \"1.2s\",\n \"timeSegmentEnd\": \"3.4s\",\n \"frames\": [{\n  \"timeOffset\": \"1.2s\",\n  \"xMin\": 0.1,\n  \"xMax\": 0.2,\n  \"yMin\": 0.3,\n  \"yMax\": 0.4\n }, {\n  \"timeOffset\": \"3.4s\",\n  \"xMin\": 0.2,\n  \"xMax\": 0.3,\n  \"yMin\": 0.4,\n  \"yMax\": 0.5,\n }],\n \"confidence\": 0.5\n }]\n}\n```", "guide": "Vertex AI"}