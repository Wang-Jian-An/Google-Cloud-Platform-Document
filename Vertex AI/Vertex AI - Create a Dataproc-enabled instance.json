{"title": "Vertex AI - Create a Dataproc-enabled instance", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Create a Dataproc-enabled instance\n# Create a Dataproc-enabled instance\nThis page describes how to create a Dataproc-enabled Vertex AI Workbench instance. This page also describes the benefits of the Dataproc JupyterLab plugin and provides an overview on how to use the plugin with Dataproc Serverless for Spark and Dataproc on Compute Engine.\n", "content": "## Overview of the Dataproc JupyterLab plugin\nVertex AI Workbench instances have the Dataproc JupyterLab plugin preinstalled, as of version `M113` and later.\n**Note:** You can also [install and use the  Dataproc JupyterLab plugin on your local machine or  a Compute Engine VM  instance](/dataproc-serverless/docs/quickstarts/jupyterlab-sessions) .\nThe Dataproc JupyterLab plugin provides two ways to run Apache Spark notebooks jobs: Dataproc clusters and Serverless Spark on Dataproc.\n- **Dataproc clusters** include a rich set  of features with control over the infrastructure that Spark runs on.  You choose the size and configuration of your Spark cluster, allowing  for customization and control over your environment. This approach is  ideal for complex workloads, long-running jobs, and  fine-grained resource management.\n- **Serverless Spark powered by Dataproc** eliminates infrastructure concerns. You submit your Spark jobs, and  Google handles the provisioning, scaling, and optimization of resources  behind the scenes. This serverless approach offers an easy and  cost-efficient option for data science and ML workloads.\nWith both options, you can use Spark for data processing and analysis. The choice between Dataproc clusters and Serverless Spark depends on your specific workload requirements, desired level of control, and resource usage patterns.\nBenefits of using Serverless Spark for data science and ML workloads include:\n- **No cluster management** : You don't need to worry  about provisioning, configuring, or managing Spark clusters. This saves  you time and resources.\n- **Autoscaling** : Serverless Spark automatically scales up  and down based on the workload, so you only pay for the resources you use.\n- **High performance** : Serverless Spark is optimized for  performance and takes advantage of Google Cloud's infrastructure.\n- **Integration with other Google Cloud technologies** :  Serverless Spark integrates with other Google Cloud products,  such as BigQuery and Dataplex.\nFor more information, see the [Dataproc Serverless documentation](/dataproc-serverless/docs) .\n## Dataproc limitations and considerations\n- Spark jobs are executed with the service account identity, not  the submitting user's identity.## Before you begin\n### Required roles\nTo ensure that the service account has the necessary  permissions to run a notebook file on a Dataproc Serverless cluster or a Dataproc cluster,   ask your administrator to grant the service account the  following IAM roles:\n- [Dataproc Worker ](https://cloud.google.com/iam/docs/understanding-roles#dataproc.worker) (`roles/dataproc.worker`)    on your project\n- [Dataproc Editor ](https://cloud.google.com/iam/docs/understanding-roles#dataproc.editor) (`roles/dataproc.editor`)    on the cluster for the`dataproc.clusters.use`permission\nFor more information about granting roles, see [Manage access](/iam/docs/granting-changing-revoking-access) .\nThese predefined roles contain     the permissions required to run a notebook file on a Dataproc Serverless cluster or a Dataproc cluster. To see the exact permissions that are   required, expand the **Required permissions** section:\nYour administrator might also be able to give the service account   these permissions  with [custom roles](/iam/docs/creating-custom-roles) or  other [predefined roles](/iam/docs/understanding-roles) .\n## Create an instance with Dataproc enabled\nTo create a Vertex AI Workbench instance with Dataproc enabled, do the following:\n- In the Google Cloud console, go to the **Instances** page. [Go to Instances](https://console.cloud.google.com/vertex-ai/workbench/instances) \n- Click add_box **Create new** .\n- In the **New instance** dialog, click **Advanced options** .\n- In the **Create instance** dialog, in the **Details** section, make sure **Enable Dataproc** is selected.\n- Make sure **Workbench type** is set to **Instance** .\n- In the **Environment** section, make sure you use the latest version or a version numbered `M113` or higher.\n- Click **Create** .Vertex AI Workbench creates an instance and automatically starts it. When the instance is ready to use, Vertex AI Workbench activates an **Open JupyterLab** link.## Open JupyterLab\nNext to your instance's name, click **Open JupyterLab** .\nThe JupyterLab **Launcher** tab opens in your browser. By default it contains sections for **Dataproc Serverless Notebooks** and **Dataproc Jobs and Sessions** . If there are Jupyter-ready clusters in the selected project and region, there will be a section called **Dataproc Cluster Notebooks** .\n## Use the plugin with Dataproc Serverless for Spark\nServerless Spark runtime templates that are in the same region and project as your Vertex AI Workbench instance appear in the **Dataproc Serverless Notebooks** section of the JupyterLab **Launcher** tab.\nTo create a runtime template, see [Create a Dataproc Serverlessruntime template](/dataproc-serverless/docs/quickstarts/jupyterlab-sessions#create_a_serverless_runtime_template) .\nTo open a new Serverless Spark notebook, click a runtime template. It takes about a minute for the remote Spark kernel to start. After the kernel starts, you can start coding. To run your code on Serverless Spark, run a code cell in your notebook.\n## Use the plugin with Dataproc on Compute Engine\nIf you created a [Dataproc on Compute EngineJupyter cluster](/dataproc/docs/concepts/components/jupyter#install_jupyter) , the **Launcher** tab has a **Dataproc Cluster Notebooks** section.\nFour cards appear for each Jupyter-ready Dataproc cluster that you have access to in that region and project.\nTo change the region and project, do the following:\n- Select **Settings\u00a0>Cloud Dataproc Settings** .\n- On the **Setup Config** tab, under **Project Info** , change the **Project ID** and **Region** , and then click **Save** .These changes don't take effect until you restart JupyterLab.\n- To restart JupyterLab, select **File\u00a0> Shut Down** , and then click **Open JupyterLab** on the **Vertex AI Workbench instances** page.\nTo create a new notebook, click a card. After the remote kernel on the Dataproc cluster starts, you can start writing your code and then run it on your cluster.\n## Manage Dataproc on Vertex AI Workbench instance using the gcloud CLI\nVertex AI Workbench instances are created with Dataproc enabled by default. You can create a Vertex AI Workbench instance with Dataproc turned off by setting the `disable-mixer` `metadata` key to `true` .\n```\ngcloud workbench instances create INSTANCE_NAME --metadata=disable-mixer=true\n```\nDataproc can be enabled on a stopped Vertex AI Workbench instance by updating the metadata value.\n```\ngcloud workbench instances create INSTANCE_NAME --metadata=disable-mixer=false\n```\n## Manage Dataproc using Terraform\nDataproc for Vertex AI Workbench instances on Terraform is managed using the `disable-mixer` key in the metadata field. Turn on Dataproc by setting the `disable-mixer` `metadata` key to `false` . Turn off Dataproc by setting the `disable-mixer` metadata key to `true` .\nTo learn how to apply or remove a Terraform configuration, see [Basic Terraform commands](/docs/terraform/basic-commands) .\n[View on GitHub](https://github.com/terraform-google-modules/terraform-docs-samples/blob/HEAD/vertex_ai/workbench_dataproc/main.tf)\n```\nresource \"google_workbench_instance\" \"default\" {\n name  = \"workbench-instance-example\"\n location = \"us-central1-a\"\n gce_setup {\n machine_type = \"n1-standard-1\"\n vm_image {\n  project = \"deeplearning-platform-release\"\n  family = \"tf-latest-gpu\"\n }\n metadata = {\n  disable-mixer = \"false\"\n }\n }\n}\n```\n## What's next\n- For more information about the Dataproc JupyterLab plugin, see [Use JupyterLab for serverless batch and interactive notebooksessions](/dataproc-serverless/docs/quickstarts/jupyterlab-sessions) .\n- To learn more about Serverless Spark, see the [Dataproc Serverless documentation](/dataproc-serverless/docs) \n- [Learn how to run Serverless Spark workloads without provisioning andmanaging clusters.](https://cloud.google.com/blog/products/data-analytics/serverless-spark-on-google-cloud-interactive-tutorial) \n- To learn more about using Spark with Google Cloud products and services, see [Spark on Google Cloud](/solutions/spark) .\n- Browse the available [Dataproc templates onGitHub](https://github.com/GoogleCloudPlatform/dataproc-templates) .\n- Learn about Serverless Spark through the [serverless-spark-workshop onGitHub](https://github.com/GoogleCloudPlatform/serverless-spark-workshop) .\n- Read the [Apache Spark documentation](https://spark.apache.org/docs/latest/) .", "guide": "Vertex AI"}