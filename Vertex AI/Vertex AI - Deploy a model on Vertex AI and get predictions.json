{"title": "Vertex AI - Deploy a model on Vertex AI and get predictions", "url": "https://cloud.google.com/vertex-ai/docs/open-source/ray-on-vertex-ai/deploy-predict", "abstract": "# Vertex AI - Deploy a model on Vertex AI and get predictions\n**    Preview     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nAfter training a model on a Ray cluster on Vertex AI, you can deploy the model for online prediction requests using the following process:\n- Export the model from the [Ray checkpoint](https://docs.ray.io/en/latest/tune/tutorials/tune-trial-checkpoints.html) .\n- Upload the model to [Vertex AI Model Registry](/vertex-ai/docs/model-registry/introduction) .\n- Deploy the model to an endpoint.\n- Make prediction requests.\n[Ray on Vertex AI overview](/vertex-ai/docs/open-source/ray-on-vertex-ai/overview)\n[set up](/vertex-ai/docs/open-source/ray-on-vertex-ai/set-up)\nThe steps in this section assume that you're using the Ray on Vertex AI SDK in an interactive Python environment.\n", "content": "## Import and initialize Ray on Vertex AI client\nIf you're already connected to your Ray cluster on Vertex AI, restart your kernel and run the following code. The `runtime_env` variable is necessary at connection time to run online prediction commands.\n```\nimport rayfrom google.cloud import aiplatform# The CLUSTER_RESOURCE_NAME is the one returned from vertex_ray.create_ray_cluster.address = 'vertex_ray://{}'.format(CLUSTER_RESOURCE_NAME)# Initialize Vertex AI to retrieve projects for downstream operations.aiplatform.init(staging_bucket=BUCKET_URI)# Shutdown cluster and reconnect with required dependencies in the runtime_env.ray.shutdown()\n```\nWhere:\n- : The full resource name for the Ray on Vertex AI cluster that must be unique across your project.\n- is the Cloud Storage bucket to store the model artifacts.## Train and export the model to Vertex AI Model Registry\nExport the Vertex AI model from the Ray checkpoint and upload the model to Vertex AI Model Registry.\n```\nimport numpy as npfrom ray.air import session, CheckpointConfig, ScalingConfigfrom ray.air.config import RunConfigfrom ray.train.tensorflow import TensorflowCheckpoint, TensorflowTrainerfrom ray.tune.syncer import SyncConfigimport tensorflow as tffrom vertex_ray.predict import tensorflow# Required dependencies at runtimeruntime_env = {\u00a0 \"pip\": [\u00a0 \u00a0 \u00a0 \"ray==2.4.0\", # pin the Ray version to prevent it from being overwritten\u00a0 \u00a0 \u00a0 \"tensorflow\",\u00a0 \u00a0 \u00a0 \"IPython\",\u00a0 \u00a0 \u00a0 \"numpy\",\u00a0 ],}# Initialize \u00a0Ray on Vertex AI client for remote cluster connectionray.init(address=address, runtime_env=runtime_env)# Define a TensorFlow model.def create_model():\u00a0 model = tf.keras.Sequential([tf.keras.layers.Dense(1, activation=\"linear\", input_shape=(4,))])\u00a0 model.compile(optimizer=\"Adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])\u00a0 return modeldef train_func(config):\u00a0 n = 100\u00a0 # Create a fake dataset\u00a0 # data \u00a0 : X - dim = (n, 4)\u00a0 # target : Y - dim = (n, 1)\u00a0 X = np.random.normal(0, 1, size=(n, 4))\u00a0 Y = np.random.uniform(0, 1, size=(n, 1))\u00a0 strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\u00a0 with strategy.scope():\u00a0 \u00a0 \u00a0 model = create_model()\u00a0 \u00a0 \u00a0 print(model)\u00a0 for epoch in range(config[\"num_epochs\"]):\u00a0 \u00a0 \u00a0 model.fit(X, Y, batch_size=20)\u00a0 \u00a0 \u00a0 model.save(\"temp/my_model\")\u00a0 \u00a0 \u00a0 checkpoint = TensorflowCheckpoint.from_saved_model(\"temp/my_model\")\u00a0 \u00a0 \u00a0 session.report({}, checkpoint=checkpoint)trainer = TensorflowTrainer(\u00a0 train_func,\u00a0 train_loop_config={\"num_epochs\": 5},\u00a0 scaling_config=ScalingConfig(num_workers=1),\u00a0 run_config=RunConfig(\u00a0 \u00a0 \u00a0 checkpoint_config=CheckpointConfig(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 num_to_keep=1 \u00a0# Keep all checkpoints.\u00a0 \u00a0 \u00a0 ),\u00a0 \u00a0 \u00a0 sync_config=SyncConfig(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 upload_dir=f'{BUCKET_URI}/ray_results/tensorflow',\u00a0 \u00a0 \u00a0 ),\u00a0 ),)# Train the model.result = trainer.fit()# Register the trained model to Vertex AI Model Registry.vertex_model = tensorflow.register_tensorflow(\u00a0 result.checkpoint,)\n```\n```\nfrom vertex_ray.predict import sklearnfrom ray.train.sklearn import SklearnCheckpointvertex_model = sklearn.register_sklearn(\u00a0 SklearnCheckpoint.from_checkpoint(result.checkpoint))\n```\n```\nfrom vertex_ray.predict import xgboostfrom ray.train.xgboost import XGBoostCheckpointvertex_model = xgboost.register_xgboost(\u00a0 XGBoostCheckpoint.from_checkpoint(result.checkpoint))\n```\n## Deploy the model\nDeploy the model to the online endpoint. For more information, see [Deploy the model to an endpoint](/vertex-ai/docs/general/deployment) .\n```\nDEPLOYED_NAME = model.display_name + \"-endpoint\"TRAFFIC_SPLIT = {\"0\": 100}MACHINE_TYPE = \"n1-standard-4\"endpoint = vertex_model.deploy(\u00a0 \u00a0 deployed_model_display_name=DEPLOYED_NAME,\u00a0 \u00a0 traffic_split=TRAFFIC_SPLIT,\u00a0 \u00a0 machine_type=MACHINE_TYPE,)\n```\nWhere:\n- (Optional) : The display name of the deployed model. If not provided upon creation, the model's `display_name` is used.\n- (Optional) : A map from a deployed model's ID to the percentage of this endpoint's traffic that should be forwarded to that deployed model. If a deployed model's ID is not listed in this map, then it receives no traffic. The traffic percentage values must add up to 100, or the map must be empty if the endpoint is to not accept any traffic at the moment. The key for the model being deployed is `\"0\"` . For example, `{\"0\": 100}` .\n- (Optional) : [Specify the compute resources](/vertex-ai/docs/predictions/configure-compute#specify) .## Make a prediction request\nSend a prediction request to the endpoint. For more information, see [Get online predictions from a custom trained model](/vertex-ai/docs/predictions/get-online-predictions) .\n```\npred_request = [\u00a0 \u00a0 [ 1.7076793 , 0.23412449, 0.95170785, -0.10901471],\u00a0 \u00a0 [-0.81881499, 0.43874669, -0.25108584, 1.75536031]]endpoint.predict(pred_request)\n```\nYou should get output like the following:\n```\nPrediction(predictions=[0.7891440987586975, 0.5843208432197571],\u00a0deployed_model_id='3829557218101952512',\u00a0model_version_id='1',\u00a0model_resource_name='projects/123456789/locations/us-central1/models/123456789101112',\u00a0explanations=None)\n```\n## What's next\n- [View logs for your Ray cluster on Vertex AI](/vertex-ai/docs/open-source/ray-on-vertex-ai/view-logs) \n- [Delete a Ray cluster](/vertex-ai/docs/open-source/ray-on-vertex-ai/delete-cluster)", "guide": "Vertex AI"}