{"title": "Vertex AI - Create a managed notebooks instance with a custom container", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Create a managed notebooks instance with a custom container\n# Create a managed notebooks instance with a custom container\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\nThis page shows you how to add a custom container to a Vertex AI Workbench managed notebooks instance as a kernel that you can run your notebook files on.\n", "content": "## Overview\nYou can add a custom container for use with your managed notebooks instance. The custom container is then available as a local kernel that you can run your notebook file on.\n## Custom container requirements\nVertex AI Workbench managed notebooks supports any of the current [Deep Learning Containerscontainer images](https://cloud.google.com/deep-learning-containers/docs/choosing-container#deciding) .\nTo create a custom container image of your own, you can modify one of the Deep Learning Containers container images to [create aderivative container image](/deep-learning-containers/docs/derivative-container) .\nTo create a custom container image from scratch, make sure the container image meets the following requirements:\n- Use a Docker container image with at least one valid Jupyter kernelspec. This exposed kernelspec lets Vertex AI Workbench managed notebooks load the container image as a kernel. If your container image includes an installation of [JupyterLab](https://pypi.org/project/jupyterlab/) or [Jupyter Notebook](https://pypi.org/project/notebook/) , the installation will include the kernelspec by default. If your container image doesn't have the kernelspec, you can [install thekernelspec](https://ipython.readthedocs.io/en/stable/install/kernel_install.html) directly. **Note:** If your container has a valid Jupyter kernelspec,  it will respond to `jupyter kernelspec list --json` with a list of available kernelspecs.\n- The Docker container image must support `sleep infinity` .\n- To use your custom container with the [managed notebooks executor](/vertex-ai/docs/workbench/managed/executor) , ensure that your custom container has the `nbexecutor` extension.\n**Note:** Deep Learning Containers container images include  a valid Jupyter kernelspec and the `nbexecutor` extension by default.\nThe following example Dockerfile text builds a custom Docker image from scratch that is based on an Ubuntu image and includes the latest Python version.\n```\nFROM --platform=linux/amd64 ubuntu:22.04RUN apt-get -y updateRUN apt-get install -y --no-install-recommends \\python3-pip \\pipx \\git \\make \\jqRUN pip install \\argcomplete>=1.9.4 \\poetry==1.1.14 \\jupyterlab==3.3.0# Create a link that points to the right python bin directoryRUN ln -s /usr/bin/pythonVERSION_NUMBER /usr/bin/python\n```\nReplace `` with the version of Python that you're using.\n### How a custom container becomes a kernel in managed notebooks\nFor each custom container image provided, your managed notebooks instance identifies the available Jupyter kernelspec on the container image when the instance starts. The kernelspec appears as a local kernel in the JupyterLab interface. When the kernelspec is selected, the managed notebooks kernel manager runs the custom container as a kernel and starts a Jupyter session on that kernel.\n### How custom container kernels are updated\nVertex AI Workbench pulls the latest container image for your kernel:\n- When you create your instance.\n- When you upgrade your instance.\n- When you start your instance.\nThe custom container kernel doesn't persist when your instance is stopped, so each time your instance is started, Vertex AI Workbench pulls the latest version of the container image.\nIf your instance is running when a new version of a container is released, your instance's kernel isn't updated until you stop and start your instance.\n### Custom container image availability\nDeep Learning Containers container images are available to all users. When you use a Deep Learning Containers container image, you must grant specific roles to your instance's service account so your instance can load the Deep Learning Containers container image as a kernel. Learn more about the required permissions and how to grant them in the [Permissions](#permissions) section.\nIf you want to use your own custom container image, it must be located in [Artifact Registry](/artifact-registry/docs) and the container image must be publicly available.\n## Before you begin\n## Add a custom container while creating an instance\nTo add a custom container to a managed notebooks instance, the custom container image must be specified at instance creation.\nTo add a custom container while you create a managed notebooks instance, complete the following steps.\n- In the Google Cloud console, go to the **Managed notebooks** page. [Go to Managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/managed) \n- Click add_box **Create new** .\n- In the **Name** field, enter a name for your instance.\n- Click the **Region** list, and select a region for your instance.\n- In the **Environment** section, select **Provide custom Docker images** .\n- Add a Docker container image in one of the following ways:- Enter a Docker container image path. For example, to use a TensorFlow 2.12 container image with accelerators from [Deep Learning Containers](/deep-learning-containers/docs/choosing-container#deciding) , enter`us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf-cpu.2-12.py310`.\n- Click **Select** to add a Docker container image from Artifact Registry. Then on the **Artifact Registry** tab where your container image is stored, change the project to the project that includes your container image, and select your container image.\n- Complete the rest of the **Create instance** dialog according to your needs.\n- Click **Create** .\n- Vertex AI Workbench automatically starts the instance. When the instance is ready to use, Vertex AI Workbench activates an **Open JupyterLab** link.## Grant permissions to Deep Learning Containers container images\nIf you aren't using a Deep Learning Containers container image, skip this section.\nTo ensure that your instance's service account has the necessary  permissions to load a Deep Learning Containers container image from Artifact Registry,   ask your administrator to grant your instance's service account the  following IAM roles on your instance:\n- [Compute Instance Admin (v1) ](https://cloud.google.com/iam/docs/understanding-roles#compute.instanceAdmin.v1) (`roles/compute.instanceAdmin.v1`)\n- [Artifact Registry Reader ](https://cloud.google.com/iam/docs/understanding-roles#artifactregistry.reader) (`roles/artifactregistry.reader`)\nFor more information about granting roles, see [Manage access](/iam/docs/granting-changing-revoking-access) .\nYour administrator might also be able to give your instance's service account  the required permissions through [custom  roles](/iam/docs/creating-custom-roles) or other [predefined  roles](/iam/docs/understanding-roles) .\n## Set up a notebook file to run in your custom container\nTo open JupyterLab, create a new notebook file, and set it up to run on your custom container's kernel, complete the following steps.\n- Next to your managed notebooks instance's name, click **Open JupyterLab** .\n- In the **Authenticate your managed notebook** dialog, click the button to get an authentication code.\n- Choose an account and click **Allow** . Copy the authentication code.\n- In the **Authenticate your managed notebook** dialog, paste the authentication code, and then click **Authenticate** .Your managed notebooks instance opens JupyterLab.\n- Select **File\u00a0> New\u00a0> Notebook** .\n- In the **Select kernel** dialog, select the kernel for the custom container image that you want to use, and then click **Select** . Larger container images may take some time to appear as a kernel. If the kernel that you want isn't there yet, try again in a few minutes. You can [change thekernel](/vertex-ai/docs/workbench/managed/create-managed-notebooks-instance-console-quickstart#change-kernel) whenever you want to run your notebook file on a different kernel.Your new notebook file opens.## What's next\n- Learn how to [access Cloud Storage buckets and filesfrom within JupyterLab](/vertex-ai/docs/workbench/managed/cloud-storage) .\n- Learn how to [query data in BigQuery tablesfrom within JupyterLab](/vertex-ai/docs/workbench/managed/bigquery) .", "guide": "Vertex AI"}