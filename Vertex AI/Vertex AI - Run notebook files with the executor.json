{"title": "Vertex AI - Run notebook files with the executor", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Run notebook files with the executor\n# Run notebook files with the executor\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\nThis page describes how to use the executor in a Vertex AI Workbench managed notebooks instance to run notebook files as a one-time execution and on a schedule.\n", "content": "## Overview\nThe executor lets you submit a notebook (ipynb) file to run on [Vertex AI custom training](/vertex-ai/docs/training/overview) . You can set parameter values for each execution of a notebook file. You can also run a notebook file on a recurring schedule. After the execution completes, you can view the execution results and share them with others.\nWhen a notebook file is submitted to Vertex AI custom training, Vertex AI creates a new custom training job that executes your notebook file following the [lifecycle of a trainingjob](/vertex-ai/docs/training/understanding-training-service#lifecycle_of_a_training_job) .\n## Requirements for notebook code run by the executor\nWhen you write notebook code to run in the executor, keep in mind that the code will run in a [tenant project](/service-infrastructure/docs/manage-tenant-projects) separate from your managed notebooks instance's project. This section describes how this affects your code when it is run in the executor.\n### Ensure package installations are available to the executor\nIf your notebook depends on package installations that are not already included in the managed notebooks kernel that you are using, make sure your packages are available to your notebook code in the executor in one of the following ways:\n- Use a [custom container](/vertex-ai/docs/workbench/managed/custom-container) that already has the package installed, and then execute your notebook on that custom container. See the [requirements for usinga custom container with the executor](#custom-container) .\n- Install the package within your notebook file's code. The package is installed every time the notebook file is executed, but this ensures that the package is available on the container that you select when you execute your notebook.\n### Use explicit project selection\nWhen you access resources through code run by the executor, the executor might not connect to the correct Google Cloud project. If you encounter permission errors, connecting to the wrong project might be the problem.\nThis problem occurs because the executor does not run your code directly in your managed notebooks instance's Google Cloud project. Instead, the executor runs your code in Vertex AI custom training within a tenant project managed by Google. Therefore, don't try to infer a project ID from the environment in your notebook code; specify project IDs explicitly.\nIf you don't want to hardcode a project ID in your code, you can reference the `CLOUD_ML_PROJECT_ID` environment variable. Vertex AI sets this environment variable in every custom training container to contain the [project number](/docs/overview#projects) of the project where you initiated custom training. Many Google Cloud tools can accept a project number wherever they take a project ID.\nFor example, if you want to use the [Python Client for GoogleBigQuery](https://github.com/googleapis/python-bigquery) to access a BigQuery table in the same project, then do not infer the project in your notebook code:\nImplicit project selection\n```\nfrom google.cloud import bigqueryclient = bigquery.Client()\n```\nInstead use code that explicitly selects a project:\nExplicit project selection\n```\nimport osfrom google.cloud import bigqueryproject_number = os.environ[\"CLOUD_ML_PROJECT_ID\"]client = bigquery.Client(project=project_number)\n```\n### Authenticate access using service accounts\nBy default, your managed notebooks instance can have access to resources that exist in the same project. Therefore, when you run your notebook file's code manually, these resources do not need additional authentication. However, because the executor runs in a separate tenant project, it does not have the same default access.\nAlso, the executor cannot use end-user credentials to authenticate access to resources, for example, the [gcloud auth login command](/sdk/gcloud/reference/auth/login) .\nTo resolve these issues, in your notebook file's code, authenticate access to resources through a service account.\nThen when you create an execution or schedule, specify the service account.\nFor example, while you [create an execution](#create-execution) , complete these steps:\n- In the **Submit notebooks to Executor** dialog, expand **Advanced options** .\n- In the **Identity and API access** section, clear the check mark next to **Use Vertex AI Training's default service account** and enter the specific service account to use.\nSee the full list of [steps for creating an execution](#create-execution) .\n## Requirements when using a custom container\nYou can use the executor to run notebook code on a custom container. Your custom container must include the `nbexecutor` extension, which enables the executor to run notebook code as a Vertex AI custom training job. To ensure that your custom container has the `nbexecutor` extension, you can modify one of the Deep Learning Containers container images to [create aderivative container image](/deep-learning-containers/docs/derivative-container) . Deep Learning Containers images include the `nbexecutor` extension.\n## Before you begin\n- If you haven't already, [create a managed notebooks instance](/vertex-ai/docs/workbench/managed/create-instance#create) .\n### Required roles\nTo ensure that your instance's service account has the necessary  permissions to interact with the Vertex AI Workbench executor,   ask your administrator to grant your instance's service account the  following IAM roles on the project:\n- Notebooks Viewer ( [roles/notebooks.viewer](/vertex-ai/docs/workbench/instances/iam#notebooks.viewer) )\n- Vertex AI User ( [roles/aiplatform.user](/vertex-ai/docs/general/access-control#aiplatform.user) )\n- Storage Admin ( [roles/storage.admin](/storage/docs/access-control/iam-roles#standard-roles) )\nFor more information about granting roles, see [Manage access](/iam/docs/granting-changing-revoking-access) .\nYour administrator might also be able to give your instance's service account  the required permissions through [custom  roles](/iam/docs/creating-custom-roles) or other [predefined  roles](/iam/docs/understanding-roles) .\n## Open JupyterLab\nTo open JupyterLab and prepare a notebook file to run, complete the following steps.\n- [Open JupyterLab](/vertex-ai/docs/workbench/managed/create-managed-notebooks-instance-console-quickstart#open-jupyterlab) .\n- Upload a notebook (ipynb) file, open an existing file, or [open a new notebookfile](/vertex-ai/docs/workbench/managed/create-managed-notebooks-instance-console-quickstart#open-a-new-notebook-file) and add the code that you want to run to the notebook.\n- Make sure your notebook file's code meets the [requirementsfor using the executor](#requirements) .## Create an execution\nTo create an execution that runs your notebook file, complete the following steps. These steps cover both scheduling executions and creating a one-time execution.\n- In your managed notebooks instance's JupyterLab user interface, open the notebook file that you want to run.\n- Click the **Execute** button.\n- In the **Submit notebooks to Executor** dialog, in the **Execution name** field, enter a name for your execution.\n- Select a **Machine type** and **Accelerator type** .\n- Select an **Environment** .\n- In the **Type** field, select **One-time execution** or select **Schedule-based recurring executions** and complete the dialog for scheduling executions.\n- In **Advanced options** , select the **Region** where you want to run your notebook.\n- In the **Cloud Storage bucket** field, select an available Cloud Storage bucket or enter a name for a new bucket and click **Create and select** . The executor stores your notebook output in this Cloud Storage bucket.\n- Optional: in the **Notebook parameterization** section, in the **Input parameters** text box, add notebook parameters separated by commas, for example `optimizer=\"SGD\",learning_rate=0.01` .Learn more about [how to usenotebook parameters](/vertex-ai/docs/workbench/managed/executor-parameters) .\n- Optional: in the **Identity and API access** section, select **Use Vertex AI Training's default service account** or clear the check mark and enter a specific service account to use. **Note:** If your notebook file's code authenticates access to services by using end-user credentials or default access within your managed notebooks instance's project, see the [Requirements for notebook code runby the executor](#requirements) and consider specifying a service account.\n- Optional: in the **Networking** section, specify a Virtual Private Cloud network. Using a VPC network for your execution requires a [private servicesaccess](/vpc/docs/private-services-access) connection.\n- Click **Submit** .One-time executions begin immediately. Scheduled executions run automatically on the schedule that you set. **Note:** If your managed notebooks instance is shut down, the executor still runs your notebook file on schedule.\nIn the Google Cloud console, on the **Vertex AI Workbench** page, you can view your completed executions on the [Executions tab](https://console.cloud.google.com/vertex-ai/workbench/executions) and view your schedules on the [Schedules tab](https://console.cloud.google.com/vertex-ai/workbench/schedules) .\n## View, share, and import an executed notebook file\nBy using your managed notebooks instance's JupyterLab user interface, you can view an executed notebook's output, share the results with others, and import the executed notebook file into JupyterLab.\n### View a notebook execution's results\nYou can view a notebook execution's results in the Google Cloud console or in the JupyterLab user interface.\n- In the Google Cloud console, go to the **Vertex AI Workbench** page and click the **Executions** tab. [Go to Executions](https://console.cloud.google.com/vertex-ai/workbench/executions) \n- Select the **Region** that contains your results.\n- Next to the execution that you want to view, click **View result** .The result opens in a new browser tab.\n- In JupyterLab's navigation menu, click the **Notebook Executor** button.\n- Click the **Executions** tab.\n- Under the execution that you want to view, click **View result** .The result opens in a new browser tab.\n### Share a notebook execution's results\nYou can share execution results by providing access to the Cloud Storage bucket that contains your notebook execution. Providing this access also grants users access to any other resources in the same Cloud Storage bucket. To share execution results, complete the following steps.\n- In the Google Cloud console, go to the **Vertex AI Workbench** page and click the **Executions** tab. [Go to Executions](https://console.cloud.google.com/vertex-ai/workbench/executions) \n- Select the **Region** that contains the execution.\n- Next to the execution that you want to share, click the people **Share** button.\n- Follow the directions in the dialog to grant users access to the Cloud Storage bucket that contains your notebook execution.\n- In your managed notebooks instance's JupyterLab user interface, in the navigation menu, click the **Notebook Executor** button.\n- Click the **Executions** tab.\n- Next to the execution that you want to share, click the more_vert options menu, and select **Share execution result** .\n- Follow the directions in the dialog to grant users access to the Cloud Storage bucket that contains your notebook execution.\n### Import an executed notebook into JupyterLab\nTo import an executed notebook into JupyterLab, complete the following steps.\n- In your managed notebooks instance's JupyterLab user interface, in the navigation menu, click the **Notebook Executor** button.\n- Click the **Executions** tab.\n- Select the **Region** that contains your executed notebook.\n- Next to the execution that you want to import, click the more_vert options menu, and select **Import executed notebook** .\n- Select the kernel that you want to open the notebook.The executor opens the executed notebook file in JupyterLab and stores this notebook file in the JupyterLab File Browser in a folder named **imported_notebook_jobs** .## View or delete a schedule\nYou can view and delete schedules by using either the Google Cloud console or your managed notebooks instance's JupyterLab user interface.\n### View a schedule\nView a schedule to see the frequency settings of the schedule or to view results of your notebook executions.\n- In the Google Cloud console, go to the **Vertex AI Workbench** page and click the **Schedules** tab. [Go to Schedules](https://console.cloud.google.com/vertex-ai/workbench/schedules) \n- Select the **Region** that contains your schedule.\n- Click a schedule name to open the **Schedule details** page.\n- Next to an execution name, click **View result** to open the executed notebook file. The executor opens your result in a new browser tab.\n- In your managed notebooks instance's JupyterLab user interface, in the navigation menu, click the **Notebook Executor** button.\n- Click the **Schedules** tab.\n- To view the latest execution, under the execution that you want to view, click **View latest execution result** . The executor opens your result in a new browser tab.To see all of the executions, click the name of the schedule. The executor opens the **Schedule details** page in the Google Cloud console.\n- Next to an execution name, click **View result** to open the executed notebook file. The executor opens your result in a new browser tab.\n### Delete a schedule\nDeleting a schedule does not delete the executions that were generated from that schedule.\n- In the Google Cloud console, go to the **Vertex AI Workbench** page and click the **Schedules** tab. [Go to Schedules](https://console.cloud.google.com/vertex-ai/workbench/schedules) \n- Select the **Region** that contains your schedule.\n- Select the schedule you want to delete.\n- Click delete **Delete** .\n- In your managed notebooks instance's JupyterLab user interface, in the navigation menu, click the **Notebook Executor** button.\n- Click the **Schedules** tab.\n- Click the name of the schedule that you want to delete. The executor opens the **Schedule details** page in the Google Cloud console.\n- Click delete **Delete** .## Jobs on Vertex AI custom training\nBecause notebook executions are run on Vertex AI custom training, they are exposed as custom training jobs in Vertex AI. You can view these custom training jobs in the Google Cloud console, on the [Custom jobs tab ofthe Vertex AI Training page](https://console.cloud.google.com/vertex-ai/training/custom-jobs) . Learn more about [how to work withVertex AI custom training jobs](/vertex-ai/docs/training/create-custom-job) .\n## What's next\n- Learn how to [run notebook executionswith parameters](/vertex-ai/docs/workbench/managed/executor-parameters) .\n- Learn more about [Vertex AI custom training](/vertex-ai/docs/training/overview) .", "guide": "Vertex AI"}