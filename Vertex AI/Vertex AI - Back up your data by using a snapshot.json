{"title": "Vertex AI - Back up your data by using a snapshot", "url": "https://cloud.google.com/vertex-ai/docs/workbench/user-managed/backup-snapshot", "abstract": "# Vertex AI - Back up your data by using a snapshot\n# Back up your data by using a snapshot\nVertex AI Workbench user-managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  user-managed notebooks will end and the ability to create user-managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your user-managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/user-managed/migrate-to-instances) .\nThis page shows you how to back up data stored on your Vertex AI Workbench user-managed notebooks instance by creating a snapshot.\nThe data on your instance is stored on a zonal [persistent disk](/compute/docs/disks#disk-types) . You can create and use snapshots of this disk to back up your data, create a recurring backup schedule, and restore data to a new instance.\n", "content": "## Create a snapshot\nYou can create snapshots from disks even while they are attached to running instances. Snapshots are [global resources](/compute/docs/regions-zones/global-regional-zonal-resources#globalresources) , so you can use them to [restore data](/compute/docs/disks/restore-snapshot) to a new disk or instance within the same project. You can also [share snapshots](/compute/docs/disks/create-snapshots#sharing_snapshots) across projects.\n**Note:** Your Jupyter notebook files are stored on a disk  named `` `-data` .\n- In the Google Cloud console, go to the **VM instances** page. [  Go to VM instances](https://console.cloud.google.com/compute/instances?walkthrough_id=compute--storage--back-up-persistent-disk)  school The remaining steps will appear automatically in  the Google Cloud console.\n- Select the project that contains your VM instances.\n- In the **Name** column, click the name of the VM that has the persistent disk to back up.\n- In:- To back up the boot disk, in the **Boot disk** section, click the **Name** of the   boot disk.\n- To back up an attached persistent disk, in **Additional disks** , click the **Name** of the attached persistent disk.\n- Click.\n- In **Name** , enter a unique name to help identify the purpose of the snapshot, for example:- `boot-disk-snapshot`\n- `attached-persistent-disk-snapshot`\n- In **Type** , the default is a regular snapshot, which is best for long-term back up and  disaster recovery.Choose **Archive snapshot** for more cost-efficient data retention.\n- In the **Location** section, [choose your snapshot  storage location](/compute/docs/disks/snapshots#selecting_a_storage_location) .   The predefined or customized default location defined in your snapshot settings is   automatically selected. Optionally, you can override the snapshot settings and store your   snapshots in a custom storage location by doing the following:- Choose the type of storage location that you want for your snapshot.- Choose **Multi-regional** for higher availability at a higher cost.\n- Choose **Regional snapshots** for more control over the physical location of your data at a lower cost.\n- In the **Select location** field, select the specific region or multi-region that    you want to use. To use the region or multi-region that is closest to your    source disk, select **Based on disk's location** .- To create a manual snapshot, click **Create** .- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.\n- Create your snapshot using the storage location policy defined by your [snapshot settings](/compute/docs/disks/snapshot-settings) or using an alternative storage location of your choice. For more information, see [Choose your snapshot storage location](/compute/docs/disks/snapshots#selecting_a_storage_location) . You must specify a snapshot name. The name must be 1-63 characters long, and comply with [RFC 1035](https://www.ietf.org/rfc/rfc1035.txt) .- To create a snapshot of a Persistent Disk volume in the predefined or customized default location configured in your snapshot settings, use the [gcloud compute snapshots create command](/sdk/gcloud/reference/compute/snapshots/create) .```\ngcloud compute snapshots create SNAPSHOT_NAME \\\n --source-disk SOURCE_DISK \\\n --snapshot-type SNAPSHOT_TYPE \\\n --source-disk-zone SOURCE_DISK_ZONE\n```\n- Alternatively, to override the snapshot settings and create a snapshot in a custom storage location, include the `--storage-location` flag to indicate where to store your snapshot:```\ngcloud compute snapshots create SNAPSHOT_NAME \\\n --source-disk SOURCE_DISK \\\n --source-disk-zone SOURCE_DISK_ZONE \\\n --storage-location STORAGE_LOCATION \\\n --snapshot-type SNAPSHOT_TYPE\n```Replace the following:- : A name for the snapshot.\n- : The name of the zonal Persistent Disk volume from which you want to  create a snapshot.\n- : The snapshot type, either **STANDARD** or **ARCHIVE** . If a snapshot type is not specified, a **STANDARD** snapshot is created. Choose Archive for more cost-efficient data retention.\n- : The zone of the zonal Persistent Disk volume from which you want  to create a snapshot.\n- : For custom storage locations, this is the [Cloud Storage multi-region](/storage/docs/bucket-locations#location-mr) or the [Cloud Storage region](/storage/docs/bucket-locations#location-r) where you want to store your snapshot. You can specify only one storage location.\nUse the `--storage-location` flag only when you want to override the predefined or customized default storage location configured in your snapshot settings.\nThe gcloud CLI waits until the operation returns a status of `READY` or `FAILED` , or reaches the maximum timeout and returns the last known details of the snapshot. **Note:** Google recommends using the [gcloud compute snapshots createcommand](/sdk/gcloud/reference/compute/snapshots/create) instead of the [gcloud compute disks snapshot command](/sdk/gcloud/reference/compute/disks/snapshot) because it supports more features, such as creating snapshots in a project different from the source disk project.\nTo create a snapshot of the zonal persistent disk, use the [google_compute_snapshot](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_snapshot) resource.\n [  compute/disk/main.tf ](https://github.com/terraform-google-modules/terraform-docs-samples/blob/HEAD/compute/disk/main.tf) [View on GitHub](https://github.com/terraform-google-modules/terraform-docs-samples/blob/HEAD/compute/disk/main.tf) \n```\nresource \"google_compute_snapshot\" \"snapdisk\" {\n name  = \"snapshot-name\"\n source_disk = google_compute_disk.default.name\n zone  = \"us-central1-a\"\n}\n```\nTo learn how to apply or remove a Terraform configuration, see [Basic Terraform commands](/docs/terraform/basic-commands) .\nCreate your snapshot in the storage location policy defined by your [snapshot settings](/compute/docs/disks/snapshot-settings) or using an alternative storage location of your choice. For more information, see [Choose your snapshot storage location](/compute/docs/disks/snapshots#selecting_a_storage_location) .- To create your snapshot in the predefined or customized default location configured in your snapshot settings, make a `POST` request to the [snapshots.insert method](/compute/docs/reference/rest/v1/snapshots/insert) :```\nPOST https://compute.googleapis.com/compute/v1/projects/DESTINATION_PROJECT_ID/global/snapshots{\u00a0 \"name\": SNAPSHOT_NAME\u00a0 \"sourceDisk\": \"projects/SOURCE_PROJECT_ID/zones/SOURCE_ZONE/disks/SOURCE_DISK_NAME\u00a0 \"snapshotType\": SNAPSHOT_TYPE}\n```Replace the following:- : The ID of project in which you want to create the snapshot.\n- : A name for the snapshot.\n- : The ID of the source disk project.\n- : The zone of the source disk.\n- : The name of the persistent disk from which you want to create a snapshot.\n- : The snapshot type, either **STANDARD** or **ARCHIVE** . If a snapshot type is not specified, a **STANDARD** snapshot is created.\n- Alternatively, to override the snapshot settings and create a snapshot in a custom storage location, make a `POST` request to the [snapshots.insert method](/compute/docs/reference/rest/v1/snapshots/insert) and include the `storageLocations` property in your request:```\nPOST https://compute.googleapis.com/compute/v1/projects/DESTINATION_PROJECT_ID/global/snapshots{\u00a0 \"name\": SNAPSHOT_NAME\u00a0 \"sourceDisk\": \"projects/SOURCE_PROJECT_ID/zones/SOURCE_ZONE/disks/SOURCE_DISK_NAME\u00a0 \"snapshotType\": SNAPSHOT_TYPE\u00a0 \"storageLocations\": STORAGE_LOCATION}\n```Replace the following:- : The ID of project in which you want to create the snapshot.\n- : A name for the snapshot.\n- : The ID of the source disk project.\n- : The zone of the source disk.\n- : The name of the persistent disk from which you want to create a snapshot.\n- : The snapshot type, either **STANDARD** or **ARCHIVE** . If a snapshot type is not specified, a **STANDARD** snapshot is created.\n- : The [Cloud Storage multi-region](/storage/docs/bucket-locations#location-mr) or the [Cloud Storage region](/storage/docs/bucket-locations#location-r) where you want to store your snapshot. You can specify only one storage location.Use the `storageLocations` parameter only when you want to override the predefined or customized default storage location configured in your snapshot settings.\n **Note:** Google recommends using the [snapshots.insert method](/compute/docs/reference/rest/v1/snapshots/insert) instead of the [disks.createSnapshot method](/compute/docs/reference/rest/v1/disks/createSnapshot) because it supports more features, such as creating snapshots in a project different from the source disk project.\n### Go\nBefore trying this sample, follow the setup instructions in the\n [Compute Engine quickstart using client libraries](/compute/docs/api/libraries) \n.\nTo authenticate to Compute Engine, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/compute/snapshots/create_snapshot.go) \n```\nimport (\u00a0 \u00a0 \u00a0 \u00a0 \"context\"\u00a0 \u00a0 \u00a0 \u00a0 \"fmt\"\u00a0 \u00a0 \u00a0 \u00a0 \"io\"\u00a0 \u00a0 \u00a0 \u00a0 compute \"cloud.google.com/go/compute/apiv1\"\u00a0 \u00a0 \u00a0 \u00a0 computepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\u00a0 \u00a0 \u00a0 \u00a0 \"google.golang.org/protobuf/proto\")// createSnapshot creates a snapshot of a disk.func createSnapshot(\u00a0 \u00a0 \u00a0 \u00a0 w io.Writer,\u00a0 \u00a0 \u00a0 \u00a0 projectID, diskName, snapshotName, zone, region, location, diskProjectID string,) error {\u00a0 \u00a0 \u00a0 \u00a0 // projectID := \"your_project_id\"\u00a0 \u00a0 \u00a0 \u00a0 // diskName := \"your_disk_name\"\u00a0 \u00a0 \u00a0 \u00a0 // snapshotName := \"your_snapshot_name\"\u00a0 \u00a0 \u00a0 \u00a0 // zone := \"europe-central2-b\"\u00a0 \u00a0 \u00a0 \u00a0 // region := \"eupore-central2\"\u00a0 \u00a0 \u00a0 \u00a0 // location = \"eupore-central2\"\u00a0 \u00a0 \u00a0 \u00a0 // diskProjectID = \"YOUR_DISK_PROJECT_ID\"\u00a0 \u00a0 \u00a0 \u00a0 ctx := context.Background()\u00a0 \u00a0 \u00a0 \u00a0 snapshotsClient, err := compute.NewSnapshotsRESTClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"NewSnapshotsRESTClient: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 defer snapshotsClient.Close()\u00a0 \u00a0 \u00a0 \u00a0 if zone == \"\" && region == \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"you need to specify `zone` or `region` for this function to work\")\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 if zone != \"\" && region != \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"you can't set both `zone` and `region` parameters\")\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 if diskProjectID == \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 diskProjectID = projectID\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 disk := &computepb.Disk{}\u00a0 \u00a0 \u00a0 \u00a0 locations := []string{}\u00a0 \u00a0 \u00a0 \u00a0 if location != \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 locations = append(locations, location)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 if zone != \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 disksClient, err := compute.NewDisksRESTClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"NewDisksRESTClient: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 defer disksClient.Close()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 getDiskReq := &computepb.GetDiskRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Project: projectID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Zone: \u00a0 \u00a0zone,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Disk: \u00a0 \u00a0diskName,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 disk, err = disksClient.Get(ctx, getDiskReq)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"unable to get disk: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 } else {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 regionDisksClient, err := compute.NewRegionDisksRESTClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"NewRegionDisksRESTClient: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 defer regionDisksClient.Close()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 getDiskReq := &computepb.GetRegionDiskRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Project: projectID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Region: \u00a0region,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Disk: \u00a0 \u00a0diskName,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 disk, err = regionDisksClient.Get(ctx, getDiskReq)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"unable to get disk: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 req := &computepb.InsertSnapshotRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Project: projectID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SnapshotResource: &computepb.Snapshot{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 proto.String(snapshotName),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SourceDisk: \u00a0 \u00a0 \u00a0 proto.String(disk.GetSelfLink()),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StorageLocations: locations,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 op, err := snapshotsClient.Insert(ctx, req)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"unable to create snapshot: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 if err = op.Wait(ctx); err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"unable to wait for the operation: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Snapshot created\\n\")\u00a0 \u00a0 \u00a0 \u00a0 return nil}\n```\n### Java\nBefore trying this sample, follow the setup instructions in the\n [Compute Engine quickstart using client libraries](/compute/docs/api/libraries) \n.\nTo authenticate to Compute Engine, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/compute/cloud-client/src/main/java/compute/disks/CreateSnapshot.java) \n```\nimport com.google.cloud.compute.v1.Disk;import com.google.cloud.compute.v1.DisksClient;import com.google.cloud.compute.v1.Operation;import com.google.cloud.compute.v1.RegionDisksClient;import com.google.cloud.compute.v1.Snapshot;import com.google.cloud.compute.v1.SnapshotsClient;import java.io.IOException;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;public class CreateSnapshot {\u00a0 public static void main(String[] args)\u00a0 \u00a0 \u00a0 throws IOException, ExecutionException, InterruptedException, TimeoutException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 // You need to pass `zone` or `region` parameter relevant to the disk you want to\u00a0 \u00a0 // snapshot, but not both. Pass `zone` parameter for zonal disks and `region` for\u00a0 \u00a0 // regional disks.\u00a0 \u00a0 // Project ID or project number of the Cloud project you want to use.\u00a0 \u00a0 String projectId = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 // Name of the disk you want to create.\u00a0 \u00a0 String diskName = \"YOUR_DISK_NAME\";\u00a0 \u00a0 // Name of the snapshot that you want to create.\u00a0 \u00a0 String snapshotName = \"YOUR_SNAPSHOT_NAME\";\u00a0 \u00a0 // The zone of the source disk from which you create the snapshot (for zonal disks).\u00a0 \u00a0 String zone = \"europe-central2-b\";\u00a0 \u00a0 // The region of the source disk from which you create the snapshot (for regional disks).\u00a0 \u00a0 String region = \"your-disk-region\";\u00a0 \u00a0 // The Cloud Storage multi-region or the Cloud Storage region where you\u00a0 \u00a0 // want to store your snapshot.\u00a0 \u00a0 // You can specify only one storage location. Available locations:\u00a0 \u00a0 // https://cloud.google.com/storage/docs/locations#available-locations\u00a0 \u00a0 String location = \"europe-central2\";\u00a0 \u00a0 // Project ID or project number of the Cloud project that\u00a0 \u00a0 // hosts the disk you want to snapshot. If not provided, the value will be defaulted\u00a0 \u00a0 // to 'projectId' value.\u00a0 \u00a0 String diskProjectId = \"YOUR_DISK_PROJECT_ID\";\u00a0 \u00a0 createSnapshot(projectId, diskName, snapshotName, zone, region, location, diskProjectId);\u00a0 }\u00a0 // Creates a snapshot of a disk.\u00a0 public static void createSnapshot(String projectId, String diskName, String snapshotName,\u00a0 \u00a0 \u00a0 String zone, String region, String location, String diskProjectId)\u00a0 \u00a0 \u00a0 throws IOException, ExecutionException, InterruptedException, TimeoutException {\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the `snapshotsClient.close()` method on the client to safely\u00a0 \u00a0 // clean up any remaining background resources.\u00a0 \u00a0 try (SnapshotsClient snapshotsClient = SnapshotsClient.create()) {\u00a0 \u00a0 \u00a0 if (zone.isEmpty() && region.isEmpty()) {\u00a0 \u00a0 \u00a0 \u00a0 throw new Error(\"You need to specify 'zone' or 'region' for this function to work\");\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 if (!zone.isEmpty() && !region.isEmpty()) {\u00a0 \u00a0 \u00a0 \u00a0 throw new Error(\"You can't set both 'zone' and 'region' parameters\");\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 // If Disk's project id is not specified, then the projectId parameter will be used.\u00a0 \u00a0 \u00a0 if (diskProjectId.isEmpty()) {\u00a0 \u00a0 \u00a0 \u00a0 diskProjectId = projectId;\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 // If zone is not empty, use the DisksClient to create a disk.\u00a0 \u00a0 \u00a0 // Else, use the RegionDisksClient.\u00a0 \u00a0 \u00a0 Disk disk;\u00a0 \u00a0 \u00a0 if (!zone.isEmpty()) {\u00a0 \u00a0 \u00a0 \u00a0 DisksClient disksClient = DisksClient.create();\u00a0 \u00a0 \u00a0 \u00a0 disk = disksClient.get(projectId, zone, diskName);\u00a0 \u00a0 \u00a0 } else {\u00a0 \u00a0 \u00a0 \u00a0 RegionDisksClient regionDisksClient = RegionDisksClient.create();\u00a0 \u00a0 \u00a0 \u00a0 disk = regionDisksClient.get(diskProjectId, region, diskName);\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 // Set the snapshot properties.\u00a0 \u00a0 \u00a0 Snapshot snapshotResource;\u00a0 \u00a0 \u00a0 if (!location.isEmpty()) {\u00a0 \u00a0 \u00a0 \u00a0 snapshotResource = Snapshot.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setName(snapshotName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setSourceDisk(disk.getSelfLink())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addStorageLocations(location)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 } else {\u00a0 \u00a0 \u00a0 \u00a0 snapshotResource = Snapshot.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setName(snapshotName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setSourceDisk(disk.getSelfLink())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 // Wait for the operation to complete.\u00a0 \u00a0 \u00a0 Operation operation = snapshotsClient.insertAsync(projectId, snapshotResource)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .get(3, TimeUnit.MINUTES);\u00a0 \u00a0 \u00a0 if (operation.hasError()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Snapshot creation failed!\" + operation);\u00a0 \u00a0 \u00a0 \u00a0 return;\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 // Retrieve the created snapshot.\u00a0 \u00a0 \u00a0 Snapshot snapshot = snapshotsClient.get(projectId, snapshotName);\u00a0 \u00a0 \u00a0 System.out.printf(\"Snapshot created: %s\", snapshot.getName());\u00a0 \u00a0 }\u00a0 }}\n```\n### Node.js\nBefore trying this sample, follow the setup instructions in the\n [Compute Engine quickstart using client libraries](/compute/docs/api/libraries) \n.\nTo authenticate to Compute Engine, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/compute/snapshots/createSnapshot.js) \n```\n/**\u00a0* TODO(developer): Uncomment and replace these variables before running the sample.\u00a0*/// const projectId = 'YOUR_PROJECT_ID';// const diskName = 'YOUR_DISK_NAME';// const snapshotName = 'YOUR_SNAPSHOT_NAME';// const zone = 'europe-central2-b';// const region = '';// const location = 'europe-central2';// let diskProjectId = 'YOUR_DISK_PROJECT_ID';const compute = require('@google-cloud/compute');async function createSnapshot() {\u00a0 const snapshotsClient = new compute.SnapshotsClient();\u00a0 let disk;\u00a0 if (!zone && !region) {\u00a0 \u00a0 throw new Error(\u00a0 \u00a0 \u00a0 'You need to specify `zone` or `region` for this function to work.'\u00a0 \u00a0 );\u00a0 }\u00a0 if (zone && region) {\u00a0 \u00a0 throw new Error(\"You can't set both `zone` and `region` parameters\");\u00a0 }\u00a0 if (!diskProjectId) {\u00a0 \u00a0 diskProjectId = projectId;\u00a0 }\u00a0 if (zone) {\u00a0 \u00a0 const disksClient = new compute.DisksClient();\u00a0 \u00a0 [disk] = await disksClient.get({\u00a0 \u00a0 \u00a0 project: diskProjectId,\u00a0 \u00a0 \u00a0 zone,\u00a0 \u00a0 \u00a0 disk: diskName,\u00a0 \u00a0 });\u00a0 } else {\u00a0 \u00a0 const regionDisksClient = new compute.RegionDisksClient();\u00a0 \u00a0 [disk] = await regionDisksClient.get({\u00a0 \u00a0 \u00a0 project: diskProjectId,\u00a0 \u00a0 \u00a0 region,\u00a0 \u00a0 \u00a0 disk: diskName,\u00a0 \u00a0 });\u00a0 }\u00a0 const snapshotResource = {\u00a0 \u00a0 name: snapshotName,\u00a0 \u00a0 sourceDisk: disk.selfLink,\u00a0 };\u00a0 if (location) {\u00a0 \u00a0 snapshotResource.storageLocations = [location];\u00a0 }\u00a0 const [response] = await snapshotsClient.insert({\u00a0 \u00a0 project: projectId,\u00a0 \u00a0 snapshotResource,\u00a0 });\u00a0 let operation = response.latestResponse;\u00a0 const operationsClient = new compute.GlobalOperationsClient();\u00a0 // Wait for the create snapshot operation to complete.\u00a0 while (operation.status !== 'DONE') {\u00a0 \u00a0 [operation] = await operationsClient.wait({\u00a0 \u00a0 \u00a0 operation: operation.name,\u00a0 \u00a0 \u00a0 project: projectId,\u00a0 \u00a0 });\u00a0 }\u00a0 console.log('Snapshot created.');}createSnapshot();\n```\n### Python\nBefore trying this sample, follow the setup instructions in the\n [Compute Engine quickstart using client libraries](/compute/docs/api/libraries) \n.\nTo authenticate to Compute Engine, set up Application Default Credentials. For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/compute/client_library/snippets/snapshots/create.py) \n```\nfrom __future__ import annotationsimport sysfrom typing import Anyfrom google.api_core.extended_operation import ExtendedOperationfrom google.cloud import compute_v1def wait_for_extended_operation(\u00a0 \u00a0 operation: ExtendedOperation, verbose_name: str = \"operation\", timeout: int = 300) -> Any:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Waits for the extended (long-running) operation to complete.\u00a0 \u00a0 If the operation is successful, it will return its result.\u00a0 \u00a0 If the operation ends with an error, an exception will be raised.\u00a0 \u00a0 If there were any warnings during the execution of the operation\u00a0 \u00a0 they will be printed to sys.stderr.\u00a0 \u00a0 Args:\u00a0 \u00a0 \u00a0 \u00a0 operation: a long-running operation you want to wait on.\u00a0 \u00a0 \u00a0 \u00a0 verbose_name: (optional) a more verbose name of the operation,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 used only during error and warning reporting.\u00a0 \u00a0 \u00a0 \u00a0 timeout: how long (in seconds) to wait for operation to finish.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If None, wait indefinitely.\u00a0 \u00a0 Returns:\u00a0 \u00a0 \u00a0 \u00a0 Whatever the operation.result() returns.\u00a0 \u00a0 Raises:\u00a0 \u00a0 \u00a0 \u00a0 This method will raise the exception received from `operation.exception()`\u00a0 \u00a0 \u00a0 \u00a0 or RuntimeError if there is no exception set, but there is an `error_code`\u00a0 \u00a0 \u00a0 \u00a0 set for the `operation`.\u00a0 \u00a0 \u00a0 \u00a0 In case of an operation taking longer than `timeout` seconds to complete,\u00a0 \u00a0 \u00a0 \u00a0 a `concurrent.futures.TimeoutError` will be raised.\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 result = operation.result(timeout=timeout)\u00a0 \u00a0 if operation.error_code:\u00a0 \u00a0 \u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 f\"Error during {verbose_name}: [Code: {operation.error_code}]: {operation.error_message}\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 file=sys.stderr,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 flush=True,\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Operation ID: {operation.name}\", file=sys.stderr, flush=True)\u00a0 \u00a0 \u00a0 \u00a0 raise operation.exception() or RuntimeError(operation.error_message)\u00a0 \u00a0 if operation.warnings:\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Warnings during {verbose_name}:\\n\", file=sys.stderr, flush=True)\u00a0 \u00a0 \u00a0 \u00a0 for warning in operation.warnings:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(f\" - {warning.code}: {warning.message}\", file=sys.stderr, flush=True)\u00a0 \u00a0 return resultdef create_snapshot(\u00a0 \u00a0 project_id: str,\u00a0 \u00a0 disk_name: str,\u00a0 \u00a0 snapshot_name: str,\u00a0 \u00a0 *,\u00a0 \u00a0 zone: str | None = None,\u00a0 \u00a0 region: str | None = None,\u00a0 \u00a0 location: str | None = None,\u00a0 \u00a0 disk_project_id: str | None = None,) -> compute_v1.Snapshot:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Create a snapshot of a disk.\u00a0 \u00a0 You need to pass `zone` or `region` parameter relevant to the disk you want to\u00a0 \u00a0 snapshot, but not both. Pass `zone` parameter for zonal disks and `region` for\u00a0 \u00a0 regional disks.\u00a0 \u00a0 Args:\u00a0 \u00a0 \u00a0 \u00a0 project_id: project ID or project number of the Cloud project you want\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 to use to store the snapshot.\u00a0 \u00a0 \u00a0 \u00a0 disk_name: name of the disk you want to snapshot.\u00a0 \u00a0 \u00a0 \u00a0 snapshot_name: name of the snapshot to be created.\u00a0 \u00a0 \u00a0 \u00a0 zone: name of the zone in which is the disk you want to snapshot (for zonal disks).\u00a0 \u00a0 \u00a0 \u00a0 region: name of the region in which is the disk you want to snapshot (for regional disks).\u00a0 \u00a0 \u00a0 \u00a0 location: The Cloud Storage multi-region or the Cloud Storage region where you\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 want to store your snapshot.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 You can specify only one storage location. Available locations:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 https://cloud.google.com/storage/docs/locations#available-locations\u00a0 \u00a0 \u00a0 \u00a0 disk_project_id: project ID or project number of the Cloud project that\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 hosts the disk you want to snapshot. If not provided, will look for\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 the disk in the `project_id` project.\u00a0 \u00a0 Returns:\u00a0 \u00a0 \u00a0 \u00a0 The new snapshot instance.\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 if zone is None and region is None:\u00a0 \u00a0 \u00a0 \u00a0 raise RuntimeError(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"You need to specify `zone` or `region` for this function to work.\"\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 if zone is not None and region is not None:\u00a0 \u00a0 \u00a0 \u00a0 raise RuntimeError(\"You can't set both `zone` and `region` parameters.\")\u00a0 \u00a0 if disk_project_id is None:\u00a0 \u00a0 \u00a0 \u00a0 disk_project_id = project_id\u00a0 \u00a0 if zone is not None:\u00a0 \u00a0 \u00a0 \u00a0 disk_client = compute_v1.DisksClient()\u00a0 \u00a0 \u00a0 \u00a0 disk = disk_client.get(project=disk_project_id, zone=zone, disk=disk_name)\u00a0 \u00a0 else:\u00a0 \u00a0 \u00a0 \u00a0 regio_disk_client = compute_v1.RegionDisksClient()\u00a0 \u00a0 \u00a0 \u00a0 disk = regio_disk_client.get(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 project=disk_project_id, region=region, disk=disk_name\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 snapshot = compute_v1.Snapshot()\u00a0 \u00a0 snapshot.source_disk = disk.self_link\u00a0 \u00a0 snapshot.name = snapshot_name\u00a0 \u00a0 if location:\u00a0 \u00a0 \u00a0 \u00a0 snapshot.storage_locations = [location]\u00a0 \u00a0 snapshot_client = compute_v1.SnapshotsClient()\u00a0 \u00a0 operation = snapshot_client.insert(project=project_id, snapshot_resource=snapshot)\u00a0 \u00a0 wait_for_extended_operation(operation, \"snapshot creation\")\u00a0 \u00a0 return snapshot_client.get(project=project_id, snapshot=snapshot_name)\n```\n**Caution:** If you attempt to create a snapshot and the snapshotting process fails, you won't be able to delete the original persistent disk until you have cleaned up the failed snapshot. This failsafe helps to prevent the accidental deletion of source data in the event of an unsuccessful backup.\n## Schedule a recurring backup\nWhen you create a snapshot schedule, you create a [resource policy](/compute/docs/reference/rest/v1/resourcePolicies) that you can apply to one or more persistent disks. You can create snapshot schedules in the following ways:\n- [Create a snapshot schedule](#create_schedule) and then [attach it to an existing persistentdisk](#attach_schedule) .\n- [Create a new persistent disk with a snapshot schedule](/compute/docs/disks/scheduled-snapshots#create_disk_add_policy) .\nA snapshot schedule includes the following properties:\n- Schedule name\n- Schedule description\n- Snapshot frequency (hourly, daily, weekly)\n- Snapshot start time\n- Region where the snapshot schedule is available\n- Source disk deletion policy for handling auto-generated snapshots if the source disk is deleted\n- Retention policy to define how long to keep snapshots that are generated from the snapshot schedule\n### Restrictions\n- A persistent disk can have at most 10 snapshot schedules attached to it at a time.\n- You cannot create archive snapshots using a snapshot schedule.\n- You can create a maximum of 1,000 in-use snapshot schedules per region.\n- Snapshot schedules apply only in the project that they were created in. Snapshot schedules cannot be used in other projects or organizations.\n- You might need to request an increase in [resource quota](/compute/quotas) through the console if you require additional resources in your region.\n- You cannot delete a snapshot schedule if it is attached to a disk. You must [detach the schedule](/compute/docs/disks/scheduled-snapshots#change_snapshot_schedule) from all disks, then delete the schedule.\n- You can update an existing snapshot schedule to change the description, schedule, and labels. To update other values for a snapshot schedule, you must delete the snapshot schedule and create a new one.\n- For persistent disks that use a [customer-supplied encryption key(CSEK)](/security/encryption/customer-supplied-encryption-keys) , you can't create snapshot schedules.\n- For persistent disks that use a [customer-managed encryption key(CMEK)](/kms/docs/cmek) , all snapshots created with a snapshot schedule are automatically encrypted with the same key.\n### Create a schedule\nCreate a snapshot schedule for your persistent disks using the Google Cloud console, Google Cloud CLI, or the Compute Engine API. You must create your snapshot schedule in the same region where your persistent disk resides. For example, if your persistent disk resides in zone `us-west1-a` , your snapshot schedule must reside in the `us-west1` region. For more information, see [Choose a storage location](/compute/docs/disks/snapshots#selecting_a_storage_location) .\n**Note:** If you use the gcloud CLI or the Google Cloud console, you must always set a retention policy when creating a snapshot schedule. If you make a request to the API directly, you can omit this field and your snapshots will be retained indefinitely.\n- In the Google Cloud console, go to the **VM instances** page. [  Go to VM instances](https://console.cloud.google.com/compute/instances?walkthrough_id=compute--storage--create-snapshot-schedule)  school The remaining steps will appear automatically in   the Google Cloud console.\n- Select the project that contains your VM instances.\n- In the **Name** column, click the name of the VM that has the persistent disk to create a  snapshot schedule for.\n- In,  click the name of the **Boot disk** or the **Additional disk** to create a snapshot  schedule for.\n- Clickedit **Edit** . You might need to  click themore_vert **More actions** menu and thenedit **Edit** .\n- In **Snapshot schedule** , choose **Create a schedule** .\n- In **Name** , enter one of the following names for the snapshot schedule:- `boot-disk-snapshot-schedule`\n- `attached-persistent-disk-snapshot-schedule`\n- In the **Location** section, [choose your snapshot   storage location](/compute/docs/disks/snapshots#selecting_a_storage_location) .   The predefined or customized default location defined in your snapshot settings is   automatically selected. Optionally, you can override the snapshot settings and store your   snapshots in a custom storage location by doing the following:- Choose the type of storage location that you want for your snapshot.- Choose **Multi-regional** for higher availability at a higher cost.\n- Choose **Regional snapshots** for more control over the physical location of your data at a lower cost.\n- In the **Select location** field, select the specific region or multi-region that    you want to use. To use the region or multi-region that is closest to your    source disk, select **Based on disk's location** .- To finish creating the snapshot schedule, click **Create** .\n- To attach this snapshot schedule to the persistent disk, click **Save** .To create a snapshot schedule for persistent disks, use the [compute resource-policies create snapshot-schedule](/sdk/gcloud/reference/compute/resource-policies/create/snapshot-schedule) `gcloud` command. Set your schedule frequency to hourly, daily, or weekly.\n```\n\u00a0 gcloud compute resource-policies create snapshot-schedule [SCHEDULE_NAME] \\\u00a0 \u00a0 \u00a0 --description \"[SCHEDULE_DESCRIPTION]\" \\\u00a0 \u00a0 \u00a0 --max-retention-days [MAX_RETENTION_DAYS] \\\u00a0 \u00a0 \u00a0 --start-time [START_TIME] \\\u00a0 \u00a0 \u00a0 --hourly-schedule [SNAPSHOT_INTERVAL] \\\u00a0 \u00a0 \u00a0 --daily-schedule \\\u00a0 \u00a0 \u00a0 --weekly-schedule [SNAPSHOT_INTERVAL] \\\u00a0 \u00a0 \u00a0 --weekly-schedule-from-file [FILE_NAME] \\\u00a0 \u00a0 \u00a0 --on-source-disk-delete [DELETION_OPTION]\n```\nwhere:- `[SCHEDULE_NAME]`is the name of the new snapshot schedule.\n- `\"[SCHEDULE_DESCRIPTION]\"`is a description of the snapshot schedule. Use quotes around your description.\n- `[MAX_RETENTION_DAYS]`is the number of days to retain the snapshot. For example, setting`3`would mean that snapshots are retained for 3 days before they are deleted. You must set a retention policy of at least 1 day.\n- `[START_TIME]`is the UTC start time. The time must start on the hour. For example:- 2:00 PM PST is`22:00`.\n- If you set a start time of`22:13`, you will receive an error.\n- `[SNAPSHOT_INTERVAL]` defines the interval at which you want snapshotting to occur. Set the hourly schedule using an integer between 1 and 23. Choose an hourly number that is evenly divided into 24. For example, setting `--hourly-schedule` to 12, means the snapshot is generated every 12 hours. For a weekly schedule define the days you want the snapshotting to occur. You must spell out the week days, they are not case-sensitive. The snapshot frequency flags `hourly-schedule` , `daily-schedule` , and `weekly-schedule` are mutually-exclusive. You must pick one for your snapshot schedule. **Note:** If you want to specify a weekly schedule with different days of the week and with different start times, use `--weekly-schedule-from-file` instead.\n- `[FILE_NAME]` is the file name that contains the weekly snapshot schedule, if you choose to provide the schedule in this format. Note that you can specify weekly schedules on different days of the week and at different times using a file (but you cannot specify multiple weekly schedules directly on the command-line). For example, your file might specify a snapshot schedule on Monday and Wednesday: `[{\"day\": \"MONDAY\", \"startTime\": \"04:00\"}, {\"day\": \"WEDNESDAY\", \"startTime\": \"02:00\"}]` If you include a start time in your file, you do not need to set the `--start-time` flag. The schedule uses the UTC time standard.\n- `[DELETION_OPTION]` determines what happens to your snapshots if the source disk is deleted. Choose either the default `keep-auto-snapshots` by omitting this flag, or use `apply-retention-policy` to apply a retention policy.\nThese are additional examples for setting up a snapshot schedule. In all the following examples:- The disk deletion rule is included; the`--on-source-disk-delete`flag is set to the default of`keep-auto-snapshots`to permanently keep all auto-generated snapshots. The alternative is to set this flag to`apply-retention-policy`to use your snapshot retention policy.\n- The storage location is set the`US`so all generated snapshots will be stored in the US multi-region.\n- The labels`env=dev`and`media=images`are applied to all generated snapshots.\n- The retention policy is set to 10 days.\n **Hourly schedule:** In this example, the snapshot schedule starts at 22:00 UTC and occurs every 4 hours.\n```\n\u00a0 gcloud compute resource-policies create snapshot-schedule SCHEDULE_NAME \\\u00a0 \u00a0 \u00a0 --description \"MY HOURLY SNAPSHOT SCHEDULE\" \\\u00a0 \u00a0 \u00a0 --max-retention-days 10 \\\u00a0 \u00a0 \u00a0 --start-time 22:00 \\\u00a0 \u00a0 \u00a0 --hourly-schedule 4 \\\u00a0 \u00a0 \u00a0 --region us-west1 \\\u00a0 \u00a0 \u00a0 --on-source-disk-delete keep-auto-snapshots \\\u00a0 \u00a0 \u00a0 --snapshot-labels env=dev,media=images \\\u00a0 \u00a0 \u00a0 --storage-location US\n```\n **Daily schedule:** In this example, the snapshot schedule starts at 22:00 UTC and occurs every day at the same time. The `--daily-schedule` flag must be present, but not set to anything.\n```\ngcloud compute resource-policies create snapshot-schedule SCHEDULE_NAME \\\u00a0 \u00a0 --description \"MY DAILY SNAPSHOT SCHEDULE\" \\\u00a0 \u00a0 --max-retention-days 10 \\\u00a0 \u00a0 --start-time 22:00 \\\u00a0 \u00a0 --daily-schedule \\\u00a0 \u00a0 --region us-west1 \\\u00a0 \u00a0 --on-source-disk-delete keep-auto-snapshots \\\u00a0 \u00a0 --snapshot-labels env=dev,media=images \\\u00a0 \u00a0 --storage-location US\n```\n **Weekly schedule:** In this example, the snapshot schedule starts at 22:00 UTC and occurs every week on Tuesday and Thursday.\n```\ngcloud compute resource-policies create snapshot-schedule SCHEDULE_NAME \\\u00a0 \u00a0 --description \"MY WEEKLY SNAPSHOT SCHEDULE\" \\\u00a0 \u00a0 --max-retention-days 10 \\\u00a0 \u00a0 --start-time 22:00 \\\u00a0 \u00a0 --weekly-schedule tuesday,thursday \\\u00a0 \u00a0 --region us-west1 \\\u00a0 \u00a0 --on-source-disk-delete keep-auto-snapshots \\\u00a0 \u00a0 --snapshot-labels env=dev,media=images \\\u00a0 \u00a0 --storage-location US\n```\nIn the API, construct a `POST` request to [resourcePolicies.insert](/compute/docs/reference/rest/v1/resourcePolicies/insert) to create a snapshot schedule. At the minimum, you must include the snapshot schedule name, snapshot storage regional location, and snapshot frequency.\nBy default, the `onSourceDiskDelete` parameter is set to `keepAutoSnapshots` . This means that if the source disk is deleted, the auto-generated snapshot for that disk is retained indefinitely. Alternatively, you can set the flag to `applyRetentionPolicy` to apply your retention policy.\nThe following example sets a daily snapshot schedule that starts at 12:00 UTC and repeats every day. The example also sets a retention policy of 5 days; after 5 days, snapshots are automatically removed.\nYou can also include [snapshot locality options](/compute/docs/disks/create-snapshots#selecting_a_storage_location) and [snapshot labels](/compute/docs/labeling-resources#adding_or_updating_labels_to_existing_resources) in your request to ensure your snapshots are stored in the location of your choice.\n```\nPOST https://compute.googleapis.com/compute/v1/projects/[PROJECT_ID]/regions/[REGION]/resourcePolicies{\u00a0\"name\": \"[SCHEDULE_NAME]\",\u00a0\"description\": \"[SCHEDULE_DESCRIPTION]\",\u00a0\"snapshotSchedulePolicy\": {\u00a0 \u00a0\"schedule\": {\u00a0 \u00a0 \u00a0\"dailySchedule\": {\u00a0 \u00a0 \u00a0 \u00a0\"startTime\": \"12:00\",\u00a0 \u00a0 \u00a0 \u00a0\"daysInCycle\": \"1\"\u00a0 \u00a0 \u00a0}\u00a0 \u00a0},\u00a0 \u00a0\"retentionPolicy\": {\u00a0 \u00a0 \u00a0\"maxRetentionDays\": \"5\"\u00a0 \u00a0},\u00a0 \u00a0\"snapshotProperties\": {\u00a0 \u00a0 \u00a0\"guestFlush\": \"False\",\u00a0 \u00a0 \u00a0\"labels\": {\u00a0 \u00a0 \u00a0 \u00a0\"env\": \"dev\",\u00a0 \u00a0 \u00a0 \u00a0\"media\": \"images\"\u00a0 \u00a0 \u00a0},\u00a0 \u00a0 \u00a0\"storageLocations\": [\"US\"]\u00a0 \u00a0}\u00a0}}\n```\nwhere:- `[PROJECT_ID]`is the project name.\n- `[REGION]`is the location of the snapshot schedule resource policy.\n- `[SCHEDULE_DESCRIPTION]`is the description of the snapshot schedule.\n- `[SCHEDULE_NAME]`is the name of the snapshot schedule.\nSimilarly, you can create a weekly or monthly schedule. Review the [API reference](/compute/docs/reference/rest/v1/resourcePolicies/insert) for details specific to setting a weekly or monthly schedule.\nFor example, the following request creates a weekly schedule that runs on Tuesday and Thursday, at 9:00 and 2:00 respectively.\n```\nPOST https://compute.googleapis.com/compute/v1/projects/[PROJECT_ID]/regions/[REGION]/resourcePolicies{\u00a0\"name\": \"[SCHEDULE_NAME]\",\u00a0\"description\": \"[SCHEDULE_DESCRIPTION]\",\u00a0\"snapshotSchedulePolicy\": {\u00a0 \u00a0\"schedule\": {\u00a0 \u00a0 \u00a0\"weeklySchedule\": {\u00a0 \u00a0 \u00a0 \u00a0\"dayOfWeeks\": [\u00a0 \u00a0 \u00a0 \u00a0{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"day\": \"Monday\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"startTime\": \"9:00\"\u00a0 \u00a0 \u00a0 \u00a0},\u00a0 \u00a0 \u00a0 \u00a0{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"day\": \"Thursday\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"startTime\": \"2:00\"\u00a0 \u00a0 \u00a0 \u00a0}\u00a0 \u00a0 \u00a0 \u00a0]\u00a0 \u00a0 \u00a0}\u00a0 \u00a0},\u00a0 \"retentionPolicy\": {\u00a0 \u00a0 \"maxRetentionDays\": \"5\"\u00a0 },\u00a0 \"snapshotProperties\": {\u00a0 \u00a0 \"guestFlush\": \"False\",\u00a0 \u00a0 \"labels\": {\u00a0 \u00a0 \u00a0 \"production\": \"webserver\"\u00a0 \u00a0 },\u00a0 \u00a0 \"storageLocations\": [\"US\"]\u00a0 }\u00a0}}\n```\n### Attach a snapshot schedule to a disk\nOnce you have a schedule, attach it to an existing disk. Use the console, `gcloud` command, or the Compute Engine API method.\nAttach a snapshot schedule to an existing disk.- In the Google Cloud console, go to the **Disks** page. [Go to the Disks page](https://console.cloud.google.com/compute/disks) \n- Select the name of the disk to which you want to attach a snapshot schedule. This opens the **Manage disk** page.\n- On the **Manage disk** page, hover and click themore_vert **More actions** menu and selectedit **Edit** .\n- Use the **Snapshot schedule** drop-down menu to add the schedule to the disk. Or create a new schedule.\n- If you created a new schedule, click **Create** .\n- Click **Save** to complete the task.\nTo attach a snapshot schedule to a disk, use the [disks add-resource-policies](/sdk/gcloud/reference/compute/disks/add-resource-policies) `gcloud` command.\n```\ngcloud compute disks add-resource-policies [DISK_NAME] \\\u00a0 \u00a0 --resource-policies [SCHEDULE_NAME] \\\u00a0 \u00a0 --zone [ZONE]\n```\nwhere:- `[DISK_NAME]`is the name of the existing disk.\n- `[SCHEDULE_NAME]`is the name of the snapshot schedule.\n- `[ZONE]`is the location of your disk.\nIn the API, construct a `POST` request to [disks.addResourcePolicies](/compute/docs/reference/rest/v1/disks/addResourcePolicies) to attach a snapshot schedule to an existing disk.\n```\nPOST https://compute.googleapis.com/compute/v1/projects/[PROJECT_ID]/zones/[ZONE]/disks/[DISK_NAME]/addResourcePolicies{\u00a0 \"resourcePolicies\": [\u00a0 \u00a0 \"regions/[REGION]/resourcePolicies/[SCHEDULE_NAME]\"\u00a0 ]}\n```\nwhere:- `[PROJECT_ID]`is the project name.\n- `[ZONE]`is the location of the disk.\n- `[REGION]`is the location of the snapshot schedule.\n- `[DISK_NAME]`is the name of the disk.\n- `[SCHEDULE_NAME]`is the name of the snapshot schedule in that region you are applying to this disk.## Restore data from a snapshot\nIf you backed up a boot or non-boot disk with a snapshot, you can create a new disk based on the snapshot.\n### Restrictions\n- The new disk must be at least the same size as the original source disk for the snapshot. If you create a disk that is larger than the original source disk for the snapshot, you must [resize the filesystem on that persistent disk](/compute/docs/disks/resize-persistent-disk) to include the additional disk space. Depending on your operating system and file system type, you might need to use a different file system resizing tool. For more information, see your operating system documentation.\n### Create a disk from a snapshot and attach it to a VM\n**Note:** You must create the disk in the same zone as your instance.- In the Google Cloud console, go to the **Snapshots** page. [Go to Snapshots](https://console.cloud.google.com/compute/snapshots) \n- Find the name of the snapshot that you want to restore.\n- Go to the **Disks** page. [Go to the Disks page](https://console.cloud.google.com/compute/disks) \n- Click **Create new disk** .\n- Specify the following configuration parameters:- A name for the disk.\n- A type for the disk.\n- Optionally, you can override the default region and zone selection. You can select any region and zone, regardless of the storage location of the source snapshot.\n- Under **Source type** , click **Snapshot** .\n- Select the name of the snapshot to restore.\n- Select the size of the new disk, in gigabytes. This number must be equal to or larger than the original source disk for the snapshot.\n- Click **Create** to create the disk.\nYou can then attach the new disk to an existing instance.- Go to the **VM instances** page. [Go to the VM instances page](https://console.cloud.google.com/compute/instances) \n- Click the name of the instance where you want to restore your non-boot disk.\n- At the top of the instance details page, click **Edit** .\n- Under **Additional disks** , click **Attach existing disk** .\n- Select the name of the new disk made from your snapshot.\n- Click **Done** to attach the disk.\n- At the bottom of the instance details page, click **Save** to apply your changes to the instance.\n- Use the [gcloud compute snapshots list command](/sdk/gcloud/reference/compute/snapshots/list) command to find the name of the snapshot you want to restore:```\ngcloud compute snapshots list\n```\n- Use the [gcloud compute snapshots describe command](/sdk/gcloud/reference/compute/snapshots/describe) command to find the size of the snapshot you want to restore:```\ngcloud compute snapshots describe SNAPSHOT_NAME\n```Replace with the name of the snapshot being restored.\n- Use the [gcloud compute disks create command](/sdk/gcloud/reference/compute/disks/create) command to create a new [regional](/compute/docs/disks#repds) or [zonal](/compute/docs/disks#pdspecs) disk from your snapshot. If you need an SSD persistent disk for additional throughput or IOPS, include the `--type` flag and specify `pd-ssd` .```\ngcloud compute disks create DISK_NAME \\\u00a0 \u00a0 --size=DISK_SIZE \\\u00a0 \u00a0 --source-snapshot=SNAPSHOT_NAME \\\u00a0 \u00a0 --type=DISK_TYPE\n```Replace the following:- : the name of the new disk.\n- : The size of the new disk, in gigabytes. This number must be equal to or larger than the original source disk for the snapshot.\n- : the name of the snapshot being restored.\n- : full or partial URL for the [type](/compute/docs/disks#disk-types) of the disk. For example,`https://www.googleapis.com/compute/v1/projects/` `` `/zones/` `` `/diskTypes/pd-ssd`.\n- Attach the new disk to an existing instance by using the [gcloud compute instances attach-diskcommand](/sdk/gcloud/reference/compute/instances/attach-disk) :```\ngcloud compute instances attach-disk INSTANCE_NAME \\\u00a0 \u00a0 --disk DISK_NAME\n```Replace the following:- is the name of the instance.\n- is the name of the disk made from your snapshot.- Construct a `GET` request to [snapshots.list](/compute/docs/reference/rest/v1/snapshots/list) to display the list of snapshots in your project.GET https://compute.googleapis.com/compute/v1/projects/ /global/snapshotsReplace with your project ID.\n- Construct a `POST` request to create a zonal disk using the [disks.insert](/compute/docs/reference/rest/v1/disks/insert) method. Include the `name` , `sizeGb` , and `type` properties. To restore a disk using a snapshot, you must include the `sourceSnapshot` property.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/disks{\u00a0\"name\": \"DISK_NAME\",\u00a0\"sizeGb\": \"DISK_SIZE\",\u00a0\"type\": \"zones/ZONE/diskTypes/DISK_TYPE\"\u00a0\"sourceSnapshot\": \"SNAPSHOT_NAME\"}\n```Replace the following:- : your project ID.\n- the zone where your instance and new disk are located.\n- : the name of the new disk.\n- : the size of the new disk, in gigabytes. This number must be equal to or larger than the original source disk for the snapshot.\n- : full or partial URL for the [type](/compute/docs/disks#disk-types) of the disk. For example`https://www.googleapis.com/compute/v1/projects/` `` `/zones/` `` `/diskTypes/pd-ssd`.\n- : the source snapshot for the disk you are restoring.\n- You can then attach the new disk to an existing instance by constructing a `POST` request to the [instances.attachDiskmethod](/compute/docs/reference/rest/v1/instances/attachDisk) , and including the URL to the zonal disk that you just created from your snapshot.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/INSTANCE_NAME/attachDisk{\u00a0\"source\": \"/compute/v1/projects/PROJECT_ID/zones/ZONE/disks/DISK_NAME\"}\n```Replace the following:- is your project ID.\n- is the zone where your instance and new disk are located.\n- is the name of the instance where you are adding the new disk.\n- is the name of the new disk.\n### GoBefore trying this sample, follow the Go setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Go API reference documentation](/go/docs/reference/cloud.google.com/go/aiplatform/latest/apiv1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/compute/disks/create_disk_from_snapshot.go) \n```\nimport (\u00a0 \u00a0 \u00a0 \u00a0 \"context\"\u00a0 \u00a0 \u00a0 \u00a0 \"fmt\"\u00a0 \u00a0 \u00a0 \u00a0 \"io\"\u00a0 \u00a0 \u00a0 \u00a0 compute \"cloud.google.com/go/compute/apiv1\"\u00a0 \u00a0 \u00a0 \u00a0 computepb \"google.golang.org/genproto/googleapis/cloud/compute/v1\"\u00a0 \u00a0 \u00a0 \u00a0 \"google.golang.org/protobuf/proto\")// createDiskFromSnapshot creates a new disk in a project in given zone.func createDiskFromSnapshot(\u00a0 \u00a0 \u00a0 \u00a0 w io.Writer,\u00a0 \u00a0 \u00a0 \u00a0 projectID, zone, diskName, diskType, snapshotLink string,\u00a0 \u00a0 \u00a0 \u00a0 diskSizeGb int64,) error {\u00a0 \u00a0 \u00a0 \u00a0 // projectID := \"your_project_id\"\u00a0 \u00a0 \u00a0 \u00a0 // zone := \"us-west3-b\" // should match diskType below\u00a0 \u00a0 \u00a0 \u00a0 // diskName := \"your_disk_name\"\u00a0 \u00a0 \u00a0 \u00a0 // diskType := \"zones/us-west3-b/diskTypes/pd-ssd\"\u00a0 \u00a0 \u00a0 \u00a0 // snapshotLink := \"projects/your_project_id/global/snapshots/snapshot_name\"\u00a0 \u00a0 \u00a0 \u00a0 // diskSizeGb := 120\u00a0 \u00a0 \u00a0 \u00a0 ctx := context.Background()\u00a0 \u00a0 \u00a0 \u00a0 disksClient, err := compute.NewDisksRESTClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"NewDisksRESTClient: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 defer disksClient.Close()\u00a0 \u00a0 \u00a0 \u00a0 req := &computepb.InsertDiskRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Project: projectID,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Zone: \u00a0 \u00a0zone,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DiskResource: &computepb.Disk{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 proto.String(diskName),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Zone: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 proto.String(zone),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Type: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 proto.String(diskType),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SourceSnapshot: proto.String(snapshotLink),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SizeGb: \u00a0 \u00a0 \u00a0 \u00a0 proto.Int64(diskSizeGb),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 op, err := disksClient.Insert(ctx, req)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"unable to create disk: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 if err = op.Wait(ctx); err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return fmt.Errorf(\"unable to wait for the operation: %w\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Disk created\\n\")\u00a0 \u00a0 \u00a0 \u00a0 return nil}\n```\n### JavaBefore trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/compute/cloud-client/src/main/java/compute/disks/CreateDiskFromSnapshot.java) \n```\nimport com.google.cloud.compute.v1.Disk;import com.google.cloud.compute.v1.DisksClient;import com.google.cloud.compute.v1.InsertDiskRequest;import com.google.cloud.compute.v1.Operation;import java.io.IOException;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;public class CreateDiskFromSnapshot {\u00a0 public static void main(String[] args)\u00a0 \u00a0 \u00a0 throws IOException, ExecutionException, InterruptedException, TimeoutException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 // Project ID or project number of the Cloud project you want to use.\u00a0 \u00a0 String projectId = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 // Name of the zone in which you want to create the disk.\u00a0 \u00a0 String zone = \"europe-central2-b\";\u00a0 \u00a0 // Name of the disk you want to create.\u00a0 \u00a0 String diskName = \"YOUR_DISK_NAME\";\u00a0 \u00a0 // The type of disk you want to create. This value uses the following format:\u00a0 \u00a0 // \"zones/{zone}/diskTypes/(pd-standard|pd-ssd|pd-balanced|pd-extreme)\".\u00a0 \u00a0 // For example: \"zones/us-west3-b/diskTypes/pd-ssd\"\u00a0 \u00a0 String diskType = String.format(\"zones/%s/diskTypes/pd-ssd\", zone);\u00a0 \u00a0 // Size of the new disk in gigabytes.\u00a0 \u00a0 long diskSizeGb = 10;\u00a0 \u00a0 // The full path and name of the snapshot that you want to use as the source for the new disk.\u00a0 \u00a0 // This value uses the following format:\u00a0 \u00a0 // \"projects/{projectName}/global/snapshots/{snapshotName}\"\u00a0 \u00a0 String snapshotLink = String.format(\"projects/%s/global/snapshots/%s\", projectId,\u00a0 \u00a0 \u00a0 \u00a0 \"SNAPSHOT_NAME\");\u00a0 \u00a0 createDiskFromSnapshot(projectId, zone, diskName, diskType, diskSizeGb, snapshotLink);\u00a0 }\u00a0 // Creates a new disk in a project in given zone, using a snapshot.\u00a0 public static void createDiskFromSnapshot(String projectId, String zone, String diskName,\u00a0 \u00a0 \u00a0 String diskType, long diskSizeGb, String snapshotLink)\u00a0 \u00a0 \u00a0 throws IOException, ExecutionException, InterruptedException, TimeoutException {\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the `disksClient.close()` method on the client to safely\u00a0 \u00a0 // clean up any remaining background resources.\u00a0 \u00a0 try (DisksClient disksClient = DisksClient.create()) {\u00a0 \u00a0 \u00a0 // Set the disk properties and the source snapshot.\u00a0 \u00a0 \u00a0 Disk disk = Disk.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setName(diskName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setZone(zone)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setSizeGb(diskSizeGb)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setType(diskType)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setSourceSnapshot(snapshotLink)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // Create the insert disk request.\u00a0 \u00a0 \u00a0 InsertDiskRequest insertDiskRequest = InsertDiskRequest.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setProject(projectId)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setZone(zone)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDiskResource(disk)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // Wait for the create disk operation to complete.\u00a0 \u00a0 \u00a0 Operation response = disksClient.insertAsync(insertDiskRequest)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .get(3, TimeUnit.MINUTES);\u00a0 \u00a0 \u00a0 if (response.hasError()) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.println(\"Disk creation failed!\" + response);\u00a0 \u00a0 \u00a0 \u00a0 return;\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 System.out.println(\"Disk created. Operation Status: \" + response.getStatus());\u00a0 \u00a0 }\u00a0 }}\n```\n### Node.jsBefore trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/compute/disks/createDiskFromSnapshot.js) \n```\n/**\u00a0* TODO(developer): Uncomment and replace these variables before running the sample.\u00a0*/// const projectId = 'YOUR_PROJECT_ID';// const zone = 'europe-central2-b';// const diskName = 'YOUR_DISK_NAME';// const diskType = 'zones/us-west3-b/diskTypes/pd-ssd';// const diskSizeGb = 10;// const snapshotLink = 'projects/project_name/global/snapshots/snapshot_name';const compute = require('@google-cloud/compute');async function createDiskFromSnapshot() {\u00a0 const disksClient = new compute.DisksClient();\u00a0 const [response] = await disksClient.insert({\u00a0 \u00a0 project: projectId,\u00a0 \u00a0 zone,\u00a0 \u00a0 diskResource: {\u00a0 \u00a0 \u00a0 sizeGb: diskSizeGb,\u00a0 \u00a0 \u00a0 name: diskName,\u00a0 \u00a0 \u00a0 zone,\u00a0 \u00a0 \u00a0 type: diskType,\u00a0 \u00a0 \u00a0 sourceSnapshot: snapshotLink,\u00a0 \u00a0 },\u00a0 });\u00a0 let operation = response.latestResponse;\u00a0 const operationsClient = new compute.ZoneOperationsClient();\u00a0 // Wait for the create disk operation to complete.\u00a0 while (operation.status !== 'DONE') {\u00a0 \u00a0 [operation] = await operationsClient.wait({\u00a0 \u00a0 \u00a0 operation: operation.name,\u00a0 \u00a0 \u00a0 project: projectId,\u00a0 \u00a0 \u00a0 zone: operation.zone.split('/').pop(),\u00a0 \u00a0 });\u00a0 }\u00a0 console.log('Disk created.');}createDiskFromSnapshot();\n```\n### PythonTo learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/compute/client_library/snippets/disks/create_from_snapshot.py) \n```\nfrom __future__ import annotationsimport sysfrom typing import Anyfrom google.api_core.extended_operation import ExtendedOperationfrom google.cloud import compute_v1def wait_for_extended_operation(\u00a0 \u00a0 operation: ExtendedOperation, verbose_name: str = \"operation\", timeout: int = 300) -> Any:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Waits for the extended (long-running) operation to complete.\u00a0 \u00a0 If the operation is successful, it will return its result.\u00a0 \u00a0 If the operation ends with an error, an exception will be raised.\u00a0 \u00a0 If there were any warnings during the execution of the operation\u00a0 \u00a0 they will be printed to sys.stderr.\u00a0 \u00a0 Args:\u00a0 \u00a0 \u00a0 \u00a0 operation: a long-running operation you want to wait on.\u00a0 \u00a0 \u00a0 \u00a0 verbose_name: (optional) a more verbose name of the operation,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 used only during error and warning reporting.\u00a0 \u00a0 \u00a0 \u00a0 timeout: how long (in seconds) to wait for operation to finish.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 If None, wait indefinitely.\u00a0 \u00a0 Returns:\u00a0 \u00a0 \u00a0 \u00a0 Whatever the operation.result() returns.\u00a0 \u00a0 Raises:\u00a0 \u00a0 \u00a0 \u00a0 This method will raise the exception received from `operation.exception()`\u00a0 \u00a0 \u00a0 \u00a0 or RuntimeError if there is no exception set, but there is an `error_code`\u00a0 \u00a0 \u00a0 \u00a0 set for the `operation`.\u00a0 \u00a0 \u00a0 \u00a0 In case of an operation taking longer than `timeout` seconds to complete,\u00a0 \u00a0 \u00a0 \u00a0 a `concurrent.futures.TimeoutError` will be raised.\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 result = operation.result(timeout=timeout)\u00a0 \u00a0 if operation.error_code:\u00a0 \u00a0 \u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 f\"Error during {verbose_name}: [Code: {operation.error_code}]: {operation.error_message}\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 file=sys.stderr,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 flush=True,\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Operation ID: {operation.name}\", file=sys.stderr, flush=True)\u00a0 \u00a0 \u00a0 \u00a0 raise operation.exception() or RuntimeError(operation.error_message)\u00a0 \u00a0 if operation.warnings:\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Warnings during {verbose_name}:\\n\", file=sys.stderr, flush=True)\u00a0 \u00a0 \u00a0 \u00a0 for warning in operation.warnings:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(f\" - {warning.code}: {warning.message}\", file=sys.stderr, flush=True)\u00a0 \u00a0 return resultdef create_disk_from_snapshot(\u00a0 \u00a0 project_id: str,\u00a0 \u00a0 zone: str,\u00a0 \u00a0 disk_name: str,\u00a0 \u00a0 disk_type: str,\u00a0 \u00a0 disk_size_gb: int,\u00a0 \u00a0 snapshot_link: str,) -> compute_v1.Disk:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Creates a new disk in a project in given zone.\u00a0 \u00a0 Args:\u00a0 \u00a0 \u00a0 \u00a0 project_id: project ID or project number of the Cloud project you want to use.\u00a0 \u00a0 \u00a0 \u00a0 zone: name of the zone in which you want to create the disk.\u00a0 \u00a0 \u00a0 \u00a0 disk_name: name of the disk you want to create.\u00a0 \u00a0 \u00a0 \u00a0 disk_type: the type of disk you want to create. This value uses the following format:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"zones/{zone}/diskTypes/(pd-standard|pd-ssd|pd-balanced|pd-extreme)\".\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 For example: \"zones/us-west3-b/diskTypes/pd-ssd\"\u00a0 \u00a0 \u00a0 \u00a0 disk_size_gb: size of the new disk in gigabytes\u00a0 \u00a0 \u00a0 \u00a0 snapshot_link: a link to the snapshot you want to use as a source for the new disk.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 This value uses the following format: \"projects/{project_name}/global/snapshots/{snapshot_name}\"\u00a0 \u00a0 Returns:\u00a0 \u00a0 \u00a0 \u00a0 An unattached Disk instance.\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 disk_client = compute_v1.DisksClient()\u00a0 \u00a0 disk = compute_v1.Disk()\u00a0 \u00a0 disk.zone = zone\u00a0 \u00a0 disk.size_gb = disk_size_gb\u00a0 \u00a0 disk.source_snapshot = snapshot_link\u00a0 \u00a0 disk.type_ = disk_type\u00a0 \u00a0 disk.name = disk_name\u00a0 \u00a0 operation = disk_client.insert(project=project_id, zone=zone, disk_resource=disk)\u00a0 \u00a0 wait_for_extended_operation(operation, \"disk creation\")\u00a0 \u00a0 return disk_client.get(project=project_id, zone=zone, disk=disk_name)\n```\n### Mount the disk\n- In the terminal, use the `lsblk` command to list the disks that are attached to your instance and find the disk that you want to mount.```\n$ sudo lsblk\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\nsda  8:0 0 10G 0 disk\n\u2514\u2500sda1 8:1 0 10G 0 part /\nsdb  8:16 0 250G 0 disk\n```In this example, `sdb` is the device name for the new blank persistent disk.\n- Use the [mount tool](http://manpages.ubuntu.com/manpages/xenial/man8/mount.8.html) to mount the disk to the instance, and enable the `discard` option:```\n$ sudo mount -o discard,defaults /dev/DEVICE_NAME /home/jupyter\n```Replace the following:- ``: the device name of the disk to mount.\n- Configure read and write permissions on the disk. For this example, grant write access to the disk for all users.```\n$ sudo chmod a+w /home/jupyter\n```## What's next\n- Learn how to [save a notebook to GitHub](/vertex-ai/docs/workbench/user-managed/save-to-github) \n- Learn more about [creating snapshots](/compute/docs/disks/create-snapshots) .\n- Learn more about [scheduling snapshots](/compute/docs/disks/scheduled-snapshots) .", "guide": "Vertex AI"}