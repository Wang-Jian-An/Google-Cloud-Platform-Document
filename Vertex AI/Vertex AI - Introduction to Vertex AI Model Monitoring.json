{"title": "Vertex AI - Introduction to Vertex AI Model Monitoring", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Introduction to Vertex AI Model Monitoring\nThis page provides an overview of Vertex AI Model Monitoring for tabular AutoML and tabular custom-trained models. To enable Vertex AI Model Monitoring, see [Using Model Monitoring](/vertex-ai/docs/model-monitoring/using-model-monitoring) .\n", "content": "## Overview\nA model deployed in production performs best on prediction input data that is similar to the training data. When the input data deviates from the data used to train the model, the model's performance can deteriorate, even if the model itself hasn't changed.\nTo help you maintain a model's performance, Model Monitoring monitors the model's prediction input data for feature and :\n- occurs when the feature data distribution in production deviates from the feature data distribution used to train the model. If the original training data is available, you can enable skew detection to monitor your models for training-serving skew.\n- occurs when feature data distribution in production changes significantly over time. If the original training data isn't available, you can enable drift detection to monitor the input data for changes over time.\nYou can enable both skew and drift detection.\nModel Monitoring supports feature skew and drift detection for and features:\n- features are data limited by number of possible values, typically grouped by qualitative properties. For example, categories such as product type, country, or customer type.\n- features are data that can be any numeric value. For example, weight and height.\nOnce the skew or drift for a model's feature exceeds an alerting threshold that you set, Model Monitoring sends you an email alert. You can also view the distributions for each feature over time to evaluate whether you need to retrain your model.\n## Calculate training-serving skew and prediction drift\nTo detect training-serving skew and prediction drift, Model Monitoring uses [TensorFlow Data Validation(TFDV)](https://github.com/tensorflow/data-validation/blob/master/g3doc/anomalies.md) to calculate the distributions and according to the following process:\n- Calculate the statistical distribution:- For skew detection, the baseline is the statistical distribution of the feature's values in the training data.\n- For drift detection, the baseline is the statistical distribution of the feature's values seen in production in the recent past.\nThe distributions for categorical and numerical features are calculated as follows:- For categorical features, the computed distribution is the number or percentage of instances of each possible value of the feature.\n- For numerical features, Model Monitoring divides the range of possible feature values into equal intervals and computes the number or percentage of feature values that falls in each interval.\nThe baseline is calculated when you [create aModel Monitoring job](/vertex-ai/docs/model-monitoring/using-model-monitoring) , and is only recalculated if you update the training dataset for the job.\n- Calculate the statistical distribution of the latest feature values seen in production.\n- Compare the distribution of the latest feature values in production against the baseline distribution by calculating a :- For categorical features, the distance score is calculated using the [L-infinity distance](https://en.wikipedia.org/wiki/Chebyshev_distance) .\n- For numerical features, the distance score is calculated using the [Jensen-Shannon divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence) .\n- When the distance score between two statistical distributions exceeds the threshold you specify, Model Monitoring identifies the anomaly as skew or drift.\nThe following example shows skew or drift between the baseline and latest distributions of a categorical feature:\nThe following example shows skew or drift between the baseline and latest distributions of a numerical feature:\n## Considerations when using Model Monitoring\n- For cost efficiency, you can set a to monitor a subset of the production inputs to a model.\n- You can set a frequency at which a deployed model's recently logged inputs are monitored for skew or drift. Monitoring frequency determines the timespan, or monitoring window size, of logged data that is analyzed in each monitoring run.\n- You can specify alerting thresholds for each feature you want to monitor. An alert is logged when the statistical distance between the input feature distribution and its corresponding baseline exceeds the specified threshold. By default, every categorical and numerical feature is monitored, with threshold values of 0.3.\n- An online prediction endpoint can host multiple models. When you enable skew or drift detection on an endpoint, the following configuration parameters are shared across all models hosted in that endpoint:- Type of detection\n- Monitoring frequency\n- Fraction of input requests monitored\nFor the other [configuration parameters](/sdk/gcloud/reference/ai/model-monitoring-jobs/create) , you can set different values for each model.## What's next\n- Learn how [schemas work with your tabular monitoring job](/vertex-ai/docs/model-monitoring/schemas) .\n- [Enable skew and drift detection](/vertex-ai/docs/model-monitoring/using-model-monitoring) for your models.\n- Try the example notebook [in Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) or [view it on GitHub](https://www.github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb) .\n- See the [TensorFlow Data Validation Anomalies Reference](https://github.com/tensorflow/data-validation/blob/master/g3doc/anomalies.md)", "guide": "Vertex AI"}