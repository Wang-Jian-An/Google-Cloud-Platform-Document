{"title": "Vertex AI - Profile model training performance using Vertex AI TensorBoard profiler", "url": "https://cloud.google.com/vertex-ai/docs/training/tensorboard-profiler", "abstract": "# Vertex AI - Profile model training performance using Vertex AI TensorBoard profiler\nThis page shows you how to enable [Vertex AI TensorBoard profiler](https://github.com/googleapis/python-aiplatform/tree/main/google/cloud/aiplatform/training_utils/cloud_profiler) so you can debug model training performance for your custom training jobs.\nTraining models can be computationally expensive. Vertex AI TensorBoard profiler lets you monitor and optimize your model training performance by helping you understand the resource consumption of training operations. With this information, you can pinpoint and fix performance bottlenecks to train models faster and cheaper.\n", "content": "## Before you begin\n- Ensure that you're using TensorFlow 2.4 or a later version.\n- Install the [Vertex AI SDK](https://github.com/googleapis/python-aiplatform) with the `cloud_profiler` plugin. From your local Docker container, run:```\npip install google-cloud-aiplatform[cloud_profiler]\n```\n- You must have a Vertex AI TensorBoard instance. See [Create a Vertex AI TensorBoard instance](/vertex-ai/docs/experiments/tensorboard-setup#create-tensorboard-instance) for instructions.\n- You must have a service account with `roles/storage.admin` and `roles/aiplatform.user` roles. See [Create a service account with required permissions](/vertex-ai/docs/experiments/tensorboard-training#create_a_service_account_with_required_permissions) for instructions.\n- You must have a Cloud Storage bucket to store Vertex AI TensorBoard logs. See [Create a Cloud Storage bucket to store Vertex AI TensorBoard logs](/vertex-ai/docs/experiments/tensorboard-training#create_a_bucket_to_store_logs) for instructions.## Enable Vertex AI TensorBoard profiler\nTo enable Vertex AI TensorBoard profiler for your training job, add the following to your training script:\n- Add the `cloud_profiler` import at your top level imports:```\nfrom google.cloud.aiplatform.training_utils import cloud_profiler\n```\n- Initialize the `cloud_profiler` plugin by adding:```\ncloud_profiler.init()\n```Here's a sample training script:\n```\n#!/usr/bin/env pythonimport tensorflow as tfimport argparseimport osfrom google.cloud.aiplatform.training_utils import cloud_profilerimport time\"\"\"Train an mnist model and use cloud_profiler for profiling.\"\"\"def _create_model():\u00a0 \u00a0 model = tf.keras.models.Sequential(\u00a0 \u00a0 \u00a0 \u00a0 [\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tf.keras.layers.Flatten(input_shape=(28, 28)),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tf.keras.layers.Dense(128, activation=\"relu\"),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tf.keras.layers.Dropout(0.2),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tf.keras.layers.Dense(10),\u00a0 \u00a0 \u00a0 \u00a0 ]\u00a0 \u00a0 )\u00a0 \u00a0 return modeldef main(args):\u00a0 \u00a0 strategy = None\u00a0 \u00a0 if args.distributed:\u00a0 \u00a0 \u00a0 \u00a0 strategy = tf.distribute.MultiWorkerMirroredStrategy()\u00a0 \u00a0 mnist = tf.keras.datasets.mnist\u00a0 \u00a0 (x_train, y_train), (x_test, y_test) = mnist.load_data()\u00a0 \u00a0 x_train, x_test = x_train / 255.0, x_test / 255.0\u00a0 \u00a0 if args.distributed:\u00a0 \u00a0 \u00a0 \u00a0 strategy = tf.distribute.MultiWorkerMirroredStrategy()\u00a0 \u00a0 \u00a0 \u00a0 with strategy.scope():\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 model = _create_model()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 model.compile(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 optimizer=\"adam\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 loss=tf.keras.losses.sparse_categorical_crossentropy,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 metrics=[\"accuracy\"],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 else:\u00a0 \u00a0 \u00a0 \u00a0 model = _create_model()\u00a0 \u00a0 \u00a0 \u00a0 model.compile(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 optimizer=\"adam\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 loss=tf.keras.losses.sparse_categorical_crossentropy,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 metrics=[\"accuracy\"],\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 # Initialize the profiler.\u00a0 \u00a0 cloud_profiler.init()\u00a0 \u00a0 # Use AIP_TENSORBOARD_LOG_DIR to update where logs are written to.\u00a0 \u00a0 tensorboard_callback = tf.keras.callbacks.TensorBoard(\u00a0 \u00a0 \u00a0 \u00a0 log_dir=os.environ[\"AIP_TENSORBOARD_LOG_DIR\"], histogram_freq=1\u00a0 \u00a0 )\u00a0 \u00a0 model.fit(\u00a0 \u00a0 \u00a0 \u00a0 x_train,\u00a0 \u00a0 \u00a0 \u00a0 y_train,\u00a0 \u00a0 \u00a0 \u00a0 epochs=args.epochs,\u00a0 \u00a0 \u00a0 \u00a0 verbose=0,\u00a0 \u00a0 \u00a0 \u00a0 callbacks=[tensorboard_callback],\u00a0 \u00a0 )if __name__ == \"__main__\":\u00a0 \u00a0 parser = argparse.ArgumentParser()\u00a0 \u00a0 parser.add_argument(\u00a0 \u00a0 \u00a0 \u00a0 \"--epochs\", type=int, default=100, help=\"Number of epochs to run model.\"\u00a0 \u00a0 )\u00a0 \u00a0 parser.add_argument(\u00a0 \u00a0 \u00a0 \u00a0 \"--distributed\", action=\"store_true\", help=\"Use MultiWorkerMirroredStrategy\"\u00a0 \u00a0 )\u00a0 \u00a0 args = parser.parse_args()\u00a0 \u00a0 main(args)\n```\n## Access the Vertex AI TensorBoard profiler dashboard\nOnce you have configured your training script to enable Vertex AI TensorBoard profiler, [run the training script with a Vertex AI TensorBoard instance](/vertex-ai/docs/experiments/tensorboard-training#create_a_custom_training_job) .\nIn your training script, ensure the following configurations:\n- Set`BASE_OUTPUT_DIR:`to the Cloud Storage bucket where you want to store the Vertex AI TensorBoard logs that's generated by your training script.\n- Set`'serviceAccount':`to the service account that you created with`roles/storage.admin`and`roles/aiplatform.user`roles.\n- Set `'tensorboard':` to the fully qualified name of the Vertex AI TensorBoard instance that you want to use with this training job. The fully qualified name has the following format:```\nprojects/PROJECT_NUMBER_OR_ID/locations/REGION/tensorboards/TENSORBOARD_INSTANCE_ID\n```\nThere are two ways to access the Vertex AI TensorBoard profiler dashboard from the Google Cloud console:\n- From the Custom jobs page.\n- From the Experiments page.You can use this method to access the Vertex AI TensorBoard profiler dashboard even if the training job is in the **Finished** state.\n- In the Google Cloud console, go to the **Custom jobs** tab on the **Training** page. [Go to Custom jobs](https://console.cloud.google.com/vertex-ai/training/custom-jobs) \n- Click the name of the training job you just created to go to the job details page.\n- Click **Open TensorBoard** .\n- Click the **Profile** tab.You can use this method to access the Vertex AI TensorBoard profiler dashboard only when the training job is in the **Running** state.\n- In the Google Cloud console, go to the Vertex AI Experiments page. [Go to Vertex AI Experiments](https://console.cloud.google.com/vertex-ai/experiments) \n- Select the region of the training job that you just created.\n- Click **Open TensorBoard** next to the name of the training job.\n- Click the **Profile** tab.## Capture a profiling session\nTo capture a profiling session, your training job must be in the **Running** state. From the **Profile** tab in the Vertex AI TensorBoard instance, perform the following steps:\n- Click **Capture profile** .\n- In the **Profile Service URL(s) or TPU name** field, enter:```\nworkerpool0-0\n```\n- For **Address type** , select **IP address** .\n- Click **Capture** .## Notebook\nTo learn more,  run the following Jupyter notebooks in the environment of your choice:\n- \"Profile model training performance using profiler\": [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_profiler_custom_training.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftensorboard%2Ftensorboard_profiler_custom_training.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_profiler_custom_training.ipynb) \n- \"Profile model training performance using Vertex AI TensorBoard profiler in custom training with prebuilt container\": [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_profiler_custom_training_with_prebuilt_container.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftensorboard%2Ftensorboard_profiler_custom_training_with_prebuilt_container.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/tensorboard/tensorboard_profiler_custom_training_with_prebuilt_container.ipynb)\n## What's next\n- See the [Tensorflow Profiler documentation](https://www.tensorflow.org/guide/profiler) to learn about the profiler tools and how to use them to optimize model performance.", "guide": "Vertex AI"}