{"title": "Vertex AI - Interpret prediction results from image object detection models", "url": "https://cloud.google.com/vertex-ai/docs/image-data/object-detection/interpret-results", "abstract": "# Vertex AI - Interpret prediction results from image object detection models\n`\"bboxes\": [  [xMin, xMax, yMin, yMax],  ...]`\n`xMin, xMax`\n`yMin, yMax`Batch AutoML image object detection prediction responses are stored as JSON Lines files in Cloud Storage buckets. Each line of the JSON Lines file contains all objects found in a single image file. Each found object has an annotation (label and normalized bounding box) with a corresponding confidence score.\n**Note: Zero coordinate values omitted.** When the API detects  a coordinate (\"x\" or \"y\") value of 0, **that coordinate is omitted in the\n  JSON response** . Thus, a response with a bounding poly around the entire image  would be **[{},{\"x\": 1,\"y\": 1}]** . For more information, see [Method: projects.locations.models.predict](https://cloud.google.com/automl/docs/reference/rest/v1/projects.locations.models/predict#boundingpoly) .\n**Note** : The following JSON Lines example includes line breaks for readability. In your JSON Lines files, line breaks are included only after each each JSON object.\n**Important: ** Bounding boxes are specified as:\n`\"bboxes\": [  [xMin, xMax, yMin, yMax],  ...]`\n`xMin`\n`xMax`\n`yMin`\n`yMax`\n```\n{\n \"instance\": {\"content\": \"gs://bucket/image.jpg\", \"mimeType\": \"image/jpeg\"},\n \"prediction\": {\n \"ids\": [1, 2],\n \"displayNames\": [\"cat\", \"dog\"],\n \"bboxes\": [  [0.1, 0.2, 0.3, 0.4],\n  [0.2, 0.3, 0.4, 0.5]\n ],\n \"confidences\": [0.7, 0.5]\n }\n}\n``", "content": "`", "guide": "Vertex AI"}