{"title": "Vertex AI - Run a managed notebooks instance on a Dataproc cluster", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Run a managed notebooks instance on a Dataproc cluster\n# Run a managed notebooks instance on a Dataproc cluster\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\nThis page shows you how to run a managed notebooks instance's notebook file on a Dataproc cluster.\n", "content": "## Before you begin\n- If you haven't already, [create a managed notebooks instance](/vertex-ai/docs/workbench/managed/create-instance#create) .\n### Required roles\nTo ensure that the service account has the necessary  permissions to run a notebook file on a Dataproc Serverless cluster,   ask your administrator to grant the service account the  following IAM roles:\n- [Dataproc Worker ](https://cloud.google.com/iam/docs/understanding-roles#dataproc.worker) (`roles/dataproc.worker`)    on your project\n- [Dataproc Editor ](https://cloud.google.com/iam/docs/understanding-roles#dataproc.editor) (`roles/dataproc.editor`)    on the cluster for the`dataproc.clusters.use`permission\nFor more information about granting roles, see [Manage access](/iam/docs/granting-changing-revoking-access) .\nThese predefined roles contain     the permissions required to run a notebook file on a Dataproc Serverless cluster. To see the exact permissions that are   required, expand the **Required permissions** section:\nYour administrator might also be able to give the service account   these permissions  with [custom roles](/iam/docs/creating-custom-roles) or  other [predefined roles](/iam/docs/understanding-roles) .\n## Create a Dataproc cluster\nTo run a managed notebooks instance's notebook file in a Dataproc cluster, your cluster must meet the following criteria:\n- The cluster's component gateway must be enabled.\n- The cluster must have the [Jupyter component](/dataproc/docs/concepts/components/jupyter) .\n- The cluster must be in the same region as your managed notebooks instance.\nTo create your Dataproc cluster, enter the following command in either [Cloud Shell](https://console.cloud.google.com?cloudshell=true) or another environment where the [Google Cloud CLI](/sdk/docs) is installed.\n```\ngcloud dataproc clusters create CLUSTER_NAME\\\n --region=REGION \\\n --enable-component-gateway \\\n --optional-components=JUPYTER\n```\nReplace the following:\n- `` : the Google Cloud location of your managed notebooks instance\n- `` : the name of your new cluster\nAfter a few minutes, your Dataproc cluster is available for use. [Learn more about creating Dataprocclusters](/dataproc/docs/guides/create-cluster) .\n## Open JupyterLab\n- If you haven't already, [createa managed notebooks instance](/vertex-ai/docs/workbench/managed/create-instance#create) in the same region where your Dataproc cluster is.\n- In the Google Cloud console, go to the **Managed notebooks** page. [Go to Managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/managed) \n- Next to your managed notebooks instance's name, click **Open JupyterLab** .## Run a notebook file in your Dataproc cluster\nYou can run a notebook file in your Dataproc cluster from any managed notebooks instance in the same project and region.\n### Run a new notebook file\n- In your managed notebooks instance's JupyterLab interface, select **File\u00a0>New\u00a0> Notebook** .\n- Your Dataproc cluster's available kernels appear in the **Select kernel** menu. Select the kernel that you want to use, and then click **Select** .Your new notebook file opens.\n- Add code to your new notebook file, and run the code.\nTo change the kernel that you want to use after you've created your notebook file, see the following section.\n### Run an existing notebook file\n- In your managed notebooks instance's JupyterLab interface, click the folder **File Browser** button, navigate to the notebook file that you want to run, and open it.\n- To open the **Select kernel** dialog, click the kernel name of your notebook file, for example: **Python (Local)** .\n- To select a kernel from your Dataproc cluster, select a kernel name that includes your cluster name at the end of it. For example, a PySpark kernel on a Dataproc cluster named `mycluster` is named **PySpark on mycluster** .\n- Click **Select** to close the dialog.You can now run your notebook file's code on the Dataproc cluster.## What's next\n- Learn more about [Dataproc](/dataproc/docs/concepts/overview) .", "guide": "Vertex AI"}