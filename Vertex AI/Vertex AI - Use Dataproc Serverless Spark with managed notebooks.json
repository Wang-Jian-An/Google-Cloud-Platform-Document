{"title": "Vertex AI - Use Dataproc Serverless Spark with managed notebooks", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Use Dataproc Serverless Spark with managed notebooks\n# Use Dataproc Serverless Spark with managed notebooks\nVertex AI Workbench managed notebooks is [deprecated](/vertex-ai/docs/deprecations) . On January 30, 2025, support for  managed notebooks will end and the ability to create managed notebooks instances  will be removed. Existing instances will continue to function  but patches, updates, and upgrades won't be available. To continue using  Vertex AI Workbench, we recommend that you [migrate your managed notebooks instances to Vertex AI Workbench instances](/vertex-ai/docs/workbench/managed/migrate-to-instances) .\n**    Preview     ** This feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nThis page shows you how to run a notebook file on serverless Spark in a Vertex AI Workbench managed notebooks instance by using [Dataproc Serverless](/dataproc-serverless/docs) .\nTo see an example of how to use serverless Spark with Vertex AI Workbench as part of a more comprehensive workflow,  run the \"Digest and analyze data from BigQuery with Dataproc\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/workbench/spark/spark_bigquery.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fworkbench%2Fspark%2Fspark_bigquery.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/workbench/spark/spark_bigquery.ipynb)\nYour managed notebooks instance can submit a notebook file's code to run on the Dataproc Serverless service. The service runs the code on a managed compute infrastructure that automatically scales resources as needed. Therefore, you don't need to provision and manage your own cluster.\n[Dataproc Serverless charges](/dataproc-serverless/pricing) apply only to the time when the workload is executing.\n", "content": "## Requirements\nTo run a notebook file on Dataproc Serverless Spark, see the following requirements.\n- Your Dataproc Serverless session must run in the same region as your managed notebooks instance.\n- The Require OS Login ( `constraints/compute.requireOsLogin` ) constraint must not be enabled for your project. See [Manage OS Login inan organization](https://cloud.google.com/compute/docs/oslogin/manage-oslogin-in-an-org) .\n- To run a notebook file on Dataproc Serverless, you must provide a [service account](/iam/docs/service-accounts) that has specific permissions. You can grant these permissions to the default service account or provide a custom service account. See the [Permissions section of this page](#permissions) .\n- Your Dataproc Serverless Spark session uses a Virtual Private Cloud (VPC) network to execute workloads. The VPC subnetwork must meet specific requirements. See the requirements in [Dataproc Serverless forSpark network configuration](/dataproc-serverless/docs/concepts/network) .## Permissions\nTo ensure that the service account has the necessary  permissions to run a notebook file on Dataproc Serverless,   ask your administrator to grant the service account the [Dataproc Editor ](https://cloud.google.com/iam/docs/understanding-roles#dataproc.editor) ( `roles/dataproc.editor` ) IAM role on your project.    For more information about granting roles, see [Manage access](/iam/docs/granting-changing-revoking-access) .\nThis predefined role contains     the permissions required to run a notebook file on Dataproc Serverless. To see the exact permissions that are   required, expand the **Required permissions** section:\nYour administrator might also be able to give the service account   these permissions  with [custom roles](/iam/docs/creating-custom-roles) or  other [predefined roles](/iam/docs/understanding-roles) .\n## Before you begin\n- If you haven't already, [create a managed notebooks instance](/vertex-ai/docs/workbench/managed/create-instance#create) .\n- If you haven't already,  configure a VPC network that meets the requirements listed in [Dataproc Serverless for Spark network configuration](/dataproc-serverless/docs/concepts/network) .## Open JupyterLab\n- In the Google Cloud console, go to the **Managed notebooks** page. [Go to Managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/managed) \n- Next to your managed notebooks instance's name, click **Open JupyterLab** .## Start a Dataproc Serverless Spark session\nTo start a Dataproc Serverless Spark session, complete the following steps.\n- In your managed notebooks instance's JupyterLab interface, select the **Launcher** tab, and then select **Serverless Spark** . If the **Launcher** tab is not open, select **File\u00a0> New Launcher** to open it.The **Create Serverless Spark session** dialog appears.\n- In the **Session name** field, enter a name for your session.\n- In the **Execution configuration** section, enter the **Service account** that you want to use. If you don't enter a service account, your session will use the [Compute Engine defaultservice account](/compute/docs/access/service-accounts#default_service_account) .\n- In the **Network configuration** section, select the **Network** and **Subnetwork** of a network that meets the requirements listed in [Dataproc Serverless forSpark network configuration](/dataproc-serverless/docs/concepts/network) .\n- Click **Create** .A new notebook file opens. The Dataproc Serverless Spark session that you created is the kernel that runs your notebook file's code.## Run your code on Dataproc Serverless Spark and other kernels\n- Add code to your new notebook file, and run the code.\n- To run code on a different kernel, [change the kernel](/vertex-ai/docs/workbench/managed/create-managed-notebooks-instance-console-quickstart#change-kernel) .\n- When you want to run the code on your Dataproc Serverless Spark session again, change the kernel back to the Dataproc Serverless Spark kernel.## Terminate your Dataproc Serverless Spark session\nYou can terminate a Dataproc Serverless Spark session in the JupyterLab interface or in the Google Cloud console. The code in your notebook file is preserved.\n- In JupyterLab, close the notebook file that was created when you created your Dataproc Serverless Spark session.\n- In the dialog that appears, click **Terminate session** .\n- In the Google Cloud console, go to the **Dataproc sessions** page. [Go to Dataproc sessions](https://console.cloud.google.com/dataproc/interactive) \n- Select the session that you want to terminate, and then click **Terminate** .## Delete your Dataproc Serverless Spark session\nYou can delete a Dataproc Serverless Spark session by using the Google Cloud console. The code in your notebook file is preserved.\n- In the Google Cloud console, go to the **Dataproc sessions** page. [Go to Dataproc sessions](https://console.cloud.google.com/dataproc/interactive) \n- Select the session that you want to delete, and then click **Delete** .## What's next\n- Learn more about [Dataproc Serverless](/dataproc-serverless/docs/overview) .", "guide": "Vertex AI"}