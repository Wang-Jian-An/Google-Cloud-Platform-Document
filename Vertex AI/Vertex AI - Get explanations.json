{"title": "Vertex AI - Get explanations", "url": "https://cloud.google.com/vertex-ai/docs/explainable-ai/getting-explanations", "abstract": "# Vertex AI - Get explanations\nThis guide describes how to get explanations from a `Model` resource on Vertex AI. You can get explanations in two ways:\n- **Online explanations:** Synchronous requests to the Vertex AI API, similar to [online predictions](/vertex-ai/docs/predictions/overview) that return predictions with feature attributions.\n- **Batch explanations:** Asynchronous requests to the Vertex AI API that return predictions with feature attributions. Batch explanations are an optional part of [batch prediction requests](/vertex-ai/docs/predictions/overview) .", "content": "## Before you begin\nBefore getting explanations, you must do the following:\n- This step differs depending on what type of machine learning model you use:- **If you want to get explanations from a custom-trained model,** then follow either [Configuring example-based explanations](/vertex-ai/docs/explainable-ai/configuring-explanations-example-based) or [Configuring feature-based explanations](/vertex-ai/docs/explainable-ai/configuring-explanations-feature-based) to create a `Model` that supports Vertex Explainable AI.\n- **If you want to get explanations from an AutoML tabularclassification or regression model,** then [train an AutoMLmodel on a tabular dataset](/vertex-ai/docs/training/automl-console) . There is no specific configuration required to use Vertex Explainable AI. Explanations for forecasting models aren't supported.\n- **If you want to get explanations from an AutoML imageclassification model,** then [train an AutoMLmodel on an image dataset](/vertex-ai/docs/training/automl-console) and [enable explanations when you deploy the model](/vertex-ai/docs/predictions/deploy-model-console) . There is no specific configuration required to use Vertex Explainable AI. Explanations for object detection models aren't supported.\n- If you want to get online explanations, [deploy the Model that youcreated in the preceding step to an Endpointresource](/vertex-ai/docs/predictions/deploy-model-console) .## Get online explanations\nTo get online explanations, follow most of the same steps that you would to get online predictions. However, instead of sending a [projects.locations.endpoints.predictrequest](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/predict) to the Vertex AI API, send a [projects.locations.endpoints.explainrequest](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/explain) .\nThe following guides provide detailed instructions for preparing and sending online explanation requests:\n- **For AutoML image classification models,** read [Getting online predictions from AutoMLmodels](/vertex-ai/docs/predictions/online-predictions-automl) .\n- **For AutoML tabular classification and regression models,** read [Getting online predictions from AutoMLmodels](/vertex-ai/docs/predictions/online-predictions-automl) .\n- **For custom-trained models,** read [Getting online predictions fromcustom-trained models](/vertex-ai/docs/predictions/get-online-predictions) .## Get batch explanations\nOnly feature-based batch explanations are supported; you cannot get example-based batch explanations.\nTo get batch explanations, set the [generateExplanationfield](/vertex-ai/docs/reference/rest/v1/projects.locations.batchPredictionJobs#BatchPredictionJob.FIELDS.generate_explanation) to `true` when you create a batch prediction job.\nFor detailed instructions about preparing and creating batch prediction jobs, read [Getting batch predictions](/vertex-ai/docs/predictions/batch-predictions-automl) .\n## Get explanations locally in Vertex AI Workbench user-managed notebooks\nIn [Vertex AI Workbenchuser-managed notebooks](/vertex-ai/docs/workbench/user-managed/introduction) , you can generate explanations for your custom-trained model by running Vertex Explainable AI within your notebook's local kernel or runtime without deploying the model to Vertex AI to get explanations. Using local explanations lets you try out different Vertex Explainable AI settings without adjusting your Vertex AI model deployment for each change. This makes it easier and faster to evaluate the impact of [using different baselines](/vertex-ai/docs/explainable-ai/improving-explanations#baselines) , trying different [visualization settings](/vertex-ai/docs/explainable-ai/visualization-settings) for your explanations, or adjusting the number of [steps or paths](/vertex-ai/docs/explainable-ai/improving-explanations#increase-steps-paths) used for your algorithm.\nLocal explanations are available only within user-managed notebooks, therefore, this feature doesn't work in Jupyter notebooks that are run outside of a user-managed notebooks instance.\nTo generate explanations locally in a user-managed notebooks instance:\n- [Createa user-managed notebooks instance](/vertex-ai/docs/workbench/user-managed/create-new) \n- Launch the JupyterLab environment from your user-managed notebooks instance, and then create or import a notebook.\n- Save the model artifact to your notebook's local environment, or a Cloud Storage bucket.\n- Generate and save metadata to describe your model and configure your explanation request.## Get Concurrent Explanations\nExplainable AI supports concurrent explanations. Concurrent explanations allow you to request both feature-based and example-based explanations from the same deployed model endpoint without having to deploy your model separately for each explanation method.\nTo get concurrent explanations, upload your model and configure either [example-based](/vertex-ai/docs/explainable-ai/configuring-explanations-example-based) or [feature-based](/vertex-ai/docs/explainable-ai/configuring-explanations-feature-based) explanations. Then, deploy your model as usual.\nAfter the model is deployed, you can request the configured explanations as usual. Additionally, you can request concurrent explanations by specifying [concurrent_explanation_spec_override](/vertex-ai/docs/reference/rest/v1/projects.locations.endpoints/explain#body.request_body.FIELDS.concurrent_explanation_spec_override) .\nNote the following when using concurrent explanations:\n- Concurrent explanations are available using only the`v1beta1`API version. If you're using the Vertex python SDK, you'll need to use the`preview`model to use concurrent explanations.\n- Example-based explanations cannot be requested after deploying with feature-based explanations. If you want both Example-based explanation and Feature-based explanations, deploy your model using Example-based explanations and request Feature-based using the concurrent explanation field.\n- Batch Explanations are not supported for Concurrent explanations. Online Explanations are the only way to use this feature.\n### Use the Explainable AI SDK in user-managed notebooks\nThe Explainable AI SDK is pre-installed in user-managed notebooks instances. Within your notebook, you can use the [Explainable AI SDK](https://github.com/GoogleCloudPlatform/explainable_ai_sdk) to save your model artifact and automatically identify metadata about your model's inputs and outputs for the explanation request. You can also specify other parameters to configure your explanation request, and then visualize the explanation results.\nYou can save models and metadata either in your notebook's local environment, or in a Cloud Storage bucket. If you're using TensorFlow, you can use the `save_model_with_metadata()` method to infer your model's inputs and outputs, and save this explanation metadata with your model.\nNext, load the model into the Explainable AI SDK using `load_model_from_local_path()` . If needed, you can [adjust the configuration](/vertex-ai/docs/explainable-ai/improving-explanations#adjusting) for the specific Vertex Explainable AI algorithm. For example, you can change the number of paths to use for Sampled Shapley, or the number of steps to use for integrated gradients or XRAI.\nFinally, call `explain()` with instances of data, and visualize the feature attributions.\nYou can use the following example code to get local explanations for a TensorFlow 2 model within a user-managed notebooks instance:\n**Note:** The following code sample works within a [user-managed notebooks instance](/vertex-ai/docs/workbench/user-managed/create-new) .\n```\n# This sample code only works within a user-managed notebooks instance.import explainable_ai_sdkfrom explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuildermetadata_and_model_builder = SavedModelMetadataBuilder('LOCAL_PATH_TO_MODEL')metadata_and_model_builder.save_model_with_metadata('LOCAL_PATH_TO_SAVED_MODEL_ARTIFACT')# Load the model and adjust the configuration for Explainable AI parametersnum_paths = 20model_artifact_with_metadata = explainable_ai_sdk.load_model_from_local_path(\u00a0 \u00a0 'LOCAL_PATH_TO_SAVED_MODEL_ARTIFACT',\u00a0 \u00a0 explainable_ai_sdk.SampledShapleyConfig(num_paths))# Explainable AI supports generating explanations for multiple predictionsinstances = [{feature_a: 10, feature_2: 100,...}, ... ]explanations = model_artifact_with_metadata.explain(instances)explanations[0].visualize_attributions()\n```\nFor more information about the [Explainable AI SDK](https://github.com/GoogleCloudPlatform/explainable_ai_sdk) , including different configurations and parameters, see the SDK's [config.py](https://github.com/GoogleCloudPlatform/explainable_ai_sdk/blob/master/explainable_ai_sdk/model/configs.py) file on GitHub. Learn more about [Vertex AI Workbenchuser-managed notebooks](/vertex-ai/docs/workbench/user-managed/introduction) .\n## Troubleshooting\nThis section describes troubleshooting steps that you might find helpful if you run into problems with while getting explanations.\n### Error: list index out of range\nIf you get the following error message when requesting explanations:\n```\n\"error\": \"Explainability failed with exception: listindex out of range\"\n```\nMake sure that you are not passing an empty array into a field that expects an array of objects. For example, if `field1` accepts an array of objects, the following request body might result in an error:\n```\n{\u00a0 \"instances\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"field1\": [],\u00a0 \u00a0 }\u00a0 ]}\n```\nInstead, make sure the array is not empty, for example:\n```\n{\u00a0 \"instances\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"field1\": [\u00a0 \u00a0 \u00a0 \u00a0 {}\u00a0 \u00a0 \u00a0 ],\u00a0 \u00a0 }\u00a0 ]}\n```\n## What's next\n- Based on the explanations you receive, learn how to [adjust your Model toimprove explanations](/vertex-ai/docs/explainable-ai/improving-explanations) .\n- [Try a sample notebook demonstrating Vertex Explainable AIon tabular data or image data](https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/main/notebooks/official/explainable_ai) .", "guide": "Vertex AI"}