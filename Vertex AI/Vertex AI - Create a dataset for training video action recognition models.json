{"title": "Vertex AI - Create a dataset for training video action recognition models", "url": "https://cloud.google.com/vertex-ai/docs/video-data/action-recognition/create-dataset", "abstract": "# Vertex AI - Create a dataset for training video action recognition models\nThis page shows you how to create a Vertex AI dataset from your video data so you can start training action recognition models. You can create a dataset using either the Google Cloud console or the Vertex AI API.\n", "content": "## Create an empty dataset and import or associate your data\nUse the following instructions to create an empty dataset and either import or associate your data.\nThe number of videos per import request is limited to 50,000.- In the Google Cloud console, in the Vertex AI section, go to  the **Datasets** page. [Go to the Datasets page](https://console.cloud.google.com/vertex-ai/datasets) \n- Click **Create** to open the create dataset details page.\n- Modify the **Dataset name** field to create a descriptive dataset display  name.\n- Select the **Video** tab.\n- Select **Video action recognition** .\n- Select a region from the **Region** drop-down list.\n- Click **Create** to create your empty dataset, and advance to the data import page.\n- Choose one of the following options from the **Select an import method** section:- In the **Select an import method** section, choose to upload data from your computer.\n- Click **Select files** and choose all the local files to upload to a Cloud Storage  bucket.\n- In the **Select a Cloud Storage path** section click **Browse** to choose a  Cloud Storage bucket location to upload your data to.\n- Clickradio_button_checked **Upload an import file from\n your computer** .\n- Click **Select files** and choose the local import file to upload to a Cloud Storage  bucket.\n- In the **Select a Cloud Storage path** section click **Browse** to choose a  Cloud Storage bucket location to upload your file to.\n- Clickradio_button_checked **Select an import file from\n Cloud Storage** .\n- In the **Select a Cloud Storage path** section click **Browse** to choose the  import file in Cloud Storage.\n- Click **Continue** .Data import can take several hours, depending on the size of your data.  You can close this tab and return to it later. You will receive an email  when your data is imported.\nIn order to create a machine learning model you must first have a representative collection of data to train with. After importing data you can make modifications and start model training.## Create a datasetUse the following samples to create a dataset for your data.Before using any of the request data, make the following replacements:- : Region where the dataset will be stored. This must be a region that supports dataset resources. For example,`us-central1`. See [List of available locations](/vertex-ai/docs/general/locations) .\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : Name for the dataset.\n- : Your project's automatically generated [project number](/resource-manager/docs/creating-managing-projects#identifiers) .\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/datasets\n```\nRequest JSON body:\n```\n{\n \"display_name\": \"DATASET_NAME\",\n \"metadata_schema_uri\": \"gs://google-cloud-aiplatform/schema/dataset/metadata/video_1.0.0.yaml\"\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/datasets\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/datasets\" | Select-Object -Expand Content\n```\nYou should see output similar to the following. You can use the in the response to [get the status](#get-operation) of the operation.\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION/operations/OPERATION_ID\",\n \"metadata\": {\n \"@type\": \"type.googleapis.com/google.cloud.aiplatform.v1.CreateDatasetOperationMetadata\",\n \"genericMetadata\": {\n  \"createTime\": \"2020-07-07T21:27:35.964882Z\",\n  \"updateTime\": \"2020-07-07T21:27:35.964882Z\"\n }\n }\n}\n```\nThe following sample uses the [google_vertex_ai_dataset](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/vertex_ai_dataset) Terraform resource to create a video dataset named `video-dataset` .\nTo learn how to apply or remove a Terraform configuration, see [Basic Terraform commands](/docs/terraform/basic-commands) .\n [View on GitHub](https://github.com/terraform-google-modules/terraform-docs-samples/blob/HEAD/vertex_ai/dataset/main.tf) \n```\nresource \"google_vertex_ai_dataset\" \"video_dataset\" {\u00a0 display_name \u00a0 \u00a0 \u00a0 \u00a0= \"video-dataset\"\u00a0 metadata_schema_uri = \"gs://google-cloud-aiplatform/schema/dataset/metadata/video_1.0.0.yaml\"\u00a0 region \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0= \"us-central1\"}\n```Before trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/CreateDatasetVideoSample.java) \n```\nimport com.google.api.gax.longrunning.OperationFuture;import com.google.cloud.aiplatform.v1.CreateDatasetOperationMetadata;import com.google.cloud.aiplatform.v1.Dataset;import com.google.cloud.aiplatform.v1.DatasetServiceClient;import com.google.cloud.aiplatform.v1.DatasetServiceSettings;import com.google.cloud.aiplatform.v1.LocationName;import java.io.IOException;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeUnit;import java.util.concurrent.TimeoutException;public class CreateDatasetVideoSample {\u00a0 public static void main(String[] args)\u00a0 \u00a0 \u00a0 throws IOException, InterruptedException, ExecutionException, TimeoutException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String project = \"YOUR_PROJECT_ID\";\u00a0 \u00a0 String datasetVideoDisplayName = \"YOUR_DATASET_VIDEO_DISPLAY_NAME\";\u00a0 \u00a0 createDatasetSample(datasetVideoDisplayName, project);\u00a0 }\u00a0 static void createDatasetSample(String datasetVideoDisplayName, String project)\u00a0 \u00a0 \u00a0 throws IOException, InterruptedException, ExecutionException, TimeoutException {\u00a0 \u00a0 DatasetServiceSettings datasetServiceSettings =\u00a0 \u00a0 \u00a0 \u00a0 DatasetServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (DatasetServiceClient datasetServiceClient =\u00a0 \u00a0 \u00a0 \u00a0 DatasetServiceClient.create(datasetServiceSettings)) {\u00a0 \u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 \u00a0 String metadataSchemaUri =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"gs://google-cloud-aiplatform/schema/dataset/metadata/video_1.0.0.yaml\";\u00a0 \u00a0 \u00a0 LocationName locationName = LocationName.of(project, location);\u00a0 \u00a0 \u00a0 Dataset dataset =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Dataset.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDisplayName(datasetVideoDisplayName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMetadataSchemaUri(metadataSchemaUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 OperationFuture<Dataset, CreateDatasetOperationMetadata> datasetFuture =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 datasetServiceClient.createDatasetAsync(locationName, dataset);\u00a0 \u00a0 \u00a0 System.out.format(\"Operation name: %s\\n\", datasetFuture.getInitialFuture().get().getName());\u00a0 \u00a0 \u00a0 System.out.println(\"Waiting for operation to finish...\");\u00a0 \u00a0 \u00a0 Dataset datasetResponse = datasetFuture.get(300, TimeUnit.SECONDS);\u00a0 \u00a0 \u00a0 System.out.println(\"Create Dataset Video Response\");\u00a0 \u00a0 \u00a0 System.out.format(\"Name: %s\\n\", datasetResponse.getName());\u00a0 \u00a0 \u00a0 System.out.format(\"Display Name: %s\\n\", datasetResponse.getDisplayName());\u00a0 \u00a0 \u00a0 System.out.format(\"Metadata Schema Uri: %s\\n\", datasetResponse.getMetadataSchemaUri());\u00a0 \u00a0 \u00a0 System.out.format(\"Metadata: %s\\n\", datasetResponse.getMetadata());\u00a0 \u00a0 \u00a0 System.out.format(\"Create Time: %s\\n\", datasetResponse.getCreateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"Update Time: %s\\n\", datasetResponse.getUpdateTime());\u00a0 \u00a0 \u00a0 System.out.format(\"Labels: %s\\n\", datasetResponse.getLabelsMap());\u00a0 \u00a0 }\u00a0 }}\n```Before trying this sample, follow the Node.js setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Node.js API reference documentation](/nodejs/docs/reference/aiplatform/latest) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/ai-platform/snippets/create-dataset-video.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\\\u00a0* (Not necessary if passing values as arguments)\u00a0*/// const datasetDisplayName = \"YOUR_DATASTE_DISPLAY_NAME\";// const project = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION';// Imports the Google Cloud Dataset Service Client libraryconst {DatasetServiceClient} = require('@google-cloud/aiplatform');// Specifies the location of the api endpointconst clientOptions = {\u00a0 apiEndpoint: 'us-central1-aiplatform.googleapis.com',};// Instantiates a clientconst datasetServiceClient = new DatasetServiceClient(clientOptions);async function createDatasetVideo() {\u00a0 // Configure the parent resource\u00a0 const parent = `projects/${project}/locations/${location}`;\u00a0 // Configure the dataset resource\u00a0 const dataset = {\u00a0 \u00a0 displayName: datasetDisplayName,\u00a0 \u00a0 metadataSchemaUri:\u00a0 \u00a0 \u00a0 'gs://google-cloud-aiplatform/schema/dataset/metadata/video_1.0.0.yaml',\u00a0 };\u00a0 const request = {\u00a0 \u00a0 parent,\u00a0 \u00a0 dataset,\u00a0 };\u00a0 // Create Dataset Request\u00a0 const [response] = await datasetServiceClient.createDataset(request);\u00a0 console.log(`Long running operation: ${response.name}`);\u00a0 // Wait for operation to complete\u00a0 await response.promise();\u00a0 const result = response.result;\u00a0 console.log('Create dataset video response');\u00a0 console.log(`Name : ${result.name}`);\u00a0 console.log(`Display name : ${result.displayName}`);\u00a0 console.log(`Metadata schema uri : ${result.metadataSchemaUri}`);\u00a0 console.log(`Metadata : ${JSON.stringify(result.metadata)}`);\u00a0 console.log(`Labels : ${JSON.stringify(result.labels)}`);}createDatasetVideo();\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\nThe following sample uses the Vertex AI SDK for Python to both create a dataset and import data. If you run this sample code, then you can skip the [Import datasection](#import-data) of this guide.\nThis particular sample imports data for classification. If your model has a different objective, then you must adjust the code.\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_and_import_dataset_video_sample.py) \n```\ndef create_and_import_dataset_video_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 src_uris: Union[str, List[str]],\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 ds = aiplatform.VideoDataset.create(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 gcs_source=src_uris,\u00a0 \u00a0 \u00a0 \u00a0 import_schema_uri=aiplatform.schema.dataset.ioformat.video.classification,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 ds.wait()\u00a0 \u00a0 print(ds.display_name)\u00a0 \u00a0 print(ds.resource_name)\u00a0 \u00a0 return ds\n```\n## Import dataAfter you create an empty dataset you can import your data into the dataset. If you used the Vertex AI SDK for Python to create the dataset, then you might have already imported data when you created the dataset. If so, you can skip this section.Before using any of the request data, make the following replacements:- : Region where dataset is to be stored. For example,`us-central1`.\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- : ID of the dataset.\n- : Path to the CSV or [JSON Lines](https://jsonlines.org/) file in Cloud Storage that lists data items stored in Cloud Storage to  use for model training; for import file formats and limitations, see [Preparing video data](/vertex-ai/docs/training-overview#video_data) .\n- : Designate either \"classification\", \"object_tracking\" or  \"action recognition\" model objective.\n- : Your project's automatically generated [project number](/resource-manager/docs/creating-managing-projects#identifiers) .\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/datasets/DATASET_ID:import\n```\nRequest JSON body:\n```\n{\n \"import_configs\": [ {\n  \"gcs_source\": {\n  \"uris\": \"IMPORT_FILE_URI\"\n  },\n  \"import_schema_uri\" : \"gs://google-cloud-aiplatform/schema/dataset/ioformat/automl_video_OBJECTIVE_io_format_1.0.0.yaml\"\n }\n ]\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/datasets/DATASET_ID:import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/datasets/DATASET_ID:import\" | Select-Object -Expand Content\n```\nYou should see output similar to the following. You can use the in the response to [get the status](#get-operation) of the operation.\n```\n{\n \"name\": \"projects/PROJECT_NUMBER/locations/LOCATION/datasets/DATASET_ID/operations/OPERATION_ID\",\n \"metadata\": {\n \"@type\": \"type.googleapis.com/google.cloud.aiplatform.v1.ImportDataOperationMetadata\",\n \"genericMetadata\": {\n  \"createTime\": \"2020-10-08T20:32:02.543801Z\",\n  \"updateTime\": \"2020-10-08T20:32:02.543801Z\"\n }\n }\n}\n```\nBefore trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/ImportDataVideoActionRecognitionSample.java) \n```\nimport com.google.api.gax.longrunning.OperationFuture;import com.google.cloud.aiplatform.v1.DatasetName;import com.google.cloud.aiplatform.v1.DatasetServiceClient;import com.google.cloud.aiplatform.v1.DatasetServiceSettings;import com.google.cloud.aiplatform.v1.GcsSource;import com.google.cloud.aiplatform.v1.ImportDataConfig;import com.google.cloud.aiplatform.v1.ImportDataOperationMetadata;import com.google.cloud.aiplatform.v1.ImportDataResponse;import java.io.IOException;import java.util.ArrayList;import java.util.List;import java.util.concurrent.ExecutionException;public class ImportDataVideoActionRecognitionSample {\u00a0 public static void main(String[] args)\u00a0 \u00a0 \u00a0 throws IOException, ExecutionException, InterruptedException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String project = \"PROJECT\";\u00a0 \u00a0 String datasetId = \"DATASET_ID\";\u00a0 \u00a0 String gcsSourceUri = \"GCS_SOURCE_URI\";\u00a0 \u00a0 importDataVideoActionRecognitionSample(project, datasetId, gcsSourceUri);\u00a0 }\u00a0 static void importDataVideoActionRecognitionSample(\u00a0 \u00a0 \u00a0 String project, String datasetId, String gcsSourceUri)\u00a0 \u00a0 \u00a0 throws IOException, ExecutionException, InterruptedException {\u00a0 \u00a0 DatasetServiceSettings settings =\u00a0 \u00a0 \u00a0 \u00a0 DatasetServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (DatasetServiceClient client = DatasetServiceClient.create(settings)) {\u00a0 \u00a0 \u00a0 GcsSource gcsSource = GcsSource.newBuilder().addUris(gcsSourceUri).build();\u00a0 \u00a0 \u00a0 ImportDataConfig importConfig0 =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ImportDataConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setGcsSource(gcsSource)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setImportSchemaUri(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"gs://google-cloud-aiplatform/schema/dataset/ioformat/\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 + \"video_action_recognition_io_format_1.0.0.yaml\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 List<ImportDataConfig> importConfigs = new ArrayList<>();\u00a0 \u00a0 \u00a0 importConfigs.add(importConfig0);\u00a0 \u00a0 \u00a0 DatasetName name = DatasetName.of(project, location, datasetId);\u00a0 \u00a0 \u00a0 OperationFuture<ImportDataResponse, ImportDataOperationMetadata> response =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 client.importDataAsync(name, importConfigs);\u00a0 \u00a0 \u00a0 // You can use OperationFuture.getInitialFuture to get a future representing the initial\u00a0 \u00a0 \u00a0 // response to the request, which contains information while the operation is in progress.\u00a0 \u00a0 \u00a0 System.out.format(\"Operation name: %s\\n\", response.getInitialFuture().get().getName());\u00a0 \u00a0 \u00a0 // OperationFuture.get() will block until the operation is finished.\u00a0 \u00a0 \u00a0 ImportDataResponse importDataResponse = response.get();\u00a0 \u00a0 \u00a0 System.out.format(\"importDataResponse: %s\\n\", importDataResponse);\u00a0 \u00a0 }\u00a0 }}\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/import_data_video_action_recognition_sample.py) \n```\ndef import_data_video_action_recognition_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 dataset_name: str,\u00a0 \u00a0 src_uris: Union[str, List[str]],\u00a0 \u00a0 sync: bool = True,):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 ds = aiplatform.VideoDataset(dataset_name=dataset_name)\u00a0 \u00a0 ds.import_data(\u00a0 \u00a0 \u00a0 \u00a0 gcs_source=src_uris,\u00a0 \u00a0 \u00a0 \u00a0 import_schema_uri=aiplatform.schema.dataset.ioformat.video.action_recognition,\u00a0 \u00a0 \u00a0 \u00a0 sync=sync,\u00a0 \u00a0 )\u00a0 \u00a0 ds.wait()\u00a0 \u00a0 print(ds.display_name)\u00a0 \u00a0 print(ds.resource_name)\u00a0 \u00a0 return ds\n```\n## Get operation status\nSome requests start long-running operations that require time to complete. These requests return an operation name, which you can use to view the operation's status or cancel the operation. Vertex AI provides helper methods to make calls against long-running operations. For more information, see [Working with long-runningoperations](/vertex-ai/docs/general/long-running-operations) .", "guide": "Vertex AI"}