{"title": "Vertex AI - Create a hyperparameter tuning job", "url": "https://cloud.google.com/vertex-ai/docs/training/using-hyperparameter-tuning", "abstract": "# Vertex AI - Create a hyperparameter tuning job\nTo see an example of how to use hyperparameter tuning in Vertex AI,  run the \"Run hyperparameter tuning for a TensorFlow model\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/hyperparameter_tuning_tensorflow.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Ftraining%2Fhyperparameter_tuning_tensorflow.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/training/hyperparameter_tuning_tensorflow.ipynb)\nHyperparameters are variables that govern the process of training a model, such as batch size or the number of hidden layers in a deep neural network. Hyperparameter tuning searches for the best combination of hyperparameter values by optimizing metric values across a series of trials. Metrics are scalar summaries that you add to your trainer, such as model accuracy.\n[Learn more about hyperparameter tuning onVertex AI](/vertex-ai/docs/training/hyperparameter-tuning-overview) . For a step-by-step example, refer to the [Vertex AI: Hyperparameter Tuning codelab](https://codelabs.developers.google.com/vertex_hyperparameter_tuning#0) .\nThis page shows you how to:\n- Prepare your training application for hyperparameter tuning by updating it to [accept hyperparameters as command-linearguments](#command-line-arguments) , and [report metric values toVertex AI](#report-metrics) .\n- [Create your hyperparameter training job](#create) . For more information about configuration options, see [understanding hyperparameter tuningconfiguration](#configuration) .", "content": "## Prepare your training application\nIn a hyperparameter tuning job, Vertex AI creates trials of your training job with different sets of hyperparameters and evaluates the effectiveness of a trial using the metrics you specified. Vertex AI passes hyperparameter values to your training application as command-line arguments. For Vertex AI to evaluate the effectiveness of a trial, your training application must report your metrics to Vertex AI.\nThe following sections describe:\n- How Vertex AI passes hyperparameters to your training application.\n- Options for passing metrics from your training application to Vertex AI.\nTo learn more about the requirements for custom training applications that run on Vertex AI, read [Training code requirements](/vertex-ai/docs/training/code-requirements) .\n### Handle the command-line arguments for the hyperparameters you want to tune\nVertex AI sets command-line arguments when it calls your training application. Make use of the command-line arguments in your code:\n- Define a name for each hyperparameter argument and parse it using whatever argument parser you prefer, such as [argparse](https://docs.python.org/3/library/argparse.html) . Use the same argument names when configuring your hyperparameter training job.For example, if your training application is a Python module named `my_trainer` and you are tuning a hyperparameter named `learning_rate` , Vertex AI starts each trial with a command like the following:```\npython3 -m my_trainer --learning_rate learning-rate-in-this-trial\n```Vertex AI determines the and passes it in using the `learning_rate` argument.\n- Assign the values from the command-line arguments to the hyperparameters in your training code.\n[Learn more about the requirements for parsing command-linearguments](/vertex-ai/docs/training/code-requirements#command-line-arguments) .\n### Report your metrics to Vertex AI\nTo report your metrics to Vertex AI, use the [cloudml-hypertunePython package](https://github.com/GoogleCloudPlatform/cloudml-hypertune) . This library provides helper functions for reporting metrics to Vertex AI.\n[Learn more about reporting hyperparameter metrics](/vertex-ai/docs/training/code-requirements#hp-tuning-metric) .\n## Create a hyperparameter tuning job\nDepending on what tool you want to use to create a `HyperparameterTuningJob` , select one of the following tabs:\nIn the Google Cloud console, you can't create a `HyperparameterTuningJob` resource directly. However, you can create a `TrainingPipeline` resource that creates a `HyperparameterTuningJob` .\nThe following instructions describe how to create a `TrainingPipeline` that creates a `HyperparameterTuningJob` and doesn't do anything else. If you want to use additional `TrainingPipeline` features, like training with a managed dataset, read [Creating trainingpipelines](/vertex-ai/docs/training/create-training-pipeline) .- In the Google Cloud console, in the Vertex AI section, go to the **Training pipelines** page. [Go to Training pipelines](https://console.cloud.google.com/vertex-ai/training/training-pipelines) \n- Click **add_boxCreate** to open the **Train new model** pane. **Note:** You can type [model.new](https://model.new) into a browser to go directly to the model creation page.\n- On the **Training method** step, specify the following settings:- In the **Dataset** drop-down list, select **No manageddataset.** \n- Select **Custom training (advanced)** .\nClick **Continue** .\n- On the **Model details** step, choose **Train new model** or **Train new version** . If you select train new model, enter a name of your choice, , for your model. Click **Continue** .\n- On the **Training container** step, specify the following settings:- Select [whether to use a Prebuilt container or a Customcontainer](/vertex-ai/docs/training/custom-training-methods#pre-built-custom) for training.\n- Depending on your choice, do one of the following:- If you want to use a prebuilt container for training, then provide Vertex AI with information it needs to use the training package that you have uploaded to Cloud Storage:- Use the **Model framework** and **Model framework version** drop-down lists to specify the [prebuiltcontainer](/vertex-ai/docs/training/pre-built-containers) that you want to use.\n- In the **Package location** field, specify the Cloud Storage URI of the [Python training application thatyou have created anduploaded](/vertex-ai/docs/training/create-python-pre-built-container) . This file usually ends with `.tar.gz` .\n- In the **Python module** field, enter the [module name of yourtraining application's entrypoint](/vertex-ai/docs/training/create-python-pre-built-container#python-modules) .\n- If you want to use a [custom container fortraining](/vertex-ai/docs/training/create-custom-container) , then in the **Container image** field, specify the Artifact Registry or Docker Hub URI of your container image.\n- In the **Model output directory** field, you may specify the Cloud Storage URI of a directory in a bucket that you have access to. The directory does not need to exist yet.This value gets passed to Vertex AI in the [baseOutputDirectory APIfield](/vertex-ai/docs/reference/rest/v1/CustomJobSpec#FIELDS.base_output_directory) , which sets [several environment variables that your training application can accesswhen it runs](/vertex-ai/docs/training/code-requirements#environment-variables) .\n- **Optional** : In the **Arguments** field, you can specify arguments for Vertex AI to use when it starts running your training code. The maximum length for all arguments combined is 100,000 characters. The behavior of these arguments differs depending on what type of container you are using:- If you are using a prebuilt container, then Vertex AI passes the arguments as command-line flags to your **Python module** .\n- If you are using a custom container, then Vertex AI [overrides your container's CMD instruction with thearguments](/vertex-ai/docs/training/configure-container-settings#configure) .Click **Continue** .\n- On the **Hyperparameter tuning** step, select **Enablehyperparameter tuning** checkbox and specify the following settings:- In the **New Hyperparameter** section, specify the **Parameter name** and **Type** of a hyperparameter that you want to tune. Depending on which type you specify, configure the additional hyperparameter settings that appear.Learn more about [hyperparameter types and theirconfigurations](/vertex-ai/docs/training/hyperparameter-tuning-overview#hyperparameters) .\n- If you want to tune more than one hyperparameter, click **Add newparameter** and repeat the previous step in the new section that appears.Repeat this for each hyperparameter that you want to tune.\n- In the **Metric to optimize** field and the **Goal** drop-down list, specify the name and goal of the [metric that you want tooptimize](/vertex-ai/docs/training/hyperparameter-tuning-overview#what_hyperparameter_tuning_optimizes) .\n- In the **Maximum number of trials** field, specify the [maximum number oftrials](/vertex-ai/docs/training/using-hyperparameter-tuning#understanding-trials) that you want Vertex AI to run for your hyperparameter tuning job.\n- In the **Maximum number of parallel trials** field, specify the [maximumnumber of trials to let Vertex AI run at the sametime](/vertex-ai/docs/training/using-hyperparameter-tuning#parallel-trials) .\n- In the **Search algorithm** drop-down list, specify a [searchalgorithm](/vertex-ai/docs/training/hyperparameter-tuning-overview#search_algorithms) for Vertex AI to use.\n- Ignore the **Enable early stopping** toggle, which has no effect.\nClick **Continue** .\n- On the **Compute and pricing** step, specify the following settings:- In the **Region** drop-down list, select a \" [region that supports customtraining](/vertex-ai/docs/general/locations) \"\n- In the **Worker pool 0** section, specify [computeresources](/vertex-ai/docs/training/configure-compute) to use for training.If you specify accelerators, [make sure the type of accelerator that youchoose is available in your selectedregion](/vertex-ai/docs/general/locations#region_considerations) .If you want to perform [distributedtraining](/vertex-ai/docs/training/distributed-training) , then click **Add moreworker pools** and specify an additional set of compute resources for each additional worker pool that you want.\nClick **Continue** .\n- On the **Prediction container** step, select **No predictioncontainer** .\n- Click **Start training** to start the custom training pipeline.\nThe following steps show how to use the Google Cloud CLI to create a `HyperparameterTuningJob` with a relatively minimal configuration. To learn about all the configuration options that you can use for this task, see the reference documentation for the [gcloud ai hp-tuning-jobs create command](/sdk/gcloud/reference/ai/hp-tuning-jobs/create) and the [HyperparameterTuningJob API resource](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs) .- Create a YAML file named `config.yaml` with some API fields that you want to specify for your new `HyerparameterTuningJob` :```\nstudySpec:\u00a0 metrics:\u00a0 - metricId: METRIC_ID\u00a0 \u00a0 goal: METRIC_GOAL\u00a0 parameters:\u00a0 - parameterId: HYPERPARAMETER_ID\u00a0 \u00a0 doubleValueSpec:\u00a0 \u00a0 \u00a0 minValue: DOUBLE_MIN_VALUE\u00a0 \u00a0 \u00a0 maxValue: DOUBLE_MAX_VALUEtrialJobSpec:\u00a0 workerPoolSpecs:\u00a0 \u00a0 - machineSpec:\u00a0 \u00a0 \u00a0 \u00a0 machineType: MACHINE_TYPE\u00a0 \u00a0 \u00a0 replicaCount: 1\u00a0 \u00a0 \u00a0 containerSpec:\u00a0 \u00a0 \u00a0 \u00a0 imageUri: CUSTOM_CONTAINER_IMAGE_URI\n```Replace the following:- `` : the name of a [hyperparameter metric](/vertex-ai/docs/training/hyperparameter-tuning-overview#what_hyperparameter_tuning_optimizes) to optimize. Your training code must [report this metric](#report-metrics) when it runs.\n- `` : the goal for your hyperparameter metric, either `MAXIMIZE` or `MINIMIZE` .\n- `` : the name of a hyperparameter to tune. Your training code must [parse a command-line flag with this name](#command-line-arguments) . For this example, the hyperparameter must take floating-point values. Learn about other [hyperparameter data types](/vertex-ai/docs/training/hyperparameter-tuning-overview#data-types) .\n- `` : The minimum value (a number) that you want Vertex AI to try for this hyperparameter.\n- `` : The maximum value (a number) that you want Vertex AI to try for this hyperparameter.\n- `` : the [type of VM](/vertex-ai/docs/training/configure-compute#machine-types) to use for training.\n- `` : the URI of a Docker container image with your training code. Learn how to [create a custom container image](/vertex-ai/docs/training/create-custom-container) .For this example, you must use a custom container. `HyperparameterTuningJob` resources also support [training code in a Python source distribution](/vertex-ai/docs/training/create-python-pre-built-container) instead of a custom container.\n- In the same directory as your `config.yaml` file, run the following shell command:```\ngcloud ai hp-tuning-jobs create \\\u00a0 \u00a0 --region=LOCATION \\\u00a0 \u00a0 --display-name=DISPLAY_NAME \\\u00a0 \u00a0 --max-trial-count=MAX_TRIAL_COUNT \\\u00a0 \u00a0 --parallel-trial-count=PARALLEL_TRIAL_COUNT \\\u00a0 \u00a0 --config=config.yaml\n```Replace the following:- `` : the region where you want to create the `HyperparameterTuningJob` . Use a [region that supports custom training](/vertex-ai/docs/general/locations#feature-availability) .\n- `` : a memorable display name of your choice for the `HyperparameterTuningJob` . Learn about [resource name requirements](/vertex-ai/docs/general/resource-naming) .\n- `` : the [maximum number of trials to run](#understanding-trials) .\n- `` : the [maximum number of trials to run in parallel](#parallel-trials) .Use the following code sample to create a hyperparameter tuning job using the [create method of the hyperparameterTuningJobresource](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/create) .\nBefore using any of the request data, make the following replacements:- ``: the region where you want to create the`HyperparameterTuningJob`. Use a [region that supports custom training](/vertex-ai/docs/general/locations#feature-availability) .\n- : Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) .\n- ``: a memorable display name of your choice for the`HyperparameterTuningJob`. Learn about [resource name requirements](/vertex-ai/docs/general/resource-naming) .\n- Specify your metrics:- ``: the name of a [hyperparameter metric](/vertex-ai/docs/training/hyperparameter-tuning-overview#what_hyperparameter_tuning_optimizes) to optimize. Your training code must [report this metric](#report-metrics) when it runs.\n- ``: the goal for your hyperparameter metric, either`MAXIMIZE`or`MINIMIZE`.\n- Specify your hyperparameters:- ``: the name of a hyperparameter to tune. Your training code must [parse a command-line flag with this name](#command-line-arguments) .\n- : (Optional.) How the parameter should be scaled. Leave unset   for CATEGORICAL parameters. Can be`UNIT_LINEAR_SCALE`,`UNIT_LOG_SCALE`,`UNIT_REVERSE_LOG_SCALE`, or`SCALE_TYPE_UNSPECIFIED`\n- If this hyperparameter's type is DOUBLE, specify the minimum ()   and maximum () values for this hyperparameter.\n- If this hyperparameter's type is INTEGER, specify the minimum   () and maximum () values for   this hyperparameter.\n- If this hyperparameter's type is CATEGORICAL, specify the acceptable values   () as an array of strings.\n- If this hyperparameter's type is DISCRETE, specify the acceptable values   () as an array of numbers.\n- Specify conditional hyperparameters. Conditional hyperparameters are added to a trial when   the parent hyperparameter's value matches the condition you specify. Learn more about [   conditional hyperparameters](/vertex-ai/docs/training/hyperparameter-tuning-overview#conditional_hyperparameters) .- : The`ParameterSpec`of the conditional    parameter. This specification includes the parameter's name, scale, range of values,    and any conditional parameters that depend on this hyperparameter.\n- If the parent hyperparameter's type is INTEGER, specify a list of integers as the. If the parent hyperparameter's value matches one of the    values specified, this conditional parameter is added to the trial.\n- If the parent hyperparameter's type is CATEGORICAL, specify a list of categories as    the. If the parent hyperparameter's value matches one of    the values specified, this conditional parameter is added to the trial.\n- If the parent hyperparameter's type is DISCRETE, specify a list of integers as the. If the parent hyperparameter's value matches one of    the values specified, this conditional parameter is added to the trial.\n- : (Optional.) The search algorithm to use in this hyperparameter tuning  job. Can be`ALGORITHM_UNSPECIFIED`,`GRID_SEARCH`, or`RANDOM_SEARCH`.\n- ``: the [maximum number of trials to run](#understanding-trials) .\n- ``: the [maximum number of trials to run in parallel](#parallel-trials) .\n- : The number of jobs that can fail before the hyperparameter  tuning job fails.\n- Define the trial custom training job:- ``: the [type of VM](/vertex-ai/docs/training/configure-compute#machine-types) to use for training.\n- : (Optional.) The type of accelerator to attach to each   trial.\n- : (Optional.) The number of accelerators to attach to   each trial.\n- : The number of worker replicas to use for each trial.\n- If your training application runs in a custom container, specify the following:- ``: the URI of a Docker container image with your training code. Learn how to [create a custom container image](/vertex-ai/docs/training/create-custom-container) .\n- : (Optional.) The command to be invoked when the    container is started. This command overrides the container's default entrypoint.\n- : (Optional.) The arguments to be passed when    starting the container.\n- If your training application is a Python package that runs in a prebuilt container,   specify the following:- : The URI of the container image that runs the    provided python package. Learn more about [prebuilt containers for training](/vertex-ai/docs/training/pre-built-containers) .\n- : The Cloud Storage location of the Python    package files which are the training program and its dependent packages. The maximum    number of package URIs is 100.\n- : The Python module name to run after installing the packages.\n- : (Optional.) Command-line arguments to be passed to    the Python module.\n- : (Optional.) The service account that Vertex AI   will use to run your code. Learn more about [  attaching a custom service account](/vertex-ai/docs/general/custom-service-account) .\n- : (Optional.) The maximum running time for each trial.\n- Specify theandfor any labels that you want to  apply to this hyperparameter tuning job.\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/projects/PROJECT/locations/LOCATION/hyperparameterTuningJobs\n```\nRequest JSON body:\n```\n{\n \"displayName\": DISPLAY_NAME,\n \"studySpec\": {\n \"metrics\": [  {\n  \"metricId\": METRIC_ID,\n  \"goal\": METRIC_GOAL\n  }\n ],\n \"parameters\": [  {\n  \"parameterId\": PARAMETER_ID,\n  \"scaleType\": PARAMETER_SCALE,\n  // Union field parameter_value_spec can be only one of the following:\n  \"doubleValueSpec\": {\n   \"minValue\": DOUBLE_MIN_VALUE,\n   \"maxValue\": DOUBLE_MAX_VALUE\n  },\n  \"integerValueSpec\": {\n   \"minValue\": INTEGER_MIN_VALUE,\n   \"maxValue\": INTEGER_MAX_VALUE\n  },\n  \"categoricalValueSpec\": {\n   \"values\": [    CATEGORICAL_VALUES\n   ]\n  },\n  \"discreteValueSpec\": {\n   \"values\": [    DISCRETE_VALUES\n   ]\n  }\n  // End of list of possible types for union field parameter_value_spec.\n  \"conditionalParameterSpecs\": [   \"parameterSpec\": {\n    CONDITIONAL_PARAMETER\n   }\n   // Union field parent_value_condition can be only one of the following:\n   \"parentIntValues\": {\n    \"values\": [INTEGERS_TO_MATCH]\n   }\n   \"parentCategoricalValues\": {\n    \"values\": [CATEGORIES_TO_MATCH]\n   }\n   \"parentDiscreteValues\": {\n    \"values\": [DISCRETE_VALUES_TO_MATCH]\n   }\n   // End of list of possible types for union field parent_value_condition.\n  ]\n  }\n ],\n \"ALGORITHM\": ALGORITHM\n },\n \"maxTrialCount\": MAX_TRIAL_COUNT,\n \"parallelTrialCount\": PARALLEL_TRIAL_COUNT,\n \"maxFailedTrialCount\": MAX_FAILED_TRIAL_COUNT,\n \"trialJobSpec\": {\n  \"workerPoolSpecs\": [  {\n   \"machineSpec\": {\n   \"machineType\": MACHINE_TYPE,\n   \"acceleratorType\": ACCELERATOR_TYPE,\n   \"acceleratorCount\": ACCELERATOR_COUNT\n   },\n   \"replicaCount\": REPLICA_COUNT,\n   // Union field task can be only one of the following:\n   \"containerSpec\": {\n   \"imageUri\": CUSTOM_CONTAINER_IMAGE_URI,\n   \"command\": [    CUSTOM_CONTAINER_COMMAND\n   ],\n   \"args\": [    CUSTOM_CONTAINER_ARGS\n   ]\n   },\n   \"pythonPackageSpec\": {\n   \"executorImageUri\": PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,\n   \"packageUris\": [    PYTHON_PACKAGE_URIS\n   ],\n   \"pythonModule\": PYTHON_MODULE,\n   \"args\": [    PYTHON_PACKAGE_ARGS\n   ]\n   }\n   // End of list of possible types for union field task.\n  }\n  ],\n  \"scheduling\": {\n  \"TIMEOUT\": TIMEOUT\n  },\n  \"serviceAccount\": SERVICE_ACCOUNT\n },\n \"labels\": {\n LABEL_NAME_1\": LABEL_VALUE_1,\n LABEL_NAME_2\": LABEL_VALUE_2\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/12345/locations/us-central1/hyperparameterTuningJobs/6789\",\n \"displayName\": \"myHyperparameterTuningJob\",\n \"studySpec\": {\n \"metrics\": [  {\n  \"metricId\": \"myMetric\",\n  \"goal\": \"MINIMIZE\"\n  }\n ],\n \"parameters\": [  {\n  \"parameterId\": \"myParameter1\",\n  \"integerValueSpec\": {\n   \"minValue\": \"1\",\n   \"maxValue\": \"128\"\n  },\n  \"scaleType\": \"UNIT_LINEAR_SCALE\"\n  },\n  {\n  \"parameterId\": \"myParameter2\",\n  \"doubleValueSpec\": {\n   \"minValue\": 1e-07,\n   \"maxValue\": 1\n  },\n  \"scaleType\": \"UNIT_LINEAR_SCALE\"\n  }\n ],\n \"ALGORITHM\": \"RANDOM_SEARCH\"\n },\n \"maxTrialCount\": 20,\n \"parallelTrialCount\": 1,\n \"trialJobSpec\": {\n \"workerPoolSpecs\": [  {\n  \"machineSpec\": {\n   \"machineType\": \"n1-standard-4\"\n  },\n  \"replicaCount\": \"1\",\n  \"pythonPackageSpec\": {\n   \"executorImageUri\": \"us-docker.pkg.dev/vertex-ai/training/training-tf-cpu.2-1:latest\",\n   \"packageUris\": [   \"gs://my-bucket/my-training-application/trainer.tar.bz2\"\n   ],\n   \"pythonModule\": \"my-trainer.trainer\"\n  }\n  }\n ]\n }\n}\n```\nBefore trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/CreateHyperparameterTuningJobPythonPackageSample.java) \n```\nimport com.google.cloud.aiplatform.v1.AcceleratorType;import com.google.cloud.aiplatform.v1.CustomJobSpec;import com.google.cloud.aiplatform.v1.HyperparameterTuningJob;import com.google.cloud.aiplatform.v1.JobServiceClient;import com.google.cloud.aiplatform.v1.JobServiceSettings;import com.google.cloud.aiplatform.v1.LocationName;import com.google.cloud.aiplatform.v1.MachineSpec;import com.google.cloud.aiplatform.v1.PythonPackageSpec;import com.google.cloud.aiplatform.v1.StudySpec;import com.google.cloud.aiplatform.v1.StudySpec.MetricSpec;import com.google.cloud.aiplatform.v1.StudySpec.MetricSpec.GoalType;import com.google.cloud.aiplatform.v1.StudySpec.ParameterSpec;import com.google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec;import com.google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ConditionalParameterSpec.DiscreteValueCondition;import com.google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DiscreteValueSpec;import com.google.cloud.aiplatform.v1.StudySpec.ParameterSpec.DoubleValueSpec;import com.google.cloud.aiplatform.v1.StudySpec.ParameterSpec.ScaleType;import com.google.cloud.aiplatform.v1.WorkerPoolSpec;import java.io.IOException;import java.util.Arrays;public class CreateHyperparameterTuningJobPythonPackageSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String project = \"PROJECT\";\u00a0 \u00a0 String displayName = \"DISPLAY_NAME\";\u00a0 \u00a0 String executorImageUri = \"EXECUTOR_IMAGE_URI\";\u00a0 \u00a0 String packageUri = \"PACKAGE_URI\";\u00a0 \u00a0 String pythonModule = \"PYTHON_MODULE\";\u00a0 \u00a0 createHyperparameterTuningJobPythonPackageSample(\u00a0 \u00a0 \u00a0 \u00a0 project, displayName, executorImageUri, packageUri, pythonModule);\u00a0 }\u00a0 static void createHyperparameterTuningJobPythonPackageSample(\u00a0 \u00a0 \u00a0 String project,\u00a0 \u00a0 \u00a0 String displayName,\u00a0 \u00a0 \u00a0 String executorImageUri,\u00a0 \u00a0 \u00a0 String packageUri,\u00a0 \u00a0 \u00a0 String pythonModule)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 JobServiceSettings settings =\u00a0 \u00a0 \u00a0 \u00a0 JobServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (JobServiceClient client = JobServiceClient.create(settings)) {\u00a0 \u00a0 \u00a0 // study spec\u00a0 \u00a0 \u00a0 MetricSpec metric =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MetricSpec.newBuilder().setMetricId(\"val_rmse\").setGoal(GoalType.MINIMIZE).build();\u00a0 \u00a0 \u00a0 // decay\u00a0 \u00a0 \u00a0 DoubleValueSpec doubleValueSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DoubleValueSpec.newBuilder().setMinValue(1e-07).setMaxValue(1).build();\u00a0 \u00a0 \u00a0 ParameterSpec parameterDecaySpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ParameterSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParameterId(\"decay\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDoubleValueSpec(doubleValueSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setScaleType(ScaleType.UNIT_LINEAR_SCALE)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 Double[] decayValues = {32.0, 64.0};\u00a0 \u00a0 \u00a0 DiscreteValueCondition discreteValueDecay =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DiscreteValueCondition.newBuilder().addAllValues(Arrays.asList(decayValues)).build();\u00a0 \u00a0 \u00a0 ConditionalParameterSpec conditionalParameterDecay =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ConditionalParameterSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParameterSpec(parameterDecaySpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParentDiscreteValues(discreteValueDecay)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // learning rate\u00a0 \u00a0 \u00a0 ParameterSpec parameterLearningSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ParameterSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParameterId(\"learning_rate\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDoubleValueSpec(doubleValueSpec) // Use the same min/max as for decay\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setScaleType(ScaleType.UNIT_LINEAR_SCALE)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 Double[] learningRateValues = {4.0, 8.0, 16.0};\u00a0 \u00a0 \u00a0 DiscreteValueCondition discreteValueLearning =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DiscreteValueCondition.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addAllValues(Arrays.asList(learningRateValues))\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 ConditionalParameterSpec conditionalParameterLearning =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ConditionalParameterSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParameterSpec(parameterLearningSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParentDiscreteValues(discreteValueLearning)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // batch size\u00a0 \u00a0 \u00a0 Double[] batchSizeValues = {4.0, 8.0, 16.0, 32.0, 64.0, 128.0};\u00a0 \u00a0 \u00a0 DiscreteValueSpec discreteValueSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DiscreteValueSpec.newBuilder().addAllValues(Arrays.asList(batchSizeValues)).build();\u00a0 \u00a0 \u00a0 ParameterSpec parameter =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ParameterSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParameterId(\"batch_size\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDiscreteValueSpec(discreteValueSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setScaleType(ScaleType.UNIT_LINEAR_SCALE)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addConditionalParameterSpecs(conditionalParameterDecay)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addConditionalParameterSpecs(conditionalParameterLearning)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // trial_job_spec\u00a0 \u00a0 \u00a0 MachineSpec machineSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 MachineSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMachineType(\"n1-standard-4\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setAcceleratorType(AcceleratorType.NVIDIA_TESLA_K80)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setAcceleratorCount(1)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 PythonPackageSpec pythonPackageSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 PythonPackageSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setExecutorImageUri(executorImageUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addPackageUris(packageUri)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setPythonModule(pythonModule)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 WorkerPoolSpec workerPoolSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 WorkerPoolSpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMachineSpec(machineSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setReplicaCount(1)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setPythonPackageSpec(pythonPackageSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 StudySpec studySpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 StudySpec.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addMetrics(metric)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .addParameters(parameter)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setAlgorithm(StudySpec.Algorithm.RANDOM_SEARCH)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 CustomJobSpec trialJobSpec =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 CustomJobSpec.newBuilder().addWorkerPoolSpecs(workerPoolSpec).build();\u00a0 \u00a0 \u00a0 // hyperparameter_tuning_job\u00a0 \u00a0 \u00a0 HyperparameterTuningJob hyperparameterTuningJob =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HyperparameterTuningJob.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setDisplayName(displayName)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setMaxTrialCount(4)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setParallelTrialCount(2)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setStudySpec(studySpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setTrialJobSpec(trialJobSpec)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 LocationName parent = LocationName.of(project, location);\u00a0 \u00a0 \u00a0 HyperparameterTuningJob response =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 client.createHyperparameterTuningJob(parent, hyperparameterTuningJob);\u00a0 \u00a0 \u00a0 System.out.format(\"response: %s\\n\", response);\u00a0 \u00a0 \u00a0 System.out.format(\"Name: %s\\n\", response.getName());\u00a0 \u00a0 }\u00a0 }}\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_hyperparameter_tuning_job_sample.py) \n```\nfrom google.cloud import aiplatformfrom google.cloud.aiplatform import hyperparameter_tuning as hptdef create_hyperparameter_tuning_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 staging_bucket: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 container_uri: str,):\u00a0 \u00a0 aiplatform.init(project=project, location=location, staging_bucket=staging_bucket)\u00a0 \u00a0 worker_pool_specs = [\u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"machine_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"machine_type\": \"n1-standard-4\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_type\": \"NVIDIA_TESLA_K80\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"replica_count\": 1,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"container_spec\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"image_uri\": container_uri,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"command\": [],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"args\": [],\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 ]\u00a0 \u00a0 custom_job = aiplatform.CustomJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name='custom_job',\u00a0 \u00a0 \u00a0 \u00a0 worker_pool_specs=worker_pool_specs,\u00a0 \u00a0 )\u00a0 \u00a0 hpt_job = aiplatform.HyperparameterTuningJob(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 custom_job=custom_job,\u00a0 \u00a0 \u00a0 \u00a0 metric_spec={\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'loss': 'minimize',\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 parameter_spec={\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'lr': hpt.DoubleParameterSpec(min=0.001, max=0.1, scale='log'),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'units': hpt.IntegerParameterSpec(min=4, max=128, scale='linear'),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'activation': hpt.CategoricalParameterSpec(values=['relu', 'selu']),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 'batch_size': hpt.DiscreteParameterSpec(values=[128, 256], scale='linear')\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 max_trial_count=128,\u00a0 \u00a0 \u00a0 \u00a0 parallel_trial_count=8,\u00a0 \u00a0 \u00a0 \u00a0 labels={'my_key': 'my_value'},\u00a0 \u00a0 )\u00a0 \u00a0 hpt_job.run()\u00a0 \u00a0 print(hpt_job.resource_name)\u00a0 \u00a0 return hpt_job\n```\n## Hyperparameter training job configuration\nHyperparameter tuning jobs search for the best combination of hyperparameters to optimize your metrics. Hyperparameter tuning jobs do this by running multiple trials of your training application with different sets of hyperparameters.\nWhen you configure a hyperparameter tuning job, you must specify the following details:\n- The hyperparameters you want to tune and the metrics that you want to use to evaluate trials. [Learn more about selecting hyperparameters and metrics](/vertex-ai/docs/training/hyperparameter-tuning-overview) .\n- Details about the number of trials to run as a part of this tuning job, such as the following:- [The maximum number of trials to run](#understanding-trials) .\n- [The number of trials that can run in parallel](#parallel-trials) .\n- [The maximum number of trials that are allowed to fail before the jobstops early](#failed-trials) .\n- Details about the custom training job that is run for each trial, such as the following:- The [machine type](/vertex-ai/docs/training/configure-compute) that the trials jobs run in and the accelerators that the job uses. **Note:** Currently, Vertex AI does not support hyperparameter tuning jobs that require TPUs.\n- The details of the custom container or Python package job. [Learn more about training code requirements](/vertex-ai/docs/training/code-requirements) .\n### Limit the number of trials\nDecide how many trials you want to allow the service to run and set the `maxTrialCount` value in the [HyperparameterTuningJob](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs#resource:-hyperparametertuningjob) object.\nThere are two competing interests to consider when deciding how many trials to allow:\n- time (and therefore cost)\n- accuracy\nIncreasing the number of trials generally yields better results, but it is not always so. Usually, there is a point of diminishing returns after which additional trials have little or no effect on the accuracy. Before starting a job with a large number of trials, you may want to start with a small number of trials to gauge the effect your chosen hyperparameters have on your model's accuracy.\nTo get the most out of hyperparameter tuning, you shouldn't set your maximum value lower than ten times the number of hyperparameters you use.\n### Parallel trials\nYou can specify how many trials can run in parallel by setting `parallelTrialCount` in the [HyperparameterTuningJob](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs#resource:-hyperparametertuningjob) .\nRunning parallel trials has the benefit of reducing the time the training job takes (real time\u2014the total processing time required is not typically changed). However, running in parallel can reduce the effectiveness of the tuning job overall. That is because hyperparameter tuning uses the results of previous trials to inform the values to assign to the hyperparameters of subsequent trials. When running in parallel, some trials start without having the benefit of the results of any trials still running.\nIf you use parallel trials, the hyperparameter tuning service provisions multiple training processing clusters (or multiple individual machines in the case of a single-process trainer). The work pool spec that you set for your job is used for each individual training cluster.\n### Handle failed trials\nIf your hyperparameter tuning trials exit with errors, you might want to end the training job early. Set the `maxFailedTrialCount` field in the [HyperparameterTuningJob](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs#resource:-hyperparametertuningjob) to the number of failed trials that you want to allow. After this number of trials fails, Vertex AI ends the training job. The `maxFailedTrialCount` value must be less than or equal to `maxTrialCount` .\nIf you do not set `maxFailedTrialCount` , or if you set it to `0` , Vertex AI uses the following rules to handle failing trials:\n- If the first trial of your job fails, Vertex AI ends the job immediately. Failure during the first trial suggests a problem in your training code, so further trials are also likely to fail. Ending the job lets you diagnose the problem without waiting for more trials and incurring greater costs.\n- If the first trial succeeds, Vertex AI might end the job after failures during subsequent trials based on one of the following criteria:- The number of failed trials has grown too high.\n- The ratio of failed trials to successful trials has grown too high.These rules are subject to change. To ensure a specific behavior, set the `maxFailedTrialCount` field.\n## Manage hyperparameter tuning jobs\nThe following sections describe how to manage your hyperparameter tuning jobs.\n### Retrieve information about a hyperparameter tuning job\nThe following code samples demonstrate how to retrieve a hyperparameter tuning job.\nUse the [gcloud ai hp-tuning-jobs describe command](/sdk/gcloud/reference/ai/hp-tuning-jobs/describe) :\n```\ngcloud ai hp-tuning-jobs describe ID_OR_NAME \\\u00a0 \u00a0 --region=LOCATION\n```\nReplace the following:- `` : either the [name](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/get) or the numerical ID of the `HyperparameterTuningJob` . (The ID is the last part of the name.)You might have seen the ID or name when you created the `HyperparameterTuningJob` . If you don't know the ID or name, you can run the [gcloud ai hp-tuning-jobs list command](/sdk/gcloud/reference/ai/hp-tuning-jobs/list) and look for the appropriate resource.\n- `` : the region where the `HyperparameterTuningJob` was created.\nUse the following code sample to retrieve a hyperparameter tuning job using the [get method of the hyperparameterTuningJobresource](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/get) .\nBefore using any of the request data, make the following replacements:- ``: the region where the`HyperparameterTuningJob`was created.\n- : The name of the hyperparameter tuning job. The job name uses the following  format`projects/{project}/LOCATIONS/{LOCATION}/hyperparameterTuningJobs/{hyperparameterTuningJob}`.\nHTTP method and URL:\n```\nGET https://LOCATION-aiplatform.googleapis.com/v1/NAME\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"name\": \"projects/12345/LOCATIONs/us-central1/hyperparameterTuningJobs/6789\",\n \"displayName\": \"my-hyperparameter-tuning-job\",\n \"studySpec\": {\n \"metrics\": [  {\n  \"metricId\": \"my_metric\",\n  \"goal\": \"MINIMIZE\"\n  }\n ],\n \"parameters\": [  {\n  \"parameterId\": \"my_parameter\",\n  \"doubleValueSpec\": {\n   \"minValue\": 1e-05,\n   \"maxValue\": 1\n  }\n  }\n ]\n },\n \"maxTrialCount\": 3,\n \"parallelTrialCount\": 1,\n \"trialJobSpec\": {\n \"workerPoolSpecs\": [  {\n  \"machineSpec\": {\n   \"machineType\": \"n1-standard-4\"\n  },\n  \"replicaCount\": \"1\",\n  \"pythonPackageSpec\": {\n   \"executorImageUri\": \"us-docker.pkg.dev/vertex-ai/training/training-tf-cpu.2-1:latest\",\n   \"packageUris\": [   \"gs://my-bucket/my-training-application/trainer.tar.bz2\"\n   ],\n   \"pythonModule\": \"my-trainer.trainer\"\n  }\n  }\n ]\n },\n \"trials\": [ {\n  \"id\": \"2\",\n  \"state\": \"SUCCEEDED\",\n  \"parameters\": [  {\n   \"parameterId\": \"my_parameter\",\n   \"value\": 0.71426874725564571\n  }\n  ],\n  \"finalMeasurement\": {\n  \"stepCount\": \"2\",\n  \"metrics\": [   {\n   \"metricId\": \"my_metric\",\n   \"value\": 0.30007445812225342\n   }\n  ]\n  },\n  \"startTime\": \"2020-09-09T23:39:15.549112551Z\",\n  \"endTime\": \"2020-09-09T23:47:08Z\"\n },\n {\n  \"id\": \"3\",\n  \"state\": \"SUCCEEDED\",\n  \"parameters\": [  {\n   \"parameterId\": \"my_parameter\",\n   \"value\": 0.3078893356622992\n  }\n  ],\n  \"finalMeasurement\": {\n  \"stepCount\": \"2\",\n  \"metrics\": [   {\n   \"metricId\": \"my_metric\",\n   \"value\": 0.30000102519989014\n   }\n  ]\n  },\n  \"startTime\": \"2020-09-09T23:49:22.451699360Z\",\n  \"endTime\": \"2020-09-09T23:57:15Z\"\n },\n {\n  \"id\": \"1\",\n  \"state\": \"SUCCEEDED\",\n  \"parameters\": [  {\n   \"parameterId\": \"my_parameter\",\n   \"value\": 0.500005\n  }\n  ],\n  \"finalMeasurement\": {\n  \"stepCount\": \"2\",\n  \"metrics\": [   {\n   \"metricId\": \"my_metric\",\n   \"value\": 0.30005377531051636\n   }\n  ]\n  },\n  \"startTime\": \"2020-09-09T23:23:12.283374629Z\",\n  \"endTime\": \"2020-09-09T23:36:56Z\"\n }\n ],\n \"state\": \"JOB_STATE_SUCCEEDED\",\n \"createTime\": \"2020-09-09T23:22:31.777386Z\",\n \"startTime\": \"2020-09-09T23:22:34Z\",\n \"endTime\": \"2020-09-10T01:31:24.271307Z\",\n \"updateTime\": \"2020-09-10T01:31:24.271307Z\"\n}\n```\nBefore trying this sample, follow the Java setup instructions in the [Vertex AI quickstart using   client libraries](/vertex-ai/docs/start/client-libraries) .       For more information, see the [Vertex AI Java API reference documentation](/java/docs/reference/google-cloud-aiplatform/latest/com.google.cloud.aiplatform.v1) .\nTo authenticate to Vertex AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/aiplatform/src/main/java/aiplatform/GetHyperparameterTuningJobSample.java) \n```\nimport com.google.cloud.aiplatform.v1.HyperparameterTuningJob;import com.google.cloud.aiplatform.v1.HyperparameterTuningJobName;import com.google.cloud.aiplatform.v1.JobServiceClient;import com.google.cloud.aiplatform.v1.JobServiceSettings;import java.io.IOException;public class GetHyperparameterTuningJobSample {\u00a0 public static void main(String[] args) throws IOException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String project = \"PROJECT\";\u00a0 \u00a0 String hyperparameterTuningJobId = \"HYPERPARAMETER_TUNING_JOB_ID\";\u00a0 \u00a0 getHyperparameterTuningJobSample(project, hyperparameterTuningJobId);\u00a0 }\u00a0 static void getHyperparameterTuningJobSample(String project, String hyperparameterTuningJobId)\u00a0 \u00a0 \u00a0 throws IOException {\u00a0 \u00a0 JobServiceSettings settings =\u00a0 \u00a0 \u00a0 \u00a0 JobServiceSettings.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setEndpoint(\"us-central1-aiplatform.googleapis.com:443\")\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 String location = \"us-central1\";\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background resources.\u00a0 \u00a0 try (JobServiceClient client = JobServiceClient.create(settings)) {\u00a0 \u00a0 \u00a0 HyperparameterTuningJobName name =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 HyperparameterTuningJobName.of(project, location, hyperparameterTuningJobId);\u00a0 \u00a0 \u00a0 HyperparameterTuningJob response = client.getHyperparameterTuningJob(name);\u00a0 \u00a0 \u00a0 System.out.format(\"response: %s\\n\", response);\u00a0 \u00a0 }\u00a0 }}\n```To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/get_hyperparameter_tuning_job_sample.py) \n```\n# Copyright 2022 Google LLC\n## Licensed under the Apache License, Version 2.0 (the \"License\");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at\n## \u00a0 \u00a0 https://www.apache.org/licenses/LICENSE-2.0\n## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an \"AS IS\" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.from google.cloud import aiplatformdef get_hyperparameter_tuning_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 hyperparameter_tuning_job_id: str,\u00a0 \u00a0 location: str = \"us-central1\",):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 hpt_job = aiplatform.HyperparameterTuningJob.get(\u00a0 \u00a0 \u00a0 \u00a0 resource_name=hyperparameter_tuning_job_id,\u00a0 \u00a0 )\u00a0 \u00a0 return hpt_job\n```\n### Cancel a hyperparameter tuning job\nThe following code samples demonstrate how to cancel a hyperparameter tuning job.\nUse the [gcloud ai hp-tuning-jobs cancel command](/sdk/gcloud/reference/ai/hp-tuning-jobs/cancel) :\n```\ngcloud ai hp-tuning-jobs cancel ID_OR_NAME \\\u00a0 \u00a0 --region=LOCATION\n```\nReplace the following:- `` : either the [name](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/cancel) or the numerical ID of the `HyperparameterTuningJob` . (The ID is the last part of the name.)You might have seen the ID or name when you created the `HyperparameterTuningJob` . If you don't know the ID or name, you can run the [gcloud ai hp-tuning-jobs list command](/sdk/gcloud/reference/ai/hp-tuning-jobs/list) and look for the appropriate resource.\n- `` : the region where the `HyperparameterTuningJob` was created.\nUse the following code sample to cancel a hyperparameter tuning job using the [cancel method of the hyperparameterTuningJobresource](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/cancel) .\nBefore using any of the request data, make the following replacements:- ``: the region where the`HyperparameterTuningJob`was created.\n- : The name of the hyperparameter tuning job. The job name uses the following  format`projects/{project}/locations/{location}/hyperparameterTuningJobs/{hyperparameterTuningJob}`.\nHTTP method and URL:\n```\nPOST https://LOCATION-aiplatform.googleapis.com/v1/NAME:cancel\n```\nTo send your request, expand one of these options:You should receive a successful status code (2xx) and an empty response.To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/cancel_hyperparameter_tuning_job_sample.py) \n```\nfrom google.cloud import aiplatformdef cancel_hyperparameter_tuning_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 hyperparameter_tuning_job_id: str,\u00a0 \u00a0 location: str = \"us-central1\",):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 hpt_job = aiplatform.HyperparameterTuningJob.get(\u00a0 \u00a0 \u00a0 \u00a0 resource_name=hyperparameter_tuning_job_id,\u00a0 \u00a0 )\u00a0 \u00a0 hpt_job.cancel()\n```\n### Delete a hyperparameter tuning job\nThe following code samples demonstrate how to delete a hyperparameter tuning job using the Vertex AI SDK for Python and the REST API.\nUse the following code sample to delete a hyperparameter tuning job using the [delete method of the hyperparameterTuningJobresource](/vertex-ai/docs/reference/rest/v1/projects.locations.hyperparameterTuningJobs/delete) .\nBefore using any of the request data, make the following replacements:- : Your region.\n- : The name of the hyperparameter tuning job. The job name uses the following  format`projects/{project}/LOCATIONs/{LOCATION}/hyperparameterTuningJobs/{hyperparameterTuningJob}`.\nHTTP method and URL:\n```\nDELETE https://LOCATION-aiplatform.googleapis.com/v1/NAME\n```\nTo send your request, expand one of these options:You should receive a successful status code (2xx) and an empty response.To learn how to install or update the Python, see [Install the Vertex AI SDK for Python](/vertex-ai/docs/start/use-vertex-ai-python-sdk) .    For more information, see the [   Python API reference documentation](/python/docs/reference/aiplatform/latest) .\n [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/delete_hyperparameter_tuning_job_sample.py) \n```\nfrom google.cloud import aiplatformdef delete_hyperparameter_tuning_job_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 hyperparameter_tuning_job_id: str,\u00a0 \u00a0 location: str = \"us-central1\",):\u00a0 \u00a0 aiplatform.init(project=project, location=location)\u00a0 \u00a0 hpt_job = aiplatform.HyperparameterTuningJob.get(\u00a0 \u00a0 \u00a0 \u00a0 resource_name=hyperparameter_tuning_job_id,\u00a0 \u00a0 )\u00a0 \u00a0 hpt_job.delete()\n```\n## What's next\n- Learn more about [the concepts involved in hyperparametertuning](/vertex-ai/docs/training/hyperparameter-tuning-overview) .", "guide": "Vertex AI"}