{"title": "Vertex AI - Introduction to Vertex AI Pipelines", "url": "https://cloud.google.com/vertex-ai/docs/pipelines/introduction", "abstract": "# Vertex AI - Introduction to Vertex AI Pipelines\nTo learn more,  run the \"Learn how to build Python function-based Kubeflow pipeline   components\" Jupyter notebook in one of the following  environments: [Openin Colab](https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/lightweight_functions_component_io_kfp.ipynb) | [Openin Vertex AI Workbench user-managed notebooks](https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https%3A%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fpipelines%2Flightweight_functions_component_io_kfp.ipynb) | [View on GitHub](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/lightweight_functions_component_io_kfp.ipynb)\nVertex AI Pipelines lets you automate, monitor, and govern your machine learning (ML) systems in a serverless manner by using ML pipelines to orchestrate your ML workflows. You can batch run ML pipelines defined using the Kubeflow Pipelines (Kubeflow Pipelines) or the TensorFlow Extended (TFX) framework. To learn how to choose a framework for defining your ML pipeline, see [Interfaces to define a pipeline](/vertex-ai/docs/pipelines/interfaces#define) .\nThis page provides an overview of the following:\n- [What is an ML pipeline?](#ml-pipeline) \n- [Structure of an ML pipeline](#structure) \n- [Pipeline tasks and components](#tasksandcomponents) \n- [Life cycle of an ML pipeline](#life-cycle) \n- [Use Vertex ML Metadata to track the lineage of ML artifacts](#track-lineage) \n- [Add pipeline runs to experiments](#experiments) \n**Note:** If you're experienced in creating ML pipelines using the Kubeflow Pipelines SDK and want to understand the differences between Vertex AI Pipelines and Kubeflow Pipelines, see [Migrate from Kubeflow Pipelines toVertex AI Pipelines](/vertex-ai/docs/pipelines/migrate-kfp) .\n", "content": "## What is an ML pipeline?\nAn ML pipeline is a portable and extensible description of an MLOps workflow as a series of steps called pipeline tasks. Each task performs a specific step in the workflow to train and/or deploy an ML model.\nWith ML pipelines, you can apply MLOps strategies to automate and monitor repeatable processes in your ML practice. For example, you can reuse a pipeline definition to continuously retrain a model on the latest production data. For more information about MLOps in Vertex AI, see [MLOps on Vertex AI](/vertex-ai/docs/start/introduction-mlops) .\n## Structure of an ML pipeline\nAn ML pipeline is a directed acyclic graph (DAG) of containerized pipeline tasks that are interconnected using input-output dependencies. You can author each task either in Python or as a prebuilt container images.\nYou can define the pipeline as a DAG using either the Kubeflow Pipelines SDK or the TFX SDK, compile it to its YAML for intermediate representation, and then run the pipeline. By default, pipeline tasks run in parallel. You can link the tasks to execute them in series. For more information about pipeline tasks, see [Pipeline task](#pipeline-task) . For more information about the workflow for defining, compiling, and running the pipeline, see [Life cycle of an ML pipeline](#life-cycle) .\n## Pipeline tasks and components\nA [pipeline task](#pipeline-task) is an instantiation of a [pipeline component](#pipeline-component) with specific inputs. While defining your ML pipeline, you can interconnect multiple tasks to form a DAG, by routing the outputs of one pipeline task to the inputs for the next pipeline task in the ML workflow. You can also use the inputs for the ML pipeline as the inputs for a pipeline task.\n### Pipeline component\nA pipeline component is a self-contained set of code that performs a specific step of an ML workflow, such as data preprocessing, model training, or model deployment. A component typically consists of the following:\n- **Inputs** : A component might have one or more input parameters and artifacts.\n- **Outputs** : Every component has one or more output parameters or artifacts.\n- **Logic** : This is the component's executable code. For containerized components, the logic also contains the definition of the environment, or container image, where the component runs.\nComponents are the basis of defining tasks in an ML pipeline. To define pipeline tasks, you can either use predefined [Google Cloud Pipeline Components](/vertex-ai/docs/pipelines/components-introduction) or create your own custom components.\nUse predefined Google Cloud Pipeline Components if you want to use features of Vertex AI, such as AutoML, in your pipeline. To learn how to use Google Cloud Pipeline Components to define a pipeline, see [Build a Pipeline](/vertex-ai/docs/pipelines/build-pipeline) .\nYou can author your own custom components to use in your ML pipeline. For more information about authoring custom components, see [Build your own pipelinecomponents](/vertex-ai/docs/pipelines/build-own-components) .\nTo learn how to author custom Kubeflow Pipelines components, see the [\"Pipelineswith lightweight components based on Python functions\"](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/pipelines/lightweight_functions_component_io_kfp.ipynb) Jupyter notebook on GitHub. To learn how to author custom TFX components, see the [TFX Python function component tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/python_function_component) on the [TensorFlow Extended in Production tutorials](https://www.tensorflow.org/tfx/tutorials#tensorflow-in-production-tutorials) .\n### Pipeline task\nA pipeline task is the instantiation of a pipeline component and performs a specific step in your ML workflow. You can author ML pipeline tasks either using Python or as prebuilt container images.\nWithin a task, you can build on the on-demand compute capabilities of Vertex AI with Kubernetes to scalably execute your code, or delegate your workload to another execution engine, such as BigQuery, Dataflow, or Dataproc Serverless.\n## Life cycle of an ML pipeline\nFrom definition to execution and monitoring, the life cycle of an ML pipeline comprises the following high-level stages:\n- **Define** : The process of defining an ML pipeline and its task is also called building a pipeline. In this stage, you need to perform the following steps:- **Choose an ML framework** : Vertex AI Pipelines supports ML pipelines defined using the TFX or Kubeflow Pipelines framework. To learn how to choose a framework for building your pipeline, see [Interfaces to define a pipeline](/vertex-ai/docs/pipelines/interfaces#define) .\n- **Define pipeline tasks and configure pipeline** : For more information, see [Build a Pipeline](/vertex-ai/docs/pipelines/build-pipeline) .\n- **Compile** : In this stage, you need to perform the following steps:- Generate your ML pipeline definition in a compiled YAML file for intermediate representation, which you can use to run your ML pipeline.\n- Optional: You can upload the compiled YAML file as a to a repository and reuse it to create ML pipeline runs.\n- **Run** : Create an execution instance of your ML pipeline using the compiled YAML file or a pipeline template. The execution instance of a pipeline definition is called a [pipeline run](#pipeline-run) .You can create a one-time occurrence of a pipeline run or use the Vertex AI Scheduler to create recurring pipeline runs from the same ML pipeline definition. You can also clone an existing pipeline run. To learn how to choose an interface to run an ML pipeline, see [Interfaces to run apipeline](/vertex-ai/docs/pipelines/interfaces#run) . For more information about how to create a pipeline run, see [Run a pipeline](/vertex-ai/docs/pipelines/run-pipeline) .\n- **Monitor, visualize, and analyze runs** : After you create a pipeline run, you can do the following to monitor the performance, status, and costs of pipeline runs:- Configure email notifications for pipeline failures. For more information, see [Configure email notifications](/vertex-ai/docs/pipelines/email-notifications) .\n- Use Cloud Logging to create log entries for monitoring events. For more information, see [View pipeline job logs](/vertex-ai/docs/pipelines/logging) .\n- Visualize, analyze, and compare pipeline runs. For more information, see [Visualize and analyze pipeline results](/vertex-ai/docs/pipelines/visualize-pipeline) .\n- Use Cloud Billing export to BigQuery to analyze pipeline run costs. For more information, see [Understand pipeline run costs](/vertex-ai/docs/pipelines/understand-pipeline-cost-labels) .\n- **Optional: stop or delete pipeline runs** : There is no restriction on how long you can keep a pipeline run active. You can optionally do the following:- Stop a pipeline run.\n- Pause or resume a pipeline run schedule.\n- Delete an existing pipeline template, pipeline run, or pipeline run schedule.\n## What is a pipeline run?\nA pipeline run is an execution instance of your ML pipeline definition. Each pipeline run is identified by a unique run name. Using Vertex AI Pipelines, you can create an ML pipeline run in the following ways:\n- Use the compiled YAML definition of a pipeline\n- Use a pipeline template from the Template Gallery\nFor more information about how to create a pipeline run, see [Run apipeline](/vertex-ai/docs/pipelines/run-pipeline) . For more information about how to create a pipeline run from a pipeline template, see [Create, upload, and use apipeline template](/vertex-ai/docs/pipelines/create-pipeline-template) .\nFor information about tracking and storing pipeline run artifacts and metadata using Vertex ML Metadata, see [Use Vertex ML Metadata to track thelineage of ML artifacts](#track-lineage) .\nFor information about using pipeline runs to experiment on your ML workflow using Vertex AI Experiments, see [Add your pipeline runs toexperiments](#experiments) .\n## Use Vertex ML Metadata to track the lineage of ML artifacts\nA pipeline run contains several artifacts and parameters, including pipeline metadata. To understand changes in the performance or accuracy of your ML system, you need to analyze the metadata and the lineage of ML artifacts from your ML pipeline runs. The lineage of an ML artifact includes all the factors that contributed to its creation, along with the artifacts and metadata that are derived from it.\nManaging this metadata in an ad-hoc manner can be difficult and time-consuming. You can use Vertex ML Metadata to maintain this metadata efficiently. When you run an ML pipeline using Vertex AI Pipelines, the artifacts and metadata from the pipeline run are stored using Vertex ML Metadata.\nFor more information about tracking the lineage of ML artifacts using Vertex ML Metadata, see [Track the lineage of pipelineartifacts](/vertex-ai/docs/pipelines/lineage) .\nFor more information about visualizing, analyzing, and comparing pipeline runs, see [Visualize and analyze pipeline results](/vertex-ai/docs/pipelines/visualize-pipeline) . For a list of first-party artifact types defined in Google Cloud Pipeline Components, see [ML Metadata artifact types](/vertex-ai/docs/pipelines/artifact-types) .\n## Add pipeline runs to experiments\nVertex AI Experiments lets you track and analyze various model architectures, hyperparameters, and training environments to find the best model for your ML use case. After you create an ML pipeline run, you can associate it with an experiment or experiment run. By doing so, you can experiment with different sets of variables, such as hyperparameters, number of training steps, or iterations.\nFor more information about experimenting with ML workflows using Vertex AI Experiments, see [Introduction toVertex AI Experiments](/vertex-ai/docs/experiments/intro-vertex-ai-experiments) .\n## What's next\n- Learn about the [interfaces you can use to define and run pipelines using Vertex AI Pipelines](/vertex-ai/docs/pipelines/interfaces) .\n- Get started by [learning how to define a pipeline using the Kubeflow Pipelines SDK](/vertex-ai/docs/pipelines/build-pipeline) .\n- [Learn how to run a pipeline](/vertex-ai/docs/pipelines/run-pipeline) .\n- Learn about [best practices for implementing custom-trained ML models on Vertex AI](https://cloud.google.com/architecture/ml-on-gcp-best-practices#machine-learning-workflow-orchestration) .", "guide": "Vertex AI"}