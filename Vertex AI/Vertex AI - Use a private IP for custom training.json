{"title": "Vertex AI - Use a private IP for custom training", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Use a private IP for custom training\nUsing private IP to connect to your training jobs provides more network security and lower network latency than using public IP. To use private IP, you use [Virtual Private Cloud (VPC)](/vpc/docs/vpc-peering) to peer your network with any type of [Vertex AI custom training job](/vertex-ai/docs/training/custom-training-methods) . This allows your training code to access private IP addresses inside your Google Cloud or on-premises networks.\nThis guide shows how to run custom training jobs in your network after you have already [set up VPC Network Peering](/vertex-ai/docs/general/vpc-peering) to peer your network with a Vertex AI `CustomJob` , `HyperparameterTuningJob` , or custom `TrainingPipeline` resource.\nNote that you can't use private IP addresses for custom training if you are also [using a TPU VM](/vertex-ai/docs/training/configure-compute#tpu) .\n", "content": "## Overview\nBefore you submit a custom training job using private IP, you must [configureprivate services access to create peering connections between your networkand Vertex AI](/vertex-ai/docs/general/vpc-peering) . If you have already set this up, you can use your existing peering connections.\nThis guide covers the following tasks:\n- Understanding which IP ranges to reserve for custom training.\n- Verify the status of your existing peering connections.\n- Perform Vertex AI custom training on your network.\n- Check for active training occurring on one network before training on another network.\n- Test that your training code can access private IPs in your network.\n### Reserve IP ranges for custom training\nWhen you reserve an IP range for service producers, the range can be used by Vertex AI and other services. This table shows the maximum number of parallel training jobs that you can run with reserved ranges from /16 to /19, assuming the range is used almost exclusively by Vertex AI. If you connect with other service producers using the same range, allocate a larger range to accommodate them, in order to avoid IP exhaustion.\n| Machine configuration for training job                                    | Reserved range | Maximum number of parallel jobs | Unnamed: 3 |\n|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------|----------------------------------:|-------------:|\n| Up to 8 nodes. For example: 1 primary replica in the first worker pool, 6 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /16    |        63 |   nan |\n| Up to 8 nodes. For example: 1 primary replica in the first worker pool, 6 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /17    |        31 |   nan |\n| Up to 8 nodes. For example: 1 primary replica in the first worker pool, 6 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /18    |        15 |   nan |\n| Up to 8 nodes. For example: 1 primary replica in the first worker pool, 6 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /19    |         7 |   nan |\n| nan                                             | nan    |        nan |   nan |\n| Up to 16 nodes. For example: 1 primary replica in the first worker pool, 14 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /16    |        31 |   nan |\n| Up to 16 nodes. For example: 1 primary replica in the first worker pool, 14 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /17    |        15 |   nan |\n| Up to 16 nodes. For example: 1 primary replica in the first worker pool, 14 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /18    |         7 |   nan |\n| Up to 16 nodes. For example: 1 primary replica in the first worker pool, 14 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /19    |         3 |   nan |\n| nan                                             | nan    |        nan |   nan |\n| Up to 32 nodes. For example: 1 primary replica in the first worker pool, 30 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /16    |        15 |   nan |\n| Up to 32 nodes. For example: 1 primary replica in the first worker pool, 30 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /17    |         7 |   nan |\n| Up to 32 nodes. For example: 1 primary replica in the first worker pool, 30 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /18    |         3 |   nan |\n| Up to 32 nodes. For example: 1 primary replica in the first worker pool, 30 replicas in the second worker pool, and 1 worker in the third worker pool (to act as a parameter server) | /19    |         1 |   nan |\nLearn more about [configuring worker pools for distributedtraining](/vertex-ai/docs/training/distributed-training) .\n## Check the status of existing peering connections\nIf you have existing peering connections you use with Vertex AI, you can list them to check status:\n```\ngcloud compute networks peerings list --network NETWORK_NAME\n```\nYou should see that the state of your peering connections are `ACTIVE` . Learn more about [active peering connections](/vpc/docs/using-vpc-peering#step_3_vpc_network_peering_becomes_active) .\n## Perform custom training\nWhen you perform custom training, you must specify the name of the network that you want Vertex AI to have access to.\nDepending on how you perform custom training, specify the network in one of the following API fields:\n- **If you are creating aCustomJob,** specify the `CustomJob.jobSpec.network` field.If you are using the Google Cloud CLI, then you can use the `--config` flag on the [gcloud ai custom-jobs createcommand](/sdk/gcloud/reference/ai/custom-jobs/create) to specify the `network` field.Learn more about [creating a CustomJob](/vertex-ai/docs/training/create-custom-job) .\n- **If you are creating aHyperparameterTuningJob,** specify the `HyperparameterTuningJob.trialJobSpec.network` field.If you are using the gcloud CLI, then you can use the `--config` flag on the [gcloud ai hpt-tuning-jobs createcommand](/sdk/gcloud/reference/ai/hp-tuning-jobs/create) to specify the `network` field.Learn more about [creating aHyperparameterTuningJob](/vertex-ai/docs/training/using-hyperparameter-tuning) .\n- **If you are creating aTrainingPipeline withouthyperparameter tuning,** specify the `TrainingPipeline.trainingTaskInputs.network` field.Learn more about [creating a customTrainingPipeline](/vertex-ai/docs/training/create-training-pipeline) .\n- **If you are creating a TrainingPipeline with hyperparameter tuning** , specify the `TrainingPipeline.trainingTaskInputs.trialJobSpec.network` field.\nIf you do not specify a network name, then Vertex AI runs your custom training without a peering connection, and without access to private IPs in your project.\n### Example: Creating a CustomJob with the gcloud CLI\nThe following example shows how to specify a network when you use the gcloud CLI to run a `CustomJob` that uses a prebuilt container. If you are perform custom training in a different way, add the `network` field [as described for the type of custom training job you're using](#perform-custom-training) .\n- Create a `config.yaml` file to specify the network. If you're using Shared VPC, use your VPC host project number.Make sure the network name is formatted correctly:```\nPROJECT_NUMBER=$(gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\")cat <<EOF > config.yamlnetwork: projects/PROJECT_NUMBER/global/networks/NETWORK_NAMEEOF\n```\n- [Create a training application](/vertex-ai/docs/training/create-python-pre-built-container) to run on Vertex AI.\n- Create the `CustomJob` , passing in your `config.yaml` file:```\ngcloud ai custom-jobs create \\\u00a0 --region=LOCATION \\\u00a0 --display-name=JOB_NAME \\\u00a0 --python-package-uris=PYTHON_PACKAGE_URIS \\\u00a0 --worker-pool-spec=machine-type=MACHINE_TYPE,replica-count=REPLICA_COUNT,executor-image-uri=PYTHON_PACKAGE_EXECUTOR_IMAGE_URI,python-module=PYTHON_MODULE \\\u00a0 --config=config.yaml\n```\nTo learn how to replace the placeholders in this command, read [Creating customtraining jobs](/vertex-ai/docs/training/create-custom-job) .\n### Run jobs on different networks\nYou can't perform custom training on a new network while you are still performing custom training on another network. Before you switch to a different network, you must wait for all submitted `CustomJob` , `HyperparameterTuningJob` , and custom `TrainingPipeline` resources to finish, or you must cancel them.\n## Test training job access\nThis section explains how to test that a custom training resource can access private IPs in your network.\n- Create a Compute Engine instance in your VPC network.\n- [Check your firewall rules](/vpc/docs/using-firewalls#listing-rules-vm) to make sure that they don't restrict ingress from the Vertex AI network. If so, add a rule to ensure the Vertex AI network can access the IP range you reserved for Vertex AI (and other service producers).\n- Set up a local server on the VM instance in order to create an endpoint for a Vertex AI`CustomJob`to access.\n- Create a Python training application to run on Vertex AI. Instead of model training code, create code that accesses the endpoint you set up in the previous step.\n- [Follow the previous example to create a CustomJob](#submit-job) .## Common problems\nThis section lists some common issues for configuring VPC Network Peering with Vertex AI.\n- When you configure Vertex AI to use your network, specify the full network name:\"projects/ /global/networks/ \"\n- Make sure you are not performing custom training on a network before performing custom training on a different network.\n- Make sure that you've allocated a sufficient IP range for all service producers your network connects to, including Vertex AI.\nFor additional troubleshooting information, refer to the [VPC Network Peering troubleshooting guide](/vpc/docs/using-vpc-peering#troubleshooting) .\n## What's next\n- Learn more about [VPC Network Peering](/vpc/docs/vpc-peering) .\n- See [reference architectures and best practices](/solutions/best-practices-vpc-design#shared-service) for VPC design.", "guide": "Vertex AI"}