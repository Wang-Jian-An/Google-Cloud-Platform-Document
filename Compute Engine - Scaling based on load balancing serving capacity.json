{"title": "Compute Engine - Scaling based on load balancing serving capacity", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Scaling based on load balancing serving capacity\nThis document describes how to scale a [managed instance group (MIG)](/compute/docs/instance-groups#managed_instance_groups) based on the serving capacity of an external Application Load Balancer or an internal Application Load Balancer. This means that autoscaling adds or removes VM instances in the group when the load balancer indicates that the group has reached a configurable fraction of its , where is defined by the [target capacity](/load-balancing/docs/backend-service#target_capacity) of the selected [balancing mode](/load-balancing/docs/backend-service#balancing-mode) of the backend instance group.\nYou can also scale a MIG based on its [CPU utilization](/compute/docs/autoscaler/scaling-cpu) or on [Monitoring metrics](/compute/docs/autoscaler/scaling-stackdriver-monitoring-metrics) .\n", "content": "## Limitations\nYou can autoscale a managed instance group based on the serving capacity of an [external Application Load Balancer](/compute/docs/load-balancing/http) and an [internal Application Load Balancer](/load-balancing/docs/l7-internal) . Other types of load balancers are not supported.\n## Before you begin\n- Review the autoscaler [limitations](/compute/docs/autoscaler#specifications) .\n- Read about autoscaler [fundamentals](/compute/docs/autoscaler#fundamentals) .\n- If you haven't already, set up authentication. [Authentication](/compute/docs/authentication) is the process by which your identity is verified for access to Google Cloud services and APIs. To run code or samples from a local development environment, you can authenticate to Compute Engine as follows.Select the tab for how you plan to use the samples on this page:\nWhen you use the Google Cloud console to access Google Cloud services and   APIs, you don't need to set up authentication.- [Install](/sdk/docs/install) the Google Cloud CLI, then [initialize](/sdk/docs/initializing) it by running the following command:```\ngcloud init\n``` **Note:** If you installed the gcloud CLI  previously, make sure you have the latest version by running`gcloud components  update`.\n- [ Set a default region and zone](/compute/docs/gcloud-compute#set_default_zone_and_region_in_your_local_client) .\nTo use the REST API samples on this page in a local development environment, you use the credentials you provide to the gcloud CLI.- [Install](/sdk/docs/install) the Google Cloud CLI, then [initialize](/sdk/docs/initializing) it by running the following command:\n- ```\ngcloud init\n```## Scaling based on HTTP(S) load balancing serving capacity\nCompute Engine provides support for load balancing within your instance groups. You can use autoscaling in conjunction with load balancing by setting up an autoscaler that scales based on the load of your instances.\nAn external or internal HTTP(S) load balancer distributes requests to backend services according to its URL map. The load balancer can have one or more [backend services](/load-balancing/docs/backend-service) , each supporting instance group or network endpoint group (NEG) backends. When backends are instance groups, the HTTP(S) load balancer offers two [balancing modes](/load-balancing/docs/backend-service#balancing-mode) : `UTILIZATION` and `RATE` . With `UTILIZATION` , you can specify a maximum target for average backend utilization of instances in the instance group. With `RATE` , you must specify a target number of requests per second on a per-instance basis or a per-group basis. (Only zonal instance groups support specifying a maximum rate for the whole group. Regional managed instance groups do not support defining a maximum rate per group.)\nThe balancing mode and the target capacity that you specify define the conditions under which Google Cloud determines when a backend VM is at full capacity. Google Cloud attempts to send traffic to healthy VMs that have remaining capacity. If all VMs are already at capacity, the target utilization or rate is exceeded.\nWhen you attach an autoscaler to an instance group backend of an HTTP(S) load balancer, the autoscaler scales the managed instance group to maintain a fraction of the load balancing serving capacity.\nFor example, assume the load balancing serving capacity of a managed instance group is defined as 100 RPS per instance. If you create an autoscaler with the HTTP(S) load balancing policy and set it to maintain a target utilization level of 0.8 or 80%, the autoscaler adds or removes instances from the managed instance group to maintain 80% of the serving capacity, or 80 RPS per instance.\nThe following diagram shows how the autoscaler interacts with a managed instance group and backend service:### Applicable load balancing configurations\nYou can set one of three options for your load balancing [serving capacity](/load-balancing/docs/backend-service) . When you first create the backend, you can choose among maximum backend utilization, maximum requests per second per instance, or maximum requests per second of the whole group. Autoscaling only works with **maximum backend utilization** and **maximum requests persecond/instance** because the value of these settings can be controlled by adding or removing instances. For example, if you set a backend to handle 10 requests per second per instance, and the autoscaler is configured to maintain 80% of that rate, then the autoscaler can add or remove instances when the requests per second per instance changes.\nAutoscaling does not work with maximum requests per group because this setting is independent of the number of instances in the instance group. The load balancer continuously sends the maximum number of requests per group to the instance group, regardless of how many instances are in the group.\nFor example, if you set the backend to handle 100 maximum requests per group per second, the load balancer sends 100 requests per second to the group, whether the group has two instances or 100 instances. Because this value cannot be adjusted, autoscaling does not work with a load balancing configuration that uses the maximum number of requests per second per group.\n### Enable autoscaling based on load balancing serving capacity- Go to the **Instance groups** page in the Google Cloud console. [Go to Instance groups](https://console.cloud.google.com/compute/instanceGroups/list) \n- If you have an instance group, select it, and then click **Edit** . If you don't have an instance group, click **Create instance group** .\n- Under **Autoscaling mode** , select **On: add and remove instances to\nthe group** to enable autoscaling.\n- Specify the minimum and maximum numbers of instances that you want the autoscaler to create in this group.\n- In the **Autoscaling metrics** section, click **Add metric** .\n- Set the **Metric type** to **HTTP load balancing utilization** .\n- Enter the **Target HTTP load balancing utilization** . This value is treated as a percentage. For example, for 60% HTTP load balancing utilization, enter `60` .\n- You can use the **Cool down period** to set the initialization period, which tells the autoscaler how long it takes for your application to initialize. Specifying an accurate initialization period improves autoscaler decisions. For example, when scaling out, the autoscaler ignores data from VMs that are still initializing because those VMs might not yet represent normal usage of your application. The default initialization period is 60 seconds.\n- Save your changes.\nTo enable an autoscaler that scales on serving capacity, use the [set-autoscaling](/sdk/gcloud/reference/compute/instance-groups/managed/set-autoscaling) sub-command. For example, the following command creates an autoscaler that scales the target managed instance group to maintain 60% of the serving capacity. Along with the `--target-load-balancing-utilization` parameter, the `--max-num-replicas` parameter is also required when creating an autoscaler:\n```\ngcloud compute instance-groups managed set-autoscaling example-managed-instance-group \\\n --max-num-replicas 20 \\\n --target-load-balancing-utilization 0.6 \\\n --cool-down-period 90\n```\nYou can use the `--cool-down-period` flag to set the initialization period, which tells the autoscaler how long it takes for your application to initialize. Specifying an accurate initialization period improves autoscaler decisions. For example, when scaling out, the autoscaler ignores data from VMs that are still initializing because those VMs might not yet represent normal usage of your application. The default initialization period is 60 seconds.\nYou can verify that your autoscaler was successfully created by using the [instance-groups managed describe sub-command](/sdk/gcloud/reference/compute/instance-groups/managed/describe) :\n```\ngcloud compute instance-groups managed describe example-managed-instance-group\n```\nFor a list of available `gcloud` commands and flags, see the [gcloud reference](/sdk/gcloud/reference/compute/instance-groups/managed) .\n **Note:** If autoscaling is already enabled for a managed instance group, the `set-autoscaling` command updates the existing autoscaler to the new specifications.\n **Note:** Although autoscaling is a feature of managed instance groups, it is a separate API resource. Keep that in mind when you construct API requests for autoscaling.\nTo create an autoscaler, use the [autoscalers.insert method](/compute/docs/reference/rest/v1/autoscalers/insert) for a zonal MIG or the [regionAutoscalers.insert method](/compute/docs/reference/rest/v1/regionAutoscalers/insert) for a regional MIG.\nThe following example creates an autoscaler for a zonal MIG:\n```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/autoscalers/\n```\nYour request body must contain the `name` , `target` , and `autoscalingPolicy` fields. `autoscalingPolicy` must define `loadBalancingUtilization` .\nYou can use the `coolDownPeriodSec` field to set the initialization period, which tells the autoscaler how long it takes for your application to initialize. Specifying an accurate initialization period improves autoscaler decisions. For example, when scaling out, the autoscaler ignores data from VMs that are still initializing because those VMs might not yet represent normal usage of your application. The default initialization period is 60 seconds.\n```\n{\n \"name\": \"example-autoscaler\",\n \"target\": \"zones/us-central1-f/instanceGroupManagers/example-managed-instance-group\",\n \"autoscalingPolicy\": {\n \"maxNumReplicas\": 20,\n \"loadBalancingUtilization\": {\n  \"utilizationTarget\": 0.8\n  },\n \"coolDownPeriodSec\": 90\n }\n}\n```\nFor more information about enabling autoscaling based on load balancing serving capacity, complete the tutorial, [Globally autoscaling a web service on Compute Engine](/compute/docs/tutorials/globally-autoscaling-a-web-service-on-compute-engine) .\n## What's next\n- Learn about [managing autoscalers](/compute/docs/autoscaler/managing-autoscalers) .\n- Learn [how autoscalers make decisions](/compute/docs/autoscaler/understanding-autoscaler-decisions) .\n- Learn how to use [multiple autoscaling signals](/compute/docs/autoscaler/multiple-policies) to scale your group.", "guide": "Compute Engine"}