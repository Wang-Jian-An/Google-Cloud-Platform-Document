{"title": "Compute Engine - About GPUs", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - About GPUs\nYou can attach graphics processing units (GPUs) to your virtual machine (VM) instance to accelerate specific workloads on Compute Engine.\nThis document describes the features and limitations of GPUs running on Compute Engine.\n", "content": "## GPUs and machine series\nGPUs are supported for N1 general-purpose, and the accelerator-optimized (A3, A2, and G2) machine series. For VMs that use N1 machine types, you attach the GPU to the VM during, or after VM creation. For VMs that use A3, A2 or G2 machine types, the GPUs are automatically attached when you create the VM. GPUs can't be used with other machine series.\n### Accelerator-optimized machine series\nEach accelerator-optimized machine type has a specific model of NVIDIA GPUs attached.\n- For A3 accelerator-optimized machine types, [NVIDIA H100 80GB GPUs](/compute/docs/gpus#h100-gpus) are attached.\n- For A2 accelerator-optimized machine types, [NVIDIA A100 GPUs](/compute/docs/gpus#a100-gpus) are attached. These are available in both A100 40GB and A100 80GB options.\n- For G2 accelerator-optimized machine types, [NVIDIA L4 GPUs](/compute/docs/gpus#l4-gpus) are attached.\nFor more information, see [Accelerator-optimized machine series](/compute/docs/accelerator-optimized-machines) .\n### N1 general-purpose machine series\nFor all other GPU types, you can use most N1 machine types except the N1 shared-core.\nFor this machine series, you can use either [predefined](/compute/docs/general-purpose-machines#n1_machines) or [custom](/compute/docs/general-purpose-machines#custom_machine_types) machine types.\n## GPUs on preemptible instances\nYou can add GPUs to your preemptible VM instances at lower [spot prices](/compute/gpus-pricing) for the GPUs. GPUs attached to preemptible instances work like normal GPUs but persist only for the life of the instance. Preemptible instances with GPUs follow the same [preemption process](/compute/docs/instances/preemptible#preemption_process) as all preemptible instances.\nConsider requesting dedicated `Preemptible GPU` quota to use for GPUs on preemptible instances. For more information, see [Quotas for preemptible VM instances](/compute/docs/instances/preemptible#quotas) .\nDuring maintenance events, preemptible instances with GPUs are preempted by default and cannot be automatically restarted. If you want to recreate your instances after they have been preempted, use a [managed instance group](/compute/docs/instance-groups/manager) . Managed instance groups recreate your instances if the vCPU, memory, and GPU resources are available.\nIf you want a warning before your instance is preempted, or want to configure your instance to automatically restart after a maintenance event, use a standard instance with a GPU. For standard instances with GPUs, Google provides [one hour advance notice](/compute/docs/gpus/gpu-host-maintenance) before preemption.\nCompute Engine does not charge you for GPUs if their instances are preempted in the first minute after they start running.\nFor steps to automatically restart a standard instance, see [Updating options for an instance](/compute/docs/instances/setting-instance-scheduling-options#updatingoption) .\nTo learn how to create preemptible instances with GPUs attached, read [Create a VM with attached GPUs](/compute/docs/gpus/create-vm-with-gpus) .\n## GPUs and Confidential VM\nYou can't attach GPUs to Confidential VM instances. For more information about Confidential VM, see [Confidential Computing concepts](/confidential-computing/confidential-vm/docs/about-cvm) .\n## GPUs and host maintenance\nVMs with attached GPUs cannot [live migrate](/compute/docs/instances/setting-instance-scheduling-options#live_migrate) and must stop for host maintenance events. These maintenance events typically occur once every two weeks. Maintenance events can also occur more frequently when necessary. For information on handling maintenance events, see [Handling GPU host maintenance events](/compute/docs/gpus/gpu-host-maintenance) .\n## GPUs and block storage\nYou can add [Local SSDs](/compute/docs/disks#localssds) to VMs that have GPUs attached. For a list of Local SSD support by GPU types and regions, see [Local SSD availability by GPU regions and zones](/compute/docs/gpus/gpu-regions-zones#local-ssd-gpu) .\n## GPU pricing\nMost VMs with an attached GPU receive [sustained use discounts](/compute/docs/sustained-use-discounts) similar to vCPUs. When you select a GPU for a virtual workstation, an NVIDIA RTX Virtual Workstation license is added to your VM.\nFor hourly and monthly pricing for GPUs, see [GPU pricing page](/compute/gpus-pricing) .\n## Reserving GPUs with committed use discounts\nTo reserve GPU resources in a specific zone, see [Reservations of Compute Engine zonal resources](/compute/docs/instances/reserving-zonal-resources) .\nTo receive committed use discounts for GPUs in a specific zone, you must purchase resource-based commitments for the GPUs and also attach reservations that specify matching GPUs to your commitments. For more information, see [Attach reservations to resource-based commitments](/compute/docs/instances/reservations-with-commitments#attach-reservations-to-resource-cuds) .\n## GPU restrictions and limitations\n**Caution:** NVIDIA K80 GPUs will reach end of life on May 1, 2024. For more information, see [NVIDIA K80 EOL](/compute/docs/eol/k80-eol) .\nFor VMs with attached GPUs, the following restrictions and limitations apply:\n- If you want to use NVIDIA K80 GPUs with your VMs, the VMs cannot use the Intel Skylake or later CPU platforms.\n- GPUs are currently only supported with general-purpose N1 or accelerator-optimized - A3, A2, and G2 - machine types.\n- To protect Compute Engine systems and users, new projects have a global GPU quota, which limits the total number of GPUs you can create in any supported zone. When you request a GPU quota, you must request a quota for the GPU models that you want to create in each region, and an additional global quota for the total number of GPUs of all types in all zones.\n- VMs with one or more GPUs have a maximum number of vCPUs for each GPU that you add to the instance. For example, each NVIDIA K80 GPU lets you have up to eight vCPUs and up to 52\u00a0GB of memory in your instance machine type. To see the available vCPU and memory ranges for different GPU configurations, see the [GPUs list](/compute/docs/gpus#gpus-list) .\n- GPUs require device drivers in order to function properly. NVIDIA GPUs running on Compute Engine must use a minimum driver version. For more information about driver versions, see [Required NVIDIA driver versions](/compute/docs/gpus/install-drivers-gpu#minimum-driver) .\n- VMs with a specific attached GPU model are covered by the [Compute Engine SLA](/compute/sla) only if that attached GPU model is generally available and is supported in more than one zone in the same region. The Compute Engine SLA does not cover GPU models in the following zones:- NVIDIA H100 80GB:- `us-east5-a`\n- NVIDIA L4:- `europe-west3-b`\n- `europe-west6-b`\n- NVIDIA A100 80GB:- `asia-southeast1-c`\n- `us-east4-c`\n- `us-east5-b`\n- NVIDIA A100 40GB:- `us-east1-b`\n- `us-west1-b`\n- `us-west3-b`\n- `us-west4-b`\n- NVIDIA T4:- `europe-west3-b`\n- `southamerica-east1-c`\n- `us-west3-b`\n- NVIDIA V100:- `asia-east1-c`\n- `us-east1-c`\n- NVIDIA P100:- `australia-southeast1-c`\n- `europe-west4-a`\n- NVIDIA K80:- `us-west1-b`\n- Compute Engine supports the running of 1 concurrent user per GPU.## What's next?\n- Learn how to [create VMs with attached GPUs](/compute/docs/gpus/create-vm-with-gpus) .\n- Learn how to [add or remove GPUs](/compute/docs/gpus/add-remove-gpus) .", "guide": "Compute Engine"}