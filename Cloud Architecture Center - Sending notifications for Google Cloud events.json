{"title": "Cloud Architecture Center - Sending notifications for Google Cloud events", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Sending notifications for Google Cloud events\nThis tutorial is for DevOps teams who want to get notifications for important Google Cloud events pushed to their collaboration platforms, such as [Google Chat](https://gsuite.google.com/products/chat/) , [Slack](https://slack.com) , or [Microsoft Teams](https://products.office.com/en-us/microsoft-teams) . Notifications free teams from having to regularly log into the Google Cloud console to check for event updates.\nAs an example for this tutorial, notifications are generated after you take disk snapshots. Taking a [disk snapshot](/compute/docs/disks/snapshot-best-practices) backs up data from your zonal persistent disks or regional persistent disks. You can modify this tutorial to automatically push notifications to your collaboration systems when other important Google Cloud events occur\u2014for example, when a virtual machine (VM) instance is created or deleted.\nThe code for this tutorial is available in a [GitHub repository](https://github.com/GoogleCloudPlatform/gcf-notification-forwarding) .\nThis tutorial is intended for engineers who specialize in DevOps and cloud technology. It assumes you are familiar with Cloud Logging, Pub/Sub, and Cloud Functions.\nThe [State of DevOps](/devops) reports identified capabilities that drive software delivery performance. This tutorial will help you with the following capabilities:- [Monitoring and observability](/solutions/devops/devops-measurement-monitoring-and-observability) \n- [Proactive failure notification](/solutions/devops/devops-measurement-proactive-failure-notification) \n", "content": "## ArchitectureThe following diagram shows the different components that you use in this tutorial.First, you create a persistent disk and take a disk snapshot. You then filter the log events that correspond to successful disk snapshots and export the events by publishing them to a [Pub/Sub](/pubsub) topic. A [Cloud Function](/functions) reads the message from the topic and sends a push notification to a [webhook](https://wikipedia.org/wiki/Webhook) . For this tutorial, this webhook is represented by a Cloud Function.## Objectives\n- Set up Cloud Logging to export selected events to Pub/Sub so that Cloud Functions can consume them.\n- Deploy a Cloud Function that consumes events exported by Cloud Logging and then triggers a webhook.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Persistent Disk](/compute/all-pricing#persistentdisk) \n- [Cloud Functions](/functions/pricing) \n- [Pub/Sub](/pubsub/pricing) \n- [Cloud Logging](/stackdriver/pricing#logging-costs) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin\n- In the Google Cloud console, on the project selector page,   select or [create a Google Cloud project](/resource-manager/docs/creating-managing-projects) . **Note** : If you don't plan to keep the  resources that you create in this procedure, create a project instead of  selecting an existing project. After you finish these steps, you can  delete the project, removing all resources associated with the project. [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\n- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) You use Cloud Shell to run all commands in this tutorial.\n- Enable the Compute Engine, Cloud Logging, Cloud Functions, and Pub/Sub APIs:```\ngcloud services enable \\\u00a0 \u00a0 compute.googleapis.com \\\u00a0 \u00a0 logging.googleapis.com \\\u00a0 \u00a0 cloudfunctions.googleapis.com \\\u00a0 \u00a0 pubsub.googleapis.com\n```\n## Preparing your environment\n- In Cloud Shell, set the `gcloud` default for the Compute Engine region and zone that you want to use for this tutorial:```\ngcloud config set compute/region us-central1gcloud config set compute/zone us-central1-a\n```This tutorial uses the `us-central1` region and the `us-central1-a` zone. You can change the region and zone to suit your needs. For more information, see [Geography and regions](/docs/geography-and-regions) .\n- Define the environment variables that you use for this tutorial:```\nPROJECT=$(gcloud config get-value project)PUBSUB_TOPIC=\"gce-snapshots-events\"DISK=\"my-disk-1\"WEBHOOK_NAME=\"webhookEmulator\"WEBHOOK_URL=\"https://$(gcloud config get-value compute/region)-$PROJECT.cloudfunctions.net/$WEBHOOK_NAME\"\n```\n## Creating resourcesIn this section, you create the following Google Cloud resources for this tutorial:- Pub/Sub topic\n- Cloud Logging sink\n- Cloud Function\n### Create a Pub/Sub topic\n- In Cloud Shell, create a Pub/Sub topic to publish event messages to:```\ngcloud pubsub topics create $PUBSUB_TOPIC\n```\n### Create a Cloud Logging sink to Pub/SubCloud Logging lets you store, search, and analyze events from Google Cloud. You can filter and export these logs to [Cloud Storage](/storage) , [BigQuery](/bigquery) , and [Pub/Sub](/pubsub) .- In Cloud Shell, export the logs generated by disk snapshots to Pub/Sub:```\ngcloud logging sinks create gce-events-sink \\\u00a0 \u00a0 pubsub.googleapis.com/projects/$PROJECT/topics/$PUBSUB_TOPIC \\\u00a0 \u00a0 --log-filter='resource.type=\"gce_disk\"jsonPayload.event_type=\"GCE_OPERATION_DONE\"jsonPayload.event_subtype=\"compute.disks.createSnapshot\"'\n```The output contains the service account's email address that Cloud Logging uses when it publishes logs to the Pub/Sub topic that you created earlier. This email address takes the form of `` `@gcp-sa-logging.iam.gserviceaccount.com` .\n- Copy the service account's email address. You need it in the next section.\n### Set up permissions\n- In Cloud Shell, grant the service account the [Pub/Sub Publisher IAM role](/iam/docs/understanding-roles#pub-sub-roles) ( `roles/pubsub.publisher` ) so that it can publish messages to the Pub/Sub topic:```\ngcloud beta pubsub topics add-iam-policy-binding $PUBSUB_TOPIC \\\u00a0 \u00a0 --member='serviceAccount:SERVICE_ACCOUNT_EMAIL_ADDRESS' \\\u00a0 \u00a0 --role='roles/pubsub.publisher'\n```Replace `` with the email address that you copied in the previous section.\n### Create a webhookTypically in production, you are notified of important Google Cloud events by push notifications sent to your collaboration platforms. Most of these platforms offer webhooks. In this tutorial, you create a Cloud Function to simulate a webhook from one of these platforms. This Cloud Function, which is triggered over HTTP, prints the content of the received messages.\nBy default, any user or service can invoke an HTTP Cloud Function. You can configure [Identity and Access Management (IAM)](/iam) on HTTP functions to restrict this behavior so that your HTTP function can be invoked only by providing authentication credentials in the request.- In Cloud Shell, clone the Git repository that contains the tutorial code:```\ngit clone https://github.com/GoogleCloudPlatform/gcf-notification-forwarding\n```\n- Switch to the working directory:```\ncd gcf-notification-forwarding/\n```\n- Deploy the Cloud Function `webhookEmulator` webhook by using an HTTP trigger:```\ngcloud functions deploy $WEBHOOK_NAME \\\u00a0 \u00a0 --runtime=nodejs8 \\\u00a0 \u00a0 --trigger-http \\\u00a0 \u00a0 --allow-unauthenticated \\\u00a0 \u00a0 --source=webhook/\n```This command can take up to two minutes to complete. **Note:** To simplify this tutorial, this command uses the `--allow-unauthenticated` flag. If you implement this solution in a production environment, we recommend that you [secure your webhook endpoint](/functions/docs/securing/authenticating#function-to-function) .\n### Create a Cloud Function to push notificationsYou create a Cloud Function that subscribes to the Pub/Sub topic that you created earlier in [push mode](/pubsub/docs/subscriber#push_pull) . Then, each time Cloud Logging exports (or pushes) an event to the Pub/Sub topic, this Cloud Function is triggered. The function receives the event, processes it, and pushes it to the HTTP endpoint of the webhook that you created earlier.- In Cloud Shell, deploy the Cloud Function:```\ngcloud functions deploy pushEventsToWebhook \\\u00a0 \u00a0 --runtime=nodejs8 \\\u00a0 \u00a0 --trigger-topic=$PUBSUB_TOPIC \\\u00a0 \u00a0 --set-env-vars=WEBHOOK_URL=$WEBHOOK_URL \\\u00a0 \u00a0 --allow-unauthenticated \\\u00a0 \u00a0 --source=push_notification/\n``` **Note:** To simplify this tutorial, this command uses the `--allow-unauthenticated` flag. If you implement this solution in a production environment, we recommend that you [secure your webhook endpoint](/functions/docs/securing/authenticating#function-to-function) .\n## Testing the setupTo test this setup, you take a disk snapshot and check whether the webhook receives the event log that the disk snapshot generates.- In Cloud Shell, create a zonal persistent disk. The default is a standard hard disk drive of 500\u00a0GB.```\ngcloud compute disks create $DISK \\\u00a0 \u00a0 --zone=$(gcloud config get-value compute/zone)\n```\n- Trigger the creation of a snapshot of the disk that you created earlier:```\ngcloud compute disks snapshot $DISK \\\u00a0 \u00a0 --zone=$(gcloud config get-value compute/zone) \\\u00a0 \u00a0 --storage-location=$(gcloud config get-value compute/region)\n```This command can take up to two minutes to complete. After the snapshot is taken, an admin activity log entry is generated. The event log is filtered and pushed to the Pub/Sub topic. The subscribed Cloud Function picks it up, formats it, and pushes it to the webhook's HTTP endpoint.\n- After a few minutes, check whether the webhook received the event log:```\ngcloud beta functions logs read $WEBHOOK_NAME \\\u00a0 \u00a0 --region=$(gcloud config get-value compute/region) \\\u00a0 \u00a0 --limit=10\n```The output is similar to following:```\n{\n data:[  {\n  \"type\":'disk',\n  \"url\":'https://console.cloud.google.com/compute/disksDetail/zones/us-central1-a/disks/my-disk-1?project=$PROJECT&supportedpurview=project',\n  \"name\":'my-disk-1'\n  },\n  {\n  \"type\":'project',\n  \"project_id\":'$PROJECT',\n  \"project_url\":'https://console.cloud.google.com/?project=$PROJECT'\n  },\n  {\n  \"zone\":'us-central1-a'\n  },\n  {\n  \"date_time\":'2020-04-15T09:07:21.205-06:00'\n  }\n ]\n}\n```The output shows that the webhook received the notification that a disk snapshot was taken.\n## Clean upThe easiest way to eliminate billing is to delete the project you created for the tutorial.- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Read about [Google Cloud Observability](/stackdriver) .\n- Learn about [routing logs](/logging/docs/routing/overview#sinks) for Cloud Logging.\n- Read about [Pub/Sub](/pubsub) .\n- Explore [tutorials for Pub/Sub](/pubsub/docs/tutorials) .\n- Read about [Cloud Functions](/functions) .\n- Explore [tutorials for Cloud Functions](/functions/docs/tutorials) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .\n- Read our resources about [DevOps](/devops) .\n- Learn more about the DevOps capabilities related to this tutorial:- [Monitoring and observability](/solutions/devops/devops-measurement-monitoring-and-observability) \n- [Proactive failure notification](/solutions/devops/devops-measurement-proactive-failure-notification) \n- Take the [DevOps quick check](https://dora.dev/quickcheck/) to understand where you stand in comparison with the rest of the industry.", "guide": "Cloud Architecture Center"}