{"title": "Compute Engine - Benchmark higher network bandwidth for VM instances", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Benchmark higher network bandwidth for VM instances\nThis document explains how to test per VM Tier_1 networking performance by creating two VMs and streaming traffic back and forth to observe network performance. To take advantage of this feature, you must create your VM with [operating systems](/compute/docs/images/os-details#networking) that support the [Google Virtual NIC (gVNIC)](/compute/docs/networking/using-gvnic) . Per VM Tier_1 networking performance requires larger VM sizes, so confirm you have enough [CPU quota](/compute/quotas#cpu_quota) to create the VMs.\n", "content": "## Before you begin\n- Ensure that you are using a public [image that supports gVNIC](/compute/docs/images/os-details#networking) or [create a custom image](/compute/docs/networking/using-gvnic#create-custom-image) in your project.\n- Verify that you created VPC firewall rules to allow ingress on port TCP:5001, or another port of your choosing, to allow for`iperf`performance testing.\n- Use iPerf version 2, not version 3, to perform the benchmarking.\n- If you haven't already, set up authentication. [Authentication](/compute/docs/authentication) is the process by which your identity is verified for access to Google Cloud services and APIs. To run code or samples from a local development environment, you can authenticate to Compute Engine as follows.Select the tab for how you plan to use the samples on this page:\nWhen you use the Google Cloud console to access Google Cloud services and   APIs, you don't need to set up authentication.- [Install](/sdk/docs/install) the Google Cloud CLI, then [initialize](/sdk/docs/initializing) it by running the following command:```\ngcloud init\n``` **Note:** If you installed the gcloud CLI  previously, make sure you have the latest version by running`gcloud components  update`.\n- [ Set a default region and zone](/compute/docs/gcloud-compute#set_default_zone_and_region_in_your_local_client) .\nTo use the REST API samples on this page in a local development environment, you use the credentials you provide to the gcloud CLI.- [Install](/sdk/docs/install) the Google Cloud CLI, then [initialize](/sdk/docs/initializing) it by running the following command:\n- ```\ngcloud init\n```## Setting up VMs for benchmarking\nCreate two `n2-standard-64` vCPU machines with per VM Tier_1 networking performance enabled and the highest [maximum transmission unit (MTU)](/vpc/docs/mtu) setting. This gives your VMs up to 75 Gbps of maximum egress bandwidth (using internal IPs).\n**Note:** To benchmark the egress for external IP addresses, you will need to associate external IP addresses with the VMs, and use those IP addresses as the target during testing.\n- To create an image, use the [gcloud compute images create command](/sdk/gcloud/reference/compute/images/create) .```\n gcloud compute images create IMAGE_NAME \\\n --project=PROJECT_ID \\\n --source-image-family=SOURCE_IMAGE_FAMILY \\\n --source-image-project=SOURCE_IMAGE_PROJECT \\\n --guest-os-features=GVNIC\n```Replace the following:- : the name of your project.\n- : the name of the image that you want to create.\n- : required version of a public image. For this test, use`ubuntu-2004-lts`.\n- : the name of the project that contains the source image. For this test, use`ubuntu-os-cloud`.\n **Example** ```\ngcloud compute images create benchmark-image-test \\\u00a0 --project=my-project \\\u00a0 --source-image-family=ubuntu-2004-lts \\\u00a0 --source-image-project=ubuntu-os-cloud \\\u00a0 --guest-os-features=GVNIC\n```\n- Create an auto mode VPC network that uses the maximum MTU setting:```\n gcloud compute networks create NETWORK_NAME \\\n --project=PROJECT_ID \\\n --subnet-mode=AUTO --mtu=8896\n```Replace the following:- : the name of your project.\n- : a name for the network.\n- Create two identical instances:```\n gcloud compute instances create \\\n  VM_NAME_1 VM_NAME_2 \\\n  --project=PROJECT_ID \\\n  --zone=ZONE \\\n  --machine-type=n2-standard-64 \\\n  --image=projects/PROJECT_NAME/global/images/IMAGE_NAME \\\n  --network=NETWORK_NAME \\\n  --network-interface=nic-type=GVNIC \\\n  --network-performance-configs=total-egress-bandwidth-tier=TIER_1\n```Replace the following:- ,: the names of the VM instances that you want to create.\n- : your project name.\n- : your VM's zone. Both VMs must reside in the same zone.\n- /global/images/: your project name and the image name.\n- : the name of the network you configured with the maximum MTU setting.\n## Performing the benchmark\nYour two VMs must reside in the same zone and on the same [VPC network](/vpc/docs/create-modify-vpc-networks) . During the benchmark, these two VMs conduct bi-directional testing of the VPC network path.\n### Verify the MTU setting\nConfirm the Virtual Private Cloud (VPC) network has the maximum MTU setting configured by using `ifconfig` in the guest OS of one of the VMs.\n- [Connect to one of the VMs](/compute/docs/instances/ssh) .\n- In the terminal window, run the following command:```\n /sbin/ifconfig | grep mtu\n```The reported MTU should be 8896.```\n ens4: flags=4163 mtu 8896\n lo: flags=73 mtu 65536\n```\n### Verify the VM configuration\nConfirm the virtual machines have Tier_1 networking enabled by examining the virtual machine properties.\nTo view the instances, use the [gcloud compute instances describe command](/sdk/gcloud/reference/compute/instances/describe) .\n```\ngcloud compute instances describe VM_NAME_1 \\\n --project=PROJECT_ID \\\n --zone=ZONE \\\n --format=\"text(networkPerformanceConfig)\"\n```\n```\ngcloud compute instances describe VM_NAME_2 \\\n --project=PROJECT_ID \\\n --zone=ZONE \\\n --format=\"text(networkPerformanceConfig)\"\n```\nReplace the following:- : the names of the VM instance that  you want to view.\n- :  the names of the VM instance that you want to view.\n- : your project name.\n- : your VM's zone. Both VMs must reside  in the same zone.\nIn the response you should see the following:\n`networkPerformanceConfig.totalEgressBandwidthTier: TIER_1`\n### Use iPerf to perform the benchmark on Debian-based systems\n**Note:** Ensure that you are using iPerf version 2 and not version 3; iPerf version 3 does not support multi-threading (by design) and can have performance implications in your results when running multiple streams.\n- If you haven't already done so, complete the steps in [Setting up VMs for benchmarking](#setup-benchmark-vms) .\n- After both VMs are running, use SSH to connect to one of the VMs.```\ngcloud compute ssh VM_NAME_1 \\\n --project=PROJECT_ID\n```Replace the following:- : the name of your first VM.\n- : your project name.\n- On the first VM, complete the following steps:- Install `iperf` .```\nsudo apt-get update && sudo apt-get install iperf\n```\n- Get the internal IP address for this VM. Make note of the internal IP address for later use.```\nip a\n```\n- Start up the iPerf server.```\niperf -s\n```This starts up a server listening for connections in order to perform the benchmark. Leave the iPerf server running for the duration of the test.\n- In a separate client terminal, connect to the second VM using SSH.```\ngcloud compute ssh VM_NAME_2 \\\n --project=PROJECT_ID\n```Replace the following:- : the name of your second VM.\n- : your project name.\n- On the second VM, complete the following steps:- Install iPerf.```\nsudo apt-get update && sudo apt-get install iperf\n```\n- Run the iperf test and specify the first VM's IP address as the target. **Note:** The order of the arguments is important.```\niperf -t 30 -c internal_ip_of_instance_1 -P 16\n```This executes a 30-second test. If iPerf is not able to reach the other VM you, might need to adjust the network or [firewall settings](/vpc/docs/using-firewalls) on the VMs or perhaps in the Google Cloud console.Your results should look something like the following example. It shows the 75 Gbps egress bandwidth limit for `n2-standard-64` with [Tier_1 networking](/compute/docs/networking/configure-vm-with-high-bandwidth-configuration#bandwidth-tiers) enabled, exceeding the default 32 Gbps egress bandwidth limit.```\n-----------------------------------------------------------Client connecting to 10.128.0.10, TCP port 5001\nTCP window size: 1.59 MByte (default)\n-----------------------------------------------------------[ 12] local 10.128.0.11 port 57722 connected with 10.128.0.10 port 5001\n[ 11] local 10.128.0.11 port 57720 connected with 10.128.0.10 port 5001\n[ 16] local 10.128.0.11 port 57730 connected with 10.128.0.10 port 5001\n[ 6] local 10.128.0.11 port 57710 connected with 10.128.0.10 port 5001\n[ 13] local 10.128.0.11 port 57724 connected with 10.128.0.10 port 5001\n[ 8] local 10.128.0.11 port 57712 connected with 10.128.0.10 port 5001\n[ 9] local 10.128.0.11 port 57716 connected with 10.128.0.10 port 5001\n[ 14] local 10.128.0.11 port 57726 connected with 10.128.0.10 port 5001\n[ 15] local 10.128.0.11 port 57728 connected with 10.128.0.10 port 5001\n[ 10] local 10.128.0.11 port 57718 connected with 10.128.0.10 port 5001\n[ 4] local 10.128.0.11 port 57706 connected with 10.128.0.10 port 5001\n[ 5] local 10.128.0.11 port 57708 connected with 10.128.0.10 port 5001\n[ 3] local 10.128.0.11 port 57704 connected with 10.128.0.10 port 5001\n[ 17] local 10.128.0.11 port 57732 connected with 10.128.0.10 port 5001\n[ 7] local 10.128.0.11 port 57714 connected with 10.128.0.10 port 5001\n[ 18] local 10.128.0.11 port 57734 connected with 10.128.0.10 port 5001\n[ ID] Interval  Transfer  Bandwidth\n[ 12] 0.0-30.0 sec 7.63 GBytes 2.19 Gbits/sec\n[ 11] 0.0-30.0 sec 17.7 GBytes 5.07 Gbits/sec\n[ 16] 0.0-30.0 sec 9.15 GBytes 2.62 Gbits/sec\n[ 6] 0.0-30.0 sec 43.8 GBytes 12.6 Gbits/sec\n[ 13] 0.0-30.0 sec 23.6 GBytes 6.76 Gbits/sec\n[ 8] 0.0-30.0 sec 13.3 GBytes 3.80 Gbits/sec\n[ 9] 0.0-30.0 sec 9.29 GBytes 2.66 Gbits/sec\n[ 14] 0.0-30.0 sec 19.6 GBytes 5.62 Gbits/sec\n[ 15] 0.0-30.0 sec 12.5 GBytes 3.58 Gbits/sec\n[ 10] 0.0-30.0 sec 11.1 GBytes 3.19 Gbits/sec\n[ 4] 0.0-30.0 sec 19.0 GBytes 5.43 Gbits/sec\n[ 5] 0.0-30.0 sec 7.32 GBytes 2.10 Gbits/sec\n[ 3] 0.0-30.0 sec 8.78 GBytes 2.51 Gbits/sec\n[ 17] 0.0-30.0 sec 17.5 GBytes 5.02 Gbits/sec\n[ 7] 0.0-30.0 sec 33.4 GBytes 9.57 Gbits/sec\n[ 18] 0.0-30.0 sec 7.64 GBytes 2.19 Gbits/sec\n[SUM] 0.0-30.0 sec 261 GBytes 74.9 Gbits/sec\n```\n## Remove resources after benchmark testing\nRemove the resources you created during the benchmark testing to avoid charges for the image and additional VMs.\n- Use the [gcloud compute instances delete command](/sdk/gcloud/reference/compute/instances/delete) to remove the instances you created for benchmark testing.```\ngcloud compute instances delete \\\n VM_NAME_1 VM_NAME_2 \\\n --project=PROJECT_ID \\\n --zone=ZONE\n```Replace the following:- ,: the names of the two VM instances that you want to delete.\n- : your project name.\n- : your VM's zone. Both VMs should be in the same zone.\n- Use the [gcloud compute networks delete command](/sdk/gcloud/reference/compute/networks/delete) to remove the network you created for benchmark testing.```\ngcloud compute networks delete NETWORK_NAME \\\n --project=PROJECT_ID\n```Replace the following:- : the name of the network that you want to delete.\n- : your project name.\n- Use the [gcloud compute images delete command](/sdk/gcloud/reference/compute/images/delete) to remove the image you created for benchmark testing.```\n gcloud compute images delete IMAGE_NAME \\\n --project=PROJECT_ID\n```Replace the following:- : the name of the image that you want to delete.\n- : your project name.\n## What's next\n- Learn about [Tier_1 networking pricing](/compute/all-pricing#high_bandwidth_configuration) .\n- Review [bandwidth tiers](/compute/docs/networking/configure-vm-with-high-bandwidth-configuration#bandwidth-tiers) for additional machine types.", "guide": "Compute Engine"}