{"title": "Cloud Architecture Center - Automating cost optimizations with Cloud Functions, Cloud Scheduler, and Cloud Monitoring", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Automating cost optimizations with Cloud Functions, Cloud Scheduler, and Cloud Monitoring\nThis document shows you how to use\n [Cloud Functions](/functions) \nto identify and clean up wasted cloud resources, schedule functions to run with\n [Cloud Scheduler](/scheduler) \n, and use\n [Cloud Monitoring](/monitoring) \nalerting policies to execute them based on observed usage. This document is intended for developers, SREs, cloud architects, and cloud infrastructure admins who are looking for a systematic and automated approach to identify and reduce wasteful cloud spending.\nThis document assumes that you're familiar with the following:- [The Cloud Functions Python runtime](/functions/docs/concepts/python-runtime) \n- [The Cloud Functions Node.js 8 runtime](/functions/docs/concepts/nodejs-8-runtime) \n- [Alerting policies in Monitoring](/monitoring/alerts) \n- RESTful APIs\n", "content": "## Objectives\n- Delete unused IP addresses: On Google Cloud, [static IP addresses are a free resource](/compute/all-pricing#ipaddress) when they're attached to a load balancer or virtual machine (VM) instance. When a static IP address is reserved, but not used, it accumulates an hourly charge. In apps that heavily depend on static IP addresses and large-scale dynamic provisioning, this waste can become significant over time.\n- Delete orphaned or unused persistent disks: [Persistent disks](/compute/all-pricing#disk) are unused or orphaned if they're created without ever being attached to a VM, or if a machine has multiple disks and one or more disks are detached.\n- Migrate to a less expensive storage classes: Google Cloud offers [multiple classes of object storage](/storage/pricing#storage-pricing) . Use the class that best fits your needs.\n## ArchitectureThe following diagram describes the first part of the deployment, where you schedule a Cloud Function to identify and clean up unused IP addresses.The first example covers the following:- Creating a Compute Engine VM with a static external IP address and a separate unused static external IP address.\n- Deploying a Cloud Function to identify unused addresses.\n- Creating a Cloud Scheduler job to schedule the function to run by using an HTTP trigger.\nIn the following diagram, you schedule a Cloud Function to identify and clean up unattached and orphaned persistent disks.The second example covers the following:- Creating a Compute Engine VM with two persistent disks and a separate unattached persistent disk. One of the disks isby being detached from the VM.\n- Deploying a Cloud Function to identify unattached and orphaned persistent disks.\n- Creating a Cloud Scheduler job to schedule the execution of the Cloud Function by using an HTTP trigger.\nIn the following diagram, you trigger a Cloud Function to migrate a storage bucket to a less expensive storage class from a Monitoring alerting policy.The third example covers the following:- Creating two storage buckets, adding a file to the serving bucket, and generating traffic against it.\n- Creating a Monitoring dashboard to visualize bucket utilization.\n- Deploying a Cloud Function to migrate the idle bucket to a less expensive storage class.\n- Triggering the function by using a payload intended to simulate a notification received from a Monitoring alerting policy.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Compute Engine](/compute/pricing) \n- [Cloud Storage](/storage/pricing) \n- [Cloud Functions](/functions/pricing) \n- [Monitoring](/monitoring/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.\n- You run all the commands in this document from Cloud Shell.## Setting up your environmentIn this section, you configure the infrastructure and identities that are required for this architecture.- In Cloud Shell, clone the repository and change to the `gcf-automated-resource-cleanup` directory:```\ngit clone https://github.com/GoogleCloudPlatform/gcf-automated-resource-cleanup.git && cd gcf-automated-resource-cleanup/\n```\n- Set the environment variables and make the repository folder your `$WORKDIR` folder, where you run all the commands:```\nexport PROJECT_ID=$(gcloud config list \\\u00a0 \u00a0 --format 'value(core.project)' 2>/dev/null)\u00a0 \u00a0 WORKDIR=$(pwd)\n```\n- Install [Apache Bench](https://httpd.apache.org/docs/2.4/programs/ab.html) , an open source load-generation tool:```\nsudo apt-get install apache2-utils\n```\n## Cleaning up unused IP addressesIn this section, you complete the following steps:- Create two static IP addresses.\n- Create a VM that uses a static IP address.\n- Review the Cloud Functions code.\n- Deploy the Cloud Function.\n- Test the Cloud Function by using Cloud Scheduler jobs.\n### Create IP addresses\n- In Cloud Shell, change to the `unused-ip` directory:```\ncd $WORKDIR/unused-ip\n```\n- Export the names of the IP addresses as variables:```\nexport USED_IP=used-ip-addressexport UNUSED_IP=unused-ip-address\n```\n- Create two static IP addresses:```\ngcloud compute addresses create $USED_IP \\\u00a0 \u00a0 --project=$PROJECT_ID --region=us-central1gcloud compute addresses create $UNUSED_IP \\\u00a0 \u00a0 --project=$PROJECT_ID --region=us-central1\n```This example uses the `us-central1` region, but you can [choose a different region](/about/locations) and refer to it consistently throughout the rest of this document.\n- Confirm that two addresses were created:```\ngcloud compute addresses list --filter=\"region:(us-central1)\"\n```In the output, a status of `RESERVED` means that the IP addresses aren't in use:```\nNAME    ADDRESS/RANGE TYPE  REGION  SUBNET STATUS\nunused-ip-address 35.232.144.85 EXTERNAL us-central1   RESERVED\nused-ip-address 104.197.56.87 EXTERNAL us-central1   RESERVED\n```\n- Set the used IP address as an environment variable:```\nexport USED_IP_ADDRESS=$(gcloud compute addresses describe $USED_IP \\\u00a0 \u00a0 --region=us-central1 --format=json | jq -r '.address')\n```\n### Create a VM\n- In Cloud Shell, create an instance:```\ngcloud compute instances create static-ip-instance \\\u00a0 \u00a0 --zone=us-central1-a \\\u00a0 \u00a0 --machine-type=n1-standard-1 \\\u00a0 \u00a0 --subnet=default \\\u00a0 \u00a0 --address=$USED_IP_ADDRESS\n```\n- Confirm that one of the IP addresses is now in use:```\ngcloud compute addresses list --filter=\"region:(us-central1)\"\n```The output is similar to the following:```\nNAME    ADDRESS/RANGE TYPE  REGION  SUBNET STATUS\nunused-ip-address 35.232.144.85 EXTERNAL us-central1   RESERVED\nused-ip-address 104.197.56.87 EXTERNAL us-central1   IN_USE\n```\n### Review the Cloud Function code\n- In Cloud Shell, output the main section of the code:```\ncat $WORKDIR/unused-ip/function.js | grep \"const compute\" -A 31\n```The output is as follows:```\nconst compute = new Compute();\ncompute.getAddresses(function(err, addresses){ // gets all addresses across regions\n  if(err){\n   console.log(\"there was an error: \" + err);\n  }\n  if (addresses == null) {\n   console.log(\"no addresses found\");\n   return;\n  }\n  console.log(\"there are \" + addresses.length + \" addresses\");\n  // iterate through addresses\n  for (let item of addresses){\n   // get metadata for each address\n   item.getMetadata(function(err, metadata, apiResponse) {\n    // if the address is not used AND if it's at least ageToDelete days old:\n    if ((metadata.status=='RESERVED') & (calculateAge(metadata.creationTimestamp) >= ageToDelete)){\n     // delete address\n     item.delete(function(err, operation, apiResponse2){\n      if (err) {\n       console.log(\"could not delete address: \" + err);\n      }\n     })\n    }\n   })\n  }\n  // return number of addresses evaluated\n  res.send(\"there are \" + addresses.length + \" total addresses\");\n });\n}\n```In the preceding code sample, pay attention to the following:- ```\ncompute.getAddresses(function(err, addresses){ // gets all addresses across regions\n```Uses the `getAddresses` method to retrieve IP addresses across all regions in the project.\n- ```\n// get metadata for each address\nitem.getMetadata(function(err, metadata, apiResponse) {\n // if the address is not used:\n  if (metadata.status=='RESERVED'){\n```Gets the metadata for each IP address and checks its `STATUS` field.\n- ```\nif ((metadata.status=='RESERVED') &\n(calculateAge(metadata.creationTimestamp) >= ageToDelete)){\n```Checks whether the IP address is in use, calculates its age by using a helper function, and compares its age against a constant (set to `0` for the purposes of the example).\n- ```\n// delete address\nitem.delete(function(err, operation, apiResponse2){\n```Deletes the IP address.\n### Deploy the Cloud Function\n- In Cloud Shell, deploy the Cloud Function:```\ngcloud functions deploy unused_ip_function --trigger-http --runtime=nodejs8\n```\n- Set the trigger URL as an environment variable:```\nexport FUNCTION_URL=$(gcloud functions describe unused_ip_function \\\u00a0 \u00a0 --format=json | jq -r '.httpsTrigger.url')\n```\n### Schedule and test the Cloud Function\n- In Cloud Shell, create a Cloud Scheduler task to run the Cloud Function at 2 AM every day:```\ngcloud scheduler jobs create http unused-ip-job \\\u00a0 \u00a0 --schedule=\"* 2 * * *\" \\\u00a0 \u00a0 --uri=$FUNCTION_URL\n```\n- Test the job by manually triggering it:```\ngcloud scheduler jobs run unused-ip-job\n```\n- Confirm that the unused IP address was deleted:```\ngcloud compute addresses list --filter=\"region:(us-central1)\"\n```The output is similar to the following:```\nNAME    ADDRESS/RANGE TYPE  REGION  SUBNET STATUS\nused-ip-address 104.197.56.87 EXTERNAL us-central1   IN_USE\n```\n## Cleaning up unused and orphaned persistent disksIn this section, you complete the following steps:- Create two persistent disks.\n- Create a VM that uses one of the disks.\n- Detach the disk from the VM.\n- Review the Cloud Function code.\n- Deploy the Cloud Function.\n- Test the Cloud Function by using Cloud Scheduler jobs.\n### Create persistent disks\n- In Cloud Shell, change to the `unattached-pd` directory:```\ncd $WORKDIR/unattached-pd\n```\n- Export the names of the disks as environment variables:```\nexport ORPHANED_DISK=orphaned-diskexport UNUSED_DISK=unused-disk\n```\n- Create the two disks:```\ngcloud beta compute disks create $ORPHANED_DISK \\\u00a0 \u00a0--project=$PROJECT_ID \\\u00a0 \u00a0--type=pd-standard \\\u00a0 \u00a0--size=500GB \\\u00a0 \u00a0--zone=us-central1-agcloud beta compute disks create $UNUSED_DISK \\\u00a0 \u00a0 --project=$PROJECT_ID \\\u00a0 \u00a0 --type=pd-standard \\\u00a0 \u00a0 --size=500GB \\\u00a0 \u00a0 --zone=us-central1-a\n```\n- Confirm that the two disks were created:```\ngcloud compute disks list\n```The output is as follows:```\nNAME    LOCATION  LOCATION_SCOPE SIZE_GB TYPE   STATUS\norphaned-disk  us-central1-a zone   500  pd-standard READY\nstatic-ip-instance us-central1-a zone   10  pd-standard READY\nunused-disk   us-central1-a zone   500  pd-standard READY\n```\n### Create a VM and inspect the disks\n- In Cloud Shell, create the instance:```\ngcloud compute instances create disk-instance \\\u00a0 \u00a0 --zone=us-central1-a \\\u00a0 \u00a0 --machine-type=n1-standard-1 \\\u00a0 \u00a0 --disk=name=$ORPHANED_DISK,device-name=$ORPHANED_DISK,mode=rw,boot=no\n```\n- Inspect the disk that was attached to the VM:```\ngcloud compute disks describe $ORPHANED_DISK \\\u00a0 \u00a0 --zone=us-central1-a \\\u00a0 \u00a0 --format=json | jq\n```The output is similar to the following:```\n{\n \"creationTimestamp\": \"2019-06-12T12:21:25.546-07:00\",\n \"id\": \"7617542552306904666\",\n \"kind\": \"compute#disk\",\n \"labelFingerprint\": \"42WmSpB8rSM=\",\n \"lastAttachTimestamp\": \"2019-06-12T12:24:53.989-07:00\",\n \"name\": \"orphaned-disk\",\n \"physicalBlockSizeBytes\": \"4096\",\n \"selfLink\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/disks/orphaned-disk\",\n \"sizeGb\": \"500\",\n \"status\": \"READY\",\n \"type\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/diskTypes/pd-standard\",\n \"users\": [ \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/instances/disk-instance\"\n ],\n \"zone\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a\"\n}\n```In the preceding code sample, pay attention to the following:- `users`identifies the VM that the disk is attached to.\n- `lastAttachTimestamp`identifies when the disk was last attached to a VM.\n- Inspect the disk that hasn't been attached to a VM:```\ngcloud compute disks describe $UNUSED_DISK \\\u00a0 \u00a0 --zone=us-central1-a \\\u00a0 \u00a0 --format=json | jq\n```The output is similar to the following:```\n{\n \"creationTimestamp\": \"2019-06-12T12:21:30.905-07:00\",\n \"id\": \"1313096191791918677\",\n \"kind\": \"compute#disk\",\n \"labelFingerprint\": \"42WmSpB8rSM=\",\n \"name\": \"unused-disk\",\n \"physicalBlockSizeBytes\": \"4096\",\n \"selfLink\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/disks/unused-disk\",\n \"sizeGb\": \"500\",\n \"status\": \"READY\",\n \"type\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/diskTypes/pd-standard\",\n \"zone\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a\"\n}\n```In the preceding code sample, the following is important:- The disk doesn't have`users`listed because it's notin use by a VM.\n- The disk doesn't have`lastAttachedTimestamp`because it's neverused.\n- Detach the orphaned persistent disk from the VM:```\ngcloud compute instances detach-disk disk-instance \\\u00a0 \u00a0 --device-name=$ORPHANED_DISK \\\u00a0 \u00a0 --zone=us-central1-a\n```\n- Inspect the orphaned disk:```\ngcloud compute disks describe $ORPHANED_DISK \\\u00a0 \u00a0 --zone=us-central1-a \\\u00a0 \u00a0 --format=json | jq\n```The output is similar to the following:```\n{\n \"creationTimestamp\": \"2019-06-12T12:21:25.546-07:00\",\n \"id\": \"7617542552306904666\",\n \"kind\": \"compute#disk\",\n \"labelFingerprint\": \"42WmSpB8rSM=\",\n \"lastAttachTimestamp\": \"2019-06-12T12:24:53.989-07:00\",\n \"lastDetachTimestamp\": \"2019-06-12T12:34:56.040-07:00\",\n \"name\": \"orphaned-disk\",\n \"physicalBlockSizeBytes\": \"4096\",\n \"selfLink\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/disks/orphaned-disk\",\n \"sizeGb\": \"500\",\n \"status\": \"READY\",\n \"type\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a/diskTypes/pd-standard\",\n \"zone\": \"https://www.googleapis.com/compute/v1/projects/automating-cost-optimization/zones/us-central1-a\"\n}\n```In the preceding code sample, the following is important:- The disk doesn't have`users`listed, which indicates that it isn't currently in use.\n- There is now a`lastDetachTimestamp`entry, indicating when the disk was last detached from a VM and, therefore, when it was last in use.\n- The`lastAttachTimestamp`field is still present.\n### Review the Cloud Function code\n- In Cloud Shell, output the section of the code that retrieves all persistent disks in the project:```\ncat $WORKDIR/unattached-pd/main.py | grep \"(request)\" -A 12\n```The output is as follows:```\ndef delete_unattached_pds(request):\n # get list of disks and iterate through it:\n disksRequest = compute.disks().aggregatedList(project=project)\n while disksRequest is not None:\n  diskResponse = disksRequest.execute()\n  for name, disks_scoped_list in diskResponse['items'].items():\n   if disks_scoped_list.get('warning') is None:\n    # got disks\n    for disk in disks_scoped_list['disks']: # iterate through disks\n     diskName = disk['name']\n     diskZone = str((disk['zone'])).rsplit('/',1)[1]\n     print (diskName)\n     print (diskZone)\n```The function uses the `aggregatedList` method to get all persistent disks in the Google Cloud project where it's running and iterates through each of the disks.\n- Output the section of the code that checks the `lastAttachTimestamp` field and deletes the disk if it doesn't exist:```\ncat $WORKDIR/unattached-pd/main.py | grep \"handle never\" -A 11\n```The output is as follows:```\n# handle never attached disk - delete it\n# lastAttachedTimestamp is not present\nif disk.get(\"lastAttachTimestamp\") is None:\n  print (\"disk \" + diskName + \" was never attached - deleting\")\n  deleteRequest = compute.disks().delete(project=project,\n    zone=diskZone,\n    disk=diskName)\n  deleteResponse = deleteRequest.execute()\n  waitForZoneOperation(deleteResponse, project, diskZone)\n  print (\"disk \" + diskName + \" was deleted\")\n  Continue\n```This section deletes the disk if `lastAttachTimestamp` isn't present\u2014meaning this disk was never in use.\n- Output the section of the code that calculates the age of the disk if it's orphaned, creates a snapshot of it, and deletes it:```\ncat $WORKDIR/unattached-pd/main.py | grep \"handle detached\" -A 32\n```The output is as follows:```\n# handle detached disk - snapshot and delete\n# lastAttachTimestamp is present AND users is not present AND it meets the age criterium\nif disk.get(\"users\") is None \\\n and disk.get(\"lastDetachTimestamp\") is not None \\\n and diskAge(disk['lastDetachTimestamp'])>=deleteAge:\n print (\"disk \" + diskName + \" has no users and has been detached\")\n print (\"disk meets age criteria for deletion\")\n # take a snapshot\n snapShotName = diskName + str(int(time.time()))\n print (\"taking snapshot: \" + snapShotName)\n snapshotBody = {\n  \"name\": snapShotName\n }\n snapshotRequest = compute.disks().createSnapshot(project=project,\n   zone=diskZone,\n   disk=diskName,\n   body=snapshotBody)\n snapshotResponse = snapshotRequest.execute()\n waitForZoneOperation(snapshotResponse, project, diskZone)\n print (\"snapshot completed\")\n # delete the disk\n print (\"deleting disk \" + diskName)\n deleteRequest = compute.disks().delete(project=project,\n  zone=diskZone,\n  disk=diskName)\n deleteResponse = deleteRequest.execute()\n waitForZoneOperation(deleteResponse, project, diskZone)\n print (\"disk \" + diskName + \" was deleted\")\n continue\n```This section of code is used when the disk does have `users` listed and `lastDetachTimestamp` is present, which means the disk is currently not in use, but was used at some time. In this case, the Cloud Function creates a snapshot of the disk to retain data and then deletes the disk.\n### Deploy the Cloud Function\n- In Cloud Shell, deploy the Cloud Function:```\ngcloud functions deploy delete_unattached_pds \\\u00a0 \u00a0 --trigger-http --runtime=python37\n```\n- Set the trigger URL of the Cloud Function as an environment variable:```\nexport FUNCTION_URL=$(gcloud functions describe delete_unattached_pds \\\u00a0 \u00a0 --format=json | jq -r '.httpsTrigger.url')\n```\n### Schedule and test the Cloud Function\n- In Cloud Shell, create a Cloud Scheduler task to run the Cloud Function at 2 AM every day:```\ngcloud scheduler jobs create http unattached-pd-job \\\u00a0 \u00a0 --schedule=\"* 2 * * *\" \\\u00a0 \u00a0 --uri=$FUNCTION_URL\n```\n- Test the job:```\ngcloud scheduler jobs run unattached-pd-job\n```\n- Confirm that a snapshot of the orphaned disk was created:```\ngcloud compute snapshots list\n```The output is similar to the following:```\nNAME      DISK_SIZE_GB SRC_DISK       STATUS\norphaned-disk1560455894 500   us-central1-a/disks/orphaned-disk READY\n```\n- Confirm that the unused disk and the orphaned disk were deleted:```\ngcloud compute disks list\n```The output is as follows:```\nNAME    LOCATION  LOCATION_SCOPE SIZE_GB TYPE   STATUS\ndisk-instance  us-central1-a zone   10  pd-standard READY\nstatic-ip-instance us-central1-a zone   10  pd-standard READY\n```\n## Migrating storage buckets to less expensive storage classesGoogle Cloud provides [storage object lifecycle rules](/storage/docs/lifecycle) that you can use to automatically move objects to different storage classes based on a set of attributes, such as their creation date or live state. However, these rules don't know whether the objects have been accessed. Sometimes, you might want to move newer objects to Nearline Storage if they haven't been accessed for a certain amount of time.\nIn this section, you complete the following steps:- Create two Cloud Storage buckets.\n- Add an object to one of the buckets.\n- Configure Monitoring to observe bucket object access.\n- Review the Cloud Function code that migrates objects from a Regional Storage bucket to a Nearline Storage bucket.\n- Deploy the Cloud Function.\n- Test the Cloud Function by using a Monitoring alert.\n### Create Cloud Storage buckets and add a file\n- In Cloud Shell, change to the `migrate-storage` directory:```\ncd $WORKDIR/migrate-storage\n```\n- Create the `serving-bucket` Cloud Storage bucket that is used later to change storage classes:```\nexport PROJECT_ID=$(gcloud config list \\\u00a0 \u00a0 --format 'value(core.project)' 2>/dev/null)gsutil mb -c regional -l us-central1 gs://${PROJECT_ID}-serving-bucket\n```\n- Make the bucket public:```\ngsutil acl ch -u allUsers:R gs://${PROJECT_ID}-serving-bucket\n```\n- Add a text file to the bucket:```\ngsutil cp $WORKDIR/migrate-storage/testfile.txt \u00a0\\\u00a0 \u00a0 gs://${PROJECT_ID}-serving-bucket\n```\n- Make the file public:```\ngsutil acl ch -u allUsers:R gs://${PROJECT_ID}-serving-bucket/testfile.txt\n```\n- Confirm that you're able to access the file:```\ncurl http://storage.googleapis.com/${PROJECT_ID}-serving-bucket/testfile.txt\n```The output is as follows:```\nthis is a test\n```\n- Create a second bucket called `idle-bucket` that doesn't serve any data:```\ngsutil mb -c regional -l us-central1 gs://${PROJECT_ID}-idle-bucket\n```\n### Set up a Cloud Monitoring workspaceIn this section, you configure Cloud Monitoring to observe bucket usage to understand when bucket objects aren't being used. When the serving bucket isn't used, a Cloud Function migrates the bucket from the Regional Storage class to the Nearline Storage class.- In the Google Cloud console, go to **Monitoring** . [Go to Cloud Monitoring](https://console.cloud.google.com/monitoring) \n- Click **New Workspace** , and then click **Add** .Wait for the initial configuration to complete.\n### Create a Cloud Monitoring dashboard\n- In Monitoring, go to **Dashboards** , and then click **Create Dashboard** .\n- Click **Add Chart** .\n- In the **Name** field, enter `Bucket Access` .\n- To find the request content metric for the Cloud Storage bucket, in the **Find resource and metric** field, enter `request` , and then select the **Request count** metric for the `gcs_bucket` resource.\n- To group the metrics by bucket name, in the **Group By** drop-down list, click **bucket_name** .\n- To filter by the method name, in the **Filter** field, enter **ReadObject** , and then click **Apply** .\n- Click **Save** .\n- In the name field, enter `Bucket Usage` .\n- To confirm that the dashboard is accessible, hold the pointer over **Dashboards** and verify that **Bucket Usage** appears.You've configured Monitoring to observe object access in your buckets. The chart doesn\u2018t display any data because there is no traffic to the Cloud Storage buckets.\n### Generate load on the serving bucketNow that monitoring is configured, use Apache Bench to send traffic to the serving bucket.- In Cloud Shell, send requests to the object in the serving bucket:```\nab -n 10000 \\\u00a0 \u00a0 http://storage.googleapis.com/$PROJECT_ID-serving-bucket/testfile.txt\n```\n- In the Google Cloud console, go to Monitoring. [Go to Cloud Monitoring](https://console.cloud.google.com/monitoring) \n- To select your **Bucket Usage** dashboard, hold your pointer over **Dashboards** and select **Bucket Usage** . Confirm that there is traffic only to the serving bucket. The `request_count metric` time series is displayed only for the serving bucket, because the idle bucket doesn't have any traffic to it.\n### Review and deploy the Cloud Function\n- In Cloud Shell, output the code that uses the Cloud Function to migrate a storage bucket to the Nearline Storage class:```\ncat $WORKDIR/migrate-storage/main.py | grep \"migrate_storage(\" -A 15\n```The output is as follows:```\ndef migrate_storage(request):\n # process incoming request to get the bucket to be migrated:\n request_json = request.get_json(force=True)\n # bucket names are globally unique\n bucket_name = request_json['incident']['resource_name']\n # create storage client\n storage_client = storage.Client()\n # get bucket\n bucket = storage_client.get_bucket(bucket_name)\n # update storage class\n bucket.storage_class = \"NEARLINE\"\n bucket.patch()\n```The Cloud Function uses the bucket name passed in the request to change its storage class to Nearline Storage.\n- Deploy the Cloud Function:```\ngcloud functions deploy migrate_storage --trigger-http --runtime=python37\n```\n- Set the trigger URL as an environment variable that you use in the next section:```\nexport FUNCTION_URL=$(gcloud functions describe migrate_storage \\\u00a0 \u00a0 --format=json | jq -r '.httpsTrigger.url')\n```\n### Test and validate alerting automation\n- Set the idle bucket name:```\nexport IDLE_BUCKET_NAME=$PROJECT_ID-idle-bucket\n```\n- Send a test notification to the Cloud Function you deployed by using the `incident.json` file:```\nenvsubst < $WORKDIR/migrate-storage/incident.json | curl -X POST \\\u00a0 \u00a0 -H \"Content-Type: application/json\" $FUNCTION_URL -d @```The output is as follows:```\nOK\n```The output isn't terminated with a newline and therefore is immediately followed by the command prompt.\n- Confirm that the idle bucket was migrated to Nearline Storage:```\ngsutil defstorageclass get gs://$PROJECT_ID-idle-bucket\n```The output is as follows:```\ngs://automating-cost-optimization-idle-bucket: NEARLINE\n```\n## Considerations for a production environmentWhen you automate cost optimizations in your own Google Cloud environment, consider the following:- General considerations: You should [increase security for Cloud Functions that have the power to modify or delete Google Cloud resources](/functions/docs/securing/authenticating) .\n- Identifying waste: This document covers a few examples of wasted spending. There are many other examples that generally fall into one of three categories:- Overprovisioned resources: Resources that are provisioned to be larger than necessary for a given workload, such as VMs with more CPU power and memory than necessary.\n- Idle resources: Resources that are entirely unused.\n- Part-time idle resources: Resources that are only used during business hours.\n- Automating cleanup: In this document, a multi-step process with multiple asynchronous operations was necessary to snapshot and delete the disk. Other Google Cloud resources such as unused IP addresses can use synchronous operations.\n- Deploying at scale: In this document, the Google Cloud project ID is defined in the Cloud Function code. To deploy such a solution at scale, consider using either the Cloud Billing or Cloud Resource Manager APIs to get the list of projects with a billing account or an organization. Then, pass those Google Cloud project IDs as variables to a function. In such a configuration, you need to add the service account of the Cloud Function to the projects where it can clean up or delete resources. We recommend using an automated deployment framework, such as [Cloud Deployment Manager](/deployment-manager) or [Terraform](https://www.terraform.io/) .\n- Alerting automation: This document shows you how to use a mock payload from a Monitoring alert to trigger the storage class migration. Monitoring alerting policies can be evaluated over a maximum of 23 hours and 59 minutes. In a production environment, this restriction might not be long enough to consider a bucket idle before migrating its storage class. Consider enabling data access audit logs on the Cloud Storage bucket and creating a pipeline that consumes these audit logs to evaluate whether a bucket has been used for serving in the last 30 days. For more information, review [understanding audit logs](/logging/docs/audit/understanding-audit-logs) and consider creating an [aggregated sink](/logging/docs/export/aggregated_sinks) to send logs to Pub/Sub and a Dataflow pipeline to process them.\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Watch [videos on cost management](https://www.youtube.com/playlist?list=PLIivdWyY5sqKeXavu1XuBNBDLBO31kzM0) .\n- Visit the [Cost Management home page](/cost-management) .\n- Review the [documentation for Cloud Billing](/billing/docs) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Cloud Architecture Center"}