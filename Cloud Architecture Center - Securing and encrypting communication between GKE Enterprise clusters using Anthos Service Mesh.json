{"title": "Cloud Architecture Center - Securing and encrypting communication between GKE Enterprise clusters using Anthos Service Mesh", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Securing and encrypting communication between GKE Enterprise clusters using Anthos Service Mesh\nLast reviewed 2021-04-30 UTC\nThis tutorial describes how to use [Anthos Service Mesh](/service-mesh/docs/overview) egress and ingress gateways to help secure inter-cluster traffic by using mutual Transport Layer Security (mTLS). The tutorial is intended for Kubernetes cluster administrators who are responsible for network, security, and platform aspects. The controls described here might be especially useful for organizations with heightened security requirements or to fulfill regulatory prerequisites. This tutorial is accompanied by a complementary [concept guide](/architecture/encrypt-secure-communication-between-multiple-anthos-clusters-concept) .\nThis tutorial assumes you are familiar with Kubernetes and Anthos Service Mesh.\n **Important:** This tutorial simulates a multi-environment deployment. It uses GKE on Google Cloud and Kubernetes Operations (kOps) to simulate an on-premise clusters. This setup is not meant to be used in production.", "content": "## Objectives\n- Use Terraform to set up infrastructure:- Create a custom VPC network with two private subnets.\n- Create two Kubernetes clusters with Anthos Service Mesh enabled:- One GKE cluster\n- One [Kubernetes Operations (kOps)](https://github.com/kubernetes/kops) cluster running in the custom VPC network\n- Register clusters to GKE Hub.\n- Deploy a MySQL client on GKE cluster.\n- Deploy a MySQL server on a kOps cluster.\n- Configure egress and ingress gateways to expose a server by using mTLS.\n- Test accessing a MySQL server by using a MySQL client that's running in different clusters or VPCs.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Google Kubernetes Engine (GKE)](/kubernetes-engine/pricing) \n- [Compute Engine](/compute/all-pricing) \n- [Container Registry](/container-registry/pricing) \n- [Anthos Service Mesh](/anthos/pricing) \n- [Cloud networking and load balancing](/vpc/network-pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you beginFor this tutorial, you need a Google Cloud project. You can create a new one, or select a project you already created:- In the Google Cloud console, go to the project selector page. [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- Select or create a Google Cloud project. **Note** : If you don't plan to keep the  resources that you create in this procedure, create a project instead of  selecting an existing project. After you finish these steps, you can  delete the project, removing all resources associated with the project.\n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\n- In the Google Cloud console, go to Cloud Shell. [Go to Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](https://console.cloud.google.com/?cloudshell=true)) session opens and displays a command-line prompt. Cloud Shell is a shell environment with the Google Cloud CLI already installed, including the [Google Cloud CLI](/sdk/gcloud) . It can take a few seconds for the session to initialize.\n- In Cloud Shell, make sure that you are working in the project that you created or selected:```\nexport PROJECT_ID=PROJECT_ID\ngcloud config set project ${PROJECT_ID}\n```Replace `` with your project ID.\n- Create an environment variable for the email address you use for Google Cloud:```\nexport GOOGLE_CLOUD_EMAIL_ADDRESS=GOOGLE_CLOUD_EMAIL_ADDRESS\n```Replace `` with the email address you use in Google Cloud.\n- Set the region and zone for your compute resources:```\nexport REGION=us-central1\nexport ZONE=us-central1-b\ngcloud config set compute/region ${REGION}\ngcloud config set compute/zone ${ZONE}\n```This tutorial uses `us-central1` for the region and `us-central1-b` for the zone. You can deploy to [a region of your choice](/about/locations#products-available-by-location) .\n- Set the required Identity and Access Management (IAM) roles. If you are a Project Owner, you have all the necessary permissions to complete the installation. Otherwise, ask your administrator to grant you Identity and Access Management (IAM) roles by running the following command in Cloud Shell:```\nROLES=(\n'roles/container.admin' \\\n'roles/gkehub.admin' \\\n'roles/iam.serviceAccountAdmin' \\\n'roles/iam.serviceAccountKeyAdmin' \\\n'roles/resourcemanager.projectIamAdmin' \\\n'roles/compute.securityAdmin' \\\n'roles/compute.instanceAdmin' \\\n'roles/storage.admin' \\\n'roles/serviceusage.serviceUsageAdmin'\n)\nfor role in \"${ROLES[@]}\"\ndo\n gcloud projects add-iam-policy-binding ${PROJECT_ID} \\\n --member \"user:${GOOGLE_CLOUD_EMAIL_ADDRESS}\" \\\n --role=\"$role\"\ndone\n```\n- Enable the APIs needed for the tutorial:```\ngcloud services enable \\\n anthos.googleapis.com \\\n anthosgke.googleapis.com \\\n anthosaudit.googleapis.com \\\n compute.googleapis.com \\\n container.googleapis.com \\\n cloudresourcemanager.googleapis.com \\\n serviceusage.googleapis.com \\\n stackdriver.googleapis.com \\\n monitoring.googleapis.com \\\n logging.googleapis.com \\\n cloudtrace.googleapis.com \\\n meshca.googleapis.com \\\n meshconfig.googleapis.com \\\n iamcredentials.googleapis.com \\\n gkeconnect.googleapis.com \\\n gkehub.googleapis.com\n``` **Note:** The meshtelemetry.googleapis.com API has been deprecated and is no longer available. Only the APIs in the preceding command need to be enabled.## Preparing your environment\n- In Cloud Shell, clone the following repository:```\ngit clone https://github.com/GoogleCloudPlatform/anthos-service-mesh-samplescd anthos-service-mesh-samples/docs/mtls-egress-ingress\n```\n- Update Terraform for your environment. By default, the Google Cloud console comes with Terraform 0.12. This tutorial assumes you have Terraform 0.13.5 or later installed. You can temporarily use another version of Terraform by running the following commands:```\nmkdir ~/bincurl https://releases.hashicorp.com/terraform/0.13.5/terraform_0.13.5_linux_amd64.zip -o ~/bin/terraform.zipunzip ~/bin/terraform.zip -d ~/bin/\n```\n- Go to the `terraform` subfolder and initialize Terraform:```\ncd terraform/~/bin/terraform init\n```\n- Create a `terraform.tfvars` file (based on the environment variables you created previously):```\ncat << EOF > terraform.tfvars\nproject_id = \"${PROJECT_ID}\"\nregion = \"${REGION}\"\nzones = [\"${ZONE}\"]\nEOF\n```In the next step, you create the initial infrastructure. To do this, you create and apply the Terraform execution plan for this configuration. The scripts and modules in this plan create the following:- A custom VPC network with two private subnets\n- Two Kubernetes clusters with Anthos Service Mesh enabled\n- One GKE cluster\n- One kOps cluster running in the custom VPC network\nThe execution plan also registers clusters to GKE Hub.\n- Run the execution plan:```\n~/bin/terraform plan -out mtls-terraform-plan~/bin/terraform apply \"mtls-terraform-plan\"\n```The output is similar to the following:```\nApply complete! Resources: 27 added, 0 changed, 0 destroyed.\nOutputs:\nserver_token = <sensitive>\n```The part is a Terraform output variable that is not shown on the console but can be queried\u2014for example, `~/bin/terraform output server_token` . **Note:** You can use this token to log in to your kOps clusters in the Google Cloud console.\n- Get your server cluster `kubeconfig` file from the `terraform` directory. Then merge it with the `client-cluster` config file:```\ncd ..export KUBECONFIG=client-server-kubeconfigcp ./terraform/server-kubeconfig $KUBECONFIGgcloud container clusters get-credentials client-cluster --zone ${ZONE} --project ${PROJECT_ID}\n```The `client-server-kubeconfig` file now holds the configuration for both clusters, which you can verify by running the following command:```\nkubectl config view -ojson | jq -r '.clusters[].name'\n```The output is the following:```\ngke_PROJECT_ID_us-central1-c_client-cluster\nserver-cluster.k8s.local\n```\n- Get the context for the two clusters for later use:```\nexport CLIENT_CLUSTER=$(kubectl config view -ojson | jq -r '.clusters[].name' | grep client)export SERVER_CLUSTER=$(kubectl config view -ojson | jq -r '.clusters[].name' | grep server)echo -e \"${CLIENT_CLUSTER}\\n${SERVER_CLUSTER}\"\n```The output is (again) the following:```\ngke_PROJECT_ID_us-central1-c_client-cluster\nserver-cluster.k8s.local\n```You can now use these cluster names as your context for further `kubectl` commands.\n- Reference the client cluster:```\nkubectl --context ${CLIENT_CLUSTER} get pods -n istio-system\n```\n- Reference the server cluster:```\nkubectl --context ${SERVER_CLUSTER} get pods -n istio-system\n```\n## Configuring the client sideAs mentioned in the [concept guide](/architecture/encrypt-secure-communication-between-multiple-anthos-clusters-concept) , the client side requires you to configure the egress gateway in Anthos Service Mesh.\nIn this section, you configure Anthos Service Mesh elements in order to identify external traffic based on its origin and to use a custom certificate to encrypt communication. Furthermore, you want to specifically route only that traffic to its destination (the MySQL DB in a container). Typically, you do this by using a service in Kubernetes. In this case, you need to catch that traffic inside the mesh communication. To catch the traffic, you use Istio elements to create a special definition of the service. You define the following elements:- Egress gateway\n- Service entry\n- Virtual service\n- TLS certificates (as a secret)\n- Destination rules\n- In Cloud Shell, get the IP address of the ingress gateway on the server-side by querying the load balancer IP address of the `istio-ingressgateway` service using the context of the server side ( `$SERVER_CLUSTER` , which you created previously):```\nINGRESS_HOST=$(kubectl -n istio-system --context ${SERVER_CLUSTER} get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n```Because the `INGRESS_HOST` is only the IP address part of your host, you need to create a [fully qualified domain name (FQDN)](https://wikipedia.org/wiki/Fully_qualified_domain_name) . This step is necessary because, in order to work properly, the certificates require a domain name.In this tutorial, you use the wildcard DNS service [nip.io](https://nip.io/) to create an FQDN for the ingress IP address. This service lets you create the FQDN without possessing a domain.\n- Store the FQDN service URL in an environment variable:```\nexport SERVICE_URL=\"${INGRESS_HOST}.nip.io\"\n```Now, with the `SERVICE_URL` defined as an FQDN, you can start defining the Istio part of the client cluster.\n### Create the egress gatewayYou start by creating the egress gateway to listen for traffic that's intended for the external service.\n- In Cloud Shell, create the following YAML file and name it `client-egress-gateway.yaml` :```\ncat <<EOF > client-egress-gateway.yamlapiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata:\u00a0name: istio-egressgateway-mysqlspec:\u00a0selector:\u00a0 \u00a0istio: egressgateway\u00a0servers:\u00a0- port:\u00a0 \u00a0 \u00a0number: 15443\u00a0 \u00a0 \u00a0name: tls\u00a0 \u00a0 \u00a0protocol: TLS\u00a0 \u00a0hosts:\u00a0 \u00a0- $SERVICE_URL\u00a0 \u00a0tls:\u00a0 \u00a0 \u00a0mode: ISTIO_MUTUALEOF\n``` **Note:** When applying the following YAML files, use the correct `--context` \u2014in this case, for the client cluster.\n- Apply the preceding YAML file to the client cluster:```\nkubectl --context ${CLIENT_CLUSTER} apply -f client-egress-gateway.yaml\n```Pay attention to the ports. You used the `default` ports here for the egress servers switch, which is `15443` . If you want to use a different port, you need to edit the egress gateway `service` object to add your custom ports.The `hosts` switch defines the endpoint, which is where the traffic should be heading.\n### Define the service entryThe next step is to tell the service mesh about the external service. Istio has its own registry where it stores service endpoints for the mesh. If Istio is installed on top of Kubernetes, the services defined in the cluster are added to the Istio registry automatically. With the service entry definition, you add a new endpoint to the Istio registry as shown in the following diagram.\n- In Cloud Shell, create the following YAML file and name it `client-service-entry.yaml` :```\ncat <<EOF > client-service-entry.yamlapiVersion: networking.istio.io/v1alpha3kind: ServiceEntrymetadata:\u00a0name: mysql-externalspec:\u00a0hosts:\u00a0 \u00a0- $SERVICE_URL\u00a0location: MESH_EXTERNAL\u00a0ports:\u00a0 \u00a0- number: 3306\u00a0 \u00a0 \u00a0name: tcp\u00a0 \u00a0 \u00a0protocol: TCP\u00a0 \u00a0- number: 13306\u00a0 \u00a0 \u00a0name: tls\u00a0 \u00a0 \u00a0protocol: TLS\u00a0resolution: DNS\u00a0endpoints:\u00a0 \u00a0- address: $SERVICE_URL\u00a0 \u00a0 \u00a0ports:\u00a0 \u00a0 \u00a0 \u00a0tls: 13306EOF\n```\n- Apply the preceding YAML file to the client cluster:```\nkubectl --context ${CLIENT_CLUSTER} apply -f client-service-entry.yaml\n```The client service definition in this YAML file tells the service what type of traffic to expect (MySQL L4 - [network layer four](https://wikipedia.org/wiki/OSI_model) , using port 3306). You also define that communication will go \"mesh external.\" In the endpoints section, you define that the flow should go toward the FQDN address `$SERVICE_URL` that you set earlier and which is mapped to the ingress gateway on the server cluster (kOps).\n### Define the virtual serviceA virtual service is a set of traffic routing rules to apply when a host is addressed. Each routing rule defines matching criteria for traffic of a specific protocol. If the traffic is matched, then it's sent to a named destination service (or a subset or version of it) defined in the registry. For more information, see the [Istio documentation](https://istio.io/latest/docs/reference/config/networking/virtual-service/) .The virtual service definition tells Istio how to apply the routing for the traffic that's reaching the external service. With the following definition, you tell the mesh to route the traffic from the client to the egress gateway on port `15443` . From the egress gateway, you then route traffic to the host `$SERVICE_URL` on port `13306` (where your server-side ingress gateway is listening).- Create the following YAML file and name it `client-virtual-service.yaml` :```\ncat <<EOF > client-virtual-service.yamlapiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:\u00a0name: direct-mysql-through-egress-gatewayspec:\u00a0hosts:\u00a0 \u00a0- $SERVICE_URL\u00a0gateways:\u00a0 \u00a0- istio-egressgateway-mysql\u00a0 \u00a0- mesh\u00a0tcp:\u00a0 \u00a0- match:\u00a0 \u00a0 \u00a0 \u00a0- gateways:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- mesh\u00a0 \u00a0 \u00a0 \u00a0 \u00a0port: 3306\u00a0 \u00a0 \u00a0route:\u00a0 \u00a0 \u00a0 \u00a0- destination:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0host: istio-egressgateway.istio-system.svc.cluster.local\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0subset: mysql\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0number: 15443\u00a0 \u00a0 \u00a0 \u00a0 \u00a0weight: 100\u00a0 \u00a0- match:\u00a0 \u00a0 \u00a0 \u00a0- gateways:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- istio-egressgateway-mysql\u00a0 \u00a0 \u00a0 \u00a0 \u00a0port: 15443\u00a0 \u00a0 \u00a0route:\u00a0 \u00a0 \u00a0 \u00a0- destination:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0host: $SERVICE_URL\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0number: 13306\u00a0 \u00a0 \u00a0 \u00a0 \u00a0weight: 100EOF\n```\n- Apply the YAML definition to the client cluster:```\nkubectl --context ${CLIENT_CLUSTER} apply -f client-virtual-service.yaml\n```You can specify which gateways the configuration should apply to by editing the `gateways` switch in the YAML file.The important part in this definition is the use of the reserved word `mesh` , which implies all the sidecars in the mesh. According to the Istio documentation, when this field is omitted, the default gateway (mesh) is used, applying the rule to all sidecars in the mesh. If you provide a list of gateway names, the rules apply only to the gateways. To apply the rules to gateways and sidecars, specify `mesh` as one of the gateway names.\nIn the next section, you define how to handle traffic that's leaving from the client prod's proxy, `match.gateways.mesh` . You also define how to route traffic from the egress to the external service by using the `match.gateways.istio-egressgateway-mysql` switch.\n### Define a destination rule (from client to egress gateway)Now that you've defined how to route traffic to the external service, you need to define what traffic policies should apply. The virtual service that you just defined is handling two routing cases at once. One handles traffic from the sidecar proxy to the egress gateway, and the other handles traffic from the egress gateway to the external service.\nTo match these cases with the destination rules, you need two separate rules. The following diagram shows the first rule, which handles traffic from the proxy to the egress gateway. In this definition, you tell Anthos Service Mesh to use its default certificates for mTLS communication.\n- In Cloud Shell, create the following YAML file and name it `client-destination-rule-to-egress-gateway.yaml` :```\ncat <<EOF > client-destination-rule-to-egress-gateway.yamlapiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata:\u00a0 name: egressgateway-for-mysqlspec:\u00a0 host: istio-egressgateway.istio-system.svc.cluster.local\u00a0 subsets:\u00a0 \u00a0 - name: mysql\u00a0 \u00a0 \u00a0 trafficPolicy:\u00a0 \u00a0 \u00a0 \u00a0 loadBalancer:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 simple: ROUND_ROBIN\u00a0 \u00a0 \u00a0 \u00a0 portLevelSettings:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 number: 15443\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tls:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mode: ISTIO_MUTUAL\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 sni: $SERVICE_URLEOF\n```\n- Apply the preceding YAML definition to the client cluster:```\nkubectl --context ${CLIENT_CLUSTER} apply -f client-destination-rule-to-egress-gateway.yaml\n```In the preceding YAML file, you used the `hosts` switch to define how to route traffic from the client proxy to the egress gateway. Also, you configured the mesh to use `ISTIO_MUTUAL` on port `15443` , which is one of the ports automatically open at the egress gateway.\n### Create a destination rule (from egress gateway to external service)The following diagram shows the second destination rule, which tells the mesh how to handle traffic from the egress gateway to the external service.You need to tell the mesh to use your injected certificates for mutual TLS communication with the external service.- In Cloud Shell, from the `anthos-service-mesh-samples/docs/mtls-egress-ingress` directory, create the certificates:```\n\u00a0./create-keys.sh\n```Make sure to **provide a password** when the script asks for it. **Note:** Client and server certificates will be created with [mtls-go-example](https://github.com/nicholasjackson/mtls-go-example) and are expected to be in a fixed location.\n- Copy the generated files to the current directory:```\ncp ./certs/2_intermediate/certs/ca-chain.cert.pem ca-chain.cert.pemcp ./certs/4_client/private/$SERVICE_URL.key.pem client-$SERVICE_URL.key.pemcp ./certs/4_client/certs/$SERVICE_URL.cert.pem client-$SERVICE_URL.cert.pem\n```\n- Create a Kubernetes secret that stores the certificates so that they can be referenced later in the gateway:```\n\u00a0kubectl --context ${CLIENT_CLUSTER} create secret -n istio-system \\\u00a0 generic client-credential \\\u00a0 --from-file=tls.key=client-$SERVICE_URL.key.pem \\\u00a0 --from-file=tls.crt=client-$SERVICE_URL.cert.pem \\\u00a0 --from-file=ca.crt=ca-chain.cert.pem\n```The preceding command adds the following certificate files to the secret:```\nclient-$SERVICE_URL.key.pem\nclient-$SERVICE_URL.cert.pem\nca-chain.cert.pem\n```The current best practice of distributing certificates is followed here by using [secret discovery service (SDS)](https://www.envoyproxy.io/docs/envoy/latest/configuration/security/secret#secret-discovery-service-sds) instead of file mounts. This practice avoids restarting the pods when adding a new certificate. Starting with Istio 1.8/1.9, with this technique you no longer need read access rights (RBAC) for the secret of the gateways.\n- Add the certificates to the `DestinationRule` and name it `client-destination-rule-to-external-service.yaml` :```\ncat <<EOF > client-destination-rule-to-external-service.yamlapiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata:\u00a0name: originate-mtls-for-mysqlspec:\u00a0host: $SERVICE_URL\u00a0trafficPolicy:\u00a0 \u00a0loadBalancer:\u00a0 \u00a0 \u00a0simple: ROUND_ROBIN\u00a0 \u00a0portLevelSettings:\u00a0 \u00a0- port:\u00a0 \u00a0 \u00a0 \u00a0number: 13306\u00a0 \u00a0 \u00a0tls:\u00a0 \u00a0 \u00a0 \u00a0mode: MUTUAL\u00a0 \u00a0 \u00a0 \u00a0credentialName: client-credential\u00a0 \u00a0 \u00a0 \u00a0sni: $SERVICE_URLEOF\n```\n- Apply the preceding YAML definition to the client cluster:```\nkubectl --context ${CLIENT_CLUSTER} apply -f client-destination-rule-to-external-service.yaml\n```This rule works only if you have created the secret beforehand. The secret ensures that the certificates are used for the mTLS encryption from egress gateway to the external endpoint.\nWhen you've completed these steps, your client side setup is done and looks like the following diagram.## Configuring the server sideAs discussed [in the concept guide]() , for the server side you need to configure the ingress gateway in Anthos Service Mesh. Before you create the necessary files, it's a good idea to review which components are required to realize the server part of the solution.\nBasically, you want to identify incoming traffic based on its origin and certificate. You also want to specifically route only that traffic to its destination: your MySQL DB in a container. Typically you use a service in Kubernetes to do this, but in this example, you identify the incoming traffic inside the mesh communication, so you need a special definition of a service that includes the following:- TLS certificates (as a secret)\n- Ingress gateway\n- Virtual service\n **Note:** When you apply the following YAML files, make sure you use the correct `--context` switch\u2014in this case, the context of the server cluster.\n### Create the secret for the ingress gatewayAs you did for the egress gateway, you need the same certificates to secure communication for the ingress gateway. To accomplish this, store the certificates in a secret and define this secret with your ingress gateway object.\n **Note:** Kubernetes secrets are not really encrypted. They use only Base64 encryption, which is more a binary string construct than a real encryption. In production, we recommend that you consider using a more secure secret manager such as [Hashicorp Vault](https://www.vaultproject.io/) .- In Cloud Shell, copy the generated files to the location you are executing the next command from:```\ncp ./certs/3_application/private/$SERVICE_URL.key.pem server-$SERVICE_URL.key.pemcp ./certs/3_application/certs/$SERVICE_URL.cert.pem server-$SERVICE_URL.cert.pem\n```\n- Create the server secret:```\nkubectl --context ${SERVER_CLUSTER} create secret -n istio-system \\\u00a0 \u00a0 generic mysql-credential \\\u00a0 \u00a0 --from-file=tls.key=server-$SERVICE_URL.key.pem \\\u00a0 \u00a0 --from-file=tls.crt=server-$SERVICE_URL.cert.pem \\\u00a0 \u00a0 --from-file=ca.crt=ca-chain.cert.pem\n```You just added the following certificate files to the secret:```\nserver-$SERVICE_URL.key.pem\nserver-$SERVICE_URL.cert.pem\nca-chain.cert.pem\n```\n### Define the ingress gatewayTo receive traffic from the client-side cluster, you need to specify an ingress gateway that can decrypt and verify the TLS communication by using the certificates.This diagram shows where the ingress gateway sits in your cluster. Traffic passes through and is inspected if it fits the security and forwarding criteria.- In Cloud Shell, use the following YAML file and name it `server-ingress-gatway.yaml` :```\ncat <<EOF > server-ingress-gatway.yamlapiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata:\u00a0name: gateway-mysqlspec:\u00a0selector:\u00a0 \u00a0istio: ingressgateway # Istio default gateway implementation\u00a0servers:\u00a0- port:\u00a0 \u00a0 \u00a0number: 13306\u00a0 \u00a0 \u00a0name: tls-mysql\u00a0 \u00a0 \u00a0protocol: TLS\u00a0 \u00a0tls:\u00a0 \u00a0 \u00a0mode: MUTUAL\u00a0 \u00a0 \u00a0credentialName: mysql-credential\u00a0 \u00a0hosts:\u00a0 \u00a0- \"$SERVICE_URL\"EOF\n```\n- Apply the preceding YAML definition to the client cluster:```\nkubectl --context ${SERVER_CLUSTER} apply -f server-ingress-gatway.yaml\n```Pay attention to the `tls:` section because it's especially important. In this section, you define that you want mTLS. To ensure that this works as expected, you need to provide the secret that you created which contains the certificates.\n- Enable port `13306` by patching the ingress service. You enable this port by creating the following JSON file and naming it `gateway-patch.json` :```\ncat <<EOF > gateway-patch.json[{\u00a0 \"op\": \"add\",\u00a0 \"path\": \"/spec/ports/0\",\u00a0 \"value\": {\u00a0 \u00a0 \"name\": \"tls-mysql\",\u00a0 \u00a0 \"protocol\": \"TCP\",\u00a0 \u00a0 \"targetPort\": 13306,\u00a0 \u00a0 \"port\": 13306\u00a0 }}]EOF\n```\n- Apply the patch to the gateway service:```\nkubectl --context ${SERVER_CLUSTER} -n istio-system patch --type=json svc istio-ingressgateway -p \"$(cat gateway-patch.json)\"\n```\nNow that you've opened up the port on the ingress gateway, you need to pick up traffic coming from your new ingress gateway and direct it to your database Pod. You do this by using a mesh internal object: the virtual service.\n### Define the virtual serviceAs discussed earlier, the virtual service is a definition of traffic matching patterns that shape traffic within your mesh. You need to correctly identify and forward the traffic from your ingress gateway toward your MySQL DB service, as shown in the following diagram.\n- In Cloud Shell, create the following YAML file and name it `server-virtual-service.yaml` :```\ncat <<EOF > server-virtual-service.yamlapiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:\u00a0name: mysql-virtual-servicespec:\u00a0hosts:\u00a0 \u00a0- \"$SERVICE_URL\"\u00a0gateways:\u00a0 \u00a0- gateway-mysql\u00a0tcp:\u00a0 \u00a0- route:\u00a0 \u00a0 \u00a0- destination:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0number: 3306\u00a0 \u00a0 \u00a0 \u00a0 \u00a0host: mysql.default.svc.cluster.localEOF\n```It's important that this virtual service references the ingress gateway that the traffic comes from. The gateway is named `gateway-mysql` .Because this virtual service is applied on L4, you need to provide a `tcp` flag to describe your MySQL traffic. This flag basically tells the mesh that L4 is used for this traffic.You might have noticed that the ingress service is using port `13306` to forward traffic. The virtual service picks that up and translates it back to `3306` .Finally, you are forwarding traffic to the MySQL server in the server Kubernetes cluster. For this example, the server is listening on the standard MySQL port `3306` .\n- Apply the YAML definition to the server cluster:```\nkubectl --context ${SERVER_CLUSTER} apply -f server-virtual-service.yaml\n```\nThese two definitions decrypt the mTLS-encapsulated MySQL client request and forward it to the MySQL database inside the mesh.\nIt's important to understand that the mesh internal forwarding is also done using encryption, but in this case, the encryption is based on mesh internal certificates. The mTLS termination happens at the gateway.\nNow you have a fully and mutually encrypted way of communicating with your MySQL server. This form of encryption is transparent for the MySQL client and server, so no application changes are necessary. This makes tasks such as changing or rotating certificates straightforward. Also, this way of communication can be used for many different scenarios.## Testing the setupNow that you have client and server sides in place, you can test the setup.It's time to generate some traffic from the client side to the server side. You want to follow the traffic flow and ensure that the traffic is routed and encrypted and decrypted as you intend.- In Cloud Shell, deploy the MySQL server into the server cluster:```\nkubectl --context ${SERVER_CLUSTER} apply -f server/mysql-server/mysql.yaml\n```\n- Start a MySQL client on the client cluster:```\nkubectl run --context ${CLIENT_CLUSTER} --env=SERVICE_URL=$SERVICE_URL -it --image=mysql:5.6 mysql-client-1 --restart=Never -- /bin/bash\n```When the container has started, you are presented with a shell, which should look like the following:```\nroot@mysql-client-1:/#\n```\n- Connect to your MySQL server:```\nmysql -pyougottoknowme -h $SERVICE_URL\n```\n- Use the following commands to add a DB and a table:```\nCREATE DATABASE test_encrypted_connection;USE test_encrypted_connection;CREATE TABLE message (id INT, content VARCHAR(20));INSERT INTO message (id,content) VALUES(1,\"Crypto Hi\");\n```\n- After connecting and adding the table, exit the MySQL connection and the Pod:```\nexitexit\n```You need to type exit twice\u2014first, to leave the DB connection, and second, to leave the Pod. If the Pod stops responding upon exit, press to cancel out of the bash shell.\nBy following these steps, you should have generated some meaningful logging output that you can now further analyze.\nIn the next section, you check that the client-side traffic is passing the proxy and the egress gateway. You also test whether you can see the traffic entering the server side through the ingress gateway.\n **Note:** To see the traffic in the logs, you must have [Direct Envoy to stdout](/service-mesh/docs/enable-optional-features#direct_envoy_to_stdout) enabled through the [Anthos Service Mesh optional features](/service-mesh/docs/enable-optional-features) . This was done for you during cluster creation by Terraform.\n### Test the client-side proxy and egress gateway\n- In Cloud Shell, on the client side proxy, check that you can see the Istio proxy logs:```\nkubectl --context ${CLIENT_CLUSTER} logs -l run=mysql-client-1 -c istio-proxy -f\n```The debug output looks similar to the following:```\n[2021-02-10T21:19:08.292Z] \"- - -\" 0 - \"-\" \"-\" 176 115 10 - \"-\" \"-\" \"-\" \"-\" \"192.168.1.4:15443\" outbound|15443|mysql|istio-egressgateway.istio-system.svc.cluster.local 192.168.1.12:58614 34.66.165.46:3306 192.168.1.12:39642 - \n```Press to exit the log output.In this log entry, you can see that the client requests the server running on IP address `34.66.165.46` on port `3306` . The request is forwarded ( `outbound` ) to `istio-egressgateway` listening on the IP address `192.168.1.4` port `15443` . You defined this forwarding in your virtual service ( `client-virtual-service.yaml` ).\n- Read the egress gateway proxy logs:```\nkubectl --context ${CLIENT_CLUSTER} logs -n istio-system -l app=istio-egressgateway -f\n```The debug output is similar to the following:```\n[2021-02-10T21:19:08.292Z] \"- - -\" 0 - \"-\" \"-\" 176 115 19 - \"-\" \"-\" \"-\" \"-\" \"34.66.165.46:13306\" outbound|13306||34.66.165.46.nip.io 192.168.1.4:53542 192.168.1.4:15443 192.168.1.12:58614 34.66.165.46.nip.io \n```Press to exit the log output.In this log entry, you can see that the client request routed to `istio-egressgateway` listening on the IP address `192.168.1.4` port `15443` is further routed to the outside the service mesh to the external service listening on the IP address `34.66.165.46` on port `13306.` You defined this forwarding in the second part of your virtual service ( `client-virtual-service.yaml` ).\n### Test the server-side ingress gateway\n- In Cloud Shell, on the server side, view the ingress gateway proxy logs:```\nkubectl --context ${SERVER_CLUSTER} logs -n istio-system -l app=istio-ingressgateway -f\n```The output in the log looks similar to the following:```\n[2021-02-10T21:22:27.381Z] \"- - -\" 0 - \"-\" \"-\" 0 78 5 - \"-\" \"-\" \"-\" \"-\" \"100.96.4.8:3306\" outbound|3306||mysql.default.svc.cluster.local 100.96.1.3:55730 100.96.1.3:13306 100.96.1.1:42244 34.66.165.46.nip.io \n```Press to exit the log output.In this log entry, you can see that the external client request routed to `istio-ingressgateway` listening on the IP address `34.66.165.46` port `13306` is further routed to the MySQL service inside the mesh identified by the service name `mysql.default.svc.cluster.local` on port `3306.` You defined this forwarding in the ingress gateway ( `server-ingress-gateway.yaml` ).\n- For the MySQL server, view the Istio proxy logs:```\nkubectl --context ${SERVER_CLUSTER} logs -l app=mysql -c istio-proxy -f\n```The output looks similar to the following:```\n[2021-02-10T21:22:27.382Z] \"- - -\" 0 - \"-\" \"-\" 1555 1471 4 - \"-\" \"-\" \"-\" \"-\" \"127.0.0.1:3306\" inbound|3306|mysql|mysql.default.svc.cluster.local 127.0.0.1:45894 100.96.4.8:3306 100.96.1.3:55730 outbound_.3306_._.mysql.default.svc.cluster.local \n```Press to exit the log output.In this log entry, you can see the inbound call to the MySQL database server listening on the IP address `100.96.4.8` port `3306` . The call is coming from the ingress Pod with the IP address `100.96.1.3` .For more information about the Envoy logging format, see [Getting Envoy's Access Logs](https://istio.io/latest/docs/tasks/observability/logs/access-log/#default-access-log-format) .\n- Test your database to see the generated input:```\nMYSQL=$(kubectl --context ${SERVER_CLUSTER} get pods -n default | tail -n 1 | awk '{print $1}')kubectl --context ${SERVER_CLUSTER} exec $MYSQL -ti -- /bin/bash\n```\n- Verify the created database:```\nmysql -pyougottoknowmeUSE test_encrypted_connection;SELECT * from message;\n```The output is similar to the following:```\n+------+-----------+\n| id | content |\n+------+-----------+\n| 1 | Crypto Hi |\n+------+-----------+\n1 row in set (0.00 sec)\n```\n- Leave the MySQL database:```\nexitexit\n```You need to type `exit` twice\u2014first, to leave the DB connection, and second, to leave the Pod.\n### Test access by omitting the certificatesNow that you have tested and verified that access works using the injected certificates, also test the opposite: what happens if you omit the egress gateway and the certificate injection. This testing is also called .\nYou can perform this test by launching another Pod in a namespace without side proxy injection enabled.- In Cloud Shell, create a new namespace:```\nkubectl --context ${CLIENT_CLUSTER} create ns unencrypted\n```\n- Create a Pod and start an interactive shell inside the container:```\nkubectl --context ${CLIENT_CLUSTER} run -it --image=mysql:5.6 \\mysql-client-2 --env=SERVICE_URL=$SERVICE_URL \\-n unencrypted --restart=Never -- /bin/bash\n```\n- Try to connect to the database once the interactive shell has started:```\nmysql -pyougottoknowme -h $SERVICE_URL\n```After 30 seconds, you see output similar to the following:```\nWarning: Using a password on the command line interface can be insecure.\nERROR 2003 (HY000): Can't connect to MySQL server on '104.154.164.12.nip.io' (110)\n```This warning is expected because this Pod is omitting the egress gateway and trying to reach the ingress gateway (the `$SERVICE_URL` ) directly through the internet.\n- Try to resolve the service IP address:```\nresolveip $SERVICE_URL\n```The output is similar to the following. Your IP address will be different.```\nIP address of 104.154.164.12.nip.io is 104.154.164.12\n```This proves that the FQDN is resolvable and that the failed connection is indeed due to the missing certificate injection.\n- Exit the MySQL connection and the MySQL server Pod:```\nexitexit\n```\n## Further investigationOne topic not covered in this tutorial is that typically egress configurations are owned by a different role or organization in your company, because they are hosted in the `istio-system` namespace. Configure Kubernetes RBAC permissions so that only network administrators can directly create and modify the resources discussed in this tutorial.\nNow that you know how to use a service mesh to help ensure secure communication, you might want to try it with an application that needs to securely exchange data and where you want to control the encryption down to the certificate layer. To get started, you can [install Anthos Service Mesh](/service-mesh/docs/install) .\nTry using two GKE clusters and combine them by using the technique in this tutorial. This technique also works in the GKE Enterprise platform between two foreign Kubernetes clusters.\nService meshes are an excellent way to increase security within your cluster as well as with external services. One final use case to try is to have a mTLS endpoint that is not a second Kubernetes cluster but a third-party provider (such as a payment provider).## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this tutorial, you can delete your project.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Read the [companion concept guide](/architecture/encrypt-secure-communication-between-multiple-anthos-clusters-concept) .\n- For further best practices on configuring your egress gateway, see [Using Anthos Service Mesh egress gateways on GKE clusters: Tutorial](/service-mesh/docs/security/egress-gateway-gke-tutorial) .\n- Consult the [GKE](/kubernetes-engine/docs/how-to/hardening-your-cluster) hardening guide and the accompanying [Terraform module](https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/tree/master/modules/safer-cluster) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Cloud Architecture Center"}