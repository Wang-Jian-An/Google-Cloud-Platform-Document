{"title": "Google Cloud Observability - Find Ops Agent troubleshooting information", "url": "https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent/troubleshoot-find-info", "abstract": "# Google Cloud Observability - Find Ops Agent troubleshooting information\nThis document describes sources of diagnostic information that you can use to identify problems in the installation or running of the Ops Agent.\n", "content": "## Agent health checks\nVersion 2.25.1 introduced start-time health checks for the Ops Agent. When the Ops Agent starts, it performs a series of checks for conditions that prevent the agent from running correctly. If the agent detects one of the conditions, it logs a message describing the problem. The Ops Agent checks for the following:\n- Connectivity problems\n- Availability of ports used by the agent to report metrics about itself\n- Permission problems\n- Availability of the APIs used by the agent to write logs or metrics\n- A problem in the health-check routine itself.\n[Find start-time errors](#start-checks)\nVersion 2.37.0 introduced runtime heath checks for the Ops Agent. These errors are reported to Cloud Logging and Error Reporting. For information about locating runtime errors, see [Find runtime errors](#runtime-checks) .\nVersion 2.46.0 introduced the informational `LogPingOpsAgent` code. This code does not represent an error. For more information, see [Verify successful log collection](#log-ping-messages) .\nThe following table lists each health-check code in alphabetical order and describes what each code means. Codes that end with the string `Err` indicate errors; other codes are informational.\n| Health-check code  | Category   | Meaning                                                 | Suggestion                                                      |\n|:-------------------------|:------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| DLApiConnErr    | Connectivity  | Request to the downloads subdomain, dl.google.com, failed.                                    | Check your internet connection and firewall rules. For more information, see Network-connectivity issues.                             |\n| FbMetricsPortErr   | Port availability | Port 20202, needed for Ops Agent self metrics, is unavailable.                                   | Verify that port 20202 is open. For more information, see Required port is unavailable.                                  |\n| HcFailureErr    | Generic   | The Ops Agent health-check routine encountered an internal error.                                  | Submit a support case from the Google Cloud console. For more information, see Getting support.                                |\n| LogApiConnErr   | Connectivity  | Request to the Logging API failed.                                          | Check your internet connection and firewall rules. For more information, see Network-connectivity issues.                             |\n| LogApiDisabledErr  | API    | The Logging API is disabled in the current Google Cloud project.                                  | Enable the Logging API.                                                  |\n| LogApiPermissionErr  | Permission  | Service account is missing the Logs Writer role (roles/logging.logWriter).                                | Grant the Logs Writer role to the service account. For more information, see Agent lacks API permissions.                             |\n| LogApiScopeErr   | Permission  | The VM is missing the https://www.googleapis.com/\u200bauth/\u200blogging.write access scope.                              | Add the https://www.googleapis.com/\u200bauth/\u200blogging.write scope to the VM. For more information, see Verify your access scopes.                         |\n| LogApiUnauthenticatedErr | API    | The current VM couldn't authenticate to the Logging API.                                    | Verify that your credential files, VM access scopes, and permissions are set up correctly. For more information, see Authorize the Ops Agent.                    |\n| LogPingOpsAgent   | nan    | An informational payload message written every 10 minutes to the ops-agent-health log. You can use the resulting log entries to verify that the agent is sending logs. This message is not an error. | This message is expected to appear every 10 minutes. If the message does not appear for 20 minutes or longer, then agent might have encountered a problem. For troubleshooting information, see Troubleshoot the Ops Agent. |\n| LogParseErr    | Runtime   | The Ops Agent was unable to parse one or more logs.                                      | Check the configuration of any logging processors you've created. For more information see Log-parsing errors.                            |\n| LogPipeLineErr   | Runtime   | The Ops Agent's logging pipeline failed.                                        | Verify that the agent has access to the buffer files; check for a full disk, and verify that the Ops Agent configuration is correct. For more information, see Pipeline errors.            |\n| MetaApiConnErr   | Connectivity  | Request to the G\u200bC\u200bE Metadata server, for querying VM access scopes, OAuth tokens, and resource labels, failed.                       | Check your internet connection and firewall rules. For more information, see Network-connectivity issues.                             |\n| MonApiConnErr   | Connectivity  | A request to the Monitoring API failed.                                         | Check your internet connection and firewall rules. For more information, see Network-connectivity issues.                             |\n| MonApiDisabledErr  | API    | The Monitoring API is disabled in the current Google Cloud project.                                  | Enable the Monitoring API.                                                  |\n| MonApiPermissionErr  | Permission  | Service account is missing the Monitoring Metric Writer role (roles/monitoring.metricWriter).                           | Grant the Monitoring Metric Writer role to the service account. For more information, see Agent lacks API permissions.                          |\n| MonApiScopeErr   | Permission  | The VM is missing the https://www.googleapis.com/\u200bauth/\u200bmonitoring.write access scope.                             | Add the https://www.googleapis.com/\u200bauth/\u200bmonitoring.write scope to the VM. For more information, see Verify your access scopes.                        |\n| MonApiUnauthenticatedErr | API    | The current VM couldn't authenticate to the Monitoring API.                                    | Verify that your credential files, VM access scopes, and permissions are set up correctly. For more information, see Authorize the Ops Agent.                    |\n| OtelMetricsPortErr  | Port availability | Port 20201, needed for Ops Agent self metrics, is unavailable.                                   | Verify that port 20201 is open. For more information, see A required port is unavailable.                                 |\n| PacApiConnErr   | Connectivity  | Request to the package repository, packages.cloud.google.com, failed.                                 | Check your internet connection and firewall rules. For more information, see Network-connectivity issues.                             |### Find start-time errors\nStarting with version 2.35.0, health-check information is written to the `ops-agent-health` log by the Cloud Logging API (versions 2.33.0, 2.34.0 use `ops-agent-health-checks` ). The same information is also written to a `health-checks.log` file as follows:\n- **Linux** :`/var/log/google-cloud-ops-agent/health-checks.log`\n- **Windows** :`C:\\ProgramData\\Google\\Cloud Operations\\Ops  Agent\\log\\health-checks.log`You can also view any health-check messages by querying the status of the Ops Agent service as follows:\n- On Linux, run the following command:```\n sudo systemctl status google-cloud-ops-agent\"*\"\n \n```Look for messages like \"[Ports Check] Result: PASS\".  Other results include \"ERROR\" and \"FAIL\".\n- On Windows, use the Windows **Event Viewer** . Look for  \"Information\", \"Error\", or \"Failure\" messages  associated with the`google-cloud-ops-agent`service.After you resolve any problems, you must [restart the agent](/stackdriver/docs/solutions/agents/ops-agent/installation#restart) . The health checks are run when the agent starts, so to re-run the checks, you must restart the agent.\n### Find runtime errors\nThe runtime health checks are reported to both Cloud Logging and Error Reporting. If the agent failed to start but was able to report errors before failing, you might also see start-time errors reported.\nTo view runtime errors from the Ops Agent in Logging, do the following:\n- In the navigation panel of the Google Cloud console, select **Logging** , and then select **Logs Explorer** : [Go to Logs Explorer](https://console.cloud.google.com/logs/query) \n- Enter the following query and click **Run query** :```\nlog_id(\"ops-agent-health\")\n```To view runtime errors from the Ops Agent in Error Reporting, do the following:\n- In the navigation panel of the Google Cloud console, select **Error Reporting** , and then select your Google Cloud project: [Go to Error Reporting](https://console.cloud.google.com/errors) \n- To see errors from the Ops Agent, filter the errors for`Ops Agent`.### Verify successful log collection\nVersion 2.46.0 of the Ops Agent introduced the informational `LogPingOpsAgent` health check. This check writes an informational message to the `ops-agent-health` every 10 minutes. You can use the presence of these messages to verify that the Ops Agent is writing logs by doing any of the following:\n- Search logs of a specific VM for the ping messages [by using Logs Explorer](#find-log-ping-messages) .\n- Check the value of the metric [log_entry_count](/monitoring/api/metrics_gcp#logging/log_entry_count) for a specific VM [by using Metrics Explorer](#view-log-ping-metric) .\n- [Create an alerting policy](#alert-log-ping-metric) to notify  you if a specific VM is not updating the [log_entry_count](/monitoring/api/metrics_gcp#logging/log_entry_count) metric.If any of these options indicates that the log messages are not being ingested, then you can do the following:\n- Check for error codes indicating [start-up errors](#start-checks) or [runtime errors](#runtime-checks) .\n- Determine if the Ops Agent is [ up and running](/stackdriver/docs/solutions/agents/ops-agent/troubleshoot-install-startup#agent-not-running) .\n- Run the [agent diagnostics script](#agent-diagnostics) .To check the status of the Ops Agent on a specific VM, you need the instance ID of the VM. To find the instance ID, do the following:\n- In the navigation panel of the Google Cloud console, select **Compute Engine** , and then select **VM instances** : [Go to VM instances](https://console.cloud.google.com/compute) \n- Click the name of a VM instance.\n- On the **Details** tab, locate the **Basic information** section.  The instance ID appears as a numeric string. Use this string for thevalue in the subsequent sections.\n## Agent diagnostics tool for VMs\nThe agent diagnostics tool gathers critical local debugging information from your VMs for all the following agents: Ops Agent, legacy Logging agent, and legacy Monitoring agent. The debugging information includes things like project info, VM info, agent configuration, agent logs, agent service status, information that typically requires manual work to gather. The tool also checks the local VM environment to ensure it meets certain requirements for the agents to function properly, for example, network connectivity and required permissions.\n**When filing a customer case for an agent on a VM, run the agentdiagnostics tool and attach the collected information to the case.Providing this information reduces the time needed to troubleshoot yoursupport case. Before you attach the information to the support case,redact any sensitive information like passwords.**\nThe agent diagnostics tool must be run from inside the VM, so you will typically need to SSH into the VM first. The following command retrieves the agent diagnostics tool and executes it:\n**Linux**\n```\ncurl -sSO https://dl.google.com/cloudagents/diagnose-agents.shsudo bash diagnose-agents.sh\n```\n**Windows**\n```\n(New-Object Net.WebClient).DownloadFile(\"https://dl.google.com/cloudagents/diagnose-agents.ps1\", \"${env:UserProfile}\\diagnose-agents.ps1\")Invoke-Expression \"${env:UserProfile}\\diagnose-agents.ps1\"\n```\nFollow the output of the script execution to locate the files that include the collected info. Typically you can find them in the `/var/tmp/google-agents` directory on Linux and in the `$env:LOCALAPPDATA/Temp` directory on Windows, unless you have customized the output directory when running the script.\nFor detailed information, examine the `diagnose-agents.sh` script on Linux or `diagnose-agents.ps1` script on Windows.\n## Agent diagnostics tool for automatic installation policies\nIf an attempt to install the Ops Agent by using an Ops Agent OS policy fails, you can use the diagnostics script described in this section for debugging. For example, you might see one of the following cases:\n- The Ops Agent installation fails when you used the **Install Ops Agent for Monitoring and Logging** checkbox to [install the Ops Agent during VM creation](/stackdriver/docs/solutions/agents/ops-agent/install-agent-vm-creation) .\n- The agent status on the Cloud Monitoring **VM instances** dashboard or the **Observability** tab on a Compute Engine VM details page stays in the **Pending** state for more than 10 minutes. A prolonged **Pending** status might indicate one of the following:- A problem applying the policy.\n- A problem in the actual installation of the Ops Agent.\n- A connectivity problem between the VM and Cloud Monitoring.\nFor some of these issues, the general [agent-diagnosticsscript](#agent-diagnostics) and [health checks](#health-checks) might also be helpful.\nTo run the policy-diagnostics script, run the following commands:\n```\ncurl -sSO https://dl.google.com/cloudagents/diagnose-ui-policies.sh\nbash diagnose-ui-policies.sh VM_NAME VM_ZONE\n```\n**Note:** You must have the `roles/osconfig.guestPolicyViewer` role to run this script.\nThis script shows information about affected VMs and related automatic installation policies.\n**When filing a customer case for an agent on a VM, run the agentdiagnostics tools and attach the collected information to the case.Providing this information reduces the time needed to troubleshoot yoursupport case. Before you attach the information to the support case,redact any sensitive information like passwords.**\n## Agent status\nYou can check the status of the Ops Agent processes on the VM to determine if the agent is running or not.\nTo check the status of the Ops Agent, use the following command:\n```\nsudo systemctl status google-cloud-ops-agent\"*\"\n```\nVerify that the \"Metrics Agent\" and \"Logging Agent\" components are listed as \"active (running)\", as shown in the following sample output (some lines have been removed for brevity):\n```\n\u25cf google-cloud-ops-agent.service - Google Cloud Ops Agent\n  Loaded: loaded (/lib/systemd/system/google-cloud-ops-agent.service; enabled; vendor preset: enabled)\n  Active: active (exited) since Wed 2023-05-03 21:22:28 UTC; 4 weeks 0 days ago\n Process: 3353828 ExecStartPre=/opt/google-cloud-ops-agent/libexec/google_cloud_ops_agent_engine -in /etc/go>\n Process: 3353837 ExecStart=/bin/true (code=exited, status=0/SUCCESS)\n Main PID: 3353837 (code=exited, status=0/SUCCESS)\n  CPU: 195ms\n[...]\n\u25cf google-cloud-ops-agent-opentelemetry-collector.service - Google Cloud Ops Agent - Metrics Agent\n  Loaded: loaded (/lib/systemd/system/google-cloud-ops-agent-opentelemetry-collector.service; static)\n  Active: active (running) since Wed 2023-05-03 21:22:29 UTC; 4 weeks 0 days ago\n Process: 3353840 ExecStartPre=/opt/google-cloud-ops-agent/libexec/google_cloud_ops_agent_engine -service=ot>\n Main PID: 3353855 (otelopscol)\n  Tasks: 9 (limit: 2355)\n  Memory: 65.3M\n  CPU: 40min 31.555s\n  CGroup: /system.slice/google-cloud-ops-agent-opentelemetry-collector.service\n    \u2514\u25003353855 /opt/google-cloud-ops-agent/subagents/opentelemetry-collector/otelopscol --config=/run/g>\n[...]\n\u25cf google-cloud-ops-agent-fluent-bit.service - Google Cloud Ops Agent - Logging Agent\n  Loaded: loaded (/lib/systemd/system/google-cloud-ops-agent-fluent-bit.service; static)\n  Active: active (running) since Wed 2023-05-03 21:22:29 UTC; 4 weeks 0 days ago\n Process: 3353838 ExecStartPre=/opt/google-cloud-ops-agent/libexec/google_cloud_ops_agent_engine -service=fl>\n Main PID: 3353856 (google_cloud_op)\n  Tasks: 31 (limit: 2355)\n  Memory: 58.3M\n  CPU: 29min 6.771s\n  CGroup: /system.slice/google-cloud-ops-agent-fluent-bit.service\n    \u251c\u25003353856 /opt/google-cloud-ops-agent/libexec/google_cloud_ops_agent_wrapper -config_path /etc/goo>\n    \u2514\u25003353872 /opt/google-cloud-ops-agent/subagents/fluent-bit/bin/fluent-bit --config /run/google-clo>\n[...]\n\u25cf google-cloud-ops-agent-diagnostics.service - Google Cloud Ops Agent - Diagnostics\n  Loaded: loaded (/lib/systemd/system/google-cloud-ops-agent-diagnostics.service; disabled; vendor preset: e>\n  Active: active (running) since Wed 2023-05-03 21:22:26 UTC; 4 weeks 0 days ago\n Main PID: 3353819 (google_cloud_op)\n  Tasks: 8 (limit: 2355)\n  Memory: 36.0M\n  CPU: 3min 19.488s\n  CGroup: /system.slice/google-cloud-ops-agent-diagnostics.service\n    \u2514\u25003353819 /opt/google-cloud-ops-agent/libexec/google_cloud_ops_agent_diagnostics -config /etc/goog>\n[...]\n```\nTo check the status of the Ops Agent, use the following command:\n```\nGet-Service google-cloud-ops-agent*\n```\nVerify that the \"Metrics Agent\" and \"Logging Agent\" components are listed as \"Running\", as shown in the following sample output:\n```\nStatus Name    DisplayName\n------ ----    ----------Running google-cloud-op... Google Cloud Ops Agent\nRunning google-cloud-op... Google Cloud Ops Agent - Logging Agent\nRunning google-cloud-op... Google Cloud Ops Agent - Metrics Agent\nRunning google-cloud-op... Google Cloud Ops Agent - Diagnostics\n```\n## Agent self logs\nIf the agent fails to ingest logs to Cloud Logging, then you might have to inspect the agent's logs locally on the VM for troubleshooting. You can also [use log rotation](/stackdriver/docs/solutions/agents/ops-agent/rotate-logs) to manage the agent's self logs.\n**Linux**\n**Note:** Everything in the Linux section has been automated as part of the [diagnostic tool](#agent-diagnostics) . To perform the log inspection manually, continue with the following steps.\nTo inspect self logs that are written to `Journald` , run the following command:\n```\njournalctl -u google-cloud-ops-agent*\n```\nTo inspect the self logs that are written to the disk by the logging module, run the following command:\n```\nvim -M /var/log/google-cloud-ops-agent/subagents/logging-module.log\n```\n**Windows**\nTo inspect self logs that are written to `Windows Event Logs` , run the following command:\n```\nGet-WinEvent -FilterHashtable @{ Logname='Application'; ProviderName='google-cloud-ops-agent*' } | Format-Table -AutoSize -Wrap\n```\nTo inspect the self logs that are written to the disk by the logging module, run the following command:\n```\nnotepad \"C:\\ProgramData\\Google\\Cloud Operations\\Ops Agent\\log\\logging-module.log\"\n```\nTo inspect the logs from the `Windows Service Control Manager` for Ops Agent services, run the following command::\n```\nGet-WinEvent -FilterHashtable @{ Logname='System'; ProviderName='Service Control Manager' } | Where-Object -Property Message -Match 'Google Cloud Ops Agent' | Format-Table -AutoSize -Wrap\n```\n## View metric usage and diagnostics in Cloud Monitoring\nThe Cloud Monitoring **Metrics Management** page provides information that can help you control the amount you spend on chargeable metrics without affecting observability. The **Metrics Management** page reports the following information:\n- Ingestion volumes for both byte- and sample-based billing, across metric  domains and for individual metrics.\n- Data about labels and cardinality of metrics.\n- Use of metrics in alerting policies and custom dashboards.\n- Rate of metric-write errors.To view the **Metrics Management** page, do the following:\n- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select query_stats **Metrics management** : [Go to Metrics management](https://console.cloud.google.com/monitoring/metrics-management) \n- In the toolbar, select your time window. By default, the **Metrics Management** page displays information about the metrics collected  in the previous one day.For more information about the **Metrics Management** page, see [View and manage metric usage](/monitoring/docs/metrics-management) .", "guide": "Google Cloud Observability"}