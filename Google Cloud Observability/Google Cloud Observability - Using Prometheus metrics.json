{"title": "Google Cloud Observability - Using Prometheus metrics", "url": "https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/sli-metrics/prometheus", "abstract": "# Google Cloud Observability - Using Prometheus metrics\nThis page covers the basics of using [Prometheus](https://prometheus.io/) metrics for availability and latency SLIs in Cloud Monitoring, and using those metrics to create an SLO.\n", "content": "## The basics of Prometheus\n[Prometheus](https://prometheus.io/) is a leading open-source monitoring solution for metrics and alerting.\nPrometheus supports dimensional data with key-value identifiers for metrics, provides the PromQL query language, and supports many integrations by providing [exporters](https://prometheus.io/docs/instrumenting/exporters) for other products.\nTo start using Prometheus with Monitoring, we recommend using [Google Cloud Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) .\n### Metrics\nPrometheus supports the following types of metrics:\n- Counter: a single value that can only be monotonically increased or reset to 0 on restart.\n- Gauge: a single numeric value that can be arbitrarily set.\n- Histogram: a group of configurable buckets for sampling observations and recording values in ranges; also provides a sum of all observed values\n- Summary: like a histogram, but it also calculates configurable quantiles over a sliding time window.\nFor more information, see [Metric types](https://prometheus.io/docs/concepts/metric_types/) .\n## Creating metrics for SLIs\nIf your application emits Prometheus metrics, you can use them for SLIs.\n- For availability SLIs on request and error counts, you can start with Prometheus counter metrics.\n- For latency SLIs, you can use Prometheus histogram or summary metrics.\nTo collect Prometheus metrics with Google Cloud Managed Service for Prometheus, refer to the documentation for setting up [managed](/stackdriver/docs/managed-prometheus/setup-managed) or [self-deployed](/stackdriver/docs/managed-prometheus/setup-unmanaged) metric collection.\nWhen you [create an SLO](/stackdriver/docs/solutions/slo-monitoring/ui/create-slo) in the Google Cloud console, the default availability and latency SLO types do not include Prometheus metrics. To use a Prometheus metric, create a custom SLO and then choose a Prometheus metric for the SLI.\nPrometheus metrics start with `prometheus.googleapis.com/` .\n### Metrics for GKE\nManaged collection of metrics by Google Cloud Managed Service for Prometheus is [enabled by default](/stackdriver/docs/managed-prometheus/setup-managed#enable-mgdcoll-gke) for GKE. If you are running in a GKE environment that does not enable managed collection by default, you can [enable managed collection manually](/stackdriver/docs/managed-prometheus/setup-managed#enable-mgdcoll-gke-manual) . When managed collection is enabled, the in-cluster components are running but metrics are not generated until you deploy a [PodMonitoring](/stackdriver/docs/managed-prometheus/setup-managed#gmp-pod-monitoring) resource that scrapes a valid metrics endpoint or enable one of the managed metrics packages.\nThe [control plane metrics](/stackdriver/docs/solutions/gke/control-plane-metrics) package includes metrics that are useful indicators of system health. [Enable collection](/stackdriver/docs/solutions/gke/managing-metrics#control-plane-metrics) of control plane metrics to use these metrics for availability, latency, and other SLIs.\n- Use [API server metrics](/stackdriver/docs/solutions/gke/control-plane-metrics#api-server) to track API server load, the fraction of API server requests that return errors, and the response latency for requests received by the API server.\n- Use [scheduler metrics](/stackdriver/docs/solutions/gke/control-plane-metrics#scheduler-metrics) to help you to proactively respond to scheduling issues when there aren't enough resources for pending Pods.\n### Metrics for availability SLIs\nYou express a request-based availability SLI in the Cloud Monitoring API by using the [TimeSeriesRatio](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#TimeSeriesRatio) structure to set up a ratio of \"good\" or \"bad\" requests to total requests. This ratio is used in the `goodTotalRatio` field of a [RequestBasedSli](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#RequestBasedSli) structure.\nYour application must emit Prometheus metrics that can be used to construct this ratio. The application must emit at least two of the following:\n- A metric that counts total events; use this metric in the ratio's `totalServiceFilter` .You can use a Prometheus counter that's incremented for every event.\n- A metric that counts \"bad\" events, use this metric in the ratio's `badServiceFilter` .You can use a Prometheus counter that's incremented for every error or other \"bad\" event.\n- A metric that counts \"good\" events, use this metric in the ratio's `goodServiceFilter` .You can use a Prometheus counter that's incremented for every successful or other \"good\" event.\n### Metrics for latency SLIs\nYou express a request-based latency SLI in the Cloud Monitoring API by creating a [DistributionCut](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#DistributionCut) structure. This structure is used in the `distributionCut` field of a [RequestBasedSli](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#RequestBasedSli) structure.\nYour application must emit a Prometheus metric that can be used to construct the distribution-cut value. You can use a Prometheus histogram or summary for this purpose. To determine how to define your buckets to accurately measure whether your responses fall within your SLO, see [Metric types](https://prometheus.io/docs/concepts/metric_types/) in the Prometheus documentation.\n## Example\nThe following JSON example uses the GKE control plane metric `prometheus.googleapis.com/apiserver_request_duration_seconds` metric to create a latency SLO for a service. The SLO requires 98% of response latency to be less than 50 seconds in a calendar month.\n```\n{\u00a0\"displayName\": \"98% Calendar month - Request Duration Under 50s\",\u00a0\"goal\": 0.98,\u00a0\"calendarPeriod\": \"MONTH\",\u00a0\"serviceLevelIndicator\": {\u00a0 \u00a0\"requestBased\": {\u00a0 \u00a0 \u00a0\"distributionCut\": {\u00a0 \u00a0 \u00a0 \u00a0\"distributionFilter\": \"metric.type=\\\"prometheus.googleapis.com/apiserver_request_duration_seconds/histogram\\\" resource.type=\\\"prometheus_target\\\"\",\u00a0 \u00a0 \u00a0 \u00a0\"range\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"min\": \"-Infinity\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0\"max\": 50\u00a0 \u00a0 \u00a0 \u00a0}\u00a0 \u00a0 \u00a0}\u00a0 \u00a0}\u00a0}}\n```\n## What's next\n- [Create an SLO](/stackdriver/docs/solutions/slo-monitoring/ui/create-slo) \n- Learn more about [Google Cloud Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) .\n- Learn more about [control plane metrics](/stackdriver/docs/solutions/gke/control-plane-metrics) .", "guide": "Google Cloud Observability"}