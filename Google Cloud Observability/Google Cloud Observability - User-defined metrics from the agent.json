{"title": "Google Cloud Observability - User-defined metrics from the agent", "url": "https://cloud.google.com/monitoring/agent/custom-metrics-agent", "abstract": "# Google Cloud Observability - User-defined metrics from the agent\n**    Beta     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nThis guide explains how you can configure the Monitoring agent to recognize and export your application metrics to Cloud Monitoring.\nThe Monitoring agent is a [collectd](https://collectd.org/wiki/index.php/Main_Page) daemon. In addition to exporting many predefined system and third-party metrics to Cloud Monitoring, the agent can export your own collectd application metrics to Monitoring as [user-defined metrics](/monitoring/custom-metrics) . Your collectd plugins can also export to Monitoring.\nAn alternative way to export application metrics to Monitoring is to use [StatsD](https://github.com/etsy/statsd/wiki) . Cloud Monitoring provides a default configuration that maps StatsD metrics to user-defined metrics. If you are satisfied with that mapping, then you don't need the customization steps described below. For more information, see the [StatsD plugin](/monitoring/agent/plugins/statsd) .\nFor more information about metrics, see the following documents:\n- [Metrics, time series, and resources](/monitoring/api/v3/metrics) .\n- [Structure of time series](/monitoring/api/v3/metrics-details) .\n- [User-defined metrics overview](/monitoring/custom-metrics) .\nThis functionality is only available for agents running on Linux. It is not available on Windows.\n", "content": "## Before you begin\n- Install the most recent Monitoring agent on a VM instance and verify it is working. To update your agent, see [Updating theagent](/monitoring/agent/monitoring/installation#upgrade) .\n- Configure [collectd](https://collectd.org/wiki/index.php/Main_Page) to get monitoring data from your application. Collectd supports many application frameworks and standard monitoring endpoints through its [read plugins](https://collectd.org/wiki/index.php/List_of_Plugins) . Find a read plugin that works for you.\n- (Optional) As a convenience, add the agent's collectd reference documentation to your system's `man` pages by updating the `MANPATH` variable and then running `mandb` :```\nexport MANPATH=\"$MANPATH:/opt/stackdriver/collectd/share/man\"sudo mandb\n```The man pages are for `stackdriver-collectd` .\n### Important files and directories\nThe following files and directories, created by installing the agent, are relevant to using the Monitoring agent (collectd):\n## How Monitoring handles collectd metrics\nAs background, the Monitoring agent processes collectd metrics and sends them to Monitoring, which treats each metric as a member of one of the following categories:\n- **User-defined metrics** . Collectd metrics that have the metadata key `stackdriver_metric_type` and a single [data source](https://collectd.org/wiki/index.php/Data_source) are handled as [user-defined metrics](/monitoring/custom-metrics) and sent to Monitoring using the [projects.timeSeries.create](/monitoring/api/ref_v3/rest/v3/projects.timeSeries/create) method in the Monitoring API.\n- **Curated metrics** . All other collectd metrics are sent to Monitoring using an internal API. Only the metrics in [the list of curated metrics](/monitoring/api/metrics_agent) are accepted and processed.\n- **Discarded metrics** . Collectd metrics that aren't in the curated metrics list and aren't user-defined metrics are silently discarded by Monitoring. The agent itself isn't aware of which metrics are accepted or discarded.\n## Write user-defined metrics with the agent\nYou configure the agent to send metric data points to Monitoring. Each point must be associated with a user-defined metric, which you define with a . These concepts are introduced in [Metrics, time series, and resources](/monitoring/api/v3/metrics) and described in detail at [Structure of time series](/monitoring/api/v3/metrics-details) and [User-defined metrics overview](/monitoring/custom-metrics) .\nYou can have a collectd metric treated as a user-defined metric by adding the proper metadata to the metric:\n- `stackdriver_metric_type` : (required) the name of the exported metric. Example: `custom.googleapis.com/my_custom_metric` .\n- `label:[LABEL]` : (optional) additional labels for the exported metric. For example, if you want a Monitoring STRING label named `color` , then your metadata key would be `label:color` and the value of the key could be `\"blue\"` . You can have up to 10 labels per metric type.\nYou can use a [collectd filter chain](https://www.collectd.org/documentation/manpages/collectd.conf.html#filter-configuration) to modify the metadata for your metrics. Because filter chains can't modify the list of data sources and user-defined metrics only support a single data source, any collectd metrics that you want to use with this facility must have a single data source.\n## Example\nIn this example we will monitor active Nginx connections from two Nginx services, `my_service_a` and `my_service_b` . We will send these to Monitoring using a user-defined metric. We will take the following steps:\n- Identify the collectd metrics for each Nginx service.\n- Define a Monitoring metric descriptor.\n- Configure a [collectd filter chain](https://www.collectd.org/documentation/manpages/collectd.conf.html#filter-configuration) to add metadata to the collectd metrics, to meet the expectations of the Monitoring agent.\n### Incoming collectd metrics\nCollectd expects metrics to consist of the following components. The first five components make up the collectd **identifier** for the metric:\n```\n Host, Plugin, Plugin-instance, Type, Type-instance, [value]\n```\nIn this example, the metrics you want to send as a user-defined metric have the following values:\n| Component  | Expected value(s)       |\n|:----------------|:------------------------------------------|\n| Host   | any          |\n| Plugin   | curl_json         |\n| Plugin instance | nginx_my_service_a or nginx_my_service_b1 |\n| Type   | gauge          |\n| Type instance | active-connections      |\n| [value]   | any value2        |\n**Notes** : In the example, this value encodes both the application (Nginx) and the connected service name. The value is typically a timestamp and double-precision number. Monitoring handles the details of interpreting the various kinds of values. Compound values aren't supported by the Monitoring agent.\n### Monitoring metric descriptor and time series\nOn the Monitoring side, design a metric descriptor for your user-defined metric. The following descriptor is a reasonable choice for the data in this example:\n- Name:`custom.googleapis.com/nginx/active_connections`\n- Labels:- `service_name`(STRING): The name of the service connected to Nginx.\n- Kind: GAUGE\n- Type: DOUBLE\nAfter you've designed the metric descriptor, you can create it by using [projects.metricDescriptors.create](/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors/create) , or you can let it be created for you from the time series metadata, discussed below. For more information, see [Creating metric descriptors](/monitoring/agent/custom-metrics-agent#creating_metric_descriptors) on this page.\nThe time series data for this metric descriptor must contain the following information, because of the way the metric descriptor is defined:\n- Metric type:`custom.googleapis.com/nginx/active_connections`\n- Metric label values:- `service_name`: either`\"my_service_a\"`or`\"my_service_b\"`Other time series information, including the associated [monitored resource](/monitoring/api/resources) \u2014the VM instance sending the data\u2014and the metric's data point, is automatically obtained by the agent for all metrics. You don't have to do anything special.\n### Your filter chain\n**Note:** You must hook your new filter chain into the `PreCache` filter chain.\nCreate a file, `/opt/stackdriver/collectd/etc/collectd.d/nginx_curl_json.conf` , containing the following code:\n```\nLoadPlugin match_regexLoadPlugin target_setLoadPlugin target_replace# Insert a new rule in the default \"PreCache\" chain, to divert your metrics.PreCacheChain \"PreCache\"<Chain \"PreCache\">\u00a0 <Rule \"jump_to_custom_metrics_from_curl_json\">\u00a0 \u00a0 # If the plugin name and instance match, this is PROBABLY a metric we're looking for:\u00a0 \u00a0 <Match regex>\u00a0 \u00a0 \u00a0 Plugin \"^curl_json$\"\u00a0 \u00a0 \u00a0 PluginInstance \"^nginx_\"\u00a0 \u00a0 </Match>\u00a0 \u00a0 <Target \"jump\">\u00a0 \u00a0 \u00a0 # Go execute the following chain; then come back.\u00a0 \u00a0 \u00a0 Chain \"PreCache_curl_json\"\u00a0 \u00a0 </Target>\u00a0 </Rule>\u00a0 # Continue processing metrics in the default \"PreCache\" chain.</Chain># Following is a NEW filter chain, just for your metric.# It is only executed if the default chain \"jumps\" here.<Chain \"PreCache_curl_json\">\u00a0 # The following rule does all the work for your metric:\u00a0 <Rule \"rewrite_curl_json_my_special_metric\">\u00a0 \u00a0 # Do a careful match for just your metrics; if it fails, drop down\u00a0 \u00a0 # to the next rule:\u00a0 \u00a0 <Match regex>\u00a0 \u00a0 \u00a0 Plugin \"^curl_json$\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Match on plugin.\u00a0 \u00a0 \u00a0 PluginInstance \"^nginx_my_service_.*$\" # Match on plugin instance.\u00a0 \u00a0 \u00a0 Type \"^gauge$\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Match on type.\u00a0 \u00a0 \u00a0 TypeInstance \"^active-connections$\" \u00a0 \u00a0# Match on type instance.\u00a0 \u00a0 </Match>\u00a0 \u00a0 <Target \"set\">\u00a0 \u00a0 \u00a0 # Specify the metric descriptor type:\u00a0 \u00a0 \u00a0 MetaData \"stackdriver_metric_type\" \"custom.googleapis.com/nginx/active_connections\"\u00a0 \u00a0 \u00a0 # Specify a value for the \"service_name\" label; clean it up in the next Target:\u00a0 \u00a0 \u00a0 MetaData \"label:service_name\" \"%{plugin_instance}\"\u00a0 \u00a0 </Target>\u00a0 \u00a0 <Target \"replace\">\u00a0 \u00a0 \u00a0 # Remove the \"nginx_\" prefix in the service_name to get the real service name:\u00a0 \u00a0 \u00a0 MetaData \"label:service_name\" \"nginx_\" \"\"\u00a0 \u00a0 </Target>\u00a0 </Rule>\u00a0 # The following rule is run after rewriting your metric, or\u00a0 # if the metric wasn't one of your user-defined metrics. The rule returns\u00a0 # to the default \"PreCache\" chain. The default processing\u00a0 # will write all metrics to Cloud Monitoring,\u00a0 # which will drop any unrecognized metrics: ones that aren't\u00a0 # in the list of curated metrics and don't have\u00a0 # the user-defined metric metadata.\u00a0 <Rule \"go_back\">\u00a0 \u00a0 Target \"return\"\u00a0 </Rule></Chain>\n```\n### Load the new configuration\nRestart your agent to pick up the new configuration by executing the following command on your VM instance:\n```\nsudo service stackdriver-agent restart\n```\nYour user-defined metric information begins to flow into Monitoring.\n## Reference and best practices\n### Metric descriptors and time series\nFor an introduction to Cloud Monitoring metrics, see [Metrics, time series, and resources](/monitoring/api/v3/metrics) . More details are available in [User-defined metrics overview](/monitoring/custom-metrics) and [Structure of time series](/monitoring/api/v3/metrics-details) .\n**Metric descriptors** . A metric descriptor has the following significant pieces:\n- A **type** of the form `custom.googleapis.com/[NAME1]/.../[NAME0]` . For example:```\ncustom.googleapis.com/my_measurementcustom.googleapis.com/instance/network/received_packets_countcustom.googleapis.com/instance/network/sent_packets_count\n```The recommended naming is hierarchical to make the metrics easier for people to keep track of. Metric types can't contain hyphens; for the exact naming rules, see [Naming metric types and labels](/monitoring/api/v3/naming-conventions#naming-types-and-labels) .\n- Up to 10 labels to annotate the metric data, such as `device_name` , `fault_type` , or `response_code` . The values of the labels aren't specified in the metric descriptor.\n- The kind and value type of the data points, such as \"a gauge value of type double\". For more information, see [MetricKind](/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#MetricKind) and [ValueType](/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#ValueType) .\n**Time series** . A metric data point has the following significant pieces:\n- The type of the associated metric descriptor.\n- Values for all of the metric descriptor's labels.\n- A timestamped value consistent with the metric descriptor's value type and kind.\n- The [monitored resource](/monitoring/api/resources) the data came from, typically a VM instance. Space for the resource is built in, so the descriptor doesn't need a separate label for it.\n### Creating metric descriptors\nYou don't have to create a metric descriptor ahead of time. When a data point arrives in Monitoring, the point's metric type, labels, and the point's value can be used to automatically create a gauge or cumulative metric descriptor. For more information, see [Auto-creation of metric descriptors](/monitoring/custom-metrics/creating-metrics#auto-creation) .\nHowever, there are advantages to creating your own metric descriptor:\n- You can include some thoughtful documentation for the metric and its labels.\n- You can specify additional kinds and types of metrics. The only (kind, type) combinations supported by the agent are (GAUGE, DOUBLE) and (CUMULATIVE, INT64). For more information, see [Metric kinds and value types](/monitoring/api/v3/kinds-and-types#metric-kinds) .\n- You can specify label types other than STRING.\nIf you write a data point to Monitoring that uses a metric type that isn't defined, then a new metric descriptor is created for the data point. This behavior can be a problem when you are debugging the code that writes metric data\u2014misspelling the metric type results in spurious metric descriptors.\nAfter you create a metric descriptor, or after it is created for you, it cannot be changed. For example, you can't add or remove labels. You can only delete the metric descriptor\u2014which deletes all its data\u2014and then recreate the descriptor the way you want.\nFor more details about creating metric descriptors, see [Creating your metric](/monitoring/custom-metrics/creating-metrics#md-create) .\n## Pricing\nIn general, Cloud Monitoring system metrics are free, and metrics from external systems, agents, or applications are not. Billable metrics are billed by either the number of bytes or the number of samples ingested.\nFor more information about Cloud Monitoring pricing, see the following documents:\n- [Cloud Monitoring pricing summary](/stackdriver/pricing#monitoring-pricing-summary) .\n- [Cloud Monitoring pricing](/stackdriver/pricing#monitoring-costs) .## Limits\nCloud Monitoring has limits on the number of metric time series and the number of user-defined metric descriptors in each project. For details, see [Quotas and limits](/monitoring/quotas) .\nIf you discover that you have created metric descriptors you no longer want, you can find and delete the descriptors using the Monitoring API. For more information, see [projects.metricDescriptors](/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors#MetricDescriptor) .\n## Troubleshooting\nThis section explains how to configure the Monitoring agent's `write_log` plugin to dump out the full set of metric points, including metadata. This can be used to determine what points need to be transformed, as well as to ensure your transformations behave as expected.\n**Note:** This will produce a lot output in the system logs. We recommend turning this feature off at the end of your troubleshooting session. If you have configured the Cloud Logging agent, then you can view the system log entries in Cloud Logging.\n### Enabling write_log\nThe `write_log` plugin is included in the `stackdriver-agent` package. To enable the plugin:\n- As **root** , edit the following configuration file:```\n/etc/stackdriver/collectd.conf\n```\n- Right after `LoadPlugin write_gcm` , add:```\nLoadPlugin write_log\n```\n- Right after `<Plugin \"write_gcm\">\u2026</Plugin>` , add:```\n<Plugin \"write_log\">\u00a0 Format JSON</Plugin>\n```\n- Search for `<Target \"write\">\u2026</Target>` and after every `Plugin \"write_gcm\"` , add:```\nPlugin \"write_log\"\n```\n- Save your changes and restart the agent:```\nsudo service stackdriver-agent restart\n```\nThese changes will print one log line per metric value reported, including the full collectd identifier, the metadata entries, and the value.\n### Output of write_log\nIf you were successful in the previous step, you should see the output of `write_log` in the system logs:\n- **Debian-based Linux** :`/var/log/syslog`\n- **Red Hat-based Linux** :`/var/log/messages`\nThe sample lines below have been formatted to make them easier to read in this document.\n```\nDec \u00a08 15:13:45 test-write-log collectd[1061]: write_log values:#012[{\u00a0 \u00a0 \"values\":[1933524992], \"dstypes\":[\"gauge\"], \"dsnames\":[\"value\"],\u00a0 \u00a0 \"time\":1481210025.252, \"interval\":60.000,\u00a0 \u00a0 \"host\":\"test-write-log.c.test-write-log.internal\",\u00a0 \u00a0 \"plugin\":\"df\", \"plugin_instance\":\"udev\", \"type\":\"df_complex\", \"type_instance\":\"free\"}]Dec \u00a08 15:13:45 test-write-log collectd[1061]: write_log values:#012[{\u00a0 \u00a0 \"values\":[0], \"dstypes\":[\"gauge\"], \"dsnames\":[\"value\"],\u00a0 \u00a0 \"time\":1481210025.252, \"interval\":60.000,\u00a0 \u00a0 \"host\":\"test-write-log.c.test-write-log.internal\",\u00a0 \u00a0 \"plugin\":\"df\", \"plugin_instance\":\"udev\", \"type\":\"df_complex\", \"type_instance\":\"reserved\"}]\n```", "guide": "Google Cloud Observability"}