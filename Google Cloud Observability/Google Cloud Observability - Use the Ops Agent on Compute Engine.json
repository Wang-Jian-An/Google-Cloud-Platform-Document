{"title": "Google Cloud Observability - Use the Ops Agent on Compute Engine", "url": "https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-opsagent", "abstract": "# Google Cloud Observability - Use the Ops Agent on Compute Engine\nThis document describes the configuration and use of an Ops Agent metrics receiver that you can use to collect metrics from Prometheus on Compute Engine. This document also describes an [example](#oagent-prom-receiver-config) that you can use to try the receiver.\nUsers of Google Kubernetes Engine have been able to collect Prometheus metrics by using [Google Cloud Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) . The Ops Agent Prometheus receiver gives users of Compute Engine the same capability.\nYou can use all of the tools provided by Cloud Monitoring, including PromQL, to view and analyze the data collected by the Prometheus receiver. For example, you can use [Metrics Explorer](/monitoring/charts/metrics-explorer) , as described in [Google Cloud console forMonitoring](#ui-monitoring) , to query your data. You can also create Cloud Monitoring [dashboards](/monitoring/dashboards) and [alerting policies](/monitoring/alerts) to monitor your Prometheus metrics. We recommend using PromQL as the query language for your Prometheus metrics.\nYou can also view your Prometheus metrics in interfaces outside Cloud Monitoring, like the [Prometheus UI](/stackdriver/docs/managed-prometheus/query-api-ui) and [Grafana](/stackdriver/docs/managed-prometheus/query) .\n", "content": "## Choose the right receiver\nBefore you decide to use the Prometheus receiver, determine if there is already an Ops Agent integration for the application you are using. For information on the existing integrations with the Ops Agent, see [Monitoring third-party applications](/stackdriver/docs/solutions/agents/ops-agent/third-party) . If there is an existing integration, we recommend using it. For more information, see [Choosing an existing integration](#use-3p-integration) .\nWe recommend using the Ops Agent Prometheus receiver when the following are true:\n- You have experience using Prometheus, rely on the Prometheus standard, and understand how factors like scraping interval and cardinality can affect your costs. For more information, see [Choosing the Prometheusreceiver](#use-prom-receiver) .\n- The software you are monitoring isn't already part of the set of [existing Ops Agent integrations](/stackdriver/docs/solutions/agents/ops-agent/third-party) .\n### Existing integrations\nThe Ops Agent provides integrations for a number of [third-party applications](/stackdriver/docs/solutions/agents/ops-agent/third-party) . These integrations provide the following for you:\n- A set of selected`workload.googleapis.com`metrics for the application\n- A dashboard for visualizing the metrics.\nThe metrics ingested by using an existing integration are subject to [byte-based pricing for agent-collected metrics](/stackdriver/pricing#metrics-charged-by-bytes) . The number and types of the metrics is known in advance, and you can use that information to estimate costs.\nFor example, if you are using the [Apache Web Server (httpd) integration](/stackdriver/docs/solutions/agents/ops-agent/third-party/apache) , the Ops Agent collects [five scalar metrics](/stackdriver/docs/solutions/agents/ops-agent/third-party/apache#monitored-metrics) ; each data point counts as 8 bytes. If you keep the Ops Agent default sampling frequency of 60 seconds, the number of bytes ingested per day is 57,600 * the number of hosts:\n- 8 (bytes) * 1440 (minutes per day) * 5 (metrics) *(hosts), or\n- 57,600 *(hosts)\nFor more information about estimating costs, see [Pricing examples based on bytes ingested](/stackdriver/pricing#pricing-examples) .\n### The Prometheus receiver\nWhen you use the Ops Agent to collect Prometheus metrics, the following apply:\n- The number and cardinality of metrics emitted by your application are under your control. There is no curated set of metrics. How much data you ingest is determined by the configuration of your Prometheus application and the Ops Agent Prometheus receiver.\n- Metrics are ingested into Cloud Monitoring as `prometheus.googleapis.com` metrics. These metrics are classified as a type of \"custom\" metrics when ingested into Cloud Monitoring and are subject to the [quotas and limits](/monitoring/quotas#custom_metrics_quotas) for custom metrics.\n- You must design and create any Cloud Monitoring dashboards you need, based on the set of metrics you are ingesting and on your business needs. For information about creating dashboards, see [Dashboards and charts](/monitoring/dashboards) .\n- Pricing for metric ingestion is based on the number of [samples ingested](/stackdriver/pricing#pricing-examples-samples) . To estimate your costs when using the Prometheus receiver, you need to determine the number of samples you are likely to collect during a billing cycle. The estimate is based on the following factors:- Number of scalar metrics; each value is one sample\n- Number of distribution metrics; each histogram counts as (2 + number of buckets in the histogram) samples\n- Sampling frequency of each metric\n- Number of hosts from which the metrics are sampled\nFor more information about counting samples and estimating costs, see [Pricing examples based on samples ingested](/stackdriver/pricing#metrics-charged-by-bytes) .## Prerequisites\nTo collect Prometheus metrics by using the Prometheus receiver, you must [install the Ops Agent](/stackdriver/docs/solutions/agents/ops-agent/install-index) version 2.25.0 or higher.\nThe Ops Agent receiver requires an endpoint that emits Prometheus metrics. Therefore, your application must either provide such an endpoint directly or use a Prometheus library or exporter to expose an endpoint. Many libraries and language frameworks like Spring and DropWizard, or applications like StatsD, DogStatsD, and Graphite, that emit non-Prometheus metrics can use Prometheus client libraries or exporters to emit Prometheus-style metrics. For example, to emit Prometheus metrics:\n- Spring users can use the [Spring Metrics](https://docs.spring.io/spring-metrics/docs/current/public/prometheus) library.\n- StatsD users can use the [statsd_exporter](https://github.com/prometheus/statsd_exporter) package.\n- Graphite users can use the [graphite_exporter](https://github.com/prometheus/graphite_exporter) package.\nWhen Prometheus metrics are emitted by an application, directly or by using a library or exporter, the metrics can then be collected by an Ops Agent configured with a Prometheus receiver.\n## Configure the Ops Agent\nThe Ops Agent [configuration model](/stackdriver/docs/solutions/agents/ops-agent/configuration#config-intro) typically involves defining the following:\n- , which determine which metrics are collected.\n- , which describe how the Ops Agent can modify the metrics.\n- , which link receivers and processors together into a.\nThe configuration for ingesting Prometheus metrics is slightly different: there are no processors involved.\n### Configuration for Prometheus metrics\nConfiguring the Ops Agent to ingest Prometheus metrics differs from the usual configuration as follows:\n- You don't create an Ops Agent processor for Prometheus metrics. The Prometheus receiver supports nearly all of the configuration options specified by the Prometheus [scrape_config specification](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config) , including relabeling options.Instead of using an Ops Agent processor, any metrics processing is done by using the `relabel_configs` and `metric_relabel_configs` sections of the scape config, as specified in the Prometheus receiver. For more information, see [Relabeling: Modifying the data beingscraped](#relabeling) .\n- You define the Prometheus pipeline in terms of the Prometheus receiver only. You don't specify any processors. You also can't use any non-Prometheus receivers in the pipeline for Prometheus metrics.\nThe majority of the receiver configuration is the specification of scrape-config options. Omitting those options for brevity, the following shows the structure of an Ops Agent configuration that uses a Prometheus receiver. You specify the values of the and .\n```\nmetrics:\n receivers:\n RECEIVER_ID:\n  type: prometheus\n  config:\n  scrape_configs:\n   [... omitted for brevity ...]\n service:\n pipelines:\n  PIPELINE_ID:\n  receivers: [RECEIVER_ID]\n```\nThe following section describes the Prometheus receiver in more detail. For a functional example of a receiver and pipeline, see [Add the Ops Agent receiver and pipeline](#oagent-config-json-exporter) .\n### The Prometheus receiver\nTo specify a receiver for Prometheus metrics, you create a metrics receiver of type `prometheus` and specify a set of `scrape_config` options. The receiver supports all of the Prometheus [scrape_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config) options, with the exception of the following:\n- The service-discovery sections,`*_sd_config`.\n- The`honor_labels`setting.\nTherefore, you can copy over existing scrape configs and use them for the Ops Agent with little or no modification.\nThe full structure of the Prometheus receiver is shown in the following:\n```\nmetrics:\n receivers:\n prom_application:\n  type: prometheus\n  config:\n  scrape_configs:\n   - job_name: 'STRING' # must be unique across all Prometheus receivers\n    scrape_interval: # duration, like 10m or 15s\n    scrape_timeout: # duration, like 10m or 15s\n    metrics_path: # resource path for metrics, default = /metrics\n    honor_timestamps: # boolean, default = false\n    scheme: # http or https, default = http\n    params:\n    - STRING: STRING\n    basic_auth:\n    username: STRING\n    password: SECRET\n    password_file: STRING\n    authorization:\n    type: STRING # default = Bearer\n    credentials: SECRET\n    credentials_file: FILENAME\n    oauth2: OAUTH2 # See Prometheus oauth2\n    follow_redirects: # boolean, default = true\n    enable_http2: # boolean, default = true\n    tls_config: TLS_CONFIG # See Prometheus tls_config\n    proxy_url: STRING\n    static_configs:\n    STATIC_CONFIG # See Prometheus static_config\n    relabel_configs:\n    RELABEL_CONFIG # See Prometheus relabel_config\n    metric_relabel_configs:\n    METRIC_RELABEL_CONFIGS # See Prometheus metric_relabel_configs\n```\nFor examples of relabeling configs, see [Additional receiverconfiguration](#other-config-examples) .\n## Example: Configure the Ops Agent for Prometheus\nThis section shows an example of how to configure the Ops Agent to collect Prometheus metrics from an application. This example uses the Prometheus community-provided JSON Exporter ( [json_exporter](https://github.com/prometheus-community/json_exporter) ), which exposes Prometheus metrics on port 7979.\nSetting up the example requires the following resources, which you might have to install:\n- `git`\n- `curl`\n- `make`\n- `python3`\n- Go language, version 1.19 or higher\n### Create or configure your application\nTo obtain and run the JSON Exporter, use the following procedure:\n- Clone the `json_exporter` repository and check out the exporter by running the following commands:```\ngit clone https://github.com/prometheus-community/json_exporter.git\ncd json_exporter\ngit checkout v0.5.0\n```\n- Build the exporter by running the following command:```\nmake build\n```\n- Start the Python HTTP server by running the following command:```\npython3 -m http.server 8000 &\n```\n- Start the JSON Exporter by running the following command:```\n./json_exporter --config.file examples/config.yml &\n```\n- Query the JSON Exporter to verify that it is running and exposing metrics on port 7979:```\ncurl \"http://localhost:7979/probe?module=default&target=http://localhost:8000/examples/data.json\"\n```If the query was successful, then you see output that resembles the following:```\n# HELP example_global_value Example of a top-level global value scrape in the json\n# TYPE example_global_value untyped\nexample_global_value{environment=\"beta\",location=\"planet-mars\"} 1234\n# HELP example_value_active Example of sub-level value scrapes from a json\n# TYPE example_value_active untyped\nexample_value_active{environment=\"beta\",id=\"id-A\"} 1\nexample_value_active{environment=\"beta\",id=\"id-C\"} 1\n# HELP example_value_boolean Example of sub-level value scrapes from a json\n# TYPE example_value_boolean untyped\nexample_value_boolean{environment=\"beta\",id=\"id-A\"} 1\nexample_value_boolean{environment=\"beta\",id=\"id-C\"} 0\n# HELP example_value_count Example of sub-level value scrapes from a json\n# TYPE example_value_count untyped\nexample_value_count{environment=\"beta\",id=\"id-A\"} 1\nexample_value_count{environment=\"beta\",id=\"id-C\"} 3\n```In this output, the strings like `example_value_active` are the metric names, with labels and values in braces. The data value follows the label set.\n### Add the Ops Agent receiver and pipeline\nTo configure the Ops Agent to ingest metrics from the JSON Exporter application, you must modify the agent's configuration to add a Prometheus receiver and pipeline. For the JSON Exporter example, use the following procedure:\n- Edit the Ops Agent configuration file, `/etc/google-cloud-ops-agent/config.yaml` , and add the following Prometheus receiver and pipeline entries:```\nmetrics:\n receivers:\n prometheus:\n  type: prometheus\n  config:\n   scrape_configs:\n   - job_name: 'json_exporter'\n    scrape_interval: 10s\n    metrics_path: /probe\n    params:\n    module: [default]\n    target: [http://localhost:8000/examples/data.json]\n    static_configs:\n    - targets: ['localhost:7979']\n service:\n pipelines:\n  prometheus_pipeline:\n  receivers:\n   - prometheus\n \n```If you have other configuration entries in this file already, add the Prometheus receiver and pipeline to the existing `metrics` and `service` entries. For more information, see [Metrics configurations](/stackdriver/docs/solutions/agents/ops-agent/configuration#metrics-config) .For examples of relabeling configs in the receiver, see [Additional receiver configuration](#other-config-examples) .\n**Note:** The minimum valid value for the `scrape_interval` field is 10 seconds. If you specify a value less than 10 seconds, then a value of 10 seconds is used instead.\n### Restart the Ops Agent\nTo apply your configuration changes, you must restart the Ops Agent.\n- To restart the agent, run the following command on your instance:```\nsudo service google-cloud-ops-agent restart\n```\n- To confirm that the agent restarted, run the following command and verify that the components \"Metrics Agent\" and \"Logging Agent\" started:```\nsudo systemctl status google-cloud-ops-agent\"*\"\n```\n- Connect to your instance using RDP or a similar tool and login to Windows.\n- Open a PowerShell terminal with administrator privileges by right-clicking the PowerShell icon and selecting **Run as Administrator** .\n- To restart the agent, run the following PowerShell command:```\nRestart-Service google-cloud-ops-agent -Force\n```\n- To confirm that the agent restarted, run the following command and verify that the components \"Metrics Agent\" and \"Logging Agent\" started:```\nGet-Service google-cloud-ops-agent*\n```## Prometheus metrics in Cloud Monitoring\nYou can use the tools provided by Cloud Monitoring with the data collected by the Prometheus receiver. For example, you can chart data by using [Metrics Explorer](/monitoring/charts/metrics-explorer) , as described in [Google Cloud console for Monitoring](#ui-monitoring) . The following sections describe the query tools available in Cloud Monitoring with Metrics Explorer:\n- [PromQL](/monitoring/promql) \n- [ Monitoring Query Language (MQL)](/monitoring/mql) \n- [Monitoring filters](/monitoring/api/v3/filters) \nYou can create Cloud Monitoring dashboards and alerting policies for your metrics. For information about dashboards and the types of charts you can use, see [Dashboards and charts](/monitoring/dashboards) . For information about alerting policies, see [Using alertingpolicies](/monitoring/alerts) .\nYou can also view your metrics in other interfaces, like the Prometheus UI and Grafana. For information about setting up these interfaces, see the following sections in the Google Cloud Managed Service for Prometheus documentation:\n- [Prometheus UI](/stackdriver/docs/managed-prometheus/query-api-ui) \n- [Grafana](/stackdriver/docs/managed-prometheus/query) \n### Use PromQL\nPromQL is the recommended query language for metrics ingested by using the Prometheus receiver.\nThe simplest way to verify that your Prometheus data is being ingested is to use the Cloud Monitoring Metrics Explorer page in the Google Cloud console:\n- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select **Metrics explorer** : [Go to Metrics explorer](https://console.cloud.google.com/monitoring/metrics-explorer) \n- In the toolbar of the query-builder pane, select the button whose name is either **MQL** or **PromQL** .\n- Verify that **PromQL** is selected in the **Language** toggle. The language toggle is in the same toolbar that lets you format your query.\n- Enter the following query into the editor, and then click **Run query** :```\nup\n```\nIf your data is being ingested, then you see a chart like the following:\nIf you are running the [JSON Exporter example](#oagent-prom-receiver-config) , then you can also issue queries like the following:\n- Query all data for a specific exported metric by name, for example:```\nexample_value_count\n```The following shows a chart for the `example_value_count` , including labels defined by the JSON Exporter application and labels added by the Ops Agent: \n- Query data for an exported metric that originated in a specific namespace. The value of the `namespace` label is the Compute Engine instance ID, a long number like `5671897148133813325` , assigned to the VM. A query looks like the following:```\nexample_value_count{namespace=\"INSTANCE_ID\"}\n```\n- Query data that matches a specific regular expression. The JSON Exporter emits metrics with an `id` label that has values like `id-A` , `id-B` , `id-C` . To filter for any metrics with an `id` label matching this pattern, use the following query:```\nexample_value_count{id=~\"id.*\"}\n```\nFor more information about using PromQL in Metrics Explorer and Cloud Monitoring charts, see [PromQL in Cloud Monitoring](/monitoring/promql) .\n### Use MQL\n**Note:** PromQL is the recommended query language for metrics ingested by using the Prometheus receiver.\nTo view your Prometheus data as Cloud Monitoring time series and to create charts and dashboards, you can also use the menu-driven interfaces or MQL. The following shows a simple query in Metrics Explorer:\n- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select **Metrics explorer** : [Go to Metrics explorer](https://console.cloud.google.com/monitoring/metrics-explorer) \n- Specify the data to appear on the chart. In addition to using the **PromQL** tab described previously, you can also use **MQL** .- To use MQL, do the following:- In the toolbar of the query-builder pane, select the button whose name is either **MQL** or **PromQL** .\n- Verify that **MQL** is selected in the **Language** toggle. The language toggle is in the same toolbar that lets you format your query.\n- Enter the following query:```\nfetch prometheus_target::prometheus.googleapis.com/up/gauge\n```\n- Click **Run Query** .\n- To use the menu-driven interface do the following:- In the **Resource type** field, type \"prometheus\" to filter the list, then select **Prometheus Target** .\n- In the **Metric** field, type \"up/\" to filter the list, then select **prometheus/up/gauge** .\nThe chart that results from either of these queries shows the same data as the chart shown with the PromQL example.\n### The prometheus_target resource\nIn Cloud Monitoring, time-series data is written against a monitored-resource type. For Prometheus metrics, the monitored-resource type is [prometheus_target](/monitoring/api/resources#tag_prometheus_target) . Monitoring queries for Prometheus metrics must specify this resource type.\nThe `prometheus_target` resource has the following labels, which you can use for filtering and manipulating queried data:\n- `project_id`: The identifier of the Google Cloud project, like`my-project`, in which the Ops Agent is running.\n- `location`: The Google Cloud or AWS region in which the Ops Agent is running; for example,`us-east1-a`(Google Cloud) or`aws:us-east-1a`(AWS).\n- `cluster`: Always`__gce__`for Prometheus metrics collected by using the Ops Agent.\n- `namespace`: The Compute Engine instance ID of the VM on which the Ops Agent is running.\n- `job`: The value of the`job_name`field in the receiver configuration.\n- `instance`: The instance label of the Prometheus target, taken from the receiver configuration; defaults to the target.\nThe values for these labels are set during collection. The values of the `namespace` , `location` , and `cluster` labels are immutable. If the metrics scraped from your application also have these labels, the Ops Agent prefixes the scraped labels with the string `exported_` .\n### View metric usage and diagnostics in Cloud Monitoring\nThe Cloud Monitoring **Metrics Management** page provides information that can help you control the amount you spend on chargeable metrics without affecting observability. The **Metrics Management** page reports the following information:\n- Ingestion volumes for both byte- and sample-based billing, across metric  domains and for individual metrics.\n- Data about labels and cardinality of metrics.\n- Use of metrics in alerting policies and custom dashboards.\n- Rate of metric-write errors.To view the **Metrics Management** page, do the following:\n- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select query_stats **Metrics management** : [Go to Metrics management](https://console.cloud.google.com/monitoring/metrics-management) \n- In the toolbar, select your time window. By default, the **Metrics Management** page displays information about the metrics collected  in the previous one day.For more information about the **Metrics Management** page, see [View and manage metric usage](/monitoring/docs/metrics-management) .\n## Relabeling: Modifying the data being scraped\nYou can use relabeling to modify the label set of the scrape target or its metrics before the target is scraped. If you have multiple steps in a relabeling config, they are applied in the order in which they appear in the configuration file.\nThe Ops Agent creates a set of meta labels (labels prefixed with the string `__meta_` . These meta labels record [information about theCompute Engine instance](#compute-meta-labels) on which the Ops Agent is running. Labels prefixed with the `__` string, including the meta labels, are available only during relabeling. You can use relabeling to capture the values of these labels in labels that are scraped.\nMetric relabeling is applied to samples; it is the last step before ingestion. You can use metric relabeling to drop time series that you don't need to ingest; dropping these time series reduces the number of samples ingested, which can lower costs.\nFor more information about relabeling, see the Prometheus documentation for [relabel_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) and [metric_relabel_configs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs) .\n### Compute Engine meta labels available during relabeling\nWhen the Ops Agent scrapes metrics, it includes a set of meta labels whose values are based on the configuration of the Compute Engine VM on which the agent is running. You can use these labels and the Prometheus receiver's `relabel_configs` section to add additional metadata to your metrics about the VM from which they were ingested. For an example, see [Additional receiver configuration](#other-config-examples) .\nThe following meta labels are available on targets for you to use in the `relabel_configs` section:\n- `__meta_gce_instance_id`: the numeric ID of the Compute Engine instance (local)\n- `__meta_gce_instance_name`: the name of the Compute Engine instance (local); the Ops Agent automatically places this value in the mutable`instance_name`label on your metrics.\n- `__meta_gce_machine_type`: full or partial URL of the machine type of the instance; the Ops Agent automatically places this value in the mutable`machine_type`label on your metrics.\n- `__meta_gce_metadata_` ``: each metadata item of the instance\n- `__meta_gce_network`: the network URL of the instance\n- `__meta_gce_private_ip`: the private IP address of the instance\n- `__meta_gce_interface_ipv4_` ``: IPv4 address of each named interface\n- `__meta_gce_project`: the Google Cloud project in which the instance is running (local)\n- `__meta_gce_public_ip`: the public IP address of the instance, if present\n- `__meta_gce_tags`: comma separated list of instance tags\n- `__meta_gce_zone`: the Compute Engine zone URL in which the instance is running\nThe values of these labels are set when the Ops Agent starts. If you modify the values, then you have to restart the Ops Agent to refresh the values.\n### Additional receiver configuration\nThis section provides examples that use the `relabel_configs` and `metric_relabel_configs` sections of the Prometheus receiver to modify the number and structure of the metrics ingested. This section also includes a modified version of the receiver for the JSON Exporter example that uses the relabeling options.\nYou can use the `relabel_configs` section to add labels to metrics. For example, the following uses a meta label, `__meta_gce_zone` , provided by the Ops Agent to create a metric label, `zone` , that is preserved after relabeling, because `zone` does not have the `__` prefix.\nFor a list of available meta labels, see [Compute Engine meta labelsavailable during relabeling](#compute-meta-labels) . Some of the meta labels are relabelled for you by the default Ops Agent configuration.\n```\nrelabel_configs:\n - source_labels: [__meta_gce_zone]\n regex: '(.+)'\n replacement: '${1}'\n target_label: zone\n```\nThe Prometheus receiver shown in [Example: Configure the Ops Agent forPrometheus](#oagent-prom-receiver-config) includes the addition of this label.\nYou can use the `metrics_relabel_configs` section to drop metrics that you do not want to ingest; this pattern is useful for cost containment. For example, you can use the following pattern to drop any metric with a namesthat matches or :\n```\nmetric_relabel_configs:\n - source_labels: [ __name__ ]\n regex: 'METRIC_NAME_REGEX_1'\n action: drop\n - source_labels: [ __name__ ]\n regex: 'METRIC_NAME_REGEX_2'\n action: drop\n```You can use the `metrics_relabel_configs` section to add static labels to all metrics ingested by the Prometheus receiver. You can use the following pattern to add labels `staticLabel1` and `staticLabel2` to all ingested metrics:\n```\nmetric_relabel_configs:\n - source_labels: [ __address__ ]\n action: replace\n replacement: 'STATIC_VALUE_1'\n target_label: staticLabel1\n - source_labels: [ __address__ ]\n action: replace\n replacement: 'STATIC_VALUE_2'\n target_label: staticLabel2\n```\nThe following version of the Prometheus receiver for the JSON Exporter example uses these configuration patterns to do the following:\n- Set the`zone`label from the value of the`__meta_gce_zone`meta label provided by the Ops Agent.\n- Drop the exporter's`example_global_value`metric.\n- Add the`staticLabel`label with the value \"A static value\" to all ingested metrics.\n```\nmetrics:\n receivers:\n prometheus:\n  type: prometheus\n  config:\n   scrape_configs:\n   - job_name: 'json_exporter'\n    scrape_interval: 10s\n    metrics_path: /probe\n    params:\n    module: [default]\n    target: [http://localhost:8000/examples/data.json]\n    static_configs:\n    - targets: ['localhost:7979']\n    relabel_configs:\n    - source_labels: [__meta_gce_zone]\n     regex: '(.+)'\n     replacement: '${1}'\n     target_label: zone\n    metric_relabel_configs:\n    - source_labels: [ __name__ ]\n     regex: 'example_global_value'\n     action: drop\n    - source_labels: [ __address__ ]\n     action: replace\n     replacement: 'A static value'\n     target_label: staticLabel\n```", "guide": "Google Cloud Observability"}