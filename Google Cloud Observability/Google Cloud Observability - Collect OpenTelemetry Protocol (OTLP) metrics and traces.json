{"title": "Google Cloud Observability - Collect OpenTelemetry Protocol (OTLP) metrics and traces", "url": "https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent/otlp", "abstract": "# Google Cloud Observability - Collect OpenTelemetry Protocol (OTLP) metrics and traces\nThis document describes how can use the Ops Agent and the OpenTelemetry Protocol (OTLP) receiver to collect user-defined metrics and traces from applications instrumented by using OpenTelemetry and running on Compute Engine.\nThis document is organized as follows:\n- [An overview](#use-oltp-receiver) that describes the use cases for the OTLP receiver.\n- [Prerequisites](#prereqs-otlp-receiver) for using the OTLP receiver.\n- [Configuring the agent to use the OTLP receiver](#config-overview) .\n- Using the receiver to [collect metrics](#otlp-metrics) . This section describes how to query your OpenTelemetry metrics in Cloud Monitoring.\n- Using the receiver to [collect traces](#otlp-traces) . This section describes how to authorize a service account to write data to Cloud Trace.", "content": "## Overview of using the OTLP receiver\nWith the Ops Agent OTLP receiver, you can do the following:\n- Instrument your application by using one of the language-specific SDKs for OpenTelemetry. For information about the supported languages, see [OpenTelemetryInstrumentation](https://opentelemetry.io/docs/instrumentation/) . The combination of OpenTelemetry SDKs and the Ops Agent do the following for you:- Collect OTLP metrics from your application and send those metrics to Cloud Monitoring for analysis.\n- Collect OTLP spans\u2014trace data\u2014from your application and then send those spans to Cloud Trace for analysis.\n- Collect traces from third-party applications that have built-in support for OTLP or plugins with such support, applications such as Nginx. The OTLP receiver in the Ops Agent can collect those traces. For an example, see [OpenTelemetry nginxmodule](https://github.com/open-telemetry/opentelemetry-cpp-contrib/tree/main/instrumentation/nginx) .\n- Use [OpenTelemetry custom instrumentation](https://opentelemetry.io/ecosystem/registry/) .\n- Use [OpenTelemetry automatic instrumentation](https://opentelemetry.io/docs/concepts/instrumenting/#automatic-instrumentation) .\nYou can use the receiver to collect metrics, traces, or both. After the Ops Agent has collected your metrics, you can use the features of Cloud Monitoring, including charts, dashboards, and alerting policies, to monitor your metrics. If your application also sends trace data, then you can use Cloud Trace to analyze that data.\n### Benefits\nBefore the availability of the OTLP plugin for the Ops Agent, the primary ways to instrument your applications to collect user-defined metrics and traces included the following:\n- Using client libraries that implement the Monitoring API or the Trace API.\n- Using the older [OpenCensus](https://opencensus.io/) libraries.\nUsing OpenTelemetry with the OTLP receiver has several benefits over these methods, including the following:\n- OpenTelemetry is the replacement for OpenCensus. The OpenCensus project is being archived. For more information, see [What isOpenTelemetry?](https://opentelemetry.io/docs/what-is-opentelemetry/) .\n- Ingestion is controlled at the agent level, so you don't have to redeploy your applications if the agent configuration changes.\n- Your applications don't need to set up Google Cloud credentials; all authorization is handled at the agent level.\n- Your application code contains no Google Cloud-specific monitoring or tracing code. You don't have to use the Monitoring API or the Trace API directly.\n- Your application pushes data to the Ops Agent, and if your application crashes, any data that has been collected by the Ops Agent isn't lost.\n### Limitations\nThe OTLP listener exposed by the Ops Agent receiver supports the gRPC transport. HTTP, which is used primarily for JavaScript clients, isn't supported. For more information about the OpenTelemetry Protocol, see [Protocol Details](https://opentelemetry.io/docs/specs/otel/protocol/otlp/#protocol-details) .\nThe OTLP receiver doesn't collect logs. You can collect logs by using the Ops Agent and other receivers and you can include log information in OTLP spans, but the OTLP receiver doesn't support the direct collection of logs. For information about using the Ops Agent to collect logs, see [Logging configurations](/stackdriver/docs/solutions/agents/ops-agent/configuration#logging-config) .\n## Prerequisites\nTo collect OTLP metrics and traces by using the OTLP receiver and the Ops Agent, you must [install the Ops Agent](/stackdriver/docs/solutions/agents/ops-agent/install-index) version 2.37.0 or higher.\nThis document assumes that you already have an OpenTelemetry-based application written by using one of the OpenTelemetry SDKs. This document doesn't cover using OpenTelemetry SDKs. For information about SDKs and the supported languages, see [OpenTelemetry Instrumentation](https://opentelemetry.io/docs/instrumentation/) .\n## Configure the Ops Agent\nTo configure the Ops Agent to use the OTLP receiver, do the following:\n- [Modify the user configuration file for the Ops Agent to include theOTLP receiver](#config-otlp) .\n- [Restart the Ops Agent](#apply-config-restart) .\nThe following sections describe each step.\n### Modify the Ops Agent user-configuration file\nAdd the configuration elements for the OTLP receiver to the the user-configuration file for the Ops Agent:\n- For Linux:`/etc/google-cloud-ops-agent/config.yaml`\n- For Windows:`C:\\Program Files\\Google\\Cloud Operations\\Ops Agent\\config\\config.yaml`\nFor general information about configuring the agent, see [Configuration model](/stackdriver/docs/solutions/agents/ops-agent/configuration#config-intro) .\nThe OTLP receiver introduces the `combined` configuration section for the Ops Agent. Using the receiver requires you to configure services for metrics and traces, even if you aren't using both of them.\nThe following sections describe the configuration steps for the OTLP receiver.\nYou place the receiver for OTLP metrics and traces in the `combined` section. No processors or services are permitted in the `combined` section. You must not configure any other receiver with the same name as a receiver in the `combined` section. The following example uses `otlp` as the name of the receiver.\nThe minimal `combined` configuration for OTLP looks like the following:\n```\ncombined:\n receivers:\n otlp:\n  type: otlp\n```\nThe `otlp` receiver has the following configuration options:\n- `type`: Required. Must be`otlp`\n- `grpc_endpoint`: Optional. The gRPC endpoint on which the OTLP receiver listens. Defaults to`0.0.0.0:4317`.\n- `metrics_mode` : Optional. Defaults to `googlemanagedprometheus` , which means the receiver sends OTLP metrics as Prometheus-formatted metrics by using the Prometheus API also used by [Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) .To send the metrics as Cloud Monitoring custom metrics by using the Monitoring API instead, set the `metrics_mode` option to the value `googlecloudmonitoring` .This choice affects how your metrics are ingested and how they are measured for billing. For more information about metrics formats, see [Ingestion formats for OTLP metrics](#otlp-metric-formats) .The OTLP receiver can collect metrics and traces, so you must define a service for metrics and for traces. If you aren't going to collect either metrics or traces, you can create empty services. If you already have services with other pipelines, you can add the OTLP pipeline to them.\nThe following shows the `metrics` and `traces` services with the OTLP receiver included in the pipelines:\n```\ncombined:\n receivers:\n otlp:\n  type: otlp\nmetrics:\n service:\n pipelines:\n  otlp:\n  receivers: [otlp]\ntraces:\n service:\n pipelines:\n  otlp:\n  receivers: [otlp]\n```\nIf you don't want to use either the `metrics` or `traces` service for OTLP collection, then leave the OTLP receiver out of the pipeline for the service. The service must exist, even if it has no pipelines. If you application sends data of a given type and there is no corresponding pipeline that includes the receiver, then the Ops Agent discards the data.\n### Restart the Ops Agent\nTo apply your configuration changes, you must restart the Ops Agent.\n- To restart the agent, run the following command on your instance:```\nsudo systemctl restart google-cloud-ops-agent\n```\n- To confirm that the agent restarted, run the following command and verify that the components \"Metrics Agent\" and \"Logging Agent\" started:```\nsudo systemctl status \"google-cloud-ops-agent*\"\n```\n- Connect to your instance using RDP or a similar tool and login to Windows.\n- Open a PowerShell terminal with administrator privileges by  right-clicking the PowerShell icon and selecting **Run as Administrator** \n- To restart the agent, run the following PowerShell command:```\nRestart-Service google-cloud-ops-agent -Force\n```\n- To confirm that the agent restarted, run the following command and  verify that the components \"Metrics Agent\" and \"Logging Agent\" started:```\nGet-Service google-cloud-ops-agent*\n```## Collect OTLP metrics\nWhen you use the OTLP receiver to collect metrics from your OpenTelemetry applications, the primary configuration choice for the receiver is the API that you want to use to ingest the metrics.\nYou make this choice by changing the `metrics_mode` option in the configuration of the `otlp` receiver or using the default value. The choice affects how your OTLP metrics are ingested into Cloud Monitoring and how that data is measured for billing purposes.\n**Note:** The number and cardinality of metrics emitted by your application are under your control. There is no curated set of metrics. How much data you ingest is determined by your application.\nThe `metrics_mode` choice doesn't affect your ability to create charts, dashboards, and alerting policies in Monitoring.\n- For information about creating charts and dashboards, see [Dashboards and charts overview](/monitoring/dashboards) .\n- For information about alerting policies, see [Alerting overview](/monitoring/alerts) .\nThe following sections describe differences in the formats used by the metric modes and how to query the ingested data for use in Monitoring.\n### Ingestion formats for OTLP metrics\nThe OTLP receiver provides the `metrics_mode` option, which specifies the API that is used to ingest your metric data. By default, the receiver uses the Prometheus API; the default value for the `metrics_mode` option is `googlemanagedprometheus` . The metrics are ingested using the same API that is used by Managed Service for Prometheus.\nYou can configure the receiver to send your metric data to the Cloud Monitoring API instead. To send data to the Monitoring API, set the value of the `metrics_mode` option to `googlecloudmonitoring` , as shown in the following example:\n```\ncombined:\n receivers:\n otlp:\n  type: otlp\n  metrics_mode: googlecloudmonitoring\n```\nThe ingestion format you use determines how the OTLP metrics are mapped into Cloud Monitoring. You can create charts, dashboards, and alerting policies in Monitoring for metrics of either metric format, but you refer to the metrics differently in queries.\nThe ingestion format also determines the pricing model used for data ingestion.\nThe following sections describe pricing, the structural differences between a metric ingested by the Prometheus API and the same metric ingested by the Monitoring API, and how to refer to the metrics in queries.\nThe ingestion format you use determines how the OTLP metrics are charged:\n- **Prometheus API:** When you use the Prometheus API to ingest your application's metrics, the data is subject to sample-based pricing, as if the metrics had come in by using Managed Service for Prometheus.- For current pricing, see [Cloud Monitoring pricingsummary](/stackdriver/pricing#monitoring-pricing-summary) .\n- For more information about counting samples and estimating costs, see [Pricing examples based on samples ingested](/stackdriver/pricing#metrics-charged-by-bytes) .\n- **Monitoring API:** When you use the Monitoring API to ingest your application's metrics, the data is subject to volume-based pricing, like data from other integrations with the Ops Agent.- For current pricing, see [Cloud Monitoring pricingsummary](/stackdriver/pricing#monitoring-pricing-summary) .\n- For more information about ingestion volume and estimating costs, see [Pricing examples based on bytes ingested](/stackdriver/pricing#pricing-examples) .Metrics ingested by using the OTLP receiver are considered types of \"custom\" metrics when ingested into Cloud Monitoring and are subject to the [quotas and limits](/monitoring/quotas#custom_metrics_quotas) for custom metrics.\nCloud Monitoring describes the format of metric data by using a schema called a . The [metric descriptor](/monitoring/api/ref_v3/rest/v3/projects.metricDescriptors) includes the name of the metric, the data type of metric values, how each value is related to prior values, and any labels associated with the values. If you configure the OTLP receiver to ingest metrics by using the Prometheus API, then the metric descriptor that is created differs from the metric descriptor created when you use the Monitoring API.\n**Prometheus API:** When you use the Prometheus API to ingest your application's metrics, each metric is transformed by using the standard [OpenTelemetry-to-Prometheus transformation](https://opentelemetry.io/docs/specs/otel/compatibility/prometheus_and_openmetrics/#prometheus-metric-points-to-otlp) and mapped to a Cloud Monitoring monitored-resource type.\n- The transformation includes the following changes:- The OTLP metric name is prefixed with the string`prometheus.googleapis.com/`.\n- Any non-alphanumeric characters, such as periods (`.`), in the OTLP metric name are replaced by underscores (`_`).\n- The OTLP metric name is postfixed with a string that indicates the metric kind, like`/gauge`or`/counter`.\n- The following labels, populated with values from the OTLP resource, are added to the metric:- `instance_name`: The value of the`host.name`resource attribute.\n- `machine_type`: The value of the`host.type`resource attribute.\n- The monitored resource recorded with the metric measurements is the generic [prometheus_target](/monitoring/api/resources#tag_prometheus_target) type. The generated Prometheus time series includes the following labels from the `prometheus_target` resource, populated with values from the OTLP resource:- `location`: The value of the`cloud.availability_zone`resource attribute.\n- `namespace`: The value of the`host.id`resource attribute.\nThe `prometheus_target` resource type also includes these labels:- `project_id`: The identifier of the Google Cloud project, like`my-project`, in which the Ops Agent is running.\n- `cluster`: The value is always`__gce__`when metrics are collected by the Ops Agent.If the incoming OTLP data is missing the resource attributes used for label values, then the values are taken from information about the VM running the Ops Agent. This behavior means that OTLP data without these resource attributes appears with the same labels as data collected by the [Ops Agent Prometheus receiver](/stackdriver/docs/solutions/agents/ops-agent/prometheus) .\n**Monitoring API:** When you use the Monitoring API to ingest your application's metrics, each metric is handled as follows:\n- The OTLP metric name is prefixed with the string`workload.googleapis.com/`, unless the OTLP metric name already contains this string or another valid metric domain, like`custom.googleapis.com`. We recommend using the \"workload\" domain.\n- The monitored resource recorded with the metric measurements is the Compute Engine virtual-machine type [gce_instance](/monitoring/api/resources#tag_gce_instance) .\nThe following examples show the metric descriptors for a pair of OpenTelemetry metrics. The metrics are created by an application that uses the [Go OpenTelemetry metrics library](https://pkg.go.dev/go.opentelemetry.io/otel/metric) . The **Prometheus API** tab shows the metric descriptor created when the OTLP receiver uses the default Prometheus metrics mode. The **Monitoring API** tab shows the metric descriptor created when the OTLP receiver uses the `googlecloudmonitoring` metric mode.\nNothing changes in the application that creates the metric; the only change is the metric mode used by the OTLP receiver.\nThe application creates an OTLP gauge metric, `otlp.test.gauge` , that records 64-bit floating-point values. The following tabs show the metric descriptor that each ingestion API creates:\n```\n{\n \"name\": \"projects/PROJECT_ID/metricDescriptors/prometheus.googleapis.com/otlp_test_gauge/gauge\",\n \"labels\": [ {\n  \"key\": \"instance_name\"\n },\n {\n  \"key\": \"machine_type\"\n }\n ],\n \"metricKind\": \"GAUGE\",\n \"valueType\": \"DOUBLE\",\n \"type\": \"prometheus.googleapis.com/otlp_test_gauge/gauge\",\n \"monitoredResourceTypes\": [ \"prometheus_target\"\n ]\n}\n``````\n{\n \"name\": \"projects/PROJECT_ID/metricDescriptors/workload.googleapis.com/otlp.test.gauge\",\n \"labels\": [ {\n  \"key\": \"instrumentation_source\"\n }\n ],\n \"metricKind\": \"GAUGE\",\n \"valueType\": \"DOUBLE\",\n \"type\": \"workload.googleapis.com/otlp.test.gauge\",\n \"monitoredResourceTypes\": [ \"gce_instance\",\n ...many other types deleted...\n ]\n}\n```\nThe application creates an OTLP counter metric, `otlp.test.cumulative` , that records increasing 64-bit floating-point values. The following tabs show the metric descriptor that each ingestion API creates:\n```\n{\n \"name\": \"projects/PROJECT_ID/metricDescriptors/prometheus.googleapis.com/otlp_test_cumulative/counter\",\n \"labels\": [ {\n  \"key\": \"instance_name\"\n },\n {\n  \"key\": \"machine_type\"\n }\n ],\n \"metricKind\": \"CUMULATIVE\",\n \"valueType\": \"DOUBLE\",\n \"type\": \"prometheus.googleapis.com/otlp_test_cumulative/counter\",\n \"monitoredResourceTypes\": [ \"prometheus_target\"\n ]\n}\n``````\n{\n \"name\": \"projects/PROJECT_ID/metricDescriptors/workload.googleapis.com/otlp.test.cumulative\",\n \"labels\": [ {\n  \"key\": \"instrumentation_source\"\n }\n ],\n \"metricKind\": \"CUMULATIVE\",\n \"valueType\": \"DOUBLE\",\n \"type\": \"workload.googleapis.com/otlp.test.cumulative\",\n \"monitoredResourceTypes\": [ \"gce_instance\",\n ...many other types deleted...\n ]\n}\n```\nThe following table summarizes some of the format differences imposed by the APIs used to ingest OTLP metrics:\n| Unnamed: 0   | Prometheus API   | Monitoring API   |\n|:-------------------|:--------------------------|:------------------------|\n| Metric domain  | prometheus.googleapis.com | workload.googleapis.com |\n| OTLP metric name | Modified during ingestion | Used as provided  |\n| Monitored resource | prometheus_target   | gce_instance   |\nThe metrics mode used in the OTLP receiver affects the way you query the resulting metrics in Cloud Monitoring when you build charts, dashboards, and alerting policies.\nWhen you configure a chart, dashboard, or alerting policy in Cloud Monitoring, the configuration includes a query for the data on which the chart, dashboard, or alerting policy operates.\nCloud Monitoring supports the following tools for querying metric data:\n- A query-builder based interface built into tools like Metrics Explorer, the dashboard-builder interface, and the alert-policy configuration interface.\n- Monitoring Query Language (MQL): A text-based query language specific to Cloud Monitoring.\n- Prometheus Query Language (PromQL): The text-based query language used by open source Prometheus.\nFor information about querying OTLP metrics by using these tools, see the following:\n- [Query OTLP metrics ingested by using thePrometheus API](#query-prom-metrics) \n- [Query OTLP metrics ingested by using theMonitoring API](#query-mon-metrics) \n### Query OTLP metrics ingested by using the Prometheus API\nThis section illustrates how you query OTLP metrics ingested by using the Prometheus API, which is the default metric mode for the OTLP receiver.\nThe queries are based on the OTLP metrics described in [Metricstructure](#metric-structure) :\n- `otlp.test.gauge`: An OTLP gauge metric that records 64-bit floating-point values.\n- `otlp.test.cumlative`: An OTLP counter metric that records increasing 64-bit floating-point values.\nThese metrics are ingested into Cloud Monitoring with the following metric types, which function as names:\n- `prometheus.googleapis.com/otlp_test_gauge/gauge`\n- `prometheus.googleapis.com/otlp_test_cumulative/counter`\nMetrics ingested by using the Prometheus API are written against the monitored-resource type [prometheus_target](/monitoring/api/resources#tag_prometheus_target) .\nThe tabs show what basic queries look like when query the metrics by using the Google Cloud console. These examples use Metrics Explorer, but the principles are the same for dashboards and alerting policies.\nTo use a query-builder interface to query metric data, you specify the metric type and the monitored-resource type by typing into search-enabled fields. There are far fewer resource types than metric types, so it's usually most efficient to search for the resource type and then use the menu of associated metrics to find the metric type.\nIf you enter \"prometheus\" in the search field, the results include the `prometheus_target` monitored resource, shown by the display name \"Prometheus Target\", and the set of metrics that write to the resource. The metrics are categorized by name; the two example metrics appear as the **Otlp** category. You can select **Prometheus/otlp_test_cumulative/counter** or **Prometheus/otlp_test_gauge/gauge** .\nFor more information about using the query builder, see [Build queries by using menus](/monitoring/charts/metrics-selector#basic-advanced-mode) .\nThe following screenshot shows the result of querying the `prometheus.googleapis.com/otlp_test_gauge/gauge` metric:\n \nThe following screenshot shows the result of querying the `prometheus.googleapis.com/otlp_test_cumulative/counter` metric:\n \nTo query metric data by using MQL, use a `fetch` statement and specify the metric type and the monitored-resource type, with `::` between them. Trivial MQL queries for the example metrics look like the following:- `fetch prometheus.googleapis.com/otlp_test_gauge/gauge::prometheus_target`\n- `fetch prometheus.googleapis.com/otlp_test_cumulative/counter::prometheus_target`\nFor more information about creating MQL queries, see [Sample MQL queries](/monitoring/mql/examples) .\nThe following screenshot shows the result of querying the `prometheus.googleapis.com/otlp_test_gauge/gauge` metric:\n \nThe following screenshot shows the result of querying the `prometheus.googleapis.com/otlp_test_cumulative/counter` metric:\n \nWhen you use PromQL to query metric data that was ingested by using the Prometheus API, you need only specify the modified form of the original OTLP metric name. You don't need to specify the prefixed `prometheus.googleapis.com/` string or the postfixed type.\nWhen the metric can be written against only one monitored-resource type, you don't need to specify the resource. As described in [Metricstructure](#metric_structure) , OTLP metrics ingested by using the Prometheus API are written only against the [prometheus_target](/monitoring/api/resources#tag_prometheus_target) monitored-resource type. Trivial PromQL queries for the example metrics look like the following:- `otlp_test_gauge`\n- `otlp_test_cumulative`\nFor more information about using PromQL in Cloud Monitoring to query metrics ingested by using the Prometheus API, see [Google Cloud Managed Service for Prometheusdata in Cloud Monitoring](/stackdriver/docs/managed-prometheus/query#gmp-in-monitoring) . For information about the PromQL language, see [QueryingPrometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/) .\nThe following screenshot shows the result of querying the `prometheus.googleapis.com/otlp_test_gauge/gauge` metric:\n \nThe following screenshot shows the result of querying the `prometheus.googleapis.com/otlp_test_cumulative/counter` metric:\n### Query OTLP metrics ingested by using the Monitoring API\nThis section illustrates how you query OTLP metrics ingested by using the Monitoring API. You select the Cloud Monitoring API by setting the `metrics_mode` field of the OTLP receiver to the value `googlecloudmonitoring` .\nThe queries are based on the OTLP metrics described in [Metricstructure](#metric-structure) :\n- `otlp.test.gauge`: An OTLP gauge metric that records 64-bit floating-point values.\n- `otlp.test.cumlative`: An OTLP counter metric that records increasing 64-bit floating-point values.\nThese metrics are ingested into Cloud Monitoring with the following metric types, which function as names:\n- `workload.googleapis.com/otlp.test.gauge`\n- `workload.googleapis.com/otlp.test.cumulative`\nMetrics ingested by using the Monitoring API are written against the monitored-resource type [gce_instance](/monitoring/api/resources#tag_gce_instance) .\nThe tabs show what basic queries look like when query the metrics by using the Google Cloud console. These examples use Metrics Explorer, but the principles are the same for dashboards and alerting policies.\nTo use a query-builder interface to query metric data, you specify the metric type and the monitored-resource type by typing into search-enabled fields. There are far fewer resource types than metric types, so it's usually most efficient to search for the resource type and then use the menu of associated metrics to find the metric type.\nIf you enter \"gce_instance\" in the search field, the results show the resource type by its display name, \"VM Instance\", and the set of metrics that write to the resource. The metrics are categorized by name; the two example metrics appear as the **Otlp** category. You can select **Workload/otlp_test_cumulative** or **Workload/otlp_test_gauge** .\nFor more information about using the query builder, see [Build queries by using menus](/monitoring/charts/metrics-selector#basic-advanced-mode) .\nThe following screenshot shows the result of querying the `workload.googleapis.com/otlp.test.gauge` metric:\n \nThe following screenshot shows the result of querying the `workload.googleapis.com/otlp.test.cumulative` metric:\n \nTo query metric data by using MQL, use a\n`fetch`\nstatement and specify the metric type and the monitored-resource type, with\n`::`\nbetween them. Trivial MQL queries for the example metrics look like the following:\n- `fetch workload.googleapis.com/otlp.test.gauge::gce_instance`\n- `fetch workload.googleapis.com/otlp.test.cumulative::gce_instance`\nFor more information about creating MQL queries, see [Sample MQL queries](/monitoring/mql/examples) .\nThe following screenshot shows the result of querying the `workload.googleapis.com/otlp.test.gauge` metric:\n \nThe following screenshot shows the result of querying the `workload.googleapis.com/otlp.test.cumulative` metric:\n \nWhen you use PromQL to query metric data that was ingested by using the Monitoring API, you have to map the metric name to PromQL conventions. The basic mapping rules include the following:- Replace the first`/`with`:`.\n- Replace all other special characters (including`.`and other`/`characters) with`_`.\nFor more information about the mapping rules, see [Mapping Cloud Monitoringmetrics to PromQL](/monitoring/promql/promql-mapping) .\nThe Monitoring metric types for the example metrics are mapped to PromQL as follows:- `workload_googleapis_com:otlp_test_gauge`\n- `workload_googleapis_com:otlp_test_cumulative`\nWhen the metric can be written against only one monitored-resource type, you don't need to specify the resource. The example metrics are written against the [gce_instance](/monitoring/api/resources#tag_gce_instance) monitored-resource type, but as described in [Metric structure](#metric_structure) , `gce_instance` is only one of the possible metric types. Therefore, the PromQL queries for these metrics must include a filter for the `gce_instance` resource type. To include the filter, add the following string to the end of the mapped metric names: `{monitored_resource=\"gce_instance\"}`\nFor more information about using PromQL in Cloud Monitoring, see [PromQL in Cloud Monitoring](/monitoring/promql) . For information about the PromQL language, see [QueryingPrometheus](https://prometheus.io/docs/prometheus/latest/querying/basics/) .\nTrivial PromQL queries for the example metrics look like the following:- `workload_googleapis_com:otlp_test_gauge{monitored_resource=\"gce_instance\"}`\n- `workload_googleapis_com:otlp_test_cumulative{monitored_resource=\"gce_instance\"}`\nThe following screenshot shows the result of querying the `workload.googleapis.com/otlp.test.gauge` metric:\n \nThe following screenshot shows the result of querying the `workload.googleapis.com/otlp.test.cumulative` metric:\n### View metric usage and diagnostics in Cloud Monitoring\nThe Cloud Monitoring **Metrics Management** page provides information that can help you control the amount you spend on chargeable metrics without affecting observability. The **Metrics Management** page reports the following information:\n- Ingestion volumes for both byte- and sample-based billing, across metric  domains and for individual metrics.\n- Data about labels and cardinality of metrics.\n- Use of metrics in alerting policies and custom dashboards.\n- Rate of metric-write errors.To view the **Metrics Management** page, do the following:\n- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select query_stats **Metrics management** : [Go to Metrics management](https://console.cloud.google.com/monitoring/metrics-management) \n- In the toolbar, select your time window. By default, the **Metrics Management** page displays information about the metrics collected  in the previous one day.For more information about the **Metrics Management** page, see [View and manage metric usage](/monitoring/docs/metrics-management) .\n## Collect OTLP traces\nIf you have configured the Ops Agent to collect traces, but you get no traces in Cloud Trace when you run your application, then you might need to grant an additional role to the Compute Engine service account the agent uses. By default, the service account gets the roles necessary to write metrics and logs, but not traces.\nThis following sections describes how to grant the service account the necessary Cloud Trace authorization.\n### Determine the roles granted to to the service account\nTo see the roles granted to a service account, run the following [gcloud projects get-iam-policy](/sdk/gcloud/reference/projects/get-iam-policy) command:\n```\ngcloud projects get-iam-policy PROJECT_ID --format=\"table(bindings.role)\" --flatten=\"bindings[].members\" --filter=\"bindings.members:SERVICE_ACCT_NAME@PROJECT_ID.iam.gserviceaccount.com\"\n```\nYou might see output like the following:\n```\nROLE\nroles/logging.logWriter\nroles/monitoring.metricWriter\n```\nIf the output includes either `roles/cloudtrace.agent` or `roles/cloudtrace.admin` , then the service account has sufficient permission to write traces. To grant one of these roles to the service account, see the following section.\n### Grant the Cloud Trace role to the service account\nFor a service account, the [Cloud Trace Agent role,roles/cloudtrace.agent](/iam/docs/understanding-roles#cloudtrace.agent) , is usually appropriate. To grant this role to the service account, run the following [gcloud projectsadd-iam-policy-binding](/sdk/gcloud/reference/projects/add-iam-policy-binding) command:\n```\ngcloud projects add-iam-policy-binding PROJECT_ID --member \"serviceAccount:SERVICE_ACCT_NAME@PROJECT_ID.iam.gserviceaccount.com\" --role=\"roles/cloudtrace.agent\"\n```\nYou can then run the `gcloud projects get-iam-policy` command to verify that the change has been made:\n```\ngcloud projects get-iam-policy PROJECT_ID --format=\"table(bindings.role)\" --flatten=\"bindings[].members\" --filter=\"bindings.members:SERVICE_ACCT_NAME@PROJECT_ID.iam.gserviceaccount.com\"\n```\nThe output now includes `roles/cloudtrace.agent` :\n```\nROLE\nroles/cloudtrace.agent\nroles/logging.logWriter\nroles/monitoring.metricWriter\n```\nFor more information about managing IAM roles, see [Manage access to project,folders, and organizations](/iam/docs/granting-changing-revoking-access) .\nAfter you authorize the service account used by the Ops Agent to write data to Cloud Trace, when you run your OpenTelemetry-based application, the traces appear in Cloud Trace:\n## Disable the OTLP receiver\nIf you are collecting both OTLP metrics and traces by using the Ops Agent, and you want to disable the collection of either metrics or traces but not both, then do the following:\n- Disable collection of either metrics or traces by making one of the following changes to the user configuration file, `config.yaml` :- Remove the`otlp`pipeline from the`metrics`service.\n- Remove the`otlp`pipeline from the`traces`service.\n- [Restart the Ops Agent](#apply-config-restart) .\nTo disable the collection of OTLP metrics and traces by the Ops Agent, do the following:\n- Remove the OTLP configuration from the user configuration file:- Delete the entire`combined`section, which includes the`otlp`receiver.\n- Remove the`otlp`pipeline from the`metrics`service.\n- Delete the entire`traces`service.\n- [Restart the Ops Agent](#apply-config-restart) .## What's next\nAfter your application metrics and traces have been ingested, you can use the Google Cloud console to monitor and analyze your data.\n- For information about dashboards and the types of charts you can create, see [Dashboards and charts](/monitoring/dashboards) .\n- For information about alerting policies, see [Using alerting policies](/monitoring/alerts) .\n- For information about analyzing trace data, see [Find and explore traces](/trace/docs/finding-traces) .", "guide": "Google Cloud Observability"}