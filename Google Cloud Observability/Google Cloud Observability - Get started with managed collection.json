{"title": "Google Cloud Observability - Get started with managed collection", "url": "https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-managed", "abstract": "# Google Cloud Observability - Get started with managed collection\nThis document describes how to set up Google Cloud Managed Service for Prometheus with managed collection. The setup is a minimal example of working ingestion, using a Prometheus deployment that monitors an example application and stores collected metrics in Monarch.\nThis document shows you how to do the following:\n- Set up your environment and command-line tools.\n- Set up managed collection for your cluster.\n- Configure a resource for target scraping and metric ingestion.\n- Migrate existing prometheus-operator custom resources.\nWe recommend that you use managed collection; it reduces the complexity of deploying, scaling, sharding, configuring, and maintaining the collectors. Managed collection is supported for GKE and all other Kubernetes environments.\nManaged collection runs Prometheus-based collectors as a Daemonset and ensures scalability by only scraping targets on colocated nodes. You configure the collectors with lightweight custom resources to scrape exporters using [pullcollection](https://prometheus.io/docs/introduction/faq/#why-do-you-pull-rather-than-push) , then the collectors push the scraped data to the central data store Monarch. Google Cloud never directly accesses your cluster to pull or scrape metric data; your collectors push data to Google Cloud. For more information about managed and self-deployed data collection, see [Data collection withManaged Service for Prometheus](/stackdriver/docs/managed-prometheus#gmp-data-collection) and [Ingestion and querying withmanaged and self-deployed collection](/stackdriver/docs/managed-prometheus/best-practices/ingest-and-query) .\n", "content": "## Before you begin\nThis section describes the configuration needed for the tasks described in this document.\n### Set up projects and tools\nTo use Google Cloud Managed Service for Prometheus, you need the following resources:\n- A Google Cloud project with the Cloud Monitoring API enabled.- If you don't have a Google Cloud project, then do the following:- In the Google Cloud console, go to **New Project** : [Create a New Project](https://console.cloud.google.com/projectcreate) \n- In the **Project Name** field, enter a name for your project and then click **Create** .\n- Go to **Billing** : [Go to Billing](https://console.cloud.google.com/billing) \n- Select the project you just created if it isn't already selected at the top of the page.\n- You are prompted to choose an existing payments profile or to create a new one.\nThe Monitoring API is enabled by default for new projects.\n- If you already have a Google Cloud project, then ensure that the Monitoring API is enabled:- Go to **APIs & services** : [Go to APIs & services](https://console.cloud.google.com/apis/dashboard) \n- Select your project.\n- Click **Enable APIs and Services** .\n- Search for \"Monitoring\".\n- In the search results, click through to \"Cloud Monitoring API\".\n- If \"API enabled\" is not displayed, then click the **Enable** button.\n- A Kubernetes cluster. If you do not have a Kubernetes cluster, then follow the instructions in the [Quickstart forGKE](/kubernetes-engine/docs/deploy-app-cluster) .\nYou also need the following command-line tools:\n- `gcloud`\n- `kubectl`\nThe `gcloud` and `kubectl` tools are part of the Google Cloud CLI. For information about installing them, see [Managing Google Cloud CLI components](/sdk/docs/components) . To see the gcloud CLI components you have installed, run the following command:\n```\ngcloud components list\n```\n### Configure your environment\nTo avoid repeatedly entering your project ID or cluster name, perform the following configuration:\n- Configure the command-line tools as follows:- Configure the gcloud CLI to refer to the ID of your Google Cloud project:```\ngcloud config set project PROJECT_ID\n```\n- Configure the `kubectl` CLI to use your cluster:```\nkubectl config set-cluster CLUSTER_NAME\n```\nFor more information about these tools, see the following:- [gcloud CLI overview](/sdk/gcloud) \n- [kubectl commands](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands) \n### Set up a namespace\nCreate the `` Kubernetes namespace for resources you create as part of the example application:\n```\nkubectl create ns NAMESPACE_NAME\n```\n## Set up managed collection\nYou can use managed collection on both GKE and non-GKE Kubernetes clusters.\nAfter managed collection is enabled, the in-cluster components will be running but no metrics are generated yet. **PodMonitoring or ClusterPodMonitoringresources are needed by these components to correctly scrape the metricsendpoints. You must either deploy these resources with valid metrics endpointsor enable one of the managed metrics packages, for example,Kube state metrics,built into GKE.** For troubleshooting information, see [Ingestion-side problems](/stackdriver/docs/managed-prometheus/troubleshooting#ingest-problems) .\nEnabling managed collection installs the following components in your cluster:\n- The`gmp-operator`Deployment, which deploys the Kubernetes operator for Managed Service for Prometheus.\n- The`rule-evaluator`Deployment, which is used to [configure and run alertingand recording rules](/stackdriver/docs/managed-prometheus/rules-managed) .\n- The`collector`DaemonSet, which horizontally scales collection by scraping metrics only from pods running on the same node as each collector.\n- The`alertmanager`StatefulSet, which is [configured to send triggered alertsto your preferred notification channels](/stackdriver/docs/managed-prometheus/rules-managed#am-config-managed) .\nFor reference documentation about the Managed Service for Prometheus operator, see the [manifests page](/stackdriver/docs/managed-prometheus/manifests) .\n### Enable managed collection: GKE\nManaged collection is enabled by default for the following:\n- [GKE Autopilotclusters](/kubernetes-engine/docs/concepts/autopilot-overview) running GKE version 1.25 or greater.\n- [GKE Standardclusters](/kubernetes-engine/docs/concepts/choose-cluster-mode#why-standard) running GKE version 1.27 or greater. You can override this default when creating the cluster; see [Disable managedcollection](#disable-mgdcoll-gke) .\nIf you are running in a GKE environment that does not enable managed collection by default, then see [Enable managed collection manually](#enable-mgdcoll-gke-manual) .\nManaged collection on GKE is automatically upgraded when new in-cluster component versions are released.\nManaged collection on GKE uses permissions granted to the default Compute Engine service account. If you have a policy that modifies the standard permissions on the default node service account, you might need to add the [Monitoring Metric Writer role](/monitoring/access-control#mon_roles_desc) to continue.\nIf you are running in a GKE environment that does not enable managed collection by default, then you can enable managed collection by using the following:\n- The **GKE Clusters** dashboard in Cloud Monitoring.\n- The **Kubernetes Engine** page in the Google Cloud console.\n- The Google Cloud CLI. To use the gcloud CLI, you must be running GKE version 1.21.4-gke.300 or newer.\n- Terraform for Google Kubernetes Engine. To use Terraform to enable Managed Service for Prometheus, you must be running GKE version 1.21.4-gke.300 or newer.\nYou can do the following by using the **GKE Clusters** dashboard in Cloud Monitoring.- Determine whether Managed Service for Prometheus is enabled on your clusters and whether you are using managed or self-deployed collection.\n- Enable managed collection on clusters in your project.\n- View other information about your clusters.\nTo view the **GKE Clusters** dashboard, do the following:- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select **Dashboards** : [Go to Dashboards](https://console.cloud.google.com/monitoring/dashboards) \n- Select the **G\u200bC\u200bP** dashboard category, and then select **GKE Clusters** .\nTo enable managed collection on one or more GKE clusters by using the GKE Clusters dashboard, do the following:- Select the checkbox for each GKE cluster on which you want to enable managed collection.\n- Select **Enable Selected** .\n **Note:** This dashboard shows only GKE clusters in the current project, even if the project has multiple projects in its metric scope. For more information, see [Overview of viewing metrics for multiple projects](/monitoring/settings) . \nYou can do the following by using the Google Cloud console:- Enable managed collection on an existing GKE cluster.\n- Create a new GKE cluster with managed collection enabled.\nTo update an existing cluster, do the following:- In the navigation panel of the Google Cloud console, select **Kubernetes Engine** , and then select **Clusters** : [Go to Kubernetes Clusters](https://console.cloud.google.com/kubernetes/list) \n- Click on the name of the cluster.\n- In the **Features** list, locate the **Managed Service for Prometheus** option. If it is listed as disabled, click **Edit** , and then select **Enable Managed Service for Prometheus** .\n- Click **Save changes** .\nTo create a cluster with managed collection enabled, do the following:- In the navigation panel of the Google Cloud console, select **Kubernetes Engine** , and then select **Clusters** : [Go to Kubernetes Clusters](https://console.cloud.google.com/kubernetes/list) \n- Click **Create** .\n- Click **Configure** for the **Standard** option.\n- In the navigation panel, click **Features** .\n- In the **Operations** section, select **Enable Managed Service forPrometheus** .\n- Click **Save** .\nYou can do the following by using the gcloud CLI:- Enable managed collection on an existing GKE cluster.\n- Create a new GKE cluster with managed collection enabled.\nThese commands might take up to 5 minutes to complete.\nFirst, set your project:\n```\ngcloud config set project PROJECT_ID\n```\nTo update an existing cluster, run one of the following `update` commands based on whether your cluster is zonal or regional:- ```\ngcloud container clusters update CLUSTER_NAME --enable-managed-prometheus --zone ZONE\n```\n- ```\ngcloud container clusters update CLUSTER_NAME --enable-managed-prometheus --region REGION\n```\nTo create a cluster with managed collection enabled, run the following command:\n```\ngcloud container clusters create CLUSTER_NAME --zone ZONE --enable-managed-prometheus\n```\nManaged collection is on by default in [GKE Autopilot clusters](/kubernetes-engine/docs/concepts/autopilot-overview) running GKE version 1.25 or greater. You can't turn off managed collection.\nIf your cluster fails to enable managed collection automatically when upgrading to 1.25, you can manually enable it by running the update command in the gcloud CLI section.\nFor instructions on configuring managed collection using Terraform, see the [Terraform registry for google_container_cluster](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#managed_prometheus) .\nFor general information about using Google Cloud with Terraform, see [Terraform with Google Cloud](/docs/terraform) .\nIf you want to disable managed collection on your clusters, then you can use one of the following methods:\nYou can do the following by using the Google Cloud console:- Disable managed collection on an existing GKE cluster.\n- Override the automatic enabling of managed collection when creating a new GKE Standard cluster running GKE version 1.27 or greater.\nTo update an existing cluster, do the following:- In the navigation panel of the Google Cloud console, select **Kubernetes Engine** , and then select **Clusters** : [Go to Kubernetes Clusters](https://console.cloud.google.com/kubernetes/list) \n- Click on the name of the cluster.\n- In the **Features** section, locate the **Managed Service forPrometheus** option. Click **Edit** , and clear **Enable Managed Service for Prometheus** .\n- Click **Save changes** .\nTo override the automatic enabling of managed collection when creating a new GKE Standard cluster (version 1.27 or greater), do the following:- In the navigation panel of the Google Cloud console, select **Kubernetes Engine** , and then select **Clusters** : [Go to Kubernetes Clusters](https://console.cloud.google.com/kubernetes/list) \n- Click **Create** .\n- Click **Configure** for the **Standard** option.\n- In the navigation panel, click **Features** .\n- In the **Operations** section, clear **Enable Managed Service forPrometheus** .\n- Click **Save** .\nYou can do the following by using the gcloud CLI:- Disable managed collection on an existing GKE cluster.\n- Override the automatic enabling of managed collection when creating a new GKE Standard cluster running GKE version 1.27 or greater.\nThese commands might take up to 5 minutes to complete.\nFirst, set your project:\n```\ngcloud config set project PROJECT_ID\n```\nTo disable managed collection on an existing cluster, run one of the following `update` commands based on whether your cluster is zonal or regional:- ```\ngcloud container clusters update CLUSTER_NAME --disable-managed-prometheus --zone ZONE\n```\n- ```\ngcloud container clusters update CLUSTER_NAME --disable-managed-prometheus --region REGION\n```\nTo override the automatic enabling of managed collection when creating a new GKE Standard cluster (version 1.27 or greater), run the following command:\n```\ngcloud container clusters create CLUSTER_NAME --zone ZONE --no-enable-managed-prometheus\n```\nYou can't turn off managed collection in [GKE Autopilot clusters](/kubernetes-engine/docs/concepts/autopilot-overview) running GKE version 1.25 or greater.\nTo disable managed collection, set the `enabled` attribute in the `managed_prometheus` configuration block to `false` . For more information about this configuration block, see the [Terraform registry for google_container_cluster](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#managed_prometheus) .\nFor general information about using Google Cloud with Terraform, see [Terraform with Google Cloud](/docs/terraform) .\n### Enable managed collection: non-GKE Kubernetes\nIf you are running in a non-GKE environment, then you can enable managed collection using the following:\n- The`kubectl`CLI.\n- The bundled solution included in GKE Enterprise deployments running version 1.12 or newer.\nTo install managed collectors when you are using a non-GKE Kubernetes cluster, run the following commands to install the setup and operator manifests:\n```\nkubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/prometheus-engine/v0.8.2/manifests/setup.yaml\nkubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/prometheus-engine/v0.8.2/manifests/operator.yaml\n```\nFor information about configuring managed collection for GKE Enterprise clusters, see the documentation for your distribution:- [Anthos clusters on VMware (v1.12+)](/anthos/clusters/docs/on-prem/latest/how-to/application-logging-monitoring#enabling_managed_service_for_prometheus_for_user_applications) \n- [Anthos clusters on bare metal (v1.12+)](/anthos/clusters/docs/bare-metal/latest/how-to/application-logging-monitoring) \n### Deploy the example application\nThe [example application](https://github.com/nilebox/prometheus-example-app) emits the `example_requests_total` counter metric and the `example_random_numbers` histogram metric (among others) on its `metrics` port. The manifest for the application defines three replicas.\nTo deploy the example application, run the following command:\n```\nkubectl -n NAMESPACE_NAME apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/prometheus-engine/v0.8.2/examples/example-app.yaml\n```\n### Configure a PodMonitoring resource\nTo ingest the metric data emitted by the example application, Managed Service for Prometheus uses target scraping. Target scraping and metrics ingestion are configured using Kubernetes [custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) . The managed service uses [PodMonitoring](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md#podmonitoring) custom resources (CRs).\nA PodMonitoring CR scrapes targets only in the namespace the CR is deployed in. To scrape targets in multiple namespaces, deploy the same PodMonitoring CR in each namespace. You can verify the PodMonitoring resource is installed in the intended namespace by running `kubectl get podmonitoring -A` .\nFor reference documentation about all the Managed Service for Prometheus CRs, see the [prometheus-engine/doc/api reference](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md) .\nThe following manifest defines a PodMonitoring resource, `` , in the `` namespace. The resource uses a [Kubernetes label selector](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) to find all pods in the namespace that have the label `app.kubernetes.io/name` with the value `prom-example` . The matching pods are scraped on a port named `metrics` , every 30 seconds, on the `/metrics` HTTP path.\n```\napiVersion: monitoring.googleapis.com/v1\nkind: PodMonitoring\nmetadata:\n name: prom-example\nspec:\n selector:\n matchLabels:\n  app.kubernetes.io/name: prom-example\n endpoints:\n - port: metrics\n interval: 30s\n```\nTo apply this resource, run the following command:\n```\nkubectl -n NAMESPACE_NAME apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/prometheus-engine/v0.8.2/examples/pod-monitoring.yaml\n```\nYour managed collector is now scraping the matching pods. You can view the status of your scrape target by [enabling the target status feature](#target-status) .\nTo configure horizontal collection that applies to a range of pods across all namespaces, use the [ClusterPodMonitoring](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md#clusterpodmonitoring) resource. The ClusterPodMonitoring resource provides the same interface as the PodMonitoring resource but does not limit discovered pods to a given namespace.\n**Note:** The `targetLabels` field provides a simplified Prometheus-style [relabel configuration](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) . You can use relabeling to add pod labels as labels on the ingested time series. You can't overwrite the mandatory target labels; for a list of these labels, see the [prometheus_targetresource](/stackdriver/docs/managed-prometheus/query-cm#target-resource) .\nIf you are running on GKE, then you can do the following:\n- To query the metrics ingested by the example application using PromQL in Cloud Monitoring, see [Query using Cloud Monitoring](/stackdriver/docs/managed-prometheus/query-cm) .\n- To query the metrics ingested by the example application using Grafana, see [Query using Grafana or any Prometheus API consumer](/stackdriver/docs/managed-prometheus/query) .\n- To learn about filtering exported metrics and adapting your prom-operator resources, see [Additional topics for managedcollection](#gmp-managed-addl-topics) .\nIf you are running outside of GKE, then you need to create a service account and authorize it to write your metric data, as described in the following section.\n### Provide credentials explicitly\nWhen running on GKE, the collecting Prometheus server automatically retrieves credentials from the environment based on the node's service account. In non-GKE Kubernetes clusters, credentials must be explicitly provided through the [OperatorConfig resource](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md#operatorconfig) in the gmp-public namespace.\n- Set the context to your target project:```\ngcloud config set project PROJECT_ID\n```\n- Create a service account:```\ngcloud iam service-accounts create gmp-test-sa\n```\n- Grant the required permissions to the service account:```\ngcloud projects add-iam-policy-binding PROJECT_ID\\\n --member=serviceAccount:gmp-test-sa@PROJECT_ID.iam.gserviceaccount.com \\\n --role=roles/monitoring.metricWriter\n```\n- Create and download a key for the service account:```\ngcloud iam service-accounts keys create gmp-test-sa-key.json \\\n --iam-account=gmp-test-sa@PROJECT_ID.iam.gserviceaccount.com\n```\n- Add the key file as a secret to your non-GKE cluster:```\nkubectl -n gmp-public create secret generic gmp-test-sa \\\n --from-file=key.json=gmp-test-sa-key.json\n```\n- Open the OperatorConfig resource for editing:```\nkubectl -n gmp-public edit operatorconfig config\n```- Add the text shown in bold to the resource:```\napiVersion: monitoring.googleapis.com/v1\nkind: OperatorConfig\nmetadata:\n namespace: gmp-public\n name: config\ncollection:\n credentials:\n name: gmp-test-sa\n key: key.json\n```Make sure you also [add these credentials to the rules section](/stackdriver/docs/managed-prometheus/rules-managed#explicit-credentials) so that managed rule evaluation works.\n- Save the file and close the editor. After the change is applied, the pods are re-created and start authenticating to the metric backend with the given service account.\n## Additional topics for managed collection\nThis section describes how to do the following:- Enable the target status feature for easier debugging.\n- Configure target scraping using Terraform.\n- Filter the data you export to the managed service.\n- Scrape Kubelet and cAdvisor metrics.\n- Convert your existing prom-operator resources for use with the managed service.\n- Run managed collection outside of GKE.### Enabling the target status feature\nYou can check the status of your targets in your PodMonitoring or ClusterPodMonitoring resources by setting the `features.targetStatus.enabled` value within the OperatorConfig resource to `true` , as shown in the following:```\n apiVersion: monitoring.googleapis.com/v1\n kind: OperatorConfig\n metadata:\n  namespace: gmp-public\n  name: config\n features:\n  targetStatus:\n  enabled: true\n```After a few seconds, the `Status.Endpoint Statuses` field appears on every valid PodMonitoring or ClusterPodMonitoring resource, when configured.If you have a PodMonitoring resource with the name `` in the `` namespace, then you can check the status by running the following command:```\nkubectl -n NAMESPACE_NAME describe podmonitorings/prom-example\n```The output looks like the following:```\nAPI Version: \u00a0monitoring.googleapis.com/v1Kind: \u00a0 \u00a0 \u00a0 \u00a0 PodMonitoring...Status:\u00a0 Conditions:\u00a0 \u00a0 ...\u00a0 \u00a0 Status: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0True\u00a0 \u00a0 Type: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0ConfigurationCreateSuccess\u00a0 Endpoint Statuses:\u00a0 \u00a0 Active Targets: \u00a0 \u00a0 \u00a0 3\u00a0 \u00a0 Collectors Fraction: \u00a01\u00a0 \u00a0 Last Update Time: \u00a0 \u00a0 2023-08-02T12:24:26Z\u00a0 \u00a0 Name: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 PodMonitoring/custom/prom-example/metrics\u00a0 \u00a0 Sample Groups:\u00a0 \u00a0 \u00a0 Count: \u00a03\u00a0 \u00a0 \u00a0 Sample Targets:\u00a0 \u00a0 \u00a0 \u00a0 Health: \u00a0up\u00a0 \u00a0 \u00a0 \u00a0 Labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Cluster: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 CLUSTER_NAME\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Container: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 prom-example\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Instance: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0prom-example-589ddf7f7f-hcnpt:metrics\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Job: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 prom-example\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Location: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0REGION\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Namespace: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 NAMESPACE_NAME\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Pod: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 prom-example-589ddf7f7f-hcnpt\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 project_id: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0PROJECT_ID\u00a0 \u00a0 \u00a0 \u00a0 Last Scrape Duration Seconds: \u00a00.020206416\u00a0 \u00a0 \u00a0 \u00a0 Health: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0up\u00a0 \u00a0 \u00a0 \u00a0 Labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 Last Scrape Duration Seconds: \u00a00.054189485\u00a0 \u00a0 \u00a0 \u00a0 Health: \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0up\u00a0 \u00a0 \u00a0 \u00a0 Labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 \u00a0 \u00a0 Last Scrape Duration Seconds: \u00a00.006224887\n```The output includes the following status fields:- `Status.Conditions.Status`is true when Managed Service for Prometheus acknowledges and processes the PodMonitoring or ClusterPodMonitoring.\n- `Status.Endpoint Statuses.Active Targets`shows the number of scrape targets that Managed Service for Prometheus counts on all collectors for this PodMonitoring resource. In the example application, the`prom-example`deployment has three replicas with a single metric target, so the value is`3`. If there are unhealthy targets, the`Status.Endpoint Statuses.Unhealthy Targets`field appears.\n- `Status.Endpoint Statuses.Collectors Fraction`shows a value of`1`(meaning 100%) if all of the managed collectors are reachable by Managed Service for Prometheus.\n- `Status.Endpoint Statuses.Last Update Time`shows the last updated time. When the last update time is significantly longer than your desired scrape interval time, the difference might indicate issues with your target or cluster.\n- `Status.Endpoint Statuses.Sample Groups`field shows sample targets grouped by common target labels injected by the collector. This value is useful for debugging situations where your targets are not discovered. If all targets are healthy and being collected, then the expected value for the`Health`field is`up`and the value for the`Last Scrape Duration Seconds`field is the usual duration for a typical target.\nFor more information about these fields, see the [Managed Service for Prometheus API document](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md#podmonitoringstatus) .Any of the following might indicate a problem wth your configuration:- There is no`Status.Endpoint Statuses`field in your PodMonitoring resource.\n- The value of the`Last Scrape Duration Seconds`field is too old.\n- You see too few targets.\n- The value of the`Health`field indicates that the target is`down`.\nFor more information about debugging target discovery issues, see [Ingestion-side problems](/stackdriver/docs/managed-prometheus/troubleshooting#ingest-problems) in the troubleshooting documentation.\n### Configuring target scraping using Terraform\nYou can automate the creation and management of PodMonitoring and ClusterPodMonitoring resources by using the [kubernetes_manifest Terraformresource type](https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs/resources/manifest) or the [kubectl_manifestTerraform resource type](https://registry.terraform.io/providers/gavinbunney/kubectl/latest/docs/resources/kubectl_manifest) , either of which lets you specify arbitrary custom resources.For general information about using Google Cloud with Terraform, see [Terraformwith Google Cloud](/docs/terraform) .\n### Filter exported metrics\nIf you collect a lot of data, you might want to prevent some time series from being sent to Managed Service for Prometheus to keep down costs. You can do this by using [Prometheus relabeling rules](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) with a `keep` action for an allowlist or a `drop` action for a denylist. For managed collection, this rule goes in the `metricRelabeling` section of your [PodMonitoring or ClusterPodMonitoring](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md#relabelingrule) resource.For example, the following metric relabeling rule will filter out any metric that begins with `foo_bar_` , `foo_baz_` , or `foo_qux_` :```\n metricRelabeling:\n - action: drop\n regex: foo_(bar|baz|qux)_.+\n sourceLabels: [__name__]\n```The Cloud Monitoring **Metrics Management** page provides information that can help you control the amount you spend on chargeable metrics without affecting observability. The **Metrics Management** page reports the following information:- Ingestion volumes for both byte- and sample-based billing, across metric  domains and for individual metrics.\n- Data about labels and cardinality of metrics.\n- Use of metrics in alerting policies and custom dashboards.\n- Rate of metric-write errors.\nFor more information about the **Metrics Management** page, see [View and manage metric usage](/monitoring/docs/metrics-management) .For additional suggestions on how to lower your costs, see [Cost controls andattribution](/stackdriver/docs/managed-prometheus/cost-controls) .- Note: Prometheus [histograms][prom-histogram]{:class=\"external\"} include several kinds of time series. For example, a histogram named <var translate=\"no\">NAME</var> includes `<var translate=\"no\">NAME</var>_bucket`, `<var translate=\"no\">NAME</var>_count`, and `<var translate=\"no\">NAME</var>_sum`. To only ingest the time series in this histogram, you must specify `{__name__=\"<var translate=\"no\">NAME</var>_.*\"}` as the filter.\n### Scraping Kubelet and cAdvisor metrics\nThe Kubelet exposes metrics about itself as well as cAdvisor metrics about containers running on its node. You can configure managed collection to scrape Kubelet and cAdvisor metrics by editing the OperatorConfig resource. For instructions, see the exporter documentation for [Kubelet and cAdvisor](/stackdriver/docs/managed-prometheus/exporters/kubelet-cadvisor) .\n### Convert existing prometheus-operator resources\nYou can usually convert your existing prometheus-operator resources to Managed Service for Prometheus managed collection PodMonitoring and ClusterPodMonitoring resources.For example, the [ServiceMonitor resource](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#servicemonitor) defines monitoring for a set of services. The [PodMonitoring resource](#gmp-pod-monitoring) serves a subset of the fields served by the ServiceMonitor resource. You can convert a ServiceMonitor CR to a PodMonitoring CR by mapping the fields as described in the following table:| monitoring.coreos.com/v1 ServiceMonitor | Compatibility                   | monitoring.googleapis.com/v1 PodMonitoring |\n|:-------------------------------------------|:---------------------------------------------------------------------------------------|:----------------------------------------------|\n| .ServiceMonitorSpec.Selector    | Identical                    | .PodMonitoringSpec.Selector     |\n| .ServiceMonitorSpec.Endpoints[]   | .TargetPort maps to .Port .Path: compatible .Interval: compatible .Timeout: compatible | .PodMonitoringSpec.Endpoints[]    |\n| .ServiceMonitorSpec.TargetLabels   | PodMonitor must specify: .FromPod[].From pod label .FromPod[].To target label   | .PodMonitoringSpec.TargetLabels    |The following is a sample ServiceMonitor CR; the content in bold type is replaced in the conversion, and the content in italic type maps directly:```\napiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\n name: example-app\nspec:\n selector:\n matchLabels:\n  app: example-app\n endpoints:\n - targetPort: web\n path: /stats\n interval: 30s\n targetLabels:\n - foo\n```The following is the analogous PodMonitoring CR, assuming that your service and its pods are labeled with `app=example-app` . If this assumption does not apply, then you need to use the label selectors of the underlying Service resource.The content in bold type has been replaced in the conversion:```\napiVersion: monitoring.googleapis.com/v1\nkind: PodMonitoring\nmetadata:\n name: example-app\nspec:\n selector:\n matchLabels:\n  app: example-app\n endpoints:\n - port: web\n path: /stats\n interval: 30s\n targetLabels:\n fromPod:\n - from: foo # pod label from example-app Service pods.\n  to: foo\n``` **Note:** You can convert a prometheus-operator [PodMonitorCR](https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#podmonitor) to the managed service's PodMonitoring CR in the same way; the label selectors are always copyable.You can always continue to use your existing prometheus-operator resources and deployment configs by using [self-deployed collectors](/stackdriver/docs/managed-prometheus/setup-unmanaged) instead of managed collectors. You can query metrics sent from both collector types, so you might want to use self-deployed collectors for your existing Prometheus deployments while using managed collectors for new Prometheus deployments.\n### Reserved labels\nManaged Service for Prometheus automatically adds the following labels to all metrics collected:- `project_id`: The identifier of the Google Cloud project associated with your metric.\n- `location`: The physical location (Google Cloud region) where the data is stored. This value is typically the region of your GKE cluster. If data is collected from an AWS or on-premises deployment, then the value might be the closest Google Cloud region.\n- `cluster`: The name of the Kubernetes cluster associated with your metric.\n- `namespace`: The name of the Kubernetes namespace associated with your metric.\n- `job`: The job label of the Prometheus target, if known; might be empty for rule-evaluation results.\n- `instance`: The instance label of the Prometheus target, if known; might be empty for rule-evaluation results.\nWhile not recommended when running on Google Kubernetes Engine, you can override the `project_id` , `location` , and `cluster` labels by [addingthem as args](/stackdriver/docs/managed-prometheus/setup-managed#gmp-outside-gcp) to the Deployment resource within `operator.yaml` . If you use any reserved labels as metric labels, Managed Service for Prometheus automatically relabels them by adding the prefix `exported_` . This behavior matches how upstream Prometheus handles [conflicts with reserved labels](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config) .\n### Teardown\nTo disable managed collection deployed using `gcloud` or the GKE UI, you can do either of the following:- Run the following command:```\ngcloud container clusters update CLUSTER_NAME --disable-managed-prometheus\n```\n- Use the GKE UI:- Select **Kubernetes Engine** in the Google Cloud console, then select **Clusters** .\n- Locate the cluster for which you want to disable managed collection and click its name.\n- On the **Details** tab, scroll down to **Features** and change the state to **Disabled** by using the edit button.To disable managed collection deployed by using Terraform, specify `enabled = false` in the `managed_prometheus` section of the [google_container_cluster resource](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#managed_prometheus) .To disable managed collection deployed by using `kubectl` , run the following command:```\nkubectl delete -f https://raw.githubusercontent.com/GoogleCloudPlatform/prometheus-engine/v0.8.2/manifests/operator.yaml\n```Disabling managed collection causes your cluster to stop sending new data to Managed Service for Prometheus. Taking this action does not delete any existing metrics data already stored in the system.Disabling managed collection also deletes the `gmp-public` namespace and any resources within it, including any [exportersinstalled](/stackdriver/docs/managed-prometheus/exporters/introduction) in that namespace.\n### Run managed collection outside of GKE\nIn GKE environments, you can run managed collection without further configuration. In other Kubernetes environments, you need to explicitly provide credentials, a `project-id` value to contain your metrics, a `location` value (Google Cloud region) where your metrics will be stored, and a `cluster` value to save the name of the cluster in which the collector is running.As `gcloud` does not work outside of Google Cloud environments, you need to [deploy using kubectl](/stackdriver/docs/managed-prometheus/setup-managed#kubectl-cli) instead. Unlike with `gcloud` , deploying managed collection using `kubectl` does not automatically upgrade your cluster when a new version is available. Remember to watch the [releasespage](https://github.com/GoogleCloudPlatform/prometheus-engine/releases) for new versions and manually upgrade by re-running the `kubectl` commands with the new version.You can provide a service account key by modifying the OperatorConfig resource within `operator.yaml` as described in [Providecredentials explicitly](#explicit-credentials) . You can provide `project-id` , `location` , and `cluster` values by adding them as `args` to the Deployment resource within `operator.yaml` .We recommend choosing `project-id` based on your planned tenancy model for reads. Pick a project to store metrics in based on how you plan to organize reads later with [metrics scopes](/stackdriver/docs/managed-prometheus/query#scoping-intro) . If you don't care, you can put everything into one project.For `location` , we recommend choosing the nearest Google Cloud region to your deployment. The further the chosen Google Cloud region is from your deployment, the more write latency you'll have and the more you'll be affected by potential networking issues. You might want to consult this [list of regions acrossmultiple clouds](https://www.cloudinfrastructuremap.com/) . If you don't care, you can put everything into one Google Cloud region. You can't use `global` as your location.For `cluster` , we recommend choosing the name of the cluster in which the operator is deployed.When properly configured, your OperatorConfig should look like this:```\n apiVersion: monitoring.googleapis.com/v1\n kind: OperatorConfig\n metadata:\n  namespace: gmp-public\n  name: config\n collection:\n  credentials:\n  name: gmp-test-sa\n  key: key.json\n rules:\n  credentials:\n  name: gmp-test-sa\n  key: key.json\n```And your Deployment resource should look like this:```\napiVersion: apps/v1\nkind: Deployment\n...\nspec:\n ...\n template:\n ...\n spec:\n  ...\n  containers:\n  - name: operator\n  ...\n  args:\n  - ...\n  - \"--project-id=PROJECT_ID\"\n  - \"--cluster=CLUSTER_NAME\"\n  - \"--location=REGION\"\n```This example assumes you have set the `` variable to a value like `us-central1` , for example.Running Managed Service for Prometheus outside of Google Cloud incurs data transfer fees. There are fees to transfer data into Google Cloud, and you might incur fees to transfer data out of another cloud. In versions 0.5.0 and higher, you can minimize these costs by enabling gzip compression through the OperatorConfig. Add the text shown in bold to the resource:```\n apiVersion: monitoring.googleapis.com/v1\n kind: OperatorConfig\n metadata:\n  namespace: gmp-public\n  name: config\n collection:\n  compression: gzip\n  ...\n```\n## Further reading on managed collection custom resources\nFor reference documentation about all the Managed Service for Prometheus custom resources, see the [prometheus-engine/doc/api reference](https://github.com/GoogleCloudPlatform/prometheus-engine/blob/v0.8.2/doc/api.md) .\n## What's next- [Use PromQL in Cloud Monitoring to query Prometheus metrics](/stackdriver/docs/managed-prometheus/query-cm) .\n- [Use Grafana to query Prometheus metrics](/stackdriver/docs/managed-prometheus/query) .\n- Use [PromQL alerts in Cloud Monitoring](/monitoring/promql/promql-in-alerting) .\n- Set up [managed rule evaluation](/stackdriver/docs/managed-prometheus/rules-managed) .\n- Set up [commonly used exporters](/stackdriver/docs/managed-prometheus/exporters/introduction) .\n-", "guide": "Google Cloud Observability"}