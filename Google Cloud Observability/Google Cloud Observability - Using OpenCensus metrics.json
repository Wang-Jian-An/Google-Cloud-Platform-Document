{"title": "Google Cloud Observability - Using OpenCensus metrics", "url": "https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/sli-metrics/open-census", "abstract": "# Google Cloud Observability - Using OpenCensus metrics\nThis page covers the basics of creating [OpenCensus](https://opencensus.io) metrics for availability and latency SLIs. It also provides implementation examples of how to define SLOs using OpenCensus metrics.\n", "content": "## The basics of OpenCensus\n[OpenCensus](https://opencensus.io) is a single open-source distribution of libraries, available on the [OpenCensus GitHub page](https://github.com/census-instrumentation) , that automatically collect traces and metrics and sends them to any backend. OpenCensus can be used to instrument your services to emit custom metrics that can be ingested into Cloud Monitoring. You can then use these metrics as SLIs.\nFor an example using OpenCensus to create Monitoring metrics that aren't specifically intended as SLIs, see [Custom metrics with OpenCensus](/monitoring/custom-metrics/open-census) .\n### Metrics\nTo collect metric data from your service by using OpenCensus, you must use the following OpenCensus constructs:\n- [Measure](https://opencensus.io/stats/measure/) , which represents the metric type to be recorded, specified with a metric name. A`Measure`can record Int64 or Float64 values.\n- [Measurement](https://opencensus.io/stats/measurement/) :, which records a specific data point collected and written by a`Measure`for a particular event. For example, a`Measurement`might record the latency of a specific response.\n- [View](https://opencensus.io/stats/view/) , which specifies an aggregation applied to a`Measure`. OpenCensus supports the following aggregation types:- Count: a count of the number of measurement points.\n- Distribution: a histogram distribution of the measurement points.\n- Sum: a sum of the measurement values.\n- LastValue: the last value recorded by the measurement.For more information, see [OpenCensus stats/metrics](https://opencensus.io/stats/) . Note that OpenCensus often refers to metrics as .\n### Instrumentation\nThe OpenCensus libraries are available for a number of languages. For language-specific information on instrumenting your service to emit metrics, see [OpenCensus language support](https://opencensus.io/language-support/) . Additionally, [Custom metrics with OpenCensus](/monitoring/custom-metrics/open-census) provides examples for languages commonly used with Monitoring.\nIn the basic case, you need to do the following:\n- Instrument your service to record and export metrics.\n- Define an exporter to receive the metrics.\nFor each metric, you need to define a `Measure` to specify the value type: Int64 or Float64. You also need to define and register the `View` to specify the aggregation type (count, distribution, sum, or last-value). To use the distribution aggregation type, you also need to specify the histogram bucket boundaries explicitly. You also specify a name for your metric in the `View` .\n### Exporter\nFinally, you need to use an exporter to collect the metrics and write them to Cloud Monitoring or another backend. For information on the language-specific exporters available for Monitoring, see [OpenCensus exporters](https://opencensus.io/exporters/) .\nYou can also write your own exporter; for more information, see [Writing a custom exporter](https://opencensus.io/exporters/custom-exporter/) .\n## Creating metrics for SLIs\nYour application must create OpenCensus metrics that can be used as SLIs in Cloud Monitoring:\n- For availability SLIs on request and error counts, use a`Measure`with count aggregation.\n- For latency SLIs, use a`Measure`with distribution aggregation.\n### Metrics for availability SLIs\nYou express a request-based availability SLI in the Cloud Monitoring API by using the [TimeSeriesRatio](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#TimeSeriesRatio) structure to set up a ratio of \"good\" or \"bad\" requests to total requests. This ratio is used in the `goodTotalRatio` field of a [RequestBasedSli](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#RequestBasedSli) structure.\nYour application must create OpenCensus metrics that can be used to construct this ratio. In your application, you must create at least two of the following:\n- A metric that counts total events; use this metric in the ratio's `totalServiceFilter` .You can create an OpenCensus metric of type Int64 with count aggregation, where you record a value of `1` for every received request.\n- A metric that counts \"bad\" events, use this metric in the ratio's `badServiceFilter` .You can create an OpenCensus metric of type Int64 with count aggregation, where you record a value of `1` for every error or failed request.\n- A metric that counts \"good\" events, use this metric in the ratio's `goodServiceFilter` .You can create an OpenCensus metric of type Int64 with count aggregation, where you record a value of `1` for every successful response.\n### Metrics for latency SLIs\nYou express a request-based latency SLI in the Cloud Monitoring API by using a [DistributionCut](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#DistributionCut) structure. This structure is used in the `distributionCut` field of a [RequestBasedSli](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#RequestBasedSli) structure.\nYou can create an Int64 or Float64 `Measure` with a `View` using the distribution aggregation type. You must also explicitly define your bucket boundaries. Note that it is critical to define the buckets in a way that allows you to precisely measure the percentage of requests that are within your desired threshold. For a discussion of this topic, see [Implementing SLOs](https://landing.google.com/sre/workbook/chapters/implementing-slos) in the [Site Reliability Engineering Workbook](https://landing.google.com/sre/workbook/toc) .\n## Implementation example\nThis section presents an example that implements metrics for basic availability and latency SLIs using OpenCensus in Node.js.\n### Instrumentation\nTo instrument your service to emit metrics using OpenCensus, do the following:\n- Include the necessary libraries:To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/monitoring/opencensus/main.go) \n```\nimport (\u00a0 \u00a0 \u00a0 \u00a0 \"flag\"\u00a0 \u00a0 \u00a0 \u00a0 \"fmt\"\u00a0 \u00a0 \u00a0 \u00a0 \"log\"\u00a0 \u00a0 \u00a0 \u00a0 \"math/rand\"\u00a0 \u00a0 \u00a0 \u00a0 \"net/http\"\u00a0 \u00a0 \u00a0 \u00a0 \"time\"\u00a0 \u00a0 \u00a0 \u00a0 \"contrib.go.opencensus.io/exporter/stackdriver\"\u00a0 \u00a0 \u00a0 \u00a0 \"go.opencensus.io/stats\"\u00a0 \u00a0 \u00a0 \u00a0 \"go.opencensus.io/stats/view\"\u00a0 \u00a0 \u00a0 \u00a0 \"go.opencensus.io/tag\")\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/monitoring/opencensus/app.js) \n```\n// opencensus setupconst {globalStats, MeasureUnit, AggregationType} = require('@opencensus/core');const {StackdriverStatsExporter} = require('@opencensus/exporter-stackdriver');\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/monitoring/opencensus/main.py) \n```\nfrom flask import Flaskfrom opencensus.ext.prometheus import stats_exporter as prometheusfrom opencensus.stats import aggregation as aggregation_modulefrom opencensus.stats import measure as measure_modulefrom opencensus.stats import stats as stats_modulefrom opencensus.stats import view as view_modulefrom opencensus.tags import tag_map as tag_map_modulefrom prometheus_flask_exporter import PrometheusMetrics\n```\n- Define and register the exporter:To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/monitoring/opencensus/main.go) \n```\n// Sets up Cloud Monitoring exporter.sd, err := stackdriver.NewExporter(stackdriver.Options{\u00a0 \u00a0 \u00a0 \u00a0 ProjectID: \u00a0 \u00a0 \u00a0 \u00a0 *projectID,\u00a0 \u00a0 \u00a0 \u00a0 MetricPrefix: \u00a0 \u00a0 \u00a0\"opencensus-demo\",\u00a0 \u00a0 \u00a0 \u00a0 ReportingInterval: 60 * time.Second,})if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 log.Fatalf(\"Failed to create the Cloud Monitoring exporter: %v\", err)}defer sd.Flush()sd.StartMetricsExporter()defer sd.StopMetricsExporter()\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/monitoring/opencensus/app.js) \n```\n// Stackdriver export interval is 60 secondsconst EXPORT_INTERVAL = 60;const exporter = new StackdriverStatsExporter({\u00a0 projectId: projectId,\u00a0 period: EXPORT_INTERVAL * 1000,});globalStats.registerExporter(exporter);\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/monitoring/opencensus/main.py) \n```\ndef setup_openCensus_and_prometheus_exporter() -> None:\u00a0 \u00a0 stats = stats_module.stats\u00a0 \u00a0 view_manager = stats.view_manager\u00a0 \u00a0 exporter = prometheus.new_stats_exporter(prometheus.Options(namespace=\"oc_python\"))\u00a0 \u00a0 view_manager.register_exporter(exporter)\u00a0 \u00a0 register_all_views(view_manager)\n```\n- Define a`Measure`for each metric:To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/monitoring/opencensus/main.go) \n```\n// Sets up metrics.var (\u00a0 \u00a0 \u00a0 \u00a0 requestCount \u00a0 \u00a0 \u00a0 = stats.Int64(\"oc_request_count\", \"total request count\", \"requests\")\u00a0 \u00a0 \u00a0 \u00a0 failedRequestCount = stats.Int64(\"oc_failed_request_count\", \"count of failed requests\", \"requests\")\u00a0 \u00a0 \u00a0 \u00a0 responseLatency \u00a0 \u00a0= stats.Float64(\"oc_latency_distribution\", \"distribution of response latencies\", \"s\"))\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/monitoring/opencensus/app.js) \n```\nconst REQUEST_COUNT = globalStats.createMeasureInt64(\u00a0 'request_count',\u00a0 MeasureUnit.UNIT,\u00a0 'Number of requests to the server');const ERROR_COUNT = globalStats.createMeasureInt64(\u00a0 'error_count',\u00a0 MeasureUnit.UNIT,\u00a0 'Number of failed requests to the server');const RESPONSE_LATENCY = globalStats.createMeasureInt64(\u00a0 'response_latency',\u00a0 MeasureUnit.MS,\u00a0 'The server response latency in milliseconds');\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/monitoring/opencensus/main.py) \n```\nm_request_count = measure_module.MeasureInt(\u00a0 \u00a0 \"python_request_count\", \"total requests\", \"requests\")m_failed_request_count = measure_module.MeasureInt(\u00a0 \u00a0 \"python_failed_request_count\", \"failed requests\", \"requests\")m_response_latency = measure_module.MeasureFloat(\u00a0 \u00a0 \"python_response_latency\", \"response latency\", \"s\")\n```\n- Define and register the`View`for each`Measure`with the appropriate aggregation type, and for response latency, the  bucket boundaries:To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/monitoring/opencensus/main.go) \n```\n// Sets up views.var (\u00a0 \u00a0 \u00a0 \u00a0 requestCountView = &view.View{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name: \u00a0 \u00a0 \u00a0 \u00a0\"oc_request_count\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Measure: \u00a0 \u00a0 requestCount,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Description: \"total request count\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Aggregation: view.Count(),\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 failedRequestCountView = &view.View{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name: \u00a0 \u00a0 \u00a0 \u00a0\"oc_failed_request_count\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Measure: \u00a0 \u00a0 failedRequestCount,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Description: \"count of failed requests\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Aggregation: view.Count(),\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 responseLatencyView = &view.View{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name: \u00a0 \u00a0 \u00a0 \u00a0\"oc_response_latency\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Measure: \u00a0 \u00a0 responseLatency,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Description: \"The distribution of the latencies\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 // Bucket definitions must be explicitly specified.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Aggregation: view.Distribution(0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000),\u00a0 \u00a0 \u00a0 \u00a0 })\u00a0 \u00a0 \u00a0 \u00a0 // Register the views.\u00a0 \u00a0 \u00a0 \u00a0 if err := view.Register(requestCountView, failedRequestCountView, responseLatencyView); err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 log.Fatalf(\"Failed to register the views: %v\", err)\u00a0 \u00a0 \u00a0 \u00a0 }\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/monitoring/opencensus/app.js) \n```\nconst request_count_metric = globalStats.createView(\u00a0 'request_count_metric',\u00a0 REQUEST_COUNT,\u00a0 AggregationType.COUNT);globalStats.registerView(request_count_metric);const error_count_metric = globalStats.createView(\u00a0 'error_count_metric',\u00a0 ERROR_COUNT,\u00a0 AggregationType.COUNT);globalStats.registerView(error_count_metric);const latency_metric = globalStats.createView(\u00a0 'response_latency_metric',\u00a0 RESPONSE_LATENCY,\u00a0 AggregationType.DISTRIBUTION,\u00a0 [],\u00a0 'Server response latency distribution',\u00a0 // Latency in buckets:\u00a0 [0, 1000, 2000, 3000, 4000, 5000, 10000]);globalStats.registerView(latency_metric);\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/monitoring/opencensus/main.py) \n```\n# set up viewslatency_view = view_module.View(\u00a0 \u00a0 \"python_response_latency\",\u00a0 \u00a0 \"The distribution of the latencies\",\u00a0 \u00a0 [],\u00a0 \u00a0 m_response_latency,\u00a0 \u00a0 aggregation_module.DistributionAggregation(\u00a0 \u00a0 \u00a0 \u00a0 [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\u00a0 \u00a0 ),)request_count_view = view_module.View(\u00a0 \u00a0 \"python_request_count\",\u00a0 \u00a0 \"total requests\",\u00a0 \u00a0 [],\u00a0 \u00a0 m_request_count,\u00a0 \u00a0 aggregation_module.CountAggregation(),)failed_request_count_view = view_module.View(\u00a0 \u00a0 \"python_failed_request_count\",\u00a0 \u00a0 \"failed requests\",\u00a0 \u00a0 [],\u00a0 \u00a0 m_failed_request_count,\u00a0 \u00a0 aggregation_module.CountAggregation(),)# register viewsdef register_all_views(view_manager: stats_module.stats.view_manager) -> None:\u00a0 \u00a0 view_manager.register_view(latency_view)\u00a0 \u00a0 view_manager.register_view(request_count_view)\u00a0 \u00a0 view_manager.register_view(failed_request_count_view)\n```\n- Record values for the request-count and error-count metrics:To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/monitoring/opencensus/main.go) \n```\n// Counts the request.stats.Record(ctx, requestCount.M(1))// Randomly fails 10% of the time.if rand.Intn(100) >= 90 {\u00a0 \u00a0 \u00a0 \u00a0 // Counts the error.\u00a0 \u00a0 \u00a0 \u00a0 stats.Record(ctx, failedRequestCount.M(1))\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/monitoring/opencensus/app.js) \n```\n// record a request count for every requestglobalStats.record([\u00a0 {\u00a0 \u00a0 measure: REQUEST_COUNT,\u00a0 \u00a0 value: 1,\u00a0 },]);// randomly throw an error 10% of the timeconst randomValue = Math.floor(Math.random() * 9 + 1);if (randomValue === 1) {\u00a0 // Record a failed request.\u00a0 globalStats.record([\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 measure: ERROR_COUNT,\u00a0 \u00a0 \u00a0 value: 1,\u00a0 \u00a0 },\u00a0 ]);\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/monitoring/opencensus/main.py) \n```\nmmap = stats_recorder.new_measurement_map()# count requestmmap.measure_int_put(m_request_count, 1)# fail 10% of the timeif random.randint(0, 100) > 90:\u00a0 \u00a0 mmap.measure_int_put(m_failed_request_count, 1)\u00a0 \u00a0 tmap = tag_map_module.TagMap()\u00a0 \u00a0 mmap.record(tmap)\u00a0 \u00a0 return (\"error!\", 500)\n```\n- Record latency values:To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/monitoring/opencensus/main.go) \n```\nrequestReceived := time.Now()// Records latency for failure OR success.defer func() {\u00a0 \u00a0 \u00a0 \u00a0 stats.Record(ctx, responseLatency.M(time.Since(requestReceived).Seconds()))}()\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/monitoring/opencensus/app.js) \n```\nglobalStats.record([\u00a0 {\u00a0 \u00a0 measure: RESPONSE_LATENCY,\u00a0 \u00a0 value: stopwatch.elapsedMilliseconds,\u00a0 },]);\n```To authenticate to Monitoring, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/monitoring/opencensus/main.py) \n```\nstart_time = time.perf_counter()mmap = stats_recorder.new_measurement_map()if random.randint(0, 100) > 90:\u00a0 \u00a0 response_latency = time.perf_counter() - start_time\u00a0 \u00a0 mmap.measure_float_put(m_response_latency, response_latency)\u00a0 \u00a0 tmap = tag_map_module.TagMap()\u00a0 \u00a0 mmap.record(tmap)\n```\n### Ingested metrics\nWhen your metrics are exported to Cloud Monitoring, they appear as metric types with a prefix that indicates that they originated from OpenCensus. For example, the name of each OpenCensus `View` in the Node.js implementation is mapped as follows:\n- `request_count_sli`becomes`custom.googleapis.com/opencensus/request_count_sli`.\n- `error_count_sli`becomes`custom.googleapis.com/opencensus/error_count_sli`.\n- `response_latency_sli`becomes`custom.googleapis.com/opencensus/response_latency_sli`.\nAfter your service is running, you can confirm that the metrics are being ingested into Monitoring by searching for them in Metrics Explorer.\n## Availability SLIs\nIn Cloud Monitoring, you express a request-based availability SLI by using a [TimeSeriesRatio](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#TimeSeriesRatio) structure. The following example shows an SLO that uses the ingested OpenCensus metrics and expects that the service has a 98% availability, as calculated by a ratio of `error_count_sli` to `request_count_sli` , over a rolling 28-day window:\n```\n{\u00a0 \"serviceLevelIndicator\": {\u00a0 \u00a0 \"requestBased\": {\u00a0 \u00a0 \u00a0 \"goodTotalRatio\": {\u00a0 \u00a0 \u00a0 \u00a0 \"totalServiceFilter\":\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"metric.type=\\\"custom.googleapis.com/opencensus/request_count_sli\\\",\u00a0 \u00a0 \u00a0 \u00a0\"badServiceFilter\":\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"metric.type=\\\"custom.googleapis.com/opencensus/error_count_sli\\\"\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 },\u00a0 \"goal\": 0.98,\u00a0 \"rollingPeriod\": \"2419200s\",\u00a0 \"displayName\": \"98% Availability, rolling 28 days\"}\n```\n**Note:** The filter strings in some of these examples have been line-wrapped for readability.\n## Latency SLIs\nIn Cloud Monitoring, you express a request-based latency SLI by using a [DistributionCut](/monitoring/api/ref_v3/rest/v3/services.serviceLevelObjectives#DistributionCut) structure. The following example shows an SLO that uses the ingested OpenCensus latency metric and expects that 98% of requests complete in under 1000 ms over a rolling one-day window:\n```\n{\u00a0 \"serviceLevelIndicator\": {\u00a0 \u00a0 \"requestBased\": {\u00a0 \u00a0 \u00a0 \"distributionCut\": {\u00a0 \u00a0 \u00a0 \u00a0 \"distributionFilter\":\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"metric.type=\\\"custom.googleapis.com/opencensus/response_latency_sli\\\",\u00a0 \u00a0 \u00a0 \u00a0 \"range\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"min\": 0,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"max\": 1000\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 },\u00a0 \"goal\": 0.98,\u00a0 \"rollingPeriod\": \"86400s\",\u00a0 \"displayName\": \"98% requests under 1000 ms\"}\n```\n**Note:** The filter strings in some of these examples have been line-wrapped for readability.", "guide": "Google Cloud Observability"}