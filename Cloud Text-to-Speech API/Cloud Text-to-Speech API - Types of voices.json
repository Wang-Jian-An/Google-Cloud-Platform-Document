{"title": "Cloud Text-to-Speech API - Types of voices", "url": "https://cloud.google.com/text-to-speech/docs/voice-types", "abstract": "# Cloud Text-to-Speech API - Types of voices\n", "content": "## Overview\nText-to-Speech generates audio data of natural, human-like speech. That is, it creates audio that sounds like a person talking. When you send a synthesis request to Text-to-Speech, you must specify a voice.\nThere are a wide selection of voices available for you to pick from in Text-to-Speech. The voices differ by language, gender, and accent (for some languages). Some languages have multiple voices to choose from. See the [Supported Voices](/text-to-speech/docs/voices) page for a complete list of voices available in your language. You can tell Text-to-Speech to use a specific voice from this list by setting the [VoiceSelectionParams](/text-to-speech/docs/reference/rest/v1/text/synthesize#voiceselectionparams) fields when you send a request to the API. See the Text-to-Speech [Quickstarts](/text-to-speech/docs/quickstarts) for details on how to send a [synthesize](/text-to-speech/docs/reference/rest/v1/text/synthesize) request.\n## Journey voices\n**    Experimental     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nJourney voices (experimental) are backed by advancements in large language modeling, which improves the prosodic richness. Journey voices can manage a broader range of pitch, volume, timbre, and length. They also have enhanced speech mechanics, making them better at handling disfluencies and interrupts compared to our other voice options. We recommend experimenting with these voices for conversational speech use cases.\n**Note:** Journey voices don't support SSML input.\n## Casual voices (Preview)\nCasual voices were designed to manage a conversational, imperfect dialogue for naturalness and comfort with human users. They support disfluencies ( , , , ) and have a more natural cadence and tone.\n## Studio voices\nThe Text-to-Speech API provides a premium voice tier called Studio. This voice type is designed specifically for use with long-form texts such as narration and news reading.\n**Note:** Studio voices support SSML, except for the following tags: `<mark>` , `<emphasis>` , `<prosody pitch>` , and `<lang>` .\n**Note:** Check the [table of supported voices](/text-to-speech/docs/voices) for availability of Studio voices in specific languages.\n## Neural2 voices\nThe Text-to-Speech API provides a voice tier called Neural2. Neural2 voices are based on the same technology used to create a [Custom Voice](/text-to-speech/custom-voice/docs) . Neural2 allows anyone to use Custom Voice technology without training their own custom voice. They're available in global and single region endpoints.\n**Note:** Check the [table of supported voices](/text-to-speech/docs/voices) for availability of Neural2 voices in specific languages.\n## WaveNet voices\nThe Text-to-Speech API also offers a group of premium voices generated using a , the same technology used to produce speech for Google Assistant, Google Search, and Google Translate. WaveNet technology provides more than just a series of synthetic voices: it represents a new way of creating synthetic speech.\n**Note:** Check the [table of supported voice](/text-to-speech/docs/voices) for availability of WaveNet-generated voices in specific languages. The Text-to-Speech API doesn't provide access to the voice of the Google Assistant.\nA WaveNet generates speech that sounds more natural than other text-to-speech systems. It synthesizes speech with more human-like emphasis and inflection on syllables, phonemes, and words.\nUnlike most other text-to-speech systems, a WaveNet model creates raw audio waveforms from scratch. The model uses a neural network that has been trained using a large volume of speech samples. During training, the network extracts the underlying structure of the speech, such as which tones follow each other and what a realistic speech waveform looks like. When given a text input, the trained WaveNet model can generate the corresponding speech waveforms from scratch, one sample at a time, with up to 24,000 samples per second and seamless transitions between the individual sounds.\n**Note:** Using WaveNet voices in your text-to-speech synthesis has different pricing than non-WaveNet generated audio. For more details, see the [pricing page](/text-to-speech/pricing) .\nTo hear the difference between a WaveNet-generated audio clip and a clip generated by another text-to-speech process, compare the two audio clips below.## Standard voices\nThe voices offered by Text-to-Speech differ in how they are produced, the synthetic speech technology used to create the machine model of the voice. One common speech technology, , typically generates audio data by passing outputs through signal processing algorithms known as [vocoders](https://en.wikipedia.org/wiki/Vocoder) . Many of the standard voices available in Text-to-Speech use a variation of this technology.", "guide": "Cloud Text-to-Speech API"}