{"title": "Compute Engine - Troubleshooting VM performance issues", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Troubleshooting VM performance issues\nThis document shows you how to diagnose and mitigate CPU, memory, and storage performance issues on Compute Engine virtual machine (VM) instances.\n", "content": "## Before you begin\n- [Install the Ops Agent](/monitoring/agent/ops-agent/install-index) to view full VM performance metrics, such as memory and disk space utilization## View performance metrics\nTo view performance metrics for your VMs, use the Cloud Monitoring observability metrics available in the Google Cloud console.\n- In the Google Cloud console, go to the **VM Instances** page. [Go to VM Instances](https://console.cloud.google.com/compute/instances) \n- You can view metrics for individual VMs or for the five VMs consuming the most of a resource.To view metrics for individual VMs, do the following:- Click the name of the VM you want to view performance metrics for. The VM instance **Details** page opens.\n- Click the **Observability** tab to open the Observability **Overview** page.\nTo view metrics for the five VMs consuming the most of a resource, click the **Observability** tab on the **VM instances** page.\n- Explore the VM's performance metrics. View the **Overview** , **CPU** , **Memory** , **Network** and **Disk** sections to see detailed metrics about each topic. The following are key metrics that indicate VM performance:- On the **Overview** page:- **CPU Utilization.** The percent of CPU used by the VM.\n- **Memory Utilization.** The percent of memory used by the VM, excluding disk caches. For Linux VMs, this also excludes kernel memory.\n- **Network Traffic.** The average rate of bytes sent and received in one minute intervals.\n- **New Connections with VMs/External/Google.** The estimated number of distinct TCP/UDP flows in one minute, grouped by peer type.\n- **Disk Throughput.** The average rate of bytes written to and read from disks.\n- **Disk IOPS.** The average rate of I/O read and write operations to disks.\n- On the **Network Summary** page:- **Sent to VMs/External/Google.** The rate of network traffic rate sent to Google services, VMs, and external destinations, based on a sample of packets. The metric is scaled so that the sum matches the total sent network traffic.\n- **Received from VMs/External/Google.** The rate of network traffic received from Google services, VMs, and external sources, based on a sample of packets. The metric is scaled so that the sum matches the total received network traffic.\n- **Network Packet Totals.** The total rate of sent and received packets in one minute intervals.\n- **Packet Mean Size.** The mean size of packets, in bytes, sent and received in one minute intervals.\n- **Firewall Incoming Packets Denied.** The rate of incoming network packets sent to the VM, but not received by the VM, because they were denied by firewall rules.\n- On the **Disks Performance** page:- **I/O Size Avg.** The average size of I/O read and write operations to disks. Small (4-16\u00a0KiB) random I/Os are usually limited by IOPS and sequential/large (256\u00a0KiB-1\u00a0MiB) I/Os by throughput.\n- **Queue Length Avg.** The number of queued and running disk I/O operations, also called queue depth, for the top 5 devices. To reach the performance limits of your persistent disks, [use a high I/O queue depth](/compute/docs/disks/optimizing-pd-performance#io-queue-depth) . Persistent disks are networked storage and generally have higher latency compared to physical disks or local SSDs.\n- **I/O Latency Avg.** The average latency of I/O read and write operations aggregated across operations of all disks attached to the VM, measured by the Ops Agent in the VM. This value includes operating system and file system processing latency, and is dependent on queue length and I/O size.## Understand performance metrics\nVM performance is affected by the hardware the VM runs on, the workload running on the VM, and the VM's machine type. If the hardware cannot support the workload or network traffic of your VM, your VM's performance might be affected.\n### CPU and memory performance\nTo understand a VM's CPU and memory performance, [view performance metrics](#viewing-performance-metrics) for **CPU Utilization** and **Memory Utilization** . You can additionally use [process metrics](/monitoring/agent/process-metrics) to view currently running processes, attribute anomalies in resource consumption to a specific process, or identify your VM's most expensive resource consumers.\nConsistently high CPU or memory utilization indicate the need to scale up a VM. If the VM consistently uses greater than 90% of its CPU or memory, [change the VM's machine type](/compute/docs/instances/changing-machine-type-of-stopped-instance#changing_a_machine_type) to a machine type with more vCPUs or memory.\n### Network performance\nTo understand a VM's network performance, [view performance metrics](#viewing-performance-metrics) for **Network Packet Totals** , **Packet Mean Size** , **New Connections with VMs/External/Google** , **Sent to VMs/External/Google** , **Received From VMs/External/Google** , and **Firewall Incoming Packets Denied** .\nReview whether **Network Packet Totals** , **Packet Mean Size** , and **New Connections with VMs/External/Google** are typical for your workload. For example, a web server might experience many connections and small packets, while a database might experience few connections and large packets.\nConsistently high outgoing network traffic might indicate the need to [change the VM's machine type](/compute/docs/instances/changing-machine-type-of-stopped-instance#changing_a_machine_type) to a machine type that has a higher egress bandwidth limit.\nIf you notice high numbers of incoming packets denied by firewalls, visit the **Network Intelligence Firewall Insights** page in the Google Cloud console to learn more about the origins of denied packets.\n[Go to the Firewall Insights page](https://console.cloud.google.com/net-intelligence/firewalls)\nIf you think your own traffic is being incorrectly denied by firewalls, [try running connectivity tests](/network-intelligence-center/docs/connectivity-tests/how-to/running-connectivity-tests) .\nIf your VM sends and receives a high amount of traffic from VMs in different zones or regions, consider modifying your workload to keep more data within a zone or region to increase latency and decrease costs. For more information, see \"VM-VM outbound data transfer pricing within Google Cloud\" on the [pricing page](/vpc/network-pricing#vpc-pricing) . If your VM sends a large amount of traffic to other VMs within the same zone, consider a [compact placement policy](/compute/docs/instances/use-compact-placement-policies) to achieve low network latency.\n### Storage performance\nTo understand a VM's storage performance, [view performance metrics](#viewing-performance-metrics) for **Throughput** , **Operations (IOPS)** , **I/O Size** , **I/O Latency** , and **Queue Length** .\nDisk throughput and IOPS indicate whether the VM workload is operating as expected. If throughput or IOPS is lower than the expected maximum listed in the [disk type chart](/compute/docs/disks/performance#type_comparison) , then I/O size, queue length, or I/O latency performance issues might be present.\nYou can expect I/O size to be between 4-16\u00a0KiB for workloads that require high IOPS and low latency, and 256\u00a0KiB-1\u00a0MiB for workloads that involve sequential or large write sizes. I/O size outside of these ranges indicate disk performance issues.\nQueue length, also known as queue depth, is a factor of throughput and IOPS. When a disk performs well, its queue length should be about the same as the queue length recommended to achieve a particular throughput or IOPS level, listed in the [Recommended I/O queue depth](/compute/docs/disks/optimizing-pd-performance#io-queue-depth) chart.\nI/O latency is dependent on queue length and I/O size. If the queue length or I/O size for a disk is high, the latency will also be high.\nIf any storage performance metrics indicate disk performance issues, do one or more of the following:\n- Review [Optimizing persistent disk performance](/compute/docs/disks/optimizing-pd-performance) and implement the best practices suggested to improve performance.\n- [Attach a new persistent disk to the VM](/compute/docs/disks/add-persistent-disk) to increase the disk performance limits. Disk performance is based on the total amount of storage attached to a VM. This option is the least disruptive as it does not require a you to unmount the filesystem, restart, or shutdown the VM.\n- [Resize the persistent disks](/compute/docs/disks/resize-persistent-disk) to increase the per-disk IOPS and throughput limits. Persistent disks do not have any reserved, unusable capacity, so you can use the full disk without performance degradation.\n- [Change the disk type](/compute/docs/disks/modify-persistent-disk#disk_type) to a disk type that offers higher performance. For more information, see [Configure disks to meet performance requirements](/compute/docs/disks/performance) .", "guide": "Compute Engine"}