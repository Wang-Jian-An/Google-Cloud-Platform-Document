{"title": "Compute Engine - Autoscaling groups of instances", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Autoscaling groups of instances\n[Managed instance groups (MIGs)](/compute/docs/instance-groups) offer autoscaling capabilities that let you automatically add or delete virtual machine (VM) instances from a MIG based on increases or decreases in load. Autoscaling helps your apps gracefully handle increases in traffic and reduce costs when the need for resources is lower. You define the [autoscaling policy](#autoscaling_policy) and the autoscaler performs automatic scaling based on the measured load and the options you configure.\nAutoscaling works by adding more VMs to your MIG when there is more load (scaling out), and deleting VMs when the need for VMs is lowered (scaling in).\n", "content": "## Prerequisites\nThe autoscaler uses the [Compute Engine Service Agent](/compute/docs/access/service-accounts#compute_engine_service_account) to add and remove instances in the group. Google Cloud automatically creates this service account, as well as its IAM policy binding to the Compute Engine Service Agent role, when the Compute Engine API is [enabled](https://console.cloud.google.com/apis/api/compute.googleapis.com/overview) .\nIf your project is missing this account\u2014for instance, if you have removed it\u2014you can add it manually:\n- In the Google Cloud console, go to the **IAM** page. [ Go to IAM](https://console.cloud.google.com/iam-admin/iam) \n- Click **Grant Access** .\n- In the **New principals** field, enter `service-` `` `@compute-system.iam.gserviceaccount.com` .\n- Select the **Compute Engine Service Agent** role.\n- Click **Save** .\n```\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n --member serviceAccount:service-PROJECT_NUMBER@compute-system.iam.gserviceaccount.com \\\n --role roles/compute.serviceAgent\n```\n## Fundamentals\nAutoscaling uses the following fundamental concepts and services.\n### Managed instance groups\nAutoscaling is a feature of [managed instance groups (MIGs)](/compute/docs/instance-groups) . A managed instance group is a collection of virtual machine (VM) instances that are created from a common [instance template](/compute/docs/instance-templates) . An autoscaler adds or deletes instances from a managed instance group based on the group's autoscaling policy. Although Compute Engine has both managed and unmanaged instance groups, only managed instance groups can be used with an autoscaler.\nTo understand the difference between a managed instance group and an unmanaged instance group, see [Instance groups](/compute/docs/instance-groups) .\nTo learn how to create a managed instance group, see [Creating MIGs](/compute/docs/instance-groups/creating-groups-of-managed-instances) .\n### Autoscaling policy\nWhen you define an autoscaling policy for your group, you specify one or more signals that the autoscaler uses to scale the group. When you set multiple signals in a policy, the autoscaler calculates the recommended number of VMs for each signal and sets your group's recommended size to the largest number.\nAn autoscaling policy must always have at least one scaling signal. When you turn on autoscaling in a MIG, by default, the autoscaler adds a CPU utilization signal. You can edit this default signal, or remove and add other signals in the policy.\nThe following sections provide an overview of signals based on target utilization metrics and signals based on schedules.\nYou can autoscale based on one or more of the following metrics that reflect the load of the instance group:\n- Average CPU utilization\n- HTTP load balancing serving capacity\n- Cloud Monitoring metrics\nThe autoscaler continuously collects usage information based on the selected utilization metric, compares actual utilization to your desired target utilization, and uses this information to determine whether the group needs to remove instances (scale in) or add instances (scale out).\nThe target utilization level is the level at which you want to maintain your virtual machine (VM) instances. For example, if you scale based on CPU utilization, you can set your target utilization level at 75% and the autoscaler will maintain the CPU utilization of the specified group of instances at or close to 75%. The utilization level for each metric is interpreted differently based on the autoscaling policy.\nFor more information about scaling based on target utilization metrics, see the following pages:\n- [Scaling based on CPU utilization](/compute/docs/autoscaler/scaling-cpu) \n- [Scaling based on load balancing serving capacity](/compute/docs/autoscaler/scaling-load-balancing) \n- [Scaling based on Cloud Monitoring metrics](/compute/docs/autoscaler/scaling-stackdriver-monitoring-metrics) You can use schedule-based autoscaling to allocate capacity for anticipated loads. You can have up to 128 scaling schedules per instance group. For each scaling schedule, specify the following:\n- **Capacity** : minimum required VM instances\n- **Schedule** : start time, duration, and recurrence (for example, once, daily, weekly, or monthly)\nEach scaling schedule is active from its start time and for the configured duration. During this time, autoscaler scales the group to have at least as many instances as defined by the scaling schedule.\nFor more information, see [Scaling based on schedules](/compute/docs/autoscaler/scaling-schedules) .\n### Initialization period\nThe initialization period, formerly known as cool down period, is the duration it takes for applications to initialize on your VM instances. While an application is initializing on an instance, the instance's usage data might not reflect normal circumstances. So the autoscaler uses the initialization period for scaling decisions in the following ways:\n- For scale-in decisions, the autoscaler considers usage data from all instances, even an instance that is still within its initialization period. The autoscaler recommends to remove instances if the average utilization from all instances is less than the target utilization.\n- For scale-out decisions, the autoscaler ignores usage data from instances that are still in their initialization period.\n- If you enable [predictive mode](#predictive_mode) , the initialization period informs the predictive autoscaler to scale out further in advance of anticipated load, so that applications are initialized when the load arrives. For example, if you set the initialization period to 300 seconds, then predictive autoscaler creates VMs 5 minutes ahead of forecasted load.\nBy default, the initialization period is 60 seconds. Actual initialization times vary because of numerous factors. We recommend that you test how long your application takes to initialize. To do this, create an instance and time the startup process from when the instance becomes [RUNNING](/compute/docs/instance-groups/getting-info-about-migs#verify_instances) until the application is ready.\nIf you set a initialization period value that is significantly longer than the time it takes for an instance to initialize, then your autoscaler might ignore legitimate utilization data, and it might underestimate the required size of your group, causing a [delay in scaling out](/compute/docs/autoscaler/understanding-autoscaler-decisions#delays_in_scaling_out) .\n### Stabilization period\nAutoscaling signals like CPU utilization are not very stable and can change rapidly. As the load goes up and down, the autoscaler needs to stabilize the signal to avoid continuous VM deletion and creation. The autoscaler stabilizes a signal by keeping sufficient VM capacity in order to serve the peak load that is observed during the .\nThe stabilization period is equal to 10 minutes or to the [initialization period](#cool_down_period) that you set, whichever is longer. The stabilization period is used only for scale-in decisions when the autoscaler has to delete VMs.\nWhen the load goes down, the autoscaler does not delete VMs immediately. The autoscaler keeps monitoring capacity needed for the duration of the stabilization period and deletes VMs only when there is sufficient capacity to meet the peak load. This might appear as a delay in scaling in, but it is a built-in feature of autoscaling.\nIf your application takes longer than 10 minutes to initialize on a new VM, then the autoscaler uses the initialization period instead of the default 10 minutes of stabilization to wait until the VM can be deleted. This ensures that the autoscaler decision to delete VM takes into account how long it takes to get back the serving capacity.\nWhen the load goes up, the autoscaler does not use stabilization period and immediately creates as many VMs as needed to meet the demand.\n### Autoscaling mode\nIf you need to investigate or configure your group without interference from autoscaler operations, you can temporarily [turn off or restrict autoscaling activities](/compute/docs/autoscaler/managing-autoscalers#turn_off_or_restrict_an_autoscaler) . The autoscaler's configuration persists while it is turned off or restricted, and all autoscaling activities resume when you turn it on again or lift the restriction.\n### Predictive autoscaling\nIf you enable predictive autoscaling to optimize your MIG for availability, the autoscaler forecasts future load based on historical data and scales out a MIG in advance of predicted load, so that new instances are ready to serve when the load arrives.\nPredictive autoscaling works best if your workload meets the following criteria:\n- Your application takes a long time to initialize\u2014for example, if you configure a [initialization period](#cool_down_period) of more than 2 minutes.\n- Your workload varies predictably with daily or weekly cycles.\nFor more information, see [Scaling based on predictions](/compute/docs/autoscaler/predictive-autoscaling) .\n### Scale-in controls\nIf your workloads take many minutes to initialize (for example, due to lengthy installation tasks), you can reduce the risk of response latency caused by abrupt scale-in events by [configuring scale-in controls](/compute/docs/autoscaler/managing-autoscalers#configuring_scale-in_controls) . Specifically, if you expect load spikes to follow soon after declines, you can limit the scale-in rate to prevent autoscaling from reducing a MIG's size by more VM instances than your workload can tolerate.\nYou don't have to configure scale-in controls if your application initializes quickly enough to pick up load spikes on scale out.\nTo configure scale-in controls, set the following properties in your autoscaling policy.\n- **Maximum allowed reduction** . The number of VM instances that your workload can afford to lose (from its peak size) within the specified trailing time window. Use this parameter to limit how much your group can be scaled in so that you can still serve a likely load spike until more instances start serving. The smaller you set the maximum allowed reduction, the longer it takes for your group to scale in.\n- **Trailing time window** . The history within which the autoscaler monitors the peak size required by your workload. The autoscaler will not resize below the maximum allowed reduction subtracted from the peak size observed in this period. You can use this parameter to define how long the autoscaler should wait before removing instances, as defined by the maximum allowed reduction. With a longer trailing time window, the autoscaler considers more historical peaks, making scale-in more conservative and stable.\nFor more information, see [Configuring scale-in controls](/compute/docs/autoscaler/managing-autoscalers#configuring_scale-in_controls) and [Understanding autoscaler decisions](/compute/docs/autoscaler/understanding-autoscaler-decisions#scale-in_controls) .\n### Recommended size\nThe recommended group size is the autoscaler's recommended number of VMs that the managed instance group should maintain, based on peak load observed during the last 10 minutes. These last 10 minutes are referred to as the [stabilization period](/compute/docs/autoscaler/understanding-autoscaler-decisions#delays_in_scaling_in) . The recommended size is recalculated constantly. If you set an autoscaling policy with scale-in controls, then the recommended size is constrained by your scale-in controls.\n## Limitations\n- You cannot use autoscaling with the following instance groups, which don't allow the autoscaler to create or delete VMs according to demand:- [Unmanaged instance groups](/compute/docs/instance-groups#unmanaged_instance_groups) \n- MIGs with [stateful configuration](/compute/docs/instance-groups/stateful-migs#stateful_configuration) \n- MIGs with [VM repairs turned off](/compute/docs/instance-groups/about-repair#turn_off_VM_repairs) \n- Regional MIGs with a [target distribution shape](/compute/docs/instance-groups/regional-mig-distribution-shape) of`ANY`or`ANY_SINGLE_ZONE`\n- You cannot [create VM instances with specific names](/compute/docs/instance-groups/add-remove-vms-in-mig#creating_instances_with_specific_names_in_migs) while autoscaling is turned on.\n- Do not use Compute Engine autoscaling with MIGs that are owned by Google Kubernetes Engine. For Google Kubernetes Engine groups, use [cluster autoscaling](/kubernetes-engine/docs/cluster-autoscaler) instead. If you're not sure whether a MIG is part of a GKE cluster, look for the `gke` prefix in the MIG name. For example, `gke-test-1-3-default-pool-eadji9ah` .## What happens during autohealing\nAutoscaling works independently from [autohealing](/compute/docs/instance-groups/autohealing-instances-in-migs) . If you configure autohealing for your group and an instance fails the health check, the MIG attempts to recreate the instance. While an instance is being recreated by the MIG, the number of running instances in the group might be lower than the minimum number of instances specified for the group ( `autoscalingPolicy.minNumReplicas` ).\n## Pricing\nThere is no additional charge for configuring an autoscaling policy. Autoscaler dynamically adds or deletes VM instances, so you are charged only for the resources that your MIG uses. You can control resource cost by configuring the minimum and maximum number of instances in the autoscaling policy. For Compute Engine pricing information, see [Pricing](https://cloud.google.com/compute/all-pricing) .\n## What's next\n- Learn [how autoscaling works in a regional MIG](/compute/docs/instance-groups/regional-migs#autoscaling_a_regional_mig) .\n- If you don't have an existing MIG, review how to [create a managed instance group](/compute/docs/instance-groups/creating-groups-of-managed-instances#create_managed_group) .\n- Create an autoscaler that scales on:- [CPU utilization](/compute/docs/autoscaler/scaling-cpu) \n- [Load balancing serving capacity](/compute/docs/autoscaler/scaling-load-balancing) \n- [Cloud Monitoring metrics](/compute/docs/autoscaler/scaling-stackdriver-monitoring-metrics) \n- [Schedules](/compute/docs/autoscaler/scaling-schedules) \n- [Manage your autoscaler](/compute/docs/autoscaler/managing-autoscalers) , for example, to get information about it, to configure scale-in controls, or to temporarily restrict it.", "guide": "Compute Engine"}