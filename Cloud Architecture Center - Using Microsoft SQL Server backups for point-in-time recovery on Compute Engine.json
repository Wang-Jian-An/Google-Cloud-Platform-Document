{"title": "Cloud Architecture Center - Using Microsoft SQL Server backups for point-in-time recovery on Compute Engine", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Using Microsoft SQL Server backups for point-in-time recovery on Compute Engine\nLast reviewed 2023-06-27 UTC\n**Note:** This document or section includes references to one or more terms that Google considers disrespectful or offensive. The terms are used because they are keywords in the software that's described in the document.The terms: `master`\nIn this tutorial, you perform backups on a Compute Engine [SQL Server](https://www.microsoft.com/en-us/sql-server/default.aspx) instance. The tutorial shows you how to manage these backups and store them in Cloud Storage and how to restore a database to a point in time.\nThis tutorial is useful if you are a sysadmin, developer, engineer, database admin, or devops engineer who wants to back up SQL Server data.\n **Note:** Although managing backups is crucial for any disaster recovery plan, this tutorial doesn't address the topic of [disaster recovery for SQL Server](/architecture/dr-scenarios-for-data#data_backup_and_recovery_2) .\nThe tutorial assumes that you are familiar with the following:- Microsoft Windows\n- Microsoft SQL Server\n- SQL Server full, differential, and transaction log backups\n- [Compute Engine](/compute) \n- [Cloud Storage](/storage) \n", "content": "## Objectives\n- Launch a SQL Server instance and create a database.\n- Perform full, differential, and transaction log backups.\n- Upload the backups to Cloud Storage.\n- Restore the database from a Cloud Storage backup.\n## Costs\nIn this document, you use the following billable components of Google Cloud:- [Compute Engine](/compute/pricing) \n- Networking\n- [Cloud Storage](/storage/pricing) \n- SQL Server (premium with compute engine)\nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . ## Before you begin- Install a Remote Desktop Protocol (RDP) client of your choice. For more  information, see [Microsoft Remote Desktop clients](https://docs.microsoft.com/windows-server/remote/remote-desktop-services/clients/remote-desktop-clients) . If you already have an RDP client installed, you can skip this task.\nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Preparing the SQL Server instanceIn this section, you launch the SQL Server instance, prepare the database, and configure an encryption key.\n### Launch the SQL Server instanceYour first task is to launch a SQL Server instance and create the backup folder.- Open Cloud Shell: [GO TO Cloud Shell](https://console.cloud.google.com/cloudshell) \n- Launch a SQL Server instance:```\ngcloud compute instances create sqlserver \\\u00a0 \u00a0 --zone=us-central1-c \\\u00a0 \u00a0 --machine-type=n1-standard-1 \\\u00a0 \u00a0 --image-family=sql-std-2019-win-2019 \\\u00a0 \u00a0 --image-project=windows-sql-cloud \\\u00a0 \u00a0 --boot-disk-size=50GB \\\u00a0 \u00a0 --boot-disk-type=pd-standard \\\u00a0 \u00a0 --tags=sqlserver \\\u00a0 \u00a0 --scopes=https://www.googleapis.com/auth/cloud-platform\n```\n- Go to the **VM instances** page in the Google Cloud console and find the Windows instance you want to connect to: [GO TO THE VM INSTANCES PAGE](https://console.cloud.google.com/compute/instances) \n- [Set the initial password for the instance](/compute/docs/instances/windows/creating-passwords-for-windows-instances) . Store the password in a safe place.\n- In the [Compute Engine section](https://console.cloud.google.com/compute/instances) of the Google Cloud console, click the **RDP** dropdown and select the **Download the RDP file** option to download the RDP file for your instance. Use this file to connect to the instance using an RDP client. For more information, see [Microsoft Remote Desktop clients](https://docs.microsoft.com/windows-server/remote/remote-desktop-services/clients/remote-desktop-clients) .\n### Install SQL Server Management StudioInstall [Microsoft SQL Server Management Studio (SSMS)](https://docs.microsoft.com/sql/ssms/download-sql-server-management-studio-ssms) by doing the following:- In your RDP session, minimize all windows, and start the Windows PowerShell ISE app.\n- At the PowerShell prompt, download and execute the SSMS installer:```\nStart-BitsTransfer `\u00a0 \u00a0 -Source \"https://aka.ms/ssmsfullsetup\" `\u00a0 \u00a0 -Destination \"$env:Temp\\ssms-setup.exe\"& $env:Temp\\ssms-setup.exe\n```\n- Accept the prompt to allow changes to be made.\n- In the SSMS installer, click **Install** .\n- When the installation is finished, click **Restart** to restart the remote machine. This closes the RDP session.\n- To reconnect, in the RDP window, click **Connect** . If the remote machine has not finished restarting, wait a few moments and then try connecting again.\n- Enter your username and the password you saved earlier (leave the **Domain** field blank), and then click **OK** to reconnect.\n### Prepare the backup and restore folders\n- In the RDP session, minimize all windows, and then open **Google Cloud SDK Shell** (not the same as Cloud Shell) on the Windows desktop.\n- Create a backup folder:```\nmkdir c:\\backup\n```\n- Create a restore folder:```\nmkdir c:\\restore\n```\n### Prepare the database\n- In Cloud Shell, on the instance, create a test database:```\nosql -E -Q \"create database testdb\"\n``` **Note:** If you see a login failed message, run the Google Cloud SDK Shell as an administrator.\n- Create a test table:```\nosql -E -Q \"create table testdb.dbo.testtable(status varchar(255))\"\n```\n### Configure the encryption key\n- In Cloud Shell, create a primary database key:```\nosql -E -Q \"USE master;CREATE MASTER KEY ENCRYPTION BY PASSWORD = 'MyPassword!';\"\n``` **Note:** In this tutorial, you use the password `MyPassword!` for the encryption key, but you can choose whichever password you want.\n- Create a backup certificate:```\nosql -E -Q \"USE master; CREATE CERTIFICATE testdbcert WITH SUBJECT = 'testdb certificate';\"\n```\n## Performing backups\nIn this section, you create full, differential, and transaction log backups while changing the database between each one.- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('Initial')\"\n```\n- In Cloud Shell, perform a full backup:```\nosql \u00a0-E -Q \"BACKUP DATABASE testdb TO DISK='c:\\backup\\testdb.bak' WITH INIT,\u00a0 \u00a0 COMPRESSION,\u00a0 \u00a0 ENCRYPTION\u00a0 \u00a0 (\u00a0 \u00a0 \u00a0 \u00a0 ALGORITHM = AES_256,\u00a0 \u00a0 \u00a0 \u00a0 SERVER CERTIFICATE = testdbcert\u00a0 \u00a0 ) \u00a0\"\n``` **Note:** You'll receive a warning that you have not backed up the certificate. Backing up the certificate is beyond the scope of this document. For more information, see [BACKUP CERTIFICATE (Transact-SQL)](https://learn.microsoft.com/en-us/sql/t-sql/statements/backup-certificate-transact-sql?view=sql-server-ver16) .\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('After Full Backup')\"\n```\n- Perform a differential backup:```\nosql \u00a0-E -Q \"BACKUP DATABASE testdb TO DISK='c:\\backup\\testdb-diff.bak' WITH DIFFERENTIAL,COMPRESSION,ENCRYPTION\u00a0 \u00a0 (\u00a0 \u00a0 ALGORITHM = AES_256,\u00a0 \u00a0 SERVER CERTIFICATE = testdbcert\u00a0 \u00a0 ) \"\n```\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('After Diff Backup')\"\n```\n- Perform a transaction log backup:```\nosql \u00a0-E -Q \"BACKUP LOG testdb TO DISK='c:\\backup\\testdb-log.bak' WITH COMPRESSION,ENCRYPTION\u00a0 \u00a0 (\u00a0 \u00a0 ALGORITHM = AES_256,\u00a0 \u00a0 SERVER CERTIFICATE = testdbcert\u00a0 \u00a0 ) \"\n```\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('Bad Row')\"\n```\n- Verify the rows in the table:```\nosql -E -Q \"select * from testdb.dbo.testtable\"\n```The output resembles the following:```\nInitial\nAfter Full Backup\nAfter Diff Backup\nBad Row\n```\nIn this section, you create full, differential, and transaction log backups while changing the database between each one. You use the built-in backup and restore commands with Cloud Storage.\nSQL Server 2022 (16.x) supports extended object storage integration by introducing a new connector that uses a REST API to connect to any provider of S3-compatible object storage. You can use the `BACKUP TO URL` and `RESTORE FROM URL` commands in SQL Server 2022 with any S3-compatible storage destination as the URL.\nSQL Server uses credentials to connect to resources outside of itself. A credential is a record containing authentication information. To authenticate and authorize your access to the Cloud Storage S3 interface, you must create and use an Access Key and a Secret Key. You then store these keys in your SQL Server credential.- Create an Access Key and Secret Key for your user account to your Cloud Storage bucket:- Go to **Cloud Storage** .\n- Go to **Settings** .\n- Go to **INTEROPERABILITY** .\n- Go to **Access keys for your user account** .\n- Scroll down and click **Create a key** to create a new Access key and a Secret key.\n- Create a credential in your SQL Server 2022 instance:Run the following code sample to create a credential. Choose a name for your credential. Replace the `ACCESS_KEY` and `SECRET` fields with the values you generated in the previous step.```\nosql -E -Q \"\u00a0 \u00a0 CREATE CREDENTIAL [CREDENTIAL_NAME]\u00a0 \u00a0 WITH\u00a0 \u00a0 \u00a0 \u00a0 IDENTITY = 'S3 Access Key',\u00a0 \u00a0 \u00a0 \u00a0 SECRET = 'ACCESS_KEY:SECRET'\u00a0 \u00a0 \"\n``` **Note:** The `IDENTITY = 'S3 Access Key'` identity definition is important because it tells SQL Server to use the S3 Connector.Do not change this field.\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('Initial')\"\n```\n- Perform the `BACKUP` operation to the Cloud Storage bucket:Run the backup database command having your Cloud Storage bucket URI set as the `URL` parameter value and the name of the credential you defined earlier as the value of the `WITH CREDENTIAL` option. This command will enable SQL Server to create the backup file and upload it at the same time to the Cloud Storage bucket, with no need for extra local disk space.```\nosql -E -Q \"\u00a0 \u00a0 BACKUP DATABASE testdb\u00a0 \u00a0 TO URL = 's3://storage.googleapis.com/BUCKET_NAME/FOLDER_NAME/testdb.bak'\u00a0 \u00a0 WITH\u00a0 \u00a0 \u00a0 \u00a0 CREDENTIAL = 'CREDENTIAL_NAME',\u00a0 \u00a0 \u00a0 \u00a0 FORMAT,\u00a0 \u00a0 \u00a0 \u00a0 STATS = 10,\u00a0 \u00a0 \u00a0 \u00a0 MAXTRANSFERSIZE = 10485760,\u00a0 \u00a0 \u00a0 \u00a0 BLOCKSIZE = 65536,\u00a0 \u00a0 \u00a0 \u00a0 COMPRESSION;\u00a0 \u00a0 \"\n``` **Note:** Make sure you are using the `'s3://storage.googleapis.com'` prefix because it tells SQL Server to use the S3-compatible connector. This also implies using HTTPS.\nThe following list explains the parameters of the **WITH** statement:- **FORMAT:** Overwrites any existing backups and creates a new media set.\n- **STATS:** Tells SQL Server to provide information about the progress of the backup.\n- **COMPRESSION:** Tells SQL Server to compress the backup file, making it smaller and faster to upload to Cloud Storage.\n- **MAXTRANSFERSIZE = 10485760** , **BLOCKSIZE = 65536** options help avoid I/O device errors with larger backup files.\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('After Full Backup')\"\n```\n- Perform a differential backup:```\nosql -E -Q \"\u00a0 \u00a0 BACKUP DATABASE testdb\u00a0 \u00a0 TO URL = 's3://storage.googleapis.com/BUCKET_NAME/FOLDER_NAME/testdb-diff.bak'\u00a0 \u00a0 WITH\u00a0 \u00a0 \u00a0 \u00a0 DIFFERENTIAL,\u00a0 \u00a0 \u00a0 \u00a0 CREDENTIAL = 'CREDENTIAL_NAME',\u00a0 \u00a0 \u00a0 \u00a0 STATS = 10,\u00a0 \u00a0 \u00a0 \u00a0 MAXTRANSFERSIZE = 10485760,\u00a0 \u00a0 \u00a0 \u00a0 BLOCKSIZE = 65536,\u00a0 \u00a0 \u00a0 \u00a0 COMPRESSION;\u00a0 \u00a0 \"\n```\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('After Diff Backup')\"\n```\n- Perform a transaction log backup:```\nosql -E -Q \"\u00a0 \u00a0 BACKUP LOG testdb\u00a0 \u00a0 TO URL = 's3://storage.googleapis.com/BUCKET_NAME/FOLDER_NAME/testdb-log.bak'\u00a0 \u00a0 WITH\u00a0 \u00a0 \u00a0 \u00a0 CREDENTIAL = 'CREDENTIAL_NAME',\u00a0 \u00a0 \u00a0 \u00a0 STATS = 10,\u00a0 \u00a0 \u00a0 \u00a0 MAXTRANSFERSIZE = 10485760,\u00a0 \u00a0 \u00a0 \u00a0 BLOCKSIZE = 65536,\u00a0 \u00a0 \u00a0 \u00a0 COMPRESSION;\u00a0 \u00a0 \"\n```\n- Add a row to the test table:```\nosql -E -Q \"insert into testdb.dbo.testtable ([status]) VALUES ('Bad Row')\"\n```\n- Verify the rows in the table:```\nosql -E -Q \"select * from testdb.dbo.testtable\"\n```The output looks like this:```\nInitial\nAfter Full Backup\nAfter Diff Backup\nBad Row\n```\n## Managing your backupsIn this section, you store your backups remotely in Cloud Storage, configure your Cloud Storage bucket to prune old backups automatically, and schedule your backups. If you're running multiple database servers, consider creating multiple directories in your Cloud Storage bucket to represent different servers.\n### Upload your backups to Cloud Storage\nNow that you have a few backup files, you can upload your backups to Cloud Storage.- In Cloud Shell, create a Cloud Storage bucket. Bucket names must be globally unique across Google Cloud. To ensure that your bucket name is unique, consider namespacing it with your project name, as shown here:```\ngsutil mb \"gs://${DEVSHELL_PROJECT_ID}-sql-backups\"\n```\n- In the shell window in the RDP session, copy your files to your Cloud Storage bucket. In the following command, replace `BUCKET_NAME` with the name of the bucket you just created.```\ngsutil cp -n c:\\backup\\testdb*.bak gs://BUCKET_NAME\n``` **Note:** The `-n` flag prevents the `gsutil` tool from overwriting identical files.You can use the [gsutil cp](/storage/docs/gsutil/commands/cp) command to create entire directory structures and to upload multiple files at a time.\nThe backup files are already on your bucket as SQL Server 2022 supports the backup directly to the Cloud Storage.\n### Set up automatic file pruning in Cloud StorageOlder backups eventually outlive their usefulness, so you need to remove them. To help automate this process, Cloud Storage has a lifecycle management mechanism that you can use to manage the lifecycle of your backup files.\n **Warning:** The lifecycle mechanism deletes files permanently, with no chance of recovering them. When testing your lifecycle configuration, test it on noncritical data files.\nTo configure lifecycle management for the objects in your bucket:- In Cloud Shell, create a JSON lifecycle configuration file. This file instructs Cloud Storage to delete files after 30 days:```\nbash -c 'cat <<EOF > \u00a0lifecycle.json{\u00a0 \u00a0 \"lifecycle\": {\u00a0 \u00a0 \u00a0 \u00a0 \"rule\": [{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"action\": { \"type\": \"Delete\" },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"condition\": { \"age\": 30 }\u00a0 \u00a0 \u00a0 \u00a0 }]\u00a0 \u00a0 }}EOF'\n```\n- Set the lifecycle configuration for your Cloud Storage bucket. Replace `BUCKET_NAME` with the name of your bucket:```\ngsutil lifecycle set lifecycle.json gs://BUCKET_NAME\n```\n### Schedule your backupsIn general, it's a good practice to take a full backup periodically and perform differential backups until the next full backup. On Windows, one way to schedule backups is by using scheduled tasks.\nIf you create a backup script that takes a series of backups, make sure to include some logical validation steps at each point to verify successful completion. If validation fails, make sure the script raises a Windows alert. In addition, to avoid filling up the local disk, make sure the script removes the local backup file after successfully uploading to Cloud Storage.## Restoring from backupIn this section, you restore your SQL Server database from backup files that you stored in Cloud Storage.\n- In Cloud Shell in your RDP session, download your backup files from Cloud Storage. Replace `BUCKET_NAME` with the name of your SQL Server backup storage bucket:```\ngsutil cp gs://BUCKET_NAME/testdb*.bak c:\\restore\n```\n- Open the SQL Server Management console.\n- Click the Start button, and then click **Microsoft SQL Server Tools 18** > **Microsoft SQL Server Management Studio 18** .\n- Leave the **Connection** fields as is, and then click **Connect** .\n **Note:** If you see an login failed message, run the Management Studio as an administrator.- In the left-hand pane, expand **Databases** .\n- Right-click`testdb`, and in pop-up the menu, click **Tasks** > **Restore** > **Database** .\n- Import the backup files to the console:- For **Source** , select **Device** .\n- Click thebutton.\n- In the dialog that opens, click **Add** , select all the files under`C:\\restore`, and then click **OK** .\n- Click **OK** .\n- To view point-in-time restore options:- Click **Timeline** .\n- Under **Restore to** , click **Specific date and time** .\n- For **Timeline Interval** , select **hour** .\n- Choose a time in the **Transaction Log Backup** range.\n- Click **Cancel** to leave the timeline screen. **Note:** To restore your database to a specific point in time, you press **OK** instead of **Cancel** .\n- In this tutorial, you restore the database to its state before the transaction log backup. In order to do that, in the backups list, clear the transaction log row: \n- Start the restore process:- Click **OK** .\n- Wait for the database to finish the restore process, and when you see the message,`Database 'testdb' restored successfully`, click **OK** .\n- List the rows in the test table:```\nosql -E -Q \"select * from testdb.dbo.testtable;\"\n```The output shows two rows:```\n\"Initial\n\"After Full Backup\"\n```You see all the lines you inserted into the table before taking the transaction log backup.\nYou can perform the `RESTORE` operation. Set the Cloud Storage file path as the `URL` parameter value. For example, this T-SQL script restores the full backup directly from Cloud Storage:\n```\n```osql -E -Q \"RESTORE DATABASE testdbFROM\u00a0 \u00a0 URL = 's3://storage.googleapis.com/BUCKET_NAME/FOLDER_NAME/testdb.bak'WITH\u00a0 \u00a0 CREDENTIAL = 'CREDENTIAL_NAME';\u00a0 \u00a0 \"```\n```- Open the SQL Server Management console.\n- Click the Start button, and then click **Microsoft SQL Server Tools 19** > **Microsoft SQL Server Management Studio 19** .\n **Note:** You need to install a Microsoft SQL Server Management Studio version 19.x.- Leave the **Connection** fields as is, and then click **Connect** .\n **Note:** If you see an login failed message, run the Management Studio as an administrator.- In the left-hand pane, expand **Databases** .\n- Right-click`testdb`, and in pop-up the menu, click **Tasks** > **Restore** > **Database** .\n- Import the backup files to the console:- For **Source** , select **Device** .\n- Click thebutton.\n- In the dialog that opens, click **Backup media type** , and select **S3 URL** \n- In the dialog that opens, click **Add** . Add the three locations of your backup files on the Cloud Storage bucket and the Secret Key and Access Key you provided when you created the credential. **Note:** Use the same format like the one for performing the backup for the **S3 URL** .\n- Click **OK** .\n- To view point-in-time restore options:- Click **Timeline** .\n- Under **Restore to** , click **Specific date and time** .\n- For **Timeline Interval** , select **hour** .\n- Choose a time in the **Transaction Log Backup** range.\n- Click **Cancel** to leave the timeline screen. **Note:** To restore your database to a specific point in time, you press **OK** instead of **Cancel** .\n- In this tutorial, you restore the database to its state before the transaction log backup. In order to do that, in the backups list, clear the transaction log row: \n- Start the restore process:- Click **OK** .\n- Wait for the database to finish the restore process, and when you see the message,`Database 'testdb' restored successfully`, click **OK** .\n- List the rows in the test table:```\nosql -E -Q \"select * from testdb.dbo.testtable;\"\n```The output shows two rows:```\n\"Initial\n\"After Full Backup\"\n```You see all the lines you inserted into the table before taking the transaction log backup.\n## Clean up\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Read about [SQL Server best practices on Google Cloud](/compute/docs/instances/sql-server/best-practices) .\n- Read about [configuring SQL Server availability groups](/compute/docs/instances/sql-server/configure-availability) .\n- Read the [disaster recovery planning guide for Google Cloud](/architecture/dr-scenarios-planning-guide) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Cloud Architecture Center"}