{"title": "Vertex AI - Compare and analyze runs", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Compare and analyze runs\nYou can use the Vertex AI SDK for Python to view Vertex AI Experiments runs data and compare the runs.\n- [Get runs data](/vertex-ai/docs/experiments/compare-analyze-runs#api-analyze-runs) \n- [Compare runs](/vertex-ai/docs/experiments/compare-analyze-runs#api-compare-runs) \nThe Google Cloud console provides a visualization of the data associated with these runs.\n- [View experiment run data](/vertex-ai/docs/experiments/compare-analyze-runs#view-experiment-run-data) \n- [Compare experiment runs](/vertex-ai/docs/experiments/compare-analyze-runs#compare-experiment-runs) ", "content": "## Get experiment runs data\nThese samples involve getting run metrics, run parameters, runtime series metrics, artifacts, and classification metrics for a particular experiment run.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_run_metrics_sample.py) \n```\ndef get_experiment_run_metrics_sample(\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 experiment: Union[str, aiplatform.Experiment],\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> Dict[str, Union[float, int]]:\u00a0 \u00a0 experiment_run = aiplatform.ExperimentRun(\u00a0 \u00a0 \u00a0 \u00a0 run_name=run_name, experiment=experiment, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_run.get_metrics()\n```\n- `run_name`: Specify the appropriate run name for this session.\n- `experiment`: The name or instance of this experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) .### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_run_params_sample.py) \n```\ndef get_experiment_run_params_sample(\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 experiment: Union[str, aiplatform.Experiment],\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> Dict[str, Union[float, int, str]]:\u00a0 \u00a0 experiment_run = aiplatform.ExperimentRun(\u00a0 \u00a0 \u00a0 \u00a0 run_name=run_name, experiment=experiment, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_run.get_params()\n```\n- `run_name`: Specify the appropriate run name for this session.\n- `experiment`: The name or instance of this experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) .### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_run_time_series_metric_data_frame_sample.py) \n```\ndef get_experiment_run_time_series_metric_data_frame_sample(\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 experiment: Union[str, aiplatform.Experiment],\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> \"pd.DataFrame\": \u00a0# noqa: F821\u00a0 \u00a0 experiment_run = aiplatform.ExperimentRun(\u00a0 \u00a0 \u00a0 \u00a0 run_name=run_name, experiment=experiment, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_run.get_time_series_data_frame()\n```\n- `run_name`: Specify the appropriate run name for this session.\n- `experiment`: The name or instance of this experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) .### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_run_artifacts_sample.py) \n```\ndef get_experiment_run_artifacts_sample(\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 experiment: Union[str, aiplatform.Experiment],\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> List[artifact.Artifact]:\u00a0 \u00a0 experiment_run = aiplatform.ExperimentRun(\u00a0 \u00a0 \u00a0 \u00a0 run_name=run_name,\u00a0 \u00a0 \u00a0 \u00a0 experiment=experiment,\u00a0 \u00a0 \u00a0 \u00a0 project=project,\u00a0 \u00a0 \u00a0 \u00a0 location=location,\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_run.get_artifacts()\n```\n- `run_name`: Specify the appropriate run name for this session.\n- `experiment`: The name or instance of this experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) .### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_run_classification_metrics_sample.py) \n```\ndef get_experiment_run_classification_metrics_sample(\u00a0 \u00a0 run_name: str,\u00a0 \u00a0 experiment: Union[str, aiplatform.Experiment],\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,) -> List[Dict[str, Union[str, List]]]:\u00a0 \u00a0 experiment_run = aiplatform.ExperimentRun(\u00a0 \u00a0 \u00a0 \u00a0 run_name=run_name, experiment=experiment, project=project, location=location\u00a0 \u00a0 )\u00a0 \u00a0 return experiment_run.get_classification_metrics()\n```\n- `run_name`: Specify the appropriate run name for this session.\n- `experiment`: The name or instance of this experiment.   You can find your list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) .## Compare runs\nUsing the Vertex AI SDK for Python, you can retrieve the data associated with your experiment. The data for the experiment runs is returned in a DataFrame.\nThe data for the experiment runs is returned in a DataFrame.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/experiment_tracking/get_experiment_data_frame_sample.py) \n```\ndef get_experiments_data_frame_sample(\u00a0 \u00a0 experiment: str,\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,):\u00a0 \u00a0 aiplatform.init(experiment=experiment, project=project, location=location)\u00a0 \u00a0 experiments_df = aiplatform.get_experiment_df()\u00a0 \u00a0 return experiments_df\n```\n- `experiment_name`: Provide a name for the experiment.   You can find your list of experiments in the   Google Cloud console by selecting **Experiments** in the section nav.\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these IDs in the Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) .## Google Cloud console\nUse the Google Cloud console to view details of your and compare the experiment runs to each other.### View experiment run data\n- In the Google Cloud console, go to the **Experiments** page. [Go to Experiments](https://console.cloud.google.com/vertex-ai/experiments) .A list of experiments associated with a project appears.\n- Select the experiment containing the run that you want to check.A list of runs,  timeseries data charts, and a metrics and parameters data table appear. Notice, in this  case, three runs are selected, but only two lines appear in the timeseries data charts.  There is no third line because the third experiment run does not have any timeseries data to display.\n- Click the name of the run to navigate to its details page.The navigation bar and timeseries data charts appear.\n- To view metrics, parameters, artifacts, and details for your selected run,  click the respective buttons in the navigation bar.- Metrics\n- Parameters\n- ArtifactsTo view artifact lineage, click the **Open artifact in Metadata Store** link. The   lineage graph associated with the run appears.\n- DetailsTo share the data with others, use the URLs associated with the views. For example, share the list of experiment runs associated with an experiment:### Compare experiment runs\nYou can select runs to compare both within an experiment and across experiments.\n- In the Google Cloud console, go to the **Experiments** page. [Go to Experiments](https://console.cloud.google.com/vertex-ai/experiments) .A list of experiments appears.\n- Select the experiment containing the runs that you want to compare. A list of runs appears.\n- Select the experiment runs that you want to compare. Click **Compare** .By default, charts appear comparing timeseries metrics of the selected experiment runs.\n- To add additional runs from any experiment in your project, click **Add run** .\nTo share the data with others, use the URLs associated with the views. For example, share the comparison view of timeseries metrics data:\nSee [Create and manage experiment runs](/vertex-ai/docs/experiments/create-manage-exp-run) for how to update the status of a run.\n## What's next\n- [Track executions and artifacts](/vertex-ai/docs/experiments/track-executions-artifacts)", "guide": "Vertex AI"}