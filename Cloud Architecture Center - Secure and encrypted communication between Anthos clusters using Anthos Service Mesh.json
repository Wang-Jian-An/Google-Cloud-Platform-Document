{"title": "Cloud Architecture Center - Secure and encrypted communication between Anthos clusters using Anthos Service Mesh", "url": "https://cloud.google.com/architecture/reference-patterns/overview", "abstract": "# Cloud Architecture Center - Secure and encrypted communication between Anthos clusters using Anthos Service Mesh\nLast reviewed 2021-04-30 UTC\nThis document shows network, platform, and security engineers who administer Kubernetes clusters how to handle external, cluster-to-cluster communication by using [Anthos Service Mesh](/service-mesh/docs/overview) ingress and egress gateways. The document describes how to use Anthos Service Mesh to encrypt and help secure outbound traffic (egress) from workloads deployed on one Kubernetes cluster to workloads running in another Kubernetes cluster. The techniques described show how to use separate certificates for mutual, encrypted, cluster-to-cluster communication.\nThe guidance in this document stems from customer requirements to use a specific root [Certificate Authority (CA)](https://wikipedia.org/wiki/Certificate_authority) for intra-cluster communication. You might find such requirements in highly regulated markets, such as financial services or healthcare. The guidance presented here also allows the use of endpoints other than Kubernetes clusters, such as financial clearance providers or an API interface for sensitive data. This guidance is especially relevant for organizations who need to adhere to strict security and auditing policies.\nYou can operate and handle the encrypted communication without touching the workloads running in the clusters. For guidance on how to configure your own clusters, follow the [accompanying tutorial](/architecture/encrypt-secure-communication-between-multiple-anthos-clusters-tutorial) .\n", "content": "## Introduction\nWhen enterprises first start adopting Kubernetes, they often start with a single cluster, where most communication stays within that cluster. Soon, cross-namespace interaction becomes increasingly important, which is where a network policy provider such as [Calico](https://www.projectcalico.org/) or [Cillium](https://cilium.io/) can help. However, as container environments grow it becomes more relevant to ensure that communication can happen securely between external services and your containers that are running inside Kubernetes clusters.\nNetwork policy is a great way to deal with traditional security concepts such as creating cluster-internal firewall rules, but it has only limited use outside of the cluster. It's possible to allow only a specific IP address to be reached, but no control over the content or identity is available. Therefore, a more versatile concept is required, which also helps you encrypt traffic to other external services. The following diagram offers one approach.\nIn the world of applications, encryption is usually done by using [TLS](https://wikipedia.org/wiki/Transport_Layer_Security) (Transport Layer Security). This means you can encrypt traffic by using a private (secret) certificate with a public counterpart, as shown in the preceding diagram. The receiving party holds the public certificate, which is used to verify that the information is coming from a trusted source. HTTPS web traffic uses TLS to help ensure secure and encrypted communications between a client and a web server. In this case, the public certificate comes from a trusted issuer (like [Google Trust Services](https://pki.goog/) ), also referred to as a CA, that is part of the [public key infrastructure](https://wikipedia.org/wiki/Public_key_infrastructure) (PKI). TLS verifies the identity of the server, but it doesn't verify the identity of the client.\nIn cases where the client itself must also be verified, mutual authentication, or mTLS, is required. mTLS is used when both the sender and receiver must identify themselves to the other party, as shown in the following diagram.\nThis method is often used for applications that need an extra layer of security. In the financial industry, and for personally identifiable information (PII), regulators often require mTLS.\n## Anthos Service Mesh\nAnthos Service Mesh is a Google-managed service mesh solution based on OSS [Istio](https://istio.io/) . That means that it is 100% Istio API compatible. Anthos Service Mesh can provide mTLS functionality at the platform level instead of inside the application code, which means it can apply to services without requiring you to recode every service. Operations like certificate rotation are also part of Anthos Service Mesh. This document focuses on mTLS and the external communication features of Anthos Service Mesh. There are many [other features](/service-mesh/docs/supported-features) such as fault injection, advanced load balancing, and error handling.\nBy routing all traffic through side-car proxies ( [Envoy](https://www.envoyproxy.io/) ), service meshes such as Anthos Service Mesh unburden the developer from mundane (but important) tasks such as encryption and certificate handling. By using a transparent proxy, service meshes can enable powerful L7 functions such as routing HTTP and HTTPS calls based on header information. However, Anthos Service Mesh also enables traffic encapsulation and encryption, which can help improve security.\n## Example configuration: MySQL communication between clusters\nYou can use this scenario when you want to have secure and trusted communication between services in different clusters. In this example, the MySQL client application is talking to a MySQL server DB workload running in a different Kubernetes cluster, as the following diagram shows.\nAlthough service meshes often work at [OSI L7](https://wikipedia.org/wiki/OSI_model#Layer_7:_Application_Layer) , you can also use some of their functionality to control [L4](https://wikipedia.org/wiki/OSI_model#Layer_4:_Transport_Layer) communications.\nHere's what you need in order to make the concept work:\n- The communication between applications and clusters must be encrypted.\n- The client and server communication need to be mutually verified (mTLS).\n- The client and server workloads don't need to change.\nAlthough you can set up the [MySQL database](https://dev.mysql.com/doc/refman/5.7/en/using-encrypted-connections.html) to accept only encrypted connections, that setup requires you to change the database client, which you might not have full control over.\nThere are multiple ways to address these requirements by using Anthos Service Mesh. One way is to create a shared Istio control plane between clusters and have the services communicate with each other because they belong to a single logical service mesh. You can do this for Anthos-enabled GKE clusters by using Anthos Service Mesh either in a [single project](/service-mesh/docs/gke-install-multi-cluster) or [multi-project](/service-mesh/docs/gke-install-overview) setup.\nHowever, because there's a requirement to have a separate trust chain for cluster-to-cluster communication you can use the [egress gateway](https://istio.io/latest/docs/tasks/traffic-management/egress/egress-gateway/) <\u2013> [ ingress gateway](https://istio.io/latest/docs/tasks/traffic-management/ingress/ingress-control/) approach using mTLS.\nEgress and ingress gateways are Envoy proxies that live on the boundaries of the mesh.\nYou can configure them to control traffic flow into and out of the service mesh.This also works for non-Kubernetes endpoints and lets you use different certs for the encrypted communication.\n## Configure Anthos Service Mesh egress and ingress\nIn the preceding scenario, you handle secure, cluster-to-cluster communication by using egress and ingress gateways between the respective clusters.\n### What is an egress gateway?\nEgress means traffic that's flowing out of your service mesh. An egress gateway provides a controlled exit point for that traffic.\nWithout additional configuration, for a Pod where the sidecar proxy has been injected, traffic destined for a service that resides outside of the mesh (for example, a public API service) is routed from the Pod to the sidecar proxy. In a GKE cluster (and most other Kubernetes clusters), the Node IP address uses a NAT to translate sidecar proxy traffic, which flows directly to the external address of the service. The following diagram shows this configuration.\nIn this diagram, the client is calling the server side, which represents the external service. To the mesh, this traffic is outbound, so you need to configure the egress gateway on the client side (for example, the MySQL client).\nYou configure the egress gateway to forward the call to the external service. After the external service processes the request and returns the response, it again goes through the egress gateway back to the client proxy and finally to the Pod that's issuing the call (for example, the MySQL client).\n### What is an ingress gateway?\nIngress means traffic that's flowing into the service mesh. An ingress gateway exposes services to the outside world (that is, outside the service mesh) and handles how these services should be accessible. It's comparable to a Kubernetes Ingress object.\nWith an ingress gateway, you can define a single controlled entrypoint where traffic goes into the mesh. Initially, the traffic enters through the load balancer, which is created by defining an ingress gateway service. From there, the request is forwarded to the sidecar proxy, and from the proxy it is forwarded to the Pod. The Pod can process the request and return the response by using the same route in reverse. The following diagram shows this configuration.\nThis traffic is inbound traffic to the mesh of the other cluster (VPC 2). Therefore, you need to configure the ingress gateway on the server side to handle those calls.\nThe server-side configuration of the ingress gateway forwards the call to the internal service. After the internal service processes the request, the response it returns traverses back through the ingress gateway to the client.\n### Combining egress and ingress functionality for mutual TLS\nAs mentioned previously, for the client side you need to define an egress gateway that acts as a controlled exit point for the service mesh. To make sure that traffic leaving the mesh through the gateway is encrypted by mTLS, you can use a technique called [TLS origination](https://istio.io/latest/docs/tasks/traffic-management/egress/egress-gateway-tls-origination/) . Configure an egress gateway to perform TLS origination for traffic to external services.\nWhen the traffic leaving the service mesh from the client side is encrypted, you need to make sure the server side can identify itself to the client and decipher the encrypted traffic.\nFor that you use the ingress gateway as a single point of entry into the mesh. [Configure the ingress gateway](https://istio.io/latest/docs/tasks/traffic-management/ingress/secure-ingress/#configure-a-mutual-tls-ingress-gateway) so that it expects mutually encrypted traffic.\n## Mesh architecture overview\nThe following diagram describes what's necessary to implement this concept for the MySQL scenario, without changing anything in the application or the server.\nIn VPC 1, you see that the client cluster running MySQL client is accessing the server. The server is located in VPC 2.\nThe client side is more configuration heavy than the server side because you need to do a bit more traffic matching and routing, to ensure that the application uses the egress gateway. However, this configuration is a day-zero effort, meaning you have to do it only once. Once you implement it, it's fairly easy to maintain.\nA benefit of implementing this concept using Kubernetes is that all configuration items are stored in YAML files. This means the entire construct can be used on a versioned repository, which lets you track changes and easily revert them if necessary.\n## The client side\nThis subsection examines the client-side configuration. Each element you see in the diagram has a distinct function in the mesh to control how the traffic is routed through the egress gateway to reach its destination, the MySQL server.\nTraffic routing is only one part of the required functionality. Other elements control the encryption of the traffic, fully transparent, to help ensure that the communication is always secure. The following sections examine the elements to further understand their role and function in this scenario.### Service entry\nA service mesh creates its own service registry to a Kubernetes cluster. The control plane uses this registry to configure the side-car proxies as a routing table. The services running in Kubernetes are automatically discovered and added to the service mesh registry. Services not running inside the Kubernetes cluster cannot be automatically discovered, but can be defined by using ServiceEntries. This way, the client can use an entry as a hostname to connect to external services.\nIn Anthos Service Mesh, fully qualified domain names (FQDNs) are used to identify all services. The FQDN is the most important part in this construct because the certificates are based on the hostname. Although it's possible to change the FQDN, it means that you also need to regenerate all necessary certificates.\nTo enable communication, you must configure the service mesh to listen for calls toward the external service in order to properly route the traffic. The mesh lets you define a [service entry](https://istio.io/latest/docs/reference/config/networking/service-entry/) that points to that external service.\nThis construct is called `MESH_EXTERNAL` and is ideal for these use cases. You might also want to specify what you're looking for. Because this is an L4 use case and you can only control the IP address and port, you need to tell the mesh the protocol and the specific ports\u2014in this case, TCP and port `3306` (the standard MySQL protocol port). Also, the server-side counterpart (as shown in the preceding diagram) is listening on port `13306` (the egress gateway of the server cluster). Finally, you need to tell your service entry to capture traffic with this port tag.\nThe following example YAML service entry illustrates this configuration:\n```\napiVersion: networking.istio.io/v1alpha3kind: ServiceEntrymetadata:\u00a0name: mysql-externalspec:\u00a0hosts:\u00a0 \u00a0- mysql.fqdn.example\u00a0location: MESH_EXTERNAL\u00a0ports:\u00a0 \u00a0- number: 3306\u00a0 \u00a0 \u00a0name: tcp\u00a0 \u00a0 \u00a0protocol: TCP\u00a0 \u00a0- number: 13306\u00a0 \u00a0 \u00a0name: tls\u00a0 \u00a0 \u00a0protocol: TLS\u00a0resolution: DNS\u00a0endpoints:\u00a0 \u00a0- address: mysql.fqdn.example\u00a0 \u00a0 \u00a0ports:\u00a0 \u00a0 \u00a0 \u00a0tls: 13306\n```\nWith the `hosts` field, you can set the FQDN of the external service, or you can specify the `location` field to be `MESH_EXTERNAL` . You must also specify the `ports` values used by the external service\u2014in this case, `13306` and [3306](https://dev.mysql.com/doc/mysql-port-reference/en/mysql-ports-reference-tables.html#:%7E:text=Port%203306%20is%20the%20default,such%20as%20mysqldump%20and%20mysqlpump.) . `13306` will be the exposed port from the server-side ingress gateway. It's important to specify both in this service entry. For the protocol, you must specify `TLS` , because this connection provides L4-based TLS communication.\nWhen you have defined the service entry, the mesh can then listen for calls and change the routing based on these rules.\nService entries must be based on existing DNS or IP address entries, meaning that the DNS name should already be resolvable by a DNS server. For example, you can use a core DNS service inside Kubernetes and add entries to it that are not already present in `kube-dns` . You can't use the service entry to create a DNS entry.\n### Virtual service\nThe [virtual service](https://istio.io/latest/docs/reference/config/networking/virtual-service/) is a definition used to affect traffic routing patterns. You use the virtual service to make sure that calls from the MySQL client to the service entry are routed to the egress gateway. Thus, you can set up a virtual service to route traffic based on vastly different factors. In an L7 use case, these factors go beyond traffic routing. For example, you can tell the virtual service how to react if a target is unreachable. This example uses a subset of this functionality in order to route matching traffic only to the egress gateway for further processing.\nThe preceding diagram shows how you use the virtual service to route traffic from the Pod through the proxy to the egress gateway and from the egress gateway to the external service.\nYou must also specify the port of your egress gateway (externally facing), which is `15443` by default. This port is set on the egress gateway once you create it. You can pick any other free port, but you'd need to patch the gateway to open the chosen port.\nThe following code snippet shows what such a virtual service definition might look like:\n```\napiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:\u00a0name: direct-mysql-through-egress-gatewayspec:\u00a0hosts:\u00a0 \u00a0- mysql.fqdn.example\u00a0gateways:\u00a0 \u00a0- istio-egressgateway-mysql\u00a0 \u00a0- mesh\u00a0tcp:\u00a0 \u00a0- match:\u00a0 \u00a0 \u00a0 \u00a0- gateways:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- mesh\u00a0 \u00a0 \u00a0 \u00a0 \u00a0port: 3306\u00a0 \u00a0 \u00a0route:\u00a0 \u00a0 \u00a0 \u00a0- destination:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0host: istio-egressgateway.istio-system.svc.cluster.local\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0subset: mysql\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0number: 15443\u00a0 \u00a0 \u00a0 \u00a0 \u00a0weight: 100\u00a0 \u00a0- match:\u00a0 \u00a0 \u00a0 \u00a0- gateways:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- istio-egressgateway-mysql\u00a0 \u00a0 \u00a0 \u00a0 \u00a0port: 15443\u00a0 \u00a0 \u00a0route:\u00a0 \u00a0 \u00a0 \u00a0- destination:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0host: mysql.fqdn.example\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0number: 13306\u00a0 \u00a0 \u00a0 \u00a0 \u00a0weight: 100\n```\nThe `hosts` field holding the FQDN URL is used to apply the match rules specifically on the given URL. The first `match` clause is defined on the mesh, which is a reserved keyword and applies to all gateways within the mesh. The first `route` block is defined to tell the mesh what to do if the match is true. In this case, you send the matched traffic to the egress gateway. This is where the egress port is defined in addition to the weighting for the route. The block also mentions a `subset` value, which you define later.\nThe second `match` clause is applied to the egress gateway. The second `route` block appended to the second `match` clause configures the mesh to send the traffic to the server cluster ingress by using the `host` field with the ingress FQDN and by specifying port `13306` .\nFor the next step, you must program the certificate injection into the gateway for the mTLS communication to work.\n### Destination rules\nNow that you have your traffic properly identified (service entry) and routed from the Pod through the proxy to the gateway (virtual service) the next step is encrypting the traffic. You use [destination rules](https://istio.io/latest/docs/reference/config/networking/destination-rule/#:%7E:text=Traffic%20policies%20can%20be%20customized,traffic%20to%20the%20port%209080.) to encrypt the traffic. Such rules in a service mesh are applied to the traffic after the routing and are used to introduce load balancing and other traffic management functionality.\nIn this case, you use destination rules to define a standard load balancing pattern and also to add certificates to enable endpoints using mTLS communication. This step is performed by matching the FQDN of the MySQL server, exposed through the server cluster's ingress gateway, and defining an mTLS rule.\nThe following definition is an example of such a destination rule:\n```\napiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata:\u00a0 name: egressgateway-for-mysqlspec:\u00a0 host: istio-egressgateway.istio-system.svc.cluster.local\u00a0 subsets:\u00a0 \u00a0 - name: mysql\u00a0 \u00a0 \u00a0 trafficPolicy:\u00a0 \u00a0 \u00a0 \u00a0 loadBalancer:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 simple: ROUND_ROBIN\u00a0 \u00a0 \u00a0 \u00a0 portLevelSettings:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 number: 15443\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 tls:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mode: ISTIO_MUTUAL\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 sni: mysql.fqdn.example\n```\nThe `host` field is set to the cluster FQDN of the egress gateway. The first destination rule is performing the inner mesh encryption of the traffic, using the [ISTIO_MUTUAL](https://istio.io/latest/docs/reference/config/networking/destination-rule/#ClientTLSSettings) mode (using the FQDN of the egress gateway). In the code snippet, you define a [subset](https://istio.io/latest/docs/reference/config/networking/destination-rule/#Subset) , which is used to create round-robin load balancing and to set (overwrite) the port to `15443` . The egress gateway uses this port to send the traffic.\nIt's important that you set the `tls` field correctly because it defines the inner mesh policy ( `ISTIO_MUTUAL` ). Under the `sni` (Service Name Indication) field, you add the FQDN of the ingress gateway from your server cluster.\nThe second destination rule encrypts the traffic with the custom provided root CA certificates, before sending them through the egress gateway:\n```\napiVersion: networking.istio.io/v1alpha3kind: DestinationRulemetadata:\u00a0name: originate-mtls-for-mysqlspec:\u00a0host: mysql.fqdn.example\u00a0trafficPolicy:\u00a0 \u00a0loadBalancer:\u00a0 \u00a0 \u00a0simple: ROUND_ROBIN\u00a0 \u00a0portLevelSettings:\u00a0 \u00a0- port:\u00a0 \u00a0 \u00a0 \u00a0number: 13306\u00a0 \u00a0 \u00a0tls:\u00a0 \u00a0 \u00a0 \u00a0mode: MUTUAL\u00a0 \u00a0 \u00a0 \u00a0credentialName: client-credential\u00a0 \u00a0 \u00a0 \u00a0sni: mysql.fqdn.example\n```\nThe `host` field is set again to the external FQDN. The `trafficPolicy` field sets the load balancer mode to `ROUND_ROBIN` . It also sets the port to `13306` and the `tls` mode to [MUTUAL](https://istio.io/latest/docs/reference/config/networking/destination-rule/#ClientTLSSettings-TLSmode) , because now you are using the custom root CA certificates and the counterpart\u2014the ingress gateway also using `tls MUTUAL` \u2014must identify itself using the same signed root CA certificates. Using this port, the traffic can flow through the server cluster by way of its ingress gateway to reach the MySQL database.\nThe encryption using the custom root CA certificates is typically [done through the Envoy Secret Discovery Service (SDS](https://istio.io/latest/docs/concepts/security/#pki) ) by using a secret in Kubernetes that holds the certificates. You add the secret name to the destination rule by using the `credentialName` field.\nIn summary, traffic now does the following:\n- It's issued by MySQL transparently toward an external FQDN. This FQDN exists in mesh registration.\n- It's encrypted by using a destination rule using internal mesh certificates.\n- It's routed to the gateway by a virtual service.\n- It's encrypted using a custom root CA by a destination rule (this is different from the mesh CA used for mesh certificates).\n- It's forwarded through the egress gateway in mTLS mode.## The server side\nIn this scenario, the server side is easier to configure than the client side. All it requires is an ingress gateway and a virtual service entry to route the traffic to the MySQL DB server, as shown in the following diagram.### The server cluster ingress gateway\nThe ingress gateway is exposing port `13306` . It can be any port, but in this case it's adding a \"1\" in front of the standard MySQL port for easier identification. For security reasons, we don't recommend exposing the standard MySQL port ( `3306` ) directly to the internet.\nBecause the default Istio ingress gateway isn't listening on port `13306` , you need to add this functionality. The following example code snippet patches port `13306` to the gateway:\n```\n[{\u00a0 \"op\": \"add\",\u00a0 \"path\": \"/spec/ports/0\",\u00a0 \"value\": {\u00a0 \u00a0 \"name\": \"tls-mysql\",\u00a0 \u00a0 \"protocol\": \"TCP\",\u00a0 \u00a0 \"targetPort\": 13306,\u00a0 \u00a0 \"port\": 13306\u00a0 }}]\n```\nYou can store this code in a JSON file and use it with the `kubectl` patch command to apply it to the ingress gateway service.\nIn order to process traffic correctly, the ingress gateway has to be set up in [MUTUAL](https://istio.io/latest/docs/tasks/traffic-management/ingress/secure-ingress/#configure-a-mutual-tls-ingress-gateway) mode.\nAt this point, the ingress gateway decrypts the incoming traffic by using the certificate from its credentials store and sends the traffic into the mesh, where the mesh internal certs are used to re-encrypt the traffic. The following example code snippet shows how this might be configured:\n```\napiVersion: networking.istio.io/v1alpha3kind: Gatewaymetadata:\u00a0name: gateway-mysqlspec:\u00a0selector:\u00a0 \u00a0istio: ingressgateway # Istio default gateway implementation\u00a0servers:\u00a0- port:\u00a0 \u00a0 \u00a0number: 13306\u00a0 \u00a0 \u00a0name: tls-mysql\u00a0 \u00a0 \u00a0protocol: TLS\u00a0 \u00a0tls:\u00a0 \u00a0 \u00a0mode: MUTUAL\u00a0 \u00a0 \u00a0credentialName: mysql-credential\u00a0 \u00a0hosts:\u00a0 \u00a0- \"mysql.fqdn.example\"\n```\nIn this example the standard Istio ingress gateway is used under the `selector` field. Using the `servers` field, you can set the port `number` ( `13306` ) and `protocol` ( `TLS` ) values that the ingress should expect. It's important to give the port a unique name.\nDefine `tls` and provide a secret containing the certificate signed by the same root CA as used with the egress gateway using the `credentialName` field. The certificate must be stored in a Kubernetes secret.\nFinally you want to match traffic directing the MySQL DB FQDN. The name resolution for this FQDN set under `hosts` must be set to the ingress gateway's public IP address.\n### The server cluster virtual service\nAfter the traffic has entered the mesh through port `13306` , coming from the egress gateway of the client cluster (originator), you have to identify this traffic and make sure it reaches the MySQL DB server. You do this by defining a virtual service:\n```\napiVersion: networking.istio.io/v1alpha3kind: VirtualServicemetadata:\u00a0name: mysql-virtual-servicespec:\u00a0hosts:\u00a0 \u00a0- \"mysql.fqdn.example\"\u00a0gateways:\u00a0 \u00a0- gateway-mysql\u00a0tcp:\u00a0 \u00a0- route:\u00a0 \u00a0 \u00a0- destination:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0number: 3306\u00a0 \u00a0 \u00a0 \u00a0 \u00a0host: mysql.default.svc.cluster.local\n```\nTo send the traffic to the MySQL DB service, you need to check for the FQDN host again by using the `hosts` field. Also, you must use the `gateways` field to configure where to apply this virtual service definition. This is the gateway object that you defined in the preceding YAML file. Set the `tcp` field, because this is L4 traffic, and set the `route` field to point to the MySQL DB Kubernetes service. You must specify the service name under the `host` field by using the Kubernetes cluster internal FQDN.\n**Note:** At no time is the MySQL DB service exposed to the internet. The service is running as a cluster internal service of type [ClusterIP](https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types) .\nThe MySQL DB can get requests from the client on port `3306` . The traffic traverses through the sidecar proxy of the MySQL DB server. For the MySQL DB server it looks like a local, unencrypted request to access the database.\nAfter the server answers the call, the traffic flows back to the client using the same route and for the client this looks as if a local DB just answered its call.\nTraffic is encrypted three times using different certificates traversing from client to server which helps secure the client-server communication.\nThe first time the traffic is encrypted or decrypted is inside the mesh at the client side with certificates using the mesh CA.\nThe second time the traffic is encrypted when leaving the mesh at the egress gateway using a certificate from a custom root CA. Then the traffic is authenticated and decrypted on the ingress gateway using a certificate signed by the same custom root CA.\nThe last (third) time the traffic is encrypted or decrypted inside the mesh at the server side when traversing from the ingress gateway to the MySQL server. Again here (because it's mesh internal) the certificates of the mesh CA are used.\nIn this scenario - the communication between the two clusters had to be encrypted using the mentioned root CA. By applying this configuration, it is possible to handle this part separately and independently from the mesh internal certificates and from the application itself.\nBy having this extra step, this configuration also lets you easily rotate these certificates regularly without changing the mesh CA of the respective Kubernetes clusters.\n## What's next\n- Try out the [companion tutorial](/architecture/encrypt-secure-communication-between-multiple-anthos-clusters-tutorial) .\n- Consult the [GKE](/kubernetes-engine/docs/how-to/hardening-your-cluster) hardening guide.\n- Learn about managing configuration and policy across all of your infrastructure with [Config Management](/anthos/config-management) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Cloud Architecture Center"}