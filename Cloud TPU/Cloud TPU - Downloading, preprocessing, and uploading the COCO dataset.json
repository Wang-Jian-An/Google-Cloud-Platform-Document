{"title": "Cloud TPU - Downloading, preprocessing, and uploading the COCO dataset", "url": "https://cloud.google.com/tpu/docs/coco-setup", "abstract": "# Cloud TPU - Downloading, preprocessing, and uploading the COCO dataset\n# Downloading, preprocessing, and uploading the COCO dataset\nCOCO is a large-scale object detection, segmentation, and captioning dataset. Machine learning models that use the COCO dataset include:\n- Mask-RCNN\n- Retinanet\n- ShapeMask\nBefore you can train a model on a Cloud TPU, you must prepare the training data.\nThis topic describes how to prepare the [COCO](http://cocodataset.org) dataset for models that run on Cloud TPU. The COCO dataset can only be prepared after you have created a Compute Engine VM. The script used to prepare the data, `download_and_preprocess_coco.sh` , is installed on the VM and must be run on the VM.\nAfter preparing the data by running the `download_and_preprocess_coco.sh` script, you can bring up the Cloud TPU and run the training.\nTo fully download/preprocess and upload the COCO dataset to a Google Cloud storage bucket takes approximately 2 hours.\n- In your [Cloud Shell](https://console.cloud.google.com/) , configure `gcloud` with your project ID.```\nexport PROJECT_ID=project-idgcloud config set project ${PROJECT_ID}\n```\n- In your [Cloud Shell](https://console.cloud.google.com/) , create a Cloud Storage bucket using the following command: **Note:** In the following command, replace with the name you want to assign to your bucket.```\ngsutil mb -p ${PROJECT_ID} -c standard -l europe-west4 gs://bucket-name\n```\n- Launch a Compute Engine VM instance.This VM instance will only be used to download and preprocess the COCO dataset. Fill in the with a name of your choosing.```\n$ gcloud compute tpus execution-groups create \\\u00a0--vm-only \\\u00a0--name=instance-name \\\u00a0--zone=europe-west4-a \\\u00a0--disk-size=300 \\\u00a0--machine-type=n1-standard-16 \\\u00a0--tf-version=2.12.0\n```\n- If you are not automatically logged in to the Compute Engine instance, log in by running the following `ssh` command. When you are logged into the VM, your shell prompt changes from `username@projectname` to `username@vm-name` :```\n\u00a0 $ gcloud compute ssh instance-name --zone=europe-west4-a\u00a0 \n```\n- Set up two variables, one for the storage bucket you created earlier and one for the directory that holds the training data (DATA_DIR) on the storage bucket.```\n(vm)$ export STORAGE_BUCKET=gs://bucket-name\n``````\n(vm)$ export DATA_DIR=${STORAGE_BUCKET}/coco\n```\n- Install the packages needed to pre-process the data.```\n(vm)$ sudo apt-get install -y python3-tk && \\\u00a0 pip3 install --user Cython matplotlib opencv-python-headless pyyaml Pillow && \\\u00a0 pip3 install --user \"git+https://github.com/cocodataset/cocoapi#egg=pycocotools&subdirectory=PythonAPI\"\n```\n- Run the `download_and_preprocess_coco.sh` script to convert the COCO dataset into a set of TFRecords ( `*.tfrecord` ) that the training application expects.```\n(vm)$ git clone https://github.com/tensorflow/tpu.git(vm)$ sudo bash tpu/tools/datasets/download_and_preprocess_coco.sh ./data/dir/coco\n```This installs the required libraries and then runs the preprocessing script. It outputs a number of `*.tfrecord` files in your local data directory. The COCO download and conversion script takes approximately 1 hour to complete.\n- Copy the data to your Cloud Storage bucketAfter you convert the data into TFRecords, copy them from local storage to your Cloud Storage bucket using the `gsutil` command. You must also copy the annotation files. These files help validate the model's performance.```\n(vm)$ gsutil -m cp ./data/dir/coco/*.tfrecord ${DATA_DIR}(vm)$ gsutil cp ./data/dir/coco/raw-data/annotations/*.json ${DATA_DIR}\n```\n- Clean up the VM resourcesOnce the COCO dataset has been converted to TFRecords and copied to the DATA_DIR on your Cloud Storage bucket, you can delete the Compute Engine instance.Disconnect from the Compute Engine instance:```\n(vm)$ exit\n```Your prompt should now be `username@projectname` , showing you are in the Cloud Shell.\n- Delete your Compute Engine instance.```\n\u00a0 $ gcloud compute instances delete instance-name\u00a0 \u00a0 --zone=europe-west4-a\u00a0 \n``", "content": "`", "guide": "Cloud TPU"}