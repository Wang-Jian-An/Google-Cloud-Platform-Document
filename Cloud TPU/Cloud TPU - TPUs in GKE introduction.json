{"title": "Cloud TPU - TPUs in GKE introduction", "url": "https://cloud.google.com/tpu/docs/tpus-in-gke", "abstract": "# Cloud TPU - TPUs in GKE introduction\n# TPUs in GKE introduction\n**Important:** If you are using the [TPU Node architecture](/tpu/docs/system-architecture-tpu-vm) , see [Run Cloud TPU applications on GKE](/tpu/docs/kubernetes-engine-setup) . This topic discusses using the TPU VM architecture with GKE.\nGoogle Kubernetes Engine (GKE) customers can now create Kubernetes node pools containing TPU v4 and v5e Pods. A is a group of TPU devices connected by high-speed interconnects. For workloads that don't require a full TPU Pod, you can use a subset of a full TPU Pod called a . Like full TPU Pods, each TPU device in a slice has its own TPU VM. We refer to a TPU VM and its connected device as a or . For more information about TPU Pods, see [System Architecture](/tpu/docs/system-architecture-tpu-vm) .\nSince the term used in the context of GKE typically means a [Kubernetes Pod](https://kubernetes.io/docs/concepts/workloads/pods/) , to avoid any confusion, we will always refer to a collection of one or more TPU devices as a .\nWhen you work with GKE you first have to create a [GKE cluster](/kubernetes-engine/docs/how-to/creating-a-zonal-cluster) .\nYou then [add node pools](/kubernetes-engine/docs/how-to/node-pools) to your cluster. GKE node pools are collections of VMs that share the same attributes. For TPU workloads, node pools consist of TPU VMs.\n", "content": "## Node pool types\nGKE supports two types of TPU node pools:\n- [Multi-host TPU slice](#multi-host) \n- [Single-host TPU slice](#single-host) \n### Multi-host TPU slice node pool\nA is a node pool that contains two or more TPU VMs. Each VM has a TPU device connected to it. The TPUs in a multi-host slice are connected over a high speed interconnect (ICI). A multi-host TPU slice node pool is immutable. Once a multi-host slice node pool is created, you cannot add nodes to it. For example, you cannot create a `v4-32` node pool and then later add an additional Kubernetes node (TPU VM) to the node pool. To add an additional TPU slice to a GKE cluster, you must create a new node pool.\nThe hosts in a multi-host TPU slice node pool are treated as a single atomic unit. If GKE is unable to deploy one node in the slice, all nodes in the slice will fail to be deployed.\nIf a node within a multi-host TPU slice needs to be repaired, GKE will shutdown all TPU VMs (nodes) in the slice, forcing all GKE Pods in the workload to be evicted. Once all TPU VMs in the slice are up and running, the GKE Pods can be scheduled on the TPU VMs in the new slice.\nThe following diagram shows an example of a TPU v5litepod-16 (v5e) multi-host slice. This slice has four TPU VMs. Each TPU VM has four TPU v5e chips connected with high-speed interconnects (ICI), and each TPU v5e chip has one TensorCore.\nThe following diagram shows a GKE cluster containing one TPU `v5litepod-16` (v5e) slice (topology: 4x4) and one TPU `v5litepod-8` (v5e) slice (topology: 2x4):\nFor an example of running a workload on a multi-host TPU slice, see [Run workload on a multi-host TPU slice](/kubernetes-engine/docs/how-to/tpus#tpu_chips_node_pool) .\n### Single-host TPU slice node pools\nA node pool is a node pool that contains one or more independent TPU VMs. Each of these VMs has a TPU device connected to it. While the VMs within a single-host slice node pool can communicate over Data Center Network (DCN), the TPUs attached to the VMs are not interconnected. The following diagram shows an example of a single-host TPU slice with seven `v4-8` machines:\nFor an example of running a workload on a single-host TPU slice, see [Run your workloads on TPU nodes](/kubernetes-engine/docs/how-to/tpus#tpu_chips_vm) .\n## TPU machine types for GKE node pools\nBefore creating node pools, you need to choose the TPU version and size of the TPU slice your workload requires. TPU v4 is supported in GKE version `1.26.1-gke.1500` and later, v5e in GKE version `1.27.2-gke.2100` and later, and v5p in GKE version `1.28.3-gke.1024000` and later.\nFor more information about the hardware specifications of the different TPU versions, see [System architecture](/tpu/docs/system-architecture-tpu-vm) . When creating a TPU node pool, select a TPU slice size (a TPU topology) based on the size of your model and how much memory it requires. The machine type you specify when creating your node pools depends on the version and size of your slices.\n### v5e\nThe following are the TPU v5e machine types and topologies that are supported for training and inference use cases:\n| Machine Type  | Topology | Number of TPU chips | Number of VMs | Recommended use case      |\n|:-----------------|:-----------|----------------------:|----------------:|:-------------------------------------------|\n| ct5lp-hightpu-1t | 1x1  |      1 |    1 | Training, single-host inference   |\n| ct5lp-hightpu-4t | 2x2  |      4 |    1 | Training, single-host inference   |\n| ct5lp-hightpu-8t | 2x4  |      8 |    1 | Training, single-host inference   |\n| ct5lp-hightpu-4t | 2x4  |      8 |    2 | Training, multi-host inference    |\n| ct5lp-hightpu-4t | 4x4  |     16 |    4 | Large-scale training, multi-host inference |\n| ct5lp-hightpu-4t | 4x8  |     32 |    8 | Large-scale training, multi-host inference |\n| ct5lp-hightpu-4t | 8x8  |     64 |    16 | Large-scale training, multi-host inference |\n| ct5lp-hightpu-4t | 8x16  |     128 |    32 | Large-scale training, multi-host inference |\n| ct5lp-hightpu-4t | 16x16  |     256 |    64 | Large-scale training, multi-host inference |\nCloud TPU v5e is a combined training and inference product. Training jobs are optimized for throughput and availability while inference jobs are optimized for latency. For more information see [v5e Training accelerator types](/tpu/docs/v5e-training#accelerator-types) and [v5e Inference accelerator types](/tpu/docs/v5e-inference#accelerator-types) .\nTPU v5e machines are available in `us-west4-a` , `us-east5-b` and `us-east1-c` . Your GKE clusters must run control plane version `1.27.2-gke.2100` or later. For more information about v5e, see [Cloud TPU v5e training](/tpu/docs/v5e-training) .\nMachine type comparison:\n| Machine Type    | ct5lp-hightpu-1t | ct5lp-hightpu-4t | ct5lp-hightpu-8t |\n|:-------------------------|:-------------------|:-------------------|:-------------------|\n| Number of v5e chips  | 1     | 4     | 8     |\n| Number of vCPUs   | 24     | 112    | 224    |\n| RAM (GB)     | 48     | 192    | 384    |\n| Number of NUMA nodes  | 1     | 1     | 2     |\n| Likelihood of preemption | High    | Medium    | Low    |\nTo make space for VMs with more chips, the GKE scheduler may preempt and reschedule VMs with fewer chips. So 8-chip VMs are likely to preempt 1 and 4-chip VMs.\n### v4 and v5p\nThe following are the TPU v4 and v5p machine types:\n| Machine type | Number of vCPUs | Memory (GB) | Number of NUMA nodes |\n|:----------------|------------------:|--------------:|-----------------------:|\n| ct4p-hightpu-4t |    240 |   407 |      2 |\n| ct5p-hightpu-4t |    208 |   448 |      2 |\nWhen creating a TPU v4 slice, use the `ct4p-hightpu-4t` machine type which has one host and contains 4 chips. See [v4 topologies](/tpu/docs/types-topologies#small_v4_topologies) and [TPU system architecture](/tpu/docs/system-architecture-tpu-vm) for more information. TPU v4 Pod machines types are available in `us-central2-b` . Your GKE clusters must run control plane version `1.26.1-gke.1500` or later.\nWhen creating a TPU v5p slice, use the `ct5p-hightpu-4t` machine type which has one host and contains 4 chips. TPU v5p Pod machine types are available in `us-west4-a` and `us-east5-b` . Your GKE clusters must run control plane version `1.28.3-gke.1024000` or later. For more information about v5p, see [v5p training introduction](/tpu/docs/v5p-training) .\n## Known issues and limitations\n- **Maximum number of Docker pods** : You can run a maximum of 256 Docker pods in a single TPU VM.\n- **SPECIFIC reservations only** : When using TPUs in GKE,`SPECIFIC`is the only supported value for the`--reservation-affinity`flag of the`gcloud container node-pools create`command.\n- **Only the Spot VMs variant of preemptible TPUs are supported** : [Spot VMs](/kubernetes-engine/docs/concepts/spot-vms) are similar to preemptible VMs and are subject to the same availability limitations, but don't have a 24h maximum duration.\n- **Autopilot clusters are not supported** : TPUs are not available in [GKE Autopilot](/kubernetes-engine/docs/concepts/autopilot-overview) clusters.\n- **No cost allocation support** : [GKE cost allocation](/kubernetes-engine/docs/how-to/cost-allocations) and [usage metering](/kubernetes-engine/docs/how-to/cluster-usage-metering) don't include any data about the usage or costs of TPUs.\n- **Autoscaler may calculate capacity** : Cluster autoscaler might calculate capacity incorrectly for new TPU nodes before those nodes are available. Cluster autoscaler might then perform additional scale up and as a result create more nodes than needed. Cluster autoscaler will scale down additional nodes, if they are not needed, after regular scale down operation.\n- **Autoscaler cancels scale up** : Cluster autoscaler cancels scaling up of TPU node pools that remain in waiting status for more than 15 minutes. Cluster Autoscaler will retry such scale up operations later. This behavior might reduce TPU obtainability for customers who don't use reservations.\n- **Taint may prevent scale down** : Non-TPU workloads that have a toleration for the TPU taint may prevent scale down of the node pool if they are recreated during draining of the TPU node pool.## Ensure sufficient TPU and GKE quotas\nYou may need to increase certain GKE-related quotas in the regions where your resources are created.\nThe following quotas have default values that will likely need to be increased:\n- **Persistent Disk SSD (GB) quota** : The boot disk of each Kubernetes node requires 100GB by default. Therefore, this quota should be set at least as high as (the maximum number of GKE nodes you anticipate creating) * 100GB.\n- **In-use IP addresses quota** : Each Kubernetes node consumes one IP address. Therefore, this quota should be set at least as high as the maximum number of GKE nodes you anticipate creating.\nTo request an increase in quota, see [Request higher quota](/docs/quota_detail/view_manage#requesting_higher_quota) . For more information about the types of TPU quotas, see [TPU Quota](/tpu/docs/quota) .\nIt may take a few days for your quota increase requests to be approved. If you experience any difficulty getting your quota increase requests approved within a few days, contact your Google Account team.\n## Migrate your TPU reservation\nIf you don't plan to use an existing TPU reservation with TPUs in GKE, skip this section and go to [Create a Google Kubernetes Engine cluster](#create-cluster) .\nIn order to use reserved TPUs with GKE, you must first migrate your TPU reservation to a new Compute Engine-based reservation system.\nThere are several important things to know about this migration:\n- TPU capacity migrated to the new Compute Engine-based reservation system cannot be used with the Cloud TPU [Queued Resource API](/tpu/docs/queued-resources) . If you intend to use TPU queued resources with your reservation, then you will need to migrate only a portion of your TPU reservation to the new Compute Engine-based reservation system.\n- No workloads can be actively running on the TPUs when they are migrated to the new Compute Engine-based reservation system.\n- Select a time to perform the migration, and work with your Google Cloud account team to schedule the migration. The migration time window needs to be during business hours (Monday - Friday, 9am-5pm Pacific Time).## Create a Google Kubernetes Engine cluster\nSee [Create a cluster](/kubernetes-engine/docs/how-to/tpus#create-cluster) in the Google Kubernetes Engine documentation.\n## Create a TPU node pool\nSee [Create a node pool](/kubernetes-engine/docs/how-to/tpus#create-node-pool) in the Google Kubernetes Engine documentation.\n## Running without privileged mode\nIf you want to reduce the permission scope on your container see [TPU privilege mode](/kubernetes-engine/docs/how-to/tpus#privileged-mode) .\n## Run workloads on TPU nodes\nSee [Run your workloads on TPU nodes](/kubernetes-engine/docs/how-to/tpus#run) in the Google Kubernetes Engine documentation.\n## Node selectors\nIn order for Kubernetes to schedule your workload on TPU nodes, you must specify two selectors for each TPU node in your Google Kubernetes Engine manifest:\n- Set`cloud.google.com/gke-accelerator-type`to`tpu-v5-lite-podslice`or`tpu-v4-podslice`.\n- Set`cloud.google.com/gke-tpu-topology`to the TPU topology of the TPU node.\n**Important:** It is mandatory for your GKE Pods to have these two labels specified under the `nodeSelector` or `nodeAffinity` node in your workload manifest.\nThe [Training workloads](#training-workloads) and [Inference workloads](#inference-workloads) sections contain example manifests that illustrate using these node selectors.\n## Workload scheduling considerations\nTPUs have unique characteristics that require special workload scheduling and management in Kubernetes. For more information, see [Workload scheduling considerations](/kubernetes-engine/docs/how-to/tpus#workload-scheduling) in the GKE documentation.\n## TPU node repair\nIf a TPU node in a multi-host TPU slice node pool is unhealthy, the entire node pool is recreated. For more information, see [Node auto repair](/kubernetes-engine/docs/how-to/tpus#node_auto_repair) in the GKE documentation.\n## Multislice - going beyond a single slice\nYou can aggregate smaller slices together in a multislice to handle larger training workloads. For more information, see [Cloud TPU Multislice](/tpu/docs/multislice-introduction) .\n## Training workload tutorials\nThese tutorials focus on training workloads on a multi-host TPU slice (for example, 4 v5e machines). They cover the following models:\n- Hugging Face FLAX Models: Train Diffusion on Pok\u00e9mon\n- PyTorch/XLA: GPT2 on WikiText\n### Download tutorial resources\nDownload the tutorial Python scripts and YAML specs for each pre-trained model with the following command:\n```\ngit clone https://github.com/GoogleCloudPlatform/ai-on-gke.git\n```\n### Create & connect to cluster\nCreate a regional GKE standard cluster, so the Kubernetes control plane is replicated in three zones, providing higher availability. Create your cluster in `us-west4` , `us-east1` or `us-central2` depending upon which TPU version you are using. For more information about TPUs and zones, see [Cloud TPU regions and zones](/tpu/docs/regions-zones) .\nThe following command creates a new GKE regional cluster subscribed to the rapid release channel with a node pool that initially contains one node per zone. The command also enables Workload Identity and Cloud Storage FUSE CSI driver features on your cluster because the example inference workloads in this guide use Cloud Storage buckets to store pre-trained models.\n```\ngcloud container clusters create cluster-name \\\u00a0 --region your-region \\\u00a0 --release-channel rapid \\\u00a0 --num-nodes=1 \\\u00a0 --workload-pool=project-id.svc.id.goog \\\u00a0 --addons GcsFuseCsiDriver\n```\nTo enable Workload Identity and Cloud Storage FUSE CSI driver features for existing clusters, run the following command:\n```\ngcloud container clusters update cluster-name \\\u00a0 --region your-region \\\u00a0 --update-addons GcsFuseCsiDriver=ENABLED \\\u00a0 --workload-pool=project-id.svc.id.goog\n```\nThe example workloads are configured with the following assumptions:\n- the node pool is using`tpu-topology=4x4`with four nodes\n- the node pool is using`machine-type``ct5lp-hightpu-4t`\nRun the following command to connect to your newly created cluster:\n```\ngcloud container clusters get-credentials cluster-name \\--location=cluster-region\n```\n### Hugging Face FLAX Models: Train Diffusion on Pok\u00e9mon\nThis example trains the Stable Diffusion model from HuggingFace using the [Pok\u00e9mon](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions) dataset.\nThe Stable Diffusion model is a latent text-to-image model that generates photo-realistic images from any text input. For more information about Stable Diffusion, see:\n- [Stable Diffusion overview](https://huggingface.co/CompVis/stable-diffusion-v1-4) \n- [Stable Diffusion code source](https://huggingface.co/CompVis/stable-diffusion-v1-4) The Dockerfile is located under the folder `ai-on-gke/gke-tpu-examples/training/diffusion/` . Run the following commands to build and push the Docker image.\n```\ncd ai-on-gke/gke-tpu-examples/training/diffusion/docker build -t gcr.io/project-id/diffusion:latest .docker push gcr.io/project-id/diffusion:latest\n```\nCreate a file with the following content and name it `tpu_job_diffusion.yaml` . Fill in the image field with the image that you just created.\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: headless-svcspec:\u00a0 clusterIP: None\u00a0 selector:\u00a0 \u00a0 job-name: tpu-job-diffusion---apiVersion: batch/v1kind: Jobmetadata:\u00a0 name: tpu-job-diffusionspec:\u00a0 backoffLimit: 0\u00a0 # Completions and parallelism should be the number of chips divided by 4.\u00a0 # (e.g. 4 for a v5litepod-16)\u00a0 completions: 4\u00a0 parallelism: 4\u00a0 completionMode: Indexed\u00a0 template:\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 subdomain: headless-svc\u00a0 \u00a0 \u00a0 restartPolicy: Never\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-tpu-accelerator: tpu-v5-lite-podslice\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-tpu-topology: 4x4\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: tpu-job-diffusion\u00a0 \u00a0 \u00a0 \u00a0 image: gcr.io/<var>project-name</var>/diffusion:latest\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8471 # Default port using which TPU VMs communicate\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8431 # Port to export TPU usage metrics, if supported\u00a0 \u00a0 \u00a0 \u00a0 securityContext:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 privileged: true\u00a0 \u00a0 \u00a0 \u00a0 command:\u00a0 \u00a0 \u00a0 \u00a0 - bash\u00a0 \u00a0 \u00a0 \u00a0 - -c\u00a0 \u00a0 \u00a0 \u00a0 - |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cd examples/text_to_image\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 python3 train_text_to_image_flax.py --pretrained_model_name_or_path=duongna/stable-diffusion-v1-4-flax --dataset_name=lambdalabs/pokemon-blip-captions --resolution=128 --center_crop --random_flip --train_batch_size=4 --mixed_precision=fp16 --max_train_steps=1500 --learning_rate=1e-05 --max_grad_norm=1 --output_dir=sd-pokemon-model\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 google.com/tpu: 4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 google.com/tpu: 4\n```\nThen deploy it using:\n```\nkubectl apply -f tpu_job_diffusion.yaml\n```\nAfter your Job finishes running you can delete it using:\n```\nkubectl delete -f tpu_job_diffusion.yaml\n```\n### PyTorch/XLA: GPT2 on WikiText\nThis tutorial shows how to run GPT2 on v5e TPUs using [HuggingFace](https://github.com/huggingface/transformers.git) on PyTorch/XLA using the [wikitext dataset](https://huggingface.co/datasets/wikitext) .\nThe Dockerfile is located under the folder `ai-on-gke/gke-tpu-examples/training/gpt/` . Run the following commands to build and push the Docker image.\n```\ncd ai-on-gke/gke-tpu-examples/training/gpt/docker build -t gcr.io/project-id/gpt:latest .docker push gcr.io/project-id/gpt:latest\n```\nCopy the following YAML and save it in a file called `tpu_job_gpt.yaml` . Fill in the image field with the image that you just created.\n```\nkind: Servicemetadata:\u00a0 name: headless-svcspec:\u00a0 clusterIP: None\u00a0 selector:\u00a0 \u00a0 job-name: tpu-job-gpt---apiVersion: batch/v1kind: Jobmetadata:\u00a0 name: tpu-job-gptspec:\u00a0 backoffLimit: 0\u00a0 # Completions and parallelism should be the number of chips divided by 4.\u00a0 # (for example, 4 for a v5litepod-16)\u00a0 completions: 4\u00a0 parallelism: 4\u00a0 completionMode: Indexed\u00a0 template:\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 subdomain: headless-svc\u00a0 \u00a0 \u00a0 restartPolicy: Never\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-tpu-accelerator: tpu-v5-lite-podslice\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-tpu-topology: 4x4\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: tpu-job-gpt\u00a0 \u00a0 \u00a0 \u00a0 image: gcr.io/<var>project-name</var>/gpt:latest\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8479\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8478\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8477\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8476\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8431 # Port to export TPU usage metrics, if supported.\u00a0 \u00a0 \u00a0 \u00a0 securityContext:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 privileged: true\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: PJRT_DEVICE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: 'TPU_C_API'\u00a0 \u00a0 \u00a0 \u00a0 - name: XLA_USE_BF16\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: '1'\u00a0 \u00a0 \u00a0 \u00a0 command:\u00a0 \u00a0 \u00a0 \u00a0 - bash\u00a0 \u00a0 \u00a0 \u00a0 - -c\u00a0 \u00a0 \u00a0 \u00a0 - |\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 numactl --cpunodebind=0 python3 -u examples/pytorch/xla_spawn.py \u00a0 --num_cores 4 examples/pytorch/language-modeling/run_clm.py \u00a0 \u00a0--num_train_epochs 3 --dataset_name wikitext \u00a0 \u00a0 --dataset_config_name wikitext-2-raw-v1 --per_device_train_batch_size 16 \u00a0 \u00a0--per_device_eval_batch_size 16 --do_train --do_eval \u00a0--output_dir /tmp/test-clm \u00a0 \u00a0 --overwrite_output_dir --config_name my_config_2.json --cache_dir /tmp --tokenizer_name gpt2 \u00a0--block_size 1024 --optim adafactor --adafactor true --save_strategy no --logging_strategy no --fsdp \"full_shard\" --fsdp_config fsdp_config.json\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 google.com/tpu: 4\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 google.com/tpu: 4\n```\nDeploy the workflow using:\n```\nkubectl apply -f tpu_job_gpt.yaml\n```\nAfter your job finishes running you can delete it using:\n```\nkubectl delete -f tpu_job_gpt.yaml\n```\n## Tutorial: Single-Host inference workloads\nThis tutorial shows how to run a single-host inference workload on GKE v5e TPUs for pre-trained models with JAX, TensorFlow, and PyTorch. At a high level, there are four separate steps to perform on the GKE cluster:\n- Create a Cloud Storage bucket and set up access to the bucket. You use a Cloud Storage bucket is used to store the pre-trained model.\n- Download and convert a pre-trained model into a TPU-compatible model. Apply a GKE Pod that downloads the pre-trained model, uses the Cloud TPU Converter and stores the converted models into a Cloud Storage bucket using the Cloud Storage FUSE CSI driver. The Cloud TPU Converter doesn't require specialized hardware. This tutorial shows you how to download the model and run the Cloud TPU Converter in the CPU node pool.\n- Launch the server for the converted model. Apply a [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) that serves the model using a server framework backed by the volume stored in the ReadOnlyMany (ROX) Persistent Volume. The deployment replicas must be run on a v5e Pod TPU node with one Kubernetes Pod per node.\n- Deploy a load balancer to test the model server. The server is exposed to external requests using the [LoadBalancer Service](https://kubernetes.io/docs/concepts/services-networking/service/) . A Python script has been provided with an example request to test out the model server.\nThe following diagram shows how requests are routed by the Load Balancer.\n**Note:** These models are reference examples only and are not performance-optimized. They are not recommended for use with benchmarking or production services.\n### Server deployment examples\nThese example workloads are configured with the following assumptions:\n- The cluster is running with a TPU v5 node pool with 3 nodes\n- The node pool is using machine type`ct5lp-hightpu-1t`where:- topology is 1x1\n- number of TPU chips is 1The following GKE manifest defines a single host server Deployment.\n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: bert-deploymentspec:\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: tf-bert-server\u00a0 replicas: 3 # number of nodes in node pool\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 annotations:\u00a0 \u00a0 \u00a0 \u00a0 gke-gcsfuse/volumes: \"true\"\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: tf-bert-server\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-tpu-topology: 1x1 \u00a0# target topology\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-tpu-accelerator: tpu-v5-lite-podslice \u00a0# target version\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: serve-bert\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/cloud-tpu-images/inference/tf-serving-tpu:2.13.0\u00a0 \u00a0 \u00a0 \u00a0 securityContext:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 privileged: true\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: MODEL_NAME\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"bert\"\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - mountPath: \"/models/\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: bert-external-storage\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8500\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8501\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8431 # Port to export TPU usage metrics, if supported.\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 google.com/tpu: 1 # TPU chip request\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 google.com/tpu: 1 # TPU chip request\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 - name: bert-external-storage\u00a0 \u00a0 \u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 claimName: external-storage-pvc\n```\nIf you are using a different number of nodes in your TPU node pool, change the `replicas` field to the number of nodes.\nIf you are using a different machine type:\n- Set`cloud.google.com/gke-tpu-topology`to the topology for the [machine type](#tpu-machine-types) you are using.\n- Set both`google.com/tpu`fields under`resources`to match the number of chips for the corresponding [machine type](#tpu-machine-types) .\n### Setup\nDownload the tutorial Python scripts and YAML manifests using the following command:\n```\ngit clone https://github.com/GoogleCloudPlatform/ai-on-gke.git\n```\nGo to the `single-host-inference` directory:\n```\ncd ai-on-gke/gke-tpu-examples/single-host-inference/\n```\nThe Python scripts you use in this tutorial require Python version 3.9 or greater. Remember to install the `requirements.txt` for each tutorial before running the Python test scripts.\nIf you don't have the proper Python setup in your local environment, you can use [Cloud Shell](https://console.cloud.google.com/?cloudshell=true) to download and run the Python scripts in this tutorial.- Create a cluster using the `e2-standard-4` machine type.```\ngcloud container clusters create cluster-name \\--region your-region \\--release-channel rapid \\--num-nodes=1 \\--machine-type=e2-standard-4 \\--workload-pool=project-id.svc.id.goog \\--addons GcsFuseCsiDriver\n```\n- [Create the single-host TPU node pool](/kubernetes-engine/docs/how-to/tpus#create-node-pool) .\nThe example workloads assume the following:\n- Your cluster is running with a TPU v5e node pool with 3 nodes.\n- TPU node pool is using machine-type`ct5lp-hightpu-1t`.\nIf you are using a different cluster configuration than previously described, you will need to edit [server deployment manifest](#server-deployment) .\nFor the JAX Stable Diffusion demo, you will need a CPU node pool with a machine type that has 16 Gi+ available memory (for example `e2-standard-4` ). This is configured in the `gcloud container clusters create` command or by adding an additional node pool to the existing cluster with the following command:\n```\ngcloud beta container node-pools create your-pool-name \\\u00a0 --zone=your-cluster-zone \\\u00a0 --cluster=your-cluster-name \\\u00a0 --machine-type=e2-standard-4 \\\u00a0 --num-nodes=1\n```\nReplace the following:\n- `your-pool-name`: The name of the node pool to create.\n- `your-cluster-zone`: The zone in which your cluster was created.\n- `your-cluster-name`: The name of the cluster in which to add the node pool.\n- `your-machine-type`: The [machine type](/compute/docs/machine-resource) of the nodes to create in your node pool.There are several ways you can store your model for serving. In this tutorial, we will use the following approach:\n- For converting the pre-trained model to work on TPUs, we will use a Virtual Private Cloud backed by Persistent Disk with`ReadWriteMany`(RWX) access.\n- For serving the model on multiple single-host TPUs, we will use the same VPC backed by the Cloud Storage bucket.\nRun the following command to create a Cloud Storage bucket.\n```\ngcloud storage buckets create gs://your-bucket-name \\\u00a0 --project=your-bucket-project-id \\\u00a0 --location=your-bucket-location\n```\nReplace the following:\n- `your-bucket-name`: The name of the Cloud Storage bucket.\n- `your-bucket-project-id`: The project ID in which you created the Cloud Storage bucket.\n- `your-bucket-location`: The [location](/storage/docs/locations) of your Cloud Storage bucket. To improve performance, specify the location where your GKE cluster is running.\nUse the following steps to give your GKE cluster access to the bucket. To simplify the setup, the following examples use the default namespace and the default Kubernetes service account. For details, see [Configure access to Cloud Storage buckets using GKE Workload Identity](/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver#authentication) .\n- Create an IAM service account for your application or use an existing IAM service account instead. You can use any IAM service account in your Cloud Storage bucket's project. **Note:** If you're using an existing IAM service account, skip this step.```\ngcloud iam service-accounts create your-iam-service-acct \\--project=your-bucket-project-id\n```Replace the following:- `your-iam-service-acct`: the name of the new IAM service account.\n- `your-bucket-project-id`: the ID of the project in which you created your IAM service account. The IAM service account must be in the same project as your Cloud Storage bucket.\n- Ensure that your IAM service account has the storage roles you need.```\ngcloud storage buckets add-iam-policy-binding gs://your-bucket-name \\--member \"serviceAccount:your-iam-service-acct@your-bucket-project-id.iam.gserviceaccount.com\" \\--role \"roles/storage.objectAdmin\"\n```Replace the following:- `your-bucket-name`: The name of your Cloud Storage bucket.\n- `your-iam-service-acct`: the name of the new IAM service account.\n- `your-bucket-project-id`: the ID of the project in which you created your IAM service account.\n- Allow the Kubernetes service account to impersonate the IAM service account by adding an IAM policy binding between the two service accounts. This binding allows the Kubernetes service account to act as the IAM service account.```\ngcloud iam service-accounts add-iam-policy-binding your-iam-service-acct@your-bucket-project-id.iam.gserviceaccount.com \\\u00a0 --role roles/iam.workloadIdentityUser \\\u00a0 --member \"serviceAccount:your-project-id.svc.id.goog[default/default]\"\n```Replace the following:- `your-iam-service-acct`: the name of the new IAM service account.\n- `your-bucket-project-id`: the ID of the project in which you created your IAM service account.\n- `your-project-id`: the ID of the project in which you created your GKE cluster. Your Cloud Storage buckets and GKE cluster can be in the same or different projects.\n- Annotate the Kubernetes service account with the email address of the IAM service account.```\nkubectl annotate serviceaccount default \\\u00a0 --namespace default \\\u00a0 iam.gke.io/gcp-service-account=your-iam-service-acct@your-bucket-project-id.iam.gserviceaccount.com\n```Replace the following:- `your-iam-service-acct`: the name of the new IAM service account.\n- `your-bucket-project-id`: the ID of the project in which you created your IAM service account.\n- Run the following command to populate your bucket name in the YAML files of this demo:```\nfind . -type f -name \"*.yaml\" | xargs sed -i \"s/BUCKET_NAME/your-bucket-name/g\"\n```Replace `your-bucket-name` with the name of your Cloud Storage bucket.\n- Create the Persistent Volume and Persistent Volume Claim with the following command:```\nkubectl apply -f pvc-pv.yaml\n```\n### JAX Model inference and serving\nInstall Python dependencies for running tutorial Python scripts that send requests to the JAX model service.\n```\npip install -r jax/requirements.txt\n```\nThis demo uses a pre trained [BERT model](https://huggingface.co/bert-base-uncased) from Hugging Face.\n**Note:** You must run the [setup](#single-host-inference-setup) instructions before running the E2E serving demo.\nThe Kubernetes Pod performs the following steps:\n- Downloads and uses the Python script`export_bert_model.py`from the example resources to download the pre-trained bert model to a temporary directory.\n- Uses the Cloud TPU Converter image to convert the pre-trained model from CPU to TPU and stores the model in the Cloud Storage bucket you created during [setup](#storage-setup) .\nThis Kubernetes Pod is configured to run on the default node pool CPU. Run the Pod with the following command:\n```\nkubectl apply -f jax/bert/install-bert.yaml\n```\nVerify the model was installed correctly with the following:\n```\nkubectl get pods install-bert\n```\nIt can take a couple of minutes for the `STATUS` to read `Completed` .\nThe example workloads in this tutorial assume the following:\n- The cluster is running with a TPU v5 node pool with three nodes\n- The node pool is using the`ct5lp-hightpu-1t`machine type that contains one TPU chip.\nIf you are using a different cluster configuration than previously described, you will need to edit [server deployment manifest](#server-deployment) .\n```\nkubectl apply -f jax/bert/serve-bert.yaml\n```\nVerify the server is running with the following:\n```\nkubectl get deployment bert-deployment\n```\nIt can take a minute for `AVAILABLE` to read `3` .\n```\nkubectl apply -f jax/bert/loadbalancer.yaml\n```\nVerify that the load balancer is ready for external traffic with the following:\n```\nkubectl get svc tf-bert-service\n```\nIt may take a few minutes for `EXTERNAL_IP` to have an IP listed.\nGet external IP from load balancer service:\n```\nEXTERNAL_IP=$(kubectl get services tf-bert-service --output jsonpath='{.status.loadBalancer.ingress[0].ip}')\n```\nRun a script for sending a request to the server:\n```\npython3 jax/bert/bert_request.py $EXTERNAL_IP\n```\nExpected output:\n```\nFor input \"The capital of France is [MASK].\", the result is \". the capital of france is paris..\"\nFor input \"Hello my name [MASK] Jhon, how can I [MASK] you?\", the result is \". hello my name is jhon, how can i help you?.\"\n```\nTo clean up resources, run `kubectl delete` in reverse order.\n```\nkubectl delete -f jax/bert/loadbalancer.yamlkubectl delete -f jax/bert/serve-bert.yamlkubectl delete -f jax/bert/install-bert.yaml\n```\nThis demo uses the pretrained [Stable Diffusion model](https://huggingface.co/CompVis/stable-diffusion-v1-4/tree/bf16) from Hugging Face.\n**Note:** You must run the [Setup](#single-host-inference-setup) instructions before running the E2E serving demo.\nExporting the stable diffusion models requires that the cluster has a CPU node pool with a machine type that has 16Gi+ available memory as described in [Setup cluster](#setup-cluster) .\nThe Kubernetes Pod executes the following steps:\n- Downloads and uses the Python script`export_stable_diffusion_model.py`from the example resources to download the pre-trained stable diffusion model to a temporary directory.\n- Uses the Cloud TPU Converter image to convert the pre-trained model from CPU to TPU and stores the model in the Cloud Storage bucket you created during [storage setup](#storage-setup) .\nThis Kubernetes Pod is configured to run on the default CPU node pool. Run the Pod with the following command:\n```\nkubectl apply -f jax/stable-diffusion/install-stable-diffusion.yaml\n```\nVerify the model was installed correctly with the following:\n```\nkubectl get pods install-stable-diffusion\n```\nIt can take a couple of minutes for the `STATUS` to read `Completed` .\nThe example workloads have been configured with the following assumptions:\n- the cluster is running with a TPU v5 node pool with three nodes\n- the node pool is using the`ct5lp-hightpu-1t`machine type where:- topology is 1x1\n- number of TPU chips is 1If you are using a different cluster configuration than previously described, you will need to edit [server deployment manifest](#server-deployment) .\nApply the deployment:\n```\nkubectl apply -f jax/stable-diffusion/serve-stable-diffusion.yaml\n```\nVerify the server is running as expected:\n```\nkubectl get deployment stable-diffusion-deployment\n```\nIt can take a minute for `AVAILABLE` to read `3` .\nApply load balancer service:\n```\nkubectl apply -f jax/stable-diffusion/loadbalancer.yaml\n```\nVerify that the load balancer is ready for external traffic with the following:\n```\nkubectl get svc tf-stable-diffusion-service\n```\nIt may take a few minutes for `EXTERNAL_IP` to have an IP listed.\nGet an external IP from the load balancer:\n```\nEXTERNAL_IP=$(kubectl get services tf-stable-diffusion-service --output jsonpath='{.status.loadBalancer.ingress[0].ip}')\n```\nRun script for sending a request to the server\n```\npython3 jax/stable-diffusion/stable_diffusion_request.py $EXTERNAL_IP\n```\nExpected output:\nThe prompt is `Painting of a squirrel skating in New York` and the output image will be saved as `stable_diffusion_images.jpg` in your current directory.\n**Note:** since the pre-trained model is relatively large, it will take about two minutes for the serving service to load the model. If you see errors when you send a request to the model server, retry after two minutes.\nTo clean up resources, run `kubectl delete` in reverse order.\n```\nkubectl delete -f jax/stable-diffusion/loadbalancer.yamlkubectl delete -f jax/stable-diffusion/serve-stable-diffusion.yamlkubectl delete -f jax/stable-diffusion/install-stable-diffusion.yaml\n```\n### Run TensorFlow ResNet-50 E2E serving demo:\nInstall Python dependencies for running tutorial Python scripts that send requests to the TF model service.\n```\npip install -r tf/resnet50/requirements.txt\n```\nApply model conversion:\n```\nkubectl apply -f tf/resnet50/model-conversion.yml\n```\nVerify the model was installed correctly with the following:\n```\nkubectl get pods resnet-model-conversion\n```\nIt can take a couple of minutes for the `STATUS` to read `Completed` .\nApply model serving deployment:\n```\nkubectl apply -f tf/resnet50/deployment.yml\n```\nVerify the server is running as expected with the following command:\n```\nkubectl get deployment resnet-deployment\n```\nIt can take a minute for `AVAILABLE` to read `3` .\nApply load balancer service:\n```\nkubectl apply -f tf/resnet50/loadbalancer.yml\n```\nVerify that the load balancer is ready for external traffic with the following:\n```\nkubectl get svc resnet-service\n```\nIt may take a few minutes for `EXTERNAL_IP` to have an IP listed.\nGet the external IP from the load balancer:\n```\nEXTERNAL_IP=$(kubectl get services resnet-service --output jsonpath='{.status.loadBalancer.ingress[0].ip}')\n```\nRun the test request (HTTP) script to send request to model server.\n```\npython3 tf/resnet50/request.py --host $EXTERNAL_IP\n```\nThe response should look like the following:\n```\nPredict result: ['ImageNet ID: n07753592, Label: banana, Confidence: 0.94921875','ImageNet ID: n03532672, Label: hook, Confidence: 0.0223388672', 'ImageNet ID: n07749582,Label: lemon, Confidence: 0.00512695312\n```\nTo clean up resources, run the following `kubectl delete` commands:\n```\nkubectl delete -f tf/resnet50/loadbalancer.ymlkubectl delete -f tf/resnet50/deployment.ymlkubectl delete -f tf/resnet50/model-conversion.yml\n```\nMake sure you delete the GKE [node pool](/kubernetes-engine/docs/how-to/node-pools#deleting_a_node_pool) and [cluster](/kubernetes-engine/docs/how-to/deleting-a-cluster) when you are done with them.\n### PyTorch model inference and serving\nInstall Python dependencies for running tutorial Python scripts that send requests to the PyTorch model service:\n```\npip install -r pt/densenet161/requirements.txt\n```- Generate model archive.- Apply model archive:\n```\nkubectl apply -f pt/densenet161/model-archive.yml\n```- Verify the model was installed correctly with the following:\n```\nkubectl get pods densenet161-model-archive\n```It can take a couple of minutes for the `STATUS` to read `Completed` .\n- Serve the Model with TorchServe:- Apply Model Serving Deployment:```\nkubectl apply -f pt/densenet161/deployment.yml\n```\n- Verify the server is running as expected with the following command:```\nkubectl get deployment densenet161-deployment\n```It can take a minute for `AVAILABLE` to read `3` .\n- Apply load balancer service:```\nkubectl apply -f pt/densenet161/loadbalancer.yml\n```Verify that the load balancer is ready for external traffic with the following command:```\nkubectl get svc densenet161-service\n```It may take a few minutes for `EXTERNAL_IP` to have an IP listed.\n- Send test request to model server:- Get external IP from load balancer:```\nEXTERNAL_IP=$(kubectl get services densenet161-service --output jsonpath='{.status.loadBalancer.ingress[0].ip}')\n```\n- Run the test request script to send request (HTTP) to model server.:```\npython3 pt/densenet161/request.py --host $EXTERNAL_IP\n```You should see a response like this:```\nRequest successful. Response: {'tabby': 0.47878125309944153, 'lynx': 0.20393909513950348, 'tiger_cat': 0.16572578251361847, 'tiger': 0.061157409101724625, 'Egyptian_cat': 0.04997897148132324\n```\n- Clean up resources, by running the following `kubectl delete` commands:```\nkubectl delete -f pt/densenet161/loadbalancer.ymlkubectl delete -f pt/densenet161/deployment.ymlkubectl delete -f pt/densenet161/model-archive.yml\n```Make sure you delete the GKE [node pool](/kubernetes-engine/docs/how-to/node-pools#deleting_a_node_pool) and [cluster](/kubernetes-engine/docs/how-to/deleting-a-cluster) when you are done with them.## Troubleshooting common issues\nYou can find GKE troubleshooting information at [Troubleshoot TPU inGKE](/kubernetes-engine/docs/troubleshooting/troubleshoot-tpus) .\n### TPU initialization failed\nIf you encounter the following error, make sure you are either running your TPU container in privileged mode or you have increased the `ulimit` inside your container. For more information, see [Running without privileged mode](#privileged-mode) .\n```\nTPU platform initialization failed: FAILED_PRECONDITION: Couldn't mmap: Resource\ntemporarily unavailable.; Unable to create Node RegisterInterface for node 0,\nconfig: device_path:  \"/dev/accel0\" mode: KERNEL debug_data_directory: \"\"\ndump_anomalies_only: true crash_in_debug_dump: false allow_core_dump: true;\ncould not create driver instance\n```\n### Scheduling deadlock\nSuppose you have two jobs (Job A and Job B) and both are to be scheduled on TPU slices with a given TPU topology (say, `v4-32` ). Also suppose that you have two `v4-32` TPU slices within the GKE cluster; we'll call those slice X and slice Y. Since your cluster has ample capacity to schedule both jobs, in theory both jobs should be quickly scheduled \u2013 one job on each of the two TPU `v4-32` slices.\nHowever, without careful planning, it is possible to get into a scheduling deadlock. Suppose the Kubernetes scheduler schedules one Pod from Job A on slice X and then schedules one Pod from Job B on slice X. In this case, given the Pod affinity rules for Job A, the scheduler will attempt to schedule all remaining Pods for Job A on slice X. Same for Job B. And thus neither Job A nor Job B will be able to be fully scheduled on a single slice. The result will be a scheduling deadlock.\nIn order to avoid the risk of a scheduling deadlock, you can use Pod anti-affinity with `cloud.google.com/gke-nodepool` as the `topologyKey` as shown in the following example:\n```\napiVersion: batch/v1kind: Jobmetadata:\u00a0name: pispec:\u00a0parallelism: 2\u00a0template:\u00a0 \u00a0metadata:\u00a0 \u00a0 \u00a0labels:\u00a0 \u00a0 \u00a0 \u00a0job: pi\u00a0 \u00a0spec:\u00a0 \u00a0 \u00a0affinity:\u00a0 \u00a0 \u00a0 \u00a0podAffinity:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0requiredDuringSchedulingIgnoredDuringExecution:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0- labelSelector:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0matchExpressions:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- key: job\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0operator: In\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- pi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0topologyKey: cloud.google.com/gke-nodepool\u00a0 \u00a0 \u00a0 \u00a0podAntiAffinity:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0requiredDuringSchedulingIgnoredDuringExecution:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0- labelSelector:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0matchExpressions:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- key: job\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0operator: NotIn\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- pi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0topologyKey: cloud.google.com/gke-nodepool\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0namespaceSelector:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0matchExpressions:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- key: kubernetes.io/metadata.name\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0operator: NotIn\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- kube-system\u00a0 \u00a0 \u00a0containers:\u00a0 \u00a0 \u00a0- name: pi\u00a0 \u00a0 \u00a0 \u00a0image: perl:5.34.0\u00a0 \u00a0 \u00a0 \u00a0command: [\"sleep\", \u00a0\"60\"]\u00a0 \u00a0 \u00a0restartPolicy: Never\u00a0backoffLimit: 4\n```\n## Creating TPU node pool resources with Terraform\nYou can also use [Terraform](https://registry.terraform.io/providers/hashicorp/google-beta/latest/docs/resources/container_node_pool) to manage your cluster and node pool resources.\n## Create a multi-host TPU slice node pool in an existing GKE Cluster\nIf you have an existing Cluster in which you want to create a multi-host TPU node pool, you can use the following Terraform snippet:\n```\nresource \"google_container_cluster\" \"cluster_multi_host\" {\u00a0 \u2026\u00a0 release_channel {\u00a0 \u00a0 channel = \"RAPID\"\u00a0 }\u00a0 workload_identity_config {\u00a0 \u00a0 workload_pool = \"my-gke-project.svc.id.goog\"\u00a0 }\u00a0 addons_config {\u00a0 \u00a0 gcs_fuse_csi_driver_config {\u00a0 \u00a0 \u00a0 enabled = true\u00a0 \u00a0 }\u00a0 }}resource \"google_container_node_pool\" \"multi_host_tpu\" {\u00a0 provider \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = google-beta\u00a0 project \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0= \"<var>your-project</var>\"\u00a0 name \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = \"<var>your-node-pool</var>\"\u00a0 location \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = \"<var>us-central2</var>\"\u00a0 node_locations \u00a0 \u00a0 = [\"<var>us-central2-b</var>\"]\u00a0 cluster \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0= google_container_cluster.cluster_multi_host.name\u00a0 initial_node_count = 2\u00a0 node_config {\u00a0 \u00a0 machine_type = \"ct4p-hightpu-4t\"\u00a0 \u00a0 reservation_affinity {\u00a0 \u00a0 \u00a0 consume_reservation_type = \"SPECIFIC_RESERVATION\"\u00a0 \u00a0 \u00a0 key = \"compute.googleapis.com/reservation-name\"\u00a0 \u00a0 \u00a0 values = [\"<var>your-reservation-name</var>\"]\u00a0 \u00a0 }\u00a0 \u00a0 workload_metadata_config {\u00a0 \u00a0 \u00a0 mode = \"GKE_METADATA\"\u00a0 \u00a0 }\u00a0 }\u00a0 placement_policy {\u00a0 \u00a0 type = \"COMPACT\"\u00a0 \u00a0 tpu_topology = \"2x2x2\"\u00a0 }}\n```\nReplace the following values:\n- `your-project`: Your Google Cloud project in which you are running your workload.\n- `your-node-pool`: The name of the node pool you are creating.\n- `us-central2`: The region in which you are running your workload.\n- `us-central2-b`: The zone in which you are running your workload.\n- `your-reservation-name`: The name of your reservation.## Create a single-host TPU slice node pool in an existing GKE Cluster\nUse the following Terraform snippet:\n```\nresource \"google_container_cluster\" \"cluster_single_host\" {\u00a0 \u2026\u00a0 cluster_autoscaling {\u00a0 \u00a0 autoscaling_profile = \"OPTIMIZE_UTILIZATION\"\u00a0 }\u00a0 release_channel {\u00a0 \u00a0 channel = \"RAPID\"\u00a0 }\u00a0 workload_identity_config {\u00a0 workload_pool = \"<var>your-project-id</var>.svc.id.goog\"\u00a0 }\u00a0 addons_config {\u00a0 \u00a0 gcs_fuse_csi_driver_config {\u00a0 \u00a0 \u00a0 enabled = true\u00a0 \u00a0 }\u00a0 }}resource \"google_container_node_pool\" \"single_host_tpu\" {\u00a0 provider \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = google-beta\u00a0 project \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0= \"<var>your-project</var>\"\u00a0 name \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = \"<var>your-node-pool</var>\"\u00a0 location \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = \"<var>us-central2</var>\"\u00a0 node_locations \u00a0 \u00a0 = [\"<var>us-central2-b</var>\"]\u00a0 cluster \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0= google_container_cluster.cluster_single_host.name\u00a0 initial_node_count = 0\u00a0 autoscaling {\u00a0 \u00a0 total_min_node_count = 2\u00a0 \u00a0 total_max_node_count = 22\u00a0 \u00a0 location_policy \u00a0 \u00a0 \u00a0= \"ANY\"\u00a0 }\u00a0 node_config {\u00a0 \u00a0 machine_type = \"ct4p-hightpu-4t\"\u00a0 \u00a0 workload_metadata_config {\u00a0 \u00a0 \u00a0 mode = \"GKE_METADATA\"\u00a0 \u00a0 }\u00a0 }}\n```\nReplace the following values:\n- `your-project`: Your Google Cloud project in which you are running your workload.\n- `your-node-pool`: The name of the node pool you are creating.\n- `us-central2`: The region in which you are running your workload.\n- `us-central2-b`: The zone in which you are running your workload.", "guide": "Cloud TPU"}