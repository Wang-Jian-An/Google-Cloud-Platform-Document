{"title": "Cloud TPU - Profile your model on Cloud TPU VMs", "url": "https://cloud.google.com/tpu/docs/profile-tpu-vm", "abstract": "# Cloud TPU - Profile your model on Cloud TPU VMs\n# Profile your model on Cloud TPU VMs\n**Important:** There are two TPU architectures, TPU VM and TPU Node. Profiling model performance differs between the two architectures. This document describes how to profile your model on a TPU VM. The two TPU architectures are described in [System Architecture](/tpu/docs/system-architecture-tpu-vm) .\nProfiling enables you to optimize your model's training performance on Cloud TPUs. You use [TensorBoard](https://www.tensorflow.org/tensorboard) and the [Cloud TPU TensorBoard plug-in](#install-plugin) to profile your model.\nFor more information about using TensorBoard with one of the supported frameworks, see the following documents:\n- [TensorFlow performance guide](/tpu/docs/tensorflow-performance-guide) \n- [PyTorch performance guide](https://cloud.google.com/tpu/docs/pytorch-xla-performance-profiling-tpu-vm) \n- [JAX performance guide](https://jax.readthedocs.io/en/latest/profiling.html) ", "content": "## Prerequisites to profiling a training script\nBefore you use the TPU profiling tools, you need to:\n- Start a model training session- [Set up a v4-8 TPU](/tpu/docs/v4-users-guide#train_resnet_on_a_tpu_pod_slice) to train a model. The profiling procedure described in this document uses a ResNet model, but you can use another model provided it trains on a v4 TPU.\n- In your TPU VM, add a line to start the profiler server to the training script.For the ResNET training, the training script is at: `/usr/share/tpu/tensorflow/resnet50_keras/resnet50.py` .Insert the highlighted lines into resnet50.py. At the top of the file, add the following import:```\nimport tensorflow.compat.v2 as tf2\n```Right before the scripts starts the training loop, add the highlighted line:```\nif name == 'main':\n tf.logging.set_verbosity(tf.logging.INFO)\n tf2.profiler.experimental.server.start(6000)\n app.run(main)\n```The TensorFlow profiler server starts on your TPU VM when you run the script.\n- Start the model training.Run your training script and wait until you see output indicating your model is actively training. The output depends on your code and model. Look for output like `Epoch 1/100` . Alternatively, you can navigate to the Cloud TPU page in the [Google Cloud console](https://console.cloud.google.com/compute/tpus) , select your TPU, and view the CPU utilization graph. While the CPU utilization graph does not show TPU utilization, it's a good indication that the TPU is training your model.\n## Start profiling the model training\nWhen the model is training, open a separate terminal window or Cloud Shell. Use the following steps to begin profiling the model training.\n- In the new window or shell, connect to your TPU VM with port forwarding.```\ngcloud compute tpus tpu-vm ssh your-vm --zone=us-central2-b --ssh-flag=\"-4 -L 9001:localhost:9001\"\n```Port forwarding allows your local browser to communicate with the TensorBoard server running on your TPU VM.\n- Install TensorFlow requirements {: id=\"install-tensorboard\"}.Your TPU VM has TensorBoard installed by default. You can also [install TensorFlow manually](https://www.tensorflow.org/install) . Either way, some additional dependencies may be required. Install these dependencies on your TPU VM by running:```\npip3 install -r /usr/share/tpu/models/official/requirements.txt\n```\n- Install the Cloud TPU TensorBoard Plugin {: id=\"install-plugin\"}.From the TPU VM, run the following commands:```\n\u00a0pip3 install --upgrade \"cloud-tpu-profiler>=2.3.0\"\u00a0pip3 install tensorflow\u00a0pip3 install tensorboard_plugin_profile\n```\n- Start the TensorBoard serverRun TensorBoard and create a log directory ( `logdir` ) on the TPU VM where TensorBoard can write profiling data. Specify the log directory using the `--logdir` flag. For example:```\nmkdir log-directoryTPU_LOAD_LIBRARY=0 tensorboard --logdir log-directory --port 9001\n```\nTensorBoard starts a web server and displays its URL:\n```\nServing TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_allTensorBoard 2.3.0 at http://localhost:9001 (Press CTRL+C to quit)\n```\nOpen a web browser and go to the URL displayed in the TensorBoard output. Select from the drop-down menu in the upper right of the TensorBoard page. The list of available profiling tools is shown in the pulldown menu on the left sidebar.\n## Capture a profile on TPU VMs\n- Select thebutton.\n- Select theradio button.\n- Typein the`Profile Service URL`field.\n- Select thebutton.\n## View profile data with TensorBoard\nAfter you capture a profile, TensorBoard displays the . The list of profiling tools you can use is displayed in the left pane.\n**Note:** If your workload is running in a multislice environment, see [Profiling a multislice environment](/tpu/docs/troubleshooting/troubleshoot-multislice) for more information about multislice specific profiling metrics.\n### Profile\nThe **Profile** tab is displayed after you have captured some model data. You may need to click the refresh button on the TensorBoard page. Once data is available, clicking the **Profile** tab presents a selection of tools to help with performance analysis. You can use any of the following tools to profile your model.\n- [Overview page](#overview_page) \n- [Input pipeline analyzer](#input_pipeline_analyzer) \n- [XLA Op profile](#op_profile) \n- [Trace viewer](#trace_viewer) (Chrome browser only)\n- [Memory viewer](#memory_viewer) The overview page ( **overview_page** ), available in the **Profile** page, provides a top level view of how your model performed during a capture run. The page shows you an aggregated overview for all your TPUs and an overall input pipeline analysis. There is an option for selecting individual TPUs in the **Host** drop-down.\nThe page displays data in the following panels:- **Performance summary** - FLOPS Utilization - The percentage utilization of the TPU matrix units\n- **Top ten TensorFlow operations on TPU** Displays the TensorFlow operations that consumed the most time:Each row displays the self-time of an operation (as the percentage of time taken by all operations), cumulative time, category, name, and the FLOPS rate achieved.\n- **Run environment** - The number of hosts used\n- The type of TPU used\n- The number of TPU cores\n### Input pipeline analyzer\nThe input pipeline analyzer provides insights into your performance results. The tool tells you immediately whether your program is input bound and can walk you through device and host-side analysis to debug whatever stage of the pipeline is creating bottlenecks.\nSee the guidance on [input pipeline performance](https://www.tensorflow.org/versions/master/performance/datasets_performance) for deeper insight into optimizing pipeline performance.\nWhen a TensorFlow program reads data from a file, the read process is divided into multiple data processing stages connected in series. The output of one stage is the input to the next one. This system of reading is called the **input pipeline** .\nA typical pipeline for reading records from files has the following stages:\n- File reading\n- File preprocessing (optional)\n- File transfer from the host machine to the device\nAn inefficient input pipeline can severely slow down your application. An application is considered **input bound** when it spends a significant portion of time in its input pipeline. Use the [Input pipeline analyzer](#input_pipeline_analyzer) to understand where the input pipeline is inefficient.\nTo open the input pipeline analyzer, select **Profile** , then select **input_pipeline_analyzer** from the **Tools** drop-down.\nThe dashboard shows device-side and host-side analysis details.- **Device step time** statistics\n- **% of device step time waiting for input data** This section shows the details of host-side analysis broken into several categories:\n- **Enqueuing data to be transferred to device** Time spent putting data into an infeed queue before transferring the data to the device.\n- **Data preprocessing** Time spent on preprocessing operations, such as image decompression.\n- **Reading data from files in advance** Time spent reading files, including caching, prefetching, and interleaving.\n- **Reading data from files on demand** Time spent on reading data from files without caching, prefetching, and interleaving.\n- **Other data reading or processing** Time spent on other input related operations not using`tf.data`.To see the statistics for individual input operations and their categories broken down by execution time, expand the `Show Input Op statistics` section.\nA source data table like the following appears:\nEach table entry contains the following information:\n- **Input Op** Shows the TensorFlow operation name of the input operation.\n- **Count** Shows the total number of instances of the operation executed during the profiling period.\n- **Total Time (in ms)** Shows the cumulative sum of time spent on each of the operation instances.\n- **Total Time %** Shows the total time spent on an operation as a fraction of the total time spent in input processing.\n- **Total Self-time (in ms)** Shows the accumulated time over all instances of the function. The self-time measures the time spent inside the function body, excluding the time spent in any functions it calls. For example, the`Iterator::PaddedBatch::Filter::ForeverRepeat::Map`is called by`Iterator::PaddedBatch::Filter`, therefore its total self-time is excluded from the total self-time of the latter.\n- **Total self-time %** Shows the total self-time as a fraction of the total time spent on input processing.\n- **Category** Shows the processing category of the input operation.\n### Op profile\nOp profile is a Cloud TPU tool that displays the performance statistics of [XLA](https://www.tensorflow.org/performance/xla/) operations executed during a profiling period. The operation profile shows:\n- How well your application uses the Cloud TPU as a percentage of time spent on operations by category and of TPU FLOPS utilization.\n- The most time-consuming operations. Those operations are potential targets for optimization.\n- Details of individual operations, including shape, padding and expressions that use the operation.\nYou can use op profile to find targets for optimization. For example, you can use operation profile to identify which XLA operations are taking the longest time to run and how many TPU FLOPS they consume.\nThe Op Profile tool contains performance statistics of XLA operations. You can view Op Profile data in TensorBoard by clicking on the **Profile** tab at the top of the screen and then selecting **op_profile** from the **Tools** drop-down. You will see a display like this:- **Overview section** Shows Cloud TPU utilization and provides suggestions for optimization.\n- **Control panel** Contains controls that let you set the number of operations displayed in the table, which operations are displayed, and how they are sorted.\n- [Op table](#op_table) Lists the top TensorFlow operation categories associated with the XLA ops. These operations are sorted by percentage of Cloud TPU usage.\n- [Op details cards](#op_details_cards) Displays details about the operations that appear when you point to an operation in the table. These details include the FLOPS utilization, the expression in which the operation is used, and the operation layout (fit).The operation table lists XLA operation categories in order from the highest to lowest percentage of Cloud TPU usage. The table shows the percentage of time taken, the operation category name, the associated TensorFlow op name, and the percentage of FLOPS utilization for the category. To display (or hide) the ten most time-consuming XLA operations for a category, click the triangle next to the category name in the table.- **Time** Shows the total percentage of time spent by all the operations in that category. You can click to expand the entry and see the breakdown of time spent by each individual operation.\n- **Top ten Ops** The toggle next to a category name displays/hides the top ten time-consuming operations within the category. If a fusion operation entry is displayed in the operations list, you can expand it to see the non-fusion, element wise operations it contains.\n- **TensorFlow Op** Shows the TensorFlow operation name associated with the XLA operation.\n- **FLOPS** Shows the FLOPS utilization, which is the measured number of FLOPS expressed as a percentage of the Cloud TPU peak FLOPS. The higher the FLOPS utilization percentage, the faster operations run. The table cell is color coded: green for high FLOPS utilization (good) and red for low FLOPS utilization (bad).When you select a table entry, a card appears displaying details about the XLA operation or the operation category. A typical card looks like this:- **Name** and **Category** Shows the highlighted XLA operation name and category.\n- **FLOPS utilization** Displays FLOPS utilization as a percentage of total FLOPS possible.\n- **Expression** Shows the [XLAexpression](https://www.tensorflow.org/performance/xla/operation_semantics) containing the operation.\n- **Memory Utilization** Displays the percentage of peak memory usage by your program.\n- **Layout** (Convolution operations only) Shows the [shape and layout](https://www.tensorflow.org/performance/xla/shapes) of a tensor, including a description of any padding performed by the XLA compiler.For convolution operations, low TPU FLOPS utilization may be due to one or both of the following reasons:\n- padding (matrix units are partially used)\n- convolution operation is memory bound\nThis section gives an interpretation of some performance metrics from a model with low FLOP utilization. In this example, **output fusion** and **convolution** dominated the execution time. There were many vector or scalar operations that had low FLOP utilization.\nOne optimization strategy for this type of profile is to transform the vector or scalar operations to convolution operations.\nIn the following example, **%convolution.399** shows lower FLOPS and memory utilization than **%convolution.340** in the previous example.\nIn this example, the batch size is being padded to 128 and feature size is being padded to 8. In this case, only 5% of the matrix units are being used effectively. Utilization is calculated by (((batch_time * num_of_features) / padding_size ) / num_of_cores). Compare the FLOPS in this example to the %convolution.340 in the previous example which uses no padding.\n## Trace viewer\nTrace viewer is a Cloud TPU performance analysis tool available on the **Profile** page. The tool uses the [Chrome trace event profiling viewer](https://github.com/catapult-project/catapult/tree/master/tracing) so it only works in the Chrome browser.\nTrace viewer displays a timeline that shows:\n- Durations for the operations that were executed by your TensorFlow model.\n- Which part of the system (TPU or host machine) executed an operation. Typically, the host machine executes infeed operations, which preprocess training data and transfers it to the TPU, whereas the TPU executes the actual model training.\nTrace viewer lets you identify performance problems in your model, then take steps to resolve them. For example, at a high level, you can identify whether infeed or model training is taking most of the time. Drilling down, you can identify which TensorFlow operations are taking the longest to execute.\nTrace viewer is limited to 1M events for each Cloud TPU. If you need to assess more events, use the [streaming trace viewer](#stream_tr_viewer) instead.\n### Trace viewer interface\nTo open trace viewer, go to TensorBoard, click the **Profile** tab at the top of the screen, and choose **trace_viewer** from the **Tools** drop-down. The viewer appears displaying your most recent run:\nThis screen contains the following main elements (marked with numbers in the preceding screen shot):\n- **Runs drop-down** Contains all runs for which you've captured trace information. The default view is your most recent run, but you can open the drop-down to select a different run.\n- **Tools drop-down** Selects different profiling tools.\n- **Host drop-down** Selects a host that contains a Cloud TPU set.\n- **Timeline pane** Shows operations that Cloud TPU and the host machine executed over time.\n- **Details pane** Shows additional information for operations selected in the Timeline pane.\nHere's a closer look at the timeline pane:\nThe Timeline pane contains the following elements:\n- **Top bar** Contains various auxiliary controls.\n- **Time axis** Shows time relative to the beginning of the trace.\n- **Section and track labels** Each section contains multiple tracks and has a triangle on the left that you can click to expand and collapse the section. There is one section for every processing element in the system.\n- **Tool selector** Contains various tools for interacting with the trace viewer.\n- **Events** Shows the time during which an operation was executed or the duration of meta-events, such as training steps.\n- **Vertical tab bar** This bar does not have a useful purpose for Cloud TPU. The bar is part of the general purpose trace viewer tool provided by Chrome that is used for a various performance analysis tasks.\n### Sections and tracks\nTrace viewer contains the following sections:\n- **One section for each TPU node** , labeled with the number of the TPU chip and the TPU node within the chip (for example, \"Chip 2: TPU Core 1\"). Each TPU node section contains the following tracks:- **Step** Shows the duration of the training steps that were running on the TPU.\n- **TensorFlow Ops** Shows TensorFlow operations executed on the TPU.\n- **XLA Ops** Shows [XLA](https://www.tensorflow.org/performance/xla/) operations that ran on the TPU. (Each operation is translated into one or several XLA operations. The XLA compiler translates the XLA operations into code that runs on the TPU.)\n- **One section for threads running on the host CPU,** labeled **\"Host Threads\"** . The section contains one track for each CPU thread. Note: You can ignore the information displayed alongside the section labels.\n### Timeline tool selector\nYou can interact with the timeline view using the timeline tool selector in TensorBoard. You can click a timeline tool or use the following [keyboard shortcuts](#keyboard_shortcuts) to activate and highlight a tool. To move the timeline tool selector, click in the dotted area at the top and then drag the selector to where you want it.\nUse the timeline tools as follows:\n| 0 | 1                                                                               |\n|----:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| nan | Selection tool click an event to select it or drag to select multiple events. Additional information about the selected event or events (name, start time, and duration) will be displayed in the details pane.                            |\n| nan | Pan tool Drag to pan the timeline view horizontally and vertically.                                                               |\n| nan | Zoom tool Drag up to zoom in or drag down to zoom out along the horizontal (time) axis. The horizontal position of the mouse cursor determines the center around which the zoom takes place. Note: If the zoom tool remains active after you release the mouse button, click the timeline view to deactivate the zoom tool. |\n| nan | Timing tool Drag horizontally to mark a time interval. The length of the interval appears on the time axis. To adjust the interval, drag its ends. To clear the interval, click anywhere inside the timeline view. If you select another tool, the interval remains marked.             |\n### Memory viewer\nMemory viewer lets you visualize the peak memory usage and memory usage trends for your program.\nThe memory viewer user interface looks like this:- **Host** **drop-down** Selects a TPU host and XLA High Level Optimizer (HLO) modules to visualize.\n- **Memory overview** Displays peak memory allocation and size without padding.\n- **Working space chart** Displays peak memory use and a plot of memory usage trends for your program. Point to a buffer in one of the buffer charts to display additional information in the buffer allocation card.\n- **Buffer charts** Two charts that display buffer allocation at peak memory usage. Point to a buffer in one of the buffer charts to display additional information in the buffer details card.\n- **Buffer allocation details card** Displays allocation details for a buffer.The memory overview (top) panel shows you the module name and the peak memory allocation set when the total buffer allocation size reaches the maximum. The unpadded peak allocation size is also shown for comparison.\nThis chart displays peak memory use and a plot of memory usage trends for your program. The vertical line indicates peak memory utilization for the program. This charts shows if your program can fit into the available global memory space.\nEach point in the graph represents a \"program point\" in the XLA HLO program. The line shows you how memory usage of your program changes over time.\nWhen you point to a buffer in abuffer charts, a horizontal line showing the lifetime of the buffer appears in the working space chart.\nThe thickness of the horizontal line indicates the relative magnitude of the buffer size relative to the peak memory allocation. The length of the line indicates the lifetime of the buffer.\nTwo charts show the breakdown of memory usage at the peak usage.- **By Program Order** Displays the buffers from left to right in the order in which they were active during program execution.\n- **By Size** Displays the buffers that were active during program execution in order of decreasing size.When you point to a buffer displayed in one of the buffer charts, a buffer allocation details card appears. A typical details card looks like this:- **Name** - Name of the XLA operation.\n- **Category** - The operation category.\n- **Size** - The size of the buffer allocation (including padding).\n- **Unpadded size** - The size of the buffer allocation without padding.\n- **Expansion** - The relative magnitude of padded buffer size versus the unpadded size.\n- **Extra memory** - Indicates how much extra memory is used for padding.\n- **Shape** - Describes the rank, size, and data type of the N-dimensional array.\n- **TensorFlow op name** - Shows the name of the TensorFlow operation associated with the buffer allocation.\n- **Allocation type** - Indicates buffer allocation category: Parameter, Output, Thread-local, and Temporary (for example, buffer allocation within a fusion).If you run a model and get an \"out of memory\" error, use the guidelines in this document to capture a profile. Wait until your script is training your model before starting the profiler. The profiling output can help you understand what caused the error.", "guide": "Cloud TPU"}