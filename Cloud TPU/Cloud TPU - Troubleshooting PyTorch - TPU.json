{"title": "Cloud TPU - Troubleshooting PyTorch - TPU", "url": "https://cloud.google.com/tpu/docs/troubleshooting/trouble-pytorch", "abstract": "# Cloud TPU - Troubleshooting PyTorch - TPU\n# Troubleshooting PyTorch - TPU\nThis guide provides troubleshooting information to help you identify and resolve problems you might encounter while training PyTorch models on Cloud TPU. For a more general guide to getting started with Cloud TPU, see the [PyTorch quickstart](/tpu/docs/run-calculation-pytorch) .\n**Note:** If you aren't able to resolve your issue using this guide, see [Getting Support](/tpu/docs/getting-support) for further assistance.\n", "content": "## Troubleshooting slow training performance\nIf your model trains slowly, [generate and review a metrics report.](https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#get-a-metrics-report)\nTo automatically analyze the metrics report and provide a summary, simply run your workload with PT_XLA_DEBUG=1.\nFor more information about issues that might cause your model to train slowly, see [Known performance caveats](https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#known-performance-caveats) .\n## Performance profiling\nTo profile your workload in depth to discover bottlenecks, you can use the following resources:\n- [PyTorch/XLA performance profiling](https://cloud.google.com/tpu/docs/pytorch-xla-performance-profiling-tpu-vm) \n- [PyTorch/XLA profiling Colab](https://colab.sandbox.google.com/github/pytorch/xla/blob/master/contrib/colab/pytorch-xla-profiling-colab.ipynb) \n- [Sample MNIST training script with profiling](https://github.com/pytorch/xla/blob/master/test/test_profile_mp_mnist.py) ## More debugging tools\nYou can specify [environment variables](https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#environment-variables) to control the behavior of the PyTorch/XLA software stack.\nIf the PyTorch process stops responding, file a GitHub issue and include [stack traces](https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#retrieving-stack-traces) .\nA [debug_run.py utility](https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#using-debug_runpy-to-collect-debug-information) is provided in scripts/debug_run.py which can be used to create a `tar.gz` archive with the information required to debug PyTorch/XLA executions.\n## Managing XLA tensors\n[XLA tensor Quirks](https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md#xla-tensor-quirks) describes what you should and should not do when working with XLA tensors and shared weights.", "guide": "Cloud TPU"}