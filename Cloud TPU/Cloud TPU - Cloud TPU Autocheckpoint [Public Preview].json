{"title": "Cloud TPU - Cloud TPU Autocheckpoint [Public Preview]", "url": "https://cloud.google.com/tpu/docs/autocheckpoint", "abstract": "# Cloud TPU - Cloud TPU Autocheckpoint [Public Preview]\n# Cloud TPU Autocheckpoint [Public Preview]\n", "content": "## Overview\nHistorically, when a TPU VM requires [maintenance](/tpu/docs/maintenance-events) , the procedure is initiated immediately, without leaving time for users to perform progress-preserving actions such as saving a checkpoint. This is shown in Figure 1(a).\n**Fig. 1.** Illustration of the Autocheckpoint feature: (a) Without Autocheckpoint, the training progress from the last checkpoint is lost when there is an upcoming maintenance event. (b) With Autocheckpoint, the training progress since the last checkpoint can be preserved when there is an upcoming maintenance event.\nYou can use Autocheckpoint (Figure 1(b)) to preserve training progress by configuring your code to save a non-scheduled checkpoint when a maintenance event occurs. When a maintenance event occurs, progress since the last checkpoint is automatically saved. The feature works on both single slices and Multislice.\nThe Autocheckpoint feature works with frameworks that can capture SIGTERM and subsequently save a checkpoint. The supported frameworks include [MaxText](https://github.com/google/maxtext) , [Pax](https://github.com/google/paxml) , and JAX with [Orbax](https://github.com/google/orbax) . Support for additional frameworks will be announced as they become available.\nOnly TPUs (v2-v4, and v5e) created through the Cloud TPU API can use this feature for now. Support for TPUs in GKE will be announced when it becomes available.\n## Using Autocheckpoint\nAutocheckpoint functionality is disabled by default. When you create a TPU or a [queued resource](/tpu/docs/queued-resources) , you can enable it by adding the `--autocheckpoint-enabled` flag when provisioning the TPU. With the feature enabled, Cloud TPU performs the following steps once it receives notification of a maintenance event:\n- Capture SIGTERM sent to the process using the TPU device,\n- Waits until the process exits, or 5 minutes have elapsed, whichever comes first, and performs maintenance on the impacted slices.\nNote that the infrastructure used by Autocheckpoint is ML framework-independent. Any ML framework can support Autocheckpoint provided it can capture the SIGTERM signal and initiate a checkpointing process.\nIn the application code, you need to enable the Autocheckpoint capabilities provided by the ML framework. In Pax, for example, this means enabling command-line flags when launching the training (see [the autocheckpoint Quickstart with Pax](#pax-single-slice) ). Behind the scenes, the frameworks save a non-scheduled checkpoint when a SIGTERM is received and the impacted TPU VM goes through maintenance when the TPU is no longer in use.\n## Quickstart: Autocheckpoint with MaxText\n[MaxText](https://github.com/google/maxtext) is a \"high performance, arbitrarily scalable, open source, well-tested LLM written in pure Python/JAX targeting Cloud TPUs\". MaxText contains all the necessary setup to use the Autocheckpoint feature.\nThe MaxText README describes two ways to run MaxText at scale:\n- Using` [multihost_runner.py](https://github.com/google/maxtext/blob/main/multihost_runner.py) `, recommended for experimentation\n- Using` [multihost_job.job](https://github.com/google/maxtext/blob/main/multihost_job.py) `, recommended for production\nWhen using `multihost_runner.py` , the only change required is to set the `autocheckpoint-enabled` flag when provisioning the queued resource. When using `multihost_job.py` , the only change required is to specify the `ENABLE_AUTOCHECKPOINT=true` command line flag when launching the job.\n## Quickstart: Autocheckpoint with Pax on single slices\nIn this section, we provide an example of how to set up and use Autocheckpoint with Pax on a single slice. With the appropriate setup:\n- A checkpoint will be saved when a maintenance event occurs.\n- Cloud TPU will perform maintenance on the affected TPU VM(s) after the checkpoint is saved.\n- When Cloud TPU completes maintenance, you can use the TPU VM as usual.\n- Use the `autocheckpoint-enabled` flag when creating the TPU VM or queued resource.For example:```\nPROJECT=your-gcp-project-nameZONE=zone-you-want-to-useNODE_ID=your-node-idACCELERATOR_TYPE=your-accelerator-typegcloud config set project $PROJECTgcloud config set compute/zone $ZONE\n``````\ngcloud alpha compute tpus tpu-vm create $NODE_ID \\--accelerator-type $ACCELERATOR_TYPE \\--version tpu-ubuntu2204-base \\--autocheckpoint-enabled\n``` **Note:** The Pax version that supports Autocheckpoint requires the runtime version `tpu-ubuntu2204-base` which comes with Python 3.10.\n- Install Pax on a single sliceThe Autocheckpoint feature works on Pax versions >= 1.1.0. On the TPU VMs, install `jax[tpu]` and the latest `paxml` :```\npip install paxml && pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n```\n- Launch the training with the appropriate configurationThe following example shows how to configure the ` [LmCloudSpmd2B](https://github.com/google/paxml/blob/b18a8d109ec45bbd7e4bcab04e3e53c2e65f3035/paxml/tasks/lm/params/lm_cloud.py#L166) ` model to save checkpoints triggered by Autocheckpoint to a Google Cloud Storage bucket:```\nJOB_LOG_DIR=gs://your-storage-bucket{ python3 .local/lib/python3.10/site-packages/paxml/main.py--jax_fully_async_checkpoint=1 \\--exit_after_ondemand_checkpoint=1 \\--exp=tasks.lm.params.lm_cloud.LmCloudSpmd2B \\--job_log_dir=$JOB_LOG_DIR; } 2>&1 | tee pax_logs.txt\n```Note the two flags that are passed to the command:- `jax_fully_async_checkpoint`: With this flag on,` [orbax.checkpoint.AsyncCheckpointer](https://github.com/google/orbax/blob/986f23ff728c0ed5273f17662fa49011a08342bc/checkpoint/orbax/checkpoint/async_checkpointer.py#L43C53-L43C53) `will be used. The`AsyncCheckpointer`class automatically saves a checkpoint when the training script receives a SIGTERM signal.\n- `exit_after_ondemand_checkpoint`: With this flag on, the TPU processes exits after the Autocheckpoint is successfully saved, which triggers the maintenance to be performed immediately. If you do not use this flag, the training will continue after the checkpoint is saved and Cloud TPU will wait for a timeout to occur (5 minutes) before performing the required maintenance..\n## Quickstart: Autocheckpoint with Pax on Multislice\nAutocheckpoint works not only for single slices, but also for [Multislice](https://cloud.google.com/tpu/docs/multislice-introduction) . This section details the steps needed to use Autocheckpoint with Multislice.\n- Specify Autocheckpoint during queued resource creation.A Multislice environment can only be provisioned through a queued resource request. Similar to the single-slice case, use the `autocheckpoint-enabled` flag in the call to create a queued resource.```\nQR_ID=your-qr-idNODE_COUNT=your-node-countACCELERATOR_TYPE=your-accelerator-typegcloud alpha compute tpus queued-resources create $QR_ID \\--node-count $NODE_COUNT \\--accelerator-type $ACCELERATOR_TYPE \\--runtime-version tpu-ubuntu2204-base \\--autocheckpoint-enabled\n```Refer to the [Multislice User Guide](/tpu/docs/multislice-introduction) for details on all available options. Once the queued resource request is created and in the `ACTIVE` state, follow the next steps to run Pax with Autocheckpoint.\n- Install Pax on all VMs in the Multislice environment.On the TPU VMs, install `jax[tpu]` and the latest `paxml` on all of the TPU VMs in your Multislice environment:```\npip install paxml && pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n```\n- Launch the training with the appropriate configurationThis example shows how to configure the model [LmCloudSpmd2B](https://github.com/google/paxml/blob/b18a8d109ec45bbd7e4bcab04e3e53c2e65f3035/paxml/tasks/lm/params/lm_cloud.py#L166) for Autocheckpoint when training in a Multislice environment. Before running the training script, set DCN_MESH_SHAPE to [2, 1, 1] as shown in the following code:```\n@experiment_registry.registerclass LmCloudSpmd2B(LmCloudSpmd):\"\"\"SPMD model with 2B params.Global batch size = 2 * 2 * 1 * 32 = 128\"\"\"PERCORE_BATCH_SIZE = 8NUM_LAYERS = 18MODEL_DIMS = 3072HIDDEN_DIMS = MODEL_DIMS * 4CHECKPOINT_POLICY = layers.AutodiffCheckpointType.SAVE_NOTHINGICI_MESH_SHAPE = [1, 4, 1]DCN_MESH_SHAPE = [2, 1, 1]\n```When launching the training, in addition to the command line flags discussed in the single-slice case, three more are required:- `num_hosts`: the total number of hosts. In this case, it is 2.\n- `host_index`: the index of the host launching the training. It varies from 0 to`N-1`where`N`is the total number of hosts.\n- `server_addr`: the IP address of worker 0 of node 0, with an unused port (for example, 8476). To find this information, use`hostname -i`on worker 0 of node 0.\n## Autocheckpoint with Orbax\nThe Autocheckpoint feature is not limited to MaxText or Pax. Any framework that can capture the SIGTERM signal and initiate a checkpointing process works with the infrastructure provided by Autocheckpoint. [Orbax](https://github.com/google/orbax) , a namespace that provides common utility libraries for JAX users, provides these capabilities.\nAs explained in the [Orbax documentation](https://github.com/google/orbax/blob/986f23ff728c0ed5273f17662fa49011a08342bc/docs/preemption_checkpointing.ipynb) , these capabilities are enabled by default for users of `orbax.checkpoint.CheckpointManager` . The `save` method that is called after every step automatically checks whether a maintenance event is impending, and if so, saves a checkpoint even if the step number is not a multiple of `save_interval_steps` . The [GitHub documentation](https://github.com/google/orbax/blob/986f23ff728c0ed5273f17662fa49011a08342bc/docs/preemption_checkpointing.ipynb) also illustrates how to make the training exit after saving an Autocheckpoint, with a modification in the user code.", "guide": "Cloud TPU"}