{"title": "Cloud TPU - Run Cloud TPU applications in a Docker container", "url": "https://cloud.google.com/tpu/docs/run-in-container", "abstract": "# Cloud TPU - Run Cloud TPU applications in a Docker container\n# Run Cloud TPU applications in a Docker container\n[Docker containers](https://www.docker.com/resources/what-container/) make configuring applications easier by combining your code and all needed dependencies in one distributable package. You can run Docker containers within TPU VMs to simplify configuring and sharing your Cloud TPU applications. This document describes how to set up a Docker container for each ML framework supported by Cloud TPU.\n**Important:** You can run a maximum of 256 Docker pods on a TPU VM.\n", "content": "## Train a TensorFlow model in a Docker container\n- Create a file named `Dockerfile` in your current directory and paste the following text```\nFROM python:3.8RUN pip install https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/tensorflow/tf-2.12.0/tensorflow-2.12.0-cp38-cp38-linux_x86_64.whlRUN curl -L https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/libtpu/1.6.0/libtpu.so -o /lib/libtpu.soRUN git clone https://github.com/tensorflow/models.gitWORKDIR ./modelsRUN pip install -r official/requirements.txtENV PYTHONPATH=/models\n```\n- Create Cloud Storage bucket```\ngsutil mb -c standard -l europe-west4 gs://your-bucket-name\n```\n- Create a TPU VM```\ngcloud compute tpus tpu-vm create your-tpu-name \\--zone=europe-west4-a \\--accelerator-type=v2-8 \\--version=tpu-vm-tf-2.16.1-pjrt\n```\n- Copy the Dockerfile to your TPU VM```\ngcloud compute tpus tpu-vm scp ./Dockerfile your-tpu-name:\n```\n- SSH into the TPU VM```\ngcloud compute tpus tpu-vm ssh your-tpu-name \\--zone=europe-west4-a\n```\n- Build the Docker image```\nsudo docker build -t your-image-name . \n```\n- Start the Docker container```\nsudo docker run -ti --rm --net=host --name your-container-name --privileged your-image-name bash\n```\n- Set environment variables```\nexport STORAGE_BUCKET=gs://your-bucket-nameexport DATA_DIR=gs://cloud-tpu-test-datasets/fake_imagenetexport MODEL_DIR=${STORAGE_BUCKET}/resnet-2x\n```\n- Train ResNet```\npython3 official/vision/train.py \\--tpu=local \\--experiment=resnet_imagenet \\--mode=train_and_eval \\--config_file=official/vision/configs/experiments/image_classification/imagenet_resnet50_tpu.yaml \\--model_dir=${MODEL_DIR} \\--params_override=\"task.train_data.input_path=${DATA_DIR}/train*, task.validation_data.input_path=${DATA_DIR}/validation*,trainer.train_steps=100\"\n```\nWhen the training script completes, make sure you clean up the resources.- Type`exit`to exit from the Docker container\n- Type`exit`to exit from the TPU VM\n- Delete the TPU VM```\n\u00a0$ gcloud compute tpus tpu-vm delete your-tpu-name --zone=europe-west4-a\n```\n- Create a file named `Dockerfile` in your current directory and paste the following text```\nFROM python:3.8RUN pip install https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/tensorflow/tf-2.12.0/tensorflow-2.12.0-cp38-cp38-linux_x86_64.whlRUN curl -L https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/libtpu/1.6.0/libtpu.so -o /lib/libtpu.soRUN git clone https://github.com/tensorflow/models.gitWORKDIR ./modelsRUN pip install -r official/requirements.txtENV PYTHONPATH=/models\n```\n- Create a TPU VM```\ngcloud compute tpus tpu-vm create your-tpu-name \\--zone=europe-west4-a \\--accelerator-type=v3-32 \\--version=tpu-vm-tf-2.16.1-pod-pjrt\n```\n- Copy the Dockerfile to your TPU VM```\ngcloud compute tpus tpu-vm scp ./Dockerfile your-tpu-name:\n```\n- SSH into the TPU VM```\ngcloud compute tpus tpu-vm ssh your-tpu-name \\--zone=europe-west4-a\n```\n- Build the Docker image```\nsudo docker build -t your-image-name . \n```\n- Start a Docker container```\nsudo docker run -ti --rm --net=host --name your-container-name --privileged your-image-name bash\n```\n- Train ResNet```\npython3 official/vision/train.py \\--tpu=local \\--experiment=resnet_imagenet \\--mode=train_and_eval \\--config_file=official/vision/configs/experiments/image_classification/imagenet_resnet50_tpu.yaml \\--model_dir=${MODEL_DIR} \\--params_override=\"task.train_data.input_path=${DATA_DIR}/train*, task.validation_data.input_path=${DATA_DIR}/validation*,task.train_data.global_batch_size=2048,task.validation_data.global_batch_size=2048,trainer.train_steps=100\"\n```\nWhen the training script completes, make sure you clean up the resources.\n- Type`exit`to exit from the Docker container\n- Type`exit`to exit from the TPU VM\n- Delete the TPU VM```\n\u00a0 $ gcloud compute tpus tpu-vm delete your-tpu-name --zone=europe-west4-a\n```## Train a PyTorch model in a Docker container\n- Create Cloud TPU VM```\ngcloud compute tpus tpu-vm create your-tpu-name \\--zone=europe-west4-a \\--accelerator-type=v2-8 \\--version=tpu-ubuntu2204-base\n```\n- SSH into TPU VM```\ngcloud compute tpus tpu-vm ssh your-tpu-name \\--zone=europe-west4-a\n```\n- Start a container in the TPU VM using the nightly PyTorch/XLA image.```\nsudo docker run -ti --rm --name your-container-name --privileged gcr.io/tpu-pytorch/xla:r2.0_3.8_tpuvm bash\n``` **Note:** After running this command your command prompt will change indicating the terminal is connected to the running container.\n- Configure TPU runtimeThere are two PyTorch/XLA runtime options: PJRT and XRT. We recommend you use PJRT unless you have a reason to use XRT. To learn more about the different runtime configurations, see you have a reason to use XRT. To learn more about the different runtime configurations, see [the PJRT runtime documentation](https://github.com/pytorch/xla/blob/master/docs/pjrt.md) .\n```\nexport PJRT_DEVICE=TPU\n```\n```\nexport XRT_TPU_CONFIG=\"localservice;0;localhost:51011\"\n```\n- Clone the PyTorch XLA repo```\ngit clone --recursive https://github.com/pytorch/xla.git\n```\n- Train ResNet50```\npython3 xla/test/test_train_mp_imagenet.py --fake_data --model=resnet50 --num_epochs=1\n```\nWhen the training script completes, make sure you clean up the resources.- Type`exit`to exit from the Docker container\n- Type`exit`to exit from the TPU VM\n- Delete the TPU VM```\n\u00a0$ gcloud compute tpus tpu-vm delete your-tpu-name --zone=europe-west4-a\n```\nWhen you run PyTorch code on a TPU Pod, you must run your code on all TPU workers at the same time. One way to do this is to use the `gcloud compute tpus tpu-vm ssh` command with the `--worker=all` and `--command` flags. The following procedure shows you how create a Docker image to make setting up each TPU worker easier.- Create a TPU VM```\ngcloud compute tpus tpu-vm create your-tpu-name \\--zone=us-central2-b \\--accelerator-type=v4-32 \\--version=tpu-ubuntu2204-base\n```\n- Add the current user to the docker group```\ngcloud compute tpus tpu-vm ssh your-tpu-name \\--zone=us-central2-b \\--worker=all \\--command=\"sudo usermod -a -G docker $USER\"\n```\n- Run the training script in a container on all TPU workers.```\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\--zone=us-central2-b \\--command=\"docker run --rm --privileged --net=host \u00a0-e PJRT_DEVICE=TPU gcr.io/tpu-pytorch/xla:r2.0_3.8_tpuvm python /pytorch/xla/test/test_train_mp_imagenet.py --fake_data --model=resnet50 --num_epochs=1\"\n```Docker command flags:- `--rm`remove the container after its process terminates.\n- `--privileged`exposes the TPU device to the container.\n- `--net=host`binds all of the container's ports to the TPU VM to allow communication between the hosts in the Pod.\n- `-e`set environment variables.\nWhen the training script completes, make sure you clean up the resources.\nDelete the TPU VM using the following command:\n```\n$ gcloud compute tpus tpu-vm delete your-tpu-name \\\u00a0 --zone=us-central2-b\n```\n## Train a JAX model in a Docker container\n- Create the TPU VM```\ngcloud compute tpus tpu-vm create your-tpu-name \\--zone=europe-west4-a \\--accelerator-type=v2-8 \\--version=tpu-ubuntu2204-base\n```\n- SSH into TPU VM```\ngcloud compute tpus tpu-vm ssh your-tpu-name \u00a0--zone=europe-west4-a\n```\n- Start Docker daemon in TPU VM```\nsudo systemctl start docker\n```\n- Start Docker container```\nsudo docker run -ti --rm --name your-container-name --privileged --network=host python:3.8 bash\n```\n- Install JAX```\npip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html\n```\n- Install FLAX```\npip install --upgrade clugit clone https://github.com/google/flax.gitpip install --user -e flax\n```\n- Run the FLAX MNIST training script```\ncd flax/examples/mnistpython3 main.py --workdir=/tmp/mnist \\--config=configs/default.py \\--config.learning_rate=0.05 \\--config.num_epochs=5\n```\nWhen the training script completes, make sure you clean up the resources.- Type`exit`to exit from the Docker container\n- Type`exit`to exit from the TPU VM\n- Delete the TPU VM```\n$ gcloud compute tpus tpu-vm delete your-tpu-name --zone=europe-west4-a\n```\nWhen you run JAX code on a TPU Pod, you must run your JAX code on all TPU workers at the same time. One way to do this is to use the `gcloud compute tpus tpu-vm ssh` command with the `--worker=all` and `--command` flags. The following procedure shows you how create a Docker image to make setting up each TPU worker easier.- Create a file named `Dockerfile` in your current directory and paste the following text```\nFROM python:3.8RUN pip install \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.htmlRUN pip install --upgrade cluRUN git clone https://github.com/google/flax.gitRUN pip install --user -e flaxWORKDIR ./flax/examples/mnist\n```\n- Build the Docker image```\ndocker build -t your-image-name .\n```\n- Add a tag to your Docker image before pushing it to the Artifact Registry. For more information on working with Artifact Registry, see [Work with container images](/artifact-registry/docs/docker) .```\ndocker tag your-image-name europe-west-docker.pkg.dev/your-project/your-repo/your-image-name:your-tag\n```\n- Push your Docker image to the Artifact Registry```\ndocker push europe-west4-docker.pkg.dev/your-project/your-repo/your-image-name:your-tag\n```\n- Create a TPU VM```\ngcloud compute tpus tpu-vm create your-tpu-name \\--zone=europe-west4-a \\--accelerator-type==v2-8 \\--version=tpu-ubuntu2204-base\n```\n- Pull the Docker image from the Artifact Registry on all TPU workers.```\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\--zone=europe-west4-a \\--command=\"sudo usermod -a -G docker ${USER}\"\n``````\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\--zone=europe-west4-a \\--command=\"gcloud auth configure-docker europe-west4-docker.pkg.dev --quiet\"\n``````\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\--zone=europe-west4-a \\--command=\"docker pull europe-west4-docker.pkg.dev/your-project/your-repo/your-image-name:your-tag\"\n```\n- Run the container on all TPU workers.```\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\zone=europe-west4-a \\--command=\"docker run -ti -d --privileged --net=host --name your-container-name europe-west4-docker.pkg.dev/your-project/your-repo/your-image:your-tag bash\"\n```\n- Run the training script on all TPU workers:```\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\--zone=europe-west4-a \\--command=\"docker exec --privileged your-container-name python3 main.py --workdir=/tmp/mnist \\--config=configs/default.py \\--config.learning_rate=0.05 \\--config.num_epochs=5\"\n```\nWhen the training script completes, make sure you clean up the resources.- Shut down the container on all workers:```\ngcloud compute tpus tpu-vm ssh your-tpu-name --worker=all \\--zone=europe-west4-a \\--command=\"docker kill your-container-name\"\n```\n- Delete the TPU VM using the following command:```\n$ gcloud compute tpus tpu-vm delete your-tpu-name \\--zone=europe-west4-a\n```## What's next\n- [Cloud TPU Tutorials](/tpus/docs/tutorials) \n- [Manage TPUs](/tpu/docs/managing-tpus-tpu-vm) \n- [Cloud TPU System Architecture](/tpu/docs/system-architecture-tpu-vm) \n- [Run TensorFlow code on TPU Pod slices](/tpu/docs/tensorflow-pods) \n- [Run JAX code on TPU Pod slices](/tpu/docs/jax-pods)", "guide": "Cloud TPU"}