{"title": "Cloud TPU - Cloud TPU Multislice Overview", "url": "https://cloud.google.com/tpu/docs/multislice-introduction", "abstract": "# Cloud TPU - Cloud TPU Multislice Overview\n# Cloud TPU Multislice Overview\nCloud TPU Multislice is a full stack performance-scaling technology that enables a training job to use multiple TPU slices within a single Pod or on slices in multiple Pods with simple data parallelism. With TPU v4 chips this means training jobs can use more than 4096 chips in a single run. For training jobs that require less than 4096 chips, a single slice can offer the best performance. However, multiple smaller slices are more readily available, allowing for a faster startup time when Multislice is used with smaller slices.\nWhen deployed in Multislice configurations, TPU chips in each slice communicate through inter-chip-interconnect (ICI). TPU chips in different slices communicate by transferring data to CPUs (hosts) which in turn transmit the data over the data-center network (DCN).\nDevelopers don't have to write code to implement inter-slice DCN communication. The XLA compiler generates that code for you and overlaps communication with computation for maximum performance.\n", "content": "## Concepts\n## Get started\nIf you have not used TPUs before, start by [installing the Google Cloud CLI](/sdk/docs/install) , and [set up your Cloud TPU environment](/tpu/docs/setup-gcp-account) . To use Multislice, your TPU resources must be managed as [Queued Resources](/tpu/docs/queued-resources) .\nIf you are an existing TPU v4 user and have a reservation you may need to migrate your reservation to a new reservation system. For more information, contact your Google Cloud account representative.\n### Introductory example\nThis tutorial uses code from the [MaxText GitHub repo](https://github.com/google/maxtext) . MaxText is a high performance, arbitrarily scalable, open source, and well-tested basic LLM written in Python and Jax. MaxText was designed to train efficiently on Cloud TPU.\nThe code in [shardings.py](https://github.com/google/maxtext/blob/main/pedagogical_examples/shardings.py) is designed to help you get started experimenting with different parallelism options. For example, data parallelism, fully sharded data parallelism (FSDP), and tensor parallelism. The code scales from single slice to Multislice environments.\nICI refers to the high speed interconnect that connects the TPUs in a single slice. ICI sharding corresponds to sharding within a slice. `shardings.py` provides three ICI parallelism parameters:\n- `ici_data_parallelism`\n- `ici_fsdp_parallelism`\n- `ici_tensor_parallelism`\nThe values you specify for these parameters determine the number of shards for each parallelism method.\nThese inputs must be constrained so that `ici_data_parallelism * ici_fsdp_parallelism * ici_tensor_parallelism` is equal to the number of chips in the slice.\nThe following table shows example user inputs for ICI parallelism for the four chips available in v4-8:\n| 0          | 1     | 2     | 3      |\n|:--------------------------------------|:---------------------|:---------------------|:-----------------------|\n| nan         | ici_data_parallelism | ici_fsdp_parallelism | ici_tensor_parallelism |\n| 4-way FSDP       | 1     | 4     | 1      |\n| 4-way Tensor parallelism    | 1     | 1     | 4      |\n| 2-way FSDP + 2-way Tensor parallelism | 1     | 2     | 2      |\nNote that `ici_data_parallelism` should be left as 1 in most cases because the ICI network is fast enough to almost always prefer FSDP to data parallelism.\nThis example assumes you are familiar with running code on a single TPU slice such as in [Run a calculation on a Cloud TPU VM using JAX](/tpu/docs/run-calculation-jax) . This example show how to run `shardings.py` on a single slice.\n- Set up the environment:```\n$ gcloud auth login$ gcloud config set project your-project-id$ gcloud config set compute/zone your-zone\n```\n- Create SSH keys for `gcloud` . We recommend leaving a blank password (press enter twice after running the following command). If you are prompted that the `google_compute_engine` file already exists, replace the existing version.```\n$ ssh-keygen -f ~/.ssh/google_compute_engine\n```\n- Provision your TPUs with the following command:```\n$ gcloud alpha compute tpus queued-resources \\create your-qr-id \\--accelerator-type your-accelerator-type \\--runtime-version tpu-ubuntu2204-base \\--node-id qr-id \\[--reserved |--best-effort]\n```The Google Cloud CLI does not support all create QR options, such as tags. For more information, see [Create QRs](#create-queued-resources) .\n- Wait until the QR is in the `ACTIVE` state which means the worker nodes are in the `READY` state. Once the QR provisioning starts, it may take one to five minutes to complete depending on the size of the QR. You can check the status of a QR request using the following command:```\n$ gcloud alpha compute tpus queued-resources \\\u00a0 list --filter=your-qr-id\n```\n- A v4-8 slice has a single TPU VM. Connect to the TPU VM using SSH:```\n$ gcloud compute tpus tpu-vm ssh your-qr-id\n```\n- Clone MaxText (which includes `shardings.py` ) to your TPU VM.\n- Within the MaxText repository directory, run the setup script to install JAX and other dependencies on your TPU slice. Setup script takes a few minutes to run.```\n$ bash setup.sh\n```\n- Run the following command to run `shardings.py` on your TPU slice.```\n$ python3 pedagogical_examples/shardings.py \\\u00a0 --ici_fsdp_parallelism 4 \\\u00a0 --batch_size 131072 \\\u00a0 --embedding_dimension 2048\n```You can see the results in the logs. Your TPUs should achieve about 260 TFLOP per second or an impressive 90%+ FLOP utilization! In this case, we've selected approximately the maximum batch that fits into the TPU's High Bandwidth Memory (HBM).\n- Feel free to explore [other sharding strategies](#single-slice-sharding-using-ici-parallelism) over ICI, for example you could try the following combination:```\n$ python3 pedagogical_examples/shardings.py \\\u00a0 --ici_tensor_parallelism 4 \\\u00a0 --batch_size 131072 \\\u00a0 --embedding_dimension 2048\n```\n- Delete the QR and TPU slice when finished. You should run these cleanup steps from the environment where you set up the slice (first run `exit` to exit the SSH session). The deletion will take two to five minutes to complete, and can be run in the background with the optional `--async` flag. **Important:** QRs must be deleted after use. If you don't they will continue to consume your QR quota which is tracked separately from TPU quota.```\n$ gcloud alpha compute tpus queued-resources\u00a0 delete your-qr-id --force (--async)\n```The `shardings.py` script takes three parameters that specify DCN parallelism, corresponding to the number of shards of each type of data parallelism:\n- dcn_data_parallelism\n- dcn_fsdp_parallelism\n- dcn_tensor_parallelism\nThe values of these parameters must be constrained so that `dcn_data_parallelism * dcn_fsdp_parallelism * dcn_tensor_parallelism` equals the number of slices.\nAs an example for two slices, use `--dcn_data_parallelism = 2` .\n| 0      | 1     | 2     | 3      | 4   |\n|:-----------------------|:---------------------|:---------------------|:-----------------------|:------------|\n| nan     | dcn_data_parallelism | dcn_fsdp_parallelism | dcn_tensor_parallelism | # of slices |\n| 2-way data parallelism | 2     | 1     | 1      | 2   |\n`dcn_tensor_parallelism` should always be set to `1` because the DCN is a poor fit for such sharding. For typical LLM workloads on v4 chips, `dcn_fsdp_parallelism` should also be set to `1` and therefore `dcn_data_parallelism` should be set to the number of slices, but this is application dependent.\nAs you increase the number of slices (assuming you keep the slice size and batch per slice constant), you increase the amount of data parallelism.\nYou can run `shardings.py` in a Multislice environment using `multihost_runner.py` or by running `shardings.py` on each TPU VM. Here we use `multihost_runner.py` . The following steps are very similar to those [Getting Started: Quick Experiments on Multiple slices](https://github.com/google/maxtext/blob/main/README.md#getting-started) from the MaxText repository, except here we run `shardings.py` instead of the more complex LLM in `train.py` .\nThe `multihost_runner.py` tool is optimized for quick experiments, repeatedly re-using the same TPUs. Because the `multihost_runner.py` script depends on long-lived SSH connections, we don't recommend it for any long-running jobs. If you want to run a longer job (for example, hours or days), we recommend you use `multihost_job.py` .\nIn this tutorial, we use the term to indicate the machine on which you run the `multihost_runner.py` script. We use the term to indicate the TPU VMs that make up your slices. You can run `multihost_runner.py` on a local machine or any Compute Engine VM in the same project as your slices. Running `multihost_runner.py` on a worker is not supported.\n`multihost_runner.py` automatically connects to TPU workers using SSH.\nIn this example, we run `shardings.py` over two v4-16 slices, a total of four VMs and 16 TPU chips. You can modify the example to run on more TPUs.- Clone [MaxText](https://github.com/google/maxtext/tree/main) on your runner machine.\n- Go to the repository directory.\n- Create SSH keys for `gcloud` , we recommend leaving a blank password (press enter twice after running the following command). If you are prompted that the `google_compute_engine` file already exists, select not to keep your existing version.```\n\u00a0 $ ssh-keygen -f ~/.ssh/google_compute_engine\u00a0 \n```\n- Add an environment variable to set the TPU slice count to `2` .```\n\u00a0 $ export SLICE_COUNT=2\u00a0 \n```\n- Create a Multislice environment using `queued-resources create` . **Note:** Ensure you have the respective quota before selecting `--reserved` , or `--best_effort` , or the default on-demand quota. For information on quota types, see [Quota Policy](/tpu/docs/quota) .The following command shows how to create a v4 Multislice TPU. To use v5e, specify a v5e `accelerator-type` (for example `v5litepod-16` ) and the v5e `runtime-version` ( `v2-alpha-tpuv5-lite` ).```\n\u00a0 $ gcloud alpha compute tpus queued-resources \u00a0 create your-qr-id \u00a0 --accelerator-type=your-accelerator-type \u00a0 --runtime-version=tpu-vm-runtime-version \u00a0 --node-count=node-count \u00a0 --node-prefix=your-qr-id \u00a0 [--reserved|--best-effort]\u00a0 \n```\n- When the QR provisioning starts it may take up to five minutes to complete depending on the size of the QR. Wait until the Queued Resource (QR) is in the `ACTIVE` state. You can check the status of a QR request using the following command:```\n$ gcloud alpha compute tpus queued-resources list \\--filter=your-qr-id\n```This should generate output that looks like:```\nNAME \u00a0 \u00a0 \u00a0 \u00a0ZONE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 NODE_COUNT \u00a0ACCELERATOR_TYPE \u00a0STATE...que-res-id \u00a0us-central2-b \u00a04 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 v4-16 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ACTIVE...\n```Contact your Google Cloud account representative if the QR status is in the `WAITING_FOR_RESOURCES` or `PROVISIONING` state for more than 15 minutes.\n- Install dependencies.```\n$ python3 multihost_runner.py \\\u00a0 --TPU_PREFIX=your-qr-id \\\u00a0 --COMMAND=\"bash setup.sh\"\n```\n- Run `shardings.py` on each worker using `multihost_runner.py` .```\n$ python3 multihost_runner.py \\\u00a0 --TPU_PREFIX=your-qr-id \\\u00a0 --COMMAND=\"python3 pedagogical_examples/shardings.py \\\u00a0 --dcn_data_parallelism $SLICE_COUNT \\\u00a0 --ici_fsdp_parallelism 8 \\\u00a0 --batch_size 131072 \\\u00a0 --embedding_dimension 2048\"\n```You'll see approximately 230 TFLOPs per second of performance in the log files.\n- Clean up the TPUs and QR when finished. The deletion will take two to five minutes to complete, and can be run in the background with the optional `--async` flag.## Scaling a workload to Multislice\nBefore running your model in a Multislice environment, make the following code changes:\n- Use [jax.experimental.mesh_utils.create_hybrid_device_mesh](https://github.com/google/jax/blob/0affb3bb180048e7d989861cb81a0398117fbe7a/jax/experimental/mesh_utils.py#L275-L297) instead of [jax.experimental.mesh_utils.create_device_mesh](https://github.com/google/jax/blob/0affb3bb180048e7d989861cb81a0398117fbe7a/jax/experimental/mesh_utils.py#L218-L238) when creating your mesh.\nThese should be the only necessary code changes when moving to Multislice. To achieve high performance, DCN needs to be mapped onto data parallel, fully sharded data parallel or pipeline parallel axes. Performance considerations and sharding strategies are discussed in more detail in [Sharding With Multislice for Maximum Performance](#sharding-with-multislice-for-maximum-performance) .\nTo validate that your code can access all the devices, you can assert that `len(jax.devices())` is equal to the number of chips in your Multislice environment. For example, if you are using four slices of `v4-16` , you have eight chips per slice * 4 slices, so `len(jax.devices())` should return 32.\n### Choosing slice sizes for Multislice environments\nTo get a linear speed up, add new slices of the same size as your existing slice. For example, if you use a `v4-512` slice, Multislice will achieve approximately twice the performance by adding a second `v4-512` slice and doubling your global batch size. For more information, see [Sharding With Multislice for Maximum Performance](#sharding-with-multislice-for-maximum-performance) .\n### Running your Job on multiple slices\nThere are three different approaches to running your custom workload in a Multislice environment:\n- Using the experimentation runner script,`multihost_runner.py`\n- Using the production runner script,`multihost_job.py`\n- Using a manual approachThe [multihost_runner.py](https://github.com/google/maxtext/blob/main/multihost_runner.py) script distributes code to an existing Multislice environment, and runs your command on each host, copies your logs back, and tracks each command's error status. The `multihost_runner.py` script is documented in [MaxText README](https://github.com/google/maxtext/blob/main/README.md) .\nBecause `multihost_runner.py` maintains persistent SSH connections, it is only suitable for modestly sized, relatively short-running experimentation. You can adapt the steps in the [multihost_runner.py tutorial](#multislice-sharding-using-dcn-parallelism) to your workload and hardware configuration.\nFor production jobs that need resiliency against hardware failures and other preemptions, it is best to integrate directly with the Create Queued Resource API. As a working example, we provide [multihost_job.py](https://github.com/google/maxtext/blob/main/multihost_job.py) , which triggers the Created Queued Resource API call with the appropriate startup script to run your training and resume on preemption. The `multihost_job.py` script is documented in the [MaxText README](https://github.com/google/maxtext/blob/main/README.md) .\nBecause `multihost_job.py` must provision resources for each run, it doesn't provide as fast an iteration cycle as `multihost_runner.py` .\nWe recommend you use or adapt [multihost_runner.py](#experimentation-runner-script) or [multihost_job.py](#production-job-script) to run your custom workload in your Multislice configuration. However, if you prefer to provision and manage your environment using QR commands directly, see [Manage a Multislice Environment](#manage-a-multislice-environment) .\n### Manage a Multislice environment\nTo manually provision and manage QRs without using the tools provided in the [MaxText repo](https://github.com/google/maxtext) , read the following sections.\nSet the following environment variables before provisioning capacity:\n```\n\u00a0 $ export your-qr-id=your-queued-resource-id\u00a0 $ export PROJECT=your-project-name\u00a0 $ export ZONE=us-central2-b\u00a0 $ export NETWORK_NAME=your-network-name\u00a0 $ export SUBNETWORK_NAME=your-subnetwork-name\u00a0 $ export RUNTIME_VERSION=tpu-ubuntu2204-base\u00a0 $ export ACCELERATOR_TYPE=v4-16\u00a0 $ export SLICE_COUNT=4\u00a0 $ export STARTUP_SCRIPT=\"#!/bin/bash\\n ...\"\u00a0 $ gcloud config set project project-name\u00a0 $ gcloud config set compute/zone zone\n```\n| 0        | 1                                      |\n|:-------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Input       | Description                                   |\n| your-qr-id      | The user-assigned ID of the QR.                              |\n| PROJECT      | Google Cloud Project Name                                |\n| ZONE       | us-central2-b                                   |\n| NETWORK_NAME     | Name of the VPC networks.                                |\n| SUBNETWORK_NAME    | Name of the subnet in VPC networks                             |\n| RUNTIME_VERSION    | tpu-ubuntu2204-base                                 |\n| ACCELERATOR_TYPE    | v4-16                                     |\n| EXAMPLE_TAG_1, EXAMPLE_TAG_2 \u2026 | Tags used to identify valid sources or targets for network firewalls                     |\n| SLICE_COUNT     | Number of slices. Limited to a maximum of 256 slices.                         |\n| STARTUP_SCRIPT     | If added to the create request, a startup script can run whenever a TPU slice is provisioned or restarted and if the TPU slice is repaired or reset. |\n```\n$ gcloud alpha compute tpus queued-resources \\\u00a0 create ${your-qr-id} \\\u00a0 --project your-project-id \\\u00a0 --zone your-zone \\\u00a0 --node-count ${SLICE_COUNT} \\\u00a0 --accelerator-type ${ACCELERATOR_TYPE} \\\u00a0 --runtime-version ${RUNTIME_VERSION} \\\u00a0 --network ${NETWORK_NAME} \\\u00a0 --subnetwork ${SUBNETWORK_NAME} \\\u00a0 --tags ${EXAMPLE_TAG_1},${EXAMPLE_TAG_2} \\ --metadata=startup-script='${STARTUP_SCRIPT}'\u00a0 [--reserved|--best-effort]\u00a0 \n```Ensure you have the respective quota before selecting `--reserved` , or `--best_effort` , or the default on-demand quota. For information on quota types, see [Quota Policy](/tpu/docs/quota) .\nCreate a file named `queued-resource-req.json` and copy the following JSON into it.\n```\n{\u00a0 \"guaranteed\": { \"reserved\": true },\u00a0 \"tpu\": {\u00a0 \u00a0 \"node_spec\": [\u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \"parent\": \"projects/your-project-number/locations/your-zone\",\u00a0 \u00a0 \u00a0 \u00a0 \"node\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"accelerator_type\": \"accelerator-type\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"runtime_version\": \"tpu-vm-runtime-version\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"network_config\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"network\": \"your-network-name\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"subnetwork\": \"your-subnetwork-name\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"enable_external_ips\": true\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"tags\" : [\"example-tag-1\"]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"metadata\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"startup-script\": \"your-startup-script\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \"multi_node_params\": {\u00a0 \u00a0 \u00a0 \u00a0 \"node_count\": slice-count,\u00a0 \u00a0 \u00a0 \u00a0 \"node_id_prefix\": \"your-queued-resource-id\"\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 \u00a0 ]\u00a0 }}\n```\n**Note:** Replace the following values:\n- - Your Google Cloud project number\n- - The zone in which you want to create your QR\n- - The version and size of a single slice\n- - The TPU VM runtime versions\n- - Optional, a network to which the QR will be attached\n- - Optional, a subnetwork to which the QR will be attached\n- - Optional, an arbitrary tag string\n- - A startup script that will be run when the QR is allocated\n- - The number of TPU slices in your Multislice environment\n- - The user supplied ID for the QR\nFor more information, see the [REST Queued Resource API](/tpu/docs/reference/rest/v2alpha1/projects.locations.queuedResources) documentation for all available options.\n**Note:** Although `node_spec` is a list, only one `node_spec` entry is supported.\nTo use preemptible capacity, replace:\n`\"guaranteed\": { \"reserved\": true }` with `\"best_effort\": {}`\nOr remove the line to use the default on-demand capacity.\nSubmit the QR create request with the JSON payload:\n```\n\u00a0 $ curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" -d @queuedresourcereq.json https://tpu.googleapis.com/v2alpha1/projects/your-project-id/locations/your-zone/queuedResources\\?queued_resource_id\\=your-qr-id\n```\n**Note:** Replace the following values:\n- - Your Google Cloud project ID\n- - The zone in which you want to create your QR\n- - The user supplied ID for the QR\nThe response should look like the following:\n```\n{\u00a0 \"name\": \"projects/<your-project-id>/locations/<your-zone>/operations/operation-<your-qr-guid>\",\u00a0 \"metadata\": {\u00a0 \u00a0 \"@type\": \"type.googleapis.com/google.cloud.common.OperationMetadata\",\u00a0 \u00a0 \"createTime\": \"2023-11-01T00:17:05.742546311Z\",\u00a0 \u00a0 \"target\": \"projects/<your-project-id>/locations/<your-zone>/queuedResources/<your-qa-id>\",\u00a0 \u00a0 \"verb\": \"create\",\u00a0 \u00a0 \"cancelRequested\": false,\u00a0 \u00a0 \"apiVersion\": \"v2alpha1\"\u00a0 },\u00a0 \"done\": false}\n```\nUse GUID value at the end of the string value for the `name` attribute to get information about the QR request.\nTo get the status of the QR request, use the following command:\n```\n\u00a0 $ curl -X GET -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" https://tpu.googleapis.com/v2alpha1/projects/your-project-id/locations/your-zone/operations/operation-your-qr-guid\n```\n**Note:** In the preceding command replace the following:\n- - Your Google Cloud project ID\n- - The zone in which to create the QR\n- - The GUID following`name`in the output from the QR creation request.\nThe response of this command contains the status of the operation:\n```\n{\u00a0 \"name\": \"projects/<your-project-id>/locations/<your-zone>/operations/operation-<your-qa-guid>,\u00a0 \"metadata\": {...},\u00a0 \"done\": true,\u00a0 \"response\": {\u00a0 \u00a0 \"@type\": \"type.googleapis.com/google.cloud.tpu.v2alpha1.QueuedResource\",\u00a0 \u00a0 ...\u00a0 \u00a0 \"state\": {\u00a0 \u00a0 \u00a0 \"state\": \"WAITING_FOR_RESOURCES\"\u00a0 \u00a0 }\u00a0 }}\n```\nIf the QR is created successfully `(\"done = true\")` , the state within the `response` field will be either `WAITING_FOR_RESOURCES` or `FAILED` . If the QR is in the `WAITING_FOR_RESOURCES` state, the QR has been enqueued and will start provisioning when there are enough resources. If the QR is in the `FAILED` state, the failure reason will be in the output. For more information about other possible states, see the [Queued resources user guide](/tpu/docs/queued-resources) .\nOnce the operation is done, use the [describe QRs](#describe-queued-resources) to monitor the stages of the QR.\nIn a rare scenario, you might find your QR in the `FAILED` state while some slices are `ACTIVE` . If this happens, delete the resources that were created, and try again in a few minutes or [reach out](https://forms.gle/pLFRKSdWZ97o2o867) to the Cloud TPU team to resolve the issue.\n[Run JAX code on TPU Pod slices](/tpu/docs/jax-pods) describes how to connect to your TPU VMs using SSH in a single slice. To connect to all TPU VMs in your Multislice environment over SSH and install dependencies, use the following `gcloud` command:\n```\n\u00a0 $ gcloud compute tpus queued-resources ssh ${your-qr-id} \\\u00a0 \u00a0 --zone your-zone \\\u00a0 \u00a0 --node=all \\\u00a0 \u00a0 --worker=all \\\u00a0 \u00a0 --command=\"command-to-run\"\u00a0 \u00a0 --batch-size=4\n```\nThis `gcloud` command sends the specified command to all workers and nodes in QR using SSH. The command is batched into groups of four and is sent simultaneously. The next batch of commands are sent when the current batch completes execution. If there is a failure with one of the commands, processing stops, and no further batches are sent. For more information, see the [Queued resource API reference](/sdk/gcloud/reference/alpha/compute/tpus/queued-resources/ssh) . If the number of slices you are using exceeds your local computer's threading limit (also called batching limit) you will run into a deadlock. As an example, assume the batching limit on your local machine is 64. If you try to run a training script on more than 64 slices, say 100, the SSH command will break up the slices into batches. It will run the training script on the first batch of 64 slices and wait for the scripts to complete before running the script on the remaining batch of 36 slices. However, the first batch of 64 slices cannot complete until the remaining 36 slices start running the script, causing a deadlock.\nTo prevent this scenario, you can run the training script in the background on each VM by appending an ampersand ( `&` ) to the script command you specify with the `--command` flag. When you do this, after starting the training script on the first batch of slices, control will immediately return to the SSH command. The SSH command can then start running the training script on the remaining batch of 36 slices. You'll need to pipe your `stdout` and `stderr` streams appropriately when running the commands in the background. To increase parallelism within the same QR, you can select specific slices using the `--node` parameter.\nEnsure TPU slices can communicate with each other by running the following steps. Install JAX on **each** of the slices. For more information, see [Run JAX code on TPU Pod slices](/tpu/docs/jax-pods) . Assert that `len(jax.devices())` is equal to the number of chips in your Multislice environment. To do this, on each slice, run:\n```\n\u00a0 $ python3 -c 'import jax; print(jax.devices())'\n```\nIf you run this code on four slices of v4-16's, there are eight chips per slice and four slices, a total of 32 chips (devices) should be returned by `jax.devices()` .\nYou can view the state of your QRs using the `queued-resources list` command:\n```\n$ gcloud alpha compute tpus queued-resources listNAME \u00a0 \u00a0 \u00a0 \u00a0ZONE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 NODE_COUNT \u00a0ACCELERATOR_TYPE \u00a0STATE...que-res-id \u00a0us-central2-b \u00a04 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 v4-16 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ACTIVE...\n```\nTo view the detailed configuration and state of a QR, use the describe QR API. You can call this API using `gcloud` or `curl` .\nUsing `gcloud` :\n```\n$ gcloud alpha compute tpus queued-resources describe ${your-qr-id}...state:\u00a0state: ACTIVE...\n```\nUsing `curl` :\n```\n$ curl -X GET -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" https://tpu.googleapis.com/v2alpha1/projects/your-project-id/locations/your-zone/queuedResources/${your-qr-id}{\u00a0 \"name\": your-queued-res,\u00a0 \"tpu\": {\u00a0 \u00a0 \"nodeSpec\": [\u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 ... // node 1\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 ... // node 2\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 ...\u00a0 \u00a0 ]\u00a0 },\u00a0 ...\u00a0 \"state\": \"ACTIVE\"}\n```\n`state` represents the status of a QR. For more information on the possible states of QRs, see [Queued resources](/tpu/docs/queued-resources) .\nYou can manually run workloads by connecting to all hosts in each slice over SSH and running the following command on all hosts.\n```\n$ gcloud compute tpus tpu-vm ssh your-qr-id \\\u00a0 --zone=your-zone \\\u00a0 --worker=all \\\u00a0 --node=all \\\u00a0 --command=\"command-to-run\"\n```\nThe `ResetQueuedResource` API can be used to [reset](/compute/docs/samples/compute-reset-instance) all the VMs in an `ACTIVE` QR. Resetting the VMs forcibly erases the memory of the machine and resets the VM to its initial state. Any data stored locally will remain intact and the startup script will be invoked after a reset. The `ResetQueuedResource` API can be useful when you want to restart all TPUs. For example, when training is stuck and resetting all VMs is easier than debugging.\nThe resets of all VMs are performed in parallel and a `ResetQueuedResource` operation takes one to two minutes to complete. To invoke the API, use the following command:\n```\n$ gcloud alpha compute tpus queued-resources reset your-qr-id\n```\nTo release resources at the end of your training session, delete the queued resource with the `--force` flag. The deletion will take two to five minutes to complete, and can be run in the background with the optional `--async` flag.\n```\n$ gcloud alpha compute tpus queued-resources \\delete your-qr-id --force (--async)\n```\nIn the event of a disruption, Multislice offers intervention-free repair of the impacted slice and reset of all slices afterward. The impacted slice is replaced with a new slice and the remaining otherwise healthy slices are [reset](/compute/docs/samples/compute-reset-instance) . If no capacity is available to allocate a replacement slice, training stops.\nTo resume training automatically after an interruption, you must specify a [startup script](/compute/docs/instances/startup-scripts/linux) that checks for and loads the last saved checkpoints. Your startup script is automatically run every time a slice is reallocated or a VM is reset. You specify a startup script in the JSON payload you send to the create QR request API.\nThe following startup script (used in [Create QRs](#create-queued-resources) ) lets you automatically recover from failures and resume training from checkpoints stored in a Cloud Storage bucket during MaxText training:\n```\n{\n \"tpu\": {\n \"node_spec\": [  {\n  ...\n   \"metadata\": {\n    \"startup-script\": \"#! /bin/bash \\n pwd \\n runuser -l user1 -c 'cd /home/user1/MaxText && python3 MaxText/train.py MaxText/configs/base.yml run_name=run_test_failure_recovery dcn_data_parallelism=4 ici_fsdp_parallelism=8 steps=10000 save_period=10 base_output_directory='gs://user1-us-central2'' EOF\"\n   }\n  ...\n  }\n ]\n }\n}\n```\nClone the [MaxText repo](https://github.com/google/maxtext) before trying this out.\n## Profiling and debugging\nProfiling is the same in single slice and Multislice environments. For more information, see [Profiling JAX programs](https://jax.readthedocs.io/en/latest/profiling.html) .\n## Optimizing training\n### Sharding with Multislice for maximum performance\nAchieving maximum performance in Multislice environments requires considering how to shard across the multiple slices. There are typically three choices (data parallelism, fully-sharded data parallelism and pipeline parallelism). We don't recommend sharding activations across the model dimensions (sometimes called tensor parallelism) because it requires too much inter-slice bandwidth. For all these strategies, you can keep the same sharding strategy within a slice that has worked for you in the past.\nWe recommend starting with pure data parallelism. Using fully-sharded data parallelism is useful for freeing up memory usage. The drawback is that communication between slices uses the DCN network and will slow down your workload. Use pipeline parallelism only when necessary based on batch size (as analyzed below).\n### When to use data parallelism\nPure data parallelism will work well in cases where you have a workload that is running well, but you'd like to improve its performance by scaling across multiple slices.\nTo achieve strong scaling across multiple slices, the amount of time required to perform all-reduce over DCN needs to be less than the amount of time required to perform a backwards pass. DCN is used for communication between slices and is a limiting factor in workload throughput.\nEach v4 TPU chip performs at a peak of 275 * 10 FLOPS per second.\nThere are four chips per TPU host and each host has a maximum network bandwidth of 50 Gbps.\nThat means the [arithmetic intensity](https://crd.lbl.gov/divisions/amcr/computer-science-amcr/par/research/roofline/introduction/#:%7E:text=Arithmetic%20Intensity%20is%20the%20ratio,ndependent%20of%20the%20vector%20size./) is 4 * 275 * 10 FLOPS / 50 Gbps = 22000 FLOPS / bit.\nYour model will use 32 to 64 bits of DCN bandwidth for each parameter per step. If you use two slices, your model will use 32 bits of DCN bandwidth. If you use more than two slices the compiler will perform a full shuffle all-reduce operation and you'll use up to 64 bits of DCN bandwidth for each parameter per step. The amount of FLOPS needed for each parameter will vary depending on your model. Specifically, for Transformer based language models, the number of FLOPS required for a forward and a backward pass are approximately 6 * B * P where:\n- B is the batch size in tokens\n- P is the number of parameters\nThe number of FLOPS per parameter is `6 * B` and the number of FLOPS per parameter during the backwards pass is `4 * B` .\nTo ensure strong scaling across multiple slices, ensure that the operational intensity exceeds the arithmetic intensity of the TPU hardware. To calculate the operational intensity, divide the number of FLOPS per parameter during the backwards pass by the network bandwidth (in bits) per parameter per step: `Operational Intensity = FLOPSbackwards_pass / DCN bandwidth`\nTherefore, for a Transformer based language model, if you are using two slices: `Operational intensity = 4 * B / 32`\nIf you are using more than two slices: `Operational intensity = 4 * B/64`\nThis suggests a minimum batch size of between 176k and 352k for Transformer based language models. Because the DCN network can briefly drop packets, it's best to maintain a significant margin for error, deploying data parallelism only if the batch size per Pod is at least 350k (two Pods) to 700k (many Pods).\nFor other model architectures, you'll need to estimate the runtime of your backwards pass per slice (either by timing it using a profiler or by counting FLOPS). Then you can compare that to the expected run time to all reduce over DCN and get a good estimate of if data parallelism will make sense for you.\n### When to use fully sharded data parallelism (FSDP)\nFully sharded data parallelism (FSDP) combines data parallelism (sharding the data across nodes) with sharding the weights across nodes. For each operation in the forward and backward passes, the weights are all-gathered so that each slice has the weights it needs. Instead of synchronizing the gradients using all-reduce, the gradients are reduce-scattered as they are produced. In this way, each slice only gets the gradients for the weights it's responsible for.\nSimilar to data parallelism, FSDP will require scaling the global batch size linearly with the number of slices. FSDP will decrease the memory pressure as you increase the number of slices. This is because the number of weights and optimizer state per slice decreases but it does so at the price of increased network traffic and the greater possibility for blocking due to a delayed collective.\nIn practice, FSDP across slices is best if you are increasing the batch per slice, storing more activations to minimize re-materialization during the backwards pass or increasing the number of parameters in your neural network.\nThe all-gather and all-reduce operations in FSDP work similarly to those in DP, so you can determine if your FSDP workload is limited by DCN performance in the same way as described in the previous section.\n### When to use pipeline parallelism\nPipeline parallelism becomes relevant when achieving high performance with other parallelism strategies that require a global batch size greater than your preferred maximum batch size. Pipeline parallelism allows the slices comprising a pipeline to \"share\" a batch. However, pipeline parallelism has two significant downsides:\n- It incurs the \"pipeline bubble\" where chips are idle because they are waiting for data.\n- It requires micro-batching which decreases the effective batch size, the arithmetic intensity and ultimately model FLOP utilization.\nPipeline parallelism should be used only if the other parallelism strategies require too large a global batch size. Before trying pipeline parallelism, it is worth experimenting to see empirically if convergence per sample slows down at the batch size necessary to achieve high performance FSDP. FSDP tends to achieve higher model FLOP utilization but if the convergence per sample slows as the batch size grows, pipeline parallelism may still be the better choice. Most workloads can tolerate sufficiently large batch sizes to not benefit from pipeline parallelism, but your workload may be different.\nIf pipeline parallelism is necessary, we recommend combining it with data parallelism or FSDP. This will enable you to minimize the pipeline depth while increasing the per pipeline batch size until DCN latency becomes less of a factor in throughput. Concretely, if you have N slices, consider pipelines of depth 2 and N/2 replicas of data parallelism, then pipelines of depth 4 and N/4 replicas of data parallelism and so on, until the batch per pipeline gets large enough that the DCN collectives can be hidden behind the arithmetic in the backwards pass. This will minimize the slowdown introduced by pipeline parallelism while allowing you to scale past the global batch size limit.\n## Multislice best practices\n### Data loading\nDuring training we repeatedly load batches from a dataset to feed into the model. Having an efficient, async data loader which shards the batch across hosts is important to avoid starving the TPUs of work. The current data loader in MaxText has each host load an equal subset of the examples. This solution is adequate for text but requires a reshard within the model. Additionally, MaxText doesn't yet offer deterministic snapshotting which would allow the data iterator to load the same data before and after preemption.\n### Checkpointing\nThe [Orbax](https://github.com/google/orbax) checkpointing library provides primitives for checkpointing JAX PyTrees to local storage or Google Cloud storage. We provide a reference integration with synchronous checkpointing into MaxText in `checkpointing.py` .\n## Supported configurations\n### Shapes\nAll slices must be of the same shape (for example, the same `AcceleratorType` ). Heterogeneous slice shapes are not supported.\n### Orchestration\nOrchestration is supported with GKE. For more information, see [TPUs in GKE](/tpu/docs/tpus-in-gke) .\n### Frameworks\nMultislice only supports JAX and PyTorch workloads.\n### Parallelism\nWe recommend users test Multislice with data parallelism. To learn more about implementing pipeline parallelism with Multislice, contact your Google Cloud account representative.\n## Support and Feedback\nWe welcome all feedback! To share feedback or request support, reach out to us using the [Cloud TPU Support or Feedback form](https://forms.gle/pLFRKSdWZ97o2o867) .", "guide": "Cloud TPU"}