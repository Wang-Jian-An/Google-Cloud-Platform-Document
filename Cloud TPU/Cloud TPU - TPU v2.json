{"title": "Cloud TPU - TPU v2", "url": "https://cloud.google.com/tpu/docs/v2?hl=zh-cn", "abstract": "# Cloud TPU - TPU v2\n# TPU v2\nThis document describes the architecture and supported configurations of Cloud TPU v2.\n", "content": "## System architecture\nArchitectural details and performance characteristics of TPU v2 are available in [A Domain Specific Supercomputer for Training Deep NeuralNetworks](https://dl.acm.org/doi/pdf/10.1145/3360307) .\n## Configurations\nA TPU v2 Pod is composed of 512 chips interconnected with reconfigurable high-speed links. To create a TPU v2 Pod slice, use the `--accelerator-type` flag in the TPU creation command ( `gcloud compute tpus tpu-vm` ). You specify the accelerator type by specifying the TPU version and the number of TPU cores. For example, for a single v2 TPU, use `--accelerator-type=v2-8` . For a v2 Pod slice with 128 TensorCores, use `--accelerator-type=v2-128` .\nThe following command shows how to create a v2 TPU Pod slice with 128 TensorCores:\n```\n\u00a0 $ gcloud compute tpus tpu-vm create tpu-name \\\u00a0 \u00a0 --zone=zone \\\u00a0 \u00a0 --accelerator-type=v2-128 \\\u00a0 \u00a0 --version=tpu-vm-tf-2.16.1-pjrt\n```\nFor more information about managing TPUs, see [ManageTPUs](/tpu/docs/managing-tpus-tpu-vm) . For more information about the TPU system architecture Cloud TPU, see [Systemarchitecture](/tpu/docs/system-architecture) .\nThe following table lists the supported v2 TPU types:\n| TPU version | Support ends   |\n|:--------------|:-----------------------|\n| v2-8   | (End date not yet set) |\n| v2-32   | (End date not yet set) |\n| v2-128  | (End date not yet set) |\n| v2-256  | (End date not yet set) |\n| v2-512  | (End date not yet set) |", "guide": "Cloud TPU"}