{"title": "Cloud TPU - \u4f7f\u7528 Ray \u64f4\u7e2e\u6a5f\u5668\u5b78\u7fd2\u5de5\u4f5c\u8ca0\u8f09", "url": "https://cloud.google.com/tpu/docs/ray-guide?hl=zh-cn", "abstract": "# Cloud TPU - \u4f7f\u7528 Ray \u64f4\u7e2e\u6a5f\u5668\u5b78\u7fd2\u5de5\u4f5c\u8ca0\u8f09\n# \u4f7f\u7528 Ray \u64f4\u7e2e\u6a5f\u5668\u5b78\u7fd2\u5de5\u4f5c\u8ca0\u8f09\n", "content": "## \u7c21\u4ecb\nCloud TPU Ray \u5de5\u5177\u7d50\u5408\u4e86 [Cloud TPU API](https://cloud.google.com/tpu/docs/reference/rest?hl=zh-cn) \u548c [Ray Job](https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html) \uff0c\u65e8\u5728\u6539\u5584\u7528\u6236\u5728 Cloud TPU \u4e0a\u7684\u958b\u767c\u9ad4\u9a57\u3002\u672c\u7528\u6236\u6307\u5357\u63d0\u4f9b\u4e86\u4e00\u500b\u6700\u5c0f\u793a\u4f8b\uff0c\u8aaa\u660e\u5982\u4f55\u5c07 [Ray](https://ray.io) \u8207 Cloud TPU \u642d\u914d\u4f7f\u7528\u3002\u9019\u4e9b\u793a\u4f8b\u50c5\u4f5c\u8aaa\u660e\u4e4b\u7528\uff0c\u4e0d\u61c9\u7528\u65bc\u751f\u7522\u670d\u52d9\u3002\n## \u6b64\u5de5\u5177\u5305\u542b\u54ea\u4e9b\u5167\u5bb9\uff1f\n\u7232\u65b9\u4fbf\u8d77\u898b\uff0c\u8a72\u5de5\u5177\u63d0\u4f9b\u4ee5\u4e0b\u529f\u80fd\uff1a\n- \u96b1\u85cf\u5e38\u898b TPU \u64cd\u4f5c\u7684\u6a23\u677f\u7684\u901a\u7528\u62bd\u8c61\n- \u53ef\u57fa\u65bc\u81ea\u5df1\u7684\u57fa\u672c\u5de5\u4f5c\u6d41\u7a0b\u5275\u5efa\u5206\u652f\u7684\u73a9\u5177\u793a\u4f8b\n\u5177\u9ad4\u800c\u8a00\uff1a\n- [tpu_api.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/tpu_api.py) \uff1a\u7528\u65bc\u4f7f\u7528 [Cloud TPU API](https://cloud.google.com/tpu/docs/reference/rest?hl=zh-cn) \u57f7\u884c\u57fa\u672c TPU \u64cd\u4f5c\u7684 Python \u5c01\u88dd\u5bb9\u5668\u3002\n- [tpu_controller.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/tpu_controller.py) \uff1aTPU \u7684\u985e\u8868\u793a\u6cd5\u3002\u9019\u672c\u8cea\u4e0a\u662f`tpu_api.py`\u7684\u5c01\u88dd\u5bb9\u5668\u3002\n- [ray_tpu_controller.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/ray_tpu_controller.py) \uff1a\u5177\u6709 Ray \u529f\u80fd\u7684 TPU \u63a7\u5236\u5668\u3002\u9019\u6703\u62bd\u8c61\u5316 Ray \u96c6\u7fa3\u548c Ray Job \u7684\u6a23\u677f\u6587\u4ef6\u3002\n- [run_basic_jax.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/run_basic_jax.py) \uff1a\u57fa\u672c\u793a\u4f8b\uff0c\u5c55\u793a\u77ad\u5982\u4f55\u5c0d`print(jax.device_count())`\u4f7f\u7528`RayTpuController`\u3002\n- [run_hp_search.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/src/tune/run_hp_search.py) \uff1a\u57fa\u672c\u793a\u4f8b\uff0c\u5c55\u793a\u77ad\u5982\u4f55\u5728 MNIST \u4e0a\u5c07 Ray Tune \u8207 JAX/Flax \u642d\u914d\u4f7f\u7528\u3002\n- [run_pax_autoresume.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/run_pax_autoresume.py) \uff1a\u6b64\u793a\u4f8b\u5c55\u793a\u77ad\u5982\u4f55\u4f7f\u7528 PAX \u4f5c\u7232\u793a\u4f8b\u5de5\u4f5c\u8ca0\u8f09\uff0c\u4f7f\u7528`RayTpuController`\u9032\u884c\u5bb9\u932f\u8a13\u7df4\u3002## \u8a2d\u7f6e Ray \u96c6\u7fa3\u982d\u7bc0\u9ede\n\u60a8\u53ef\u4ee5\u5c07 Ray \u8207 TPU Pod \u642d\u914d\u4f7f\u7528\u7684\u4e00\u7a2e\u57fa\u672c\u65b9\u6cd5\u662f\u5c07 TPU Pod \u8a2d\u7f6e\u7232 Ray \u96c6\u7fa3\u3002\u81ea\u7136\u800c\u7136\u7684\u662f\u5275\u5efa\u4e00\u500b\u55ae\u7368\u7684 CPU \u865b\u64ec\u6a5f\u4f5c\u7232\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u3002\u4e0b\u5716\u986f\u793a\u4e86 Ray \u96c6\u7fa3\u914d\u7f6e\u7684\u793a\u4f8b\uff1a\n\u4ee5\u4e0b\u547d\u4ee4\u5c55\u793a\u77ad\u5982\u4f55\u4f7f\u7528 Google Cloud CLI \u8a2d\u7f6e Ray \u96c6\u7fa3\uff1a\n```\n$ gcloud compute instances create my_tpu_admin --machine-type=n1-standard-4 ...$ gcloud compute ssh my_tpu_admin$ (vm) pip3 install ray[default]$ (vm) ray start --head --port=6379 --num-cpus=0...# (Ray returns the IP address of the HEAD node, for example, RAY_HEAD_IP)$ (vm) gcloud compute tpus tpu-vm create $TPU_NAME ... --metadata startup-script=\"pip3 install ray && ray start --address=$RAY_HEAD_IP --resources='{\\\"tpu_host\\\": 1}'\"\n```\n\u7232\u65b9\u4fbf\u8d77\u898b\uff0c\u6211\u5011\u9084\u63d0\u4f9b\u7528\u65bc\u5275\u5efa\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u4ee5\u53ca\u5c07\u6b64\u6587\u4ef6\u593e\u7684\u5167\u5bb9\u90e8\u7f72\u5230\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u7684\u57fa\u672c\u8173\u672c\u3002\u5982\u9700\u77ad\u89e3\u6e90\u4ee3\u78bc\uff0c\u8acb\u53c3\u95b1 [create_cpu.sh](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/create_cpu.sh) \u548c [deploy.sh](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/deploy.sh) \u3002\n\u9019\u4e9b\u8173\u672c\u6703\u8a2d\u7f6e\u4e00\u4e9b\u9ed8\u8a8d\u503c\uff1a\n- `create_cpu.sh`\u5c07\u5275\u5efa\u4e00\u500b\u540d\u7232`$USER-admin`\u7684\u865b\u64ec\u6a5f\uff0c\u4e26\u4f7f\u7528\u8a2d\u7f6e\u7232`gcloud config`\u9ed8\u8a8d\u503c\u7684\u4efb\u4f55\u9805\u76ee\u548c\u5340\u57df\u3002\u904b\u884c`gcloud config list`\u53ef\u67e5\u770b\u9019\u4e9b\u9ed8\u8a8d\u503c\u3002\n- `create_cpu.sh`\u9ed8\u8a8d\u5206\u914d\u5927\u5c0f\u7232 200GB \u7684\u5553\u52d5\u78c1\u76e4\u3002\n- `deploy.sh`\u5047\u5b9a\u60a8\u7684\u865b\u64ec\u6a5f\u540d\u7a31\u7232`$USER-admin`\u3002\u5982\u679c\u60a8\u5728`create_cpu.sh`\u4e2d\u66f4\u6539\u8a72\u503c\uff0c\u8acb\u52d9\u5fc5\u5728`deploy.sh`\u4e2d\u9032\u884c\u66f4\u6539\u3002\n\u8981\u4f7f\u7528\u4fbf\u6377\u8173\u672c\uff0c\u8acb\u57f7\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a\n- \u5c07 GitHub \u4ee3\u78bc\u5eab\u514b\u9686\u5230\u672c\u5730\u6a5f\u5668\u4e26\u8f38\u5165 `ray_tpu` \u6587\u4ef6\u593e\uff1a```\n$ git clone https://github.com/tensorflow/tpu.git$ cd tpu/tools/ray_tpu/\n```\n- \u5982\u679c\u60a8\u6c92\u6709\u7528\u65bc\u7ba1\u7406 TPU \u7684\u5c08\u7528\u670d\u52d9\u5e33\u865f\uff08\u5f37\u70c8\u5efa\u8b70\uff09\uff0c\u8acb\u8a2d\u7f6e\u4e00\u500b\uff1a```\n$ ./create_tpu_service_account.sh\n``` **\u6ce8\u610f** \uff1a\u6b64\u8173\u672c\u53ea\u9700\u904b\u884c\u4e00\u6b21\u3002\n- \u5275\u5efa\u5354\u8abf\u5668\u865b\u64ec\u6a5f\uff1a```\n$ ./create_cpu.sh\n```\u6b64\u8173\u672c\u4f7f\u7528 [\u5553\u52d5\u8173\u672c](https://cloud.google.com/compute/docs/instances/startup-scripts/linux?hl=zh-cn) \u5728\u865b\u64ec\u6a5f\u4e0a\u5b89\u88dd\u4f9d\u8cf4\u9805\uff0c\u4e26\u81ea\u52d5\u963b\u6b62\uff0c\u76f4\u5230\u5553\u52d5\u8173\u672c\u5b8c\u6210\u3002\n- \u5c07\u672c\u5730\u4ee3\u78bc\u90e8\u7f72\u5230\u5354\u8abf\u5668\u865b\u64ec\u6a5f\uff1a```\n$ ./deploy.sh\n```\n- \u901a\u904e SSH \u9023\u63a5\u5230\u865b\u64ec\u6a5f\uff1a```\n$ gcloud compute ssh $USER-admin -- -L8265:localhost:8265\n```\u6b64\u8655\u5553\u7528\u4e86\u7aef\u53e3\u8f49\u767c\uff0c\u56e0\u7232 Ray \u6703\u81ea\u52d5\u5728\u7aef\u53e3 8265 \u5553\u52d5\u4fe1\u606f\u4e2d\u5fc3\u3002\u60a8\u53ef\u4ee5\u5f9e\u901a\u904e SSH \u9023\u63a5\u5230\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u7684\u6a5f\u5668\uff0c\u901a\u904e [http://127.0.0.1:8265/](http://127.0.0.1:8265/) \u8a2a\u554f\u6b64\u4fe1\u606f\u4e2d\u5fc3\u3002\n- \u5982\u679c\u60a8\u8df3\u904e\u4e86\u7b2c 0 \u6b65\uff0c\u8acb\u5728 CPU \u865b\u64ec\u6a5f\u4e2d\u8a2d\u7f6e gcloud \u6191\u64da\uff1a```\n$ (vm) gcloud auth login --update-adc\n```\u6b64\u6b65\u9a5f\u6703\u8a2d\u7f6e\u9805\u76ee ID \u4fe1\u606f\u4e26\u5141\u8a31 Cloud TPU API \u5728\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u4e0a\u904b\u884c\u3002 **\u6ce8\u610f** \uff1a\u6b64\u547d\u4ee4\u6703\u6388\u6b0a\u60a8\u7684\u865b\u64ec\u6a5f\u5be6\u4f8b\u4f7f\u7528\u60a8\u7684\u500b\u4eba Google \u5e33\u865f\uff0c\u9019\u5728\u751f\u7522\u8a2d\u7f6e\u4e2d\u53ef\u80fd\u5b58\u5728\u5b89\u5168\u98a8\u96aa\u3002\n- \u5b89\u88dd\u8981\u6c42\uff1a```\n$ (vm) pip3 install -r src/requirements.txt\n```\n- \u5728\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u4e0a\u5553\u52d5 Ray\uff0c\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u5c07\u6210\u7232 Ray \u96c6\u7fa3\u7684\u982d\u7bc0\u9ede\uff1a```\n$ (vm) ray start --head --port=6379 --num-cpus=0\n``` **\u6ce8\u610f** \uff1a--num-cpus=0 \u53ef\u907f\u514d\u5728\u5354\u8abf\u5668\u865b\u64ec\u6a5f\u4e0a\u8abf\u5ea6 CPU \u4f5c\u696d\uff08\u5982\u6027\u80fd\u5206\u6790\uff09\u3002## \u7528\u6cd5\u793a\u4f8b\n### \u57fa\u672c JAX \u793a\u4f8b\n[run_basic_jax.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/run_basic_jax.py) \u662f\u4e00\u500b\u6975\u7232\u7c21\u55ae\u7684\u793a\u4f8b\uff0c\u6f14\u793a\u77ad\u5982\u4f55\u5728\u5177\u6709 TPU \u865b\u64ec\u6a5f\u7684 Ray \u96c6\u7fa3\u4e0a\u4f7f\u7528 Ray Job \u548c Ray \u904b\u884c\u6642\u74b0\u5883\u4f86\u904b\u884c JAX \u5de5\u4f5c\u8ca0\u8f09\u3002\n\u5c0d\u65bc\u8207\u4f7f\u7528\u591a\u63a7\u5236\u5668\u7de8\u7a0b\u6a21\u578b\uff08\u4f8b\u5982 JAX \u548c PyTorch/XLA PJRT\uff09\u7684 Cloud TPU \u517c\u5bb9\u7684\u6a5f\u5668\u5b78\u7fd2\u6846\u67b6\uff0c\u60a8\u5fc5\u9808\u7232\u6bcf\u500b\u4e3b\u6a5f\u904b\u884c\u81f3\u5c11\u4e00\u500b\u9032\u7a0b\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u591a\u9032\u7a0b\u7de8\u7a0b\u6a21\u578b](https://jax.readthedocs.io/en/latest/multi_process.html#multi-process-programming-model) \u3002\u5728\u5be6\u8e10\u4e2d\uff0c\u9019\u53ef\u80fd\u5982\u4e0b\u6240\u793a\uff1a\n```\n$ gcloud compute tpus tpu-vm scp my_bug_free_python_code my_tpu:~/ --worker=all$ gcloud compute tpus tpu-vm ssh my_tpu --worker=all --command=\"python3 ~/my_bug_free_python_code/main.py\"\n```\n\u5982\u679c\u60a8\u7684\u4e3b\u6a5f\u8d85\u904e 16 \u500b\u4ee5\u4e0a\uff08\u4f8b\u5982 v4-128\uff09\uff0c\u60a8\u5c07\u9047\u5230 SSH \u53ef\u4f38\u7e2e\u6027\u554f\u984c\uff0c\u4e26\u4e14\u60a8\u7684\u547d\u4ee4\u53ef\u80fd\u5fc5\u9808\u66f4\u6539\u7232\uff1a\n```\n$ gcloud compute tpus tpu-vm scp my_bug_free_python_code my_tpu:~/ --worker=all --batch-size=8$ gcloud compute tpus tpu-vm ssh my_tpu --worker=all --command=\"python3 ~/my_bug_free_python_code/main.py &\" --batch-size=8\n```\n\u5982\u679c `my_bug_free_python_code` \u5305\u542b bug\uff0c\u9019\u53ef\u80fd\u6703\u59a8\u7919\u958b\u767c\u8005\u7684\u901f\u5ea6\u3002\u89e3\u6c7a\u6b64\u554f\u984c\u7684\u4e00\u7a2e\u65b9\u6cd5\u662f\u4f7f\u7528 Kubernetes \u6216 Ray \u7b49 Orchestrator\u3002Ray \u5305\u542b [\u904b\u884c\u6642\u74b0\u5883](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html#runtime-environments) \u7684\u6982\u5ff5\uff0c\u4f7f\u7528\u8a72\u74b0\u5883\u5f8c\uff0c\u8a72\u74b0\u5883\u6703\u5728 Ray \u61c9\u7528\u904b\u884c\u6642\u90e8\u7f72\u4ee3\u78bc\u548c\u4f9d\u8cf4\u9805\u3002\n\u901a\u904e\u5c07 Ray \u904b\u884c\u6642\u74b0\u5883\u8207 Ray \u96c6\u7fa3\u548c Ray Job \u76f8\u7d50\u5408\uff0c\u60a8\u53ef\u4ee5\u7e5e\u904e SCP/SSH \u9031\u671f\u3002\u5047\u8a2d\u60a8\u9075\u5faa\u4e86\u4e0a\u8ff0\u793a\u4f8b\uff0c\u5247\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u78bc\u904b\u884c\u6b64\u64cd\u4f5c\uff1a\n```\n$ python3 legacy/run_basic_jax.py\n```\n\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a\n```\n2023-03-01 22:12:10,065 \u00a0 INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 10.130.0.19:6379...2023-03-01 22:12:10,072 \u00a0 INFO worker.py:1544 -- Connected to Ray cluster. View the dashboard at http://127.0.0.1:8265W0301 22:12:11.148555 140341931026240 ray_tpu_controller.py:143] TPU is not found, create tpu...Creating TPU: \u00a0$USER-ray-testRequest: \u00a0{'accelerator_config': {'topology': '2x2x2', 'type': 'V4'}, 'runtimeVersion': 'tpu-ubuntu2204-base', 'networkConfig': {'enableExternalIps': True}, 'metadata': {'startup-script': '#! /bin/bash\\necho \"hello world\"\\nmkdir -p /dev/shm\\nsudo mount -t tmpfs -o size=100g tmpfs /dev/shm\\n pip3 install ray[default]\\nray start --resources=\\'{\"tpu_host\": 1}\\' --address=10.130.0.19:6379'}}Create TPU operation still running......Create TPU operation complete.I0301 22:13:17.795493 140341931026240 ray_tpu_controller.py:121] Detected 0 TPU hosts in cluster, expecting 2 hosts in totalI0301 22:13:17.795823 140341931026240 ray_tpu_controller.py:160] Waiting for 30s for TPU hosts to join cluster...\u2026I0301 22:15:17.986352 140341931026240 ray_tpu_controller.py:121] Detected 2 TPU hosts in cluster, expecting 2 hosts in totalI0301 22:15:17.986503 140341931026240 ray_tpu_controller.py:90] Ray already started on each host.2023-03-01 22:15:18,010 \u00a0 INFO dashboard_sdk.py:315 -- Uploading package gcs://_ray_pkg_3599972ae38ce933.zip.2023-03-01 22:15:18,010 \u00a0 INFO packaging.py:503 -- Creating a file package for local directory '/home/$USER/src'.2023-03-01 22:15:18,080 \u00a0 INFO dashboard_sdk.py:362 -- Package gcs://_ray_pkg_3599972ae38ce933.zip already exists, skipping upload.I0301 22:15:18.455581 140341931026240 ray_tpu_controller.py:169] Queued 2 jobs....I0301 22:15:48.523541 140341931026240 ray_tpu_controller.py:254] [ADMIN]: raysubmit_WRUtVB7nMaRTgK39: Status is SUCCEEDEDI0301 22:15:48.561111 140341931026240 ray_tpu_controller.py:256] [raysubmit_WRUtVB7nMaRTgK39]: E0301 22:15:36.294834089 \u00a0 21286 credentials_generic.cc:35] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Could not get HOME environment variable.8I0301 22:15:58.575289 140341931026240 ray_tpu_controller.py:254] [ADMIN]: raysubmit_yPCPXHiFgaCK2rBY: Status is SUCCEEDEDI0301 22:15:58.584667 140341931026240 ray_tpu_controller.py:256] [raysubmit_yPCPXHiFgaCK2rBY]: E0301 22:15:35.720800499 \u00a0 \u00a08561 credentials_generic.cc:35] \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0Could not get HOME environment variable.8\n```\n### \u5bb9\u932f\u8a13\u7df4\n\u4ee5\u4e0b\u793a\u4f8b\u5c55\u793a\u77ad\u5982\u4f55\u4f7f\u7528 `RayTpuController` \u5be6\u73fe\u5bb9\u932f\u8a13\u7df4\u3002\u5728\u6b64\u793a\u4f8b\u4e2d\uff0c\u6211\u5011\u5728 v4-16 \u4e0a\u7684 [PAX](https://github.com/google/paxml) \u4e0a\u9810\u8a13\u7df4\u4e00\u500b\u7c21\u55ae\u7684 LLM\uff0c\u4f46\u8acb\u6ce8\u610f\uff0c\u60a8\u53ef\u4ee5\u5c07\u6b64 PAX \u5de5\u4f5c\u8ca0\u8f09\u66ff\u63db\u7232\u4efb\u4f55\u5176\u4ed6\u9577\u6642\u9593\u904b\u884c\u7684\u5de5\u4f5c\u8ca0\u8f09\u3002\u5982\u9700\u77ad\u89e3\u6e90\u4ee3\u78bc\uff0c\u8acb\u53c3\u95b1 [run_pax_autoresume.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/legacy/run_basic_jax.py) \u3002\n\u5982\u9700\u904b\u884c\u6b64\u793a\u4f8b\uff0c\u8acb\u57f7\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a\n- \u5c07 `paxml` \u514b\u9686\u5230\u5354\u8abf\u8005\u865b\u64ec\u6a5f\uff1a```\n$ git clone https://github.com/google/paxml.git\n```\u7232\u4e86\u6f14\u793a Ray \u904b\u884c\u6642\u74b0\u5883\u5728\u9032\u884c\u548c\u90e8\u7f72 JAX \u66f4\u6539\u6642\u63d0\u4f9b\u7684\u6613\u7528\u6027\uff0c\u6b64\u793a\u4f8b\u8981\u6c42\u60a8\u4fee\u6539 PAX\u3002\n- \u6dfb\u52a0\u65b0\u7684\u5be6\u9a57\u914d\u7f6e\uff1a```\n$ cat <<EOT >> paxml/paxml/tasks/lm/params/lm_cloud.py\n@experiment_registry.register\nclass TestModel(LmCloudSpmd2BLimitSteps):\nICI_MESH_SHAPE = [1, 4, 2]\nCHECKPOINT_POLICY = layers.AutodiffCheckpointType.SAVE_CONTEXT_AND_OUT_PROJ\ndef task(self) -> tasks_lib.SingleTask.HParams:\n task_p = super().task()\n task_p.train.num_train_steps = 1000\n task_p.train.save_interval_steps = 100\n return task_p\nEOT\n```\n- \u904b\u884c `run_pax_autoresume.py` \uff1a```\n$ python3 legacy/run_pax_autoresume.py --model_dir=gs://your/gcs/bucket\n```\n- \u5728\u5de5\u4f5c\u8ca0\u8f09\u904b\u884c\u6642\uff0c\u5617\u8a66\u9ed8\u8a8d\u522a\u9664 TPU\uff08\u540d\u7232 `$USER-tpu-ray` \uff09\u5f8c\u6703\u767c\u751f\u4ec0\u9ebc\u60c5\u6cc1\uff1a```\n$ gcloud compute tpus tpu-vm delete -q $USER-tpu-ray --zone=us-central2-b\n```Ray \u5c07\u901a\u904e\u4ee5\u4e0b\u6d88\u606f\u6aa2\u6e2c\u5230 TPU \u5df2\u5b95\u6a5f\uff1a```\nI0303 05:12:47.384248 140280737294144 checkpointer.py:64] Saving item to gs://$USER-us-central2/pax/v4-16-autoresume-test/checkpoints/checkpoint_00000200/metadata.W0303 05:15:17.707648 140051311609600 ray_tpu_controller.py:127] TPU is not found, create tpu...2023-03-03 05:15:30,774 WARNING worker.py:1866 -- The node with node id: 9426f44574cce4866be798cfed308f2d3e21ba69487d422872cdd6e3 and address: 10.130.0.113 and node name: 10.130.0.113 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \u00a0 \u00a0 \u00a0 (1) raylet crashes unexpectedly (OOM, preempted node, etc.)\u00a0 \u00a0 \u00a0 (2) raylet has lagging heartbeats due to slow network or busy workload.2023-03-03 05:15:33,243 WARNING worker.py:1866 -- The node with node id: 214f5e4656d1ef48f99148ddde46448253fe18672534467ee94b02ba and address: 10.130.0.114 and node name: 10.130.0.114 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \u00a0 \u00a0 \u00a0 (1) raylet crashes unexpectedly (OOM, preempted node, etc.)\u00a0 \u00a0 \u00a0 (2) raylet has lagging heartbeats due to slow network or busy workload.\n```\u8a72\u4f5c\u696d\u5c07\u81ea\u52d5\u91cd\u65b0\u5275\u5efa TPU \u865b\u64ec\u6a5f\u4e26\u91cd\u5553\u8a13\u7df4\u4f5c\u696d\uff0c\u4ee5\u4fbf\u5f9e\u6700\u65b0\u7684\u6aa2\u67e5\u9ede\uff08\u672c\u4f8b\u4e2d\u7232 200 \u6b65\uff09\u7e7c\u7e8c\u8a13\u7df4\uff1a```\nI0303 05:22:43.141277 140226398705472 train.py:1149] Training loop starting...I0303 05:22:43.141381 140226398705472 summary_utils.py:267] Opening SummaryWriter `gs://$USER-us-central2/pax/v4-16-autoresume-test/summaries/train`...I0303 05:22:43.353654 140226398705472 summary_utils.py:267] Opening SummaryWriter `gs://$USER-us-central2/pax/v4-16-autoresume-test/summaries/eval_train`...I0303 05:22:44.008952 140226398705472 py_utils.py:350] Starting sync_global_devices Start training loop from step: 200 across 8 devices globally\n```\n### \u8d85\u53c3\u6578\u641c\u7d22\n\u6b64\u793a\u4f8b\u6f14\u793a\u77ad\u5982\u4f55\u4f7f\u7528 Ray AIR \u4e2d\u7684 Ray Tune \u901a\u904e JAX/FLAX \u9032\u884c\u8d85\u53c3\u6578\u8abf\u512a MNIST\u3002\u5982\u9700\u77ad\u89e3\u6e90\u4ee3\u78bc\uff0c\u8acb\u53c3\u95b1 [run_hp_search.py](https://github.com/tensorflow/tpu/blob/master/tools/ray_tpu/src/tune/run_hp_search.py) \u3002\n\u5982\u9700\u904b\u884c\u6b64\u793a\u4f8b\uff0c\u8acb\u57f7\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a\n- \u5b89\u88dd\u8981\u6c42\uff1a```\n$ pip3 install -r src/tune/requirements.txt\n```\n- \u904b\u884c `run_hp_search.py` \uff1a```\n$ python3 src/tune/run_hp_search.py\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\nNumber of trials: 3/3 (3 TERMINATED)+-----------------------------+------------+-------------------+-----------------+------------+--------+--------+------------------+| Trial name \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0| status \u00a0 \u00a0 | loc \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 | \u00a0 learning_rate | \u00a0 momentum | \u00a0 \u00a0acc | \u00a0 iter | \u00a0 total time (s) ||-----------------------------+------------+-------------------+-----------------+------------+--------+--------+------------------|| hp_search_mnist_8cbbb_00000 | TERMINATED | 10.130.0.84:21340 | \u00a0 \u00a0 1.15258e-09 | \u00a0 0.897988 | 0.0982 | \u00a0 \u00a0 \u00a03 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a082.4525 || hp_search_mnist_8cbbb_00001 | TERMINATED | 10.130.0.84:21340 | \u00a0 \u00a0 0.000219523 | \u00a0 0.825463 | 0.1009 | \u00a0 \u00a0 \u00a03 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a073.1168 || hp_search_mnist_8cbbb_00002 | TERMINATED | 10.130.0.84:21340 | \u00a0 \u00a0 1.08035e-08 | \u00a0 0.660416 | 0.098 \u00a0| \u00a0 \u00a0 \u00a03 | \u00a0 \u00a0 \u00a0 \u00a0 \u00a071.6813 |+-----------------------------+------------+-------------------+-----------------+------------+--------+--------+------------------+2023-03-02 21:50:47,378 \u00a0 INFO tune.py:798 -- Total run time: 318.07 seconds (318.01 seconds for the tuning loop)....\n```## \u554f\u984c\u6392\u67e5\n### Ray \u982d\u7bc0\u9ede\u7121\u6cd5\u9023\u63a5\n\u5982\u679c\u60a8\u904b\u884c\u7684\u5de5\u4f5c\u8ca0\u8f09\u6703\u5275\u5efa/\u522a\u9664 TPU \u751f\u547d\u9031\u671f\uff0c\u6709\u6642\u9019\u4e0d\u6703\u65b7\u958b TPU \u4e3b\u6a5f\u8207 Ray \u96c6\u7fa3\u7684\u9023\u63a5\u3002\u9019\u53ef\u80fd\u986f\u793a\u7232 gRPC \u932f\u8aa4\uff0c\u6307\u793a Ray \u982d\u7bc0\u9ede\u7121\u6cd5\u9023\u63a5\u5230\u4e00\u7d44 IP \u5730\u5740\u3002\n\u56e0\u6b64\uff0c\u60a8\u53ef\u80fd\u9700\u8981\u7d42\u6b62\u5149\u7dda\u6703\u8a71 ( `ray stop` ) \u4e26\u91cd\u5553 ( `ray start --head --port=6379 --num-cpus=0` )\u3002\n### Ray \u4f5c\u696d\u76f4\u63a5\u5931\u6557\uff0c\u6c92\u6709\u4efb\u4f55\u65e5\u8a8c\u8f38\u51fa\nPAX \u76ee\u524d\u8655\u65bc\u5be6\u9a57\u968e\u6bb5\uff0c\u6b64\u793a\u4f8b\u53ef\u80fd\u6703\u56e0\u7232 pip \u4f9d\u8cf4\u9805\u800c\u4e2d\u65b7\u3002\u5982\u679c\u767c\u751f\u9019\u7a2e\u60c5\u6cc1\uff0c\u60a8\u53ef\u80fd\u6703\u770b\u5230\u5982\u4e0b\u5167\u5bb9\uff1a\n```\nI0303 20:50:36.084963 140306486654720 ray_tpu_controller.py:174] Queued 2 jobs.I0303 20:50:36.136786 140306486654720 ray_tpu_controller.py:238] Requested to clean up 1 stale jobs from previous failures.I0303 20:50:36.148653 140306486654720 ray_tpu_controller.py:253] Job status: Counter({<JobStatus.FAILED: 'FAILED'>: 2})I0303 20:51:38.582798 140306486654720 ray_tpu_controller.py:126] Detected 2 TPU hosts in cluster, expecting 2 hosts in totalW0303 20:51:38.589029 140306486654720 ray_tpu_controller.py:196] Detected job raysubmit_8j85YLdHH9pPrmuz FAILED.2023-03-03 20:51:38,641 \u00a0 INFO dashboard_sdk.py:362 -- Package gcs://_ray_pkg_ae3cacd575e24531.zip already exists, skipping upload.2023-03-03 20:51:38,706 \u00a0 INFO dashboard_sdk.py:362 -- Package gcs://_ray_pkg_ae3cacd575e24531.zip already exists, skipping upload.\n```\n\u5982\u9700\u67e5\u770b\u932f\u8aa4\u7684\u6839\u672c\u539f\u56e0\uff0c\u8acb\u8f49\u5230 [http://127.0.0.1:8265/](http://127.0.0.1:8265/) \u4e26\u67e5\u770b\u6b63\u5728\u904b\u884c/\u5931\u6557\u4f5c\u696d\u7684\u4fe1\u606f\u4e2d\u5fc3\uff0c\u5176\u4e2d\u6703\u63d0\u4f9b\u66f4\u591a\u4fe1\u606f\u3002 `runtime_env_agent.log` \u6703\u986f\u793a\u8207 Runtime_env \u8a2d\u7f6e\u76f8\u95dc\u7684\u6240\u6709\u932f\u8aa4\u4fe1\u606f\uff0c\u4f8b\u5982\uff1a\n```\n60 \u00a0 \u00a0INFO: pip is looking at multiple versions of \n```", "guide": "Cloud TPU"}