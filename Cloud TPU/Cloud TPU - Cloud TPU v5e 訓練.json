{"title": "Cloud TPU - Cloud TPU v5e \u8a13\u7df4", "url": "https://cloud.google.com/tpu/docs/v5e-training?hl=zh-cn", "abstract": "# Cloud TPU - Cloud TPU v5e \u8a13\u7df4\n# Cloud TPU v5e \u8a13\u7df4\nCloud TPU v5e \u662f Google Cloud \u6700\u65b0\u4e00\u4ee3 AI \u52a0\u901f\u5668\u3002\u6bcf\u500b Pod \u4f54\u7528\u7684 256 \u500b\u82af\u7247\u66f4\u5c11\uff0cv5e \u7d93\u904e\u512a\u5316\uff0c\u662f Transformer\u3001\u6587\u672c\u5230\u5716\u50cf\u548c\u5377\u7a4d\u795e\u7d93\u7db2\u7d61 (CNN) \u8a13\u7df4\u3001\u5fae\u8abf\u548c\u50b3\u9001\u7684\u6700\u5177\u50f9\u503c\u7684\u7522\u54c1\u3002\n", "content": "## Cloud TPU v5e \u6982\u5ff5\u3001\u7cfb\u7d71\u67b6\u69cb\u548c\u914d\u7f6e\n\u5982\u679c\u60a8\u525b\u958b\u59cb\u63a5\u89f8 Cloud TPU\uff0c\u8acb\u67e5\u770b [TPU \u6587\u6a94\u9996\u9801](https://cloud.google.com/tpu/docs?hl=zh-cn) \u3002\n[Cloud TPU \u7cfb\u7d71\u67b6\u69cb](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm?hl=zh-cn) \u9801\u9762\u4ecb\u7d39\u4e86\u4e00\u822c Cloud TPU \u6982\u5ff5\uff08\u4f8b\u5982\u5207\u7247\u3001\u4e3b\u6a5f\u3001\u82af\u7247\u548c TensorCore\uff09\u4ee5\u53ca Cloud TPU \u7cfb\u7d71\u67b6\u69cb\u3002\n\u6bcf\u500b Cloud TPU \u7248\u672c\u90fd\u9700\u8981\u7279\u5b9a\u7684\u52a0\u901f\u5668\u985e\u578b\u4f86\u9032\u884c\u8a13\u7df4\u548c\u63a8\u65b7\u3002 [TPU \u914d\u7f6e](https://cloud.google.com/tpu/docs/supported-tpu-configurations?hl=zh-cn) \u9801\u9762\u4ecb\u7d39\u4e86\u9019\u4e9b\u52a0\u901f\u5668\u985e\u578b\u3002\n### \u63a8\u65b7\n\u63a8\u65b7\u662f\u4f7f\u7528\u8a13\u7df4\u597d\u7684\u6a21\u578b\u5c0d\u65b0\u6578\u64da\u9032\u884c\u9810\u6e2c\u7684\u904e\u7a0b\u3002\u4f9b [\u50b3\u9001](#serving) \u9032\u7a0b\u4f7f\u7528\u3002\n### \u5207\u7247\n\u4e00\u500b\u5207\u7247\u8868\u793a\u5168\u90e8\u4f4d\u65bc\u540c\u4e00\u500b Pod \u5167\u901a\u904e\u9ad8\u901f\u82af\u7247\u9593\u4e92\u9023 (ICI) \u9023\u63a5\u7684\u82af\u7247\u7684\u96c6\u5408\u3002v5e \u5177\u6709 2D \u5207\u7247\u5f62\u72c0\u3002\u5982\u9700\u77ad\u89e3\u652f\u6301\u7684\u5207\u7247\u5f62\u72c0\uff0c\u8acb\u53c3\u95b1 [\u52a0\u901f\u5668\u985e\u578b](https://cloud.google.com/tpu/docs/supported-tpu-configurations?hl=zh-cn#tpu-v5e-config) \u90e8\u5206\u4e2d\u7684\u8868\u683c\u3002\n\u548c \u4e5f\u662f\u6307\u5207\u7247\u5f62\u72c0\u3002\n### \u63d0\u4f9b\u670d\u52d9\n\u670d\u52d9\u662f\u5c07\u7d93\u904e\u8a13\u7df4\u7684\u6a5f\u5668\u5b78\u7fd2\u6a21\u578b\u90e8\u7f72\u5230\u751f\u7522\u74b0\u5883\u7684\u904e\u7a0b\uff0c\u5728\u8a72\u74b0\u5883\u4e2d\uff0c\u6a21\u578b\u53ef\u7528\u65bc\u9032\u884c\u9810\u6e2c\u6216\u6c7a\u7b56\u3002\u5ef6\u9072\u6642\u9593\u548c\u670d\u52d9\u7d1a\u53ef\u7528\u6027\u5c0d\u65bc\u670d\u52d9\u5f88\u91cd\u8981\u3002\n### \u55ae\u500b\u4e3b\u6a5f\u8207\u591a\u4e3b\u6a5f\n\u4e3b\u6a5f\u662f\u904b\u884c\u865b\u64ec\u6a5f\u7684\u7269\u7406\u8a08\u7b97\u6a5f (CPU)\u3002\u4e00\u500b\u4e3b\u6a5f\u53ef\u4ee5\u540c\u6642\u904b\u884c\u591a\u500b\u865b\u64ec\u6a5f\u3002\n\u4f7f\u7528\u5c11\u65bc 8 \u500b\u689d\u72c0\u6a19\u7c64\u7684\u5207\u7247\u6700\u591a\u4f7f\u7528\u4e00\u500b\u4e3b\u6a5f\u3002\u8d85\u904e 8 \u500b\u82af\u7247\u7684\u5207\u7247\u53ef\u4ee5\u8a2a\u554f\u591a\u500b\u4e3b\u6a5f\uff0c\u4e26\u4e14\u53ef\u4ee5\u4f7f\u7528\u591a\u500b\u4e3b\u6a5f\u904b\u884c\u5206\u4f48\u5f0f\u8a13\u7df4\u3002\u5982\u9700\u8a73\u7d30\u77ad\u89e3\u5207\u7247\u548c\u82af\u7247\uff0c\u8acb\u53c3\u95b1 [TPU \u7cfb\u7d71\u67b6\u69cb](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm?hl=zh-cn) \u9801\u9762\u3002\nv5e \u652f\u6301\u591a\u4e3b\u6a5f\u8a13\u7df4\u548c\u591a\u4e3b\u6a5f\u63a8\u7406\uff08\u4f7f\u7528 [SAX](https://github.com/google/saxml) \uff09\u3002\n### TPU \u865b\u64ec\u6a5f\n\u904b\u884c Linux \u7684\u865b\u64ec\u6a5f\uff0c\u80fd\u5920\u8a2a\u554f\u5e95\u5c64 TPU\u3002\u5c0d\u65bc v5e TPU\uff0c\u6bcf\u500b TPU \u865b\u64ec\u6a5f\u53ef\u4ee5\u76f4\u63a5\u8a2a\u554f 1\u30014 \u6216 8 \u500b\u82af\u7247\uff0c\u5177\u9ad4\u53d6\u6c7a\u65bc\u7528\u6236\u6307\u5b9a\u7684\u52a0\u901f\u5668\u985e\u578b\u3002TPU \u865b\u64ec\u6a5f\u4e5f\u7a31\u7232\u201c\u5de5\u4f5c\u5668\u201d\u3002\n### \u5de5\u4f5c\u5668\n\u8acb\u53c3\u95b1 [TPU \u865b\u64ec\u6a5f](#tpu-vm) \u3002\n## \u958b\u59cb\u4f7f\u7528\n\u5982\u9700\u77ad\u89e3 v5e TPU \u786c\u4ef6\uff0c\u8acb\u53c3\u95b1 [\u7cfb\u7d71\u67b6\u69cb](https://cloud.google.com/tpu/docs/system-architecture-tpu-vm?hl=zh-cn) \u3002\n### \u4fdd\u969c\u5bb9\u91cf\n\u806f\u7e6b [Cloud \u92b7\u552e\u5718\u968a](https://cloud.google.com/contact?hl=zh-cn) \uff0c\u958b\u59cb\u4f7f\u7528 Cloud TPU v5e \u8655\u7406 AI \u5de5\u4f5c\u8ca0\u8f09\u3002\n### \u6e96\u5099 Google Cloud \u9805\u76ee\n- [\u767b\u9304](https://accounts.google.com/Login?hl=zh-cn) \u60a8\u7684 Google \u8cec\u865f\u3002 \u5982\u679c\u60a8\u5c1a\u672a [\u8a3b\u518a\u65b0\u5e33\u865f](https://accounts.google.com/SignUp?hl=zh-cn) \uff0c\u8acb\u5148\u8a3b\u518a\u3002\n- \u5728 [Google Cloud \u63a7\u5236\u6aaf](https://console.cloud.google.com/?hl=zh-cn) \u4e2d\uff0c\u5f9e\u9805\u76ee\u9078\u64c7\u5668\u9801\u9762 [\u9078\u64c7](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#get_an_existing_project) \u6216 [\u5275\u5efa](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#creating_a_project) Google Cloud \u9805\u76ee\u3002\n- \u6240\u6709 Google Cloud \u7528\u91cf\u90fd\u9700\u8981 [\u7d50\u7b97\u8a2d\u7f6e](https://cloud.google.com/billing/docs?hl=zh-cn) \uff0c\u56e0\u6b64\u8acb\u78ba\u4fdd\u60a8\u7684\u9805\u76ee\u5df2\u5553\u7528\u7d50\u7b97\u529f\u80fd\u3002\n- \u5b89\u88dd [gcloud alpha components](https://cloud.google.com/sdk/gcloud/reference/components/install?hl=zh-cn) \u3002\n- \u5982\u679c\u60a8\u662f\u91cd\u8907\u4f7f\u7528\u73fe\u6709 `gcloud alpha` \u7d44\u4ef6\u7684 TPU \u7528\u6236\uff0c\u8acb\u66f4\u65b0\u9019\u4e9b\u7d44\u4ef6\u4ee5\u78ba\u4fdd\u76f8\u95dc\u547d\u4ee4\u548c\u6a19\u8a8c\u53d7\u652f\u6301\uff1a```\ngcloud components update\n```\n- \u5728 Cloud Shell \u4e2d\u901a\u904e\u4ee5\u4e0b `gcloud` \u547d\u4ee4\u5553\u7528 TPU API\u3002\uff08\u60a8\u4e5f\u53ef\u4ee5 [\u901a\u904e Google Cloud \u63a7\u5236\u6aaf](https://console.cloud.google.com/apis/library/tpu.googleapis.com?hl=zh-cn) \u5553\u7528\u8a72\u529f\u80fd\u3002\uff09```\ngcloud services enable tpu.googleapis.com\n```\n- \u5553\u7528 TPU \u670d\u52d9\u5e33\u865f\u3002\u670d\u52d9\u5e33\u865f\u5141\u8a31 Cloud TPU \u670d\u52d9\u8a2a\u554f\u5176\u4ed6 Google Cloud \u670d\u52d9\u3002\u5efa\u8b70\u4f7f\u7528\u7528\u6236\u4ee3\u7ba1\u5f0f\u670d\u52d9\u5e33\u865f\u3002\u8acb\u6309\u7167\u76f8\u95dc\u6307\u5357 [\u5275\u5efa](https://cloud.google.com/iam/docs/service-accounts-create?hl=zh-cn) \u548c [\u6388\u4e88\u89d2\u8272](https://cloud.google.com/iam/docs/granting-changing-revoking-access?hl=zh-cn) \u3002\u4ee5\u4e0b\u89d2\u8272\u5fc5\u4e0d\u53ef\u5c11\uff1a- TPU Admin\n- Storage Admin\uff1a\u8a2a\u554f Cloud Storage \u6642\u9700\u8981\n- Logs Writer\uff1a\u4f7f\u7528 Logging API \u5beb\u5165\u65e5\u8a8c\u6642\u9700\u8981\n- Monitoring Metric Writer\uff1a\u5c07\u6307\u6a19\u5beb\u5165 Cloud Monitoring \u6642\u9700\u8981\u7528\u5230\n- \u914d\u7f6e\u9805\u76ee\u548c\u5340\u57df\u3002\u60a8\u7684\u9805\u76ee ID \u662f [Cloud \u63a7\u5236\u6aaf\u4e0a\u986f\u793a\u7684](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#identifying_projects) \u9805\u76ee\u540d\u7a31\u3002```\nexport PROJECT_ID=your-project-idexport ZONE=us-west4-agcloud alpha compute tpus tpu-vm service-identity create --zone=${ZONE}gcloud auth logingcloud config set project ${PROJECT_ID}gcloud config set compute/zone ${ZONE}\n```\n### \u9810\u914d Cloud TPU \u74b0\u5883\n\u6700\u4f73\u5be6\u8e10\u662f\u4f7f\u7528 `queued-resource create` \u547d\u4ee4\u5c07 Cloud TPU v5 \u9810\u914d\u7232 [\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \u3002\u4f46\u662f\uff0c\u60a8\u4e5f\u53ef\u4ee5\u4f7f\u7528 Create Node API ( `gcloud alpha compute tpus tpu-vm create` ) \u9810\u914d Cloud TPU v5\u3002\n\u8a2d\u7f6e\u5275\u5efa TPU \u6240\u9700\u7684\u74b0\u5883\u8b8a\u91cf\u3002\n\u5c07\u4ee5\u4e0b\u5217\u8868\u4e2d\u7684\u8b8a\u91cf\uff08\u7d05\u8272\uff09\u66ff\u63db\u7232\u60a8\u5c07\u7528\u65bc\u8a13\u7df4\u6216\u63a8\u7406\u4f5c\u696d\u7684\u503c\u3002\n```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=your_queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n| 0     | 1                                     |\n|:---------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------|\n| \u8b8a\u91cf     | \u8aaa\u660e                                    |\n| PROJECT_ID   | Google Cloud \u9805\u76ee\u540d\u7a31                                |\n| ACCELERATOR_TYPE  | \u5982\u9700\u77ad\u89e3\u652f\u6301\u7684\u52a0\u901f\u5668\u985e\u578b\uff0c\u8acb\u53c3\u95b1\u52a0\u901f\u5668\u985e\u578b\u90e8\u5206\u3002                         |\n| \u5340\u9593     | \u6240\u6709\u5bb9\u91cf\u5747\u4f4d\u65bc us-west4-a\u3002                              |\n| RUNTIME_VERSION  | \u8acb\u4f7f\u7528 v2-alpha-tpuv5-lite\u3002                              |\n| SERVICE_ACCOUNT  | \u9019\u662f\u60a8\u7684\u670d\u52d9\u5e33\u865f\u7684\u5730\u5740\uff0c\u60a8\u53ef\u4ee5\u5728 Google Cloud \u63a7\u5236\u6aaf ->\u201cIAM\u201d->\u201c\u670d\u52d9\u5e33\u865f\u201d\u4e2d\u627e\u5230\u5b83\u3002\u4f8b\u5982\uff1atpu-service-account@myprojectID.iam.gserviceaccount.com |\n| TPU_NAME    | TPU \u7684\u6587\u672c ID\uff0c\u7531\u7528\u6236\u5206\u914d\u7684\u6587\u672c ID\uff0c\u5728\u5206\u914d\u6392\u968a\u7684\u8cc7\u6e90\u8acb\u6c42\u6642\u5275\u5efa\u3002                     |\n| QUEUED_RESOURCE_ID | \u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8acb\u6c42\u4e14\u7531\u7528\u6236\u5206\u914d\u7684\u6587\u672c ID\u3002\u5982\u9700\u77ad\u89e3\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\uff0c\u8acb\u53c3\u95b1\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u6587\u6a94\u3002             |\n| QUOTA_TYPE   | \u8a72\u6a19\u8a8c\u53ef\u4ee5\u662f reserved \u6216 best-effort\u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 TPU \u914d\u984d\u985e\u578b\u3002\u201c\u76e1\u529b\u800c\u7232\u201d\u914d\u984d\u662f\u9ed8\u8a8d\u8a2d\u7f6e\uff0c\u56e0\u6b64\u60a8\u7121\u9700\u8a2d\u7f6e\u8a72\u503c\u3002 |\n| VALID_UNTIL_DURATION | \u8acb\u6c42\u7684\u6709\u6548\u6642\u9577\u3002\u5982\u9700\u77ad\u89e3\u4e0d\u540c\u7684\u6709\u6548\u671f\uff0c\u8acb\u53c3\u95b1 \u6392\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002                      |\n```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n```\n**\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002\n\u5982\u679c\u6210\u529f\u5275\u5efa\u4e86\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\uff0c `response` \u5b57\u6bb5\u4e2d\u7684\u72c0\u614b\u5c07\u7232 `WAITING_FOR_RESOURCES` \u6216 `FAILED` \u3002\u5982\u679c\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `WAITING_FOR_RESOURCES` \u72c0\u614b\uff0c\u5247\u610f\u5473\u7740\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u5df2\u901a\u904e\u521d\u6b65\u9a57\u8b49\uff0c\u6b63\u5728\u7b49\u5f85\u5bb9\u91cf\u3002\u7576\u5bb9\u91cf\u53ef\u7528\u5f8c\uff0c\u8acb\u6c42\u5c07\u8f49\u63db\u7232 `PROVISIONING` \u3002\u8655\u65bc `WAITING_FOR_RESOURCES` \u72c0\u614b\u4e26\u4e0d\u4e00\u5b9a\u610f\u5473\u7740\u60a8\u80fd\u7372\u5f97\u5206\u914d\u7684\u914d\u984d\uff0c\u4e26\u4e14\u7cfb\u7d71\u53ef\u80fd\u9700\u8981\u4e00\u4e9b\u6642\u9593\u624d\u80fd\u5f9e `WAITING_FOR_RESOURCES` \u72c0\u614b\u66f4\u6539\u7232 `ACTIVE` \u72c0\u614b\u3002\u5982\u679c\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `FAILED` \u72c0\u614b\uff0c\u5247\u8f38\u51fa\u4e2d\u6703\u986f\u793a\u5931\u6557\u539f\u56e0\u3002\u5982\u679c\u672a\u5728 `--valid-until-duration` \u4e2d\u586b\u5145\u8acb\u6c42\uff0c\u4e26\u4e14\u72c0\u614b\u8b8a\u7232\u201cFAILED\u201d\uff0c\u8a72\u8acb\u6c42\u5c07\u904e\u671f\u3002\n\u5f85\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u5f8c\uff0c\u60a8\u5c31\u53ef\u4ee5\u4f7f\u7528 SSH \u8a2a\u554f TPU \u865b\u64ec\u6a5f\u3002\n\u4f7f\u7528 `[list](/tpu/docs/managing-tpus-tpu-vm)` \u6216 `[describe](/tpu/docs/managing-tpus-tpu-vm)` \u547d\u4ee4\u67e5\u8a62\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u7684\u72c0\u614b\u3002\n```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\n\u8868\u793a\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u7684\u72c0\u614b\u3002\u72c0\u614b\u7684\u5b9a\u7fa9\u5982\u4e0b\uff1a\n| 0      | 1                              |\n|:----------------------|:-----------------------------------------------------------------------------------------------------------------------|\n| \u72c0\u614b     | \u8aaa\u660e                             |\n| WAITING_FOR_RESOURCES | \u5df2\u6536\u5230\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90 create \u547d\u4ee4\uff0c\u8a72\u547d\u4ee4\u5c07\u5728\u5bb9\u91cf\u53ef\u7528\u6642\u7acb\u5373\u958b\u59cb\u9810\u914d\u3002             |\n| PROVISIONING   | \u6b63\u5728\u9810\u914d TPU \u5207\u7247\u3002                         |\n| ACTIVE    | \u6240\u6709 TPU \u5747\u5df2\u9810\u914d\uff0c\u96a8\u6642\u53ef\u4ee5\u4f7f\u7528\u3002\u5982\u679c\u7d66\u5b9a\u4e86\u5553\u52d5\u8173\u672c\uff0c\u7576\u6392\u968a\u7684\u8cc7\u6e90\u72c0\u614b\u8f49\u63db\u7232 ACTIVE \u6642\uff0c\u8a72\u8173\u672c\u5c07\u5728\u6240\u6709 TPU \u4e0a\u958b\u59cb\u57f7\u884c\u3002 |\n| FAILED    | \u7121\u6cd5\u9810\u914d\u9019\u4e9b\u5207\u7247\u3002                          |\n| SUSPENDING   | \u6b63\u5728\u522a\u9664\u4e00\u500b\u6216\u591a\u500b\u5207\u7247\u3002                        |\n| SUSPENDED    | \u7cfb\u7d71\u6703\u522a\u9664\u6240\u6709\u5e95\u5c64\u5207\u7247\uff0c\u4f46\u6392\u968a\u7684\u8cc7\u6e90\u5c07\u4fdd\u6301\u4e0d\u8b8a\uff0c\u76f4\u5230\u660e\u78ba\u522a\u9664\u7232\u6b62\u3002\u76ee\u524d\uff0c\u5df2\u66ab\u505c\u968a\u5217\u4e2d\u7684\u8cc7\u6e90\u7121\u6cd5\u6062\u5fa9\uff0c\u61c9\u5c07\u5176\u522a\u9664\u3002  |\n| DELETING    | \u6b63\u5728\u522a\u9664\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002                        |\n### \u4f7f\u7528 SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\n\u4ee5\u4e0b\u90e8\u5206\u4ecb\u7d39\u5982\u4f55\u5728 TPU \u5207\u7247\u4e2d\u7684\u6bcf\u500b TPU \u865b\u64ec\u6a5f\u4e0a\u5b89\u88dd\u4e8c\u9032\u5236\u6587\u4ef6\u4e26\u904b\u884c\u4ee3\u78bc\u3002\u5728\u6b64\u4e0a\u4e0b\u6587\u4e2d\uff0cTPU \u865b\u64ec\u6a5f\u4e5f\u7a31\u7232\u201c\u5de5\u4f5c\u5668\u201d \u3002\n\u5982\u9700\u78ba\u5b9a\u60a8\u7684\u5207\u7247\u5c07\u64c1\u6709\u7684\u865b\u64ec\u6a5f\u6578\u91cf\uff0c\u8acb\u53c3\u95b1 [\u865b\u64ec\u6a5f\u985e\u578b](https://cloud.google.com/tpu/docs/supported-tpu-configurations?hl=zh-cn#lite-pod-types) \u90e8\u5206\u3002\n\u5982\u9700\u5b89\u88dd\u4e8c\u9032\u5236\u6587\u4ef6\u6216\u904b\u884c\u4ee3\u78bc\uff0c\u8acb\u4f7f\u7528 [tpu-vm ssh \u547d\u4ee4](https://cloud.google.com/sdk/gcloud/reference/alpha/compute/tpus/tpu-vm/ssh?hl=zh-cn) \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME}\n```\n\u5982\u9700\u4f7f\u7528 SSH \u8a2a\u554f\u7279\u5b9a\u7684 TPU \u865b\u64ec\u6a5f\uff0c\u8acb\u4f7f\u7528 `--worker` \u6a19\u8a8c\uff0c\u8a72\u6a19\u8a8c\u5f8c\u8ddf\u7d22\u5f15\uff08\u5f9e 0 \u958b\u59cb\uff09\uff1a\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} --worker=1\n```\n\u5982\u679c\u5207\u7247\u5f62\u72c0\u8d85\u904e 8 \u500b\u82af\u7247\uff0c\u5247\u4e00\u500b\u5207\u7247\u4e2d\u6703\u6709\u591a\u500b\u865b\u64ec\u6a5f\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u8acb\u4f7f\u7528 `--worker=all` \u6a19\u8a8c\u5728\u6240\u6709 TPU \u865b\u64ec\u6a5f\u4e0a\u904b\u884c\u5b89\u88dd\uff0c\u800c\u4e0d\u5fc5\u5206\u5225\u9023\u63a5\u5230\u6bcf\u500b\u865b\u64ec\u6a5f\u3002\u4f8b\u5982\uff1a\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='pip install \"jax[tpu]==0.4.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html'\n```\n### \u7ba1\u7406\n[\u7ba1\u7406 TPU](https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm?hl=zh-cn) \u4e2d\u4ecb\u7d39\u4e86\u53ef\u7528\u65bc\u7ba1\u7406 TPU \u865b\u64ec\u6a5f\u7684\u6240\u6709\u547d\u4ee4\u3002\n### \u6846\u67b6\u8a2d\u7f6e\n\u672c\u90e8\u5206\u4ecb\u7d39\u4e86\u642d\u914d\u4f7f\u7528 JAX \u6216 PyTorch \u8207 TPU v5e \u8a13\u7df4\u81ea\u5b9a\u7fa9\u6a21\u578b\u7684\u5e38\u898f\u8a2d\u7f6e\u904e\u7a0b\u3002 `tpu-vm-tf-2.15.0-pjrt` \u548c `tpu-vm-tf-2.15.0-pod-pjrt` TPU \u904b\u884c\u6642\u7248\u672c\u652f\u6301 TensorFlow\u3002\n\u5982\u9700\u77ad\u89e3\u63a8\u65b7\u8a2d\u7f6e\u8aaa\u660e\uff0c\u8acb\u53c3\u95b1 [v5e \u63a8\u65b7\u7c21\u4ecb](https://cloud.google.com/tpu/docs/v5e-inference?hl=zh-cn) \u3002\n\u5982\u679c\u5207\u7247\u5f62\u72c0\u8d85\u904e 8 \u500b\u82af\u7247\uff0c\u5247\u4e00\u500b\u5207\u7247\u4e2d\u6703\u6709\u591a\u500b\u865b\u64ec\u6a5f\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u60a8\u9700\u8981\u4f7f\u7528 `--worker=all` \u6a19\u8a8c\u5728\u6240\u6709 TPU \u865b\u64ec\u6a5f\u4e0a\u904b\u884c\u5b89\u88dd\u6b65\u9a5f\uff0c\u7121\u9700\u4f7f\u7528 SSH \u5206\u5225\u767b\u9304\u6bcf\u500b\u865b\u64ec\u6a5f\uff1a\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='pip install \"jax[tpu]==0.4.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html'\n```\n\u60a8\u53ef\u4ee5\u904b\u884c\u4ee5\u4e0b\u547d\u4ee4\u4f86\u6aa2\u67e5\u8a2d\u5099\u6578\u91cf\uff08\u6b64\u8655\u986f\u793a\u7684\u8f38\u51fa\u662f\u4f7f\u7528 v5litepod-16 \u5207\u7247\u751f\u6210\u7684\uff09\u3002\u6b64\u4ee3\u78bc\u901a\u904e\u6aa2\u67e5 JAX \u662f\u5426\u80fd\u5920\u770b\u5230 Cloud TPU TensorCore\uff0c\u4ee5\u53ca\u662f\u5426\u53ef\u4ee5\u904b\u884c\u57fa\u672c\u64cd\u4f5c\u4f86\u6e2c\u8a66\u6240\u6709\u5167\u5bb9\u662f\u5426\u5747\u5df2\u6b63\u78ba\u5b89\u88dd\uff1a\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='python3 -c \"import jax; print(jax.device_count()); print(jax.local_device_count())\"'\n```\n\u8f38\u51fa\u5c07\u5982\u4e0b\u6240\u793a\uff1a\n```\nSSH: Attempting to connect to worker 0...SSH: Attempting to connect to worker 1...SSH: Attempting to connect to worker 2...SSH: Attempting to connect to worker 3...164164164164\n```\n`jax.device\\_count()` \u986f\u793a\u7d66\u5b9a\u5207\u7247\u4e2d\u7684\u689d\u72c0\u6a19\u7c64\u7e3d\u6578\u3002 `jax.local\\_device\\_count()` \u8868\u793a\u6b64\u5207\u7247\u4e2d\u55ae\u500b\u865b\u64ec\u6a5f\u53ef\u8a2a\u554f\u7684\u82af\u7247\u6578\u91cf\u3002\n```\n# Check the number of chips in the given slice by summing the count of chips# from all VMs through the# jax.local_device_count() API call.gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='python3 -c \"import jax; xs=jax.numpy.ones(jax.local_device_count()); print(jax.pmap(lambda x: jax.lax.psum(x, \\\"i\\\"), axis_name=\\\"i\\\")(xs))\"'\n```\n\u8f38\u51fa\u5c07\u5982\u4e0b\u6240\u793a\uff1a\n```\nSSH: Attempting to connect to worker 0...SSH: Attempting to connect to worker 1...SSH: Attempting to connect to worker 2...SSH: Attempting to connect to worker 3...[16. 16. 16. 16.][16. 16. 16. 16.][16. 16. 16. 16.][16. 16. 16. 16.]\n```\n\u5617\u8a66\u53c3\u95b1\u672c\u6587\u6a94\u4e2d\u7684 [JAX \u6559\u7a0b](#jax-flax-examples) \uff0c\u958b\u59cb\u4f7f\u7528 JAX \u9032\u884c v5e \u8a13\u7df4\u3002\n\u8acb\u6ce8\u610f\uff0cv5e \u50c5\u652f\u6301 [PJRT \u904b\u884c\u6642](https://github.com/pytorch/xla/blob/master/docs/pjrt.md) \uff0cPyTorch 2.1 \u53ca\u66f4\u9ad8\u7248\u672c\u6703\u5c07 PJRT \u7528\u4f5c\u6240\u6709 TPU \u7248\u672c\u7684\u9ed8\u8a8d\u904b\u884c\u6642\u3002\n\u672c\u90e8\u5206\u4ecb\u7d39\u5982\u4f55\u958b\u59cb\u5728 v5e \u4e0a\u901a\u904e PyTorch/XLA \u901a\u904e\u547d\u4ee4\u4f7f\u7528 PJRT\uff0c\u7232\u6240\u6709\u5de5\u4f5c\u5668\u4f7f\u7528 PJRT\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 sudo apt-get update -y\u00a0 \u00a0 \u00a0 sudo apt-get install libomp5 -y\u00a0 \u00a0 \u00a0 pip3 install mkl mkl-include\u00a0 \u00a0 \u00a0 pip3 install tf-nightly tb-nightly tbp-nightly\u00a0 \u00a0 \u00a0 pip3 install numpy\u00a0 \u00a0 \u00a0 sudo apt-get install libopenblas-dev -y\u00a0 \u00a0 \u00a0 pip3 install torch~=2.1.0 torchvision torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html\u00a0 \u00a0 \u00a0 pip3 install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html'\n```\n\u5982\u679c\u60a8\u7121\u6cd5\u7232 Torch/torch_xla/torchvision \u5b89\u88dd\u8eca\u8f2a\uff0c\u4e26\u770b\u5230 `pkg_resources.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier) torch==nightly+20230222` \u9019\u6a23\u7684\u932f\u8aa4\uff0c\u8acb\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\u964d\u7d1a\u60a8\u7684\u7248\u672c\uff1a\n```\npip3 install setuptools==62.1.0\n```\n**\u6ce8\u610f** \uff1a\u5c0d\u65bc\u5206\u914d\u898f\u6a21\u8f03\u5927\u4e14\u9700\u8981\u983b\u7e41\u7684\u6a21\u578b\uff0c\u8207\u9ed8\u8a8d\u7684 `malloc` \u5be6\u73fe\u76f8\u6bd4\uff0c\u4f7f\u7528 `tcmalloc` \u53ef\u4ee5\u986f\u8457\u7e2e\u77ed\u8a13\u7df4\u6642\u9593\uff0c\u56e0\u6b64 TPU \u865b\u64ec\u6a5f\u4e0a\u4f7f\u7528\u7684\u9ed8\u8a8d `malloc` \u7232 `tcmalloc` \u3002\u4f46\u662f\uff0c `tcmalloc` \u53ef\u80fd\u6703\u5c0e\u81f4\u904b\u884c\u901f\u5ea6\u8b8a\u6162\uff0c\u5177\u9ad4\u53d6\u6c7a\u65bc\u60a8\u7684\u5de5\u4f5c\u8ca0\u8f09\uff08\u4f8b\u5982\uff0c\u4f7f\u7528\u5177\u6709\u975e\u5e38\u5927\u7684\u5d4c\u5165\u8868\u5206\u914d\u7684 DLRM\uff09\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u60a8\u53ef\u4ee5\u5617\u8a66\u6539\u7528\u9ed8\u8a8d `malloc` \u53d6\u6d88\u8a2d\u7f6e\u4ee5\u4e0b\u8b8a\u91cf\uff1a\n```\nunset LD_PRELOAD\n```\n\u4ee5\u4e0b\u662f\u4f7f\u7528 Python \u8173\u672c\u5728 v5e \u865b\u64ec\u6a5f\u4e0a\u9032\u884c\u8a08\u7b97\u7684\u793a\u4f8b\uff1a\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/.local/lib/\u00a0 \u00a0 \u00a0 export PJRT_DEVICE=TPU_C_API\u00a0 \u00a0 \u00a0 export PT_XLA_DEBUG=0\u00a0 \u00a0 \u00a0 export USE_TORCH=ON\u00a0 \u00a0 \u00a0 unset LD_PRELOAD\u00a0 \u00a0 \u00a0 export TPU_LIBRARY_PATH=$HOME/.local/lib/python3.10/site-packages/libtpu/libtpu.so\u00a0 \u00a0 \u00a0 python3 -c \"import torch; import torch_xla; import torch_xla.core.xla_model as xm; print(xm.xla_device()); dev = xm.xla_device(); t1 = torch.randn(3,3,device=dev); t2 = torch.randn(3,3,device=dev); print(t1 + t2)\"'\n```\n\u9019\u5c07\u751f\u6210\u5982\u4e0b\u6240\u793a\u7684\u8f38\u51fa\uff1a\n```\nSSH: Attempting to connect to worker 0...SSH: Attempting to connect to worker 1...xla:0tensor([[ 1.8611, -0.3114, -2.4208],[-1.0731, 0.3422, 3.1445],[ 0.5743, 0.2379, 1.1105]], device='xla:0')xla:0tensor([[ 1.8611, -0.3114, -2.4208],[-1.0731, 0.3422, 3.1445],[ 0.5743, 0.2379, 1.1105]], device='xla:0')\n```\n\u53c3\u95b1\u672c\u6587\u6a94\u4e2d\u7684 [PyTorch \u6559\u7a0b](#pytorch-xla) \uff0c\u958b\u59cb\u4f7f\u7528 PyTorch \u9032\u884c v5e \u8a13\u7df4\u3002\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\u5982\u9700\u522a\u9664\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\uff0c\u8acb\u6309\u7167\u4ee5\u4e0b 2 \u500b\u6b65\u9a5f\u522a\u9664\u5207\u7247\uff0c\u7136\u5f8c\u522a\u9664\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\uff1a\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n\u9019\u5169\u500b\u6b65\u9a5f\u9084\u53ef\u7528\u65bc\u79fb\u9664\u8655\u65bc `FAILED` \u72c0\u614b\u7684\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8acb\u6c42\u3002\n### \u76e3\u63a7\u548c\u6027\u80fd\u5206\u6790\nCloud TPU v5e \u652f\u6301\u4f7f\u7528\u8207\u4e0a\u4e00\u4ee3 Cloud TPU \u76f8\u540c\u7684\u65b9\u6cd5\u9032\u884c\u76e3\u63a7\u548c\u5206\u6790\u3002\u60a8\u53ef\u4ee5\u95b1\u8b80 [\u4f7f\u7528 Cloud TPU \u5de5\u5177\u5206\u6790\u6a21\u578b](https://cloud.google.com/tpu/docs/cloud-tpu-tools?hl=zh-cn) \uff0c\u8a73\u7d30\u77ad\u89e3\u5982\u4f55\u5c0d Cloud TPU \u865b\u64ec\u6a5f\u9032\u884c\u6027\u80fd\u5206\u6790\u548c [\u76e3\u63a7](https://cloud.google.com/tpu/docs/troubleshooting/tpu-vm-monitoring?hl=zh-cn) \uff0c\u5f9e\u800c\u8a73\u7d30\u77ad\u89e3\u5982\u4f55\u9032\u884c\u76e3\u63a7\u3002\n## JAX/FLAX \u793a\u4f8b\n### \u5728 v5e \u4e0a\u8a13\u7df4 ImageNet\n\u672c\u6559\u7a0b\u4ecb\u7d39\u5982\u4f55\u4f7f\u7528\u865b\u69cb\u8f38\u5165\u6578\u64da\u5728 v5e \u4e0a\u8a13\u7df4 ImageNet\u3002\u5982\u679c\u60a8\u60f3\u4f7f\u7528\u771f\u5be6\u6578\u64da\uff0c\u8acb\u53c3\u95b1 [GitHub \u4e0a\u7684 README \u6587\u4ef6](https://github.com/google/flax/blob/main/examples/imagenet/README.md) \u3002- \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=your_queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002 **\u6ce8\u610f** \uff1a\u4e00\u65e6\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576 QueuedResource \u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u5982\u4e0b\u6240\u793a\uff1a```\n\u00a0state: ACTIVE\n```\n- \u5b89\u88dd\u6700\u65b0\u7248\u672c\u7684 JAX \u548c jaxlib\uff1a```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='pip install \"jax[tpu]==0.4.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html'\n``` **\u6ce8\u610f** \uff1a\u5982\u679c\u60a8\u770b\u5230\u63d0\u793a\u60a8\u4f7f\u7528 jax>=0.4.8 \u7684\u932f\u8aa4\uff0c\u53ef\u4ee5\u653e\u5fc3\u5730\u5ffd\u7565\u8a72\u6d88\u606f\u3002\n- \u514b\u9686 ImageNet \u6a21\u578b\u4e26\u5b89\u88dd\u76f8\u61c9\u7684\u8981\u6c42\uff1a```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='git clone https://github.com/google/flax.git && cd flax/examples/imagenet && pip install -r requirements.txt && pip install flax==0.7.4'\n```\n- \u7232\u4e86\u751f\u6210\u865b\u69cb\u6578\u64da\uff0c\u6a21\u578b\u9700\u8981\u6709\u95dc\u6578\u64da\u96c6\u7dad\u5ea6\u7684\u4fe1\u606f\u3002\u9019\u53ef\u4ee5\u5f9e ImageNet \u6578\u64da\u96c6\u7684\u5143\u6578\u64da\u4e2d\u6536\u96c6\uff1a```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} --project=${PROJECT_ID} --zone=${ZONE} --worker=all --command='mkdir -p $HOME/flax/.tfds/metadata/imagenet2012/5.1.0 && curl https://raw.githubusercontent.com/tensorflow/datasets/v4.4.0/tensorflow_datasets/testing/metadata/imagenet2012/5.1.0/dataset_info.json --output $HOME/flax/.tfds/metadata/imagenet2012/5.1.0/dataset_info.json'\n```\u5b8c\u6210\u524d\u9762\u7684\u6240\u6709\u6b65\u9a5f\u5f8c\uff0c\u60a8\u5c31\u53ef\u4ee5\u8a13\u7df4\u6a21\u578b\u4e86\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='cd flax/examples/imagenet && JAX_PLATFORMS=tpu python3 imagenet_fake_data_benchmark.py'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n```\ngcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n### \u64c1\u62b1\u81c9 FLAX \u6a21\u578b\n\u63a1\u7528 FLAX \u5be6\u73fe\u7684 [Hugging Face](https://huggingface.co/) \u6a21\u578b\u53ef\u5728 Cloud TPU v5e \u4e0a\u958b\u7bb1\u5373\u7528\u3002\u672c\u90e8\u5206\u4ecb\u7d39\u77ad\u5982\u4f55\u904b\u884c\u71b1\u9580\u6a21\u578b\u3002\n\u672c\u6559\u7a0b\u4ecb\u7d39\u77ad\u5982\u4f55\u5728 Cloud TPU v5e \u4e0a\u4f7f\u7528 Fast AI [imagenette](https://github.com/fastai/imagenette) \u6578\u64da\u96c6\u901a\u904e HuggingFace \u8a13\u7df4 [Vision Transformer](https://arxiv.org/abs/2010.11929) (ViT) \u6a21\u578b\u3002\nViT \u6a21\u578b\u662f\u7b2c\u4e00\u500b\u5728 ImageNet \u4e0a\u6210\u529f\u8a13\u7df4 Transformer \u7de8\u78bc\u5668\u4e26\u6bd4\u5377\u7a4d\u7db2\u7d61\u53d6\u5f97\u51fa\u8272\u7d50\u679c\u7684\u6a21\u578b\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1\u4ee5\u4e0b\u8cc7\u6e90\uff1a\n- [ViT \u6982\u89bd](https://huggingface.co/docs/transformers/model_doc/vit) \n- [ViT \u4ee3\u78bc\u8cc7\u6e90](https://github.com/huggingface/transformers/tree/main/examples/flax/vision) - \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=your_queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002\u5f85\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u5f8c\uff0c\u60a8\u5c07\u80fd\u5920\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n\u00a0state: ACTIVE\n```\n- \u5b89\u88dd JAX \u53ca\u5176\u5eab\uff1a```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='pip install \"jax[tpu]==0.4.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html'\n```\n- \u4e0b\u8f09 Hugging Face [\u4ee3\u78bc\u5eab](https://github.com/huggingface/transformers.git) \u548c\u5b89\u88dd\u8981\u6c42\uff1a```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='git clone https://github.com/huggingface/transformers.git && cd transformers && pip install . && pip install -r examples/flax/_tests_requirements.txt && pip install --upgrade huggingface-hub urllib3 zipp && pip install tensorflow==2.16.1 && pip install -r examples/flax/vision/requirements.txt'\n```\n- \u4e0b\u8f09 Imagenette \u6578\u64da\u96c6\uff1a```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='cd transformers && wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz && tar -xvzf imagenette2.tgz'\n```\u4f7f\u7528 4GB \u7684\u9810\u6620\u5c04\u7de9\u885d\u5340\u4f86\u8a13\u7df4\u6a21\u578b\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='cd transformers && JAX_PLATFORMS=tpu python3 examples/flax/vision/run_image_classification.py --train_dir \"imagenette2/train\" --validation_dir \"imagenette2/val\" --output_dir \"./vit-imagenette\" --learning_rate 1e-3 --preprocessing_num_workers 32 --per_device_train_batch_size 8 --per_device_eval_batch_size 8 --model_name_or_path google/vit-base-patch16-224-in21k --num_train_epochs 3'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u6392\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n\u8a13\u7df4\u8173\u672c\u5728 v5litepod-4\u3001v5litepod-16 \u548c v5litepod-64 \u4e0a\u904b\u884c\uff0c\u4e0b\u8868\u986f\u793a\u4e86\u4f7f\u7528\u4e0d\u540c\u52a0\u901f\u5668\u985e\u578b\u6642\u7684\u541e\u5410\u91cf\u3002\n| 0     | 1   | 2   | 3   |\n|:------------------|:------------|:-------------|:-------------|\n| \u52a0\u901f\u5668\u985e\u578b  | v5litepod-4 | v5litepod-16 | V5litepod-64 |\n| \u7d00\u5143    | 3   | 3   | 3   |\n| \u5168\u5c40\u6279\u91cf\u5927\u5c0f  | 32   | 128   | 512   |\n| \u541e\u5410\u91cf\uff08\u793a\u4f8b/\u79d2\uff09 | 263.40  | 429.34  | 470.71  |\n\u672c\u6559\u7a0b\u4ecb\u7d39\u5982\u4f55\u4f7f\u7528 Cloud TPU v5e \u4e0a\u7684 [Pok\u00e9mon](https://huggingface.co/datasets/lambdalabs/pokemon-blip-captions) \u6578\u64da\u96c6\u901a\u904e HuggingFace \u8a13\u7df4 Stable Diffusion \u6a21\u578b\u3002\n\u7a69\u5b9a\u64f4\u6563\u6a21\u578b\u662f\u4e00\u7a2e\u6f5b\u5728\u7684\u6587\u672c\u5230\u5716\u50cf\u6a21\u578b\uff0c\u53ef\u6839\u64da\u4efb\u4f55\u6587\u672c\u8f38\u5165\u751f\u6210\u903c\u771f\u7684\u5716\u50cf\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1\u4ee5\u4e0b\u8cc7\u6e90\uff1a\n- [Stable Diffusion \u6982\u89bd](https://huggingface.co/CompVis/stable-diffusion-v1-4) \n- [Stable Diffusion \u6e90\u4ee3\u78bc ](https://github.com/huggingface/diffusers/tree/main/examples/text_to_image) - \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002 **\u6ce8\u610f** \uff1a\u7576\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u5f8c\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n\u00a0state: ACTIVE\n```\n- \u5b89\u88dd JAX \u53ca\u5176\u5eab\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='pip install \"jax[tpu]==0.4.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html'\n```\n- \u4e0b\u8f09 HuggingFace [\u4ee3\u78bc\u5eab](https://github.com/huggingface/diffusers) \u548c\u5b89\u88dd\u8981\u6c42\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='git clone https://github.com/RissyRan/diffusers.git && cd diffusers && pip install . && pip install tensorflow==2.16.1 clu && pip install -U -r examples/text_to_image/requirements_flax.txt'\n```\u4f7f\u7528 4GB \u7684\u9810\u6620\u5c04\u7de9\u885d\u5340\u4f86\u8a13\u7df4\u6a21\u578b\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='cd diffusers/examples/text_to_image && JAX_PLATFORMS=tpu,cpu python3 train_text_to_image_flax.py --pretrained_model_name_or_path=duongna/stable-diffusion-v1-4-flax --dataset_name=lambdalabs/pokemon-blip-captions --resolution=128 --center_crop --random_flip --train_batch_size=4 --mixed_precision=fp16 --max_train_steps=1500 --learning_rate=1e-05 --max_grad_norm=1 --output_dir=sd-pokemon-model'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n\u8a13\u7df4\u8173\u672c\u5728 v5litepod-4\u3001v5litepod-16 \u548c v5litepod-64 \u4e0a\u904b\u884c\uff0c\u4e0b\u8868\u986f\u793a\u4e86\u541e\u5410\u91cf\u3002\n| 0     | 1   | 2   | 3   |\n|:------------------|:------------|:-------------|:-------------|\n| \u52a0\u901f\u5668\u985e\u578b  | v5litepod-4 | v5litepod-16 | V5litepod-64 |\n| \u8a13\u7df4\u6b65\u6578   | 1500  | 1500   | 1500   |\n| \u5168\u5c40\u6279\u91cf\u5927\u5c0f  | 32   | 64   | 128   |\n| \u541e\u5410\u91cf\uff08\u793a\u4f8b/\u79d2\uff09 | 36.53  | 43.71  | 49.36 \u6b72  |\n### \u4f7f\u7528 OSCAR \u6578\u64da\u96c6\u8a13\u7df4 GPT2\n\u672c\u6559\u7a0b\u4ecb\u7d39\u77ad\u5982\u4f55\u5728 Cloud TPU v5e \u4e0a\u4f7f\u7528 [OSCAR](https://huggingface.co/datasets/oscar) \u6578\u64da\u96c6\u901a\u904e HuggingFace \u8a13\u7df4 [ GPT2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) \u6a21\u578b\u3002\nGPT2 \u662f\u4e00\u7a2e\u57fa\u65bc\u539f\u59cb\u6587\u672c\u9032\u884c\u9810\u8a13\u7df4\u7684\u8f49\u63db\u5668\u6a21\u578b\uff0c\u7121\u9700\u4eba\u5de5\u6a19\u8a18\u3002\u7d93\u8a13\u7df4\uff0c\u5b83\u80fd\u5920\u9810\u6e2c\u53e5\u5b50\u4e2d\u7684\u4e0b\u4e00\u500b\u5b57\u8a5e\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1\u4ee5\u4e0b\u8cc7\u6e90\uff1a\n- [GPT2 \u6982\u89bd](https://huggingface.co/gpt2) \n- [GPT2 \u6e90\u4ee3\u78bc](https://github.com/huggingface/transformers/tree/main/examples/flax/language-modeling) - \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002 **\u6ce8\u610f** \uff1a\u5f85\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u5f8c\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n\u00a0state: ACTIVE\n```\n- \u5b89\u88dd JAX \u53ca\u5176\u5eab\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='pip install \"jax[tpu]==0.4.16\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html'\n```\n- \u4e0b\u8f09 HuggingFace [\u4ee3\u78bc\u5eab](https://github.com/huggingface/transformers.git) \u548c\u5b89\u88dd\u8981\u6c42\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='git clone https://github.com/huggingface/transformers.git && cd transformers && pip install . && pip install -r examples/flax/_tests_requirements.txt && pip install --upgrade huggingface-hub urllib3 zipp && pip install tensorflow && pip install -r examples/flax/language-modeling/requirements.txt'\n```\n- \u4e0b\u8f09\u914d\u7f6e\u4ee5\u8a13\u7df4\u6a21\u578b\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='cd transformers/examples/flax/language-modeling && gsutil cp -r gs://cloud-tpu-tpuvm-artifacts/v5litepod-preview/jax/gpt .'\n```\u4f7f\u7528 4GB \u7684\u9810\u6620\u5c04\u7de9\u885d\u5340\u4f86\u8a13\u7df4\u6a21\u578b\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='cd transformers/examples/flax/language-modeling && TPU_PREMAPPED_BUFFER_SIZE=4294967296 JAX_PLATFORMS=tpu python3 run_clm_flax.py --output_dir=./gpt --model_type=gpt2 --config_name=./gpt --tokenizer_name=./gpt --dataset_name=oscar --dataset_config_name=unshuffled_deduplicated_no --do_train --do_eval --block_size=512 --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --learning_rate=5e-3 --warmup_steps=1000 --adam_beta1=0.9 --adam_beta2=0.98 --weight_decay=0.01 --overwrite_output_dir --num_train_epochs=3 --logging_steps=500 --eval_steps=2500'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u6392\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n\u8a13\u7df4\u8173\u672c\u5728 v5litepod-4\u3001v5litepod-16 \u548c v5litepod-64 \u4e0a\u904b\u884c\uff0c\u4e0b\u8868\u986f\u793a\u4e86\u541e\u5410\u91cf\u3002\n| 0     | 1   | 2   | 3   |\n|:------------------|:------------|:-------------|:-------------|\n| nan    | v5litepod-4 | v5litepod-16 | V5litepod-64 |\n| \u7d00\u5143    | 3   | 3   | 3   |\n| \u5168\u5c40\u6279\u91cf\u5927\u5c0f  | 64   | 64   | 64   |\n| \u541e\u5410\u91cf\uff08\u793a\u4f8b/\u79d2\uff09 | 74.60  | 72.97  | 72.62  |\n## PyTorch/XLA\n### \u4f7f\u7528 PJRT \u904b\u884c\u6642\u8a13\u7df4 ResNet\nPyTorch/XLA \u6b63\u5728\u5f9e PyTorch 2.0+ \u9077\u79fb\u5230 PjRt\u3002\u4ee5\u4e0b\u662f\u7232 PyTorch/XLA \u8a13\u7df4\u5de5\u4f5c\u8ca0\u8f09\u8a2d\u7f6e v5e \u7684\u66f4\u65b0\u8aaa\u660e\u3002- \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=tpu-nameexport QUEUED_RESOURCE_ID=queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--{QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002 **\u6ce8\u610f** \uff1a\u7576 QueuedResource \u8655\u65bc `ACTIVE` \u72c0\u614b\u5f8c\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n\u00a0state: ACTIVE\n```\n- \u5b89\u88dd Torch/XLA \u5c08\u7528\u4f9d\u8cf4\u9805```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 sudo apt-get update -y\u00a0 \u00a0 \u00a0 sudo apt-get install libomp5 -y\u00a0 \u00a0 \u00a0 pip3 install mkl mkl-include\u00a0 \u00a0 \u00a0 pip3 install tf-nightly tb-nightly tbp-nightly\u00a0 \u00a0 \u00a0 pip3 install numpy\u00a0 \u00a0 \u00a0 sudo apt-get install libopenblas-dev -y\u00a0 \u00a0 \u00a0 pip3 install torch~=2.1.0 torchvision torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html\u00a0 \u00a0 \u00a0 pip3 install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html'\n``````\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 date\u00a0 \u00a0 \u00a0 export PJRT_DEVICE=TPU_C_API\u00a0 \u00a0 \u00a0 export PT_XLA_DEBUG=0\u00a0 \u00a0 \u00a0 export USE_TORCH=ON\u00a0 \u00a0 \u00a0 export XLA_USE_BF16=1\u00a0 \u00a0 \u00a0 export LIBTPU_INIT_ARGS=--xla_jf_auto_cross_replica_sharding\u00a0 \u00a0 \u00a0 export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\u00a0 \u00a0 \u00a0 export TPU_LIBRARY_PATH=$HOME/.local/lib/python3.10/site-packages/libtpu/libtpu.so\u00a0 \u00a0 \u00a0 git clone https://github.com/pytorch/xla.git\u00a0 \u00a0 \u00a0 cd xla/\u00a0 \u00a0 \u00a0 git reset --hard caf5168785c081cd7eb60b49fe4fffeb894c39d9\u00a0 \u00a0 \u00a0 python3 test/test_train_mp_imagenet.py --model=resnet50 \u00a0--fake_data --num_epochs=1 \u2014num_workers=16 \u00a0--log_steps=300 --batch_size=64 --profile'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u6392\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n\u4e0b\u8868\u986f\u793a\u4e86\u57fa\u6e96\u541e\u5410\u91cf\u3002\n| 0   | 1     |\n|:-------------|:------------------|\n| \u52a0\u901f\u5668\u985e\u578b | \u541e\u5410\u91cf\uff08\u793a\u4f8b/\u79d2\uff09 |\n| v5litepod-4 | 4240 ex/s   |\n| v5litepod-16 | 10,810 ex/s  |\n| V5litepod-64 | 46,154 ex/s  |\n### \u5728 v5e \u4e0a\u8a13\u7df4 GPT2\n\u672c\u6559\u7a0b\u4ecb\u7d39\u77ad\u5982\u4f55\u4f7f\u7528 [Wikitext \u6578\u64da\u96c6](https://huggingface.co/datasets/wikitext) \u5728 PyTorch/XLA \u4e0a\u4f7f\u7528 HuggingFace [\u4ee3\u78bc\u5eab](https://github.com/huggingface/transformers.git) \u5728 v5e \u4e0a\u904b\u884c GPT2\u3002- \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u50c5\u7528\u65bc\u9810\u7559\u8cc7\u6e90\uff0c\u76e1\u529b\u800c\u7232\u8cc7\u6e90\u4e0d\u9700\u8981\u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002 **\u6ce8\u610f** \uff1a\u7576 QueuedResource \u8655\u65bc `ACTIVE` \u72c0\u614b\u5f8c\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\nstate: ACTIVE\n```\n- \u5b89\u88dd Torch/xla \u4f9d\u8cf4\u9805\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 sudo apt-get -y update\u00a0 \u00a0 \u00a0 sudo apt install -y libopenblas-base\u00a0 \u00a0 \u00a0 pip3 install torchvision\u00a0 \u00a0 \u00a0 pip3 uninstall -y torch\u00a0 \u00a0 \u00a0 pip3 install torch~=2.1.0 torchvision torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html\u00a0 \u00a0 \u00a0 pip3 install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html'\n```\n- \u4e0b\u8f09 HuggingFace [\u4ee3\u78bc\u5eab](https://github.com/huggingface/transformers.git) \u548c\u5b89\u88dd\u8981\u6c42\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 git clone https://github.com/pytorch/xla.git\u00a0 \u00a0 \u00a0 pip install --upgrade accelerate\u00a0 \u00a0 \u00a0 git clone https://github.com/huggingface/transformers.git\u00a0 \u00a0 \u00a0 cd transformers\u00a0 \u00a0 \u00a0 git checkout ebdb185befaa821304d461ed6aa20a17e4dc3aa2\u00a0 \u00a0 \u00a0 pip install .\u00a0 \u00a0 \u00a0 git log -1\u00a0 \u00a0 \u00a0 pip install datasets evaluate scikit-learn\u00a0 \u00a0 \u00a0 '\n```\n- \u4e0b\u8f09\u9810\u8a13\u7df4\u6a21\u578b\u7684\u914d\u7f6e\u3002```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 gsutil cp -r gs://cloud-tpu-tpuvm-artifacts/config/xl-ml-test/pytorch/gpt2/my_config_2.json transformers/examples/pytorch/language-modeling/\u00a0 \u00a0 \u00a0 gsutil cp gs://cloud-tpu-tpuvm-artifacts/config/xl-ml-test/pytorch/gpt2/fsdp_config.json transformers/examples/pytorch/language-modeling/'\n```\u4f7f\u7528 16 \u7684\u6279\u6b21\u5927\u5c0f\u4f86\u8a13\u7df4 2B \u6a21\u578b\u3002\n```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 export PJRT_DEVICE=TPU_C_API\u00a0 \u00a0 \u00a0 cd transformers/\u00a0 \u00a0 \u00a0 export LD_LIBRARY_PATH=/usr/local/lib/\u00a0 \u00a0 \u00a0 export PT_XLA_DEBUG=0\u00a0 \u00a0 \u00a0 export USE_TORCH=ON\u00a0 \u00a0 \u00a0 python3 examples/pytorch/xla_spawn.py \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--num_cores=4 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0examples/pytorch/language-modeling/run_clm.py \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--num_train_epochs=3 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--dataset_name=wikitext \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--dataset_config_name=wikitext-2-raw-v1 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--per_device_train_batch_size=16 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--per_device_eval_batch_size=16 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--do_train \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--do_eval \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--logging_dir=./tensorboard-metrics \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--cache_dir=./cache_dir \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--output_dir=/tmp/test-clm \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--overwrite_output_dir \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--cache_dir=/tmp \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--config_name=examples/pytorch/language-modeling/my_config_2.json \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--tokenizer_name=gpt2 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--block_size=1024 \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--optim=adafactor \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--adafactor=true \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--save_strategy=no \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--logging_strategy=no \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--fsdp=full_shard \\\u00a0 \u00a0 \u00a0 \u00a0 \u00a0--fsdp_config=examples/pytorch/language-modeling/fsdp_config.json'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u6392\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n\u8a13\u7df4\u8173\u672c\u5728 v5litepod-4\u3001v5litepod-16 \u548c v5litepod-64 \u4e0a\u904b\u884c\uff0c\u4e0b\u8868\u986f\u793a\u4e86\u4e0d\u540c\u52a0\u901f\u5668\u985e\u578b\u7684\u57fa\u6e96\u541e\u5410\u91cf\u3002\n| 0     | 1   | 2   | 3   |\n|:------------------|:------------|:-------------|:-------------|\n| nan    | v5litepod-4 | v5litepod-16 | V5litepod-64 |\n| \u7d00\u5143    | 3   | 3   | 3   |\n| \u914d\u7f6e    | 6 \u5104  | 20 \u5104  | 160 \u5104  |\n| \u5168\u5c40\u6279\u91cf\u5927\u5c0f  | 64   | 128   | 256   |\n| \u541e\u5410\u91cf\uff08\u793a\u4f8b/\u79d2\uff09 | 66   | 77   | 31   |\n### \u5728 v5e \u4e0a\u8a13\u7df4 ViT\n\u672c\u6559\u7a0b\u4ecb\u7d39\u77ad\u5982\u4f55\u5728 PyTorch/XLA \u4e0a\u4f7f\u7528 [cifar10 \u6578\u64da\u96c6](https://huggingface.co/datasets/cifar10) \u4e0a\u7684 HuggingFace [\u4ee3\u78bc\u5eab](https://github.com/huggingface/transformers.git) \u5728 v5e \u4e0a\u904b\u884c VIT\u3002- \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-west4-aexport RUNTIME_VERSION=v2-alpha-tpuv5-liteexport SERVICE_ACCOUNT=your_service_accountexport TPU_NAME=tpu-nameexport QUEUED_RESOURCE_ID=queued_resource_idexport QUOTA_TYPE=quota_typeexport VALID_UNTIL_DURATION=1d\n```\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--valid-until-duration=${VALID_UNTIL_DURATION} \\\u00a0 \u00a0--service-account=${SERVICE_ACCOUNT} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a `QUOTA_TYPE` \u6a19\u8a8c\u53ef\u4ee5\u662f `reserved` \u6216 `best-effort` \u3002\u5982\u9700\u77ad\u89e3 Cloud TPU \u652f\u6301\u7684\u4e0d\u540c\u985e\u578b\u7684\u914d\u984d\uff0c\u8acb\u53c3\u95b1 [quotas](https://cloud.google.com/tpu/docs/quota?hl=zh-cn#quota_types) \u3002 **\u6ce8\u610f** \uff1a\u4e00\u65e6 QueuedResource \u8655\u65bc `ACTIVE` \u72c0\u614b\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\uff1a```\n\u00a0gcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\u7576\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\u6642\uff0c\u8f38\u51fa\u5c07\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n\u00a0state: ACTIVE\n```\n- \u5b89\u88dd Torch/xla \u4f9d\u8cf4\u9805```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 sudo apt-get update -y\u00a0 \u00a0 \u00a0 sudo apt-get install libomp5 -y\u00a0 \u00a0 \u00a0 pip3 install mkl mkl-include\u00a0 \u00a0 \u00a0 pip3 install tf-nightly tb-nightly tbp-nightly\u00a0 \u00a0 \u00a0 pip3 install numpy\u00a0 \u00a0 \u00a0 sudo apt-get install libopenblas-dev -y\u00a0 \u00a0 \u00a0 pip3 install torch~=2.1.0 torchvision torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html\u00a0 \u00a0 \u00a0 pip3 install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html'\n```\n- \u4e0b\u8f09 HuggingFace [\u4ee3\u78bc\u5eab](https://github.com/huggingface/transformers.git) \u548c\u5b89\u88dd\u8981\u6c42\u3002```\n\u00a0 \u00a0gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command=\"\u00a0 \u00a0 \u00a0 git clone https://github.com/suexu1025/transformers.git vittransformers; \\\u00a0 \u00a0 \u00a0 cd vittransformers; \\\u00a0 \u00a0 \u00a0 pip3 install .; \\\u00a0 \u00a0 \u00a0 pip3 install datasets; \\\u00a0 \u00a0 \u00a0 wget https://github.com/pytorch/xla/blob/master/scripts/capture_profile.py\"\n``````\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--worker=all \\\u00a0 \u00a0--command='\u00a0 \u00a0 \u00a0 export PJRT_DEVICE=TPU_C_API\u00a0 \u00a0 \u00a0 export PT_XLA_DEBUG=0\u00a0 \u00a0 \u00a0 export USE_TORCH=ON\u00a0 \u00a0 \u00a0 export TF_CPP_MIN_LOG_LEVEL=0\u00a0 \u00a0 \u00a0 export XLA_USE_BF16=1\u00a0 \u00a0 \u00a0 export LD_LIBRARY_PATH=/usr/local/lib:$LD_LIBRARY_PATH\u00a0 \u00a0 \u00a0 export TPU_LIBRARY_PATH=$HOME/.local/lib/python3.10/site-packages/libtpu/libtpu.so\u00a0 \u00a0 \u00a0 cd vittransformers\u00a0 \u00a0 \u00a0 python3 -u examples/pytorch/xla_spawn.py --num_cores 4 examples/pytorch/image-pretraining/run_mae.py --dataset_name=cifar10 \\\u00a0 \u00a0 \u00a0 --remove_unused_columns=False \\\u00a0 \u00a0 \u00a0 --label_names=pixel_values \\\u00a0 \u00a0 \u00a0 --mask_ratio=0.75 \\\u00a0 \u00a0 \u00a0 --norm_pix_loss=True \\\u00a0 \u00a0 \u00a0 --do_train=true \\\u00a0 \u00a0 \u00a0 --do_eval=true \\\u00a0 \u00a0 \u00a0 --base_learning_rate=1.5e-4 \\\u00a0 \u00a0 \u00a0 --lr_scheduler_type=cosine \\\u00a0 \u00a0 \u00a0 --weight_decay=0.05 \\\u00a0 \u00a0 \u00a0 --num_train_epochs=3 \\\u00a0 \u00a0 \u00a0 --warmup_ratio=0.05 \\\u00a0 \u00a0 \u00a0 --per_device_train_batch_size=8 \\\u00a0 \u00a0 \u00a0 --per_device_eval_batch_size=8 \\\u00a0 \u00a0 \u00a0 --logging_strategy=steps \\\u00a0 \u00a0 \u00a0 --logging_steps=30 \\\u00a0 \u00a0 \u00a0 --evaluation_strategy=epoch \\\u00a0 \u00a0 \u00a0 --save_strategy=epoch \\\u00a0 \u00a0 \u00a0 --load_best_model_at_end=True \\\u00a0 \u00a0 \u00a0 --save_total_limit=3 \\\u00a0 \u00a0 \u00a0 --seed=1337 \\\u00a0 \u00a0 \u00a0 --output_dir=MAE \\\u00a0 \u00a0 \u00a0 --overwrite_output_dir=true \\\u00a0 \u00a0 \u00a0 --logging_dir=./tensorboard-metrics \\\u00a0 \u00a0 \u00a0 --tpu_metrics_debug=true'\n```\n\u5728\u6703\u8a71\u7d50\u675f\u6642\u522a\u9664 TPU \u548c\u6392\u5165\u968a\u5217\u7684\u8cc7\u6e90\u3002\n```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME}\u00a0 \u00a0--project=${PROJECT_ID}\u00a0 \u00a0--zone=${ZONE}\u00a0 \u00a0--quietgcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID}\u00a0 \u00a0--project=${PROJECT_ID}\u00a0 \u00a0--zone=${ZONE}\u00a0 \u00a0--quiet\n```\n\u4e0b\u8868\u986f\u793a\u4e86\u4e0d\u540c\u52a0\u901f\u5668\u985e\u578b\u7684\u57fa\u6e96\u541e\u5410\u91cf\u3002\n| 0     | 1   | 2   | 3   |\n|:------------------|:------------|:-------------|:-------------|\n| nan    | v5litepod-4 | v5litepod-16 | V5litepod-64 |\n| \u7d00\u5143    | 3   | 3   | 3   |\n| \u5168\u5c40\u6279\u91cf\u5927\u5c0f  | 32   | 128   | 512   |\n| \u541e\u5410\u91cf\uff08\u793a\u4f8b/\u79d2\uff09 | 201   | 657   | 2844   |\n## TensorFlow 2.x\n### \u5728\u55ae\u500b\u4e3b\u6a5f v5e \u4e0a\u8a13\u7df4 Resnet\n\u672c\u6559\u7a0b\u4ecb\u7d39\u5982\u4f55\u4f7f\u7528\u865b\u69cb\u6578\u64da\u96c6\u5728 `v5litepod-4` \u6216 `v5litepod-8` \u4e0a\u8a13\u7df4 ImageNet\u3002\u5982\u679c\u8981\u4f7f\u7528\u5176\u4ed6\u6578\u64da\u96c6\uff0c\u8acb\u53c3\u95b1 [\u6e96\u5099\u6578\u64da\u96c6](https://github.com/google/flax/blob/main/examples/imagenet/README.md#preparing-the-dataset) \u3002- \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your-project-IDexport ACCELERATOR_TYPE=v5litepod-4export ZONE=us-east1-cexport RUNTIME_VERSION=tpu-vm-tf-2.15.0-pjrtexport TPU_NAME=your-tpu-nameexport QUEUED_RESOURCE_ID=your-queued-resource-idexport QUOTA_TYPE=quota-type\n````ACCELERATOR_TYPE` \u53ef\u4ee5\u662f `v5litepod-4` \u6216 `v5litepod-8` \u3002/\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a\u4e00\u65e6\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\u3002\u5982\u9700\u6aa2\u67e5\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u7684\u72c0\u614b\uff0c\u8acb\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\n- \u4f7f\u7528 SSH \u9023\u63a5\u5230\u60a8\u7684 TPU```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\n- \u8a2d\u7f6e\u4e00\u4e9b\u74b0\u5883\u8b8a\u91cf```\nexport MODELS_REPO=/usr/share/tpu/modelsexport PYTHONPATH=\"${MODELS_REPO}:${PYTHONPATH}\"export MODEL_DIR=gcp-directory-to-store-modelexport DATA_DIR=gs://cloud-tpu-test-datasets/fake_imagenetexport NEXT_PLUGGABLE_DEVICE_USE_C_API=trueexport TF_PLUGGABLE_DEVICE_LIBRARY_PATH=/lib/libtpu.so\n```\n- \u66f4\u6539\u6a21\u578b\u4ee3\u78bc\u5eab\u76ee\u9304\u548c\u5b89\u88dd\u8981\u6c42\u3002```\ncd ${MODELS_REPO} && git checkout r2.15.0pip install -r official/requirements.txt\n```\u904b\u884c\u8a13\u7df4\u8173\u672c\u3002\n```\npython3 official/vision/train.py \\\u00a0 \u00a0--tpu=local \\\u00a0 \u00a0--experiment=resnet_imagenet \\\u00a0 \u00a0--mode=train_and_eval \\\u00a0 \u00a0--config_file=official/vision/configs/experiments/image_classification/imagenet_resnet50_tpu.yaml \\\u00a0 \u00a0--model_dir=${MODEL_DIR} \\\u00a0 \u00a0--params_override=\"runtime.distribution_strategy=tpu,task.train_data.input_path=${DATA_DIR}/train*,task.validation_data.input_path=${DATA_DIR}/validation*,task.train_data.global_batch_size=2048,task.validation_data.global_batch_size=2048,trainer.train_steps=100\"\n```- \u522a\u9664 TPU```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n- \u522a\u9664\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8acb\u6c42```\ngcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n### \u5728\u591a\u4e3b\u6a5f v5e \u4e0a\u8a13\u7df4 Resnet\n\u672c\u6559\u7a0b\u4ecb\u7d39\u5982\u4f55\u4f7f\u7528\u865b\u69cb\u6578\u64da\u96c6\u5728 `v5litepod-16` \u6216\u66f4\u9ad8\u7248\u672c\u4e0a\u8a13\u7df4 ImageNet\u3002\u5982\u679c\u8981\u4f7f\u7528\u5176\u4ed6\u6578\u64da\u96c6\uff0c\u8acb\u53c3\u95b1 [\u6e96\u5099\u6578\u64da\u96c6](https://github.com/google/flax/blob/main/examples/imagenet/README.md#preparing-the-dataset) \u3002\n- \u5275\u5efa\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport PROJECT_ID=your_project_IDexport ACCELERATOR_TYPE=v5litepod-16export ZONE=us-east1-cexport RUNTIME_VERSION=tpu-vm-tf-2.15.0-pod-pjrtexport TPU_NAME=your_tpu_nameexport QUEUED_RESOURCE_ID=your-queued-resource-idexport QUOTA_TYPE=quota-type\n````ACCELERATOR_TYPE` \u53ef\u4ee5\u5927\u65bc `v5litepod-16` \u3002\n- [\u5275\u5efa TPU \u8cc7\u6e90](https://cloud.google.com/tpu/docs/queued-resources?hl=zh-cn) \uff1a```\ngcloud alpha compute tpus queued-resources create ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--node-id=${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--accelerator-type=${ACCELERATOR_TYPE} \\\u00a0 \u00a0--runtime-version=${RUNTIME_VERSION} \\\u00a0 \u00a0--${QUOTA_TYPE}\n``` **\u6ce8\u610f** \uff1a\u4e00\u65e6\u6392\u968a\u7684\u8cc7\u6e90\u8655\u65bc `ACTIVE` \u72c0\u614b\uff0c\u60a8\u5c31\u53ef\u4ee5\u901a\u904e SSH \u9023\u63a5\u5230 TPU \u865b\u64ec\u6a5f\u3002\u5982\u9700\u6aa2\u67e5\u5df2\u52a0\u5165\u968a\u5217\u8cc7\u6e90\u7684\u72c0\u614b\uff0c\u8acb\u4f7f\u7528\u4ee5\u4e0b\u547d\u4ee4\uff1a```\ngcloud alpha compute tpus queued-resources describe ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\n- \u4f7f\u7528 SSH \u9023\u63a5\u5230\u60a8\u7684 TPU\uff08\u5de5\u4f5c\u5668\u96f6\uff09```\ngcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \u00a0\\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE}\n```\n- \u8a2d\u7f6e\u4e00\u4e9b\u74b0\u5883\u8b8a\u91cf```\nexport MODELS_REPO=/usr/share/tpu/modelsexport PYTHONPATH=\"${MODELS_REPO}:${PYTHONPATH}\"export MODEL_DIR=gcp-directory-to-store-modelexport DATA_DIR=gs://cloud-tpu-test-datasets/fake_imagenetexport TPU_LOAD_LIBRARY=0export TPU_NAME=your_tpu_name\n```\n- \u66f4\u6539\u6a21\u578b\u4ee3\u78bc\u5eab\u76ee\u9304\u548c\u5b89\u88dd\u8981\u6c42\u3002```\n\u00a0cd $MODELS_REPO && git checkout r2.15.0\u00a0pip install -r official/requirements.txt\n```\u904b\u884c\u8a13\u7df4\u8173\u672c\u3002\n```\npython3 official/vision/train.py \\\u00a0 \u00a0--tpu=${TPU_NAME} \\\u00a0 \u00a0--experiment=resnet_imagenet \\\u00a0 \u00a0--mode=train_and_eval \\\u00a0 \u00a0--model_dir=${MODEL_DIR} \\\u00a0 \u00a0--params_override=\"runtime.distribution_strategy=tpu,task.train_data.input_path=${DATA_DIR}/train*, task.validation_data.input_path=${DATA_DIR}/validation*\"\n```- \u522a\u9664 TPU```\ngcloud alpha compute tpus tpu-vm delete ${TPU_NAME} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```\n- \u522a\u9664\u5df2\u52a0\u5165\u968a\u5217\u7684\u8cc7\u6e90\u8acb\u6c42```\ngcloud alpha compute tpus queued-resources delete ${QUEUED_RESOURCE_ID} \\\u00a0 \u00a0--project=${PROJECT_ID} \\\u00a0 \u00a0--zone=${ZONE} \\\u00a0 \u00a0--quiet\n```", "guide": "Cloud TPU"}