{"title": "Cloud TPU - Add a Persistent Disk to a TPU VM", "url": "https://cloud.google.com/tpu/docs/setup-persistent-disk", "abstract": "# Cloud TPU - Add a Persistent Disk to a TPU VM\n# Add a Persistent Disk to a TPU VM\nA TPU VM includes a 100GB boot disk. For some scenarios, your TPU VM might need additional storage for training or preprocessing. You can add a [Persistent Disk](/compute/docs/disks#pdspecs) to expand your local disk capacity.\n", "content": "## Overview\nA Persistent Disk attached to a single-device TPU (v2-8, v3-8, v4-8, etc.) can be configured as `read-write` or `read-only` . When you attach a Persistent Disk to a TPU VM that is part of a TPU Pod, the disk is attached to each TPU VM in that Pod. To prevent two or more TPU VMs from a Pod from writing to a Persistent Disk at once, all Persistent Disks attached to a TPU VM in a Pod must be configured as `read-only` . `read-only` disks are useful for storing a dataset for processing on a TPU Pod.\nAfter creating and attaching a Persistent Disk to your TPU VM, you must mount the Persistent Disk, specifying where in the file system the Persistent Disk can be accessed. For more information, see [Mounting a disk](/compute/docs/disks/format-mount-disk-linux#mounting) .\n## Prerequisites\nYou need to have a Google Cloud account and project set up before using the following procedures. If you don't already have a Cloud TPU project set up, follow the procedure in [Set up an account and a Cloud TPU project](/tpu/docs/setup-gcp-account) before continuing.\n## High-level steps\nThe high-level steps to set up a Persistent Disk:\n- [Create a Persistent Disk](#create-pd) \n- [Attach a Persistent Disk to a TPU VM](#attach-pd) \n- [Mount the Persistent Disk](#mount-pd) \n- [Clean up TPU VM and Persistent Disk resources](#cleanup) ## Setting up a TPU VM and a Persistent Disk\nYou can attach a Persistent Disk to a TPU VM when you create the TPU VM. You can also attach a Persistent Disk to an existing TPU VM.\n### Create a Persistent Disk\nUse the following command to create a Persistent Disk:\n```\n\u00a0 $ gcloud compute disks create disk-name \\\u00a0 \u00a0 --size disk-size \u00a0\\\u00a0 \u00a0 --zone zone \\\u00a0 \u00a0 --type pd-balanced\n```### Attach a Persistent Disk\nYou can attach a Persistent Disk to your TPU VM when you create the TPU VM or you can add one after the TPU VM is created.\n**Note:** The TPU software version you specify when launching the TPU VM depends on  the framework you are using, TensorFlow, PyTorch, or JAX. To determine  which TPU software version to specify, refer to [Cloud TPU software versions.](/tpu/docs/supported-tpu-versions#tpu_software_versions)\nUse the `--data-disk` flag to attach a Persistent Disk when you create a TPU VM. If you are creating a TPU Pod, you must specify `mode=read-only` . If you are creating a single TPU device, you can specify `mode=read-only` or `mode=read-write` . The following command creates a single TPU and sets the Persistent Disk mode to `read-write` :\n```\n\u00a0 $ gcloud compute tpus tpu-vm create tpu-name \\\u00a0 \u00a0 --project project-id \\\u00a0 \u00a0 --zone=zone \\\u00a0 \u00a0 --accelerator-type=v3-8 \\\u00a0 \u00a0 --version=Cloud TPU software version \\\u00a0 \u00a0 --data-disk source=projects/project-id/zones/zone/disks/disk-name,mode=read-write\n```\n**Note:** To create a TPU Pod, set `--accelerator-type` to a TPU Pod type, for example `v4-32` :\nUse the `gcloud alpha compute tpus tpu-vm attach-disk` command to attach a Persistent Disk to an existing TPU VM. See the [gcloud](/sdk/gcloud/reference/alpha/compute/tpus/tpu-vm/attach-disk) documentation for more details and examples.\n```\n\u00a0 $ gcloud alpha compute tpus tpu-vm attach-disk tpu-name \\\u00a0 \u00a0 --zone=zone \\\u00a0 \u00a0 --disk=disk-name \\\u00a0 \u00a0 --mode=disk-mode\n```\nIf you want to delete the Persistent Disk when you delete the TPU VM, you need to set the auto-delete state of the Persistent Disk using the following command:\n**Important:** You must run the `gcloud compute instances set-disk-auto-delete` command from your local Cloud Shell and not in the TPU VM.\n```\n$ gcloud compute instances set-disk-auto-delete vm-instance \\\u00a0 --zone=zone \\\u00a0 --auto-delete \\\u00a0 --disk=disk-name\n```If your VM shuts down for any reason, the Persistent Disk might be disconnected. See [Configure automatic mounting on system restart](/compute/docs/disks/format-mount-disk-linux#configure_automatic_mounting_on_vm_restart) to cause your Persistent Disk to automatically mount on VM restart.\nFor more information about automatically deleting a Persistent Disk, see [Modify a Persistent Disk](/compute/docs/disks/modify-persistent-disk) .\n### Mount a Persistent Disk\nIn order to access a Persistent Disk from a TPU VM, you must mount the disk. This specifies a location in the TPU VM file system where the Persistent Disk can be accessed.\n- Connect to your TPU VM using SSH:```\n$ gcloud compute tpus tpu-vm ssh tpu-name --zone zone\n```When working with a TPU Pod, there is a one TPU VM for each TPU in the Pod. The preceding command will work for both TPU devices and TPU Pods. If you are using TPU Pods this command will connect you to the first TPU in the Pod (also called worker 0).\n- From the TPU VM, list the disks attached to the TPU VM:```\n(vm)$ sudo lsblk\n```The output from the `lsblk` command should look like the following:```\nNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT\nloop0  7:0 0 55.5M 1 loop /snap/core18/1997\nloop1  7:1 0 67.6M 1 loop /snap/lxd/20326\nloop2  7:2 0 32.3M 1 loop /snap/snapd/11588\nloop3  7:3 0 32.1M 1 loop /snap/snapd/11841\nloop4  7:4 0 55.4M 1 loop /snap/core18/2066\nsda  8:0 0 300G 0 disk\n\u251c\u2500sda1 8:1 0 299.9G 0 part /\n\u251c\u2500sda14 8:14 0  4M 0 part\n\u2514\u2500sda15 8:15 0 106M 0 part /boot/efi\nsdb  8:16 0 10G 0 disk <== Persistent Disk\n```In this example `sda` is the boot disk and `sdb` is the name of the newly attached Persistent Disk. The name of the attached Persistent Disk will depend upon how many persistent disks are attached to the VM.When using a TPU Pod, you will need to mount the Persistent Disk on all TPU VMs in your Pod. The name of the Persistent Disk should be the same for all TPU VMs, but it is not guaranteed. For example if you detach and then re-attach the Persistent Disk, the device name will be incremented, changing from `sdb` to `sdc` , and so on.\n- If the disk has not been formatted, format the attached Persistent Disk now: **Note:** If you attached a Persistent Disk to a TPU Pod, the disk must already be formatted because it is attached as a read-only volume.```\n(vm)$ sudo mkfs.ext4 -m 0 -E lazy_itable_init=0,lazy_journal_init=0,discard /dev/sdb\n```\n- Create a directory to mount the Persistent Disk:If you are using a TPU device, run the following command to create a directory to mount the Persistent Disk:```\n(vm)$ sudo mkdir -p /mnt/disks/persist\n```If you are using a TPU Pod, run the following command outside of your TPU VM. This will create the directory on all TPU VMs in the Pod.```\n(vm)$ gcloud compute tpus tpu-vm ssh $TPU_NAME --worker=all --command=\"sudo mkdir -p /mnt/disks/persist\"\n```\n- Mount the Persistent Disk:If you are using a TPU device, run the following command to mount the Persistent Disk on your TPU VM.```\n(vm)$ sudo mount -o discard,defaults /dev/sdb /mnt/disks/persist\n```If you are using a TPU Pod, run the following command outside of your TPU VM. It will mount the Persistent Disk on all TPU VMs in your Pod.```\n(vm)$ gcloud compute tpus tpu-vm ssh $TPU_NAME --worker=all --command=\"sudo mount -o discard,defaults /dev/sdb /mnt/disks/persist\"\n```## Clean up\nDelete your TPU resources when you are done with them.\n- Disconnect from the Compute Engine instance, if you have not already done so:```\n(vm)$ exit\n```Your prompt should now be `username@projectname` , showing you are in the Cloud Shell.\n- Delete your Cloud TPU and Compute Engine resources.```\n$ gcloud compute tpus tpu-vm delete tpu-name \\\u00a0--zone=zone\n```\n- Verify the resources have been deleted by running `gcloud list` . The deletion might take several minutes. The output from `gcloud list` shouldn't display any of the TPU VM resources created by this procedure.\n```\n$ gcloud compute tpus tpu-vm list --zone=zone\n```\n```\n$ gcloud compute tpus execution-groups list --zone zone\n```\n- Verify that the Persistent Disk was automatically deleted when the TPU VM was deleted by listing all disks in the zone where you created the Persistent Disk:```\n$ gcloud compute disks list --filter=\"zone:( us-central1-b )\"\n```If the Persistent Disk was not deleted when the TPU VM was deleted, use the following commands to delete it:```\n$ gcloud compute disks delete disk-name \\--zone zone\n```", "guide": "Cloud TPU"}