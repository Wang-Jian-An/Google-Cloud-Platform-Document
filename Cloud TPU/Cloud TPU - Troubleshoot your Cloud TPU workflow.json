{"title": "Cloud TPU - Troubleshoot your Cloud TPU workflow", "url": "https://cloud.google.com/tpu/docs/troubleshooting/troubleshooting", "abstract": "# Cloud TPU - Troubleshoot your Cloud TPU workflow\n# Troubleshoot your Cloud TPU workflow\nOnce you have your training or inference workload running on TPUs, the next step is to ensure your workload is working as expected. Cloud TPU generates metrics and logs that enable you to look for and debug any TPU VMs that are not behaving as expected. We refer to such VMs as throughout this documentation.\nThe general troubleshooting workflow is:\n- View Cloud TPU metrics to check for outlier TPU VMs\n- View Cloud TPU logs for the outlier TPU VMs\n- Profile your workload\nYou can view metrics and logs in the [Metrics Explorer](/monitoring/charts/metrics-explorer) and the [Logs Explorer](/logging/docs/view/logs-explorer-interface) in the Google Cloud console. You can also use monitoring and logging dashboards to collect all Cloud TPU related metrics and logs in individual dashboards.\n", "content": "## Cloud TPU VM metrics\nCloud Monitoring automatically collects metrics from your TPUs and their host Compute Engine VMs. Metrics track numerical quantities over time, for example, CPU utilization, network usage, or TensorCore idle duration. For more information on Cloud TPU metrics, see [Monitoring TPU VMs](/tpu/docs/troubleshooting/tpu-vm-monitoring) .\n## Cloud TPU logs\nCloud Logging automatically collects logs from your TPUs and their host Compute Engine VMs. Cloud Logging tracks events generated by Cloud TPU. You can also instrument your code to generate logs. Two types of logs are generated by Cloud TPU:\n- TPU Worker logs\n- Audited resource logs\nTPU Worker logs contain information about a specific TPU worker in a specific zone, for example the amount of memory available on the TPU worker (system_available_memory_GiB).\nAudited Resource logs contain information about when a specific Cloud TPU API was called and who made the call. For example `CreateNode` , `UpdateNode` , and `DeleteNode` .\nYou can also use the `cloud-tpu-diagnostics` PyPi package to write stack traces to logs. For more information, see [Debugging TPU VMs](/tpu/docs/troubleshooting/debugging) .\nFor more information about logs, see [Logging](/tpu/docs/troubleshooting/tpu-vm-monitoring#locate_logs) .\n## Monitoring and logging dashboards\nHaving a single page in the Google Cloud console can make viewing and interpreting Cloud TPU-related metrics and logs easier. The [monitoring-debugging](https://github.com/google/cloud-tpu-monitoring-debugging) GitHub repository contains a set of scripts and configuration files that use [Terraform](https://developer.hashicorp.com/terraform) to automatically deploy dashboards that contain all Cloud TPU related metrics and logs in dashboards. To set up these dashboards in your Google Cloud project, see [Monitoring and Logging Dashboards](/tpu/docs/troubleshooting/dashboards) .\n## Profiling your workloads on TPU VMs\nProfiling lets you optimize your model's training performance on TPU VMs. You use [TensorBoard](https://www.tensorflow.org/tensorboard) and the [TPU TensorBoard plug-in](/tpu/docs/profile-tpu-vm#install-plugin) to profile your model. For more information about how to profile your workload, see [Profile your model on TPU VMs](/tpu/docs/profile-tpu-vm) .\nFor more information about using TensorBoard with one of the supported frameworks, see the following documents:\n- [TensorFlow performance guide](/tpu/docs/tensorflow-performance-guide) \n- [PyTorch performance guide](/tpu/docs/pytorch-xla-performance-profiling-tpu-vm) \n- [JAX performance guide](https://jax.readthedocs.io/en/latest/profiling.html)", "guide": "Cloud TPU"}