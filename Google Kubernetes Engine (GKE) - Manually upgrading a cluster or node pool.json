{"title": "Google Kubernetes Engine (GKE) - Manually upgrading a cluster or node pool", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview", "abstract": "# Google Kubernetes Engine (GKE) - Manually upgrading a cluster or node pool\nBy default, [automatic upgrades](/kubernetes-engine/docs/concepts/cluster-upgrades#upgrading_automatically) are enabled for Google Kubernetes Engine (GKE) clusters and for GKE Standard node pools.\nThis page explains how to manually request an upgrade or downgrade for the control plane or nodes of a GKE cluster. You can manually upgrade the version as follows:\n- **Autopilot** : [Upgrade the control plane version](#upgrade_cp) .\n- **Standard** : [Upgrade the control plane version](#upgrade_cp) and the [node pool version](#upgrading-nodes) .\nTo upgrade a cluster, GKE updates the version the control plane and nodes are running. Clusters are upgraded to either a newer minor version (for example, 1.24 to 1.25) or newer patch version (for example, 1.24.2-gke.100 to 1.24.5-gke.200). For more information, see [GKE versioning and support](/kubernetes-engine/versioning) .\nYou can learn more about [how automatic and manual cluster upgrades work](/kubernetes-engine/docs/concepts/cluster-upgrades) . You can also control when auto-upgrades can and cannot occur by configuring [maintenance windows and exclusions](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) .\n**Note about terminology:** A cluster's control plane and nodes do not necessarily run the same version at all times. In this topic, [cluster upgrade](#upgrading_the_cluster) and are used interchangeably, and are differentiated from [node upgrades](#upgrading-nodes) .\nNew versions of GKE are [announced regularly](/kubernetes-engine/docs/release-notes) , and you can receive notice about the new versions a specific cluster can be upgraded to with [cluster notifications](/kubernetes-engine/docs/concepts/cluster-notifications) .\nTo learn about about available versions, see [Versioning](/kubernetes-engine/versioning) . To learn more about clusters, see [Cluster architecture](/kubernetes-engine/docs/concepts/cluster-architecture) . For guidance on upgrading clusters, see [Best practices for upgrading clusters](/kubernetes-engine/docs/best-practices/upgrading-clusters) .\n", "content": "## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n### Save your data to persistent disks\nBefore upgrading a node pool, you must ensure that any data you wish to keep is stored in a Pod using [persistent volumes](/kubernetes-engine/docs/concepts/persistent-volumes) which use [persistent disks](/compute/docs/disks#pdspecs) . Persistent disks are unmounted, rather than erased, during upgrades, and their data is \"handed off\" between Pods.\nThe following restrictions pertain to persistent disks:\n- The nodes on which Pods are running must be Compute Engine VMs\n- Those VMs need to be in the same Compute Engine project and zone as the persistent disk\nTo learn how to add a persistent disk to an existing node instance, see [Adding or resizing zonal persistent disks](/compute/docs/disks/add-persistent-disk#create_disk) in the Compute Engine documentation.\n## About upgrading\nA cluster's [control plane](#upgrade_cp) and [nodes](#upgrade_nodes) are upgraded separately.\nCluster control planes are always [upgraded](/kubernetes-engine/upgrades#automatic_cp_upgrades) on a regular basis, regardless of whether your cluster is enrolled in a [release channel](/kubernetes-engine/docs/concepts/release-channels) or not.\nTo receive upgrade notifications proactively, refer to [Receive cluster notifications](/kubernetes-engine/docs/how-to/cluster-notifications) .\n### Limitations\n[Alpha clusters](/kubernetes-engine/docs/concepts/alpha-clusters) cannot be upgraded.\n### Supported versions\nThe [release notes](/kubernetes-engine/docs/release-notes) announce when new versions become available and when older versions are no longer available. At any time, you can list all supported cluster and node versions using this command:\n```\ngcloud container get-server-config\n```\nIf your cluster is enrolled in a release channel, you can upgrade to a patch version in a different release channel with the same minor version as your control plane. For example, you can upgrade your cluster from version 1.21.12-gke.1700 in the Regular channel to 1.21.13-gke.900 in the Rapid channel. For more information, refer to [Running patch versions from a newer channel](/kubernetes-engine/docs/concepts/release-channels#newer-patch-versions) . All Autopilot clusters are enrolled in a release channel.\n### Downgrading limitations\nYou can downgrade the version of your cluster to an earlier version in certain scenarios.\nTo mitigate an unsuccessful cluster control plane upgrade, you can [downgrade your control plane to a previous patch release](#downgrading_clusters) if the version is an [earlier patch release within the same minor version](/kubernetes-engine/versioning#versioning_scheme) . For example, if your cluster's control plane is running GKE 1.25.3-gke.400, you can downgrade the control plane to 1.25.2-gke.100, if that version is still [available](/kubernetes-engine/versioning#available_versions) .\nYou can't downgrade a Kubernetes cluster control plane to an earlier minor version. For example, if your control plane runs GKE version 1.25, you cannot downgrade to 1.24. If you attempt to do this, the following error message appears:\n```\nERROR: (gcloud.container.clusters.upgrade) ResponseError: code=400,\nmessage=Master cannot be upgraded to \"1.24.3-gke.100\": specified version is not\nnewer than the current version.\n```\nYou can't downgrade the minor version of a cluster's control plane, so we recommend that you [test and qualify minor version upgrades](/kubernetes-engine/docs/best-practices/upgrading-clusters#test-versions) with clusters in a testing environment when a new minor version [becomes available but before the version becomes default](/kubernetes-engine/docs/concepts/release-channels#what_versions_are_available_in_a_channel) . This is especially recommended if your cluster might be affected by significant changes in the next minor version, such as [deprecated APIs or features](/kubernetes-engine/docs/deprecations) being removed.\nTo mitigate an unsuccessful node pool upgrade, you can downgrade a node pool to an earlier patch release or minor version. Ensure that you don't downgrade nodes to a version that is more than [two minor versions behind the cluster control plane version](https://kubernetes.io/releases/version-skew-policy/#supported-version-skew) .\n## Upgrading the cluster\nGoogle upgrades clusters and nodes automatically. For more control over which auto-upgrades your cluster and its nodes receive, you can enroll it in a [release channel](/kubernetes-engine/docs/concepts/release-channels) . All Autopilot clusters are automatically enrolled in a release channel.\nTo learn more about managing your cluster's GKE version, see [Upgrades](/kubernetes-engine/upgrades#automatic_cp_upgrades) .\nYou can initiate a [manual upgrade](#upgrade_cp) any time after a new version becomes available.\n### Manually upgrading the control plane\n**Note:** You cannot upgrade your cluster more than . For example, you can upgrade a cluster from version 1.25 to 1.26, but not directly from 1.25 to 1.27. For more information, refer to [Can I skip versions during a cluster upgrade?](/kubernetes-engine/versioning#skip-versions) .\nWhen initiating a cluster upgrade, you can't modify the cluster's configuration for several minutes, until the control plane is accessible again. If you need to prevent downtime during control plane upgrades, consider using an [Autopilot cluster](/kubernetes-engine/docs/concepts/autopilot-overview) or a [regional Standard cluster](/kubernetes-engine/docs/concepts/regional-clusters#about_regional_clusters) . This operation does not affect the availability of the worker nodes that your workloads run on as they remain available during control plane upgrades.\nYou can manually upgrade your Autopilot or Standard control plane using the Google Cloud console or the Google Cloud CLI.\nTo see the available versions for your cluster's control plane, run the following command:\n```\ngcloud container get-server-config\n```\nTo upgrade to the default cluster version, run the following command:\n```\ngcloud container clusters upgrade CLUSTER_NAME --master\n```\nTo upgrade to a specific version that is not the default, specify the `--cluster-version` flag as in the following command:\n```\ngcloud container clusters upgrade CLUSTER_NAME --master \\\u00a0 \u00a0 --cluster-version VERSION\n```\nReplace `` with the version that you want to upgrade your cluster to. You can use a specific version, such as `1.18.17-gke.100` or you can use a version alias, like `latest` . For more information, see [Specifying cluster version](/kubernetes-engine/versioning#specifying_cluster_version) .\n **Note:** If your cluster is enrolled in a release channel, the `` must be a valid minor version for the release channel, or a valid patch version in a newer release channel. All Autopilot clusters are enrolled in a release channel.\nTo manually update your cluster control plane, perform the following steps:- Go to the **Google Kubernetes Engine** page in Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Click the desired cluster name.\n- Under **Cluster basics** , click **Upgrade Available** next to **Version** .\n- Select the desired version, then click **Save Changes** .\nAfter upgrading a Standard control plane, you can [upgrade its nodes](#upgrading-nodes) . By default, Standard nodes created using the Google Cloud console have auto-upgrade enabled, so this happens automatically. Autopilot always upgrades nodes automatically.\n### Downgrading clusters\n**Note:** Be sure you understand the [limitations](#downgrading-limitations) before attempting to downgrade a cluster.\n- Set a [maintenance exclusion](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#exclusions) before downgrading to prevent GKE from automatically upgrading the control plane after you downgrade it.\n- Downgrade the cluster control plane to an earlier patch version:```\n\u00a0gcloud container clusters upgrade CLUSTER_NAME \\\u00a0 \u00a0 \u00a0--master --cluster-version VERSION\n```\n**Note:** If your cluster is subscribed to a release channel, the `` must be an [available patch version](/kubernetes-engine/docs/concepts/release-channels#viewing_the_default_and_available_versions_for_release_channels) for the release channel. All Autopilot clusters are enrolled in a release channel.\n### Disabling cluster auto-upgrades\nInfrastructure security is high priority for GKE, and as such [control planes are upgraded](/kubernetes-engine/docs/concepts/cluster-upgrades) on a regular basis, and cannot be disabled. However, you can apply [maintenance windows and exclusions](/kubernetes-engine/docs/how-to/maintenance-windows-and-exclusions) to temporarily suspend upgrades for control planes and nodes.\nAlthough it is , you can [disable node auto-upgrade](/kubernetes-engine/docs/how-to/node-auto-upgrades#disable) .\n## Upgrading node pools\nBy default, a cluster's nodes have [auto-upgrade](/kubernetes-engine/docs/concepts/cluster-upgrades#node_pool_upgrades) enabled, and it's recommended that you don't [disableit](/kubernetes-engine/docs/how-to/node-auto-upgrades#disable) . Node auto-upgrades ensure that your cluster's control plane and node version remain in sync and in compliance with the [Kubernetes version skewpolicy](https://kubernetes.io/releases/version-skew-policy/) , which ensures that control planes are compatible with nodes up to two minor versions older than the control plane. For example, Kubernetes 1.29 control planes are compatible with Kubernetes 1.27 nodes.\nWith GKE node pool upgrades, you can choose between two configurable upgrade strategies, namely [surge upgrades](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#surge) and [blue-green upgrades](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy) .\n[Choose a strategy](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies) and [use the parameters to tune the strategy](/kubernetes-engine/docs/how-to/node-pool-upgrade-strategies) to best fit your cluster environment's needs.\nWhile a node is being upgraded, GKE stops scheduling new Pods onto it, and attempts to schedule its running Pods onto other nodes. This is similar to other events that re-create the node, such as enabling or disabling a feature on the node pool.\n**Note:** During automatic or manual node upgrades, [PodDisruptionBudgets (PDBs)](https://kubernetes.io/docs/tasks/run-application/configure-pdb/) and [Pod termination grace period](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination) are respected for a maximum of 1 hour. If Pods running on a node cannot be scheduled onto new nodes within 1 hour, the upgrade is initiated, regardless. If a workload requires more flexibility with graceful termination, we recommend using [blue-green upgrades](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy) , which provide settings for additional soak time to extend PDB checks beyond the 1 hour default. For more information about what to expect during node termination in general, see the topic about [Pods](https://kubernetes.io/docs/concepts/workloads/pods/#pod-templates) .\nThe upgrade is only complete when all nodes have been recreated and the cluster is in the desired state. When a newly-upgraded node registers with the control plane, GKE marks the node as schedulable.\nNew node instances run the desired Kubernetes version as well as:\n- The [node image](/kubernetes-engine/docs/concepts/node-images) \n- [kubelet](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/) \n- [kube-proxy](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/) \n### Manually upgrade a node pool\nYou can manually upgrade a node pool version to match the version of the control plane or to a previous version that is still available and is compatible with the control plane. You can manually upgrade multiple node pools in parallel, whereas GKE automatically upgrades only one node pool at a time.\nWhen you manually upgrade a node pool, GKE removes any [labels youadded to individual nodes using kubectl](https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/#add-a-label-to-a-node) . To avoid this, [apply labels to node pools](/kubernetes-engine/docs/how-to/update-existing-nodepools#updating_node_labels) instead.\n**Note:** Upgrading a node pool may disrupt workloads running in that node pool. To avoid this, you can create a new node pool with the desired version and migrate the workload. After migration, you can delete the old node pool.\n**Note:** If you upgrade a node pool with an Ingress in an errored state, the instance group does not sync. To work around this issue, first check the status using the `kubectl get ing` command. If the instance group is not synced, you can work around the problem by re-applying the manifest used to create the ingress.\nYou can manually upgrade your node pools to a version compatible with the control plane, using the Google Cloud console or the Google Cloud CLI.\nThe following variables are used in the commands in this section:- ``: the name of the cluster of the node pool to be upgraded.\n- ``: the name of the node pool to be upgraded.\n- ``: the Kubernetes version to which the nodes are upgraded. For example,`--cluster-version=1.7.2`or`cluster-version=latest`.\nUpgrade a node pool:\n```\ngcloud container clusters upgrade CLUSTER_NAME \\\u00a0 --node-pool=NODE_POOL_NAME\n```\nTo specify a different version of GKE on nodes, use the optional `--cluster-version` flag:\n```\ngcloud container clusters upgrade CLUSTER_NAME \\\u00a0 --node-pool=NODE_POOL_NAME \\\u00a0 --cluster-version VERSION\n```\nFor more information about specifying versions, see [Versioning](/kubernetes-engine/versioning) .\nFor more information, refer to the [gcloud container clusters upgrade](/sdk/gcloud/reference/container/clusters/upgrade) documentation.\nTo upgrade a node pool using the Google Cloud console, perform the following steps:- Go to the **Google Kubernetes Engine** page in Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Next to the cluster you want to edit, click **Actions** , then click **Edit** .\n- On the **Cluster details** page, click the **Nodes** tab.\n- In the **Node Pools** section, click the name of the node pool that you want to upgrade.\n- Click **Edit** .\n- Click **Change** under **Node version** .\n- Select the desired version from the **Node version** drop-down list, then click **Change** .\n **Note:** It may take several minutes for the node version to change.\n### Downgrading node pools\nYou can downgrade a node pool, for example, to mitigate an unsuccessful node pool upgrade. Review the [limitations](/kubernetes-engine/docs/how-to/upgrading-a-cluster#downgrading-limitations) before downgrading a node pool.\n**Note:** We recommend the [blue-green node upgrade strategy](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy) if you need to optimize for risk mitigation for node pool upgrades impacting your workloads. With this strategy, you can [rollback](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#rollback-a-blue-green-upgrade) an in-progress upgrade to the original nodes if the upgrade is unsuccessful.\n- Set a [maintenance exclusion](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#exclusions) for the cluster to prevent the node pool from being automatically upgraded by GKE after being downgraded.\n- To downgrade a node pool, specify an earlier version while following the instructions to [Manually upgrade a node pool](/kubernetes-engine/docs/how-to/upgrading-a-cluster#upgrade_nodes) .\n### Changing surge upgrade parameters\nTo learn more about changing surge upgrade parameters, see [Configure surge upgrades](/kubernetes-engine/docs/how-to/node-pool-upgrade-strategies#surge) .\n### Checking node pool upgrade status\nYou can check the status of an upgrade using [gcloud container operations](/sdk/gcloud/reference/container/operations) .\nView a list of every running and completed operation in the cluster:\n```\ngcloud container operations list\n```\nEach operation is assigned an and an operation type as well as start and end times, target cluster, and status. The list appears similar to the following example:\n```\nNAME        TYPE    ZONE   TARGET    STATUS_MESSAGE STATUS START_TIME      END_TIME\noperation-1505407677851-8039e369 CREATE_CLUSTER  us-west1-a  my-cluster       DONE 20xx-xx-xxT16:47:57.851933021Z 20xx-xx-xxT16:50:52.898305883Z\noperation-1505500805136-e7c64af4 UPGRADE_CLUSTER  us-west1-a  my-cluster       DONE 20xx-xx-xxT18:40:05.136739989Z 20xx-xx-xxT18:41:09.321483832Z\noperation-1505500913918-5802c989 DELETE_CLUSTER  us-west1-a  my-cluster       DONE 20xx-xx-xxT18:41:53.918825764Z 20xx-xx-xxT18:43:48.639506814Z\n```\nTo get more information about a specific operation, specify the operation ID as shown in the following command:\n```\ngcloud container operations describe OPERATION_ID\n```\nFor example:\n```\ngcloud container operations describe operation-1507325726639-981f0ed6\nendTime: '20xx-xx-xxT21:40:05.324124385Z'\nname: operation-1507325726639-981f0ed6\noperationType: UPGRADE_CLUSTER\nselfLink: https://container.googleapis.com/v1/projects/.../kubernetes-engine/docs/zones/us-central1-a/operations/operation-1507325726639-981f0ed6\nstartTime: '20xx-xx-xxT21:35:26.639453776Z'\nstatus: DONE\ntargetLink: https://container.googleapis.com/v1/projects/.../kubernetes-engine/docs/zones/us-central1-a/clusters/...\nzone: us-central1-a\n```\n### Checking node pool upgrade settings\nYou can see details on the node upgrade strategy being used for your node pools using the [gcloud container node-poolsdescribe](/sdk/gcloud/reference/container/node-pools/describe) command. For blue-green upgrades, the command also returns the [currentphase](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#phases-of-blue-green-upgrades) of the upgrade.\nRun the following command:\n```\ngcloud container node-pools describe NODE_POOL_NAME \\--cluster=CLUSTER_NAME\n```\nReplace the following:\n- ``: the name of the node pool to describe.\n- ``: the name of the cluster of the node pool to describe.\nThis command will output the current upgrade settings. The following example shows the output if you are using the blue-green upgrade strategy.\n```\nupgradeSettings:\n blueGreenSettings:\n nodePoolSoakDuration: 1800s\n standardRolloutPolicy:\n  batchNodeCount: 1\n  batchSoakDuration: 10s\n strategy: BLUE_GREEN\n```\nIf you are using the blue-green upgrade strategy, the output also includes details about the blue-green upgrade settings and its current intermediate phase. The following example shows what this might look like:\n```\nupdateInfo:\n blueGreenInfo:\n blueInstanceGroupUrls:\n - https://www.googleapis.com/compute/v1/projects/{PROJECT_ID}/zones/{LOCATION}/instanceGroupManagers/{BLUE_INSTANCE_GROUP_NAME}\n bluePoolDeletionStartTime: {BLUE_POOL_DELETION_TIME}\n greenInstanceGroupUrls:\n - https://www.googleapis.com/compute/v1/projects/{PROJECT_ID}/zones/{LOCATION}/instanceGroupManagers/{GREEN_INSTANCE_GROUP_NAME} \n greenPoolVersion: {GREEN_POOL_VERSION}\n phase: DRAINING_BLUE_POOL\n```\n### Canceling a node pool upgrade\nYou can cancel an upgrade at any time. To learn more about what happens when you cancel a surge upgrade, see [Cancel a surge upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#cancel-a-surge-upgrade) . To learn more about what happens when you cancel a blue-green upgrade, see [Cancel a blue-green upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#cancel-a-blue-green-upgrade) .\n- Get the upgrade's operation ID:```\ngcloud container operations list\n```\n- Cancel the upgrade:```\ngcloud container operations cancel OPERATION_ID\n```\nRefer to the [gcloud container operations cancel](/sdk/gcloud/reference/container/operations/cancel) documentation.\n### Resuming a node pool upgrade\nYou can resume an upgrade by [manually initiating the upgrade](#upgrading-nodes) again, specifying the target version from the original upgrade.\nFor example, if you paused an ongoing upgrade to version 1.23.1-gke.100, you could resume the canceled upgrade by starting the same upgrade again on the node pool, targeting version 1.23.1-gke.100.\nTo learn more about what happens when you resume an upgrade, see [Resume a surge upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#resume-a-surge-upgrade) and [blue-green upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#resume-a-blue-green-upgrade) .\nTo resume an upgrade, use the following command:\n```\n\u00a0 \u00a0 gcloud container clusters upgrade CLUSTER_NAME \\\u00a0 \u00a0 \u00a0 --node-pool=NODE_POOL_NAME \\\u00a0 \u00a0 \u00a0 --cluster-version VERSION\n```\nReplace the following:\n- ``: the name of the node pool for which you want to resume the node pool upgrade.\n- ``: the name of the cluster of the node pool for which you want to resume the upgrade.\n- ``: the target version of the canceled node pool upgrade.\nFor more information, refer to the [gcloud container clusters upgrade](/sdk/gcloud/reference/container/clusters/upgrade) documentation.\n### Rolling back a node pool upgrade\nYou can roll back a node pool to downgrade the upgraded nodes to their original state from before the node pool upgrade started.\nUse the `rollback` command if an in-progress upgrade was [cancelled](/kubernetes-engine/docs/how-to/node-auto-upgrades#cancel) , the upgrade failed, or the upgrade is incomplete due to a [maintenance window](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#maintenance_windows) timing out. Alternatively, if you want to specify the version, follow the instructions to [downgrade](/kubernetes-engine/docs/how-to/upgrading-a-cluster#downgrading_nodes) the node pool.\n**Note:** You cannot roll back node pools once they have been successfully upgraded. You must [downgrade](/kubernetes-engine/docs/how-to/upgrading-a-cluster#downgrading_nodes) the node pool if you need the nodes to be on the previous version.\nTo learn more about what happens when you roll back a node pool upgrade, see [Roll back a surge upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#rollback-a-surge-upgrade) or [Roll back a blue-green upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#rollback-a-blue-green-upgrade) .\nTo roll back an upgrade, run the following command:\n```\ngcloud container node-pools rollback NODE_POOL_NAME \\\u00a0 --cluster CLUSTER_NAME\n```\nReplace the following:\n- ``: the name of the node pool for which to to roll back the node pool upgrade.\n- ``: the name of the cluster of the node pool for which to roll back the upgrade.\nRefer to the [gcloud container node-pools rollback](/sdk/gcloud/reference/container/node-pools/rollback) documentation.\n### Completing a node pool upgrade\n**Warning:** Using the `complete-upgrade` command is only possible with [blue-green upgrades](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy) .\nIf you are using the blue-green upgrade strategy, you can complete a node pool upgrade during the [Soak phase](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#bg-phase-soak-node-pool) , skipping the rest of the soak time.\nTo learn how completing a node pool upgrade works, see [Complete a node pool upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#complete-a-blue-green-upgrade) .\nTo complete an upgrade when using the blue-green upgrade strategy, run the following command:\n```\ngcloud container node-pools complete-upgrade NODE_POOL_NAME \\\u00a0 --cluster CLUSTER_NAME\n```\nReplace the following:\n- ``: the name of the node pool for which you want to complete the upgrade.\n- ``: the name of the cluster of the node pool for which you want to complete the upgrade.\nRefer to the [gcloud container node-pools complete-upgrade](/sdk/gcloud/reference/container/node-pools/complete-upgrade) documentation.\n## Known issues\nIf you have `PodDisruptionBudget` objects configured that are unable to allow any additional disruptions, node upgrades might fail to upgrade to the control plane version after repeated attempts. To prevent this failure, we recommend that you scale up the `Deployment` or `HorizontalPodAutoscaler` to allow the node to drain while still respecting the `PodDisruptionBudget` configuration.\nTo see all `PodDisruptionBudget` objects that do not allow any disruptions:\n```\nkubectl get poddisruptionbudget --all-namespaces -o jsonpath='{range .items[?(@.status.disruptionsAllowed==0)]}{.metadata.name}/{.metadata.namespace}{\"\\n\"}{end}'\n```\nAlthough automatic upgrades might encounter the issue, the automatic upgrade process forces the nodes to upgrade. However, the upgrade takes an extra hour for every node in the `istio-system` namespace that violates the PodDisruptionBudget.\n## Troubleshooting\n### Nodes CPU usage higher than expected\nYou might encounter an issue where some nodes are using higher CPU usage than is expected from the running Pods.\nThis can occur if your cluster or nodes are not running a [supported version](#supported-versions) . Review the [release notes](/kubernetes-engine/docs/release-notes) to ensure the versions you are using are available and supported. You can also run the following command to list all supported cluster and node versions:\n```\ngcloud container get-server-config\n```\n## What's next\n- Learn about [Cluster architecture](/kubernetes-engine/docs/concepts/cluster-architecture) .\n- Learn about [Release channels](/kubernetes-engine/docs/concepts/release-channels) .", "guide": "Google Kubernetes Engine (GKE)"}