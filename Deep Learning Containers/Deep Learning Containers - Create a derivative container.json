{"title": "Deep Learning Containers - Create a derivative container", "url": "https://cloud.google.com/deep-learning-containers/docs/derivative-container", "abstract": "# Deep Learning Containers - Create a derivative container\nThis page describes how to create a derivative container based on one of the standard available Deep Learning Containers images.\nTo complete the steps in this guide, you can use either [Cloud Shell](https://console.cloud.google.com?cloudshell=true) or any environment where the [Google Cloud CLI](/sdk/docs) is installed.\n", "content": "## Before you begin\nBefore you begin, make sure you have completed the following steps.\n- Complete the set up steps in the Before you begin section of [Gettingstarted with a local deep learningcontainer](/deep-learning-containers/docs/getting-started-local) .\n- Make sure that billing is enabled for your Google Cloud project. [Learn how to enablebilling](https://cloud.google.com/billing/docs/how-to/modify-project) \n- Enable the Artifact Registry API. [Enable theAPI](https://console.cloud.google.com/flows/enableapi?apiid=artifactregistry.googleapis.com) ## The Process\nTo create a derivative container, you'll use a process similar to this:\n- Create the initial Dockerfile and run modification commands.To start, you create a Deep Learning Containers container using one of the [available image types](/deep-learning-containers/docs/choosing-container) . Then use conda, pip, or Jupyter commands to modify the container image for your needs.\n- Build and push the container image.Build the container image, and then push it to somewhere that is accessible to your Compute Engine service account.## Create the initial Dockerfile and run modification commands\nUse the following commands to select a Deep Learning Containers image type and make a small change to the container image. This example shows how to start with a TensorFlow image and updates the image with the latest version of TensorFlow. Write the following commands to the Dockerfile:\n```\nFROM us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf-gpu:latest# Uninstall the container's TensorFlow version and install the latest versionRUN pip uninstall -y tensorflow && \\\u00a0 \u00a0 pip install tensorflow\n```\n## Build and push the container image\nUse the following commands to build and push the container image to Artifact Registry, where it can be accessed by your Google Compute Engine service account.\nCreate and authenticate the repository:\n```\nexport PROJECT=$(gcloud config list project --format \"value(core.project)\")gcloud artifacts repositories create REPOSITORY_NAME \\\u00a0 \u00a0 --repository-format=docker \\\u00a0 \u00a0 --location=LOCATIONgcloud auth configure-docker LOCATION-docker.pkg.dev\n```\nReplace the following:\n- ``: The regional or multi-regional [location](/artifact-registry/docs/repositories#locations) of the repository, for example`us`. To view a list of supported locations, run the command`gcloud artifacts locations list`.\n- ``: The name of the repository that you want to create, for example`my-tf-repo`.\nThen, build and push the image:\n```\nexport IMAGE_NAME=\"LOCATION-docker.pkg.dev/${PROJECT}/REPOSITORY_NAME/tf-custom:v1\"docker build . -t $IMAGE_NAMEdocker push $IMAGE_NAME\n```", "guide": "Deep Learning Containers"}