{"title": "Deep Learning Containers - Train in a container using Google Kubernetes Engine", "url": "https://cloud.google.com/deep-learning-containers/docs/kubernetes-container", "abstract": "# Deep Learning Containers - Train in a container using Google Kubernetes Engine\nThis page shows you how to run a training job in a Deep Learning Containers instance, and run that container image on a Google Kubernetes Engine cluster.\n", "content": "## Before you begin\nBefore you begin, make sure you have completed the following steps.\n- Complete the set up steps in the Before you begin section of [Gettingstarted with a local deep learningcontainer](/deep-learning-containers/docs/getting-started-local) .\n- Make sure that billing is enabled for your Google Cloud project. [Learn how to enablebilling](https://cloud.google.com/billing/docs/how-to/modify-project) \n- Enable the Google Kubernetes Engine, Compute Engine, and Container Registry APIs. [Enable theAPIs](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com,compute_component,containerregistry.googleapis.com) ## Open your command line tool\nYou can follow this guide using [Cloud Shell](https://cloud.google.com/shell) or command line tools locally. Cloud Shell comes preinstalled with the `gcloud` , `docker` , and `kubectl` command-line tools used in this tutorial. If you use Cloud Shell, you don't need to install these command-line tools on your workstation.\nTo use Cloud Shell, complete the following steps.- Go to the [Google Cloud console](https://console.cloud.google.com/) .\n- Click the **Activate Cloud Shell** button at the top of the console window.A Cloud Shell session opens inside a new frame at the bottom of the console and displays a command-line prompt.\nTo use your local command line, complete the following steps.- Using the gcloud CLI, install the [Kubernetes](https://kubernetes.io/) command-line tool. `kubectl` is used to communicate with Kubernetes, which is the cluster orchestration system of Deep Learning Containers clusters:```\ngcloud components install kubectl\n```You installed Google Google Cloud CLI and [Docker](https://docs.docker.com/engine/installation/) already when you completed the [getting startedsteps](/deep-learning-containers/docs/getting-started-local) .## Create a GKE cluster\nRun the following command to create a two-node cluster in GKE named `pytorch-training-cluster` :\n```\ngcloud container clusters create pytorch-training-cluster \\\u00a0 \u00a0 --num-nodes=2 \\\u00a0 \u00a0 --zone=us-west1-b \\\u00a0 \u00a0 --accelerator=\"type=nvidia-tesla-p100,count=1\" \\\u00a0 \u00a0 --machine-type=\"n1-highmem-2\" \\\u00a0 \u00a0 --scopes=\"gke-default,storage-rw\"\n```\nFor more information on these settings, see the [documentation on creatingclusters for runningcontainers](https://cloud.google.com/sdk/gcloud/reference/container/clusters/create) .\nIt may take several minutes for the cluster to be created.\nAlternatively, instead of creating a cluster, you can use an existing cluster in your Google Cloud project. If you do this, you may need to run the following command to make sure the `kubectl` command-line tool has the proper credentials to access your cluster:\n```\ngcloud container clusters get-credentials YOUR_EXISTING_CLUSTER\n```\nNext, [install the NVIDIA GPU devicedrivers](https://cloud.google.com/kubernetes-engine/docs/how-to/gpus#installing_drivers) .\n## Create the Dockerfile\nThere are many ways to build a container image. These steps will show you how to build one to run a Python script named `trainer.py` .\nTo view a list of container images available:\n```\ngcloud container images list \\\u00a0 --repository=\"gcr.io/deeplearning-platform-release\"\n```\nYou may want to go to [Choosing a container](/deep-learning-containers/docs/choosing-container) to help you select the container that you want.\nThe following example will show you how to place a Python script named `trainer.py` into a specific PyTorch deep learning container type.\nTo create the dockerfile, write the following commands to a file named `Dockerfile` . This step assumes that you have code to train a machine learning model in a directory named `model-training-code` and that the main Python module in that directory is named `trainer.py` . In this scenario, the container will be removed once the job completes, so your training script should be configured to output to Cloud Storage (see [an example of a script that outputs toCloud Storage](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/pytorch/containers/quickstart/mnist/trainer/mnist.py) ) or to output to [persistent storage](https://cloud.google.com/kubernetes-engine/docs/concepts/persistent-volumes) .\n```\nFROM gcr.io/deeplearning-platform-release/pytorch-gpuCOPY model-training-code /trainCMD [\"python\", \"/train/trainer.py\"]\n```\n## Build and upload the container image\nTo build and upload the container image to Container Registry, use the following commands:\n```\nexport PROJECT_ID=$(gcloud config list project --format \"value(core.project)\")export IMAGE_REPO_NAME=pytorch_custom_containerexport IMAGE_TAG=$(date +%Y%m%d_%H%M%S)export IMAGE_URI=gcr.io/$PROJECT_ID/$IMAGE_REPO_NAME:$IMAGE_TAGdocker build -f Dockerfile -t $IMAGE_URI ./docker push $IMAGE_URI\n```\n## Deploy your application\nCreate a file named pod.yaml with the following contents, replacing with your image's URI.\n```\napiVersion: v1kind: Podmetadata:\u00a0 name: gke-training-podspec:\u00a0 containers:\u00a0 - name: my-custom-container\u00a0 \u00a0 image: IMAGE_URI\u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: 1\n```\nUse the `kubectl` command-line tool to run the following command and deploy your application:\n```\nkubectl apply -f ./pod.yaml\n```\nTo track the pod's status, run the following command:\n```\nkubectl describe pod gke-training-pod\n```", "guide": "Deep Learning Containers"}