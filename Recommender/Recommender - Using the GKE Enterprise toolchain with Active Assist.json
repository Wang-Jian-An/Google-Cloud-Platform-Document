{"title": "Recommender - Using the GKE Enterprise toolchain with Active Assist", "url": "https://cloud.google.com/recommender/docs/use-anthos-toolchain-with-active-assist", "abstract": "# Recommender - Using the GKE Enterprise toolchain with Active Assist\nThis document is part of a series that discusses architectural patterns that enterprises can use to optimize their cloud footprint at scale using Active Assist. The tutorial shows you how to build an automation pipeline for Active Assist recommendations that works with the GKE Enterprise toolchain. It's intended for people who are using Config Sync to manage their GKE Enterprise environments and [Config Connector](/config-connector/docs/overview) to manage Google Cloud resources. The other parts of the series are as follows:- [Patterns for using Active Assist at scale](/recommender/docs/patterns-for-using-active-assist-at-scale) \n- [Using serverless pipelines with Active Assist ](/recommender/docs/using-serverless-pipelines-with-active-assist) \n- Using the GKE Enterprise toolchain with Active Assist (this document)\nThe automation pipeline that you build in this tutorial can help you to achieve the following:- Scaling the use of the Active Assist portfolio in your organization.\n- Making Active Assist a part of your continuous integration and continuous delivery (CI/CD) pipeline.\n- Controlling the review and actuation of Active Assist recommendations using constructs such as GitHub issues and pull requests.\nThis tutorial also uses [kpt](https://googlecontainertools.github.io/kpt/) , an open source toolkit developed by Google to help you manage, manipulate, customize, and apply Kubernetes resource configuration data files.\n#", "content": "## ArchitectureThe following architectural diagram shows the components that you use in this tutorial.The components are used in the following ways:- A GitHub [don't repeat yourself (DRY)](https://wikipedia.org/wiki/Don%27t_repeat_yourself) repository, which is used for Config Connector templates that you deploy across projects in your Google Cloud organization.\n- One or more GitHub repositories which are specific to a project or environment and hold hydrated configuration files. These hydrated repositories are for the environments that Config Sync manages. They use Config Connector to actuate and manage Google Cloud resources in the Google Cloud organization.\n- An GKE cluster that uses Config Sync for version control and drift detection. This cluster also has Config Connector installed. Config Connector enables the cluster to manage Google Cloud resources across the Google Cloud organization.\n- A Cloud Build trigger that triggers a build when a template is pushed into the GitHub DRY repository.\n- A scheduled Cloud Build trigger that triggers a build periodically. The build job uses a kpt function. The function invokes the Active Assist Recommender APIs to fetch active recommendations. It reviews and parses recommendations to determine if the Google Cloud resources that Config Connector manages need to be resized or optimized. The kpt function creates a GitHub issue in the DRY repository with the details of the recommended change if the Config Connector-managed Google Cloud resources need to be resized or optimized.\nThe workflow for this architecture is as follows:- Authorized teams with access to the DRY repository create and manage Config Connector templates in the repository.\n- A Cloud Build job is triggered when a template is created or modified and checked into the`main`branch.\n- The Cloud Build job hydrates the templates by invoking kpt setters. The job pushes the hydrated config files to the hydrated GitHub repository. [Secret Manager](/secret-manager) is used to store GitHub deployment keys for the private repository.\n- Config Sync monitors for changes to the hydrated repository and applies updates found in the repository to the managed cluster.\n- Config Connector monitors for changes and actuates Google Cloud resources if any resources need to be created or updated as a result of the [Kubernetes Resource Model (KRM)](/blog/topics/developers-practitioners/build-platform-krm-part-1-whats-platform) changes applied by the Config Sync.\n- A scheduled Cloud Build trigger runs periodically to invoke the Recommender API to fetch active recommendations for the projects that Config Connector managed.\n- The scheduled Cloud Build job executes a custom kpt function to invoke the Recommender API and fetch and parse active recommendations.\n- The kpt function creates a GitHub issue that shows a comparison of the current resource configuration and the recommended configuration for the resource. With this approach, GitHub issues are created in the DRY repository, which makes it easier to keep track of repository changes.\n## Objectives\n- Create the following sample GitHub repositories:- A DRY repository for Config Connector KRMs.\n- A repository to hold hydrated configuration files generated using kpt setters.\n- Create an GKE cluster with Config Sync and Config Connector.\n- Create a sample kpt function to retrieve Active Assist recommendations for projects managed by Config Connector.\n- Create a Cloud Build trigger that gets triggered when a template is pushed to the`main`branch of the DRY repository.\n- Create a scheduled Cloud Build job that runs periodically to retrieve available Active Assist recommendations for the resources being managed by Config Connector.\n- Test the end to end pipeline with the stub recommendations provided in the GitHub repository for this tutorial.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Cloud Build](/cloud-build/pricing) \n- [Cloud Run](/run/pricing) \n- [Firestore](/firestore/pricing) \n- [Pub/Sub](/pubsub/pricing) \n- [Container Registry](/container-registry/pricing) \n- [Cloud Scheduler](/scheduler/pricing) \n- [Google Kubernetes Engine (GKE) Enterprise edition](/scheduler/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin\n- In the Google Cloud console, go to the project selector page. [Go to project selector](https://console.cloud.google.com/projectselector2/home/dashboard) \n- Select or create a Google Cloud project. **Note** : If you don't plan to keep the  resources that you create in this procedure, create a project instead of  selecting an existing project. After you finish these steps, you can  delete the project, removing all resources associated with the project.\n- Make a note of the Google Cloud project ID. You use this ID in the next section when you set up your environment. This project is referred to throughout the tutorial as the`build`project.\n- Enable the Cloud Build, Firestore, App Engine, Pub/Sub, Cloud Run, Cloud Scheduler, and Cloud Source Repositories APIs. [Enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=sourcerepo.googleapis.com,cloudscheduler.googleapis.com,firestore.googleapis.com,pubsub.googleapis.com,appengine.googleapis.com,run.googleapis.com,cloudbuild.googleapis.com) You use the default application credentials for this tutorial. If you are prompted to create credentials on the **Add credentials to your\nproject** page, click **Cancel.** \n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\n### Setting up your environmentIn this tutorial, you run all of the commands in Cloud Shell.- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) \n- Set variables for the project ID and project number of the current `build` Google Cloud project:```\nexport RECO_MGR_PROJECT=PROJECT_IDgcloud config set project $RECO_MGR_PROJECTexport RECO_MGR_PROJECT_NUMBER=$(gcloud projects describe $RECO_MGR_PROJECT --format='value(projectNumber)')\n```Replace `` with the project ID that you noted in the previous section.\n- Set variables for the deployment region:```\nexport REGION=us-central1export ZONE=us-central1-a\n```\n- Clone the repository that contains the code for the sample app used in this tutorial:```\ngit clone https://github.com/GoogleCloudPlatform/activeassist-anthos-toolchain.git\n```\n- Go to the project directory:```\ncd activeassist-anthos-toolchain\n```\n## Build the pipelineIn this section, you create the components to build the pipeline. Active Assist recommendations are generated based on usage patterns and system metrics. Each recommendation category can use a different default window of time to analyze usage data and metrics based on which recommendations are generated. To test the end-to-end pipeline, the repository that you cloned in an earlier step provides sample recommendations (stubs) that you use to run the end-to-end pipeline.\nAlternatively, if you are running the pipeline in a sample project that has existing resources and recommendations, you can make appropriate changes to the sample code and then run the pipeline.\n### Set up sample private GitHub repositoriesIn the following sections, you set up the sample GitHub repositories for this tutorial.\n- Create a [private GitHub repository](https://docs.github.com/en/get-started/quickstart/create-a-repo) for the DRY repository. Make a note of the name you give the repository.\n- In Cloud Shell, create an environment variable for your GitHub username and the name of the DRY repository:```\nexport REPO_OWNER=YOUR_GITHUB_USERNAMEexport DRY_REPO_NAME=YOUR_PRIVATE_DRY_REPO\n```Replace the following:- ``: your GitHub username.\n- ``: the name of your DRY repository.\n- Create a personal access token (PAT) to create issues in this repository. The pipeline creates GitHub issues if there are Active Assist recommendations that need to be reviewed. For more information about creating PATs in GitHub, see the [GitHub documentation](https://docs.github.com/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token) .When you set a **scope** for this token, select **Full control of privaterepositories** .\n- In Cloud Shell, create an environment variable for the PAT that you generated:```\nexport GITHUB_TOKEN=YOUR_PERSONAL_ACCESS_TOKEN\n```Replace `` with your own token.\n- Create a [private GitHub repository](https://docs.github.com/get-started/quickstart/create-a-repo) for the hydrated repository. Make a note of the name you give the repository.\n- In Cloud Shell, set an environment variable for the hydrated repository:```\nexport HYDRATED_REPO_NAME=YOUR_PRIVATE_HYDRATED_REPOexport HYDRATED_REPO='git@github.com:$REPO_OWNER/$HYDRATED_REPO_NAME.git'\n```Replace `` with the name of your hydrated repository.\n- Create a deploy key pair:```\nssh-keygen -t rsa -b 4096 \\-C 'active-assist-robot' \\-N '' \\-f $(pwd)/active-assist-robot\n```A deploy key lets you deploy to your private GitHub repository when you run a Cloud Build job to hydrate config files.\n- Print the generated key:```\ncat $(pwd)/active-assist-robot.pub\n```\n- Add the deploy key to the private GitHub repository. Make sure to select **Allow write access** when you add the deploy key. To learn how to add deploy keys to GitHub repositories, see the GitHub documentation for [Managing deploy keys](https://docs.github.com/developers/overview/managing-deploy-keys#setup-2) .\n### Upload GitHub keys to Secret Manager\n- In Cloud Shell, create a secret to store the private key from the deploy key pair:```\ngcloud secrets create github-ssh-key \\\u00a0 --data-file=$(pwd)/active-assist-robot\n```\n- Create a secret to store the PAT:```\necho $GITHUB_TOKEN | gcloud secrets create github-pat --data-file=```\n### Create an GKE clusterIn this section, you create a GKE cluster with the Config Connector add-on, create an identity, and configure Config Connector. You also configure [Config Sync](/anthos-config-management/docs/config-sync-overview#the_nomos_command) . You can use Config Sync to create a common configuration across all your infrastructure, including custom policies, and apply it both on-premises and in the cloud. Config Sync evaluates changes and rolls them out to all Kubernetes clusters so that your desired state is always reflected in your clusters.- In Cloud Shell, create a new GKE cluster with the [Config Connector add-on](/config-connector/docs/overview) enabled:```\ngcloud container clusters create sample-ops \\\u00a0 --machine-type n1-standard-4 \\\u00a0 --zone $ZONE \\\u00a0 --release-channel regular \\\u00a0 --addons ConfigConnector \\\u00a0 --workload-pool=$RECO_MGR_PROJECT.svc.id.goog \\\u00a0 --enable-stackdriver-kubernetes \\\u00a0 --enable-ip-alias\n```\n- Complete the following sections in the [Installing with the GKE add-on](/config-connector/docs/how-to/install-upgrade-uninstall) guide, to create an identity and configure Config Connector.- [Creating an identity](/config-connector/docs/how-to/install-upgrade-uninstall#identity) \n- [Configuring Config Connector](/config-connector/docs/how-to/install-upgrade-uninstall#addon-configuring) \n- [Install Config Sync](/anthos-config-management/docs/how-to/installing-config-sync) in the GKE cluster that you created. When you configure Config Sync, you must do the following:- Use a [token](/anthos-config-management/docs/how-to/installing-config-sync#token) to [grant Config Sync read-only access to Git](/anthos-config-management/docs/how-to/installing-config-sync#git-creds-secret) . Use the GitHub token that you [created when you set up a private DRY GitHub repository](#set_up_a_private_dry_github_repository) . The token is available through the`$GITHUB_TOKEN`environment variable.\n- [Configure Config Sync using gcloud](/anthos-config-management/docs/how-to/installing-config-sync) . Set the following settings:- **sourceFormat** :`hierarchy`\n- **syncRepo** :`https://github.com/` `` `/` ``\n- **syncBranch** :`main`\n- **secretType** :`token`\n- **policyDir** : Don't fill in this option\n### Create a Cloud Build trigger to push to the hydrated repositoryIn the following sections, you create a Cloud Build trigger that is triggered when templates are pushed to the main branch of your `` repository. This trigger runs the steps that hydrate the config-as-data KRM templates in the `` repository and pushes the hydrated configuration files to your `` repository.In this section, you [connect](/build/docs/automating-builds/build-repos-from-github#installing_the_google_cloud_build_app) the `` and `` GitHub repositories to Cloud Build.- Go to the GitHub marketplace page for the Cloud Build app. [Go to the Cloud Build app page](https://github.com/marketplace/google-cloud-build) \n- Click **Setup with Google Cloud Build** .\n- If prompted, sign in to GitHub.\n- Select **Only select repositories** .Use the **Select repositories** drop-down to enable access to your `` and `` repositories through the Cloud Build app.\n- Click **Install** .\n- Sign in to Google Cloud. The **Authorization** page is displayed and you are prompted to authorize the **Google Cloud Build** app to connect to Google Cloud.\n- Click **Authorize Google Cloud Build by GoogleCloudBuild** . You are redirected to the Google Cloud console.\n- Select your Google Cloud project.\n- Select the consent checkbox and click **Next** .\n- Click **Install** .\n- Sign in to Google Cloud. The **Authorization** page is displayed and you are prompted to authorize the **Google Cloud Build** app to connect to Google Cloud.\n- Click **Authorize Google Cloud Build by GoogleCloudBuild** . You are redirected to the Google Cloud console.\n- Select your Google Cloud project.\n- Select the consent checkbox and click **Next** .\n- In the **Select repository** page that appears, select the following GitHub repositories:- ``\n- ``\n- Click **Connect** and then click **Done** .\n- In Cloud Shell, run the following command:```\nenvsubst < cloudbuild.template.yaml > cloudbuild.yaml\n```The command generates a `cloudbuild.yaml` file.\n- Create the trigger:```\ngcloud beta builds triggers create github \\\u00a0 --name ActiveAssistDemo \\\u00a0 --repo-name=$DRY_REPO_NAME \\\u00a0 --repo-owner=$REPO_OWNER \\\u00a0 --branch-pattern=\"main\" \\\u00a0 --build-config=cloudbuild.yaml\n```\n- Give the Cloud Build service account permission to access Secret Manager:```\ngcloud secrets add-iam-policy-binding github-ssh-key \u00a0\\\u00a0 --member=\"serviceAccount:${RECO_MGR_PROJECT_NUMBER}@cloudbuild.gserviceaccount.com\" \\\u00a0 --role=\"roles/secretmanager.secretAccessor\"gcloud secrets add-iam-policy-binding github-pat \u00a0\\\u00a0 --member=\"serviceAccount:${RECO_MGR_PROJECT_NUMBER}@cloudbuild.gserviceaccount.com\" \\\u00a0 --role=\"roles/secretmanager.secretAccessor\"\n```\n## Create a scheduled Cloud Build trigger for Active Assist recommendations **Note:** You use stubs to test the pipeline in this tutorial. When you use the pipeline for your Google Cloud projects, make sure to give the Cloud Build service account the [permissions](/recommender/docs/overview#granting_permissions_to_view_and_update_recommendations_and_insights) that it needs to fetch Active Assist recommendations.\nIn the following sections, you create a scheduled Cloud Build trigger that runs periodically. This trigger fetches Active Assist recommendations using a kpt function and determines if there are any active recommendations for the resources in your `` repository. The kpt function also creates a GitHub issue in your `` repository if there are active recommendations for resource configuration that need to be reviewed and actuated.\n### Generate a Cloud Build imageIn this section, you generate a [Cloud Build](/cloud-build/docs/cloud-builders) image that has kpt, [gh](https://github.com/cli/cli) , and Node components.- In Cloud Shell, build and push a Docker image to [Container Registry](/container-registry) :```\ngcloud auth configure-dockerdocker build -t gcr.io/$RECO_MGR_PROJECT/kpt-dev-gh:1 ./recommender-kpt-functiondocker push gcr.io/$RECO_MGR_PROJECT/kpt-dev-gh:1\n```\n### Create a Cloud Build trigger for your hydrated repo\n- In Cloud Shell, create the configuration file needed to set up the scheduled Cloud Build trigger:```\n\u00a0envsubst < cloudbuild-scheduled-recommendations.template.yaml > cloudbuild-scheduled-recommendations.yaml\n```\n- Create the Cloud Build trigger:```\ngcloud beta builds triggers create github \\\u00a0 --name ActiveAssistScheduledRecommendations \\\u00a0 --repo-name=YOUR_PRIVATE_HYDRATED_REPO \\\u00a0 --repo-owner=$REPO_OWNER \\\u00a0 --branch-pattern=\"main\" \\\u00a0 --build-config=cloudbuild-scheduled-recommendations.yaml\n```\n- Get the ID of this trigger:```\nexport TRIGGER_ID=`gcloud beta builds triggers describe \\\u00a0 ActiveAssistScheduledRecommendations \\\u00a0 --format=\"value(id)\"`\n```\n### Create a Cloud Scheduler job to invoke your trigger\n- In Cloud Shell, create a service account:```\ngcloud iam service-accounts create build-invoker \\\u00a0 \u00a0--description \"Service Account used by Cloud Scheduler to invoke the sample scheduled Cloud Build job\" \\\u00a0 \u00a0--display-name \"recommender-scheduler-sa\" \\\u00a0 \u00a0--project $RECO_MGR_PROJECT\n```Cloud Scheduler jobs use this service account to run the `recommender-parser` service.\n- Give the service account the permissions to invoke a Cloud Build job:```\ngcloud projects add-iam-policy-binding $RECO_MGR_PROJECT \\\u00a0 --member serviceAccount:build-invoker@$RECO_MGR_PROJECT.iam.gserviceaccount.com \\\u00a0 --role roles/cloudbuild.builds.editor \\\u00a0 --project $RECO_MGR_PROJECT\u00a0gcloud projects add-iam-policy-binding $RECO_MGR_PROJECT \\\u00a0 \u00a0--member serviceAccount:build-invoker@$RECO_MGR_PROJECT.iam.gserviceaccount.com \\\u00a0 \u00a0--role roles/serviceusage.serviceUsageConsumer \\\u00a0 \u00a0--project $RECO_MGR_PROJECT\n```\n- Create a Cloud Scheduler job to invoke the trigger that you created in the previous step:```\ngcloud scheduler jobs create http scheduled-build \\\u00a0 \u00a0--project $RECO_MGR_PROJECT \\\u00a0 \u00a0--time-zone \"America/Los_Angeles\" \\\u00a0 \u00a0--schedule=\"0 */3 * * *\" \\\u00a0 \u00a0--uri=\"https://cloudbuild.googleapis.com/v1/projects/${RECO_MGR_PROJECT}/triggers/${TRIGGER_ID}:run\" \\\u00a0 \u00a0--description=\"Scheduler job to invoke Cloud Build\" \\\u00a0 \u00a0--oauth-service-account-email=\"build-invoker@$RECO_MGR_PROJECT.iam.gserviceaccount.com\" \\\u00a0 \u00a0--headers=\"Content-Type=application/json\" \\\u00a0 \u00a0--http-method=\"POST\" \\\n```Select `Y` if your see the following message:`There is no App Engine app in the project.`If you are prompted to choose the region where you want your App Engine application located, select the `us-central` region.\n### Commit and push the Cloud Build configuration files to GitHubPush the two Cloud Build configuration files that you created to your `` repository:\n```\ngit remote add dry https://github.com/$REPO_OWNER/$DRY_REPO_NAME.gitgit add cloudbuild.yamlgit add cloudbuild-scheduled-recommendations.yamlgit commit -m \"Added cloudbuild configuration YAMLs\"git push dry main\n```\nYou might be prompted to enter your GitHub credentials when you push to your private repository.\n### Review the outcome of the Cloud Build jobWhen you commit and push changes to your `` repository, the Cloud Build job is triggered. If the Cloud Build job runs successfully, several resources are created. In this section, you verify whether the resources are created after the Cloud Build job completes.- In Cloud Shell, in your `sample-ops` cluster, validate that you have a namespace called `activeassist-kcc` :```\nkubectl get ns | grep activeassist-kcc\n```\n- Config Connector deploys a running sample Compute Engine instance to your `` project.Validate that the Compute Engine instance is in the project:```\n\u00a0gcloud compute instances list | grep \\\u00a0computeinstance-sample-cloudmachine\n```The `MACHINE_TYPE` type for this machine is `n1-standard-1` .\n## Run end-to-end testsTo let you test the end-to-end pipeline, the repository that you cloned for this tutorial provides sample recommendations (stubs). You use these stubs to run the end-to-end pipeline. The stub imitates an Active Assist recommendation payload and has a recommendation to change the machine type for the compute engine instance that was deployed from the `n1-standard-1` instance type to the `g1-small` instance type.\nIn this section, you invoke the scheduled Cloud Build trigger manually to run the job that uses a kpt function to fetch Active Assist recommendations. You also verify that a GitHub issue is created in your `` repository.- Open the **Build Triggers page** in the Google Cloud console. [Open the Build Triggers page](https://console.cloud.google.com/cloud-build/triggers) \n- Select the `ActiveAssistScheduledRecommendations` trigger.\n- To manually test the trigger, click **Run** on the entry for your trigger on the triggers list.The trigger creates a GitHub issue in your `` repository. The issue is similar to the following:```\ngcloud auth configure-dockerdocker build -t gcr.io/$RECO_MGR_PROJECT/kpt-dev-gh:1 ./recommender-kpt-functiondocker push gcr.io/$RECO_MGR_PROJECT/kpt-dev-gh:1\n```In the sample issue, the kpt function output shows that the current `MACHINE_TYPE` type for the Compute Engine instance is `n1-standard-1` type. The Active Assist recommendation is to change it to a `g1-small` type.Version control reviewers in your enterprise can review automated GitHub issues and action them as appropriate for your enterprise.\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Learn more about Google Cloud [serverless](/serverless) technologies.\n- Read about how to [integrate Policy Intelligence recommendations into an Infrastructure as Code (IaC) pipeline](/blog/products/devops-sre/how-to-integrate-policy-intelligence-recommendations-into-an-iac-pipeline) .", "guide": "Recommender"}