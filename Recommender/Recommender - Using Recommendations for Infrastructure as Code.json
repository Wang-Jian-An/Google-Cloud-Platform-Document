{"title": "Recommender - Using Recommendations for Infrastructure as Code", "url": "https://cloud.google.com/recommender/docs/tutorial-iac", "abstract": "# Recommender - Using Recommendations for Infrastructure as Code\n", "content": "## Overview [Google Cloud Policy Intelligence](/policy-intelligence) helps enterprises understand and manage their policies to reduce their risk. By providing more visibility and automation, customers can increase security without increasing their workload.\n [Recommender](/recommender/docs) enables you to retrieve recommendations for Google Cloud resources, helping you to improve cloud security, save costs, and more. For a list of supported recommendations refer to the [Recommender documentation](/recommender/docs) . This tutorial describes using [sizing recommendations for VM instances](/compute/docs/instances/apply-sizing-recommendations-for-instances) and [Identity and Access Management (IAM) recommendations](/iam/docs/recommender-overview) . Recommender uses machine learning to provide administrators with recommendations for removing unnecessary access to Google Cloud resources and resizing Compute Engine instances for more efficient resource utilization.\nEach recommendation includes a suggested action and its impact. After reviewing recommendations for the identified impacts as well as other considerations specific to your environment, you can select the recommendations that you want to apply. You can apply recommendations manually from the Google Cloud console or you can apply them programmatically by integrating them into your Infrastructure as Code (IaC) pipeline.\nIaC enables you to automate the creation of your Google Cloud resources.You must keep your IaC repository up-to-date and route changes that are made to the Google Cloud organization through it. IaC strategies in organizations generally prove to be beneficial when they are implemented with rigor and serve as the single version of truth for your cloud infrastructure. Keeping your IaC repository up-to-date is critical to prevent drifts between the version of your infrastructure that your IaC repository reflects and what you have in the organization.\n### IAM recommendationsAmongst other leading practices, a common one is the security principle of least privilege and a careful consideration of how changes to your organization are rolled out and synchronized with your IaC repository.\n### Sizing recommendation for VMsSizing recommendations help you lower costs by providing suggestions for resizing the machine type of your instances to more efficiently use instance resources\nThis tutorial describes how to architect and build an automation pipeline to apply a Policy Intelligence recommendation programmatically. As part of this automation pipeline, you will learn how to keep your IaC repository up-to-date with the changes that you decide to make to your Google Cloud organization, based on the VM sizing and IAM policy bindings recommendation that Recommender makes available.\nThis tutorial uses [Hashicorp Terraform](https://www.terraform.io/) as the IaC tool, however the architectural patterns and components used in the described automation pipeline can be leveraged even if you are using a different IaC management tool such as [Deployment Manager](/deployment-manager/docs) . You will need to modify the open source codebase made available with this tutorial to suit your specific IaC implementation.\nThis guide is targeted at architects, product owners and developers who might be responsible for administration, security and infrastructure planning of their Google Cloud.\n### Automation pipeline architectureThe following diagram shows the components you use in this automation pipeline.A scheduled Cloud Scheduler job runs the Recommender Parser service. The service calls the Recommender API to retrieve Recommender recommendations for the projects that you specify. It then parses these VM sizing and IAM recommendations to map them to the configuration you have in your Terraform manifests. The service updates your IaC manifests to reflect these recommendations. It generates a pull request with the changes so that you can review the updates. Once you review and merge the pull request, a Cloud Build job rolls out the changes to your infrastructure in your Google Cloud organization.\nSeveral ancillary Google Cloud services are used in the pipeline for the purposes of tracking processed recommendations, generating notifications on build completion and storing Terraform state. You will learn more about these services over the course of this tutorial.\nThe following list describes the component purpose and access control requirements:## Objectives\n- Build an automation pipeline to- Proactively monitor platform Policy Intelligence recommendations\n- Parse recommendations and apply updates to an existing IaC repository\n- Learn how you can use a suite of Google Cloud services, [Hashicorp Terraform](https://www.terraform.io/) and [GitHub](https://github.com/) to build this pipeline.\n- Understand the assumptions and best practices you need to keep in mind to build this pipeline\n- Test the pipeline\n## CostsIn this document, you use the following billable components of Google Cloud:- Cloud Run\n- Cloud Build\n- Compute Engine\n- Cloud Storage\n- Firestore\n- Pub/Sub\n- Cloud Scheduler\n- Recommender\nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . ## Before you beginThis tutorial assumes that you have a [GitHub](https://github.com/) account, and are familiar with [Git](https://git-scm.com/) , [Node.js](https://nodejs.org/en/) , [Terraform](https://www.terraform.io/) and [Docker](https://www.docker.com/) .\n### Release Notes and AssumptionsThere is a lot of variability in how IaC tools and manifests are used.\nReview the following information to determine how this tutorial can fit your IaC pipeline and what kinds of changes might be required.- This pipeline uses Terraform. 0.12. Significant changes in [HCL](https://www.terraform.io/docs/configuration/syntax.html) configuration syntax or changes to the structure of the Terraform state file might introduce breaking issues.\n- This pipeline assumes that the IaC directory structures are not nested and that one IaC repository manages resources in one or more Google Cloud projects.\n- Terraform variables passed in as environment variables, command line arguments are not supported. The prototype assumes declarative configuration of Terraform variables in a tfvars file.\n- Recommender generates IAM recommendations when a subset of permissions for a role have not been used for 60 days and VM sizing recommendations follow a similar pattern. For the purposes of this tutorial, sample recommendation payloads have been provided that can be used to test the pipeline.\n- Loops within Terraform are not supported in this release\n- Terraform Modules are not supported. The codebase is open source and it is assumed that you will make any necessary specific enhancements to the parsing flow to suit your directory structure and usage of modules.\nThe current version of the open source recommender parser service is aligned to the following known limitations of [IAM recommendations](/iam/docs/recommender-overview) :- Recommendations can only be made for IAM policy bindings that are:- At the project level\n- Associated with [user accounts](/iam/docs/overview#google_account) and [user-managed service accounts](/iam/docs/service-account-types#user-managed) \n- IAM recommendations support [basic roles](/iam/docs/understanding-roles#basic) and [predefined roles](/iam/docs/understanding-roles#predefined_roles) only. [Custom roles](/iam/docs/understanding-custom-roles) and [conditional bindings](/iam/docs/conditions-overview) cannot be evaluated or recommended.\n- Recommended roles only contain a subset of the current role's permissions. No new permissions are introduced by a recommended role.\n### Prerequisites\n- Select or create two Google Cloud projects. [Go to the project selector page](https://console.cloud.google.com/projectselector2/home/dashboard) - A **build** project that hosts and runs the automation   pipeline.\n- A **test** project that hosts Google Cloud resources   used to test the automation pipeline.\n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\n- In the **test** project, enable the Recommender and Compute Engine API. [Enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=recommender.googleapis.com,compute) \n- In the **build** project, enable the Cloud Run, Firestore,  Pub/Sub and Cloud Scheduler, IAM and  CloudResourceManager APIs. [Enable the APIs](https://console.cloud.google.com/flows/enableapi?apiid=run.googleapis.com,pubsub.googleapis.com,cloudbuild.googleapis.com,cloudscheduler.googleapis.com,firestore.googleapis.com,cloudresourcemanager.googleapis.com,iam) \nWhen you finish this tutorial, you can avoid continued billing by deleting the resources you created. See [Cleaning up](#heading=h.mlrdlgcohh7k) for more detail.## Set up your environment\n- In Google Cloud console, select your`build`project.\n- In the Google Cloud console, go to Cloud Shell. [Go to Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/features) session opens and displays a command-line prompt. Cloud Shell is a shell environment with the [Google Cloud CLI](/sdk/gcloud) already installed, and with values already set for your current project. It can take a few seconds for the session to initialize.Use Cloud Shell for all of the terminal commands in this tutorial.\n- Create an environment variable to hold the project number for your `build` project using the command below:```\nexport BUILD_PROJECT_ID=$DEVSHELL_PROJECT_ID\n```\n- Create an environment variable to hold the project number for your `test` project . Copy the test project ID manually and replace with it,```\nexport TEST_PROJECT_ID=PROJECT-ID\n```\n- You assign default settings for values that are used throughout the tutorial, such as [region and zone](/compute/docs/regions-zones) . In this tutorial, you use us-central1 as the default region and us-central1-b as the default zone.\n- Set the default region and zone for this tutorial by running the following command:.```\ngcloud config set compute/zone us-central1-b --project $BUILD_PROJECT_IDgcloud config set compute/zone us-central1-b --project $TEST_PROJECT_ID\n```\n- Set your `build` project as the default project:```\ngcloud config set project $BUILD_PROJECT_ID\n```\n- Create an environment variable called `BUILD_PROJECT_NUMBER` for your `build` project number```\nexport BUILD_PROJECT_NUMBER=$(gcloud projects describe $DEVSHELL_PROJECT_ID --format='value(projectNumber)')\n```\n- Clone the [GitHub repository](https://github.com/GoogleCloudPlatform/recommender-iac-pipeline-nodejs-tutorial) for this tutorial: **Note:** Execute all the commands in this tutorial in Cloud Shell unless specified otherwise.\n## Create Bucket for Terraform StateCreate a Cloud Storage bucket in your build project to store the Terraform state file.\n```\ngsutil mb -p ${BUILD_PROJECT_ID} -l us-central1 \\\u00a0gs://recommender-tf-state-$BUILD_PROJECT_ID\n```## Create a GitHub repositoryCreate a GitHub repository to serve as the sample IaC repository- Create a new private GitHub repository. This repository serves as your IaC repository for the purposes of this tutorial\n- In the following setps, you will push the files in the `sample-iac` sub-directory of the cloned repository to your GitHub account.- In Cloud Shell, copy the `sample-iac` directory to your home directory. You will use this directory to create a new local repository and push that to GitHub.```\ncp -r recommender-iac-pipeline-nodejs-tutorial/sample-iac $HOME\n```\n- Navigate to the new directory```\ncd $HOME/sample-iac\n```\n- Initialize the repository in your local machine.```\ngit init\n```\n- Add as the remote repository, replace and with appropriate values```\ngit remote add origin https://github.com/GITHUB-ACCOUNT/IAC-REPO-NAME\n```\n- Replace the placeholders in the files in this repository with your `test` project ID and the Terraform Cloud Storage bucket name.```\nsed -i \"s|__PROJECT_ID__|${TEST_PROJECT_ID}|g\" ./terraform.tfvarssed -i \"s|__STATE_BUCKET_NAME__|recommender-tf-state-$BUILD_PROJECT_ID|g\" ./backend.tf\n```\n- Add, commit, and push to GitHub.```\ngit add .git commit -m \"First Commit\"git push origin master\n```\n- Sign in to your GitHub account when prompted.## Generate SSH keys for your repositorySet up SSH key authentication with your IaC repository in GitHub and upload the keys to Cloud Storage.- Generate SSH keys for your GitHub repository.- Generate an SSH key pair. Replace with your GitHub email address. In Cloud Shell:```\nssh-keygen -t rsa -b 4096 -m PEM -C \"your_email@example.com\"\n```\n- When you're prompted to \"Enter a file in which to save the key,\" press **Enter** . This accepts the default file location.\n- At the prompt to enter a passphrase, press **Enter** .\n- Make note of the directory that you save the downloaded SSH keys in. By default the location is `$HOME/.ssh/`\n- Copy the SSH public key that you generated to your GitHub repository as a [Deploy Key](https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys) .- Copy the SSH public key that you generated in Cloud Shell. Replace with your directory path.```\ncat SSH-KEYS-DIR/id_rsa.pub\n```\n- In your GitHub account, navigate to the repository\n- Click **Settings > Deploy Keys** .\n- Click **Add Deploy Key** and paste in the SSH public key you copied. Choose a **Title** for the key.\n- Select the check box \" **Allow write access** \"\n- Click **Save** .\n- Navigate back to your Cloud Shell session\n- Create the `known_hosts` file for GitHub. In your Cloud Shell session, run the command:```\nssh-keyscan github.com >> ~/.ssh/known_hosts\n```\n- Create a Cloud Storage bucket in your `build` project and upload your SSH keys and `known_hosts` file to it. Replace with the path to the directory where you generated the SSH keys.```\ngsutil mb -p ${BUILD_PROJECT_ID} -l us-central1 gs://github-keys-$BUILD_PROJECT_IDgsutil cp SSH-KEYS-DIR/id_rsa* gs://github-keys-$BUILD_PROJECT_IDgsutil cp SSH-KEYS-DIR/known_hosts gs://github-keys-$BUILD_PROJECT_ID\n```\n- Generate a **Personal Access Token** for GitHub. This token is used when performing Git operations using API calls that the recommender-parser service makes to generate pull requests, check-in updated IaC manifests.- In your GitHub account, in the upper-right corner of any page, click your profile photo, then click **Settings** .\n- In the left sidebar, click **Developer settings** .\n- In the left sidebar, click **Personal access tokens** \n- Click Generate new token.\n- Give your token a descriptive name.\n- Select the scopes as **repo** .\n- Click **Generate token** .\n- Copy the token to your clipboard.\n- In your Cloud Shell session, create an environment variable.```\nexport GITHUB_PAT=personal-access-token-you-copied\n```## Set up Cloud Build\n- Connect your Git repository to integrate with Cloud Build.- Go to the [Cloud Build App page](https://github.com/marketplace/google-cloud-build) in the GitHub Marketplace.\n- Scroll down and click **Setup with Google Cloud Build** at the bottom of the page.\n- If prompted, **Sign in to GitHub** .\n- Select **Only select repositories** . Use the **Select\nrepositories** drop-down list to only enable access to yourin the Cloud Build app.\n- Click **Install** .\n- Sign in to Google Cloud.The Authorization page is displayed where you are asked to authorize the **Google Cloud Build** app to connect to Google Cloud.\n- Click **Authorize Google Cloud Build by GoogleCloudBuild** . You are redirected to the Google Cloud console.\n- Select your Google Cloud project.\n- Enable the consent checkbox and click **Next** .\n- In the **Select repository** page that appears, select the GitHub repo\n- Click **Connect repository** .\n- Click **Create a Trigger** . This creates a trigger definition for you.\n- Click **Create** to save your build trigger.\nFor more information, see [Running builds on GitHub](/build/docs/run-builds-on-github#installing_the_google_cloud_build_app) .\n- The directory that you copied has a `cloudbuild.yaml` file. This configuration file outlines the steps that a Cloud Build job executes when triggered.```\nsteps:- name: hashicorp/terraform:0.12.0\u00a0 args: ['init']- name: hashicorp/terraform:0.12.0\u00a0 args: ['apply', '-auto-approve']\n```\n- Add permissions to your Cloud Build service account to allow it to create service accounts, associate roles, and virtual machines (Compute Engine instances) in the test project```\ngcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\\u00a0 --member serviceAccount:$BUILD_PROJECT_NUMBER@cloudbuild.gserviceaccount.com \\\u00a0 --role roles/compute.admin \\\u00a0 --project $TEST_PROJECT_IDgcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\\u00a0 --member serviceAccount:$BUILD_PROJECT_NUMBER@cloudbuild.gserviceaccount.com \\\u00a0 --role roles/iam.serviceAccountAdmin \\\u00a0 --project $TEST_PROJECT_IDgcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\--member serviceAccount:$BUILD_PROJECT_NUMBER@cloudbuild.gserviceaccount.com \\--role roles/iam.securityAdmin \\--project $TEST_PROJECT_ID\n```\n- [Open the Build Triggers page](https://console.cloud.google.com/cloud-build/triggers) in the Google Cloud console.\n- Select `build` project, click **Open** .\n- Update the trigger's definition:- Clickmore_vertmenu and then click **Edit** .\n- For **Configuration** , select the **Cloud Build\nconfiguration file (yaml or json)** option and type in`cloudbuild.yaml`in the text field.\n- Click **Save** .\n- To manually test the build trigger, click **Run** on your trigger's entry in the triggers list.\n- Verify that a Compute Engine instance called `tf-compute-1` and a service account called `Terraform Recommender Test` are created in your test project by the Cloud Build job you ran in the previous step\n **Note:** You might need to wait a few moments for the Cloud Build job to complete before verifying the creation of resources in your test project.## Deploy the recommender-parser Cloud Run service\n- In Cloud Shell, Change directories to the directory created by cloning the repository```\ncd $HOME/recommender-iac-pipeline-nodejs-tutorial/parser-service\n```\n- Configure Google Cloud to use a default region for Cloud Run services. In this tutorial, you use the us-central1 region but you can choose a different supported region if you prefer.```\ngcloud config set run/region us-central1\n```\n- The `parser-service` directory has a stub sub-directory which has a few sample payload JSONs for you to test the recommender-parser service with. Run the following sed commands to replace the **PROJECT_ID** placeholders in these JSONs with your test project ID.```\nsed -i \"s|__PROJECT_ID__|${TEST_PROJECT_ID}|g\" ./stub/iam.jsonsed -i \"s|__PROJECT_ID__|${TEST_PROJECT_ID}|g\" ./stub/vm.json\n```\n- Run the following command to create an environment variable for your Docker image.```\nexport IMAGE=gcr.io/$BUILD_PROJECT_ID/recommender-parser:1.0\n```\n- Build the image and upload to [Container Registry](/container-registry) ```\ngcloud builds submit --tag $IMAGE .\n```\n- Create a service account for the recommender-parser service to interact with other Google Cloud services in the pipeline. It is a good practice to grant granular permissions to your Cloud Run services, refer to [Cloud Run service identity](/run/docs/securing/service-identity) for more details.```\ngcloud beta iam service-accounts create recommender-parser-sa \\\u00a0 --description \"Service account that the recommender-parser service uses to invoke other Google Cloud services\" \\\u00a0 --display-name \"recommender-parser-sa\" \\\u00a0 --project $BUILD_PROJECT_ID\n```\n- The recommender-parser service needs to access the GitHub SSH keys and Terraform state you uploaded to Cloud Storage buckets created earlier. Add the service account as a member to the Cloud Storage bucket.```\ngsutil iam ch serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com:objectCreator,objectViewer \\gs://github-keys-$BUILD_PROJECT_IDgsutil iam ch serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com:objectCreator,objectViewer \\gs://recommender-tf-state-$BUILD_PROJECT_ID\n```\n- Give the recommender-parser service's service account access to Firestore, Recommender, and the Service Usage API.```\ngcloud projects add-iam-policy-binding $BUILD_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/datastore.usergcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/recommender.iamAdmingcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/recommender.iamViewergcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/recommender.computeAdmingcloud projects add-iam-policy-binding $TEST_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/serviceusage.serviceUsageConsumer\n```\n- Deploy the Cloud Run service, which is called , by running the command. Replace with your GitHub account username, not email. Accept any system prompts.```\ngcloud run deploy \\\u00a0--image=${IMAGE} \\\u00a0--no-allow-unauthenticated \\\u00a0--region us-central1 \\\u00a0--platform managed \\\u00a0--service-account recommender-parser-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0--set-env-vars=\"GITHUB_ACCOUNT=github.com:GITHUB-ACCOUNT,GITHUB_PAT=${GITHUB_PAT},SSH_KEYS_BUCKET=github-keys-${BUILD_PROJECT_ID},TERRAFORM_STATE_BUCKET=recommender-tf-state-$BUILD_PROJECT_ID\" \\\u00a0--project $BUILD_PROJECT_ID \\\u00a0recommender-parser\n```\n## Set up Firestore\n- In Google Cloud console, in your`build`project, navigate to the [Firestore page](https://console.cloud.google.com/firestore/data) .\n- When prompted for mode selection, click **Select Native Mode** .\n- Select`us-east1`as the default **location** .\n- Click **Create Database** .\nThe `recommender-parser` service writes documents to this database for the following purposes:- To keep track of the recommendations it has retrieved from the Recommender API\n- Call the Recommender API once the recommendations are processed to update the status of each processed recommendation to`SUCCEEDED`or`FAILED`as appropriate. This is a key step that makes the pipeline idempotent by ensuring that recommendations are not processed incompletely or multiple times.\n## Set up a Cloud Scheduler job\n- Create a service account that Cloud Scheduler jobs use to run the recommender-parser service.```\ngcloud beta iam service-accounts create recommender-scheduler-sa \\\u00a0 --description \"Service Account used by Cloud Scheduler to invoke the recommender-parser service\" \\\u00a0 --display-name \"recommender-scheduler-sa\" \\\u00a0 --project $BUILD_PROJECT_ID\n```\n- Give the service account run/invoker role to be able to invoke the Cloud Run service.```\ngcloud beta run services add-iam-policy-binding recommender-parser \\--member=serviceAccount:recommender-scheduler-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\--role=roles/run.invoker \\--region=us-central1\n```\n- Get your recommender-service URL:```\ngcloud beta run services list --platform managed --project $BUILD_PROJECT_ID\n```Your Cloud Scheduler job invokes the recommender-parser service's /recommendation/iam route to parse IAM recommendations and the /recommender/vm route to parse VM sizing recommendations.\n- Create a variable for the endpoint that Cloud Scheduler jobs invoke. Replace with the recommender-service URL you copied in the previous step.```\nexport RECOMMENDER_ROUTE_TO_INVOKE_IAM=RECOMMENDER-SERVICE-URL/recommendation/iam\n```You URL should look like this sample URL after appending the route information:```\nRECOMMENDER-SERVICE-URL/recommendation/iam\n```\n- Create a Cloud Scheduler job called `recommender-iam-scheduler.`- Change the selected time-zone based on your location.\n- Replacewith the name of the GitHub repository you created.\nThe message body takes three inputs and you must construct it as outlined below:- `repo` : This is the name of your GitHub repository that you created in [Create a GitHubrepository](#create_a_github_repository) .\n- `projects` : A list / array of Google Cloud projects IDs that this IaC GitHub repository maps to. In this tutorial, it is your `test` project.\n- `stub` : Recommender generates IAM recommendations when a subset of permissions for a role have not been used for 60 days and VM sizing recommendations follow a similar pattern. For the purposes of testing this pipeline on demand, `stub` can be passed in as `true` so that the pipeline is tested using the sample Recommender payloads provided in the repository that you cloned for this tutorial.\n```\ngcloud beta scheduler jobs create http recommender-iam-scheduler \\\u00a0 --project $BUILD_PROJECT_ID \\\u00a0 --time-zone \"America/Los_Angeles\" \\\u00a0 --schedule=\"0 */3 * * *\" \\\u00a0 --uri=$RECOMMENDER_ROUTE_TO_INVOKE_IAM \\\u00a0 --description=\"Scheduler job to invoke recommendation pipeline\" \\\u00a0 --oidc-service-account-email=\"recommender-scheduler-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com\" \\\u00a0 --headers=\"Content-Type=application/json\" \\\u00a0 --http-method=\"POST\" \\\u00a0 --message-body=\"{ \\\"repo\\\": \\\"IAC-REPO-NAME\\\", \\\"projects\\\": [\\\"$TEST_PROJECT_ID\\\"], \\\"location\\\": \\\"global\\\", \\\"stub\\\": true }\"\n```\n **Note:** `--schedule=\"0 */3 * * *\"` runs the Scheduler job every 3 hours. Change it per your requirement. Also, if you need to create a scheduler job to parse VM sizing recommendations, you should append the `your-recommender-parser` service URL with `/recommendation/vm` and set the `location` attribute in the `--message-body` parameter to a valid zone.## Additional stepsCloud Build publishes build information to a Pub/Sub topic called cloud-builds that was automatically created when you enabled the Cloud Build API in your build project.- Run the following command to verify the cloud-builds topic exists in your `build` project:```\ngcloud pubsub topics describe cloud-builds\n```If the topic exists, you will see the following output, where is your build project ID:```\nname: projects/BUILD-PROJECT-ID/topics/cloud-builds\n```If you receive an error message saying the resource was not found, follow the instructions for [subscribing to build notifications](/build/docs/subscribe-build-notifications) , to create the topic manually.\n- Create a service account that Pub/Sub uses to invoke the recommender-parser service endpoint.```\ngcloud beta iam service-accounts create recommender-ci-subscription-sa \\\u00a0 --description \"Service Account used by Cloud Pub/Sub to push Cloud Build events to the recommender-parser service\" \\\u00a0 --display-name \"recommender-ci-subscription-sa\" \\\u00a0 --project $BUILD_PROJECT_ID\n```\n- The Pub/Sub service account should be associated with the roles it needs to be able to publish messages and invoke the recommender-parser service.```\ngcloud projects add-iam-policy-binding $BUILD_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-ci-subscription-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/pubsub.publisher \\\u00a0 --project $BUILD_PROJECT_IDgcloud projects add-iam-policy-binding $BUILD_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-ci-subscription-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/pubsub.subscriber \\\u00a0 --project $BUILD_PROJECT_IDgcloud projects add-iam-policy-binding $BUILD_PROJECT_ID \\\u00a0 --member serviceAccount:recommender-ci-subscription-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role roles/run.invoker \\\u00a0 --project $BUILD_PROJECT_ID\n```\n- Add the `recommender-ci-subscription-sa` service account you created to the recommender-parser service as a member with the `invoker` role```\ngcloud beta run services add-iam-policy-binding recommender-parser \\\u00a0 --member=serviceAccount:recommender-ci-subscription-sa@$BUILD_PROJECT_ID.iam.gserviceaccount.com \\\u00a0 --role=roles/run.invoker --region=us-central1\n```\n- Navigate to [Pub/Sub](https://console.cloud.google.com/cloudpubsub) in Google Cloud console.\n- Click the cloud-builds topic.\n- Click **Create Subscription** .\n- For Subscription ID, type `recommender-service-build-events` .\n- For **Delivery Type** , select **Push** .\n- For **Endpoint** , type in your recommender-service URL appended by `/ci` .\n- Check **Enable Authentication** .- Select the service account`recommender-ci-subscription-sa`that you created.\n- Click **Grant** in response to the prompt message.\n- Select **Acknowledgement deadline as 60 seconds** .\n- Keep rest of the defaults.\n- Click **Create** .\n## Test the pipelineRecommender generates IAM recommendations when a subset of permissions for a role have not been used for 60 days. VM sizing recommendations follow a similar pattern. For the purposes of testing this pipeline on demand, you will use the sample recommendations JSON payloads provided in the `stub` sub-directory provided in the repository you cloned for this tutorial. This enables you to test the pipeline, barring the API calls that the recommender-parser makes to the Recommender API endpoint to update the status of recommendations it has successfully applied.\nAlternatively, if you have active recommendations in your Google Cloud projects then you can test the pipeline end-to-end without needing to use stubs. The outcome outlined below is pertinent to when you are using the sample payloads for testing the pipeline. However, the steps to test this pipeline without samples remains the same.- In the Google Cloud console, navigate to your test project and review the resource that were created. You should have the following:- A Compute Engine instance called`tf-compute-1`with Machine Type`g1-small`.\n- A service account named`Terraform Recommender Test`with the role of`editor`for your test project.\n- In the [Cloud Scheduler](https://console.cloud.google.com/cloudscheduler) console page in your `build` project, click **Run now** for the recommender-iam-scheduler job.\n- Click the job to view the logs. You can also view the recommender-parser service logs to get a detailed view of the steps being executed by the service.\n- Once the service completes its run, navigate to your GitHub repository. The `recommender-parser` service would have generated a pull request for you. Review the modified IaC manifests that comprise this pull request and click **Merge Pull Request** if you are satisfied with the changes to your IaC manifests. **Warning:** In production environments, we recommend that you enforce a robust approval workflow that includes human review of pull requests before changes are merged. The reviewers should have the knowledge to assess impacts identified in recommendations, as well as impacts specific to your infrastructure and business. Applying recommendations without proper assessment could result in unexpected changes, such as issues with system performance, poor reliability, or loss of required permissions. See the [GitHub documentation](https://help.github.com/en/articles/enabling-required-reviews-for-pull-requests) for instructions to set up a review process.\n- A new commit to the master branch is created when you merge the pull request. This triggers a Cloud Build job that rolls out the modifications to the Google Cloud resources in your `test` project. Allow a few moments for the Cloud Build job to complete, you can review its status in the Google Cloud console **Note:** Making sure that you have a functional rollback strategy in place is a best practice when setting up your DevOps pipelines. For example, the infrastructure changes rolled out by the automation pipeline that you built in this tutorial can be rolled back by reverting to a previous Git commit. You can learn more about the [https://git-scm.com/docs/git-reset](/recommender/docs/git%20reset) and [git revert](https://git-scm.com/docs/git-revert) commands in this Git documentation.\n- Once the job is complete, navigate to your test project. The sample payloads provided make the following changes to the resources in your test project.- Terraform Test service account which earlier has a role of`editor`when deployed, is changed to`viewer`.\n **Note:** When you run the Cloud Scheduler service to invoke parsing VM sizing recommendations at the /recommendation/vm endpoint then the Compute Engine instance `tf-compute-1` which is originally has a Machine Type of `g1-small` is changed to `f1-micro` .\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this tutorial, delete **both** projects that you created.\nThe easiest way to eliminate billing is to delete the project that you created for the tutorial.\nTo delete the project:\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n## What's next\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .\n- Learn more about Google Cloud Policy Intelligence in the [documentation](/policy-intelligence) .", "guide": "Recommender"}