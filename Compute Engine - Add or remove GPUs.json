{"title": "Compute Engine - Add or remove GPUs", "url": "https://cloud.google.com/compute/docs/instances", "abstract": "# Compute Engine - Add or remove GPUs\nCompute Engine provides graphics processing units (GPUs) that you can add to your virtual machine (VM) instances. You can use these GPUs to accelerate specific workloads on your VMs such as machine learning and data processing.\nYou can only use two machine families when running GPUs on Compute Engine:\n- The accelerator-optimized machine family: A3, A2, and G2.\n- The N1 general-purpose machine family. You can use most N1 machine types except the N1 shared-core machine type. If you are not using an N1 general-purpose machine, you can [switch to an N1 general-purpose machine](/compute/docs/instances/changing-machine-type-of-stopped-instance) and then add the GPUs.", "content": "## Before you begin\n- To review additional prerequisite steps such as selecting an OS image and  checking GPU quota, review the [overview](/compute/docs/gpus/create-vm-with-gpus) document.\n- If you haven't already, set up authentication. [Authentication](/compute/docs/authentication) is the process by which your identity is verified for access to Google Cloud services and APIs. To run code or samples from a local development environment, you can authenticate to Compute Engine as follows.Select the tab for how you plan to use the samples on this page:\nWhen you use the Google Cloud console to access Google Cloud services and   APIs, you don't need to set up authentication.To use the REST API samples on this page in a local development environment, you use the credentials you provide to the gcloud CLI.- [Install](/sdk/docs/install) the Google Cloud CLI, then [initialize](/sdk/docs/initializing) it by running the following command:\n- ```\ngcloud init\n```## Accelerator-optimized VMs\nEach accelerator-optimized machine type has a specific model of NVIDIA GPUs attached.\n- For A3 accelerator-optimized machine types, [NVIDIA H100 80GB GPUs](/compute/docs/gpus#h100-gpus) are attached.\n- For A2 accelerator-optimized machine types, [NVIDIA A100 GPUs](/compute/docs/gpus#a100-gpus) are attached. These are available in both A100 40GB and A100 80GB options.\n- For G2 accelerator-optimized machine types, [NVIDIA L4 GPUs](/compute/docs/gpus#l4-gpus) are attached.\nYou can modify each accelerator-optimized VM as follows:\n- For A2 standard VMs, you can modify the GPU count by switching from one A2 standard machine type to another A2 standard machine type.\n- For A3 standard and A2 ultra VMs, you can't modify the machine type. If you are using an A3 standard or A2 ultra machine type for your VM and you need to change the machine type, create a new VM.\n- For G2 standard VMs, you can do the following:- You can modify the GPU count by switching from one G2 standard machine type to another G2 standard machine type.\n- You can switch from a G2 standard machine type to a machine type from a different machine family such as general-purpose or compute-optimized. See [Change the machine type](/compute/docs/instances/changing-machine-type-of-stopped-instance#changing_machine_type) .\n- You can't remove GPUs from an accelerator-optimized machine type. If you no longer require GPUs, complete the following:- For A2 standard or ultra VMs, create a new VM.\n- For G2 VMs, change to a machine type from a different machine family.\n### Modify the GPU count\nYou can modify the GPU count of an A2 standard or G2 accelerator-optimized VM by using either the Google Cloud console, or REST.\nYou can modify the number of GPUs for your VM by stopping the VM and editing the VM configuration.- Verify that all of your critical applications are stopped on the VM.\n- In the Google Cloud console, go to the **VM instances** page to see your list of VMs. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- Click the name of the VM that you want to modify the number of GPUs for. The **Details** page opens.\n- Complete the following steps from the **Details** page.- If the VM is running, on the toolbar, click stop **Stop** . Then, wait for the VM to stop.\n- On the toolbar, click edit **Edit** .\n- In the **Machine configuration** section, select the **GPUs** machine family, and then do the following:- In the **Number of GPUs** list, increase or decrease the GPU count. **Note:** Each accelerator-optimized machine type has a specific number of GPUs attached. If you adjust the number of GPUs, the machine type changes.\n- To apply your changes, click **Save** .\n- To restart the VM, click **Start/Resume** .\nYou can modify the number of GPUs on your VM by stopping the VM and changing the machine type. Each accelerator-optimized machine type has a specific number of GPUs attached. If you change the machine type, this adjusts the number of GPUs that are attached to the VM.- Verify that all of your critical applications are stopped on the VM, and then create a POST command to stop the VM so it can move to a host system where GPUs are available.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/stop\n```\n- After the VM stops, create a POST request to modify the machine type.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/setMachineType\n{\n machineType: \"zones/ZONE/machineTypes/MACHINE_TYPE\"\n}\n```\n- Start the VM.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/start\n```\nReplace the following:- ``: your project ID.\n- ``: the name of the VM that you want to add GPUs to.\n- ``: the zone where the VM is located. This zone must support [GPUs](/compute/docs/gpus/gpu-regions-zones) .\n- `` : the machine type that you want to use. It must be one of the following:- If your VM uses an A2 standard machine, select another [A2 machine type](/compute/docs/gpus#a100-gpus) .\n- If your VM uses a G2 machine type, select another [G2 machine type](/compute/docs/gpus#l4-gpus) . G2 machine types also support custom memory. Memory must be a multiple of 1024 MB and within the supported memory range. For example, to create a VM with 4 vCPUs and 19 GB of memory specify`--machine-type=g2-custom-4-19456`.\n### Limitations\n- You don't receive [sustaineduse discounts](/compute/docs/sustained-use-discounts) and flexible committed use discounts for VMs that use A2 standard machine types.\n- You can only use A2 standard machine types in certain [regionsand zones](/compute/docs/regions-zones) .\n- You can't use [regionalpersistent disks](/compute/docs/disks/regional-persistent-disk) on VMs that use A2 standard machine types.\n- The A2 standard machine type is only available on the [Cascade Lake platform](/compute/docs/cpu-platforms) .\n- If your VM uses an A2 standard machine type, you can only switch from one A2 standard machine type to another A2 standard machine type. You can't change to any other machine type. For more information, see [Modify accelerator-optmized VMs](/compute/docs/gpus/add-remove-gpus#accelerator-optimized_vms) .\n- You can't use the`a2-megagpu-16g`A2 standard machine type on Windows operating systems. When using Windows operating systems, choose a different A2 standard machine type.\n- You can't do a quick format of the attached Local SSDs on Windows VMs that use A2 standard machine types. To format these Local SSDs, you must do a full format by using the [diskpartutility](https://docs.microsoft.com/windows-server/administration/windows-commands/diskpart) and specifying`format fs=ntfs label=tmpfs`.\n- A2 standard machine types don't support sole-tenancy.- You don't receive [sustaineduse discounts](/compute/docs/sustained-use-discounts) and flexible committed use discounts for VMs that use A2 ultra machine types.\n- You can only use A2 ultra machine types in certain [regionsand zones](/compute/docs/regions-zones) .\n- You can't use [regionalpersistent disks](/compute/docs/disks/regional-persistent-disk) on VMs that use A2 ultra machine types.\n- The A2 ultra machine type is only available on the [Cascade Lake platform](/compute/docs/cpu-platforms) .\n- If your VM uses an A2 ultra machine type, you can't change the machine type. If you need to use a different A2 ultra machine type, or any other machine type, you must create a new VM.\n- You can't change any other machine type to an A2 ultra machine type. If you need to create a VM that uses an A2 ultra machine type, you must create a new VM.\n- You can't do a quick format of the attached Local SSDs on Windows VMs that use A2 ultra machine types. To format these Local SSDs, you must do a full format by using the [diskpartutility](https://docs.microsoft.com/windows-server/administration/windows-commands/diskpart) and specifying`format fs=ntfs label=tmpfs`.- You don't receive [sustaineduse discounts](/compute/docs/sustained-use-discounts) and flexible committed use discounts for VMs that use G2 standard machine types.\n- You can only use G2 standard machine types in certain [regionsand zones](/compute/docs/regions-zones) .\n- You can't use [regionalpersistent disks](/compute/docs/disks/regional-persistent-disk) on VMs that use G2 standard machine types.\n- The G2 standard machine type is only available on the [Cascade Lake platform](/compute/docs/cpu-platforms) .\n- Standard persistent disks (`pd-standard`) are not supported on VMs that use G2 standard machine types. For supported disk types, see [Supported disk types for G2](/compute/docs/accelerator-optimized-machines#g2-disks) .\n- You can't create [Multi-InstanceGPUs](https://www.nvidia.com/en-us/technologies/multi-instance-gpu/) on G2 standard machine types.\n- If you need to change the machine type of a G2 VM, review [Modify accelerator-optmized VMs](/compute/docs/gpus/add-remove-gpus#accelerator-optimized_vms) .\n- You can't use [Deep Learning VM Images](/deep-learning-vm/docs/images) as boot disks for your VMs that use G2 standard machine types.\n- The current default driver for Container-Optimized OS doesn't support L4 GPUs running on G2 machine types. Container-Optimized OS also only support a select set of drivers. If you want to use Container-Optimized OS on G2 machine types, review the following notes:- Use a Container-Optimized OS version that supports the minimum recommended  NVIDIA driver version`525.60.13`or later. For more information, review the [Container-Optimized OS release notes](/container-optimized-os/docs/release-notes) .\n- When you [install the driver](/container-optimized-os/docs/how-to/run-gpus#install-driver) ,  specify the latest available version that works for the L4 GPUs.  For example,`sudo cos-extensions install gpu -- -version=525.60.13`.\n- You must use the Google Cloud CLI or REST to [create G2 VMs](/compute/docs/gpus/create-gpu-vm-accelerator-optimized#create-vm) for the following scenarios:- You want to specify custom memory values.\n- You want to customize the number of visible CPU cores.## N1-general purpose VMs\nThis section covers how to add, modify, or remove GPUs from a N1-general purpose machine.\nIn summary, the process to add, modify, or remove GPUs from an existing VM is as follows:\n- Check that your VM has a boot disk size of at least 40\u00a0GB.\n- Stop the VM.\n- Add, modify, or remove the GPUs.If your VM didn't have GPUs attached before, you need to complete the following steps:- [Prepare your VM](#prep-vm) for the modification.\n- Modify the host maintenance setting for the VM. VMs with GPUs cannot [live migrate](/compute/docs/instances/setting-instance-scheduling-options#live_migrate) because they are assigned to specific hardware devices. For more information, see [GPU restrictions](/compute/docs/gpus#restrictions) .\n- Change the machine type. GPUs are only supported on [select machine types](/compute/docs/machine-resource#gpus) .\n- [Install a GPU driver on your VM](/compute/docs/gpus/install-drivers-gpu) , so that your system can use the device.\n### Prepare your VM\nWhen a GPU is added to a VM, the order of the network interface can change.\nMost public images on Compute Engine don't have persistent network interface names and adjust to the new order.\nHowever, if you are using either SLES or a custom image, you must update the system setting to prevent the network interface from persisting. To prevent the network interface from persisting, run the following command on your VM:\n```\n rm /etc/udev/rules.d/70-persistent-net.rules \n```\n### Add GPUs or modify GPU type on existing VMs\nThis section covers how to add GPUs, or modify the GPU type on an existing N1 general-purpose VMs. This procedure supports the following GPU types:\nNVIDIA GPUs:\n- NVIDIA T4:`nvidia-tesla-t4`\n- NVIDIA P4:`nvidia-tesla-p4`\n- NVIDIA P100:`nvidia-tesla-p100`\n- NVIDIA V100:`nvidia-tesla-v100`\n- NVIDIA K80:`nvidia-tesla-k80`. See [NVIDIA K80 EOL](/compute/docs/eol/k80-eol) .\nNVIDIA RTX Virtual Workstation (vWS) (formerly known as NVIDIA GRID):\n- NVIDIA T4 Virtual Workstation:`nvidia-tesla-t4-vws`\n- NVIDIA P4 Virtual Workstation:`nvidia-tesla-p4-vws`\n- NVIDIA P100 Virtual Workstation: `nvidia-tesla-p100-vws`For these virtual workstations, an NVIDIA RTX Virtual Workstation (vWS) license is automatically added to your VM.\nTo add GPUs or modify the GPU type, complete the following steps.- Verify that all of your critical applications are stopped on the VM.\n- In the Google Cloud console, go to the **VM instances** page to see your list of VMs. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- Click the name of the VM that you want to update. The **Details** page opens.\n- Complete the following steps from the **Details** page.- If the VM is running, on the toolbar, click stop **Stop** . Then, wait for the VM to stop.\n- On the toolbar, click edit **Edit** .\n- In the **Machine configuration** section, select the **GPUs** machine family, and then do the following:- In the **GPU type** list, select or switch to any of the GPU types supported on N1 VMs.\n- In the **Number of GPUs** list, select the number of GPUs.\n- If your GPU model supports [NVIDIA RTX Virtual Workstations (vWS) for graphics workloads](/compute/docs/gpus#gpu-virtual-workstations) , and you plan on running graphics-intensive workloads on this VM, select **Enable Virtual Workstation (NVIDIA GRID)** .\n- If your VM didn't have GPUs attached before, complete the following:- If the VM has a shared-core machine type, you must change the machine type. In the **Machine type** list, select one of the preset N1 machine types. Alternatively, you can also specify custom machine type settings.\n- In the **Management** section, complete the following:- In the **On host maintenance** list, select **Terminate VM instance** . VMs with attached GPUs can't live migrate. See [Handle GPU host events](/compute/docs/gpus/gpu-host-maintenance) .\n- In the **Automatic restart** list, select **On** .\n- To apply your changes, click **Save** .\n- To restart the VM, click **Start/Resume** .\nYou can add or modify GPUs on your VM by stopping the VM and changing your VM's configuration through the API.- Verify that all of your critical applications are stopped on the VM and then create a POST command to stop the VM so it can move to a host system where GPUs are available.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/stop\n```\n- If your VM didn't have GPUs attached before, complete the following steps:- Identify the GPU type that you want to add to your VM. You can submit a `GET` request to list the GPU types that are available to your project in a specific zone.```\nGET https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/acceleratorTypes\n```\n- If the VM has a shared-core machine type, you must [change the machine type](/compute/docs/instances/changing-machine-type-of-stopped-instance#changing_a_machine_type) to have one or more vCPUs. You cannot add accelerators to VMs with shared-core machine types.\n- Create a POST command to set the scheduling options for the VM.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/setScheduling\n{\n\"onHostMaintenance\": \"TERMINATE\",\n\"automaticRestart\": true\n}\n```\n- Create a POST request to add or modify the GPUs that are attached to your VM.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/setMachineResources\n {\n  \"guestAccelerators\": [  {\n  \"acceleratorCount\": ACCELERATOR_COUNT,\n  \"acceleratorType\": \"https://www.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/acceleratorTypes/ACCELERATOR_TYPE\"\n  }\n  ]\n }\n```\n- Start the VM.```\nPOST https://compute.googleapis.com/compute/v1/projects/PROJECT_ID/zones/ZONE/instances/VM_NAME/start\n```Replace the following:- ``: your project ID.\n- ``: the name of the VM that you want to add GPUs to.\n- ``: the zone where the VM is located.\n- ``: the number of GPUs that you want attached to your VM. For a list of GPU limits based on the machine type of your VM, see [GPUs on Compute Engine](/compute/docs/gpus#introduction) .\n- `` : the [GPU model](/compute/docs/gpus#introduction) that you want to attach or switch to. If you plan on running graphics-intensive workloads on this VM, use one of the [virtual workstation models](/compute/docs/gpus#gpu-virtual-workstations) .Choose one of the following values:- NVIDIA GPUs:- NVIDIA T4:`nvidia-tesla-t4`\n- NVIDIA P4:`nvidia-tesla-p4`\n- NVIDIA P100:`nvidia-tesla-p100`\n- NVIDIA V100:`nvidia-tesla-v100`\n- NVIDIA K80:`nvidia-tesla-k80`. See [NVIDIA K80 EOL](/compute/docs/eol/k80-eol) .\n- NVIDIA RTX Virtual Workstation (vWS) (formerly known as NVIDIA GRID):- NVIDIA T4 Virtual Workstation:`nvidia-tesla-t4-vws`\n- NVIDIA P4 Virtual Workstation:`nvidia-tesla-p4-vws`\n- NVIDIA P100 Virtual Workstation:`nvidia-tesla-p100-vws`\nFor these virtual workstations, an NVIDIA RTX Virtual Workstation (vWS) license is automatically added to your VM.To install the drivers, choose one of the following options:\n- If you plan to run graphics-intensive workloads, such as those for gaming and visualization, [install drivers for the NVIDIA RTX Virtual Workstation](/compute/docs/gpus/install-grid-drivers) .\n- For most workloads, [install the GPU drivers](/compute/docs/gpus/install-drivers-gpu) .\n### Remove GPUs\nThis section covers how to remove the following GPU types from an existing N1 general-purpose VM.\nNVIDIA GPUs:\n- NVIDIA T4:`nvidia-tesla-t4`\n- NVIDIA P4:`nvidia-tesla-p4`\n- NVIDIA P100:`nvidia-tesla-p100`\n- NVIDIA V100:`nvidia-tesla-v100`\n- NVIDIA K80:`nvidia-tesla-k80`. See [NVIDIA K80 EOL](/compute/docs/eol/k80-eol) .\nNVIDIA RTX Virtual Workstation (vWS) (formerly known as NVIDIA GRID):\n- NVIDIA T4 Virtual Workstation:`nvidia-tesla-t4-vws`\n- NVIDIA P4 Virtual Workstation:`nvidia-tesla-p4-vws`\n- NVIDIA P100 Virtual Workstation: `nvidia-tesla-p100-vws`For these virtual workstations, an NVIDIA RTX Virtual Workstation (vWS) license is automatically added to your VM.\nYou can use the [Google Cloud console](https://console.cloud.google.com/) to remove GPUs from an existing VM. To remove GPUs, complete the following steps:\n- Verify that all of your critical applications are stopped on the VM.\n- In the Google Cloud console, go to the **VM instances** page to see your list of VMs. [Go to VM instances](https://console.cloud.google.com/compute/instances) \n- Click the name of the VM that you want to remove GPUs from. The **Details** page opens.\n- Complete the following steps from the **Details** page.- If the VM is running, on the toolbar, click stop **Stop** . Then, wait for the VM to stop.\n- On the toolbar, click edit **Edit** .\n- In the **Machine configuration** section, select the **General purpose** machine family, and then do the following:- To view attached GPUs, expand **Advanced configurations** .\n- In the **GPUs** section, remove GPUs using one of the following options:- To remove some GPUs, in the **Number of GPUs** list, select a new number.\n- To remove all GPUs, click delete **Delete GPU** .\n- Optional: Modify the VM host maintenance policy setting. VMs with GPUs must have the host maintenance policy set to **Terminate VM instance** . But if you removed all GPUs, you have the option to live migrate this VM during host maintenance. For more information, see [Set VM host maintenance policy](/compute/docs/instances/setting-instance-scheduling-options) .\n- To apply your changes, click **Save** .\n- To restart the VM, click **Start/Resume** .\n## What's next?\n- Learn more about [GPU platforms](/compute/docs/gpus) .\n- [Add Local SSDs to your instances](/compute/docs/disks/local-ssd) . Local SSD devices pair well with GPUs when your apps require high-performance storage.\n- [Create groups of GPU instances using instance templates](/compute/docs/gpus/gpu-instance-groups) .\n- To monitor GPU performance, see [Monitoring GPU performance](/compute/docs/gpus/monitor-gpus) .\n- To improve network performance, see [Use higher network bandwidth](/compute/docs/gpus/optimize-gpus) .\n- To handle GPU host maintenance, see [Handling GPU host events](/compute/docs/gpus/gpu-host-maintenance) .\n- Try the [Running TensorFlow Inference Workloads at Scale with TensorRT5and NVIDIA T4 GPU](/compute/docs/tutorials/ml-inference-t4) tutorial.", "guide": "Compute Engine"}