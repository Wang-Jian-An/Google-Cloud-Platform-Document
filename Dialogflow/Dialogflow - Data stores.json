{"title": "Dialogflow - Data stores", "url": "https://cloud.google.com/dialogflow/vertex/docs/concept/data-store", "abstract": "# Dialogflow - Data stores\nare used by [data store agents](/dialogflow/vertex/docs/concept/data-store-agent) to find answers for end-user's questions from your data. Data stores are a collection of websites and documents, each of which reference your data.\nWhen an end-user asks the agent a question, the agent searches for an answer from the given source content and summarizes the findings into a coherent agent response. It also provides supporting links to the sources of the response for the end-user to learn more. The agent can provide up to five answer snippets for a given question.\n", "content": "## Data store sources\nThere are different sources that you can supply for your data:\n- **Website URLs** : Automatically crawl [website content](#web) from a list of domains or web pages.\n- **BigQuery** : [Import data](#import) from your BigQuery table.\n- **Cloud Storage** : [Import data](#import) from your Cloud Storage bucket.## Website content\nWhen adding website content as a source, you can add and exclude multiple sites. When you specify a site, you can use individual pages or `*` as a wildcard for a pattern. All HTML and PDF content will be processed.\nYou must [verify your domain](/generative-ai-app-builder/docs/domain-verification) when using website content as a source.\nLimitations:\n- Files from public URLs must have been crawled by the Google Search indexer, so that they exist in the search index. You can check this with the [Google Search Console](https://search.google.com/search-console) .\n- Maximum of 200,000 pages are indexed. If the data store contains more pages, indexing fails and the last indexed content remains.## Import data\nYou can import your data from either BigQuery or [Cloud Storage](#cloud-storage) . This data can be [structured](#structured) or [unstructured](#unstructured) , and it can be [with metadata](#with-metadata) or [without metadata](#without-metadata) .\nThe following **Data Import Options** are available:\n- **Add/Update Data** : The provided documents are added to the data store. If a new document has the same ID as an old document, the new document replaces the old document.\n- **Override Existing Data** : All old data is deleted, then new data is uploaded. This is irreversible.\n### Structured data store\nStructured data stores can hold answers to frequently asked questions (FAQ). When user questions are matched with high confidence to an uploaded question, the agent returns the answer to that question without any modification. You can provide a title and a URL for each question and answer pair that is displayed by the agent.\nWhen uploading data to the data store, the CSV format must be used. Each file must have a header row describing the columns.\nFor example:\n```\n\"question\",\"answer\",\"title\",\"url\"\n\"Why is the sky blue?\",\"The sky is blue because of Rayleigh scattering.\",\"Rayleigh scattering\",\"https://en.wikipedia.org/wiki/Rayleigh_scattering\"\n\"What is the meaning of life?\",\"42\",\"\",\"\"\n```\nThe `title` and `url` columns are optional and can be omitted:\n```\n\"answer\",\"question\"\n\"42\",\"What is the meaning of life?\"\n```\nDuring the upload process, a folder can be selected where each file is treated as a CSV file regardless of extension.\nLimitations:\n- Extra space character after`,`causes an error.\n- Blank lines (even at the end of the file) cause an error.\n### Unstructured data store\nUnstructured data stores can contain content in the following formats:\n- HTML\n- PDF\n- TXT\n- CSV\n**Note:** CSV files can also be imported as unstructured content. The same schema requirements apply. Metadata gets generated automatically, if `title` and `url` columns are provided. Each question and answer pair gets indexed separately. The matching requirements are less strict compared to structured CSV data stores, and the answer might be rewritten by the agent.\n**Note:** It's possible (but uncommon) to import files from another project's Cloud Storage bucket. Explicit access needs to be granted to the import process. Follow the instruction in the error message, as it contains the name of the user that needs read access to the bucket.\nLimitations:\n- The maximum size of a document is 100Mb.\n### Data store with metadata\nA title and URL can be provided as metadata. When the agent is in a conversation with a user, the agent can provide this information to the user. This can help users to quickly link to internal web pages not accessible by the Google Search indexer.\nTo import content with metadata, you provide one or more [JSON Lines](https://jsonlines.org/) files. Each line of this file describes one document. You do not directly upload the actual documents; URIs that link to the Cloud Storage paths are provided in the JSON Lines file.\nWhen providing your JSON Lines files, you provide a Cloud Storage folder that contains these files. Do not put any other files in this folder.\nField descriptions:\n| Field    | Type | Description                 |\n|:-------------------|:-------|:----------------------------------------------------------------------------|\n| id     | string | Unique identifier for the document.           |\n| content.mimeType | string | MIME type of the document. \"application/pdf\" and \"text/html\" are supported. |\n| content.uri  | string | URI for the document in Cloud Storage.          |\n| content.structData | string | Single line JSON object with optional title and url fields.     |\nFor example:\n```\n{ \"id\": \"d001\", \"content\": {\"mimeType\": \"application/pdf\", \"uri\": \"gs://example-import/unstructured/first_doc.pdf\"}, \"structData\": {\"title\": \"First Document\", \"url\": \"https://internal.example.com/documents/first_doc.pdf\"} }{ \"id\": \"d002\", \"content\": {\"mimeType\": \"application/pdf\", \"uri\": \"gs://example-import/unstructured/second_doc.pdf\"}, \"structData\": {\"title\": \"Second Document\", \"url\": \"https://internal.example.com/documents/second_doc.pdf\"} }{ \"id\": \"d003\", \"content\": {\"mimeType\": \"text/html\", \"uri\": \"gs://example-import/unstructured/mypage.html\"}, \"structData\": {\"title\": \"My Page\", \"url\": \"https://internal.example.com/mypage.html\"} }\n```\n### Data store without metadata\nThis type of content has no metadata. Just provide the documents to import. The content type is determined by the file extension.\n## Create a data store\nTo create a data store:\n- Go to the Vertex AI Conversation console: [Vertex AI Conversation console](https://console.cloud.google.com/gen-app-builder/) \n- Select your project from the console drop-down.\n- Read and agree to the Terms of Service, then click **Continue and activatethe API** .\n- Click **Data Stores** in the left navigation.\n- Click **New Data Store** .\n- Choose a data [source](#sources) .\n- Enable [Advanced website indexing](/generative-ai-app-builder/docs/about-advanced-features#advanced-website-indexing) . This is required for data store agents.\n- Provide data and configuration for the data store source you selected. Your data store location should correspond to the [agent location](/dialogflow/cx/docs/concept/region) .\n- Click **Create** to create the data store.\n- [Verify your website domain](/generative-ai-app-builder/docs/domain-verification) .## Using Cloud Storage for a data store document\nIf your content is not public, storing your content in [Cloud Storage](/storage/docs) is the recommended option. When creating data store documents, you provide the URLs for your Cloud Storage objects in the form: `gs://bucket-name/folder-name` . Each document within the folder is added to the data store.\nWhen creating the Cloud Storage bucket:\n- Be sure that you have selected the project you use for the agent.\n- Use the [Standard Storage class](/storage/docs/storage-classes#standard) .\n- Set the [bucket location](/storage/docs/locations) to the same location as your agent.\nFollow the [Cloud Storage quickstart](/storage/docs/quickstart-console) instructions to create a bucket and upload files.\n## Supported languages\nFor supported languages, see the data store column in the [Dialogflow language reference](/dialogflow/cx/docs/reference/language) .\nFor best performance, it is recommended that data stores be created in a single language.\n## Supported regions\nFor supported regions, see the [Dialogflow region reference](/dialogflow/cx/docs/concept/region#avail) .", "guide": "Dialogflow"}