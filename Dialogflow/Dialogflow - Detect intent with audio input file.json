{"title": "Dialogflow - Detect intent with audio input file", "url": "https://cloud.google.com/dialogflow/es/docs/how/detect-intent-audio", "abstract": "# Dialogflow - Detect intent with audio input file\nThis guide shows how to send audio input to a detect intent request using the API. Dialogflow processes the audio and converts it to text before attempting an intent match. This conversion is known as , , , or .\n", "content": "## Before you begin\nThis feature is only applicable when using the API for [end-user interactions](/dialogflow/docs/api-overview) . If you are using an [integration](/dialogflow/docs/integrations) , you can skip this guide.\nYou should do the following before reading this guide:\n- Read [Dialogflow basics](/dialogflow/es/docs/basics) .\n- Perform [setup steps](/dialogflow/es/docs/quick/setup) .## Create an agent\nIf you have not already created an agent, create one now:- Go to the [Dialogflow ES Console](https://dialogflow.cloud.google.com) .\n- If requested, sign in to the Dialogflow Console.  See [Dialogflow console overview](/dialogflow/docs/console) for more information.\n- Click **Create Agent** in the left sidebar menu.  (If you already have other agents, click the agent name,  scroll to the bottom and click **Create new agent** .)\n- Enter your agent's name, default language, and default time zone.\n- If you have already created a project, enter that project.  If you want to allow the Dialogflow Console to create the project,  select **Create a new Google project** .\n- Click the **Create** button.## Import the example file to your agent\nThe steps in this guide make assumptions about your agent, so you need to [import](/dialogflow/docs/agents-settings#export) an agent prepared for this guide. When importing, these steps use the option, which overwrites all agent settings, intents, and entities.\nTo import the file, follow these steps:\n- Download the [room-booking-agent.zip](/static/dialogflow/es/docs/data/room-booking-agent.zip) file.\n- Go to the [Dialogflow ES Console](https://dialogflow.cloud.google.com) .\n- Select your agent.\n- Click the  settingsbutton  next to the agent name.\n- Select the **Export and Import** tab.\n- Select **Restore From Zip** and follow instructions to restore the zip file that you downloaded.## Detect intent\nTo detect intent, call the `detectIntent` method on the [Sessions](/dialogflow/es/docs/reference/common-types#sessions) type.\nDownload the\n [book-a-room.wav](/static/dialogflow/es/docs/data/book-a-room.wav) \nsample input audio file, which says \"book a room\". The audio file must be base64 encoded for this example, so it can be provided in the JSON request below. Here is a Linux example:\n```\nwget https://cloud.google.com/dialogflow/es/docs/data/book-a-room.wavbase64 -w 0 book-a-room.wav > book-a-room.b64\n```\nFor examples on other platforms, see [Base64 encoding audio content](/speech-to-text/docs/base64-encoding) in the Cloud Speech-to-Text API documentation.\nBefore using any of the request data, make the following replacements:- : your Google Cloud project ID\n- : the base64 encoded audio content\nHTTP method and URL:\n```\nPOST https://dialogflow.googleapis.com/v2/projects/PROJECT_ID/agent/sessions/123456789:detectIntent\n```\nRequest JSON body:\n```\n{\n \"queryInput\": {\n \"audioConfig\": {\n  \"languageCode\": \"en-US\"\n }\n },\n \"inputAudio\": \"AUDIO\"\n}\n```\nTo send your request, expand one of these options:\nYou should receive a JSON response similar to the following:\n```\n{\n \"responseId\": \"3c1e5a89-75b9-4c3f-b63d-4b1351dd5e32\",\n \"queryResult\": {\n \"queryText\": \"book a room\",\n \"action\": \"room.reservation\",\n \"parameters\": {\n  \"time\": \"\",\n  \"date\": \"\",\n  \"guests\": \"\",\n  \"duration\": \"\",\n  \"location\": \"\"\n },\n \"fulfillmentText\": \"I can help with that. Where would you like to reserve a room?\",\n \"fulfillmentMessages\": [  {\n  \"text\": {\n   \"text\": [   \"I can help with that. Where would you like to reserve a room?\"\n   ]\n  }\n  }\n ],\n \"intent\": {\n  \"name\": \"projects/PROJECT_ID/agent/intents/e8f6a63e-73da-4a1a-8bfc-857183f71228\",\n  \"displayName\": \"room.reservation\"\n },\n \"intentDetectionConfidence\": 1,\n \"diagnosticInfo\": {},\n \"languageCode\": \"en-us\"\n }\n}\n```\nNotice that the value of the `queryResult.action` field is \"room.reservation\", and the value of the `queryResult.fulfillmentMessages[0|1].text.text[0]` field asks the user for more information.\nTo authenticate to Dialogflow, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/golang-samples/blob/HEAD/dialogflow/detect_intent/detect_intent.go) \n```\nfunc DetectIntentAudio(projectID, sessionID, audioFile, languageCode string) (string, error) {\u00a0 \u00a0 \u00a0 \u00a0 ctx := context.Background()\u00a0 \u00a0 \u00a0 \u00a0 sessionClient, err := dialogflow.NewSessionsClient(ctx)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return \"\", err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 defer sessionClient.Close()\u00a0 \u00a0 \u00a0 \u00a0 if projectID == \"\" || sessionID == \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return \"\", errors.New(fmt.Sprintf(\"Received empty project (%s) or session (%s)\", projectID, sessionID))\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 sessionPath := fmt.Sprintf(\"projects/%s/agent/sessions/%s\", projectID, sessionID)\u00a0 \u00a0 \u00a0 \u00a0 // In this example, we hard code the encoding and sample rate for simplicity.\u00a0 \u00a0 \u00a0 \u00a0 audioConfig := dialogflowpb.InputAudioConfig{AudioEncoding: dialogflowpb.AudioEncoding_AUDIO_ENCODING_LINEAR_16, SampleRateHertz: 16000, LanguageCode: languageCode}\u00a0 \u00a0 \u00a0 \u00a0 queryAudioInput := dialogflowpb.QueryInput_AudioConfig{AudioConfig: &audioConfig}\u00a0 \u00a0 \u00a0 \u00a0 audioBytes, err := ioutil.ReadFile(audioFile)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return \"\", err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 queryInput := dialogflowpb.QueryInput{Input: &queryAudioInput}\u00a0 \u00a0 \u00a0 \u00a0 request := dialogflowpb.DetectIntentRequest{Session: sessionPath, QueryInput: &queryInput, InputAudio: audioBytes}\u00a0 \u00a0 \u00a0 \u00a0 response, err := sessionClient.DetectIntent(ctx, &request)\u00a0 \u00a0 \u00a0 \u00a0 if err != nil {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 return \"\", err\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 queryResult := response.GetQueryResult()\u00a0 \u00a0 \u00a0 \u00a0 fulfillmentText := queryResult.GetFulfillmentText()\u00a0 \u00a0 \u00a0 \u00a0 return fulfillmentText, nil}\n```To authenticate to Dialogflow, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/dialogflow/snippets/src/main/java/com/example/dialogflow/DetectIntentAudio.java) \n```\nimport com.google.api.gax.rpc.ApiException;import com.google.cloud.dialogflow.v2.AudioEncoding;import com.google.cloud.dialogflow.v2.DetectIntentRequest;import com.google.cloud.dialogflow.v2.DetectIntentResponse;import com.google.cloud.dialogflow.v2.InputAudioConfig;import com.google.cloud.dialogflow.v2.QueryInput;import com.google.cloud.dialogflow.v2.QueryResult;import com.google.cloud.dialogflow.v2.SessionName;import com.google.cloud.dialogflow.v2.SessionsClient;import com.google.protobuf.ByteString;import java.io.IOException;import java.nio.file.Files;import java.nio.file.Paths;public class DetectIntentAudio {\u00a0 // DialogFlow API Detect Intent sample with audio files.\u00a0 public static QueryResult detectIntentAudio(\u00a0 \u00a0 \u00a0 String projectId, String audioFilePath, String sessionId, String languageCode)\u00a0 \u00a0 \u00a0 throws IOException, ApiException {\u00a0 \u00a0 // Instantiates a client\u00a0 \u00a0 try (SessionsClient sessionsClient = SessionsClient.create()) {\u00a0 \u00a0 \u00a0 // Set the session name using the sessionId (UUID) and projectID (my-project-id)\u00a0 \u00a0 \u00a0 SessionName session = SessionName.of(projectId, sessionId);\u00a0 \u00a0 \u00a0 System.out.println(\"Session Path: \" + session.toString());\u00a0 \u00a0 \u00a0 // Note: hard coding audioEncoding and sampleRateHertz for simplicity.\u00a0 \u00a0 \u00a0 // Audio encoding of the audio content sent in the query request.\u00a0 \u00a0 \u00a0 AudioEncoding audioEncoding = AudioEncoding.AUDIO_ENCODING_LINEAR_16;\u00a0 \u00a0 \u00a0 int sampleRateHertz = 16000;\u00a0 \u00a0 \u00a0 // Instructs the speech recognizer how to process the audio content.\u00a0 \u00a0 \u00a0 InputAudioConfig inputAudioConfig =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 InputAudioConfig.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setAudioEncoding(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 audioEncoding) // audioEncoding = AudioEncoding.AUDIO_ENCODING_LINEAR_16\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setLanguageCode(languageCode) // languageCode = \"en-US\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setSampleRateHertz(sampleRateHertz) // sampleRateHertz = 16000\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // Build the query with the InputAudioConfig\u00a0 \u00a0 \u00a0 QueryInput queryInput = QueryInput.newBuilder().setAudioConfig(inputAudioConfig).build();\u00a0 \u00a0 \u00a0 // Read the bytes from the audio file\u00a0 \u00a0 \u00a0 byte[] inputAudio = Files.readAllBytes(Paths.get(audioFilePath));\u00a0 \u00a0 \u00a0 // Build the DetectIntentRequest\u00a0 \u00a0 \u00a0 DetectIntentRequest request =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 DetectIntentRequest.newBuilder()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setSession(session.toString())\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setQueryInput(queryInput)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .setInputAudio(ByteString.copyFrom(inputAudio))\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 .build();\u00a0 \u00a0 \u00a0 // Performs the detect intent request\u00a0 \u00a0 \u00a0 DetectIntentResponse response = sessionsClient.detectIntent(request);\u00a0 \u00a0 \u00a0 // Display the query result\u00a0 \u00a0 \u00a0 QueryResult queryResult = response.getQueryResult();\u00a0 \u00a0 \u00a0 System.out.println(\"====================\");\u00a0 \u00a0 \u00a0 System.out.format(\"Query Text: '%s'\\n\", queryResult.getQueryText());\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Detected Intent: %s (confidence: %f)\\n\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 queryResult.getIntent().getDisplayName(), queryResult.getIntentDetectionConfidence());\u00a0 \u00a0 \u00a0 System.out.format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"Fulfillment Text: '%s'\\n\",\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 queryResult.getFulfillmentMessagesCount() > 0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ? queryResult.getFulfillmentMessages(0).getText()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 : \"Triggered Default Fallback Intent\");\u00a0 \u00a0 \u00a0 return queryResult;\u00a0 \u00a0 }\u00a0 }}\n```To authenticate to Dialogflow, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/dialogflow/detect.js) \n```\nconst fs = require('fs');const util = require('util');const {struct} = require('pb-util');// Imports the Dialogflow libraryconst dialogflow = require('@google-cloud/dialogflow');// Instantiates a session clientconst sessionClient = new dialogflow.SessionsClient();// The path to identify the agent that owns the created intent.const sessionPath = sessionClient.projectAgentSessionPath(\u00a0 projectId,\u00a0 sessionId);// Read the content of the audio file and send it as part of the request.const readFile = util.promisify(fs.readFile);const inputAudio = await readFile(filename);const request = {\u00a0 session: sessionPath,\u00a0 queryInput: {\u00a0 \u00a0 audioConfig: {\u00a0 \u00a0 \u00a0 audioEncoding: encoding,\u00a0 \u00a0 \u00a0 sampleRateHertz: sampleRateHertz,\u00a0 \u00a0 \u00a0 languageCode: languageCode,\u00a0 \u00a0 },\u00a0 },\u00a0 inputAudio: inputAudio,};// Recognizes the speech in the audio and detects its intent.const [response] = await sessionClient.detectIntent(request);console.log('Detected intent:');const result = response.queryResult;// Instantiates a context clientconst contextClient = new dialogflow.ContextsClient();console.log(` \u00a0Query: ${result.queryText}`);console.log(` \u00a0Response: ${result.fulfillmentText}`);if (result.intent) {\u00a0 console.log(` \u00a0Intent: ${result.intent.displayName}`);} else {\u00a0 console.log(' \u00a0No intent matched.');}const parameters = JSON.stringify(struct.decode(result.parameters));console.log(` \u00a0Parameters: ${parameters}`);if (result.outputContexts && result.outputContexts.length) {\u00a0 console.log(' \u00a0Output contexts:');\u00a0 result.outputContexts.forEach(context => {\u00a0 \u00a0 const contextId =\u00a0 \u00a0 \u00a0 contextClient.matchContextFromProjectAgentSessionContextName(\u00a0 \u00a0 \u00a0 \u00a0 context.name\u00a0 \u00a0 \u00a0 );\u00a0 \u00a0 const contextParameters = JSON.stringify(\u00a0 \u00a0 \u00a0 struct.decode(context.parameters)\u00a0 \u00a0 );\u00a0 \u00a0 console.log(` \u00a0 \u00a0${contextId}`);\u00a0 \u00a0 console.log(` \u00a0 \u00a0 \u00a0lifespan: ${context.lifespanCount}`);\u00a0 \u00a0 console.log(` \u00a0 \u00a0 \u00a0parameters: ${contextParameters}`);\u00a0 });}\n```To authenticate to Dialogflow, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/dialogflow/detect_intent_audio.py) \n```\ndef detect_intent_audio(project_id, session_id, audio_file_path, language_code):\u00a0 \u00a0 \"\"\"Returns the result of detect intent with an audio file as input.\u00a0 \u00a0 Using the same `session_id` between requests allows continuation\u00a0 \u00a0 of the conversation.\"\"\"\u00a0 \u00a0 from google.cloud import dialogflow\u00a0 \u00a0 session_client = dialogflow.SessionsClient()\u00a0 \u00a0 # Note: hard coding audio_encoding and sample_rate_hertz for simplicity.\u00a0 \u00a0 audio_encoding = dialogflow.AudioEncoding.AUDIO_ENCODING_LINEAR_16\u00a0 \u00a0 sample_rate_hertz = 16000\u00a0 \u00a0 session = session_client.session_path(project_id, session_id)\u00a0 \u00a0 print(\"Session path: {}\\n\".format(session))\u00a0 \u00a0 with open(audio_file_path, \"rb\") as audio_file:\u00a0 \u00a0 \u00a0 \u00a0 input_audio = audio_file.read()\u00a0 \u00a0 audio_config = dialogflow.InputAudioConfig(\u00a0 \u00a0 \u00a0 \u00a0 audio_encoding=audio_encoding,\u00a0 \u00a0 \u00a0 \u00a0 language_code=language_code,\u00a0 \u00a0 \u00a0 \u00a0 sample_rate_hertz=sample_rate_hertz,\u00a0 \u00a0 )\u00a0 \u00a0 query_input = dialogflow.QueryInput(audio_config=audio_config)\u00a0 \u00a0 request = dialogflow.DetectIntentRequest(\u00a0 \u00a0 \u00a0 \u00a0 session=session,\u00a0 \u00a0 \u00a0 \u00a0 query_input=query_input,\u00a0 \u00a0 \u00a0 \u00a0 input_audio=input_audio,\u00a0 \u00a0 )\u00a0 \u00a0 response = session_client.detect_intent(request=request)\u00a0 \u00a0 print(\"=\" * 20)\u00a0 \u00a0 print(\"Query text: {}\".format(response.query_result.query_text))\u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 \"Detected intent: {} (confidence: {})\\n\".format(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 response.query_result.intent.display_name,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 response.query_result.intent_detection_confidence,\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 )\u00a0 \u00a0 print(\"Fulfillment text: {}\\n\".format(response.query_result.fulfillment_text))\n```No preface\n **C#** : Please follow the [C# setup instructions](/dialogflow/docs/reference/libraries) on the client libraries page  and then visit the [Dialogflow reference documentation for .NET.](https://googleapis.github.io/google-cloud-dotnet/docs/Google.Cloud.Dialogflow.V2/index.html) \n **PHP** : Please follow the [PHP setup instructions](/dialogflow/docs/reference/libraries) on the client libraries page  and then visit the [Dialogflow reference documentation for PHP.](/php/docs/reference/cloud-dialogflow/latest) \n **Ruby** : Please follow the [Ruby setup instructions](/dialogflow/docs/reference/libraries) on the client libraries page  and then visit the [Dialogflow reference documentation for Ruby.](https://googleapis.dev/ruby/google-cloud-dialogflow/latest/Google/Cloud/Dialogflow.html)", "guide": "Dialogflow"}