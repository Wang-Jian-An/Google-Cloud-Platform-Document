{"title": "Dialogflow - Best practices", "url": "https://cloud.google.com/dialogflow/vertex/docs/concept/best-practices", "abstract": "# Dialogflow - Best practices\n**    Preview     ** This product or feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA products and features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nThe following best practices can help you build robust playbook agents.\n", "content": "## Concise goals\nGoals should be a concise description of the playbook's purpose.\n## Provide quality instructions\nInstructions should:\n- reflect the step-by-step approach to solving an end-user problem\n- be concise natural language sentences of high level instructions\n- be straightforward and specify the scenarios for tool uses## At least one example for each playbook\nYou should have at least one [example](/dialogflow/vertex/docs/concept/examples) for each playbook, but it is recommended to have at least four. Examples should include happy path scenarios.\nWithout enough examples, a playbook is likely to result in unpredictable behavior. If your agent is not responding or behaving in the manner you expect, missing or poorly defined examples are likely the cause. Try improving your examples or adding new ones.\n## Precision of instructions and examples\nWhile it helps to write clear and descriptive instructional instructions, it's really the quality and quantity of your examples that determine the accuracy of the agent's behavior. In other words, spend more time writing thorough examples than writing perfectly precise instructions.\n## Tool schema operationId field\nWhen defining schemas for your tools, the `operationId` value is important. Your playbook instructions will reference this value. The following are naming recommendations for this field:\n- Letters, numbers and underscores only.\n- Must be unique among all`operationId`s described in the schema.\n- Must be a meaningful name reflecting the capability provided.## Tool schema validation\nYou should validate your tool schema. You can use the [Swagger Editor](https://editor.swagger.io/) to check your openAPI 3.0 schema syntax.\n## Handle empty tool results\nWhen your agent relies on a tool to inform its response, an empty tool result can lead to unpredictable agent behavior. Sometimes, the agent LLM will hallucinate information in a response in lieu of a tool result. To prevent this, you can add specific instructions to ensure the agent LLM doesn't attempt to answer on its own.\nSome use cases require agent responses to be well grounded in tool results or provided data and need to mitigate responses based only on the agent LLM's knowledge.\nExamples of instructions to mitigate hallucinations:\n- \"You must use the tool to answer all user questions\"\n- \"If you don't get any data back from the tool, respond that you don't know the answer to the user's query\"\n- \"Don't make up an answer if you don't get any data back from the tool\"## Generate a schema with Bard\n[Bard](https://bard.google.com/) can generate a schema for you. For example, try \"can you create an example openAPI 3.0 schema for Google Calendar\".\n## Focused playbooks\nAvoid creating very large and complex playbooks. Each playbook should accomplish a specific and clear task. If you have a complex playbook, consider breaking it down into smaller sub-playbooks.\n## Avoid loops and recursion\nDon't create loops or recursion when linking playbook agents in your instructions.", "guide": "Dialogflow"}