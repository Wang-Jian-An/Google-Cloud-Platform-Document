{"title": "Dialogflow - Generators", "url": "https://cloud.google.com/dialogflow/cx/docs/concept/generative/generators", "abstract": "# Dialogflow - Generators\n**Note:** The feature is excluded from the [DialogflowSLA](/dialogflow/sla) .\nGenerators use Google's latest generative large language models (LLMs), and prompts that you provide, to generate agent behavior and responses at runtime. The available models are provided by [VertexAI](/vertex-ai/docs/generative-ai/learn/overview) .\nA Generator allows you to make a call to an LLM natively from Dialogflow CX without needing to create your own external webhook. You can configure the generator to do anything you would normally ask an LLM to do.\nGenerators are great at tasks like summarization, parameter extraction, data transformations, and so on, see [examples below](#examples) .\n", "content": "## Limitations\nThis feature is currently available for agents in any Dialogflow language. Note that the available models may have more restrictive language limitations, see [Vertex AI](/vertex-ai/docs/generative-ai/learn/overview) for more.\n## Understand generator concepts\nThe [Vertex AI](/vertex-ai/docs/generative-ai/learn/overview) documentation contains information that is important to understand when creating generators for Dialogflow:\n- [Models](/vertex-ai/docs/generative-ai/learn/models) \n- [Prompts](/vertex-ai/docs/generative-ai/learn/introduction-prompt-design) \n- [Controls (called \"parameter values\" in Vertex AI)](/vertex-ai/docs/generative-ai/learn/introduction-prompt-design#experiment-with-different-parameter-values) ## Define a generator\nTo create a generator:\n- Go to the [Dialogflow CX Console](https://dialogflow.cloud.google.com/cx/projects) .\n- Select your Google Cloud project.\n- Select the agent.\n- Click the **Manage** tab.\n- Click **Generators** .\n- Click **Create new** .\n- Enter a descriptive display name for the generator.\n- Enter the text prompt, model, and controls as described in [concepts](#concepts) .\n- Click **Save** .\nThe text prompt is sent to the generative model during fulfillment at runtime. It should be a clear question or request in order for the model to generate a satisfactory response.\nYou can make the prompt contextual by marking words as placeholders by adding a `$` before the word. You can later associate these with session parameters in fulfillment and they are replaced by the session parameter values during execution.\nThere are special that do not need to be associated with session parameters. These are\n| Term     | Definition                    |\n|:---------------------|:-----------------------------------------------------------------------------------------|\n| $conversation  | The conversation between the agent and the user, excluding the very last user utterance. |\n| $last-user-utterance | The last user utterance.                 |\n## Use a generator in fulfillment\nYou can use generators during fulfillment (in **Routes** , **Event-handlers** , **Parameters** and more).\nGo to the **Generators** section of the **Fulfillment** pane and expand it. Then, click **Add generator** . Now you can select a predefined generator or define a new generator in place.\nAfter selecting a generator, you need to associate the of the prompt with session parameters. Moreover, you need to define the output parameter that will contain the result of the generator after execution.\nNote that you can add several generators in one fulfillment, which are executed in parallel.\nThe output parameter can then be used later on, for example in the agent response.\n## Test a generator\nThe feature can be directly tested in the simulator.\n## Examples\nThis section provides example use cases for generators.\n### Content summarization\nThis example shows how to summarize content.\n**Prompt:**\n```\nYour goal is to summarize a given text.\nText:\n$text\nA concise summary of the text in 1 or 2 sentences is:\n```\n### Conversation summarization\nThis example shows how to provide a conversation summary. Note how we can explicitly specify the prefixes of the conversation turns in the conversation history and add the $last-user-utterance because it is not included in $conversation.\n**Prompt:**\n```\nYour goal is to summarize a given conversation between a Human and an AI.\nConversation:\n${conversation USER:\"Human:\" AGENT:\"AI:\"}Human: $last-user-utterance\nA concise summary of the conversation in 1 or 2 sentences is:\n```\n**Resolved prompt:**\nFor an example conversation, the resolved prompt that is sent to the generative model could be:\n```\nYour goal is to summarize a given conversation between a Human and an AI.\nConversation:\nAI: Good day! What can I do for you today?\nHuman: Hi, which models can I use in Dialogflow's generators?\nAI: You can use all models that Vertex AI provides!\nHuman: Thanks, thats amazing!\nA concise summary of the conversation in 1 or 2 sentences is:\n```\n### Markdown formatting\nThis example shows how to format text in markdown.\n```\n# Instructions\nYou are presented with a text and your goal is to apply markdown formatting to text.\n**NOTE:** Do not change the meaning of the text, only the formatting.\n# Example\n## Text\nGenerators allow you to use Googles latest generative models to format text,\nor to create a summaries, or even to write code. What an amazing feature.\n## Text in Markdown\n*Generators* allow you to use Google's latest generative models to\n* format text\n* create a summaries\n* write code\nWhat an amazing feature.\n# Your current task\n## Text\n$text\n## Text in Markdown\n```\n### Question answering\nThis series of examples shows how to use generators to answer questions.\nFirst, you can simply rely on the internal knowledge of the generative model to answer the question. Note however, that the model will simply provide an answer based on information that was part of its training data. There is no guarantee that the answer is true or up-to-date.\n**Prompt for question answering with self-knowledge**\n```\nYour goal is to politely reply to a human with an answer to their question.\nThe human asked:\n$last-user-utterance\nYou answer:\n```\n**Prompt for question answering with provided information**\nHowever, if you want the model to answer based on information you provide, you can simply add it to the prompt. This works if there is not too much information you want to provide (e.g. a small restaurant menu or contact information of your company).\n```\n# Instructions\nYour goal is to politely answer questions about the restaurant menu.\nIf you cannot answer the question because it is not related to the restaurant\nmenu or because relevant information is missing from the menu, you politely\ndecline to answer.\n# Restaurant menu:\n## Starters\nSalat 5$\n## Main dishes\nPizza 10$\n## Deserts\nIce cream 2$\n# Examples\nQuestion: How much is the pizza?\nAnswer: The pizza is 10$.\nQuestion: I want to order the ice cream.\nAnswer: We do have ice cream! However, I can only answer questions about the menu.\nQuestion: Do you have spaghetti?\nAnswer: I'm sorry, we do not have spaghetti on the menu.\n# Your current task\nQuestion: $last-user-utterance\nAnswer:\n```\n**Prompt for question answering with dynamic provided information**\nOften, the information you want the model to base its answer on is too much to simply be pasted into the prompt. In this case you can connect the generator to an information retrieval system like a database or a search engine, to dynamically retrieve the information based on a query. You can simply save the output of that system into a parameter and connect it to a placeholder in the prompt.\n```\n# Instructions\nYour goal is to politely answer questions based on the provided information.\nIf you cannot answer the question given the provided information, you plitely\ndecline to answer.\n# Provided information:\n$information\nQuestion: $last-user-utterance\nAnswer:\n```\n### Code generation\nThis example shows how to use a generator to write code! Note that here it makes sense to use a generative model that was specifically trained to generate code.\n**Prompt**\n```\n# Instructions:\nYour goal is to write code in a given programming language solving a given problem.\nProblem to solve:\n$problem\nProgramming language:\n$programming-language\n# Solution:\n```\n### Escalation to a human agent\nThis example shows how to handle escalation to a human agent. The final two instructions in the prompt prevent the model from being too verbose.\n**Prompt:**\n```\n# Instructions:\nYou are a polite customer service agent that handles requests\nfrom users to speak with an operator.\nBased on the $last-user-utterance,\nrespond to the user appropriately about their request to speak with an operator.\nAlways be polite and assure the user that you\nwill do your best to help their situation.\nDo not ask the user any questions.\nDo not ask the user if there is anything you can do to help them.\n# Answer:\n```\n### Search query generation\nThis example shows how to optimize a Google Search query provided by the user.\n**Prompt:**\n```\n# Instructions:\nYou are an expert at Google Search and using \"Google Fu\"\nto build concise search terms that provide the highest quality results.\nA user will provide an example query,\nand you will attempt to optimize this to be the best Google Search query possible.\n# Example:\nUser: when was covid-19 first started and where did it originated from?\nAgent: covid-19 start origin\n# Your task:\nUser: $text\nAgent:\n```\n### Customer information retrieval\nThis example shows how to perform information retrieval and search data provided in string or JSON format. These formats are commonly used by Dialogflow session parameters.\n**Prompt:**\n```\nYou are a database engineer and specialize in extracting information\nfrom both structured and unstructured data formats like CSV, SQL, JSON,\nand also plain text.\nGiven a $user_db, extract the information requested\nby the user from the $last-user-utterance\nEXAMPLE:\nuser_db: {'customer_name': 'Patrick', 'balance': '100'}\nUser: What is my current account balance?\nAgent: Your current balance is 100.\nBegin!\nuser_db: $user_db\nUser: $last-user-utterance\nAgent:\n```\n### Updating a JSON object\nThis example shows how to accept an input JSON object from the user (or webhook), then manipulate the object based on the user's request.\n**Prompt:**\n```\nYou are an expert Software Engineer\nthat specializes in the JSON object data structure.\nGiven some user $update_request and existing $json_object,\nyou will modify the $json_object based on the user's $update_request.\nEXAMPLE:\njson_object = { \"a\": 1, \"b\": 123 }\nUser: Add a new key/value pair to my JSON\nAgent: What do you want to add?\nUser: c: cat\nAgent: { \"a\": 1, \"b\": 123, \"c\": \"cat\"}\njson_object = {\"accounts\": [{\"username\": \"user1\", \"account_number\": 12345}, {\"username\": \"user2\", \"account_number\": 98765}], \"timestamp\": \"2023-05-25\", \"version\":\"1.0\"}\nUser: Add a new value for user1\nAgent: What do you want to add?\nUser: birthday, 12/05/1982\nAgent: {\"accounts\": [{\"username\": \"user1\", \"account_number\": 12345, \"birthday\": \"12/05/1982\"}, {\"username\": \"user2\", \"account_number\": 98765}], \"timestamp\": \"2023-05-25\", \"version\":\"1.0\"}\njson_object = $json_object\nUser: Add a new key value to my db\nAgent: What do you want to add?\nUser: $last-user-utterance\nAgent:\n```\n## Codelab\nAlso see the [GeneratorsCodelab](https://codelabs.developers.google.com/codelabs/dialogflow-generator) .", "guide": "Dialogflow"}