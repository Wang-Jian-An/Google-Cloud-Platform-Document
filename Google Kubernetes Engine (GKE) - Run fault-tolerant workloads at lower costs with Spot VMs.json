{"title": "Google Kubernetes Engine (GKE) - Run fault-tolerant workloads at lower costs with Spot VMs", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/kubernetes-engine-overview", "abstract": "# Google Kubernetes Engine (GKE) - Run fault-tolerant workloads at lower costs with Spot VMs\nThis page shows you how to run fault-tolerant, stateless, or batch workloads at lower costs by using Spot VMs in your Google Kubernetes Engine (GKE) clusters and node pools.\n", "content": "## Overview\nSpot VMs are Compute Engine [virtual machines (VMs)](/compute/docs/instances) that are priced lower than the default standard VMs and provide no guarantee of availability. Spot VMs offer the same [machine types](/compute/docs/machine-types) and options as standard Compute Engine VMs. Compute Engine can reclaim Spot VMs at any time due to system events, such as when the resources are needed for standard VMs.\nTo learn more about Spot VMs in GKE, see [Spot VMs](/kubernetes-engine/docs/concepts/spot-vms) .\nSpot VMs replace the need to use [preemptible VMs](/compute/docs/instances/preemptible) to run stateless, batch, or fault-tolerant workloads. In contrast to preemptible VMs, which expire after 24 hours, Spot VMs have no expiration time. Spot VMs are terminated when Compute Engine requires the resources to run standard VMs.\n**Note:** GKE continues to support using preemptible VMs in your clusters and node pools.\nSpot VMs are also supported on GKE Autopilot clusters through [Spot Pods](/kubernetes-engine/docs/how-to/autopilot-spot-pods) . With Spot Pods, Autopilot automatically schedules and manages workloads on Spot VMs.\n## Limitations\n- The [kubelet graceful node shutdown feature](https://kubernetes.io/docs/concepts/architecture/nodes/#graceful-node-shutdown) is only enabled on clusters running GKE version 1.20 and later. For GKE versions prior to 1.20, you can use the [Kubernetes on GCP Node Termination Event Handler](https://github.com/GoogleCloudPlatform/k8s-node-termination-handler) to gracefully terminate your Pods when Spot VMs are preempted.\n- Spot VMs do not support Windows Server node pools.## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.## Create a cluster with Spot VMs\nYou can create a new cluster using Spot VMs with the Google Cloud CLI or the Google Cloud console.\nCreate a new cluster which uses Spot VMs in the default node pool instead of standard VMs:\n```\ngcloud container clusters create CLUSTER_NAME \\\u00a0 \u00a0 --spot\n```\nReplace `` with the name of your new cluster.\nTo create a new cluster with a node pool using Spot VMs, perform the following steps:- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Click **Create** .\n- On the **Create cluster** dialog, next to **GKE Standard** , click **Configure** .\n- From the navigation menu, in the **Node pools** section, click the name of the node pool you want to configure, and then click **Nodes** .\n- Select the **Enable Spot VMs** checkbox.\n- Configure the cluster as needed, and then click **Create** .## Create a node pool with Spot VMs\nYou can create new node pools using Spot VMs with the gcloud CLI or Google Cloud console. You can only enable Spot VMs on new node pools. You cannot enable or disable Spot VMs on existing node pools.\nCreate a new node pool using Spot VMs:\n```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --cluster=CLUSTER_NAME \\\u00a0 \u00a0 --spot\n```\nReplace `` with the name of your new node pool.\nTo create a new node pool using Spot VMs, perform the following steps:- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- In the cluster list, click the name of the cluster you want to modify.\n- Click add_box **Add node pool** .\n- From the navigation menu, click **Nodes** .\n- Select the **Enable Spot VMs** checkbox.\n- Configure the node pool as needed, and then click **Create** .## Schedule workloads on Spot VMs\nGKE adds the `cloud.google.com/gke-spot=true` and `cloud.google.com/gke-provisioning=spot` (for nodes running GKE version 1.25.5-gke.2500 or later) [labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) to nodes that use Spot VMs. You can filter for this label in your Pod spec using either the [nodeSelector](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/) field in your Pod spec or [node affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity) .\nIn the following example, you create a cluster with two node pools, one of which uses Spot VMs. Then, you deploy a stateless `nginx` application onto the Spot VMs, using a `nodeSelector` to control where GKE places the Pods.\n- Create a new cluster with the default node pool using standard VMs:```\ngcloud container clusters create CLUSTER_NAME\n```Replace `` with the name of your new cluster.\n- Get credentials for the cluster:```\ngcloud container clusters get-credentials CLUSTER_NAME\n```\n- Create a node pool using Spot VMs:```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --num-nodes=1 \\\u00a0 \u00a0 --spot\n```Replace `` with the name of your new node pool.\n- Save the following manifest as a file named `pi-app.yaml` :```\napiVersion: batch/v1kind: Jobmetadata:\u00a0 name: pispec:\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: pi\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-spot: \"true\"\u00a0 \u00a0 \u00a0 terminationGracePeriodSeconds: 25\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: pi\u00a0 \u00a0 \u00a0 \u00a0 image: perl:5.34.0\u00a0 \u00a0 \u00a0 \u00a0 command: [\"perl\", \u00a0\"-Mbignum=bpi\", \"-wle\", \"print bpi(2000)\"]\u00a0 \u00a0 \u00a0 restartPolicy: Never\u00a0 backoffLimit: 4\n```In this manifest, the `nodeSelector` field tells GKE to only schedule Pods on nodes that use Spot VMs.\n- Apply the manifest to your cluster:```\nkubectl apply -f pi-app.yaml\n```\n- Describe the Pod:```\nkubectl describe pod pi\n```The output is similar to the following:```\nName:   pi-kjbr9\nNamespace: default\nPriority:  0\nNode:   gke-cluster-2-spot-pool-fb434072-44ct\n...\nLabels:  app=pi\n    job-name=pi\nStatus:  Succeeded\n...\nControlled By: Job/pi\nContainers:\n...\nConditions:\n Type    Status\n Initialized  True \n Ready    False \n ContainersReady False \n PodScheduled  True \nVolumes:\n...\nNode-Selectors:    cloud.google.com/gke-spot=true\nTolerations:     node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n       node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n Type Reason  Age From    Message\n ---- ------  ---- ----    ------ Normal Scheduled 4m3s default-scheduler Successfully assigned default/pi-kjbr9 to gke-cluster-2-spot-pool-fb434072-44ct\n Normal Pulling 4m2s kubelet   Pulling image \"perl:5.34.0\"\n Normal Pulled  3m43s kubelet   Successfully pulled image \"perl:5.34.0\" in 18.481761978s\n Normal Created 3m43s kubelet   Created container pi\n Normal Started 3m43s kubelet   Started container pi\n```The `Node` field shows that GKE only schedules your Pods on nodes that use Spot VMs.## Use taints and tolerations for Spot VMs\nAs a best practice, create clusters with at least one node pool without Spot VMs where you can place system workloads like DNS. You can use [node taints](/kubernetes-engine/docs/how-to/node-taints) and the corresponding [tolerations](/kubernetes-engine/docs/how-to/node-taints#configuring_pods_to_tolerate_a_taint) to tell GKE to avoid placing certain workloads on Spot VMs.\n- To create a node pool with nodes that use Spot VMs and have node taints, use the `--node-taints` flag when creating the node pool:```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --node-taints=cloud.google.com/gke-spot=\"true\":NoSchedule\u00a0 \u00a0 --spot\n```\n- To add the corresponding toleration to the Pods that you want to schedule to Spot VMs, modify your deployments and add the following to your Pod specification:```\ntolerations:- key: cloud.google.com/gke-spot\u00a0 operator: Equal\u00a0 value: \"true\"\u00a0 effect: NoSchedule\n```GKE only schedules Pods with this toleration onto the Spot VMs with the added node taint.## What's next\n- [Learn how to run a GKE application on Spot VMs with on-demand nodes as fallback](/blog/topics/developers-practitioners/running-gke-application-spot-nodes-demand-nodes-fallback) .\n- [Learn more about Spot VMs in GKE](/kubernetes-engine/docs/concepts/spot-vms) .\n- [Learn about taints and tolerations](/kubernetes-engine/docs/how-to/node-taints) .\n- [Take a tutorial about deploying a batch workload using Spot VMs in GKE](/kubernetes-engine/docs/tutorials/batch-ml-workload) .", "guide": "Google Kubernetes Engine (GKE)"}