{"title": "Cloud SQL - Export and import using pg_dump, pg_dumpall, and pg_restore", "url": "https://cloud.google.com/sql/docs/postgres/import-export/import-export-dmp", "abstract": "# Cloud SQL - Export and import using pg_dump, pg_dumpall, and pg_restore\nThis page describes exporting and importing data into Cloud SQL instances using pg_dump, pg_dumpall, and pg_restore.\n**Note:** If you're migrating an entire database from a supported database server (on-premises, in AWS, or Cloud SQL) to a new Cloud SQL instance, you can use the [Database Migration Service](/database-migration/docs) instead of exporting and then importing files. If you're exporting because you want to create a new instance from the exported file, consider [restoring from a backup to a different instance](/sql/docs/postgres/backup-recovery/restoring#restorebackups-another-instance) or [cloning the instance](/sql/docs/postgres/clone-instance) .\n", "content": "## Before you begin\n**Important:** Before starting a large export, ensure that at least 25 percent of the database size is free (on the instance). Doing so helps prevent issues with aggressive autogrowth, which can affect the availability of the instance.\nExports use database resources, but they do not interfere with normal database operations unless the instance is under-provisioned.\nFor best practices, see [Best Practices for Importing and Exporting Data](/sql/docs/postgres/import-export) .\nAfter completing an import operation, [verify](/sql/docs/postgres/import-export#verify) the results.\nLearn more about the [pg_dump](https://www.postgresql.org/docs/12/static/app-pgdump.html) , [pg_dumpall](https://www.postgresql.org/docs/12/static/app-pg-dumpall.html) , and [pg_restore](https://www.postgresql.org/docs/12/static/app-pgrestore.html) utilities.\n## Export data from Cloud SQL for PostgreSQL\nYou can use Cloud SQL to perform an export from the Google Cloud console, the [gcloud CLI](/sdk/gcloud) , or the API.\n- To export a single PostgreSQL database, use the [pg_dump](https://www.postgresql.org/docs/12/static/app-pgdump.html) utility.\n- To export all PostgreSQL databases of a cluster, use the [pg_dumpall](https://www.postgresql.org/docs/12/static/app-pg-dumpall.html) utility.\nWhen using either utility, make sure that you also use the required options to ensure that the resulting export file is valid for import back into Cloud SQL.\n### Export data from an on-premises PostgreSQL server using pg_dump\nTo export a database that is not managed by Cloud SQL, for later import into Cloud SQL, use the `pg_dump` utility with the following flags:\n- `--no-owner`Ownership change commands must not be included in the dump file.\n- `--format`The `custom` and `directory` formats are allowed if  the dump file is intended for use with `pg_restore` .For `plain-text` format, export to a [SQL dump file](/sql/docs/postgres/import-export/import-export-sql#export-sql-dump-file) instead. This format is not compatible with `pg_restore` , and  must be imported using the Google Cloud console import command or `psql` client.\n- `--no-acl`This flag is required if your dump would otherwise contain statements  to grant or revoke membership in a `SUPERUSER` role.\nIn addition, you must remove all of the following:\n- Extension-related statements, if Cloud SQL does not support that  extension. See [PostgreSQL Extensions](/sql/docs/postgres/extensions) for the list of supported extensions.\n- `CREATE EXTENSION`or`DROP EXTENSION`statements  referencing plpgsql. This extension comes pre-installed on Cloud SQL  Postgres instances.\n- `COMMENT ON EXTENSION`statements.\nConfirm that the default encoding, as determined by the database settings, is correct for your data. If needed, you can override the default with the `--encoding` flag.\n### Export data using the custom format from Cloud SQL for PostgreSQL\nTo use the custom format, from a command line, run `pg_dump` :\n```\npg_dump \\-U USERNAME \\--format=custom \\--no-owner \\--no-acl \\DATABASE_NAME > DATABASE_NAME.dmp\n```\n### Export data from multiple files in parallel from Cloud SQL for PostgreSQL\nYou can only use the `directory` output format to [export data from multiple files in parallel](/sql/docs/postgres/import-export/import-export-parallel#export-data-multiple-files-parallel) .\nTo export in parallel, use the `-j` `` flag. is the number of cores on the source instance.\n### Export all databases\n[pg_dumpall](https://www.postgresql.org/docs/12/static/app-pg-dumpall.html) is a utility that allows you to extract all PostgreSQL databases of a cluster into a single script file. This file has SQL commands that you can use to restore the databases.\nTo export all PostgreSQL databases in a Cloud SQL instance, use the `pg_dumpall` utility with the following mandatory flags:\n- `exclude-database=cloudsqladmin`\n- `exclude-database=template*`\nThe `pg_dumpall` utility doesn't have access to the `cloudsqladmin` or `template` databases.\nIf you're using the`pg_dumpall`utility to export all PostgreSQL databases of a cluster that aren't managed by Cloud SQL, then you don't have to use the`exclude-database=cloudsqladmin`flag.\nIf an instance has multiple databases and these databases have multiple owners, then this command fails. If this occurs, then use the`pg_dump`utility to export the databases individually.\nTo export all PostgreSQL databases, run the following command:\n```\npg_dumpall \\-h HOST_NAME -l DATABASE_NAME \u2013exclude-database=cloudsqladmin \\\u2013exclude-database=template* > pg_dumpall.sql\n```\nTo view role passwords when dumping roles with `pg_dumpall` , [set the cloudsql.pg_authid_select_role flag](/sql/docs/postgres/users#setting_the_flags_for_the_pg_shadow_view_and_the_pg_authid_table) to a PostgreSQL role name. If the role exists, then it has read-only ( `SELECT` ) access to the [pg_authid](/sql/docs/postgres/users#pg_shadow) table. This table contains role passwords.\n## Import\nUse the `pg_restore` utility to import an archive into a Cloud SQL database. `pg_restore` works only with archives created by [pg_dump](https://www.postgresql.org/docs/current/static/app-pgdump.html) in either the `custom` or `directory` formats. [Learn more](https://www.postgresql.org/docs/current/static/app-pgrestore.html) about `pg_restore` .\n### Import from a dump file created with the custom format to Cloud SQL for PostgreSQL\nIf the dump file was created with custom format, run the following command:\n```\npg_restore \\--list DATABASE_NAME.dmp | sed -E 's/(.* EXTENSION )/; \\1/g' > \u00a0DATABASE_NAME.toc\n```\nPost-processing from `sed` comments out all extension statements in the SQL dump file.\nWhen importing using `pg_restore` , specify the processed table of contents with the command-line argument \"--use-list= .toc\".\n### Import data from multiple files in parallel to Cloud SQL for PostgreSQL\nYou can [import data from multiple files in parallel](/sql/docs/postgres/import-export/import-export-parallel#import-data-multiple-files-parallel) only for archives created using the `directory` and `custom` output formats.\nTo import in parallel, use the `-j` `` flag. is the number of cores on the destination instance.\n### Import performance on Cloud SQL for PostgreSQL\n`pg_restore`performance depends on the write performance of the Cloud SQL instance. [Learn more](/sql/docs/postgres/diagnose-issues#performance) about performance in Cloud SQL.\n## What's next\n- Learn how to [check the status of import and export operations](/sql/docs/postgres/import-export/checking-status-import-export) .\n- Learn more about [best practices for importing and exporting data](/sql/docs/postgres/import-export) .\n- Learn more about the [PostgreSQL pg_dump utility](https://www.postgresql.org/docs/current/static/app-pgdump.html) .\n- [Known issues for imports and exports](/sql/docs/postgres/known-issues#import-export) .", "guide": "Cloud SQL"}