{"title": "Cloud SQL - Export and import using BAK files and transaction log files", "url": "https://cloud.google.com/sql/docs/sqlserver/import-export/import-export-bak", "abstract": "# Cloud SQL - Export and import using BAK files and transaction log files\nThis page describes exporting and importing data into Cloud SQL instances using BAK files and importing data into Cloud SQL instances using transaction log files.\n**Note:** In Cloud SQL, SQL Server currently supports the export of native BAK files. If you're exporting to create a new instance from the exported file, consider [restoring from a backup to a different instance](/sql/docs/sqlserver/backup-recovery/restoring#restorebackups-another-instance) or [cloning the instance](/sql/docs/sqlserver/clone-instance) .\n**WARNING!** Don't use a BAK file created from a read-only database or from a database that is in single-user mode. If you import a BAK file created from a read-only database or from a database that's in single-user mode, then an error might occur.\n", "content": "## Before you begin\n**Important:** Before starting a large export, ensure that at least 25 percent of the database size is free (on the instance). Doing so helps prevent issues with aggressive autogrowth, which can affect the availability of the instance.\nExports use database resources, but exports don't interfere with normal database operations unless the instance is under-provisioned.\nFor best practices, see [Best Practices for Importing andExporting Data](/sql/docs/sqlserver/import-export) .\nAfter completing an import operation, [verify](/sql/docs/sqlserver/import-export#verify) the results.\n## Export data from Cloud SQL for SQL Server\nCloud SQL supports the export of built-in BAK files.\nIf you aim to create a new instance from an exported file, then consider [restoring from a backup to a different instance](/sql/docs/sqlserver/backup-recovery/restoring#restorebackups-another-instance) or [cloning the instance](/sql/docs/sqlserver/clone-instance) .\nCloud SQL performs a [full backup](https://docs.microsoft.com/en-us/sql/relational-databases/backup-restore/full-database-backups-sql-server?view=sql-server-ver15) of the selected database during an export operation.\n**Note:** For information about striped export, see [Use striped export](#use-striped-export) .\n### Required roles and permissions for exporting from Cloud SQL for SQL Server\nTo export data from Cloud SQL into Cloud Storage, the user initiating the export must have one of the following roles:\n- The [Cloud SQL Editor](/sql/docs/sqlserver/iam-roles) role\n- A [custom role](/iam/docs/understanding-custom-roles) ,  including the following permissions:- `cloudsql.instances.get`\n- `cloudsql.instances.export`\nAdditionally, the service account for the Cloud SQL instance must have one of the following roles:- The`storage.objectAdmin`Identity and Access Management (IAM) role\n- A custom role, including the following permissions:- `storage.objects.create`\n- `storage.objects.list`(for striped export only)\n- `storage.objects.delete`(for striped export only)For help with IAM roles, see [Identity and Access Management](/storage/docs/access-control/iam) .\n**Note** : The changes that you make to the IAM permissions and roles might take a few minutes to take effect. For more information, see [Access change propagation](/iam/docs/access-change-propagation) .### Export data to a BAK file from Cloud SQL for SQL Server\n**Note:** You can't export a [database snapshot](https://docs.microsoft.com/en-us/sql/relational-databases/databases/database-snapshots-sql-server) to a BAK file.\n- In the Google Cloud console, go to the **Cloud SQL Instances** page. [Go to Cloud SQL Instances](https://console.cloud.google.com/sql) \n- To open the **Overview** page of an instance, click the instance name.\n- Click **Export** .\n- In the **File format** section, click **BAK** .\n- In the **Data to export** section, use the drop-down menu to select the  database you want to export from.\n- In the **Destination** section, select **Browse** to search for a  Cloud Storage bucket or folder for your export.\n- Click **Export** to begin the export.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) .\n- Find the service account for the Cloud SQL instance you're exporting from. You can do this running the`gcloud sql instances describe`command. Look for the`serviceAccountEmailAddress`field in the output.```\ngcloud sql instances describe INSTANCE_NAME\u00a0 \n```\n- Use` [ gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) to the service account. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export the database:```\ngcloud sql export bak INSTANCE_NAME gs://BUCKET_NAME/FILENAME \\--database=DATABASE_NAME\u00a0 \n```For information about using the `gcloud sql export bak` command, see the [ command reference page](/sdk/gcloud/reference/beta/sql/export/bak) .\n- If you don't need to retain the IAM role you set  previously, then [revoke](/iam/docs/granting-changing-revoking-access#revoking-console) it now.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the export.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Provide your instance with the`legacyBucketWriter` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [UsingIAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export your database:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the SQL dump fle\n- : The name of a database inside the Cloud SQL instance\n- : The name of a database inside the Cloud SQL instance\n- : Enables serverless export. Set to`true`to  use serverless export. **Note:** Serverless export costs extra. See the [pricing page](/sql/pricing#storage-networking-prices) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_dump_file\",\n  \"databases\": [\"database_name\"],\n  \"offload\": true | false\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n- If you don't need to retain the IAM role you set previously, then remove it now.For the complete list of parameters for the request, see the\n [instances:export](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/export) \npage.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the export.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [UsingIAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export your database:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the SQL dump fle\n- : The name of a database inside the Cloud SQL instance\n- : The name of a database inside the Cloud SQL instance\n- : Enables serverless export. Set to`true`to  use serverless export. **Note:** Serverless export costs extra. See the [pricing page](/sql/pricing#storage-networking-prices) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_dump_file\",\n  \"databases\": [\"database_name\"],\n  \"offload\": true | false\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n- If you don't need to retain the IAM role you set previously, then [revoke](/iam/docs/granting-changing-revoking-access#revoking-console) it now.For the complete list of parameters for the request, see the\n [instances:export](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/export) \npage.\n### Export differential database backups\nBefore exporting a [differential database backup](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/differential-backups-sql-server?view=sql-server-ver16) , you must export a differential base.\nIf other services or features, such as point-in-time recovery and read replica, trigger a full backup between your full backup export and differential backup export, then you must trigger a full backup export again.\nTo understand this better, consider the following example:\n- You raise a full backup request at 7:00 AM.\n- You enable point-in-time recovery at 9:00 AM. This triggers a full backup on your instance.\n- You try to take a differential backup at 5:00 PM. This export request fails with an error message because the last full backup was triggered by point-in-time recovery.\n**Note:** On an instance enabled with point-in-time recovery, Cloud SQL triggers a daily backup and this daily backup also triggers a full database backup. This means that on an instance enabled with point-in-time recovery, you have to take full backup and differential backup within two consecutive daily backups.\nCloud SQL doesn't support database export requests with `--differential-base` or `--bak-type=DIFF` on replica instances.\n- [ Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Find the service account for the Cloud SQL instance from which you're exporting. You can do this running the`gcloud sql instances describe`command. Look for the`serviceAccountEmailAddress`field in the output.```\ngcloud sql instances describe INSTANCE_NAME\u00a0 \n```\n- Use` [ gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) to the service account. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export the database as the differential base.```\ngcloud sql export bak INSTANCE_NAME gs://BUCKET_NAME/DIFFERENTIAL_BASE_FILENAME \\--database=DATABASE_NAME --differential-base\n```For information about using the `gcloud sql export bak` command, see the [ command reference page](/sdk/gcloud/reference/sql/export/bak) .\n- Export a differential backup.```\ngcloud sql export bak INSTANCE_NAME gs://BUCKET_NAME/DIFFERENTIAL_BACKUP_FILENAME \\--database=DATABASE_NAME --bak-type=DIFF\u00a0 \n```For information about using the `gcloud sql export bak` command, see the [ command reference page](/sdk/gcloud/reference/sql/export/bak) .\n- If you don't need to retain the IAM role you set  previously, then [revoke](/iam/docs/granting-changing-revoking-access#revoking-console) it now.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the export.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Provide your instance with the`legacyBucketWriter` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [UsingIAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export your full database backup as the differential base.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the SQL dump fle\n- : the name of a database inside the Cloud SQL instance\n- : the name of a database inside the Cloud SQL instance\n- : to enable and use serverless export, set its value to`true`. **Note:** Serverless export costs extra. See the [pricing page](/sql/pricing#storage-networking-prices) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_dump_file\",\n  \"databases\": [\"database_name\"]\n  \"offload\": true | false\n  \"bakExportOptions\": {\n  \"differentialBase\":true\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Export a differential backup.Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the SQL dump fle\n- : The name of a database inside the Cloud SQL instance\n- : The name of a database inside the Cloud SQL instance\n- : Enables serverless export. Set to`true`to  use serverless export. **Note:** Serverless export costs extra. See the [pricing page](/sql/pricing#storage-networking-prices) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_dump_file\",\n  \"databases\": [\"database_name\"]\n  \"offload\": true | false\n  \"bakExportOptions\": {\n  bakType:\"DIFF\"\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- If you don't need to retain the IAM role you set previously, then remove it now.For the complete list of parameters for the request, see the\n [instances:export](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/export) \npage.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the export.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [UsingIAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export your full database backup as the differential base.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the SQL dump fle\n- : the name of a database inside the Cloud SQL instance\n- : the name of a database inside the Cloud SQL instance\n- : to enable and use serverless export, set its value to`true`. **Note:** Serverless export costs extra. For more information, see the [pricing page](/sql/pricing#storage-networking-prices) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_dump_file\",\n  \"databases\": [\"database_name\"]\n  \"offload\": true | false\n  \"bakExportOptions\": {\n   \"differentialBase\":true\n  }\n  }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Export a differential backup:Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the SQL dump fle\n- : the name of a database inside the Cloud SQL instance\n- : the name of a database inside the Cloud SQL instance\n- : to enable and use serverless exports, set this value to`true`. **Note:** Serverless export costs extra. For more information, see the [pricing page](/sql/pricing#storage-networking-prices) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_dump_file\",\n  \"databases\": [\"database_name\"]\n  \"offload\": true | false\n  \"bakExportOptions\": {\n  bakType:\"DIFF\"\n  }\n  }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- If you don't need to retain the IAM role you set previously, then [revoke](/iam/docs/granting-changing-revoking-access#revoking-console) it now.For the complete list of parameters for the request, see the\n [instances:export](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/export) \npage.\n### Use striped export\nThe advantages of striped export are the following:\n- Reductions in the time needed for operations to complete\n- Databases larger than 5 TB can be exported\nA potential disadvantage of using striped export is that the backup, rather than consisting of one file, is split across a set of files. This set is called a \"stripe set\"; see [Backup devices in a striped media set (a stripe set)](https://learn.microsoft.com/en-us/sql/t-sql/statements/backup-transact-sql?view=sql-server-ver16#backup-devices-in-a-striped-media-set-a-stripe-set) . In Cloud SQL, you export to an empty folder in Cloud Storage instead of generating a single file. For more information, see [How to use striped export](#how-to-use-striped-export) .\nStriped export can improve the performance of exports. However, if your use case requires a single output file, or if your database is less than 5 TB in size, and if faster performance isn't critical, you may want to use a non-striped export.\nIf you decide to use striped export, then consider the number of stripes. You can specify this value in your gcloud CLI command or REST API call. However, if you want an optimal number of stripes for performance, or if you don't know a number, omit the number. An optimal number of stripes is set automatically.\nThe maximum number of stripes currently supported by Cloud SQL for SQL Server is 64.- [ Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Find the service account for the Cloud SQL instance you're exporting from. You can do this by running the`gcloud sql instances describe`command. Look for the`serviceAccountEmailAddress`field in the output.```\ngcloud sql instances describe INSTANCE_NAME\u00a0 \n```\n- Use` [ gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) to the service account. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- To export the database, specify the`--striped`parameter  and/or specify a value for`--stripe_count`.  Setting a value for`--stripe_count`implies that the`--striped`parameter is intended. An error  occurs if you specify`--no-striped`but specify a value for`--stripe_count`:```\ngcloud beta sql export bak INSTANCE_NAME \\gs://BUCKET_NAME/STRIPED_EXPORT_FOLDER \\--database=DATABASE_NAME --striped --stripe_count=NUMBER\u00a0 \n```For information about using the `gcloud beta sql export bak` command, see the [ command reference page](/sdk/gcloud/reference/beta/sql/export/bak) .\n- If you don't need to retain the IAM role you set  previously, then [ revoke](/iam/docs/granting-changing-revoking-access#revoking-console) it now.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the export.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Provide your instance with the`legacyBucketWriter` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [UsingIAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export your database:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the folder (in the Cloud Storage bucket) to which to  export the striped set to\n- : The name of a database in your Cloud SQL instance\n- : Set to`true`to use striped export.  If you specify`true`without specifying a stripe count, an optimal number of stripes  is set automatically\n- : The number of stripes to use. If specified,`striped`is implied as`true`\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_folder\",\n  \"databases\": [\"database_name\"],\n  \"bakExportOptions\": {\n  \"striped\": true | false,\n  \"stripe_count\": [\"number_of_stripes\"]\n  }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n- If you don't need to retain the IAM role you set previously, then remove it now.For the complete list of parameters for the request, see the\n [instances:export](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/export) \npage.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the export.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but is strongly recommended, so you don't open up access to any other data.\n- Provide your instance with the`legacyBucketWriter` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [UsingIAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Export your database:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the folder (in the Cloud Storage bucket) to which to  export the striped set\n- : The name of a database in your Cloud SQL instance\n- : Set to`true`to use striped export.  If you specify`true`without specifying a stripe count, an optimal number of stripes  is set automatically\n- : The number of stripes to use. If specified,`striped`is implied as`true`\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/export\n```\nRequest JSON body:\n```\n{\n \"exportContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_folder\",\n  \"databases\": [\"database_name\"],\n  \"bakExportOptions\": {\n  \"striped\": true | false,\n  \"stripe_count\": [\"number_of_stripes\"]\n  }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n- If you don't need to retain the IAM role you set previously, then remove it now.For the complete list of parameters for the request, see the\n [instances:export](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/export) \npage.\n## Import to Cloud SQL for SQL Server\n### Required roles and permissions for importing to Cloud SQL for SQL Server\nTo import data from Cloud Storage into Cloud SQL, the user initiating the import must have one of the following roles:\n- The [Cloud SQL Editor](/sql/docs/sqlserver/iam-roles) role\n- A [custom role](/iam/docs/understanding-custom-roles) ,  including the following permissions:- `cloudsql.instances.get`\n- `cloudsql.instances.import`\nAdditionally, the service account for the Cloud SQL instance must have one of the following roles:- The`storage.objectAdmin`IAM role\n- A custom role, including the following permissions:- `storage.objects.get`\n- `storage.objects.list`(for striped import only)For help with IAM roles, see [Identity and Access Management](/storage/docs/access-control/iam) .\n**Note** : The changes that you make to the IAM permissions and roles might take a few minutes to take effect. For more information, see [Access change propagation](/iam/docs/access-change-propagation) .### Import data from a BAK file to Cloud SQL for SQL Server\nTo use striped import, see [Use striped import](#use-striped-import) .\nVarious import frameworks are available. For example, Cloud SQL for SQL Server supports [change data capture (CDC)](/sql/docs/sqlserver/replication/enable-cdc) for the following database versions:\n- SQL Server 2017 Standard\n- SQL Server 2017 Enterprise\n- SQL Server 2019 Standard\n- SQL Server 2019 Enterprise\nWhen importing a CDC-enabled database, the [KEEP_CDC](https://docs.microsoft.com/en-us/sql/t-sql/statements/restore-statements-arguments-transact-sql?view=sql-server-ver15#change_data_capture_with_option) flag is retained.\n**Note:** You can't import a database that was exported from a higher version of SQL Server or import from a higher compatibility level into a lower one. For example, if you exported a SQL Server 2017 version, you can't import it into a SQL Server 2014 version.\nIf your instance version is a Microsoft SQL Server Enterprise Edition, then you can import encrypted BAK files.\nMicrosoft SQL Server Standard Edition instances also import encrypted BAK files, but only through gcloud CLI.\nThe only supported BAK extensions are `.bak` and `.bak.gz` . GPG encrypted backups are not currently supported.\nFor the instructions below, prepare to specify a new database; don't create a database before starting the import of your BAK file.\n**Note:** Cloud SQL only supports importing a full backup with a single backup set.\nTo import data to a Cloud SQL instance using a BAK file:\n- In the Google Cloud console, go to the **Cloud SQL Instances** page. [Go to Cloud SQL Instances](https://console.cloud.google.com/sql) \n- To open the **Overview** page of an instance, click the instance name.\n- Click **Import** .\n- In the **Choose the file you'd like to import data from** field,  enter the path to the bucket and BAK file to use for the import.You can import a compressed ( `.gz` ) or an uncompressed file.\n- In the **Format** section, select **BAK** .\n- Specify the **Database** in  your Cloud SQL instance where you want to import the BAK file.\n- Click the **Import** to start the import.\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the import.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Make sure you have configured the required roles and permissions.\n- [Upload](/storage/docs/uploading-objects#uploading-an-object) the data from the BAK file to the bucket.\n- Describe the instance that you are importing to:```\ngcloud sql instances describe INSTANCE_NAME\n```\n- Copy the`serviceAccountEmailAddress`field.\n- Use` [gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectViewer` [IAM role](/storage/docs/access-control/iam-roles) to the service account for the bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import the data from the file:```\ngcloud sql import bak INSTANCE_NAME gs://BUCKET_NAME/FILE_NAME \\--database=DATABASE_NAME\n```For encrypted imports, use the following command:```\ngcloud sql import bak INSTANCE_NAME gs://BUCKET_NAME/FILE_NAME--database=DATABASE_NAME --cert-path=gs://BUCKET_NAME/CERTIFICATE_NAME\u00a0--pvk-path=gs://BUCKET_NAME/KEY_NAME --prompt-for-pvk-password\n```\n- If you don't need to retain the IAM permissions you set previously, then remove them using` [gsutil iam](/storage/docs/gsutil/commands/iam) `.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import the data from the file:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the BAK file\n- : The name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_bak_file\",\n  \"database\": \"database_name\"\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:To use a different user for the import, specify the `importContext.importUser` property.For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import the data from the file:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the BAK file\n- : The name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_bak_file\",\n  \"database\": \"database_name\"\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:To use a different user for the import, specify the `importContext.importUser` property.For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\nIf you get an error such as `ERROR_RDBMS` , ensure the BAK file exists in the bucket and you have the correct permissions on the bucket. For help configuring access control in Cloud Storage, see [Create and Manage Access Control Lists](/storage/docs/access-control/create-manage-lists) .\n### Import differential database backups\nBefore you import a [differential database backup](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/differential-backups-sql-server?view=sql-server-ver16) , you need a full backup import and your database must be in the `RESTORING` state after the full backup import.\nCloud SQL doesn't support importing differential database backups on instances that are enabled with point-in-time recovery. This is because importing a database backup with `--no-recovery` is a prerequisite for importing differential database backups. Additionally, you can't enable point-in-time recovery on an instance if the database is in the `RESTORING` state. In the case of import failure, do one of the following to enable point-in-time recovery:\n- Bring the database that's in the `RESTORING` state online by using the `--recovery-only` flag.\n- Remove the database.\nTo import data to a Cloud SQL instance using a differential database backup, perform the following steps:\n- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the import.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't mandatory, but we strongly recommend that you perform it so that you don't open up access to any other data.\n- Make sure that you've configured the required roles and permissions.\n- [Upload](/storage/docs/uploading-objects#uploading-an-object) the data from the BAK file to the bucket.\n- Describe the instance that you are importing to:```\ngcloud sql instances describe INSTANCE_NAME\n```\n- Copy the`serviceAccountEmailAddress`field.\n- Use` [gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectViewer` [IAM role](/storage/docs/access-control/iam-roles) to the service account for the bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import a full backup with `--no-recovery` .```\ngcloud sql import bak INSTANCE_NAME gs://BUCKET_NAME/DIFFERENTIAL_BASE_FILENAME \\--database=DATABASE_NAME --bak-type=FULL --no-recovery\n```\n- Import a differential database backup.```\ngcloud sql import bak INSTANCE_NAME gs://BUCKET_NAME/DIFFERENTIAL_BACKUP_FILENAME \\--database=DATABASE_NAME --bak-type=DIFF --no-recovery\n```\n- Use the `--recovery-only` flag to bring the imported database online. This step is optional, and you need to perform it only if your database is in the `RESTORING` state.```\ngcloud sql import bak INSTANCE_NAME \\--database=DATABASE_NAME --recovery-only\n```\n- If you don't need to retain the IAM permissions you set previously, then remove them using` [gsutil iam](/storage/docs/gsutil/commands/iam) `.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- **Note** : In the following steps, specify the`importContext.importUser`property to use a different user for the import. For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- Import a full backup with`noRecovery`.Before using any of the request data, make the following replacements:- : the project ID.\n- : the instance ID.\n- : the Cloud Storage bucket name.\n- : the path to the BAK file.\n- : the name of a database inside the Cloud SQL instance.\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"noRecovery\": true,\n  \"bakType\": \"FULL\",\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Import a differential database backup.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the BAK file\n- : the name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_bak_file\",\n  \"database\": \"database_name\"\n  \"bakImportOptions\": {\n  \"bakType\": \"DIFF\",\n  \"noRecovery\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Use `recoveryOnly` to bring the imported database online. This step is optional, and you need to perform it only if your database is in the `RESTORING` state.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the BAK file\n- : the name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"recoveryOnly\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- **Note** : In the following steps, specify the`importContext.importUser`property to use a different user for the import. For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- Import a full backup with`noRecovery`.Before using any of the request data, make the following replacements:- : the project ID.\n- : the instance ID.\n- : the Cloud Storage bucket name.\n- : the path to the BAK file.\n- : the name of a database inside the Cloud SQL instance.\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT-ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"noRecovery\": true,\n  \"bakType\": \"FULL\",\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT-ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT-ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Import a differential database backup.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the BAK file\n- : the name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_bak_file\",\n  \"database\": \"database_name\"\n  \"bakImportOptions\": {\n  \"bakType\": \"DIFF\",\n  \"noRecovery\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Use `recoveryOnly` to bring the imported database online. This step is optional, and you need to perform it only if your database is in the `RESTORING` state.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the BAK file\n- : the name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"recoveryOnly\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- If you don't need to retain the IAM permissions you set previously, remove the permissions.\nIf you get an error such as `ERROR_RDBMS` , then ensure that the BAK file exists in the bucket and you have the correct permissions on the bucket. For help configuring access control in Cloud Storage, see [Create and Manage Access Control Lists](/storage/docs/access-control/create-manage-lists) .\n### Import transaction log backups\nA [transaction log](https://learn.microsoft.com/en-us/sql/relational-databases/logs/the-transaction-log-sql-server?view=sql-server-ver16#Characteristics) is a record of your database's transactions and the modifications made by each transaction. You can use it to re-establish database consistency in the event of a system failure.\n**Note** :- Cloud SQL doesn't support striped import of transaction log backups.\n- Cloud SQL doesn't support importing transaction log backups on instances that are  enabled with point-in-time recovery. This is because importing a database backup  with`--no-recovery`is a prerequisite for importing transaction log backups.  Additionally, you can't enable point-in-time recovery on an instance if the database is in the`RESTORING`state. In the case of import failure, do one of the following to enable point-in-time recovery:- Bring the database that's in the`RESTORING`state online by using the`--recovery-only`flag.\n- Remove the database.To import data to a Cloud SQL instance using a transaction log backup, perform the following steps:\n- [ Optional: Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the import.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```\n- [Upload](/storage/docs/uploading-objects#uploading-an-object) the backup files to the bucket.\n- Describe the instance that you are importing to:```\ngcloud sql instances describe INSTANCE_NAME\n```\n- Copy the`serviceAccountEmailAddress`field.\n- Use` [gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectViewer` [IAM role](/storage/docs/access-control/iam-roles) to the service account for the bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import a full backup using the `--no-recovery` parameter. Ensure that your database is in the `RESTORING` state after the full backup import.```\ngcloud sql import bak INSTANCE_NAME gs://BUCKET_NAME/BACKUP_FILENAME \\--database=DATABASE_NAME --bak-type=FULL --no-recovery\n```\n- Optional: [Import a differential backup](/sql/docs/sqlserver/import-export/import-export-bak#import_diff) .\n- Import a transaction log backup.```\ngcloud sql import bak INSTANCE_NAME gs://BUCKET_NAME/BACKUP_FILENAME \\--database=DATABASE_NAME --bak-type=TLOG--stop-at=STOP_AT_TIMESTAMP --stop-at-mark=STOP_AT_MARK_NAME--no-recovery\n```Replace the following:- : the instance name.\n- : the Cloud Storage bucket name.\n- : the name of your backup file.\n- : the name of a database inside the Cloud SQL instance.\n- : the timestamp at which the transaction log import must stop. This is an  optional field and the value  must use the [RFC 3339 format](https://www.ietf.org/rfc/rfc3339.txt) .\n- : the [ marked transaction](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/use-marked-transactions-to-recover-related-databases-consistently?view=sql-server-ver16) at which the transaction log import must stop. This is an  optional field and can take any string as its value. If the value is in the format`lsn:log-sequence-number`,  then the transaction log import  stops at the given [ log sequence number](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/recover-to-a-log-sequence-number-sql-server?view=sql-server-ver16#LSNs) .\nRepeat this step until all transaction log backups are imported.\n- Optional: Use the `--recovery-only` flag to bring the imported database online. Perform this step only if your database is in the `RESTORING` state.```\ngcloud sql import bak INSTANCE_NAME \\--database=DATABASE_NAME --recovery-only\n```\n- If you don't need to retain the IAM permissions you set previously, then remove them using` [gsutil iam](/storage/docs/gsutil/commands/iam) `.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- For the complete list of parameters for the request, see the\n- [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) \n- page.\n- Import a full backup with`noRecovery`. Ensure that your database is in the`RESTORING`state after the full backup import.Before using any of the request data, make the following replacements:- : the project ID.\n- : the instance ID.\n- : the Cloud Storage bucket name.\n- : the path to the BAK file.\n- : the name of a database inside the Cloud SQL instance.\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"noRecovery\": true,\n  \"bakType\": \"FULL\",\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Optional: [Import a differential backup](/sql/docs/sqlserver/import-export/import-export-bak#import_diff-v1) .\n- Import a transaction log backup.Before using any of the request data, make the following replacements:- : the project ID.\n- : the instance ID.\n- : the Cloud Storage bucket name.\n- : the path to the transaction log file.\n- : the name of a database inside the Cloud SQL instance.\n- : the timestamp at which the transaction log import must stop. This is an  optional field and the value  must use the [RFC 3339 format](https://www.ietf.org/rfc/rfc3339.txt) .\n- : the [ marked transaction](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/use-marked-transactions-to-recover-related-databases-consistently?view=sql-server-ver16) at which the transaction log import must stop. This is an  optional field and can take any string as its value. If the value is in the format`lsn:log-sequence-number`,  then the transaction log import  stops at the given [ log sequence number](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/recover-to-a-log-sequence-number-sql-server?view=sql-server-ver16#LSNs) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_TLOG_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"bakType\": \"TLOG\",\n  \"stopAt\": STOP_AT_TIMESTAMP,\n  \"stopAtMark\": STOP_AT_MARK_NAME,\n  \"noRecovery\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:Repeat this step until all transaction log backups are imported.\n- Optional: Use `recoveryOnly` to bring the imported database online. Perform this step only if your database is in the `RESTORING` state.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the BAK file\n- : the name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"recoveryOnly\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- **Note** : In the following steps, specify the`importContext.importUser`property to use a different user for the import. For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- Import a full backup with`noRecovery`. Ensure that your database is in the`RESTORING`state after the full backup import.Before using any of the request data, make the following replacements:- : the project ID.\n- : the instance ID.\n- : the Cloud Storage bucket name.\n- : the path to the BAK file.\n- : the name of a database inside the Cloud SQL instance.\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT-ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"noRecovery\": true,\n  \"bakType\": \"FULL\",\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT-ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT-ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- Optional: [Import a differential backup](/sql/docs/sqlserver/import-export/import-export-bak#import_diff-v1beta4) .\n- Import a transaction log backup. Here,`stopAt`and`stopAtMark`are optional fields.Before using any of the request data, make the following replacements:- : the project ID.\n- : the instance ID.\n- : the Cloud Storage bucket name.\n- : the path to the BAK file.\n- : the name of a database inside the Cloud SQL instance.\n- : the timestamp at which the transaction log import must stop. This is an  optional field and the value  must use the [RFC 3339 format](https://www.ietf.org/rfc/rfc3339.txt) .\n- : the [ marked transaction](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/use-marked-transactions-to-recover-related-databases-consistently?view=sql-server-ver16) at which the transaction log import must stop. This is an  optional field and can take any string as its value. If the value is in the format`lsn:log-sequence-number`,  then the transaction log import  stops at the given [ log sequence number](https://learn.microsoft.com/en-us/sql/relational-databases/backup-restore/recover-to-a-log-sequence-number-sql-server?view=sql-server-ver16#LSNs) .\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"bakType\": \"TLOG\",\n  \"stopAt\": STOP_AT_TIMESTAMP,\n  \"stopAtMark\":STOP_AT_MARK_NAME,\n  \"noRecovery\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:Repeat this step until all transaction log backups are imported.\n- Optional: Use `recoveryOnly` to bring the imported database online. Perform this step only if your database is in the `RESTORING` state.Before using any of the request data, make the following replacements:- : the project ID\n- : the instance ID\n- : the Cloud Storage bucket name\n- : the path to the BAK file\n- : the name of a database inside the Cloud SQL instance\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_ID/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://BUCKET_NAME/PATH_TO_BAK_FILE\",\n  \"database\": \"DATABASE_NAME\"\n  \"bakImportOptions\": {\n  \"recoveryOnly\": true,\n  }\n }\n}\n```\nTo send your request, choose one of these options:\n **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\ncurl -X POST \\ -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\ -H \"Content-Type: application/json; charset=utf-8\" \\ -d @request.json \\ \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_ID/import\"\n``` **Note:** The following command assumes that you have logged in to  the`gcloud`CLI with your user account by running [gcloud init](/sdk/gcloud/reference/init) or [gcloud auth login](/sdk/gcloud/reference/auth/login) ,  or by using [Cloud Shell](/shell/docs) ,  which automatically logs you into the`gcloud`CLI.  You can check the currently active account by running [gcloud auth list](/sdk/gcloud/reference/auth/list) .\nSave the request body in a file named `request.json` ,  and execute the following command:\n```\n$cred = gcloud auth print-access-token$headers = @{ \"Authorization\" = \"Bearer $cred\" }Invoke-WebRequest ` -Method POST ` -Headers $headers ` -ContentType: \"application/json; charset=utf-8\" ` -InFile request.json ` -Uri \"https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_ID/import\" | Select-Object -Expand Content\n```\nYou should receive a JSON response similar to the following:\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\n### Use striped import\nThe advantages of striped import are the following:\n- Reductions in the time needed for operations to complete\n- Databases larger than 5 TB can be imported\n**Note:** Striped import does not support the import of encrypted columns.\nA potential disadvantage of using striped import is that all of the files in the striped set (rather than a single file) must be uploaded to the same folder in your Cloud Storage bucket, before you perform the import.\nIn most use cases, striped import enables better performance with no disadvantages. However, if you can't back up to a striped set from a given instance, or if your database is less than 5 TB, and if faster performance is not critical, you may want to use a non-striped import.- [ Create a Cloud Storage bucket](/storage/docs/creating-buckets) for the import.```\ngsutil mb -p PROJECT_NAME -l LOCATION_NAME gs://BUCKET_NAME\n```This step isn't required, but strongly recommended, so you don't open up access to any other data.\n- Make sure you have configured the required IAM roles and permissions.\n- [Create](/storage/docs/folders#tool) a new folder in your bucket.\n- To import the database, [ upload](/storage/docs/uploading-objects#uploading-an-object) the files of the striped set (of the database) to the new folder.  Ensure that all the files are uploaded to the folder, and that the folder  contains no extra files.\n- Describe the instance you are exporting from:```\ngcloud sql instances describe INSTANCE_NAME\n```\n- Copy the`serviceAccountEmailAddress`field.\n- Use` [ gsutil iam](/storage/docs/gsutil/commands/iam) `to grant the`storage.objectViewer` [ IAM role](/storage/docs/access-control/iam-roles) to the service account for the bucket. For more information about setting IAM permissions, see [ Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import the data from the folder. The difference from a non-striped import is  the following: The URI links to the name of the folder to which the stripe  set was uploaded, rather than to a single file, and you specify the`--striped`parameter:```\ngcloud beta sql import bak INSTANCE_NAME gs://BUCKET_NAME/FOLDER_NAME \\--database=DATABASE_NAME --striped\n```\n- If you don't need to retain the IAM permissions you set previously, then remove them using` [ gsutil iam](/storage/docs/gsutil/commands/iam) `.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import the data from the file:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the folder (in the Cloud Storage bucket) where the stripe set is located\n- : The name of a database to create in your Cloud SQL instance\n- : Set to`true`to use striped import\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_folder\",\n  \"database\": \"database_name\",\n  \"bakImportOptions\": {\n  \"striped\": true | false\n  }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:To use a different user for the import, specify the `importContext.importUser` property.For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\n- [Create a Cloud Storage bucket.](/storage/docs/creating-buckets) \n- Upload the file to your bucket.For help with uploading files to buckets, see [Uploading objects](/storage/docs/uploading-objects) .\n- Provide your instance with the`storage.objectAdmin` [IAM role](/storage/docs/access-control/iam-roles) for your bucket. For more information about setting IAM permissions, see [Using IAM permissions](/storage/docs/access-control/using-iam-permissions) .\n- Import the data from the file:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\n- : The Cloud Storage bucket name\n- : The path to the folder (in the Cloud Storage bucket) where the stripe set is located\n- : The name of a database to create in your Cloud SQL instance\n- : Set to`true`to use striped import\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id/import\n```\nRequest JSON body:\n```\n{\n \"importContext\":\n {\n  \"fileType\": \"BAK\",\n  \"uri\": \"gs://bucket_name/path_to_folder\",\n  \"database\": \"database_name\",\n  \"bakImportOptions\": {\n  \"striped\": true | false\n  }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:To use a different user for the import, specify the `importContext.importUser` property.For the complete list of parameters for the request, see the [instances:import](/sql/docs/sqlserver/admin-api/rest/v1beta4/instances/import) page.\n- If you don't need to retain the IAM permissions you set previously, then remove the permissions.\nIf you get an error such as `ERROR_RDBMS` , then ensure that the table exists. If the table exists, then confirm that you have the correct permissions on the bucket. For help configuring access control in Cloud Storage, see [Create and Manage Access Control Lists](/storage/docs/access-control/create-manage-lists) .\n## What's next\n- Learn how to [check the status of import and export operations](/sql/docs/sqlserver/import-export/checking-status-import-export) .\n- Learn more about [best practices for importing and exporting data](/sql/docs/sqlserver/import-export) .\n- [Known issues for imports and exports](/sql/docs/sqlserver/known-issues#import-export) .", "guide": "Cloud SQL"}