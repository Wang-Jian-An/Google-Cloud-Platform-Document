{"title": "Cloud SQL - Overcome transaction ID (TXID) wraparound protection", "url": "https://cloud.google.com/sql/docs/postgres/txid-wraparound", "abstract": "# Cloud SQL - Overcome transaction ID (TXID) wraparound protection\nThis page describes what you can do when your database runs into Transaction ID Wraparound protection in PostgreSQL. It manifests as an `ERROR` message, as follows:\n```\ndatabase is not accepting commands to avoid wraparound data loss in databasedbname.Stop the postmaster and vacuum that database in single-user mode.You might also need to commit or roll back old prepared transactions, or dropstale replication slots.\n```\nAlternatively, a `WARNING` message as follows might appear:\n```\ndatabase dbname must be vacuumed within 10985967 transactions.To avoid a database shutdown, execute a database-wide VACUUM in that database.\n```\n**Important:** The error message \"Stop the postmaster and vacuum that database in single-user mode.\" is an outdated error from before PostgreSQL v.8.3 when this was actually true. In most cases, you don't have to switch to single-user mode. Instead, you can run the required `VACUUM` commands and perform tuning for `VACUUM` to run fast.By default, you can't run any data manipulation language (DML), but you can still run `VACUUM` .\n#", "content": "## Flag `cloudsql.enable_maintenance_mode`By default, you can't run any DDL or DML once the database is 'in wraparound' but Cloud SQL for PostgreSQL offers an emergency maintenance mode which gives you 500,000 more transaction IDs to use to get out of the situation without the need to restart the server in single-user mode.To activate maintenance mode, set `cloudsql.enable_maintenance_mode` to `on` in the database session before using any commands requiring a transaction ID.```\nSET cloudsql.enable_maintenance_mode = 'on';\n[ your SQL, DML or DDL commands here ]\n```This needs to be done in the session where you're performing the maintenance before you do anything requiring a transaction ID.\n## Overview of steps\n- Find out which database and which tables are causing the wraparound.\n- Check if there's anything holding back (AUTO)VACUUM (for example, a stuck transaction ID).\n- Measure the speed of AUTOVACUUM. If it is slow, optionally, you can try to speed it up.\n- If needed, run a few more VACUUM commands manually.\n- Investigate other ways to speed up the vacuum. Sometimes the fastest way is to drop the table or some indexes.\nMany of the recommendations for values of flags are purposefully not exact because they depend on many database parameters. Read the documents linked at the end of this page for a deeper analysis on this topic.\n## Find the database and table causing the wraparound\n### Finding the database\nTo find out which database or databases contain the tables that are causing the wraparound, run the following query:\n```\nSELECT datname, \u00a0 \u00a0 \u00a0 \u00a0age(datfrozenxid), \u00a0 \u00a0 \u00a0 \u00a02^31-1000000-age(datfrozenxid) as remaining\u00a0 FROM pg_database\u00a0ORDER BY 3\n```\nThe database with the `remaining` value close to 0 is the one causing the problem.\n### Finding the table\nConnect to that database and run the following query:\n```\nSELECT c.relnamespace::regnamespace as schema_name,\u00a0 \u00a0 \u00a0 \u00a0c.relname as table_name,\u00a0 \u00a0 \u00a0 \u00a0greatest(age(c.relfrozenxid),age(t.relfrozenxid)) as age,\u00a0 \u00a0 \u00a0 \u00a02^31-1000000-greatest(age(c.relfrozenxid),age(t.relfrozenxid)) as remaining\u00a0 FROM pg_class c\u00a0 LEFT JOIN pg_class t ON c.reltoastrelid = t.oid\u00a0WHERE c.relkind IN ('r', 'm')\u00a0ORDER BY 4;\n```\nThis query returns the table or tables causing the problem.\n### For TEMPORARY tables\nIf the `schema_name` starts with `pg_temp_` , then the only way to resolve the problem is to drop the table because PostgreSQL doesn't let you VACUUM temporary tables created in other sessions. Sometimes if that session is open and accessible, you can vacuum the table there, but this is often not the case. Use the following SQL statements to drop the temp table:\n```\nSET cloudsql.enable_maintenance_mode = 'on'; /* get extra transaction ids */DROP TABLE pg_temp_<N>.<tablename>;\n```\nIf this was the only blocker, then in about a minute, the autovacuum picks up this change and moves the `datfrozenxid` forward in `pg_database` . This resolves the wraparound protection read-only state.\n### Normal tables\nFor normal (that is non-temporary) tables, continue with the next steps below here to see if anything is blocking the clean-up, if the VACUUM is running fast enough, and it the most important table is being vacuumed.\n## Check for a stuck transaction ID\nOne possible reason why the system can run out of transaction IDs is that PostgreSQL can't (that is, mark as visible to all transactions) any transaction IDs created after the oldest currently running transaction started. This is because of multiversion concurrency control (MVCC) rules. In extreme cases, such transactions can become so old that they make it impossible for VACUUM to clean up any old transactions for the entire 2 billion transaction ID wraparound limit and cause the whole system to stop accepting new DML. You typically also see warnings in the log file, saying `WARNING: oldest xmin is far in the past` .\nYou should move on to optimization only after the stuck transaction ID has been remediated.\nHere are four potential reasons why there might be a stuck transaction ID, with information on how to mitigate each of them:\n- **Long running transactions:** Identify them and cancel or terminate the  backend to unblock the vacuum.\n- **Orphaned prepare transactions:** Roll back these transactions.\n- **Abandoned replication slots:** Drop the abandoned slots.\n- **Long running transaction on replica, with\n hot_standby_feedback = on:** Identify them and cancel or  terminate the backend to unblock the vacuum.\nFor these scenarios, the following query returns the age of the oldest transaction and the number of transactions left until wraparound:\n```\n\u00a0WITH q AS (SELECT\u00a0 (SELECT max(age(backend_xmin))\u00a0 \u00a0 \u00a0 FROM pg_stat_activity \u00a0WHERE state != 'idle' ) \u00a0 \u00a0 \u00a0 AS oldest_running_xact_age,\u00a0 (SELECT max(age(transaction)) FROM pg_prepared_xacts) \u00a0 \u00a0AS oldest_prepared_xact_age,\u00a0 (SELECT max(greatest(age(catalog_xmin),age(xmin))) FROM pg_replication_slots) \u00a0 \u00a0 \u00a0 \u00a0AS oldest_replication_slot_age,\u00a0 (SELECT max(age(backend_xmin)) FROM pg_stat_replication) AS oldest_replica_xact_age)SELECT *,\u00a0 \u00a0 \u00a0 \u00a02^31 - oldest_running_xact_age AS oldest_running_xact_left,\u00a0 \u00a0 \u00a0 \u00a02^31 - oldest_prepared_xact_age AS oldest_prepared_xact_left,\u00a0 \u00a0 \u00a0 \u00a02^31 - oldest_replication_slot_age AS oldest_replication_slot_left,\u00a0 \u00a0 \u00a0 \u00a02^31 - oldest_replica_xact_age AS oldest_replica_xact_leftFROM q;\n```\nThis query might return any of the values reported close to or less than 1 million away from wraparound. This value is the wraparound protection limit when PostgreSQL stops accepting new write commands. In this case, see either [Remove VACUUM blockers](#how-to-remove) or [Tune VACUUM](#tuning-vacuum-short) .\nFor example, the preceding query might return:\n```\n\u250c\u2500[ RECORD 1 ]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 oldest_running_xact_age \u00a0 \u00a0 \u00a0\u2502 2146483655 \u2502\u2502 oldest_prepared_xact_age \u00a0 \u00a0 \u2502 2146483655 \u2502\u2502 oldest_replication_slot_age \u00a0\u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 oldest_replica_xact_age \u00a0 \u00a0 \u00a0\u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 oldest_running_xact_left \u00a0 \u00a0 \u2502 999993 \u00a0 \u00a0 \u2502\u2502 oldest_prepared_xact_left \u00a0 \u00a0\u2502 999993 \u00a0 \u00a0 \u2502\u2502 oldest_replication_slot_left \u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 oldest_replica_xact_left \u00a0 \u00a0 \u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nwhere `oldest_running_xact_left` and `oldest_prepared_xact_left` are within the 1 million wraparound protection limit. In this case, you must first remove the blockers for the VACUUM to be able to proceed.\n## Remove VACUUM blockers\n### Long-running transactions\nIn the preceding query, if `oldest_running_xact` is equal to `oldest_prepared_xact` , then go to the [Orphaned prepare transaction](#orphaned-prepare) section, because the value includes also the prepared transactions.\nYou might first need to run the following command as the `postgres` user:\n```\nGRANT pg_signal_backend TO postgres;\n```\nIf the offending transaction belongs to any of the system users (starting with `cloudsql...` ), you can't cancel it directly. You must restart the database to cancel it.\nTo identify a long-running query, and cancel or terminate it to unblock the vacuum, first select a few of the oldest queries. The `LIMIT 10` line helps fit the result on the screen. You might need to repeat this after resolving the oldest running queries.\n```\nSELECT pid,\u00a0 \u00a0 \u00a0 \u00a0age(backend_xid) AS age_in_xids,\u00a0 \u00a0 \u00a0 \u00a0now() - xact_start AS xact_age,\u00a0 \u00a0 \u00a0 \u00a0now() - query_start AS query_age,\u00a0 \u00a0 \u00a0 \u00a0state,\u00a0 \u00a0 \u00a0 \u00a0query\u00a0FROM pg_stat_activity\u00a0WHERE state != 'idle'\u00a0ORDER BY 2 DESC\u00a0LIMIT 10;\n```\nIf `age_in_xids` comes back as `NULL` , this means the transaction has not been allocated a permanent transaction ID and can be safely ignored.\nCancel the queries where the `xids_left_to_wraparound` is approaching 1M.\nIf `state` is `active` , then the query can be cancelled using `SELECT pg_cancel_backend(` `` `);` . Otherwise, you need to terminate the whole connection using `SELECT pg_terminate_backend(` `` `);` , where is the `pid` from the previous query\n### Orphaned prepare transactions\n**Note:** To commit a prepared transaction, you must be connected as the same user that originally executed the transaction. See the field `owner` in the following table. is the name of the database in your `pg_stat_progress_vacuum` view.\nList all prepared transactions:\n```\nDB_NAME=> SELECT age(transaction),* FROM pg_prepared_xacts ;\u250c\u2500[ RECORD 1 ]\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 age \u00a0 \u00a0 \u00a0 \u00a0 \u2502 2146483656 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 transaction \u2502 2455493932 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 gid \u00a0 \u00a0 \u00a0 \u00a0 \u2502 trx_id_pin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 prepared \u00a0 \u00a0\u2502 2021-03-03 16:54:07.923158+00 \u2502\u2502 owner \u00a0 \u00a0 \u00a0 \u2502 postgres \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 database \u00a0 \u00a0\u2502 DB_NAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nRoll back the oldest orphaned prepared transaction(s) by using the `gid` from the last query (in this case, `trx_id_pin` ) as the transaction ID:\n```\nROLLBACK PREPARED trx_id_pin;\n```\nAlternatively, commit it:\n```\nCOMMIT PREPARED trx_id_pin;\n```\nSee the [SQL ROLLBACK PREPARED](https://www.postgresql.org/docs/13/sql-rollback-prepared.html) documentation for a full explanation.\n### Abandoned replication slots\nIn case the replication slot is abandoned because the existing replica is either stopped, paused, or has some other issue, you can delete the replica from `gcloud` or Google Cloud console.\nFirst, check that the replica is not disabled as described in [Managing read replicas](/sql/docs/postgres/replication/manage-replicas) . If the replica is disabled, enable it again. If the lag still stays high, delete the replica,\nThe replication slots are visible in the `pg_replication_slots` system view.\nThe following query fetches the relevant info:\n```\nSELECT *, age(xmin) AS age FROM pg_replication_slots;\u250c\u2500[ RECORD 1 ]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 slot_name \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 cloudsql_1_355b114b_9ff4_4bc3_ac88_6a80199bd738 \u2502\u2502 plugin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 slot_type \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 physical \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 datoid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 database \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 active \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 t \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 active_pid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 1126 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 xmin \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 2453745071 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 catalog_xmin \u00a0 \u00a0 \u00a0 \u00a0\u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 restart_lsn \u00a0 \u00a0 \u00a0 \u00a0 \u2502 C0/BEF7C2D0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 confirmed_flush_lsn \u2502 \u00a4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 age \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 59 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nIn this example, the `pg_replication_slots` value is healthy (age == 59). If the age was near 2 billion, you would want to delete the slot. There is no easy way to know which replica is which in case the query returns multiple records. So, check them all in case there is a long-running transaction on any replica.\n### Long-running transactions on replicas\nCheck replicas for the oldest running transaction with `hot_standby_feedback` set to `on` and disable it on the replica.\nThe `backend_xmin` column in the `pg_stat_replication` view has the oldest `TXID` needed on the replica.\nTo move it forward, stop the query that holds it back on the replica. To discover which query is holding it back, use the query in [Long running transactions](#long-running-transaction) , but this time, run it on the replica.\nAnother option is to restart the replica.\n## Configure VACUUM\nSet the following two flags:\n- autovacuum_vacuum_cost_delay = 0\n- autovacuum_work_mem = 1048576\nThe first disables any disk throttling for vacuuming by PostgreSQL so VACUUM can run at full speed. By default, autovacuum is throttled so it does not use up all disk IO on the slowest servers.\nThe second flag, `autovacuum_work_mem` , decreases the number of index cleanup passes. If possible, it should be large enough to store all IDs of dead rows in a table that VACUUM is going to clean up. When setting this value, consider that this is the maximum amount of local memory each running VACUUM can allocate. Make sure that you're not allowing more than is available, with some left in reserve. If you leave the database running in read-only mode, then also consider the local memory used for read-only queries.\nOn most systems, use the maximum value (1 GB or 1048576 kB, as shown in the sample). This value fits up to about 178 million dead tuples. Any more still causes multiple index scan passes.\nThese and other flags are explained in more detail in [Optimizing, monitoring, and troubleshooting VACUUM operations in PostgreSQL](/solutions/optimizing-monitoring-troubleshooting-vacuum-operations-postgresql) .\nAfter setting these flags, restart the database so that autovacuum starts with the new values.\nYou can use the `pg_stat_progress_vacuum` view to monitor the progress of autovacuum-started VACUUMs. This view shows VACUUMs running in all databases, and for tables (relations) from other databases that you can't look up the table name using the view column `relid` .\nTo identify the databases and tables that need vacuuming next, use queries from [Optimizing, monitoring, and troubleshooting VACUUM operations in PostgreSQL](/solutions/optimizing-monitoring-troubleshooting-vacuum-operations-postgresql) . If the server VM is powerful enough and has the bandwidth for more parallel VACUUM processes than started by autovacuum, you can start some manual vacuums.\n## Check VACUUM speed\nThis section describes how to check VACUUM speed and how to accelerate it, if needed.\n### Check running autovacuums\nAll backends running VACUUM are visible in the system view [pg_stat_progress_vacuum](https://www.postgresql.org/docs/11/progress-reporting.html) .\nIf the current phase is `scanning heap` , then you can monitor progress by watching changes in the column `heap_blks_scanned` . Unfortunately, there is no easy way to determine scan speed in other phases.\n### Estimate the VACUUM scan speed\nTo estimate the scan speed, you need to first store the base values and then calculate the change over time to estimate the completion time. First, you need to save a snapshot of `heap_blks_scanned` together with a timestamp by using the following snapshot query:\n```\nSELECT set_config('save.ts', clock_timestamp()::text, false),\u00a0 \u00a0 \u00a0 \u00a0set_config('save.heap_blks_scanned', heap_blks_scanned::text, false)FROM pg_stat_progress_vacuumWHERE datname = 'DB_NAME';\n```\nSince we can't save anything in tables that are already in wraparound, use `set_config(flag, value)` to set two user-defined flags - `save.ts` and `save.heap_blks_scanned` - to the current values from `pg_stat_progress_vacuum` .\nIn the next query, we use these two as the comparison base to determine speed and estimate completion time.\nNOTE: `WHERE datname =` `` restricts the investigation to one database at a time. This number is enough if there is only one autovacuum running in this database, with more than one row per database. Extra filter conditions `('AND relid= \u2026'')` need to be added to WHERE to indicate a single autovacuum row. This is also true for the next query.\nOnce you've saved the base values, you can run the following query:\n```\nwith q as (\u00a0 \u00a0 SELECT datname,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0phase,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0heap_blks_total,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0heap_blks_scanned,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0clock_timestamp() - current_setting('save.ts')::timestamp AS ts_delta,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0heap_blks_scanned - current_setting('save.heap_blks_scanned')::bigint AS scanned_delta\u00a0 \u00a0 \u00a0FROM pg_stat_progress_vacuum\u00a0 \u00a0 \u00a0WHERE datname = DB_NAME), q2 AS (SELECT *,\u00a0 \u00a0 \u00a0 \u00a0scanned_delta / extract('epoch' FROM ts_delta) AS pages_per_second\u00a0 FROM q)SELECT *,\u00a0 \u00a0 \u00a0 \u00a0(heap_blks_total - heap_blks_scanned) / pages_per_second AS remaining_time\u00a0 FROM q2;\n```\n```\n\u250c\u2500[ RECORD 1 ]\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 datname \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 DB_NAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 phase \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 scanning heap \u00a0 \u00a0\u2502\u2502 heap_blks_total \u00a0 \u2502 9497174 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 heap_blks_scanned \u2502 18016 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 ts_delta \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 00:00:40.30126 \u00a0 \u2502\u2502 as_scanned_delta \u00a0\u2502 11642 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 pages_per_second \u00a0\u2502 288.87434288655 \u00a0\u2502\u2502 remaining_time \u00a0 \u00a0\u2502 32814.1222418038 \u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nThis query compares the current values to the save base values and calculates `pages_per_second` and `remaining_time` , which lets us decide if VACUUM is running fast enough or if we want to speed it up. The `remaining_time` value is only for the `scanning heap` phase. Other phases also take time, sometimes even more. You can [read more on vacuuming](https://www.postgresql.org/docs/13/sql-vacuum.html) and view blog posts on the internet discussing some of the complex aspects of vacuum.\n## Speed up VACUUM\nThe easiest and fastest way to make VACUUM scan faster is setting `autovacuum_vacuum_cost_delay=0` . This can be done from the Google Cloud console.\nUnfortunately, the already running VACUUM does not pick up this value and you might need to restart the database.\nAfter a restart, you might see a result similar to the following:\n```\n\u250c\u2500[ RECORD 1 ]\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502 datname \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 DB_NAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 phase \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502 scanning heap \u00a0 \u00a0\u2502\u2502 heap_blks_total \u00a0 \u2502 9497174 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502\u2502 heap_blks_scanned \u2502 222382 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 ts_delta \u00a0 \u00a0 \u00a0 \u00a0 \u00a0\u2502 00:00:21.422615 \u00a0\u2502\u2502 as_scanned_delta \u00a0\u2502 138235 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u2502\u2502 pages_per_second \u00a0\u2502 6452.76031894332 \u2502\u2502 remaining_time \u00a0 \u00a0\u2502 1437.33713040171 \u2502\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\nIn this sample, the speed increased from <300 pages/sec to ~6500 pages/sec, and the expected remaining time for the heap scanning phase decreased from 9 hours to 23 minutes.\nThe scan speed of the other phases is not as easy to measure, but they should show a similar speedup.\nAlso consider making `autovacuum_work_mem` as large as possible to avoid multiple passes over indexes. An index pass happens each time the memory is filled with dead tuple pointers.\nIf the database is not being used otherwise, set `autovacuum_work_mem` to have ~80% of memory free after allowing the required amount for `shared_buffers` . This is the upper limit for each of the autovacuum-started VACUUM processes. If you want to continue running read-only workloads, use less memory.\n## Other ways to improve speed\n### Avoid vacuuming indexes\nFor huge tables, VACUUM spends most of the time cleaning up indexes.\nPostgreSQL 14 has special optimizations for avoiding index cleanup if the system is in danger of wraparound.\nIn PostgreSQL 12 and 13, you can manually run the following statement:\n```\nVACUUM (INDEX_CLEANUP OFF, TRUNCATE OFF) <tablename>;\n```\nIn versions 11 and older, you can `DROP` the index before running vacuum and recreate it later.\nDropping the index when an autovacuum is already running on that table requires cancelling the running vacuum and then immediately executing the drop index command before the autovacuum manages to start vacuum on that table again.\nFirst, run the following statement to find the PID of the autovacuum process you need to terminate:\n```\nSELECT pid, query \u00a0 FROM pg_stat_activity\u00a0WHERE state != 'idle'\u00a0 \u00a0AND query ilike '%vacuum%';\n```\nThen run the following statements to terminate the running vacuum and drop one or more indexes:\n```\nSET cloudsql.enable_maintenance_mode = 'on'; /* get extra transaction ids */SELECT pg_terminate_backend(<pid>);DROP INDEX <index1>;DROP INDEX <index2>; ...\n```\n### Drop the offending table\nIn some rare cases, you can drop the table. For example, if it's a table that's easy to restore from another source like a backup or other database.\nYou still need to use `cloudsql.enable_maintenance_mode = 'on'` and likely also terminate the VACUUM on that table as shown in the previous section.\n### VACUUM FULL\nIn rare cases, it's faster to run `VACUUM FULL FREEZE` , usually when the table has only a small proportion of live tuples. This can be checked from the `pg_stat_user_tables` view (unless there has been a crash which has wiped out the statistics).\nThe `VACUUM FULL` command copies live tuples to a new file, so enough space has to be available for the new file and its indexes.\n## What's next\n- Learn more about [VACUUM for wraparound](https://www.postgresql.org/docs/current/routine-vacuuming.html#VACUUM-FOR-WRAPAROUND) \n- Learn more about [routine vacuuming](https://www.postgresql.org/docs/current/routine-vacuuming.html) .\n- Learn more about [automatic vacuuming](https://www.postgresql.org/docs/current/runtime-config-autovacuum.html) \n- Learn more about [Optimizing, monitoring, and troubleshooting VACUUM operations in PostgreSQL](https://cloud.google.com/solutions/optimizing-monitoring-troubleshooting-vacuum-operations-postgresql)", "guide": "Cloud SQL"}