{"title": "Cloud SQL - Use point-in-time recovery (PITR)", "url": "https://cloud.google.com/sql/docs/postgres/backup-recovery/pitr", "abstract": "# Cloud SQL - Use point-in-time recovery (PITR)\nThis page describes how to use point-in-time recovery (PITR) to restore your primary Cloud SQL instance.\nTo learn more about PITR, see [PITR](/sql/docs/postgres/backup-recovery/restore#tips-pitr) .\n**Note:** This page contains features related to Cloud SQL editions. For more information about Cloud SQL editions, see [Introduction to Cloud SQL editions](/sql/docs/postgres/editions-intro) .\nBy default, PITR is enabled for Cloud SQL Enterprise Plus edition instances.\nIf you create a Cloud SQL Enterprise edition instance in Google Cloud console, then PITR is enabled by default. Otherwise, you must manually enable PITR.\n", "content": "## Log storage for PITR\n[write-ahead logging (WAL)](https://www.postgresql.org/docs/current/wal-intro.html)\nOn January 9, 2023, we launched storing write-ahead logs for PITR in [Cloud Storage](/storage/docs) . Since this launch, the following conditions apply:\n- All Cloud SQL Enterprise Plus edition instances store their write-ahead logs in Cloud Storage. Only Cloud SQL Enterprise Plus edition instances that you upgrade from Cloud SQL Enterprise edition and had PITR enabled before January 9, 2023 continue to store their logs.\n- Cloud SQL Enterprise edition instances created with PITR enabled before January 9, 2023 continue to store their logs.\n- All Cloud SQL Enterprise edition instances that you create with PITR enabled after January 9, 2023 store logs in Cloud Storage.\nFor instances that store write-ahead logs only on disk, you can move the logs from disk to Cloud Storage by first deactivating and then re-enabling PITR.\n**Caution:** Moving write-ahead logs from disk to Cloud Storage results in both a few minutes of downtime and a loss of previous logs for PITR. The downtime is because the instances must be restarted, and the logs are cleared when you deactivate PITR.\n### Log retention period\nTo see whether an instance's logs are stored in Cloud Storage, check the [bytes_used_by_data_type](/sql/docs/postgres/admin-api/metrics) metric for the instance. If the value for the `archived_wal_log` data type is `0` , then the instance's logs are stored in Cloud Storage.\nAfter you use a PostgreSQL client such as ` [psql](https://www.postgresql.org/docs/current/app-psql.html) ` or ` [pgAdmin](https://www.pgadmin.org/) ` to connect to a database of the instance, run the following command: `show archive_command` . If any write-ahead logs are archived in Cloud Storage, then you see `-async_archive -remote_storage` .\nAll other existing instances that have PITR enabled continue to have their logs stored on disk. The change to storing logs in Cloud Storage is available at a later time.\nIf the logs are stored in Cloud Storage, then Cloud SQL uploads logs every five minutes or less. As a result, if a Cloud SQL instance is available, then the instance can be recovered to the latest time. However, if [the instance isn't available](/sql/docs/postgres/backup-recovery/restore#pitr-instance-not-available) , then the [recovery point objective](/sql/docs/postgres/backup-recovery/restore#pitr-instance-not-available) is typically five minutes or less. Use the [gcloud CLI](/sdk/gcloud) or Admin API to [check for the latest time](#get-the-latest-recovery-time) to which you can restore the instance, and perform the recovery to that time.\nThe write-ahead logs used with PITR are deleted automatically with their associated automatic backup, which generally happens after the value set for [transactionLogRetentionDays](/sql/docs/postgres/admin-api/rest/v1/instances) is met. This is the number of days of transaction logs that Cloud SQL retains for PITR. For Cloud SQL Enterprise Plus edition, the number of days of retained transaction logs can be set from 1 to 35, and for Cloud SQL Enterprise edition, the value can be set from 1 to 7.\nWhen you restore a backup on a Cloud SQL instance before enabling PITR, you lose the write-ahead logs that allow the operability of PITR.\nFor [customer-managed encryption key (CMEK)-enabled instances](/sql/docs/postgres/configure-cmek) , write-ahead logs are encrypted using the latest version of the CMEK. To perform a restore, all versions of the key that were the latest for the number of days that you configured for the [retained-transaction-log-days](#enablingpitr) parameter should be available.\nFor instances having write-ahead logs stored in Cloud Storage, the logs are stored in the same region as the primary instance. This log storage (up to 35 days for Cloud SQL Enterprise Plus edition and seven days for Cloud SQL Enterprise edition, the maximum length for PITR) generates no additional cost per instance.\n### Logs and disk usage\nIf your instance has PITR enabled, and if the size of your write-ahead logs on disk is causing an issue for your instance:\n- You can disable PITR and re-enable it to ensure that new logs are stored in Cloud Storage in the same region as the instance. However, any existing write-ahead logs are deleted, so you can't perform a point-in-time restore earlier than the time that you re-enabled PITR.\n- You can increase the instance storage size. However, the write-ahead log size increase in disk usage might be temporary.\n- We recommend enabling [automatic storage increase](/sql/docs/postgres/instance-settings#automatic-storage-increase-2ndgen) to avoid unexpected storage issues. This recommendation applies only if your instance has PITR enabled and your logs are stored on disk.\n- You can disable PITR if you want to delete logs and recover storage. Decreasing the write-ahead logs used doesn't shrink the size of the disk provisioned for the instance.\n- Logs are purged once daily, not continuously. Setting log retention to two days means that at least two days of logs, and at most three days of logs, are retained. We recommend setting the number of backups to one more than the days of log retention to guarantee a minimum of specified days of log retention.## Enable PITR\n**Automated\nbackups**\n**Enable point-in-time recovery**\nThe following procedure enables PITR on an primary instance.\n- In the Google Cloud console, go to the **Cloud SQL Instances** page. [Go to Cloud SQL Instances](https://console.cloud.google.com/sql) \n- Open the more actions menufor the instance you  want to enable PITR on and click **Edit** .\n- Under **Customize your instance** , expand the **Data Protection** section.\n- Select the **Enable point-in-time recovery** checkbox.\n- Expand **Advanced options** .\n- Enter the number of days to retain logs, from 1-35 for Cloud SQL Enterprise Plus edition, or  1-7 for Cloud SQL Enterprise edition.\n- Click **Save** .\n- Display the instance overview:```\ngcloud sql instances describe INSTANCE_NAME\n```\n- If you see`enabled: false`in the`backupConfiguration`section, enable scheduled backups:```\ngcloud sql instances patch INSTANCE_NAME \\--backup-start-time=HH:MM\n```Specify the `backup-start-time` parameter using 24-hour   time in UTC\u00b100 time zone.\n- Enable PITR:```\ngcloud sql instances patch INSTANCE_NAME \\--enable-point-in-time-recovery\n```If you're enabling PITR on a primary instance, you can also configure the number of days for which you want to retain transaction logs by adding the following parameter:```\n--retained-transaction-log-days=RETAINED_TRANSACTION_LOG_DAYS\n```\n- Confirm your change:```\ngcloud sql instances describe INSTANCE_NAME\n```In the `backupConfiguration` section, you see `pointInTimeRecoveryEnabled: true` if the change was successful.\nTo enable PITR, use a [Terraform resource](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/sql_database_instance) .\n [  cloud_sql/postgres_instance_pitr/main.tf ](https://github.com/terraform-google-modules/terraform-docs-samples/blob/main/cloud_sql/postgres_instance_pitr/main.tf) [View on GitHub](https://github.com/terraform-google-modules/terraform-docs-samples/blob/main/cloud_sql/postgres_instance_pitr/main.tf) \n```\nresource \"google_sql_database_instance\" \"postgres_instance_pitr\" {\n name    = \"\"\n region   = \"us-central1\"\n database_version = \"POSTGRES_14\"\n settings {\n tier = \"db-custom-2-7680\"\n backup_configuration {\n  enabled      = true\n  point_in_time_recovery_enabled = true\n  start_time      = \"20:55\"\n  transaction_log_retention_days = \"3\"\n }\n }\n # set `deletion_protection` to true, will ensure that one cannot accidentally delete this instance by\n # use of Terraform whereas `deletion_protection_enabled` flag protects this instance at the GCP level.\n deletion_protection = false\n}\n```To apply your Terraform configuration in a Google Cloud project, complete the steps in the following sections.## Prepare Cloud Shell\n- Launch [Cloud Shell](https://shell.cloud.google.com/) .\n- Set the default Google Cloud project  where you want to apply your Terraform configurations.You only need to run this command once per project, and you can run it in any directory.```\nexport GOOGLE_CLOUD_PROJECT=PROJECT_ID\n```Environment variables are overridden if you set explicit values in the Terraform  configuration file.\n## Prepare the directoryEach Terraform configuration file must have its own directory (also called a ).- In [Cloud Shell](https://shell.cloud.google.com/) , create a directory and a new  file within that directory. The filename must have the`.tf`extension\u2014for example`main.tf`. In this  tutorial, the file is referred to as`main.tf`.```\nmkdir DIRECTORY && cd DIRECTORY && touch main.tf\n```\n- If you are following a tutorial, you can copy the sample code in each section or step.Copy the sample code into the newly created `main.tf` .Optionally, copy the code from GitHub. This is recommended  when the Terraform snippet is part of an end-to-end solution.\n- Review and modify the sample parameters to apply to your environment.\n- Save your changes.\n- Initialize Terraform. You only need to do this once per directory.```\nterraform init\n```Optionally, to use the latest Google provider version, include the `-upgrade` option:```\nterraform init -upgrade\n```\n## Apply the changes\n- Review the configuration and verify that the resources that Terraform is going to create or  update match your expectations:```\nterraform plan\n```Make corrections to the configuration as necessary.\n- Apply the Terraform configuration by running the following command and entering`yes`at the prompt:```\nterraform apply\n```Wait until Terraform displays the \"Apply complete!\" message.\n- [Open your Google Cloud project](https://console.cloud.google.com/) to view  the results. In the Google Cloud console, navigate to your resources in the UI to make sure  that Terraform has created or updated them.\n **Note:** Terraform samples typically assume that the required APIs are enabled in your Google Cloud project.To delete your changes, do the following:- To disable deletion protection, in your Terraform configuration file set the`deletion_protection`argument to`false`.```\ndeletion_protection = \"false\"\n```\n- Apply the updated Terraform configuration by running the following command and    entering`yes`at the prompt:```\nterraform apply\n```\n- Remove resources previously applied with your Terraform configuration by running the following command and entering `yes` at the prompt:```\nterraform destroy\n```\nBefore using any of the request data, make the following replacements:- : the ID or [project number](/resource-manager/docs/creating-managing-projects#identifying_projects) of the Google Cloud project that contains the instance\n- : the name of the primary or read replica instance that you're configuring for high availability\n- : the time (in hours and minutes)\nHTTP method and URL:\n```\nPATCH https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_NAME\n```\nRequest JSON body:\n```\n{\n \"settings\":\n {\n \"backupConfiguration\":\n {\n  \"startTime\": \"START_TIME\",\n  \"enabled\": true,\n  \"pointInTimeRecoveryEnabled\": true\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:Before using any of the request data, make the following replacements:- : the ID or [project number](/resource-manager/docs/creating-managing-projects#identifying_projects) of the Google Cloud project that contains the instance\n- : the name of the primary or read replica instance that you're configuring for high availability\n- : the time (in hours and minutes)\nHTTP method and URL:\n```\nPATCH https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_NAME\n```\nRequest JSON body:\n```\n{\n \"settings\":\n {\n \"backupConfiguration\":\n {\n  \"startTime\": \"START_TIME\",\n  \"enabled\": true,\n  \"pointInTimeRecoveryEnabled\": true\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n## Get the latest recovery time\nFor an available instance, you can perform PITR to the latest time. If the instance is unavailable and the instance logs are stored in [Cloud Storage](/storage/docs) , then you can retrieve the latest recovery time and perform the PITR to that time. In both cases, you can [restore the instance to a different zone](/sql/docs/postgres/clone-instance#clone-unavailable-instance) by providing a value for the preferred zone.\nGet the latest time to which you can recover a Cloud SQL instance that's not available.\nReplace with the name of the instance that you're querying.\n```\ngcloud sql instances get-latest-recovery-time INSTANCE_NAME\n```Before using any of the request data, make the following replacements:- : the project ID\n- : the name of the instance for which you're querying for the latest recovery time\nHTTP method and URL:\n```\nGET https://sqladmin.googleapis.com/v1/projects/PROJECT_ID/instances/INSTANCE_NAME/getLatestRecoveryTime\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"kind\": \"sql#getLatestRecoveryTime\",\n \"latestRecoveryTime\": \"2023-06-20T17:23:59.648821586Z\"\n}\n```\nBefore using any of the request data, make the following replacements:- : the project ID\n- : the name of the instance for which you're querying for the latest recovery time\nHTTP method and URL:\n```\nGET https://sqladmin.googleapis.com/sql/v1beta4/projects/PROJECT_ID/instances/INSTANCE_NAME/getLatestRecoveryTime\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n```\n{\n \"kind\": \"sql#getLatestRecoveryTime\",\n \"latestRecoveryTime\": \"2023-06-20T17:23:59.648821586Z\"\n}\n```\n## Perform PITR- In the Google Cloud console, go to the **Cloud SQL Instances** page. [Go to Cloud SQL Instances](https://console.cloud.google.com/sql) \n- Open the more actions menufor the instance you  want to recover and click **Create clone** .\n- Optionally, on the **Create a clone** page, update the ID of the  new clone.\n- Select **Clone from an earlier point in time** .\n- Enter a PITR time.\n- Click **Create clone** .\nCreate a clone using PITR.\nReplace the following:- - Name of the instance you're   restoring from.\n- - Name for the clone.\n- - UTC timezone for the source instance in RFC   3339 format. For example, 2012-11-15T16:19:00.094Z.\n```\ngcloud sql instances clone SOURCE_INSTANCE_NAME \\NEW_INSTANCE_NAME \\--point-in-time 'TIMESTAMP'\n```Before using any of the request data, make the following replacements:- : The project ID\n- : The target instance ID\n- : The source instance ID\n- The point-in-time to restore up to\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/v1/projects/project-id/instances/source-instance-id/clone\n```\nRequest JSON body:\n```\n{\n \"cloneContext\":\n {\n \"kind\": \"sql#cloneContext\",\n \"destinationInstanceName\": \"target-instance-id\",\n \"pointInTime\": \"restore-timestamp\"\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:Before using any of the request data, make the following replacements:- : The project ID\n- : The target instance ID\n- : The source instance ID\n- The point-in-time to restore up to\nHTTP method and URL:\n```\nPOST https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/source-instance-id/clone\n```\nRequest JSON body:\n```\n{\n \"cloneContext\":\n {\n \"kind\": \"sql#cloneContext\",\n \"destinationInstanceName\": \"target-instance-id\",\n \"pointInTime\": \"restore-timestamp\"\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n## Disable point-in-time recovery\n- In the Google Cloud console, go to the **Cloud SQL Instances** page. [Go to Cloud SQL Instances](https://console.cloud.google.com/sql) \n- Open the more actions menufor the instance you  want to disable and select **Edit** .\n- Under **Customize your instance** , expand the **Data Protection** section.\n- Clear **Enable point-in-time recovery** .\n- Click **Save** .\n- In the **Overview** page for the instance, under **Configuration** , the PITR setting is listed as  disabled.\n- Disable point-in-time recovery:```\ngcloud sql instances patch INSTANCE_NAME \\--no-enable-point-in-time-recovery\n```\n- Confirm your change:```\ngcloud sql instances describe INSTANCE_NAME\n```In the `backupConfiguration` section, you see `pointInTimeRecoveryEnabled: false` if the change was successful.\nBefore using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\nHTTP method and URL:\n```\nPATCH https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id\n```\nRequest JSON body:\n```\n{\n \"settings\":\n {\n \"backupConfiguration\":\n {\n  \"enabled\": false,\n  \"pointInTimeRecoveryEnabled\": false\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:Before using any of the request data, make the following replacements:- : The project ID\n- : The instance ID\nHTTP method and URL:\n```\nPATCH https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id\n```\nRequest JSON body:\n```\n{\n \"settings\":\n {\n \"backupConfiguration\":\n {\n  \"enabled\": false,\n  \"pointInTimeRecoveryEnabled\": false\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n## Set transaction log retention\nTo set the number of days to retain write-ahead logs:\n- In the Google Cloud console, go to the **Cloud SQL Instances** page. [Go to Cloud SQL Instances](https://console.cloud.google.com/sql) \n- Open the more actions menufor the instance you  want to set the transaction log on and select **Edit** .\n- Under **Customize your instance** , expand the **Data Protection** section.\n- In the **Enable point-in-time recovery** section, expand **Advanced options** .\n- Enter the number of days to retain logs, from 1-35 for Cloud SQL Enterprise Plus edition or  1-7 for Cloud SQL Enterprise edition.\n- Click **Save** .\nEdit the instance to set the number of days to retain  write-ahead logs.\nReplace the following:- - The name of the instance you want to    set the transaction log on.\n- - The number of days of transaction logs    to keep. The valid range is between 1 and 35 (default: 15) for Cloud SQL Enterprise Plus edition and    between 1 and 7 (default: 7) for Cloud SQL Enterprise edition. The default value is used    if not specified. Only valid when point in time recovery is enabled.    Keeping more days of transaction logs requires bigger storage    size.```\n\u00a0 gcloud sql instances patch INSTANCE-NAME \\\u00a0 \u00a0 --retained-transaction-log-days=DAYS-TO-RETAIN\u00a0 \n```\nBefore using any of the request data, make the following replacements:- : The number of days to retain transaction logs, from 1 to 7\n- : The project ID\n- : The instance ID\nHTTP method and URL:\n```\nPATCH https://sqladmin.googleapis.com/v1/projects/project-id/instances/instance-id\n```\nRequest JSON body:\n```\n{\n \"settings\":\n {\n \"backupConfiguration\":\n {\n  \"transactionLogRetentionDays\": \"days-to-retain\"\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\nBefore using any of the request data, make the following replacements:- : The number of days to retain transaction logs, from 1 to 7\n- : The project ID\n- : The instance ID\nHTTP method and URL:\n```\nPATCH https://sqladmin.googleapis.com/sql/v1beta4/projects/project-id/instances/instance-id\n```\nRequest JSON body:\n```\n{\n \"settings\":\n {\n \"backupConfiguration\":\n {\n  \"transactionLogRetentionDays\": \"days-to-retain\"\n }\n }\n}\n```\nTo send your request, expand one of these options:You should receive a JSON response similar to the following:\n## What's next\n- [Configure flags](/sql/docs/postgres/flags) on your clone", "guide": "Cloud SQL"}