{"title": "Google Kubernetes Engine (GKE) - Creating a cluster using Windows Server node pools", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster-windows", "abstract": "# Google Kubernetes Engine (GKE) - Creating a cluster using Windows Server node pools\nIn this page, you learn how to create a Google Kubernetes Engine (GKE) cluster with [node pools](/kubernetes-engine/docs/concepts/node-pools) running Microsoft Windows Server. With this cluster, you can use Windows Server containers. Microsoft Hyper-V containers are not currently supported. Similar to Linux containers, Windows Server containers provide process and namespace isolation.\nA Windows Server node requires more resources than a typical Linux node. Windows Server nodes need the extra resources to run the Windows OS and for the Windows Server components that cannot run in containers. Since Windows Server nodes require more resources, your [allocatable resources](/kubernetes-engine/docs/concepts/cluster-architecture#node_allocatable) are lower than they would be with Linux nodes.\n", "content": "## Creating a cluster using Windows Server node pools\nIn this section, you create a cluster that uses a Windows Server container.\nTo create this cluster you need to complete the following tasks:\n- [Choose your Windows Server node image](#choose_your_windows_server_node_image) .\n- [Update and configure gcloud](#update_and_configure_gcloud) .\n- [Create a cluster and node pools](#create_a_cluster_and_node_pools) .\n- [Get kubectl credentials](#get_kubectl_credentials) .\n- [Wait for cluster initialization](#wait_for_cluster_initialization) .\n**Note:** The `gcloud` commands for these tasks assume you are using a Linux machine.\n### Choose your Windows Server node image\n**Warning:** Windows Server Semi-Annual Channel (SAC) images aren't supported after August 9, 2022 because Microsoft is removing support for the SAC. For potential impact and migration instructions, refer to [Windows Server Semi-Annual Channel end of servicing](/kubernetes-engine/docs/deprecations/windows-server-sac) .\nTo run on GKE, Windows Server container node images need to be built on Windows Server version 2019 (LTSC), Windows Server version 20H2 (SAC), or Windows Server version 2022 (LTSC). A single cluster can have multiple Windows Server node pools using different Windows Server versions, but each individual node pool can only use one Windows Server version.\nConsider the following when choosing your node image:\n- **Support timing** :- The support timing for a Windows Server node image is subject to the support timing provided by Microsoft, as described in [Support policy for OS images](/compute/docs/images#lifecycle_policy) . You can find the support end date for GKE Windows node images by using the`gcloud container get-server-config`command as described in the [Mapping GKE and Windows versions](#version_mapping) section.\n- SAC versions are only supported by Microsoft for 18 months after their initial release. **If you choose SAC for the image type for your node pool,\nbut do not upgrade your node pool to newer GKE versions\nthat target newer SAC versions, you cannot create new nodes in your node\npool when the support lifecycle for the SAC version ends** . Learn more about Google's support for the [Windows Server operating system](/compute/docs/images/os-details#support-windows-server) . We recommend using LTSC because of its longer support lifecycle.\n- Do not choose SAC if you enroll your GKE cluster in the [stable release channel](/kubernetes-engine/docs/concepts/release-channels#channels) . Since SAC versions are only supported by Microsoft for 18 months, there is a risk of the SAC node pool image becoming unsupported while the stable GKE version is still available.\n- **Version compatibility and complexity** :- Only choose SAC if you can [upgrade your node pool](#upgrading_windows_server_node_pools) and the containers running in it regularly. GKE periodically updates the SAC version used for Windows node pools in new GKE releases, so choosing SAC for your node pool image type requires you to rebuild your containers more often.\n- **If you are unsure of which Windows Server image type to use, we\nrecommend choosing Windows Server LTSC** to avoid version incompatibility problems when upgrading your node pool. For additional information, see [Windows Server servicing channels: LTSC and SAC](https://docs.microsoft.com/en-us/windows-server/get-started/servicing-channels-comparison) in Microsoft's documentation.\n- Both [Windows Server Core](https://hub.docker.com/_/microsoft-windows-servercore) and [Nano Server](https://hub.docker.com/_/microsoft-windows-nanoserver) can be used as a base image for your containers.\n- Windows Server containers have important version compatibility requirements:- Windows Server containers built for LTSC do not run on SAC nodes, and vice-versa.\n- Windows Server containers built for a specific LTSC or SAC version do not run on other LTSC or SAC versions without being rebuilt to target the other version.\n- Building your Windows Server container images as [multi-arch images](#building_multi-arch_images) that can target multiple Windows Server versions can help you manage this versioning complexity.\n- **New features** :- New Windows Server features are typically introduced into SAC versions first. Because of this, new GKE Windows functionality might be introduced in SAC node pools first.\n- Consider SAC if you depend on features not yet available in the LTSC release.\n- **Container runtime** :- For both the Windows Server LTSC and SAC node images, the container runtime can be Docker or containerd. For GKE node version 1.21.1-gke.2200 and later, we recommend using the containerd runtime. For more information, see [Node images](/kubernetes-engine/docs/concepts/node-images) . **Warning: ** In GKE version 1.24 and later, Docker-based node image types are not supported. In GKE version 1.23, you also cannot create new node pools with Docker node image types. You must migrate to a containerd node image type. To learn more about this change, see [About the Docker node image deprecation](/kubernetes-engine/docs/deprecations/docker-containerd) .\n### Update and configure gcloud\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n- Ensure you have the correct permission to create clusters. At minimum, you should be a [Kubernetes Engine Cluster Admin](/iam/docs/understanding-roles#kubernetes-engine-roles) .\n### Create a cluster and node pools\nTo run Windows Server containers, your cluster must have at least one Windows and one Linux node pool. **You cannot create a cluster using only a WindowsServer node pool.** The Linux node pool is required to run critical cluster add- ons.\nBecause of its importance, we recommend turning on autoscaling to ensure your Linux node pool has sufficient capacity to run cluster add-ons.\n**Note:** Clusters using Windows Server node pools do not support all Kubernetes and GKE features. See the [limitations section](#limitations) for more information.\nCreate a cluster with the following fields:\n```\ngcloud container clusters create CLUSTER_NAME \\\u00a0 \u00a0 --enable-ip-alias \\\u00a0 \u00a0 --num-nodes=NUMBER_OF_NODES \\\u00a0 \u00a0 --cluster-version=VERSION_NUMBER \\\u00a0 \u00a0 --release-channel CHANNEL\n```\nReplace the following:- ``: the name you choose for your cluster.\n- `--enable-ip-alias`turns on [alias IP](/vpc/docs/alias-ip) . Alias IP is required for Windows Server nodes. To read more about its benefits, see [Understanding native container routing with Alias IPs](/blog/products/networking/understanding-native-container-routing-with-alias-ips) .\n- ``: the number of Linux nodes you create. You should provide sufficient compute resources to run cluster add-ons. This is an optional field and if omitted, uses the default value of`3`.\n- ``: the specific cluster version you want to use, which must be 1.16.8-gke.9 or higher. If you do not specify a release channel, GKE enrolls your cluster in the most mature release channel where that version is available.\n- ``: the [release channel](/kubernetes-engine/docs/concepts/release-channels) to enroll the cluster in, which can be one of`rapid`,`regular`,`stable`, or`None`. By default, the cluster is enrolled in the`regular`release channel unless at least one of the following flags is specified:`--cluster-version`,`--release-channel`,`--no-enable-autoupgrade`, and`--no-enable-autorepair`. You must specify`None`if you choose a cluster version and do not want your cluster to be enrolled in a release channel.\nCreate the Windows Server node pool with the following fields:\n```\ngcloud container node-pools create NODE_POOL_NAME \\\u00a0 \u00a0 --cluster=CLUSTER_NAME \\\u00a0 \u00a0 --image-type=IMAGE_NAME \\\u00a0 \u00a0 --no-enable-autoupgrade \\\u00a0 \u00a0 --machine-type=MACHINE_TYPE_NAME \\\u00a0 \u00a0 --windows-os-version=WINDOWS_OS_VERSION\n```\nReplace the following:- ``: the name you choose for your Windows Server node pool.\n- ``: the name of the cluster you created above.\n- `` : You can specify one of the following values:- `WINDOWS_LTSC_CONTAINERD`: Windows Server LTSC with containerd. This is the image type for both Windows Server 2022 and Windows Server 2019 OS image\n- `WINDOWS_SAC_CONTAINERD`: Windows Server SAC with containerd [(Unsupported after August 9, 2022)](/kubernetes-engine/docs/deprecations/windows-server-sac) \n- `WINDOWS_LTSC`: Windows Server LTSC with Docker\n- `WINDOWS_SAC`: Windows Server SAC with Docker [(Unsupported after August 9, 2022)](/kubernetes-engine/docs/deprecations/windows-server-sac) \n **Warning:** In GKE version 1.24 and later, images with the Docker runtime are unsupported. Migrate to images with the containerd runtime before you upgrade to GKE 1.24. To learn more about this change, see [Migrating from Docker to containerd](/kubernetes-engine/docs/deprecations/docker-containerd) .For more information about these node images, see the [Choose your Windows node image](#choose_your_windows_server_node_image) section.\n- `--no-enable-autoupgrade` disables [node auto-upgrade](/kubernetes-engine/docs/how-to/node-auto-upgrades) . Review [Upgrading Windows Server node pools](#upgrading_windows_server_node_pools) before enabling.\n- `` : defines the machine type. `n1-standard-2` is the minimum recommended machine type as Windows Server nodes require additional resources. Machine types `f1-micro` and `g1-small` are not supported. Each machine type is billed differently. For more information, refer to the [machine type price sheet](/compute/pricing#standard_machine_types) .\n- `` : defines the Windows OS version to use for image type `WINDOWS_LTSC_CONTAINERD` . This is an optional flag. When not specified, the default OS version used will be LTSC2019. Set the value to `ltsc2022` to create a Windows Server 2022 node pool. Set the value to `ltsc2019` to create a Windows Server 2019 node pool.\n **Note:** The Windows Server 2022 node image and Windows Server 2019 node image share the same image type `WINDOWS_LTSC_CONTAINERD` . The default LTSC image that GKE uses to create Windows_LTSC_Containerd node pools through the Google Cloud console or CLI is `ltsc2019` . Creation of Windows Server 2022 node images are only supported for GKE version `1.25.3-gke.800` or later. If you want your clusters to consume Windows Server 2022 node pools, make sure to upgrade your clusters to the supported GKE versions.\nThe following example shows how you can create a Windows Server 2022 node pool:\n```\ngcloud container node-pools create node_pool_name \\\u00a0 \u00a0 --cluster=cluster_name \\\u00a0 \u00a0 --image-type=WINDOWS_LTSC_CONTAINERD \\\u00a0 \u00a0 --windows-os-version=ltsc2022\n```\nThe following example shows how you can update an existing Windows node pool to use Windows Server 2022 OS image:\n```\ngcloud container node-pools create node_pool_name \\\u00a0 \u00a0 --cluster=cluster_name \\\u00a0 \u00a0 --windows-os-version=ltsc2022\n```- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Click **Create** .\n- In the **Cluster basics** section, complete the following:- Enter the **Name** for your cluster.\n- For the **Location type** , select the desired [region or zone](/compute/docs/regions-zones#available) for your cluster.\n- Under **Control plane Version** , select a **Release channel** or choose to specify a **Static version** . The static version must be 1.16.8-gke.9 or higher.\n- From the navigation pane, under **Node Pools** , click **default-pool** to create your Linux node pool. When configuring this node pool, you should provide sufficient compute resources to run cluster add-ons. You must also have available [resource quota](/compute/quotas) for the nodes and their resources (such as firewall routes).\n- At the top of the page, click **AddNode Pool** to create your Windows Server node pool.\n- In the **Node pool details** section, complete the following:- Enter a **Name** for the [node pool](/kubernetes-engine/docs/concepts/node-pools) .\n- For static version nodes, choose the **Node version** .\n- Enter the **Number of nodes** to create in the node pool.\n- From the navigation pane, under **Node Pools** , click **Nodes** .- From the **Image type** drop-down list, select one of the following node images:- Windows Long Term Servicing Channel with Docker\n- Windows Long Term Servicing Channel with containerd\n- Windows Semi-Annual Channel with Docker\n- Windows Semi-Annual Channel with containerd\n **Warning: ** In GKE version 1.24 and later, Docker-based node image types are not supported. In GKE version 1.23, you also cannot create new node pools with Docker node image types. You must migrate to a containerd node image type. To learn more about this change, see [About the Docker node image deprecation](/kubernetes-engine/docs/deprecations/docker-containerd) .For more information, see the [Choose your Windows node image](#choose_your_windows_server_node_image) section.\n- Choose the default [Machine configuration](/compute/docs/machine-types) to use for the instances. `n1-standard-2` is the minimum recommended size as Windows Server nodes require additional resources. Machine types `f1-micro` and `g1-small` are not supported. Each machine type is billed differently. For more information, refer to the [machine type price sheet](/compute/pricing#standard_machine_types) .\n- From the navigation pane, select the name of your Windows Server node pool. This returns you to the **Node pool details** page.- Under **Automation** , clear the **Enable node auto-upgrade** checkbox. Review the [Upgrading Windows Server node pools](#upgrading_windows_server_node_pools) section before enabling auto-upgrade.\n- From the navigation pane, under **Cluster** , select **Networking** .- Under **Advanced networking options** , ensure **Enable VPC-native\ntraffic routing (uses alias IP)** is selected. Alias IP is required for Windows Server nodes. To read more about its benefits, see [Understanding native container routing with Alias IPs](/blog/products/networking/understanding-native-container-routing-with-alias-ips) .\n- Click **Create** .\nYou can use the [Google Terraform provider](https://www.terraform.io/docs/providers/google/index.html) to create a GKE cluster with a Windows Server node pool.\nAdd this block to your Terraform configuration:\n```\nresource \"google_container_cluster\" \"cluster\" {\u00a0 project \u00a0= \"PROJECT_ID\"\u00a0 name \u00a0 \u00a0 = \"CLUSTER_NAME\"\u00a0 location = \"LOCATION\"\u00a0 min_master_version = \"VERSION_NUMBER\"\u00a0 # Enable Alias IPs to allow Windows Server networking.\u00a0 ip_allocation_policy {\u00a0 \u00a0 cluster_ipv4_cidr_block \u00a0= \"/14\"\u00a0 \u00a0 services_ipv4_cidr_block = \"/20\"\u00a0 }\u00a0 # Removes the implicit default node pool, recommended when using\u00a0 # google_container_node_pool.\u00a0 remove_default_node_pool = true\u00a0 initial_node_count \u00a0 \u00a0 \u00a0 = 1}# Small Linux node pool to run some Linux-only Kubernetes Pods.resource \"google_container_node_pool\" \"linux_pool\" {\u00a0 name \u00a0 \u00a0 \u00a0 = \"linux-pool\"\u00a0 project \u00a0 \u00a0= google_container_cluster.cluster.project\u00a0 cluster \u00a0 \u00a0= google_container_cluster.cluster.name\u00a0 location \u00a0 = google_container_cluster.cluster.location\u00a0 node_count = 1\u00a0 node_config {\u00a0 \u00a0 image_type = \"COS_CONTAINERD\"\u00a0 }}# Node pool of Windows Server machines.resource \"google_container_node_pool\" \"windows_pool\" {\u00a0 name \u00a0 \u00a0 \u00a0 = \"NODE_POOL_NAME\"\u00a0 project \u00a0 \u00a0= google_container_cluster.cluster.project\u00a0 cluster \u00a0 \u00a0= google_container_cluster.cluster.name\u00a0 location \u00a0 = google_container_cluster.cluster.location\u00a0 node_count = 1\u00a0 node_config {\u00a0 \u00a0 image_type \u00a0 = \"IMAGE_NAME\"\u00a0 \u00a0 machine_type = \"MACHINE_TYPE_NAME\"\u00a0 }\u00a0 # The Linux node pool must be created before the Windows Server node pool.\u00a0 depends_on = [google_container_node_pool.linux_pool]}\n```\nReplace the following:- ``: the project ID in which the cluster is created.\n- ``: the name of the GKE cluster.\n- ``: the location (region or zone) in which the cluster is created.\n- ``: must be 1.16.8-gke.9 or higher.\n- ``: the name you choose for your Windows Server node pool.\n- `` : You can specify one of the following values:- `WINDOWS_LTSC_CONTAINERD`: Windows Server LTSC with containerd. This is the image type for both Windows Server 2022 and Windows Server 2019 OS image.\n- `WINDOWS_SAC_CONTAINERD`: Windows Server SAC with containerd [(Unsupported after August 9, 2022)](/kubernetes-engine/docs/deprecations/windows-server-sac) \n- `WINDOWS_LTSC`: Windows Server LTSC with Docker\n- `WINDOWS_SAC`: Windows Server SAC with Docker [(Unsupported after August 9, 2022)](/kubernetes-engine/docs/deprecations/windows-server-sac) \n **Warning: ** In GKE version 1.24 and later, Docker-based node image types are not supported. In GKE version 1.23, you also cannot create new node pools with Docker node image types. You must migrate to a containerd node image type. To learn more about this change, see [About the Docker node image deprecation](/kubernetes-engine/docs/deprecations/docker-containerd) .For more information about these node images, see the [Choose your Windows node image](#choose_your_windows_server_node_image) section.\n- `` : defines the machine type. `n1-standard-2` is the minimum recommended machine type as Windows Server nodes require additional resources. Machine types `f1-micro` and `g1-small` are not supported. Each machine type is billed differently. For more information, refer to the [machine type price sheet](/compute/pricing#standard_machine_types) .\nAfter you create a Windows Server node pool, the cluster goes into a `RECONCILE` state for several minutes as the control plane is updated.\n### Get kubectl credentials\nUse the `get-credentials` command to enable `kubectl` to work with the cluster you created.\n```\ngcloud container clusters get-credentials CLUSTER_NAME\n```\nFor more information on the `get-credentials` command, see the SDK [get-credentials](/sdk/gcloud/reference/container/clusters/get-credentials) documentation.\n### Wait for cluster initialization\nBefore using the cluster, wait for several seconds until `windows.config.common-webhooks.networking.gke.io` is created. This webhook adds scheduling tolerations to Pods created with the `kubernetes.io/os: windows` node selector to ensure they are allowed to run on Windows Server nodes. It also validates the Pod to ensure that it only uses features supported on Windows.\nTo ensure the webhook is created, run the following command:\n```\nkubectl get mutatingwebhookconfigurations\n```\nThe output should show the webhook running:\n```\nNAME            CREATED AT\nwindows.config.common-webhooks.networking.gke.io 2019-12-12T16:55:47Z\n```\nNow that you have a cluster with two node pools (one Linux and one Windows), you can [deploy a Windows application](/kubernetes-engine/docs/how-to/deploying-windows-app) .\n## Mapping GKE and Windows versions\n**    Preview     ** This feature is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA features are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\nMicrosoft releases new SAC versions approximately every six months and new LTSC versions every two to three years. These new versions are typically available in new GKE minor versions. Within a [GKE minor version](/kubernetes-engine/versioning-and-upgrades#versioning_scheme) the LTSC and SAC versions usually remain fixed.\nTo see the version mapping between GKE versions and Windows Server versions, use the [gcloud beta container get-server-config](#gcloud_versionmapping) command:\n```\ngcloud beta container get-server-config\n```\nThe version mapping is returned in the `windowsVersionMaps` field of the response. To filter the response to see the version mapping for specific GKE versions in your cluster, perform the following steps in a Linux shell or in Cloud Shell.\n- Set the following variables:```\nCLUSTER_NAME=CLUSTER_NAMENODE_POOL_NAME=NODE_POOL_NAMEZONE=COMPUTE_ZONE\n```Replace the following:- ``: the name of your cluster.\n- ``: the name of the Windows Server node pool.\n- ``: the [compute zone](/compute/docs/regions-zones#available) for the cluster.\n- Obtain the node pool version and store it in the `NODE_POOL_VERSION` variable:```\nNODE_POOL_VERSION=`gcloud container node-pools describe $NODE_POOL_NAME \\--cluster $CLUSTER_NAME --zone $ZONE --format=\"value(version)\"`\n```\n- Obtain the Windows Server versions for `` :```\ngcloud beta container get-server-config \\\u00a0 \u00a0 --format=\"yaml(windowsVersionMaps.\\\"$NODE_POOL_VERSION\\\")\"\n```The output is similar to the following:```\nwindowsVersionMaps:\n 1.18.6-gke.6601:\n windowsVersions:\n - imageType: WINDOWS_SAC\n  osVersion: 10.0.18363.1198\n  supportEndDate:\n  day: 10\n  month: 5\n  year: 2022\n - imageType: WINDOWS_LTSC\n  osVersion: 10.0.17763.1577\n  supportEndDate:\n  day: 9\n  month: 1\n  year: 2024\n```\n- Obtain the Windows Server version for the `WINDOWS_SAC` image type:```\ngcloud beta container get-server-config \\\u00a0 --flatten=windowsVersionMaps.\\\"$NODE_POOL_VERSION\\\".windowsVersions \\\u00a0 --filter=\"windowsVersionMaps.\\\"$NODE_POOL_VERSION\\\".windowsVersions.imageType=WINDOWS_SAC\" \\\u00a0 --format=\"value(windowsVersionMaps.\\\"$NODE_POOL_VERSION\\\".windowsVersions.osVersion)\"\n```The output is similar to the following:```\n10.0.18363.1198\n```\n**Important:** Before upgrading your node pools to 1.16.8-gke.8 or later, review Microsoft's documentation about the [February 2020 Windows Server container incompatibility issue](https://support.microsoft.com/en-us/help/4542617/you-might-encounter-issues-when-using-windows-server-containers-with-t) and build your container images with [base Windows images](https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/container-base-images) that include Windows Updates from March 2020.\n## Upgrading Windows Server node pools\nThe [Windows Server container version compatibilityrequirements](https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/version-compatibility?tabs=windows-server-20H2%2Cwindows-10-1909) mean that your container images might need to be rebuilt to match the Windows Server version for a new GKE version before upgrading your node pools.\nTo ensure that your container images remain compatible with your nodes, we recommend that you check [the version mapping](#version_mapping) and build your Windows Server container images as [multi-arch images](#building_multi-arch_images) that can target multiple Windows Server versions. You can then update your container deployments to target the multi-arch images that will work on both the current and the next GKE version before manually invoking a GKE node pool upgrade. [Manual node pool upgrades](/kubernetes-engine/docs/how-to/upgrading-a-cluster) must be performed regularly because nodes cannot be more than two minor versions behind the control plane version.\nWe recommend that you [subscribe to upgrade notifications usingPub/Sub](/kubernetes-engine/docs/how-to/cluster-notifications) to proactively receive updates about new GKE versions and the Windows OS versions they use.\nWe recommend enabling [node auto-upgrades](/kubernetes-engine/docs/how-to/node-auto-upgrades) only if you continuously build multi-arch Windows Server container images that target the latest Windows Server versions, especially if you are using Windows Server SAC as the node image type. Node auto-upgrades are less likely to cause problems with the Windows Server LTSC node image type but there is still a risk of encountering version incompatibility issues.\n## Windows Updates\nWindows Updates are disabled for Windows Server nodes. Automatic updates can cause node restarts at unpredictable times, and any Windows Updates installed after a node starts would be lost when the node is recreated by GKE. GKE makes Windows Updates available by periodically updating the Windows Server node images used in new GKE releases. There can be a delay between when Windows Updates are released by Microsoft and when they are available in GKE. When critical security updates are released, GKE updates the Windows Server node images as quickly as possible.\n## Control how Windows Pods and Services communicate\nYou can control how Windows Pods and Services communicate using [network policies](/kubernetes-engine/docs/how-to/network-policy) .\nYou can have a Windows Server container on clusters that have network policy enabled in GKE versions 1.22.2 and later. This feature is available for clusters that use the `WINDOWS_LTSC` or `WINDOWS_LTSC_CONTAINERD` node image types.\nIf your control planes or nodes are running earlier versions, you can migrate your node pools to a version that supports network policy by upgrading your node pools and your control plane to GKE version 1.22.2 or later. This option is only available if you created your cluster with the `--enable-dataplane-v2` flag.\nAfter you enable network policy, all previously configured policies, including policies that did not work on Windows Server containers before you enabled the feature, become active.\nSome clusters cannot be used with Windows Server containers on clusters with network policy enabled. See the [limitations](#limitations) section for more details.\n## Viewing and querying logs\nLogging is enabled automatically in GKE clusters. You can view the logs of the containers and the logs from other services on the Windows Server nodes using [Kubernetes Engine monitoring](/monitoring/kubernetes-engine) .\nThe following is an example of a filter to get the container log:\n```\nresource.type=\"k8s_container\"\nresource.labels.cluster_name=\"your_cluster_name\"\nresource.labels.namespace_name=\"your_namespace_id\"\nresource.labels.container_name=\"your_container_name\"\nresource.labels.Pod_name=\"your_Pod_name\"\n```\n## Accessing a Windows Server node using Remote Desktop Protocol (RDP)\nYou can connect to a Windows Server node in your cluster using RDP. For instructions on how to connect, see [Connecting to Windows instances](/compute/docs/instances/connecting-to-windows) in the Compute Engine documentation.\n## Building multi-arch images\nYou can build the multi-arch images manually or use a Cloud Build builder. For instructions, see [Building Windows multi-arch images](/kubernetes-engine/docs/tutorials/building-windows-multi-arch-images) .\n## Using gMSA\nThe following steps show you how to use a Group Managed Service Account (gMSA) with your Windows Server node pools.\n- Configure Windows Server nodes in your cluster to automatically join your AD domain. For instructions, see [Configure Windows Server nodes to automatically join an Active Directory domain](/kubernetes-engine/docs/how-to/auto-join-windows-nodepools) .\n- Create and grant a gMSA access to the security group automatically created by the domain join service. This step needs to be done in a machine with administrative access to your AD domain.```\n$instanceGroupUri = gcloud container node-pools describe NODE_POOL_NAME --cluster CLUSTER_NAME --format=\"value(instanceGroupUrls)\"$securityGroupName = ([System.Uri]$instanceGroupUri).Segments[-1]$securityGroup = dsquery group -name $securityGroupName$gmsaName = GMSA_NAME$dnsHostName = DNS_HOST_NAMENew-ADServiceAccount -Name $gmsaName -DNSHostName $dnsHostName -PrincipalsAllowedToRetrieveManagedPassword $securityGroupGet-ADServiceAccount $gmsaNameTest-ADServiceAccount $gmsaName\n```Replace the following:- ``: the name of your Windows Server node pool. The automatically created security group has the same name as your Windows Server node pool.\n- ``: the name of your cluster.\n- ``: the name you choose for the new gMSA.\n- ``: the Fully Qualified Domain Name (FQDN) of the service account you created. For example, if``is`webapp01`and the domain is`example.com`, then``is`webapp01.example.com`.\n- Configure your gMSA by following the instructions in the [Configure GMSA for Windows Pods and containers](https://kubernetes.io/docs/tasks/configure-pod-container/configure-gmsa/) tutorial.## Deleting Windows Server node pools\nDelete a Windows Server node pool by using `gcloud` or the Google Cloud console.\n```\ngcloud container node-pools delete NODE_POOL_NAME \\\u00a0 \u00a0 --cluster=CLUSTER_NAME\n```\nTo delete a Windows Server node pool using the Google Cloud console, perform the following steps:- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Beside the cluster you want to edit, click **Actions** , then click **Edit** .\n- Select the **Nodes** tab.\n- Under the **Node Pools** section, click **Delete** next to the node pool you want to delete.\n- When prompted to confirm, click **Delete** again.## Limitations\nThere are some Kubernetes features that are not yet supported for Windows Server containers. In addition, some features are Linux-specific and do not work for Windows. For the complete list of supported and unsupported Kubernetes features, see the [Kubernetes documentation](https://kubernetes.io/docs/setup/production-environment/windows/intro-windows-in-kubernetes/#supported-functionality-and-limitations) .\nIn addition to the unsupported Kubernetes features, there are some GKE features that are not supported.\nFor GKE clusters, the following features are not supported with Windows Server node pools:\n- [Cloud TPUs](/tpu/docs/tpus) (`--enable-tpu`)\n- [Image streaming](/kubernetes-engine/docs/how-to/image-streaming) \n- [Ingress with Network Endpoint Groups](/kubernetes-engine/docs/concepts/ingress#container-native_load_balancing) \n- [Gateway](/kubernetes-engine/docs/concepts/gateway-api) \n- [Intranode visibility](/kubernetes-engine/docs/how-to/intranode-visibility) (`--enable-intra-node-visibility`)\n- [IP masquerade agent](/kubernetes-engine/docs/how-to/ip-masquerade-agent) \n- [Kubernetes alpha cluster](/kubernetes-engine/docs/concepts/alpha-clusters) (`--enable-kubernetes-alpha`)\n- [Node Local DNS cache](/kubernetes-engine/docs/how-to/nodelocal-dns-cache) \n- [Private use of Class E IP addresses](/kubernetes-engine/docs/how-to/alias-ips#enable_reserved_ip_ranges) \n- [Private use of public IP addresses](/kubernetes-engine/docs/how-to/alias-ips#enable_pupis) \n- [Network policy logging](/kubernetes-engine/docs/how-to/network-policy-logging) \n- [Kubernetes service.spec.sessionAffinity](https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies) \n- [GPUs](/compute/docs/gpus) (`--accelerator`)\n- [Setting the maximum Pods per node greater than the default limit of 110](/kubernetes-engine/docs/how-to/flexible-pod-cidr) \n- [Filestore CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver) \n- Docker-based [CloudSQL Auth proxy](/sql/docs/mysql/sql-proxy) \n[Local External Traffic Policy](/kubernetes-engine/docs/how-to/service-parameters#externalTrafficPolicy) on Windows node pool is only supported with GKE version v1.23.4-gke.400 or later.\nOther Google Cloud products that you want to use with GKE clusters might not support Windows Server node pools. For specific limitations, refer to the documentation of that product.\n## Troubleshooting\nSee the Kubernetes documentation for general guidance on [debugging Pods](https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/#debugging-pods) and [Services](https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/#debugging-services) .\n### Containerd node issues\nFor known issues using a Containerd node image, see [Known issues](/kubernetes-engine/docs/concepts/using-containerd#known_issues) .\n### Windows Pods fail to start\nA version mismatch between the Windows Server container and the Windows node that is trying to run the container can result in your Windows Pods failing to start.\nIf the version for your Windows node pool is 1.16.8-gke.8 or later, review Microsoft's documentation for the [February 2020 Windows Server container incompatibility issue](https://support.microsoft.com/en-us/help/4542617/you-might-encounter-issues-when-using-windows-server-containers-with-t) and build your container images with [base Windows images](https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/container-base-images) that include Windows Updates from March 2020. Container images built on earlier base Windows images might fail to run on these Windows nodes and can also cause the node to fail with status `NotReady` .\n### Image pull errors\nWindows Server container images, and the individual layers they are composed of, can be quite large. Their size can cause Kubelet to timeout and fail when downloading and extracting the container layers.\nYou might have encountered this problem if you see the \"Failed to pull image\" or \"Image pull context cancelled\" error messages or an `ErrImagePull` status for your Pods.\nIf the pull image occurs frequently, you should use node pools with a higher CPU specification. Container extraction is executed in parallel across cores, so [machine types](/sdk/gcloud/reference/container/node-pools/create#--machine-type) with more cores reduces the overall pull time.\nTry the following options to successfully pull your Windows Server containers:\n- Break the application layers of the Windows Server container image into smaller layers that can each be pulled and extracted more quickly. This can make Docker's layer caching more effective and make image pull retries more likely to succeed. To learn more about layers, see the Docker article [About images, containers, and storage drivers](https://docs.docker.com/v17.09/engine/userguide/storagedriver/imagesandcontainers/#images-and-layers) .\n- Connect to your Windows Server nodes and manually use the `docker pull` command on your container images before creating your Pods.\n- Set the [image-pull-progress-deadline flag](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/#options) for the `kubelet` service to increase the timeout for pulling container images.Set the flag by connecting to your Windows nodes and running the following PowerShell commands. **Note:** This procedure requires a `kubelet restart` , which can disrupt Pods running on the node.- Get the existing command line for the Kubelet service from the Windows registry.```\nPS C:\\> $regkey = \"HKLM\\SYSTEM\\CurrentControlSet\\Services\\kubelet\"\n``````\nPS C:\\> $name = \"ImagePath\"\n``````\nPS C:\\> $(reg query ${regkey} /v ${name} | Out-String) -match `\"(?s)${name}.*(C:.*kubelet\\.exe.*)\"\n``````\nPS C:\\> $kubelet_cmd = $Matches[1] -replace `\"--image-pull-progress-deadline=.* \",\"\" -replace \"\\r\\n\",\" \"\n```\n- Set a new command line for the Kubelet service, with an additional flag to increase the timeout.```\nPS C:\\> reg add ${regkey} /f /v ${name} /t REG_EXPAND_SZ /d \"${kubelet_cmd} `--image-pull-progress-deadline=40m \"\n```\n- Confirm that the change was successful.```\nPS C:\\> reg query ${regkey} /v ${name}\n```\n- Restart the `kubelet` service so the new flag takes effect.```\nPS C:\\> Restart-Service kubelet\n```\n- Confirm that the `kubelet` service restarted successfully.```\nPS C:\\> Get-Service kubelet # ensure state is Running\n```\n### Image family reached end of life\nWhen creating a node pool with a Windows image, you receive an error similar to the following:\n```\nWINDOWS_SAC image family for 1.18.20-gke.501 has reached end of life, newer versions are still available.\n```\nTo resolve this error, choose a Windows image that is available and supported. You can find the support end date for GKE Windows node images by using the `gcloud container get-server-config` command as described in the [Mapping GKE and Windows versions](#version_mapping) section.\n### Timeout during node pool creation\nNode pool creation can time out if you are creating a large number of nodes (for example, 500) and it's the first node pool in the cluster using a Windows Server image.\nTo resolve this issue, reduce the number of nodes you are creating. You can increase the number of nodes later.\n### Windows nodes become NotReady with error: \"PLEG is not healthy\"\nThis is a [known Kubernetes issue](https://github.com/kubernetes/kubernetes/issues/88153) that happens when multiple Pods are started very rapidly on a single Windows node. To recover from this situation, restart the Windows Server node. A recommended workaround to avoid this issue is to limit the rate at which Windows Pods are created to one Pod every 30 seconds.\n### Inconsistent TerminationGracePeriod\nThe Windows system timeout for the container might differ from the grace period you configure. This difference can cause Windows to force-terminate the container before the end of the grace period passed to the runtime.\nYou can modify the Windows timeout by editing container-local registry keys at image-build time. If you modify the Windows timeout, you might need to adjust TerminationGracePeriodSeconds to match.\n### Network connectivity problems\nIf you experience network connectivity problems from your Windows Server containers, it might be because Windows Server container networking often assumes a network MTU of `1500` , which is incompatible with Google Cloud's MTU of `1460` .\nCheck that both the MTU of the network interface in the container and the network interfaces of the Windows Server node itself are set to the same value (that is, `1460` or less). For information on how to set the MTU, see [known issues for Windows containers](/compute/docs/containers#mtu_failures) .\n### Node startup issues\nIf nodes fail to start in the cluster or fail to join the cluster successfully, review the diagnostic information provided in the node's [serial port](/compute/docs/instances/viewing-serial-port-output) output.\nRun the following command to see the serial port output:\n```\ngcloud compute instances get-serial-port-output NODE_NAME --zone=COMPUTE_ZONE\n```\nReplace the following:\n- ``: the name of the node.\n- ``: the [compute zone](/compute/docs/zones#available) for the specific node.\n### Intermittently unreachable Services in Windows nodes with cluster running 1.24 or earlier\nWhen starting Windows nodes in Kubernetes clusters with a high number of Host Network Service Load Balancer rules, there is a delay in processing the rules. Services are intermittently unreachable during the delay, which lasts around 30 seconds per rule, and the total delay can be significant if there are enough rules. To learn more, see the [original issue in GitHub](https://github.com/kubernetes/kubernetes/issues/109162) .\nFor GKE clusters running version 1.24 or earlier, with any Windows nodes that had an event that restarted `kube-proxy` \u2014for example, node startup, node upgrade, manual restart\u2014any Services being reached by a Pod running on that node will be unreachable until all rules are synced by the component.\nFor GKE clusters running version 1.25 or later, this behavior is substantially improved. For details on this improvement, see the [pull request in GitHub](https://github.com/kubernetes/kubernetes/pull/109124) . If you are experiencing this issue, we recommend upgrading your cluster's control plane to 1.25 or later.\n## What's next\n- Learn how to [deploy a Windows application](/kubernetes-engine/docs/how-to/deploying-windows-app) .\n- Read Microsoft's [short introduction](https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/) on Windows containers.\n- Read [Microsoft's guidance](https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/net-core-net-framework-containers/net-container-os-targets) on choosing the container base images.\n- Read about Microsoft on Windows [container version compatibility](https://docs.microsoft.com/en-us/virtualization/windowscontainers/deploy-containers/version-compatibility) .", "guide": "Google Kubernetes Engine (GKE)"}