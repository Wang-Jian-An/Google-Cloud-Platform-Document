{"title": "Google Kubernetes Engine (GKE) - Storage for GKE clusters overview", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/storage-overview", "abstract": "# Google Kubernetes Engine (GKE) - Storage for GKE clusters overview\nThis document covers the storage options that GKE supports and some key considerations for selecting the best option for your business needs.\nGKE supports the following storage types and integrations:\n- [Block storage using Persistent Disk](#pd) \n- [Block storage using Google Cloud Hyperdisk](#hyperdisk) \n- [Ephemeral and raw block storage using Local SSD](#local-ssd) \n- [File storage](#filestore) \n- [Object storage using Cloud Storage FUSE](#fuse) \n- [Managed databases](#managed-dbs) \n- [Build artifacts](#ar) ", "content": "## Block storage (Persistent Disk)\nPersistent Disk volumes are durable network storage devices managed by Compute Engine that your GKE clusters can access like physical disks in a desktop or a server. When your clusters require additional storage space, you can attach more Persistent Disk volumes to your nodes or resize your existing Persistent Disk volumes. You can let GKE [dynamically provision PersistentVolumes](/kubernetes-engine/docs/concepts/persistent-volumes) backed by Persistent Disk, or you can manually provision disks.\nThis storage option is supported on GKE Autopilot and Standard clusters.\nBy default, Persistent Disk volumes are zonal resources (kept in a single zone within a region). You can create regional Persistent Disk volumes (kept across two zones in the same region). You can also attach a Persistent Disk volume as read-only to multiple nodes simultaneously. This is supported for both zonal and regional Persistent Disk volumes.\nPersistent Disk storage on GKE is persistent, meaning that the data stored on your disks will persist even if the Pod that is using it is terminated.\n### Why use Persistent Disk storage\nUse Persistent Disk storage if your clusters require access to high-performance, highly available durable block storage. A Persistent Disk volume is typically attached to a single Pod. This storage option supports the [ReadWriteOnce access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) . GKE provides support for configuring Persistent Disk volumes with a range of latency and performance options, including the following:\n- **Balanced Persistent Disk** : Suitable for standard enterprise applications. This option provides a balance of performance and cost. Backed by solid-state drives (SSD). This is the default option for dynamic volume provisioning on clusters and nodes running GKE 1.24 or later.\n- **Performance Persistent Disk** : Suitable for scale-out analytics, databases, and persistent caching. This option is ideal for performance-sensitive workloads. Backed by solid-state drives (SSD).\n- **Standard Persistent Disk** : Suitable for big data, big compute workloads. This option is the most cost-effective disk type. Backed by standard hard disk drives (HDD).\n- **Extreme Persistent Disk** : Suitable for enterprise applications such as SAP HANA and Oracle. This option offers the highest performance to meet the needs of the largest in-memory databases. Backed by solid-state drives (SSD). For performance-critical applications, where Persistent Disk does not provide enough performance, use [Hyperdisk Extreme](#hyperdisk) disks.\nTo start using this storage option, see these resources:\n- To learn about the available disk types, see [Storage options](/compute/docs/disks#disk-types) in the Compute Engine documentation.\n- The Compute Engine Persistent Disk CSI driver is the primary way you use Persistent Disk storage with GKE. For instructions, see [Using the Compute Engine Persistent Disk CSI Driver](/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver#using_the_for_linux_clusters) .## Block storage (Google Cloud Hyperdisk)\nHyperdisk volumes use the next generation of Google Cloud block storage. Hyperdisk volumes let you dynamically tune the performance of your block storage to your workload. You can configure input/output operations per second (IOPS) and throughput independently for your applications and adapt to changing performance needs over time.\nThis storage option is supported on GKE Autopilot and Standard clusters. Hyperdisk volumes are zonal resources, subject to [regional availability](/compute/docs/disks/hyperdisks#hyperdisk_regions) . Hyperdisk storage on GKE is persistent, meaning that the data stored on your disks will persist even if the Pod that is using it is terminated.\n### Why use Hyperdisk storage\nUse Hyperdisk storage if you need to dynamically resize and adjust IOPS or throughput. A Hyperdisk volume is typically attached to a single Pod. This storage option supports the [ReadWriteOnce access mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) . You can select from the following Hyperdisk storage options for GKE based on your price-performance needs:\n- **Hyperdisk Throughput** : Optimized for cost-efficient high-throughput, with up to 3\u00a0GB/s throughput (\u2265128\u00a0KB IO size). This is a good option if your use case targets scale-out analytics (for example, Hadoop or Kafka), restoring cold data from backup servers, and throughput-oriented cost-sensitive workloads. This storage option is supported on GKE Autopilot and Standard clusters.\n- **Hyperdisk Extreme** : Optimized for IOPS performance, with >320,000 provisioned IOPS and >4.8\u00a0GB/s throughput. This is a good option if you're deploying high-performance workloads, such as database management systems. This storage option is supported on Standard clusters only.\nTo start using this storage option, refer to these resources:\n- For an overview, see [About Hyperdisk for GKE](/kubernetes-engine/docs/concepts/hyperdisk) .\n- To set up and consume Hyperdisk storage in your clusters, see [Scale your storage performance with Hyperdisk](/kubernetes-engine/docs/how-to/persistent-volumes/hyperdisk) .## Ephemeral and raw block storage (Local SSD)\nLocal SSD disks are physical drives that are attached directly to your nodes. They can offer better performance, but are ephemeral. Each Local SSD volume is attached to a specific node. You can't move the volume to a different node.\nThis storage option is supported on GKE Standard clusters. Autopilot support for Local SSD is available in preview on A2 Ultra A100 machines, on clusters and node pools running GKE 1.27 and later.\nEphemeral storage backed by Local SSD storage on GKE is tied to the lifecycle of a Pod. When your Pod is terminated, the ephemeral storage associated with that Pod is also deleted.\n### Why use Local SSD\nUsing Local SSD storage in GKE clusters is suitable if you need hot caching for databases and for real-time analytics, or flash-optimized ephemeral storage offering the lowest latencies. Local SSD storage can be particularly effective as a caching layer in front of Cloud Storage for AI/ML, batch processing, analytics, and in-memory databases use cases.\nTo start using this storage option, refer to these resources:\n- For an overview, see [About Local SSD storage for GKE](/kubernetes-engine/docs/concepts/local-ssd) .\n- To set up and consume Local SSD storage in your clusters as [emptyDir](https://kubernetes.io/docs/concepts/storage/volumes/#emptydir) , see [Provision and use Local SSD-backed ephemeral storage](/kubernetes-engine/docs/how-to/persistent-volumes/local-ssd) .\n- To set up and consume Local SSD storage in your clusters as [local](https://kubernetes.io/docs/concepts/storage/volumes/#local) PersistentVolumes resources, see [Provision and use Local SSD-backed raw block storage](/kubernetes-engine/docs/how-to/persistent-volumes/local-ssd-raw) .## File storage\nFilestore provides a cloud-based shared file system for unstructured data, with network file system (NFS) access. Filestore instances function as file servers on Google Cloud that provide durable storage with [ReadWriteMany](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes) access for your GKE clusters. Filestore instances are decoupled from the host and require minimal manual operation. Workload failovers are seamless because there are no infrastructure operations to attach or detach volumes.\nThis storage option is supported on GKE Autopilot and Standard clusters. Filestore storage with the [enterprise service tier](/filestore/docs/service-tiers#enterprise_tier) defaults to regional availability, while the other service tiers have zonal availability. Filestore storage on GKE is persistent, meaning that the data stored in your instances will persist even if the Pod that is using it is terminated.\n### Why use Filestore storage\nUse Filestore storage if your applications need network file system (NFS) access and multiple readers and writers. This storage option is suitable if your use case involves content management systems, application migration, data analytics, rendering, and media processing.\nFor additional cost efficiency, [Filestore multishares for GKE](/filestore/docs/multishares) lets you share a Filestore enterprise tier instance of 10\u00a0GiB or larger with up to 80 PersistentVolumes.\nTo start using this storage option, refer to these resources:\n- For an overview, see [About Filestore support for GKE](/kubernetes-engine/docs/concepts/filestore-for-gke) .\n- The Filestore CSI driver is the primary way you use Filestore storage with GKE. For instructions, see [Access Filestore instances with the Filestore CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver) .\n- For Filestore multishares instructions, see [Optimize storage with Filestore multishares for GKE](/filestore/docs/optimize-multishares) .## Object storage (Cloud Storage FUSE)\nCloud Storage is an object store for binary and object data, blobs, and unstructured data. The [Cloud Storage FUSE CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver) manages the integration of Cloud Storage FUSE with Kubernetes APIs to consume existing Cloud Storage buckets as volumes. You can use the Cloud Storage FUSE CSI driver to mount buckets as file systems on GKE nodes.\nThe Cloud Storage FUSE CSI driver supports the `ReadWriteMany` , `ReadOnlyMany` , and `ReadWriteOnce` access modes on GKE Autopilot and Standard clusters. Cloud Storage objects have regional availability. Cloud Storage data on GKE is persistent, meaning that the data stored in your buckets will persist even if the Pod that is using it is terminated.\n### Why use Cloud Storage FUSE\nThe Cloud Storage FUSE option is suitable if you need file semantics in front of Cloud Storage for portability. Cloud Storage FUSE is also a common choice for developers who want to store and access [machine learning (ML) training](/storage/docs/gcsfuse-integrations#machine-learning) and model data as objects in Cloud Storage.\nTo start using this storage option, refer to these resources:\n- For an overview, see [Cloud Storage FUSE](/storage/docs/gcs-fuse) .\n- To consume Google Cloud buckets in your clusters, see [Access Cloud Storage buckets with the Cloud Storage CSI FUSE driver](/kubernetes-engine/docs/how-to/persistent-volumes/cloud-storage-fuse-csi-driver) .## Managed databases\nA managed database, such as [Cloud SQL](/sql) or [Spanner](/spanner) , provides reduced operational overhead and is optimized for Google Cloud infrastructure. Managed databases require less effort to maintain and operate than a database that you deploy directly in Kubernetes.\n### Why use managed databases\nUsing a Google Cloud managed database lets your stateful workloads on GKE to access persistent data while automating maintenance tasks such as backups, patching, and scaling. You create a database, build your app, and let Google Cloud scale it for you. However, this also means you might not have access to the exact version of a database, extension, or the exact flavor of database that you want.\nGKE provides support for connecting with Google Cloud managed database services, including the following:\n- **Cloud SQL** : Fully managed MySQL, PostgreSQL, and SQL Server database. Refer to [Connect from Google Kubernetes Engine](/sql/docs/postgres/connect-kubernetes-engine) .\n- **Spanner** : Horizontally scalable relational database with high consistency and availability. Refer to [Deploy an app using GKE Autopilot and Cloud Spanner](/kubernetes-engine/docs/tutorials/gke-spanner-integration) .\n- **Memorystore for Redis** : Fully managed in-memory data store service. Refer to [Connecting to a Redis instance from a Google Kubernetes Engine cluster](/memorystore/docs/redis/connect-redis-instance-gke) .\nTo start using this storage option, refer to these resources:\n- [Your Google Cloud database options, explained](https://cloud.google.com/blog/topics/developers-practitioners/your-google-cloud-database-options-explained) .\n- For considerations on using a managed database or a containerized database hosted on GKE, see [Plan your database deployments on GKE](/kubernetes-engine/docs/concepts/database-options) .## Build artifacts (Artifact Registry)\nArtifact Registry is a repository manager for container images, OS packages, and language packages that you build and deploy.\n### Why use Artifact Registry\nArtifact Registry is a suitable option for storing your private container images, Helm charts, and other build artifacts.\nTo pull images from Artifact Registry Docker repositories to GKE, see [Deploying to Google Kubernetes Engine](/artifact-registry/docs/integrate-gke) in the Artifact Registry documentation.\n## What's next\n- Read the blog post [A map of storage options in Google Cloud](https://cloud.google.com/blog/topics/developers-practitioners/map-storage-options-google-cloud) .\n- [Design an optimal storage strategy for your cloud workload](/architecture/storage-advisor) .\n- Understand how to use Kubernetes storage abstractions in GKE: [PersistentVolumes](/kubernetes-engine/docs/concepts/persistent-volumes) , [StatefulSets](/kubernetes-engine/docs/concepts/statefulset) .\n- See the [Data on GKE](/kubernetes-engine/docs/integrations/data) resource page to learn about data solutions you can integrate with GKE.", "guide": "Google Kubernetes Engine (GKE)"}