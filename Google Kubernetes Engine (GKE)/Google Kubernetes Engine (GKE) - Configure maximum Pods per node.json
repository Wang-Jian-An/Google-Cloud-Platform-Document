{"title": "Google Kubernetes Engine (GKE) - Configure maximum Pods per node", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/flexible-pod-cidr", "abstract": "# Google Kubernetes Engine (GKE) - Configure maximum Pods per node\nThis page explains how you can configure the maximum number of Pods that can run on a node for Standard clusters. This value determines the size of the IP address ranges that are assigned to nodes on Google Kubernetes Engine (GKE). The Pods that run on a node are allocated IP addresses from the node's assigned CIDR range.\nWhen scheduling, GKE uses the maximum number of Pods per node to determine if there is sufficient capacity to schedule a Pod. Only Pods that have been assigned to a node, and are not yet terminated ( [Failed or Succeeded phase](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-phase) ), are counted against this capacity.\nThe steps on this page do not apply to Autopilot clusters because the maximum number of nodes is pre-configured and immutable.\n", "content": "## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n### Restrictions\n- You can only configure the maximum Pods per node in [VPC-native clusters](/kubernetes-engine/docs/how-to/alias-ips) .\n- Node creation is limited by the number of available addresses in the Pod address range. Check the [IP address range planning table](/kubernetes-engine/docs/concepts/alias-ips#defaults_limits) for the default, minimum, and maximum Pod address range sizes. You can also add additional Pod IP addresses using [discontiguous multi-Pod CIDR](/kubernetes-engine/docs/how-to/multi-pod-cidr) .\n- Each cluster needs to create kube-system Pods, such as [kube-proxy](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/) , in the `kube-system` namespace. Remember to account for both your workload Pods and System Pods when you reduce the maximum number of Pods per node. To list System Pods in your cluster, run the following command:```\nkubectl get pods --namespace kube-system\n```## Configure the maximum Pods per node\nYou can configure the maximum number of Pods per node when creating a cluster or when creating a node pool. You cannot change this setting after the cluster or node pool is created.\nHowever, if you run out of Pod IP addresses, you can create additional Pod IP address ranges using [discontiguous multi-Pod CIDR](/kubernetes-engine/docs/how-to/multi-pod-cidr) .\nYou can set the size of the Pod address range when creating a cluster by using the gcloud CLI or the Google Cloud console.\nTo set the default maximum Pods per node using the gcloud CLI, run the following command:\n```\ngcloud container clusters create CLUSTER_NAME \\\u00a0 \u00a0 --enable-ip-alias \\\u00a0 \u00a0 --cluster-ipv4-cidr=10.0.0.0/21 \\\u00a0 \u00a0 --services-ipv4-cidr=10.4.0.0/19 \\\u00a0 \u00a0 --create-subnetwork=name='SUBNET_NAME',range=10.5.32.0/27 \\\u00a0 \u00a0 --default-max-pods-per-node=MAXIMUM_PODS \\\u00a0 \u00a0 --location=COMPUTE_LOCATION\n```\nReplace the following:- ``: the name of your new cluster.\n- ``: the name of the new subnetwork for your cluster.\n- ``: the default maximum number of Pods per node for your cluster, can be configured up to`256`. If omitted, Kubernetes assigns the default value of`110`.\n- ``: the [Compute Engine location](/compute/docs/regions-zones/viewing-regions-zones) for the new cluster.\n- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Click **Create** .\n- Configure your new cluster.\n- From the navigation pane, under **Cluster** , click **Networking** .\n- Ensure the **Enable VPC-native traffic routing (uses alias IP)** checkbox is selected.\n- From the navigation pane, under **Node pools** , click **Nodes** .\n- Set the **Maximum pods per node** field to `110` . GKE uses this value to tune the size of the IP address range assigned to nodes.\n- Click **Create** .\nWhen you configure the maximum number of Pods per node for the cluster, Kubernetes uses this value to allocate a CIDR range for the nodes. You can calculate the maximum number of nodes on the cluster based on the cluster's secondary IP address range for Pods and the allocated CIDR range for the node.\nFor example, if you set the default maximum number of Pods to `110` and the secondary IP address range for Pods to `/21` , Kubernetes assigns a `/24` CIDR range to nodes on the cluster. This allows a maximum of `2` `` `= 2` `` `= 8` nodes on the cluster.\nSimilarly, if you set the default maximum Pods to `8` and the cluster's secondary IP address range for Pods to `/21` , Kubernetes assigns a `/28` CIDR range to nodes. This allows a maximum of `2` `` `= 2` `` `= 128` nodes on the cluster.\n## Configure the maximum number of Pods in a new node pool for an existing cluster\nYou can also specify the maximum number of Pods per node when creating a node pool in an existing cluster. Creating a new node pool lets you optimize IP address allocation, even in existing clusters where there is no configured default maximum number of Pods per node at the cluster level.\nSetting the maximum number of Pods at the node pool level overrides the cluster-level default maximum. If you do not configure a maximum number of Pods per node when you create the node pool, the cluster-level maximum applies.\n```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --cluster=CLUSTER_NAME \\\u00a0 \u00a0 --max-pods-per-node=MAXIMUM_PODS\n```\nReplace the following:- ``: the name of your new node pool.\n- ``: the name of the cluster in which you want to create the node pool.\n- ``: the maximum number of Pods in the node pool.\n- Go to the **Google Kubernetes Engine** page in Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- In the cluster list, click the name of the cluster you want to modify.\n- Click **Add Node Pool** .\n- From the navigation pane, click **Nodes** .\n- Under **Networking** , enter a value for the **Maximum Pods per node** field. GKE uses this value to tune the size of the IP address range assigned to nodes.## About default maximum Pods per node\nBy default, GKE allows up to 110 Pods per node on Standard clusters, however Standard clusters can be configured to allow up to 256 Pods per node. Autopilot clusters, based on the on the expected workload Pod density, choose the maximum Pods per node from a range between 8 and 256. Kubernetes assigns each node a range of IP addresses, [a CIDRblock](https://tools.ietf.org/html/rfc1918) , so that each Pod can have a unique IP address. The size of the CIDR block corresponds to the maximum number of Pods per node.\n### Pod CIDR ranges in Standard clusters\nWith the default maximum of 110 Pods per node for Standard clusters, Kubernetes assigns a /24 CIDR block (256 addresses) to each of the nodes. By having more than twice as many available IP addresses as the maximum number of Pods that can be created on a node, Kubernetes can reduce IP address reuse as Pods are added to and removed from a node.\nAlthough having 256 Pods per node is a hard limit, you can reduce the number of Pods on a node. The size of the CIDR block assigned to a node depends on the maximum Pods per node value. The block always contains at least twice as many addresses as the maximum number of Pods per node.\nThe following table lists the size of the CIDR block and the corresponding number of available IP addresses that Kubernetes assigns to nodes based on the maximum Pods per node:\n| Maximum Pods per Node | CIDR Range per Node | Number of IP addresses |\n|:------------------------|:----------------------|-------------------------:|\n| 8      | /28     |      16 |\n| 9 \u2013 16     | /27     |      32 |\n| 17 \u2013 32     | /26     |      64 |\n| 33 \u2013 64     | /25     |      128 |\n| 65 \u2013 128    | /24     |      256 |\n| 129 - 256    | /23     |      512 |\n**Note:** Setting the maximum Pods per node over the default limit of 110 is only supported for GKE versions 1.23.5-gke.1300 and later.\n### Pod CIDR ranges in Autopilot clusters\nThe default settings for Autopilot cluster CIDR sizes are as follows:\n- Subnetwork range: /23\n- Secondary IP address range for Pods: /17\n- Secondary IP address range for Services: /22\nAutopilot has a maximum Pods per node of [32](/kubernetes-engine/quotas#limits_per_cluster) . As with GKE Standard, this results in a `/26` range being provisioned per node, that is, 64 IPs. A Pod address range of `/17` results in a cluster than can support at most 511 nodes (32,766 usable IPs / 64 IP addresses per node).\nEnsure the secondary IP address range for Pods that you specify is large enough to support your anticipated maximum cluster size. A range of `/16` (for example, `cluster-ipv4-cidr=10.0.0.0/16` ) is recommended to support maximum growth of the cluster.\n### Reduce the maximum number of Pods\nReducing the maximum number of Pods per node allows the cluster to have more nodes, since each node requires a smaller part of the total IP address space. Alternatively, you could support the same number of nodes in the cluster by specifying a smaller IP address space for Pods at cluster creation time.\nReducing the maximum number of Pods per node also lets you create smaller clusters that require fewer IP addresses. For example, with eight Pods per node, each node is granted a /28 CIDR. These IP address ranges plus the [subnet and secondary ranges](/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing) that you define determine the number of IP addresses required to create a cluster successfully.\nYou can configure the maximum number of Pods per node at cluster creation time and at [node pool](/kubernetes-engine/docs/concepts/node-pools) creation time.\n## What's next\n- Learn how to create [VPC-native](/kubernetes-engine/docs/how-to/alias-ips) clusters.\n- Learn how to add [additional Pod IP addresses](/kubernetes-engine/docs/how-to/multi-pod-cidr) to clusters.\n- Learn about [IP address management strategies when migrating to GKE](/kubernetes-engine/docs/concepts/gke-ip-address-mgmt-strategies) .\n- Learn about [GKE IP address utilization insights](/network-intelligence-center/docs/network-analyzer/insights/kubernetes-engine/gke-ip-utilization) .", "guide": "Google Kubernetes Engine (GKE)"}