{"title": "Google Kubernetes Engine (GKE) - Deploy Redis to GKE using Redis Enterprise", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/stateful-workloads/enterprise-redis", "abstract": "# Google Kubernetes Engine (GKE) - Deploy Redis to GKE using Redis Enterprise\nThe guide shows you how to deploy [Redis Enterprise](https://redis.io/docs/about/redis-enterprise/) to Google Kubernetes Engine (GKE) clusters.\n [Redis](https://redis.io/) is an open source in-memory NoSQL database primarily used for caching. It has built-in replication, Lua scripting, LRU eviction, transactions, on-disk persistence, and high availability.\nRedis Enterprise is an enterprise-grade solution that extends the Redis open-source with simplified management including geo-replicated data distribution, linear scaling of operations throughput, data tiering, advanced security features, and more.\nRedis Enterprise has different pricing for each deployment option, including: [Software](https://console.cloud.google.com/marketplace/product/redislabs-public/redis-enterprise) , [Cloud](https://console.cloud.google.com/marketplace/product/redis-marketplace-isaas/redis-enterprise-cloud-flexible-plan) , or [Hybrid and Multi-cloud](https://redis.com/redis-enterprise-cloud/pricing/) .\nThis guide is intended for platform administrators, cloud architects, and operations professionals interested in deploying Redis Enterprise on Google Kubernetes Engine (GKE).\n **Note:** Redis Enterprise Software distributed under a [Redis Enterprise License](https://redis.com/software-subscription-agreement/) , and license restrictions require users to have an active subscription after a 30 day [trial](https://redis.com/legal/redis-software-trial-terms/) to keep using Redis Enterprise.", "content": "## Objectives\n- Plan and deploy GKE infrastructure for Redis\n- Deploy the Redis Enterprise Operator\n- Deploy a Redis Enterprise Cluster\n- Create a Redis Enterprise Database\n- Demonstrate database authentication\n## BenefitsRedis Enterprise offers the following benefits:- A Kubernetes-native way to manage Redis Enterprise Cluster (REC) lifecycle and Redis Enterprise Databases (REDBs)\n- Resource utilization by co-locating multiple Redis databases within a single Kubernetes Pod\n- Reduced operational overhead by handling routine maintenance tasks such as patching and upgrades\n- Support for Redis software images from private container registries, such as Artifact Registry, to enhance the security and availability of containers\n- Support for Google Cloud Managed Service for Prometheus for database monitoring and observability\n- Enhanced security features such as encryption, access controls, and integration with Kubernetes RBAC (Role-Based Access Control)\n- Advanced authentication methods including LDAP and third party credential managers like Vault\n- Ability to [configure scheduled backups](https://docs.redis.com/latest/rs/databases/import-export/schedule-backups/) \n### Deployment architectureRedis Enterprise manages the following Kubernetes resources:- The Enterprise cluster and its configuration in a StatefulSet. The cluster consists of Redis nodes (Pods) with installed Redis packages. These nodes have running processes to ensure the node is part of a cluster. Each node provides a container to run multiple database instances (shards). Although Kubernetes best practices state that a Pod should represent one application with one container, Redis Enterprise deploys multiple Redis databases to a single container. This approach provides better resource utilization, performance, and network throughput. Each container also has a zero-latency proxy to route and manage traffic to specific Redis database processes within a container.\n- The`RedisEnterpriseDatabase`(REDBs) custom resource that represents the Redis database instances created within the REC\n- Kubernetes Services that serve REDB instances as database endpoints\n- A controller Pod called Service Rigger that creates and deletes database endpoints when a database is created or deleted\nIn this tutorial, you create a [one-to-many](https://docs.redis.com/latest/kubernetes/deployment/deployment-options/#single-rec-and-multiple-namespaces-one-to-many) deployment by deploying a REC into a dedicated namespace and using separate namespaces for application deployments for better isolation.\nThe following diagram describes Redis Enterprise components and how they are interconnected:In this tutorial, you configure Redis Enterprise Cluster to be highly available. To accomplish this, the REC requires an odd number of nodes and a minimum of three nodes. You also set affinity, anti-affinity rules, and node taints that ensure that each Redis node is placed in a different Kubernetes node and the Redis nodes are spread evenly across the Kubernetes cluster.\nUsing multiple nodes and zones is crucial for achieving a high-available GKE cluster for the following reasons:- **Fault tolerance** : Multiple nodes distribute the workload across the cluster, ensuring that if one node fails, the other nodes can take over the tasks, preventing downtime and service interruptions.\n- **Scalability** : Having multiple nodes allows for horizontal scaling by adding or removing nodes as needed, ensuring optimal resource allocation and accommodating increased traffic or workload demands.\n- **High availability** : Using multiple zones within a region ensures redundancy and minimizes the risk of a single point of failure. If an entire availability zone experiences an outage, the cluster can continue running in other zones, maintaining service availability.\n- **Geographic redundancy** : By spanning nodes across regions, the cluster's data and services are geographically distributed, providing resilience against natural disasters, power outages, or other local disruptions that might impact a single zone.\n- **Rolling updates and maintenance** : By using multiple nodes, you can perform rolling updates and maintenance on individual nodes without impacting the overall availability of the cluster. This ensures continuous service while allowing you to perform necessary updates and apply patches seamlessly.\n- **Service Level Agreements (SLAs)** : Google Cloud provides SLAs for multi-zone deployments, guaranteeing a minimum level of uptime and availability.\n## CostsIn this document, you use the following billable components of Google Cloud:- [Compute Engine](/compute/disks-image-pricing) \n- [GKE](/kubernetes-engine/pricing) \n- [Google Cloud Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin- Grant roles to your Google Account. Run the following command once for each of the following   IAM roles: `roles/compute.securityAdmin, roles/compute.viewer, roles/container.clusterAdmin, roles/container.admin, roles/iam.serviceAccountAdmin, roles/iam.serviceAccountUser` ```\ngcloud projects add-iam-policy-binding PROJECT_ID --member=\"user:EMAIL_ADDRESS\" --role=ROLE\n```- Replace``with your project ID.\n- Replace``with your email address.\n- Replace``with each individual role.\n### Set up your environmentIn this tutorial, you use [Cloud Shell](/shell) to manage resources hosted on Google Cloud. Cloud Shell comes preinstalled with the software you need for this tutorial, including [kubectl](https://kubernetes.io/docs/reference/kubectl/) , the [gcloud CLI](/sdk/gcloud) , and [Terraform](/docs/terraform) .\nTo set up your environment with Cloud Shell, follow these steps:- Launch a Cloud Shell session from the Google Cloud console, by clicking **Activate Cloud Shell** in the [Google Cloud console](https://console.cloud.google.com/) . This launches a session in the bottom pane of the Google Cloud console.\n- Set environment variables:```\nexport PROJECT_ID=PROJECT_ID\nexport KUBERNETES_CLUSTER_PREFIX=redis\nexport REGION=us-central1\n```Replace `` : your Google Cloud with your [project ID](/resource-manager/docs/creating-managing-projects#identifying_projects) .\n- Clone the GitHub repository:```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples\n```\n- Change to the working directory:```\ncd kubernetes-engine-samples/databases/redis-enterprise-operator\n```\n## Create your cluster infrastructureIn this section, you run a Terraform script to create a private, highly-available, regional GKE cluster and VPC.\nThe following diagram shows a private regional Standard GKE cluster deployed across three different zones:To deploy this infrastructure, run the following commands from the Cloud Shell:\n```\n\u00a0 cd terraform/gke-standard\u00a0 export GOOGLE_OAUTH_ACCESS_TOKEN=$(gcloud auth print-access-token)\u00a0 terraform init\u00a0 terraform apply -var project_id=${PROJECT_ID} \u00a0 \\\u00a0 \u00a0 -var region=${REGION} \u00a0\\\u00a0 \u00a0 -var cluster_prefix=${KUBERNETES_CLUSTER_PREFIX}\n```\nWhen prompted, type `yes` . It might take several minutes for this command to complete and for the cluster to show a ready status.\nTerraform creates the following resources:- A VPC network and private subnet for the Kubernetes nodes\n- A router to access the internet through NAT\n- A private GKE cluster in the`us-central1`region\n- One node pool with auto-scaling enabled (One to two nodes per zone, one node per zone minimum)\nThe output is similar to the following:\n```\n...\nApply complete! Resources: 14 added, 0 changed, 0 destroyed.\n...\n```\n### Connect to the clusterUsing Cloud Shell, configure `kubectl` to communicate with the cluster:\n```\ngcloud container clusters get-credentials ${KUBERNETES_CLUSTER_PREFIX}-cluster --region ${REGION}\n```## Deploy the Redis Enterprise operator to your clusterIn this section, you deploy the [Redis Enterprise operator](https://docs.redis.com/latest/kubernetes/architecture/operator) to your Kubernetes cluster.- Create namespaces for the REC and its applications:```\nkubectl create namespace rec-nskubectl create namespace application\n```\n- Label the namespaces:```\nkubectl label namespace rec-ns connection=rediskubectl label namespace application connection=redis\n```\n- Get the latest version of the Redis Enterprise Operator bundle:```\nVERSION=`curl --silent https://api.github.com/repos/RedisLabs/redis-enterprise-k8s-docs/releases/latest | grep tag_name | awk -F'\"' '{print $4}'`\n```\n- Install the Redis Enterprise operator:```\nkubectl apply -n rec-ns -f https://raw.githubusercontent.com/RedisLabs/redis-enterprise-k8s-docs/$VERSION/bundle.yaml\n```The output is similar to the following:```\nrole.rbac.authorization.k8s.io/redis-enterprise-operator created\nrolebinding.rbac.authorization.k8s.io/redis-enterprise-operator created\nserviceaccount/redis-enterprise-operator created\nservice/admission created\ncustomresourcedefinition.apiextensions.k8s.io/redisenterpriseclusters.app.redislabs.com created\ncustomresourcedefinition.apiextensions.k8s.io/redisenterprisedatabases.app.redislabs.com created\ncustomresourcedefinition.apiextensions.k8s.io/redisenterpriseremoteclusters.app.redislabs.com created\ncustomresourcedefinition.apiextensions.k8s.io/redisenterpriseactiveactivedatabases.app.redislabs.com created\ndeployment.apps/redis-enterprise-operator created\n```\n## Deploy Redis Enterprise Cluster\n- Apply the manifest to your cluster:```\nkubectl apply -n rec-ns -f manifests/01-basic-cluster/rec.yaml\n```The command might take several minutes to complete.\n- Check the status of the REC deployment:```\nkubectl get rec -n rec-ns\n```The output is similar to the following:```\nNAME \u00a0 \u00a0 \u00a0NODES \u00a0 VERSION \u00a0 \u00a0STATE \u00a0 \u00a0 SPEC STATUS \u00a0 LICENSE STATE \u00a0 SHARDS LIMIT \u00a0 LICENSE EXPIRATION DATE \u00a0 AGEgke-rec \u00a0 3 \u00a0 \u00a0 \u00a0 7.2.4-52 \u00a0 Running \u00a0 Valid \u00a0 \u00a0 \u00a0 \u00a0 Valid \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 4 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a02023-09-29T20:15:32Z \u00a0 \u00a0 \u00a04m7s\n```The cluster is ready when `STATE` is `RUNNING` .\n## Optional: Configure the admission controllerYou can optionally configure infrastructure for the database validation on deployment.- Setup the admission controller and check if the admission tls Secret is present:```\nkubectl get secret admission-tls -n rec-ns\n```\n- Get the certificate:```\nexport CERT=$(kubectl get secret admission-tls -n rec-ns -o jsonpath='{.data.cert}')\n```\n- Copy the certificate into the `webhook.yaml` file:```\nsed -i -e 's/CRT/'$CERT'/g' manifests/01-basic-cluster/webhook.yaml\n```\n- Deploy the validation webhook:```\nsed -i -e 's/CRT/'$CERT'/g' manifests/01-basic-cluster/webhook.yaml\n```The admission controller validates database syntax on labeled namespaces.\n- Verify the admission controller by creating a non-functional database:```\nkubectl apply -n rec-ns -f - << EOFapiVersion: app.redislabs.com/v1alpha1kind: RedisEnterpriseDatabasemetadata:\u00a0 name: redis-enterprise-databasespec:\u00a0 evictionPolicy: illegalEOF\n```The output is similar to the following:```\nError from server: error when creating \"STDIN\": admission webhook \"redisenterprise.admission.redislabs\" denied the request: 'illegal' is an invalid value for 'eviction_policy'. Possible values are ['volatile-lru', 'volatile-ttl', 'volatile-random', 'allkeys-lru', 'allkeys-random', 'noeviction', 'volatile-lfu', 'allkeys-lfu']\n```\n## Create namespacesBy default, the Redis Enterprise Operator has no privileges to perform actions outside its own namespace. To allow the Redis Enterprise Operator to create REDB and database endpoints in other namespaces, you must configure RBAC.- Apply the corresponding role and role binding in the application namespace:```\nkubectl apply -f manifests/01-basic-cluster/role.yaml -n applicationkubectl apply -f manifests/01-basic-cluster/role-binding.yaml -n application\n```\n- Create cluster role and cluster role binding in the `rec-ns` namespace:```\nkubectl apply -n rec-ns -f manifests/01-basic-cluster/cluster_role.yaml kubectl apply -n rec-ns -f manifests/01-basic-cluster/cluster_role_binding.yaml\n```\n- Edit the REC ConfigMap to add control over the application namespace:```\nkubectl patch ConfigMap/operator-environment-config --type merge -p '{\"data\": {\"REDB_NAMESPACES_LABEL\": \"connection=redis\"}}' -n rec-ns\n```Each namespace labeled as ConfigMap is patched.\n- Check the status of the resources in your Redis infrastructure in the `rec-ns` namespace:.```\nkubectl get pod,deploy,svc,rec,statefulset,cm,secrets -n rec-ns\n```The output is similar to the following:```\nNAME            READY STATUS RESTARTS  AGE\npod/gke-rec-0         2/2  Running 0    172m\npod/gke-rec-1         2/2  Running 0    171m\npod/gke-rec-2         2/2  Running 0    168m\npod/gke-rec-services-rigger-5f885f59dc-gc79g  1/1  Running 0    172m\npod/redis-enterprise-operator-6668ccd8dc-kx29z 2/2  Running 2 (5m58s ago) 5h\nNAME          READY UP-TO-DATE AVAILABLE AGE\ndeployment.apps/gke-rec-services-rigger  1/1  1   1   172m\ndeployment.apps/redis-enterprise-operator 1/1  1   1   5h\nNAME     TYPE  CLUSTER-IP EXTERNAL-IP PORT(S)    AGE\nservice/admission  ClusterIP 10.52.11.13 <none>  443/TCP    5h\nservice/gke-rec  ClusterIP 10.52.5.44 <none>  9443/TCP,8001/TCP 172m\nservice/gke-rec-prom ClusterIP None   <none>  8070/TCP   172m\nservice/gke-rec-ui  ClusterIP 10.52.3.29 <none>  8443/TCP   172m\nNAME            NODES VERSION STATE  SPEC STATUS LICENSE STATE SHARDS LIMIT LICENSE EXPIRATION DATE AGE\nredisenterprisecluster.app.redislabs.com/gke-rec 3  7.2.4-52 Running Valid   Valid   4    2023-10-05T11:07:20Z  172m\nNAME      READY AGE\nstatefulset.apps/gke-rec 3/3  172m\nNAME         DATA AGE\nconfigmap/gke-rec-bulletin-board  1  172m\nconfigmap/gke-rec-health-check   5  172m\nconfigmap/kube-root-ca.crt    1  5h2m\nconfigmap/operator-environment-config 1  5h\nNAME     TYPE  DATA AGE\nsecret/admission-tls Opaque 2  5h\nsecret/gke-rec   Opaque 2  172m\n```\n## Deploy Redis Enterprise Databases\n- Create Redis Enterprise Databases in the application namespaces:```\nkubectl apply -f manifests/01-basic-cluster/a-rdb.yaml -n application\n```\n- Check the REDB status:```\nkubectl get redb --all-namespaces\n```The output is similar to the following:```\nNAMESPACE  NAME  VERSION PORT CLUSTER SHARDS STATUS SPEC STATUS AGE\napplication app-db 7.2.0  12999 gke-rec 1  active Valid   15s\n```\n- Verify that the Services for each REDB are running:```\nkubectl get svc --all-namespaces\n```The output is similar to the following:```\nNAMESPACE  NAME  TYPE   CLUSTER-IP EXTERNAL-IP       PORT(S) AGE\napplication app-db ExternalName <none>  redis-12999.rec-ns.svc.cluster.local 12999/TCP 72m\n```\n- Verify that the Secret was created:```\nkubectl get secrets -n application\n```The output is similar to the following:```\nNAME   TYPE  DATA AGE\nredb-app-db Opaque 3  96m\n```\n## Authenticate using passwordsYou can connect to REDB using a Pod with `redis-cli` in the application namespace. The client Pod uses the secrets available in the application namespace (REDB) to establish a connection.\nDatabases created with the Custom Resource REDB only support [password authentication without ACL](https://docs.redis.com/latest/kubernetes/reference/db-options/#databasesecretnamehttpsgithubcomredislabsredis-enterprise-k8s-docsblobmasterredis_enterprise_database_apimdredisenterprisedatabasespec) .- Create the client Pod:```\nkubectl apply -n application -f manifests/03-auth/client_pod.yaml\n```\n- Connect to the client Pod:```\nkubectl exec -n application -i -t redis-client -c redis-client -- /bin/sh\n```\n- Connect to the database:```\nredis-cli -h $SERVICE -p $PORT --pass $PASS\n```\n- Create a key:```\nSET mykey \"Hello World\"\n```The output is similar to the following:```\nOK\n```\n- Get the key:```\nGET mykey\n```The output is similar to the following:```\n\"Hello World\"\n```\n- Exit the Pod shell```\nexit\n```\n## Understand how Prometheus collects metrics for your Redis clusterThe following diagram shows how Prometheus metrics collecting works:In the diagram, a GKE private cluster contains:- A Redis Pod that gathers metrics on path`/`and port`8070`\n- Prometheus-based collectors that process the metrics from the Redis Pod\n- A`PodMonitoring`resource that sends metrics to Cloud Monitoring\nThe Redis Enterprise operator exposes cluster metrics in Prometheus format.- Create the metrics-proxy Deployment:```\nkubectl apply -n rec-ns -f manifests/02-prometheus-metrics/metrics-proxy.yaml\n```Because the operator only provides an HTTPS endpoint with the self-signed certificate and the `PodMonitoring` resource doesn't support disabling TLS certificate verification, you use the `metrics-proxy` Pod as a reverse proxy for this endpoint to expose the metrics on the HTTP port.\n- Create the [PodMonitoring](/stackdriver/docs/managed-prometheus/setup-managed#gmp-pod-monitoring) resource to scrape metrics by `labelSelector` :```\nkubectl apply -n rec-ns -f manifests/02-prometheus-metrics/pod-monitoring.yaml\n```\n- In the Google Cloud console, go to the **GKE Clusters Dashboard** page. [Go to GKE Clusters Dashboard](https://console.cloud.google.com/monitoring/dashboards/resourceList/gmp_gke_cluster) The dashboard shows non-zero metrics ingestion rate.\n### Create a DashboardYou can view the metrics by creating a dashboard.- Create the dashboard:```\ngcloud --project \"${PROJECT_ID}\" monitoring dashboards create --config-from-file monitoring/dashboard.json\n```The output is similar to the following:```\nCreated [f4efbe4e-2605-46b4-9910-54b13d29b3be].\n```\n- In the Google Cloud console, go to the **Dashboards** page. [Go to Dashboards](https://console.cloud.google.com/monitoring/dashboards) \n- Open the **Redis Enterprise Cluster dashboard** . It might take several minutes for the dashboard to auto-provision.\n### Verify the exported metricsTo verify the metrics, create new database and examine the metrics.- Open the **Redis Enterprise Cluster dashboard** .\n- Create an additional Redis database:```\nkubectl apply -n rec-ns -f manifests/02-prometheus-metrics/c-rdb.yaml\n```The **Database Count** on the dashboard should update.\n- Create a client Pod to connect to the new database:```\nkubectl apply -n rec-ns -f manifests/02-prometheus-metrics/client_pod.yaml\n```\n- Connect to the client Pod and prepare variables:```\nkubectl exec -it redis-client-c -n rec-ns -- /bin/bash\n```\n- Use the `redis-cli` tool to create new keys:```\nfor i in {1..50}; do \\\u00a0 redis-cli -h $SERVICE -p $PORT -a $PASS \\\u00a0 --no-auth-warning SET mykey-$i \"myvalue-$i\"; \\done\n```\n- Refresh the page and observe that graphs have been updated to show the actual database state.\n- Exit the Pod shell```\nexit\n```\n## Clean up\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- Delete a Google Cloud project:\n- ```\ngcloud projects delete PROJECT_ID\n```\n### Delete individual resources\n- Set environment variables.```\nexport PROJECT_ID=${PROJECT_ID}export KUBERNETES_CLUSTER_PREFIX=redisexport REGION=us-central1\n```\n- Run the `terraform destroy` command:```\nexport GOOGLE_OAUTH_ACCESS_TOKEN=$(gcloud auth print-access-token)cd terraform/gke-standardterraform destroy -var project_id=${PROJECT_ID} \u00a0 \\\u00a0 -var region=${REGION} \u00a0\\\u00a0 -var cluster_prefix=${KUBERNETES_CLUSTER_PREFIX}\n```When prompted, type `yes` .\n- Find all unattached disks:```\nexport disk_list=$(gcloud compute disks list --filter=\"-users:* AND labels.name=${KUBERNETES_CLUSTER_PREFIX}-cluster\" --format \"value[separator=|](name,zone)\")\n```\n- Delete the disks:```\nfor i in $disk_list; do\u00a0 disk_name=$(echo $i| cut -d'|' -f1)\u00a0 disk_zone=$(echo $i| cut -d'|' -f2|sed 's|.*/||')\u00a0 echo \"Deleting $disk_name\"\u00a0 gcloud compute disks delete $disk_name --zone $disk_zone --quietdone\n```\n- Delete the GitHub repository:```\nrm -r ~/kubernetes-engine-samples/\n```\n## What's next\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Google Kubernetes Engine (GKE)"}