{"title": "Google Kubernetes Engine (GKE) - GKE cluster architecture", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture", "abstract": "# Google Kubernetes Engine (GKE) - GKE cluster architecture\nThis page introduces the architecture of a Google Kubernetes Engine (GKE) cluster. Your containerized Kubernetes workloads all run in a GKE cluster.\nA GKE cluster consists of a and worker machines called . The control plane and nodes make up the [Kubernetes](https://kubernetes.io) cluster orchestration system. GKE Autopilot manages the entire underlying infrastructure of clusters, including the control plane, nodes, and all system components. If you use GKE Standard mode, GKE manages the control plane and system components, and you manage the nodes. The following diagram shows the architecture of a GKE cluster:\n", "content": "## About the control plane\nThe control plane runs processes such as the Kubernetes API server, scheduler, and core resource controllers. GKE manages the control plane lifecycle from cluster creation to deletion. This includes upgrades to the Kubernetes version running on the control plane, which GKE performs automatically, or manually at your request if you prefer to upgrade earlier than the automatic schedule.\n### Control plane and the Kubernetes API\nThe control plane is the unified endpoint for your cluster. You interact with the control plane through Kubernetes API calls. The control plane runs the Kubernetes API server process ( `kube-apiserver` ) to handle API requests. You can make Kubernetes API calls in the following ways:\n- Direct calls: HTTP/gRPC\n- Indirect calls: Kubernetes command-line clients such as`kubectl`, or the Google Cloud console.\nThe API server process is the hub for all communication for the cluster. All internal cluster components such as nodes, system processes, and application controllers act as clients of the API server.\nYour API requests tell Kubernetes what your is for the objects in your cluster. Kubernetes attempts to constantly maintain that state. Kubernetes lets you configure objects in the API either or .\nTo learn more about object management in Kubernetes, refer to the following pages:\n- [Understanding Kubernetes objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/) \n- [Kubernetes object management](https://kubernetes.io/docs/concepts/overview/working-with-objects/object-management/) \n### Control plane and node interaction\nThe control plane manages what runs on all of the cluster's nodes. The control plane schedules workloads and manages the workloads' lifecycle, scaling, and upgrades. The control plane also manages network and storage resources for those workloads. The control plane and nodes communicate with each other using Kubernetes APIs.\n### Control plane interactions with Artifact Registry\nWhen you create or update a cluster, GKE pulls container images for the Kubernetes system software running on the control plane and nodes from the `pkg.dev` Artifact Registry or the `gcr.io` Container Registry. An outage affecting these registries might cause the following actions to fail:\n- New cluster creation\n- Cluster version upgrades\nDisruptions to workloads might occur even without your intervention, depending on the specific nature and duration of the outage.\nIf the `pkg.dev` Artifact Registry or the `gcr.io` Container Registry outage is regional, we might redirect requests to a zone or region that isn't affected by the outage.\nTo check the status of Google Cloud services, go to the [Google Cloud status dashboard](https://status.cloud.google.com/) .\n**Note:** Container Registry is deprecated and scheduled for shutdown. Organizations that haven't used Container Registry prior to January 8, 2024 have new gcr.io repositories hosted on Artifact Registry by default. After May 15, 2024, Google Cloud projects without previous usage of Container Registry will only support hosting and managing images for the `gcr.io` domain in [Artifact Registry](/artifact-registry/docs) .Container Registry is scheduled for shutdown on March 18, 2025. For details on the deprecation, see [Container Registry deprecation](/container-registry/docs/deprecations/container-registry-deprecation) .\n## About the nodes\nNodes are the worker machines that run your containerized applications and other workloads. The individual machines are [Compute Engine virtual machines (VMs)](/compute/docs/instances) that GKE creates. The control plane manages and receives updates on each node's self-reported status.\nA node runs the services necessary to support the containers that make up your cluster's workloads. These include the runtime and the Kubernetes node agent ( `kubelet` ), which communicates with the control plane and is responsible for starting and running containers scheduled on the node.\nGKE also runs a number of system containers that run as per-node agents, called DaemonSets, that provide functionality such as log collection and intra-cluster network connectivity.\n[mode of operation](/kubernetes-engine/docs/concepts/choose-cluster-mode)\n| Node component    | Autopilot mode                                          | Standard mode                                                            |\n|:---------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Lifecycle     | Fully managed by GKE, including: Automatic upgrades Automatic repairs Health checks Automatic node scaling Node creation and deletion Resizing Labelling for workload separation. | GKE manages the following: Automatic upgrades Automatic repairs Health checks You can manage the following: Node automatic scaling configuration Manual version upgrades Configuration changes (such as labels and resizing) Node pool creation and deletion |\n| Visibility     | View nodes using kubectl. Underlying Compute Engine virtual machines not visible or accessible in the gcloud CLI or the Google Cloud console.          | View nodes using kubectl, the gcloud CLI, and the Google Cloud console. View and access underlying Compute Engine VMs.                                  |\n| Connectivity    | No direct connection to the underlying VMs.                                   | Connect to underlying VMs using SSH.                                                       |\n| Node operating system (OS) | Managed by GKE. All nodes use Container-Optimized OS with containerd (cos_containerd).                        | Choose an operating system for your nodes.                                                     |\n| Machine hardware selection | Request compute classes in Pods based on use case. GKE manages machine configuration, scheduling, quantity, and lifecycle.              | Choose and configure Compute Engine machine types when creating node pools. Configure settings for sizing, scaling, quantity, scheduling, and location based on need.                      |", "guide": "Google Kubernetes Engine (GKE)"}