{"title": "Google Kubernetes Engine (GKE) - Optimize Pod autoscaling based on metrics", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics", "abstract": "# Google Kubernetes Engine (GKE) - Optimize Pod autoscaling based on metrics\nThis tutorial demonstrates how to automatically scale your Google Kubernetes Engine (GKE) workloads based on metrics available in\n [Cloud Monitoring](/monitoring) \n.\nIn this tutorial, you can set up autoscaling based on one of four different metrics:\n **CPU utilization** \nScale based on the percent utilization of CPUs across nodes. This can be cost effective, letting you maximize CPU resource utilization. Because CPU usage is a trailing metric, however, your users might experience latency while a scale-up is in progress.\n **Pub/Sub backlog** \nScale based on the number of unacknowledged messages remaining in a [Pub/Sub subscription](/pubsub/docs/subscriber) . This can effectively reduce latency before it becomes a problem, but might use relatively more resources than autoscaling based on CPU utilization.\n **Custom Cloud Monitoring metric** \nScale based on a custom user-defined metric exported by the [Cloud Monitoring client libraries](/monitoring/docs/reference/libraries) . To learn more, refer to [Creating custom metrics](/monitoring/custom-metrics/creating-metrics) in the Cloud Monitoring documentation.\n **Custom Prometheus Metric** \nScale based on a custom user-defined metric exported in the [Prometheus](https://prometheus.io/docs/instrumenting/exposition_formats/) format. Your Prometheus metric must be of type [Gauge](https://prometheus.io/docs/concepts/metric_types/#gauge) , and must not contain the `custom.googleapis.com` prefix.Autoscaling is fundamentally about finding an acceptable balance between cost and latency. You might want to experiment with a combination of these metrics [and others](/monitoring/api/metrics_kubernetes) to find a policy that works for you.", "content": "## Objectives\nThis tutorial covers the following tasks:\n- How to deploy the [Custom Metrics Adapter](https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter) .\n- How to export metrics from within your application code.\n- How to view your metrics on the Cloud Monitoring interface.\n- How to deploy a [HorizontalPodAutoscaler (HPA)](/kubernetes-engine/docs/concepts/horizontalpodautoscaler) resource to scale your application based on Cloud Monitoring metrics.\n## CostsIn this document, you use the following billable components of Google Cloud:- [GKE](/kubernetes-engine/pricing) \n- [Pub/Sub](/pubsub/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin\nTake the following steps to enable the Kubernetes Engine API:\n- Visit the [ Kubernetes Engine page](https://console.cloud.google.com/projectselector/kubernetes) in the Google Cloud console.\n- Create or select a project.\n- Wait for the API and related services to be enabled.  This can take several minutes.\n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\nYou can follow this tutorial using [Cloud Shell](/shell) , which comes preinstalled with the `gcloud` and `kubectl` command-line tools used in this tutorial. If you use Cloud Shell, you don't need to install these command-line tools on your workstation.\nTo use Cloud Shell:- Go to the [Google Cloud console](https://console.cloud.google.com/) .\n- Click the **Activate Cloud Shell** button at the top of the Google Cloud console window.A Cloud Shell session opens inside a new frame at the bottom of the Google Cloud console and displays a command-line prompt. \n### Setting up your environment\n- Set the default zone for the Google Cloud CLI:```\ngcloud config set compute/zone zone\n```Replace the following:- ``: Choose a zone that's closest to you. For more information, see [Regions and Zones](/compute/docs/regions-zones) .\n- Set the `PROJECT_ID` environment variable to your [Google Cloud project ID](/resource-manager/docs/creating-managing-projects#identifying_projects) ( ):```\nexport PROJECT_ID=project-id\n```\n- Set the default zone for the Google Cloud CLI:```\ngcloud config set project $PROJECT_ID\n```\n- Create a GKE [cluster](/kubernetes-engine/docs/clusters) ```\ngcloud container clusters create metrics-autoscaling\n``` **Note:** This tutorial is specific to clusters which have [workload identity federation for GKE](/kubernetes-engine/docs/how-to/workload-identity)  . If your cluster has workload identity federation for GKE you will have to execute additional steps as explained in this [GitHub page](https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter#configure-cluster) ## Deploying the Custom Metrics AdapterThe [Custom Metrics Adapter](https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter) lets your cluster send and receive metrics with Cloud Monitoring.\nNot applicable: Horizontal Pod Autoscalers can scale based on CPU utilization natively, so the Custom Metrics Adapter is not needed.\nGrant your user the ability to create required authorization roles:\n```\nkubectl create clusterrolebinding cluster-admin-binding \\\u00a0 \u00a0 --clusterrole cluster-admin --user \"$(gcloud config get-value account)\"\n```\nDeploy the **new resource model** adapter on your cluster:\n```\nkubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/k8s-stackdriver/master/custom-metrics-stackdriver-adapter/deploy/production/adapter_new_resource_model.yaml\n```\nGrant your user the ability to create required authorization roles:\n```\nkubectl create clusterrolebinding cluster-admin-binding \\\u00a0 \u00a0 --clusterrole cluster-admin --user \"$(gcloud config get-value account)\"\n```\nDeploy the **resource model** adapter on your cluster:\n```\nkubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/k8s-stackdriver/master/custom-metrics-stackdriver-adapter/deploy/production/adapter_new_resource_model.yaml\n```\nGrant your user the ability to create required authorization roles:\n```\nkubectl create clusterrolebinding cluster-admin-binding \\\u00a0 \u00a0 --clusterrole cluster-admin --user \"$(gcloud config get-value account)\"\n```\nDeploy the **legacy resource model** adapter on your cluster:\n```\nkubectl apply -f https://raw.githubusercontent.com/GoogleCloudPlatform/k8s-stackdriver/master/custom-metrics-stackdriver-adapter/deploy/production/adapter.yaml\n```\n **Note:** There are two versions of the adapter: the legacy model and the new resource model. More information can be found on the adapter's [GitHub page](https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter#configure-cluster) ## Deploying an application with metricsDownload the repo containing the application code for this tutorial:\n```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples.gitcd kubernetes-engine-samples/quickstarts/hello-app\n```\n```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples.gitcd kubernetes-engine-samples/databases/cloud-pubsub\n```\n```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples.gitcd kubernetes-engine-samples/observability/custom-metrics-autoscaling/direct-to-sd\n```\n```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples.gitcd kubernetes-engine-samples/observability/custom-metrics-autoscaling/prometheus-to-sd\n```The repo contains code that exports metrics to Cloud Monitoring:\nThis application responds \"Hello, world!\" to any web requests on port `8080` . [Compute Engine](/compute/docs) CPU metrics are automatically collected by Cloud Monitoring.\n [  quickstarts/hello-app/main.go ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app/main.go) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app/main.go) \n```\npackage mainimport (\u00a0 \u00a0 \u00a0 \u00a0 \"fmt\"\u00a0 \u00a0 \u00a0 \u00a0 \"log\"\u00a0 \u00a0 \u00a0 \u00a0 \"net/http\"\u00a0 \u00a0 \u00a0 \u00a0 \"os\")func main() {\u00a0 \u00a0 \u00a0 \u00a0 // register hello function to handle all requests\u00a0 \u00a0 \u00a0 \u00a0 mux := http.NewServeMux()\u00a0 \u00a0 \u00a0 \u00a0 mux.HandleFunc(\"/\", hello)\u00a0 \u00a0 \u00a0 \u00a0 // use PORT environment variable, or default to 8080\u00a0 \u00a0 \u00a0 \u00a0 port := os.Getenv(\"PORT\")\u00a0 \u00a0 \u00a0 \u00a0 if port == \"\" {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 port = \"8080\"\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 // start the web server on port and accept requests\u00a0 \u00a0 \u00a0 \u00a0 log.Printf(\"Server listening on port %s\", port)\u00a0 \u00a0 \u00a0 \u00a0 log.Fatal(http.ListenAndServe(\":\"+port, mux))}// hello responds to the request with a plain-text \"Hello, world\" message.func hello(w http.ResponseWriter, r *http.Request) {\u00a0 \u00a0 \u00a0 \u00a0 log.Printf(\"Serving request: %s\", r.URL.Path)\u00a0 \u00a0 \u00a0 \u00a0 host, _ := os.Hostname()\u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Hello, world!\\n\")\u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Version: 1.0.0\\n\")\u00a0 \u00a0 \u00a0 \u00a0 fmt.Fprintf(w, \"Hostname: %s\\n\", host)}\n```\nThis application polls a [Pub/Sub subscription](/pubsub/docs/subscriber) for new messages, acknowledging them as they arrive. Pub/Sub subscription metrics are automatically collected by Cloud Monitoring.\n [  databases/cloud-pubsub/main.py ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/cloud-pubsub/main.py) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/cloud-pubsub/main.py) \n```\nfrom google import authfrom google.cloud import pubsub_v1def main():\u00a0 \u00a0 \"\"\"Continuously pull messages from subsciption\"\"\"\u00a0 \u00a0 # read default project ID\u00a0 \u00a0 _, project_id = auth.default()\u00a0 \u00a0 subscription_id = 'echo-read'\u00a0 \u00a0 subscriber = pubsub_v1.SubscriberClient()\u00a0 \u00a0 subscription_path = subscriber.subscription_path(\u00a0 \u00a0 \u00a0 \u00a0 project_id, subscription_id)\u00a0 \u00a0 def callback(message: pubsub_v1.subscriber.message.Message) -> None:\u00a0 \u00a0 \u00a0 \u00a0 \"\"\"Process received message\"\"\"\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Received message: ID={message.message_id} Data={message.data}\")\u00a0 \u00a0 \u00a0 \u00a0 print(f\"[{datetime.datetime.now()}] Processing: {message.message_id}\")\u00a0 \u00a0 \u00a0 \u00a0 time.sleep(3)\u00a0 \u00a0 \u00a0 \u00a0 print(f\"[{datetime.datetime.now()}] Processed: {message.message_id}\")\u00a0 \u00a0 \u00a0 \u00a0 message.ack()\u00a0 \u00a0 streaming_pull_future = subscriber.subscribe(\u00a0 \u00a0 \u00a0 \u00a0 subscription_path, callback=callback)\u00a0 \u00a0 print(f\"Pulling messages from {subscription_path}...\")\u00a0 \u00a0 with subscriber:\u00a0 \u00a0 \u00a0 \u00a0 try:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 streaming_pull_future.result()\u00a0 \u00a0 \u00a0 \u00a0 except Exception as e:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(e)\n```\nThis application exports a constant value metric using the [Cloud Monitoring client libraries](/monitoring/docs/reference/libraries) .\n [  observability/custom-metrics-autoscaling/direct-to-sd/sd_dummy_exporter.go ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/direct-to-sd/sd_dummy_exporter.go) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/direct-to-sd/sd_dummy_exporter.go) \n```\nfunc exportMetric(stackdriverService *monitoring.Service, metricName string,\u00a0 \u00a0 \u00a0 \u00a0 metricValue int64, metricLabels map[string]string, monitoredResource string, resourceLabels map[string]string) error {\u00a0 \u00a0 \u00a0 \u00a0 dataPoint := &monitoring.Point{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Interval: &monitoring.TimeInterval{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 EndTime: time.Now().Format(time.RFC3339),\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Value: &monitoring.TypedValue{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Int64Value: &metricValue,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 // Write time series data.\u00a0 \u00a0 \u00a0 \u00a0 request := &monitoring.CreateTimeSeriesRequest{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 TimeSeries: []*monitoring.TimeSeries{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Metric: &monitoring.Metric{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Type: \u00a0 \"custom.googleapis.com/\" + metricName,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Labels: metricLabels,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Resource: &monitoring.MonitoredResource{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Type: \u00a0 monitoredResource,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Labels: resourceLabels,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Points: []*monitoring.Point{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dataPoint,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 \u00a0 projectName := fmt.Sprintf(\"projects/%s\", resourceLabels[\"project_id\"])\u00a0 \u00a0 \u00a0 \u00a0 _, err := stackdriverService.Projects.TimeSeries.Create(projectName, request).Do()\u00a0 \u00a0 \u00a0 \u00a0 return err}\n```\nThis application exports a constant value metric using the [Prometheus](https://prometheus.io/docs/instrumenting/exposition_formats/) format.\n [  observability/custom-metrics-autoscaling/prometheus-to-sd/prometheus_dummy_exporter.go ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/prometheus-to-sd/prometheus_dummy_exporter.go) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/prometheus-to-sd/prometheus_dummy_exporter.go) \n```\nmetric := prometheus.NewGauge(\u00a0 \u00a0 \u00a0 \u00a0 prometheus.GaugeOpts{\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Name: *metricName,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Help: \"Custom metric\",\u00a0 \u00a0 \u00a0 \u00a0 },)prometheus.MustRegister(metric)metric.Set(float64(*metricValue))http.Handle(\"/metrics\", promhttp.Handler())log.Printf(\"Starting to listen on :%d\", *port)err := http.ListenAndServe(fmt.Sprintf(\":%d\", *port), nil)\n```\nThe repo also contains a Kubernetes manifest to deploy the application to your cluster: [  quickstarts/hello-app/manifests/helloweb-deployment.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app/manifests/helloweb-deployment.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app/manifests/helloweb-deployment.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: helloweb\u00a0 labels:\u00a0 \u00a0 app: hellospec:\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: hello\u00a0 \u00a0 \u00a0 tier: web\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: hello\u00a0 \u00a0 \u00a0 \u00a0 tier: web\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: hello-app\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8080\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 200m\n``` [  databases/cloud-pubsub/deployment/pubsub-with-secret.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/cloud-pubsub/deployment/pubsub-with-secret.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/cloud-pubsub/deployment/pubsub-with-secret.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: pubsubspec:\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: pubsub\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: pubsub\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 - name: google-cloud-key\u00a0 \u00a0 \u00a0 \u00a0 secret:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 secretName: pubsub-key\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: subscriber\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/pubsub-sample:v2\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - name: google-cloud-key\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mountPath: /var/secrets/google\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: GOOGLE_APPLICATION_CREDENTIALS\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: /var/secrets/google/key.json\n``` [  observability/custom-metrics-autoscaling/direct-to-sd/custom-metrics-sd.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/direct-to-sd/custom-metrics-sd.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/direct-to-sd/custom-metrics-sd.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 labels:\u00a0 \u00a0 run: custom-metric-sd\u00a0 name: custom-metric-sd\u00a0 namespace: defaultspec:\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 run: custom-metric-sd\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 run: custom-metric-sd\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - command: [\"./sd-dummy-exporter\"]\u00a0 \u00a0 \u00a0 \u00a0 args:\u00a0 \u00a0 \u00a0 \u00a0 - --use-new-resource-model=true\u00a0 \u00a0 \u00a0 \u00a0 - --use-old-resource-model=false\u00a0 \u00a0 \u00a0 \u00a0 - --metric-name=custom-metric\u00a0 \u00a0 \u00a0 \u00a0 - --metric-value=40\u00a0 \u00a0 \u00a0 \u00a0 - --pod-name=$(POD_NAME)\u00a0 \u00a0 \u00a0 \u00a0 - --namespace=$(NAMESPACE)\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/sd-dummy-exporter:v0.3.0\u00a0 \u00a0 \u00a0 \u00a0 name: sd-dummy-exporter\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 100m\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 # save Kubernetes metadata as environment variables for use in metrics\u00a0 \u00a0 \u00a0 \u00a0 - name: POD_NAME\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valueFrom:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldRef:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 apiVersion: v1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldPath: metadata.name\u00a0 \u00a0 \u00a0 \u00a0 - name: NAMESPACE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valueFrom:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldRef:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 apiVersion: v1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldPath: metadata.namespace\n``` [  observability/custom-metrics-autoscaling/prometheus-to-sd/custom-metrics-prometheus-sd.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/prometheus-to-sd/custom-metrics-prometheus-sd.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/prometheus-to-sd/custom-metrics-prometheus-sd.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 labels:\u00a0 \u00a0 run: custom-metric-prometheus-sd\u00a0 name: custom-metric-prometheus-sd\u00a0 namespace: defaultspec:\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 run: custom-metric-prometheus-sd\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 run: custom-metric-prometheus-sd\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 # sample container generating custom metrics\u00a0 \u00a0 \u00a0 - name: prometheus-dummy-exporter\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/prometheus-dummy-exporter:v0.2.0\u00a0 \u00a0 \u00a0 \u00a0 command: [\"./prometheus-dummy-exporter\"]\u00a0 \u00a0 \u00a0 \u00a0 args:\u00a0 \u00a0 \u00a0 \u00a0 - --metric-name=custom_prometheus\u00a0 \u00a0 \u00a0 \u00a0 - --metric-value=40\u00a0 \u00a0 \u00a0 \u00a0 - --port=8080\u00a0 \u00a0 \u00a0 # pre-built 'prometheus-to-sd' sidecar container to export prometheus\u00a0 \u00a0 \u00a0 # metrics to Stackdriver\u00a0 \u00a0 \u00a0 - name: prometheus-to-sd\u00a0 \u00a0 \u00a0 \u00a0 image: gcr.io/google-containers/prometheus-to-sd:v0.5.0\u00a0 \u00a0 \u00a0 \u00a0 command: [\"/monitor\"]\u00a0 \u00a0 \u00a0 \u00a0 args:\u00a0 \u00a0 \u00a0 \u00a0 - --source=:http://localhost:8080\u00a0 \u00a0 \u00a0 \u00a0 - --stackdriver-prefix=custom.googleapis.com\u00a0 \u00a0 \u00a0 \u00a0 - --pod-id=$(POD_ID)\u00a0 \u00a0 \u00a0 \u00a0 - --namespace-id=$(POD_NAMESPACE)\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 # save Kubernetes metadata as environment variables for use in metrics\u00a0 \u00a0 \u00a0 \u00a0 - name: POD_ID\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valueFrom:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldRef:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 apiVersion: v1\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldPath: metadata.uid\u00a0 \u00a0 \u00a0 \u00a0 - name: POD_NAMESPACE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valueFrom:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldRef:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 fieldPath: metadata.namespace\n```\nDeploy the application to your cluster:\n```\nkubectl apply -f manifests/helloweb-deployment.yaml\n```\nEnable the Pub/Sub API on your project:\n```\ngcloud services enable cloudresourcemanager.googleapis.com pubsub.googleapis.com\n```\nCreate a Pub/Sub topic and subscription:\n```\ngcloud pubsub topics create echogcloud pubsub subscriptions create echo-read --topic=echo\n```\nCreate a service account with access to Pub/Sub:\n```\ngcloud iam service-accounts create autoscaling-pubsub-sagcloud projects add-iam-policy-binding $PROJECT_ID \\\u00a0 --member \"serviceAccount:autoscaling-pubsub-sa@$PROJECT_ID.iam.gserviceaccount.com\" \\\u00a0 --role \"roles/pubsub.subscriber\"\n```\n **Note:** The above service account settings assumes that the cluster has [workload identity federation for GKE](/kubernetes-engine/docs/how-to/workload-identity)  . If your cluster has workload identity federation for GKE , there are additional service account specific steps to be executed as explained in this [GitHub page](https://github.com/GoogleCloudPlatform/k8s-stackdriver/tree/master/custom-metrics-stackdriver-adapter#configure-cluster) \nDownload the service account key file:\n```\ngcloud iam service-accounts keys create key.json \\\u00a0 --iam-account autoscaling-pubsub-sa@$PROJECT_ID.iam.gserviceaccount.com\n```\nImport the service account key to your cluster as a [Secret](https://kubernetes.io/docs/concepts/configuration/secret/) :\n```\nkubectl create secret generic pubsub-key --from-file=key.json=./key.json\n```\nDeploy the application to your cluster:\n```\nkubectl apply -f deployment/pubsub-with-secret.yaml\n```\n```\nkubectl apply -f custom-metrics-sd.yaml\n```\n```\nkubectl apply -f custom-metrics-prometheus-sd.yaml\n```After waiting a moment for the application to deploy, all Pods reach the `Ready` state:\n```\nkubectl get pods\n```\nOutput:\n```\nNAME      READY STATUS RESTARTS AGE\nhelloweb-7f7f7474fc-hzcdq 1/1  Running 0   10s\n```\n```\nkubectl get pods\n```\nOutput:\n```\nNAME      READY STATUS RESTARTS AGE\npubsub-8cd995d7c-bdhqz 1/1  Running 0   58s\n```\n```\nkubectl get pods\n```\nOutput:\n```\nNAME        READY STATUS RESTARTS AGE\ncustom-metric-sd-58dbf4ffc5-tm62v 1/1  Running 0   33s\n```\n```\nkubectl get pods\n```\nOutput:\n```\nNAME           READY STATUS RESTARTS AGE\ncustom-metric-prometheus-sd-697bf7c7d7-ns76p 2/2  Running 0   49s\n```## Viewing metrics on Cloud MonitoringAs your application runs, it writes your metrics to Cloud Monitoring.\nTo view the metrics for a monitored resource by using the Metrics Explorer, do the following:- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select **Metrics explorer** : [Go to Metrics explorer](https://console.cloud.google.com/monitoring/metrics-explorer) \n- In the **Metric** element, expand the **Select a metric** menu, and then  select a resource type and metric type. For example, to chart the CPU utilization of a  virtual machine, do the following:- (Optional) To reduce the menu's options, enter part of the metric name in the **Filter bar** . For this example, enter`utilization`.\n- In the **Active resources** menu, select **VM instance** .\n- In the **Active metric categories** menu, select **Instance** .\n- In the **Active metrics** menu, select **CPU utilization** and then   click **Apply** .- To filter which time series are displayed, use the [Filter element](/monitoring/charts/metrics-selector#filter-option) .\n- To combine time series, use the menus on the [Aggregation element](/monitoring/charts/metrics-selector#select_display) .  For example, to display the CPU utilization for your VMs, based on their zone, set the  first menu to **Mean** and the second menu to **zone** .All time series are displayed when the first menu of the **Aggregation** element  is set to **Unaggregated** . The default settings for the **Aggregation** element  are determined by the metric type you selected.\nThe resource type and metrics are the following:\n [Metrics Explorer](https://console.cloud.google.com/monitoring/metrics-explorer?pageState=%7B%22xyChart%22:%7B%22dataSets%22:%5B%7B%22timeSeriesFilter%22:%7B%22filter%22:%22metric.type%3D%5C%22compute.googleapis.com%2Finstance%2Fcpu%2Futilization%5C%22%20resource.type%3D%5C%22gce_instance%5C%22%22,%22minAlignmentPeriod%22:%2260s%22,%22unitOverride%22:%22ratio%22,%22aggregations%22:%5B%7B%22perSeriesAligner%22:%22ALIGN_MEAN%22,%22crossSeriesReducer%22:%22REDUCE_NONE%22,%22groupByFields%22:%5B%5D%7D,%7B%22crossSeriesReducer%22:%22REDUCE_NONE%22%7D%5D%7D,%22targetAxis%22:%22Y1%22,%22plotType%22:%22LINE%22%7D%5D,%22options%22:%7B%22mode%22:%22COLOR%22%7D,%22constantLines%22:%5B%5D,%22timeshiftDuration%22:%220s%22,%22y1Axis%22:%7B%22label%22:%22y1Axis%22,%22scale%22:%22LINEAR%22%7D%7D,%22isAutoRefresh%22:true,%22timeSelection%22:%7B%22timeRange%22:%221h%22%7D%7D) \nResource type: `gce_instance`\nMetric: `compute.googleapis.com/instance/cpu/utilization`\n [Metrics Explorer](https://console.cloud.google.com/monitoring/metrics-explorer?pageState=%7B%22xyChart%22:%7B%22dataSets%22:%5B%7B%22timeSeriesFilter%22:%7B%22filter%22:%22metric.type%3D%5C%22pubsub.googleapis.com%2Fsubscription%2Fnum_undelivered_messages%5C%22%20resource.type%3D%5C%22pubsub_subscription%5C%22%22,%22minAlignmentPeriod%22:%2260s%22,%22unitOverride%22:%221%22,%22aggregations%22:%5B%7B%22perSeriesAligner%22:%22ALIGN_MEAN%22,%22crossSeriesReducer%22:%22REDUCE_NONE%22,%22groupByFields%22:%5B%5D%7D,%7B%22crossSeriesReducer%22:%22REDUCE_NONE%22%7D%5D%7D,%22targetAxis%22:%22Y1%22,%22plotType%22:%22LINE%22%7D%5D,%22options%22:%7B%22mode%22:%22COLOR%22%7D,%22constantLines%22:%5B%5D,%22timeshiftDuration%22:%220s%22,%22y1Axis%22:%7B%22label%22:%22y1Axis%22,%22scale%22:%22LINEAR%22%7D%7D,%22isAutoRefresh%22:true,%22timeSelection%22:%7B%22timeRange%22:%221h%22%7D%7D) \nResource type: `pubsub_subscription`\nMetric: `pubsub.googleapis.com/subscription/num_undelivered_messages`\n [Metrics Explorer](https://console.cloud.google.com/monitoring/metrics-explorer?pageState=%7B%22xyChart%22:%7B%22dataSets%22:%5B%7B%22timeSeriesFilter%22:%7B%22filter%22:%22metric.type%3D%5C%22custom.googleapis.com%2Fcustom-metric%5C%22%20resource.type%3D%5C%22k8s_pod%5C%22%22,%22minAlignmentPeriod%22:%2260s%22,%22unitOverride%22:%221%22,%22aggregations%22:%5B%7B%22perSeriesAligner%22:%22ALIGN_MEAN%22,%22crossSeriesReducer%22:%22REDUCE_NONE%22,%22groupByFields%22:%5B%5D%7D,%7B%22crossSeriesReducer%22:%22REDUCE_NONE%22%7D%5D%7D,%22targetAxis%22:%22Y1%22,%22plotType%22:%22LINE%22%7D%5D,%22options%22:%7B%22mode%22:%22COLOR%22%7D,%22constantLines%22:%5B%5D,%22timeshiftDuration%22:%220s%22,%22y1Axis%22:%7B%22label%22:%22y1Axis%22,%22scale%22:%22LINEAR%22%7D%7D,%22isAutoRefresh%22:true,%22timeSelection%22:%7B%22timeRange%22:%221h%22%7D%7D) \nResource type: `k8s_pod`\nMetric: `custom.googleapis.com/custom-metric`\n [Metrics Explorer](https://console.cloud.google.com/monitoring/metrics-explorer?pageState=%7B%22xyChart%22:%7B%22dataSets%22:%5B%7B%22timeSeriesFilter%22:%7B%22filter%22:%22metric.type%3D%5C%22custom.googleapis.com%2Fcustom_prometheus%5C%22%20resource.type%3D%5C%22gke_container%5C%22%22,%22minAlignmentPeriod%22:%2260s%22,%22unitOverride%22:%221%22,%22aggregations%22:%5B%7B%22perSeriesAligner%22:%22ALIGN_MEAN%22,%22crossSeriesReducer%22:%22REDUCE_NONE%22,%22groupByFields%22:%5B%5D%7D,%7B%22crossSeriesReducer%22:%22REDUCE_NONE%22%7D%5D%7D,%22targetAxis%22:%22Y1%22,%22plotType%22:%22LINE%22%7D%5D,%22options%22:%7B%22mode%22:%22COLOR%22%7D,%22constantLines%22:%5B%5D,%22timeshiftDuration%22:%220s%22,%22y1Axis%22:%7B%22label%22:%22y1Axis%22,%22scale%22:%22LINEAR%22%7D%7D,%22isAutoRefresh%22:true,%22timeSelection%22:%7B%22timeRange%22:%221h%22%7D%7D) \nResource type: `gke_container`\nMetric: `custom.googleapis.com/custom_prometheus`\n **Note:** Depending on the metric, you might not see much activity on the Cloud Monitoring Metrics Explorer yet. Don't be surprised if your metric isn't updating.## Creating a HorizontalPodAutoscaler objectWhen you see your metric in Cloud Monitoring, you can deploy a `HorizontalPodAutoscaler` to resize your Deployment based on your metric. [  quickstarts/hello-app/manifests/helloweb-hpa.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app/manifests/helloweb-hpa.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app/manifests/helloweb-hpa.yaml) \n```\napiVersion: autoscaling/v2kind: HorizontalPodAutoscalermetadata:\u00a0 name: cpuspec:\u00a0 scaleTargetRef:\u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 name: helloweb\u00a0 minReplicas: 1\u00a0 maxReplicas: 5\u00a0 metrics:\u00a0 - type: Resource\u00a0 \u00a0 resource:\u00a0 \u00a0 \u00a0 name: cpu\u00a0 \u00a0 \u00a0 target:\u00a0 \u00a0 \u00a0 \u00a0 type: Utilization\u00a0 \u00a0 \u00a0 \u00a0 averageUtilization: 30\n``` [  databases/cloud-pubsub/deployment/pubsub-hpa.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/cloud-pubsub/deployment/pubsub-hpa.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/cloud-pubsub/deployment/pubsub-hpa.yaml) \n```\napiVersion: autoscaling/v2beta2kind: HorizontalPodAutoscalermetadata:\u00a0 name: pubsubspec:\u00a0 minReplicas: 1\u00a0 maxReplicas: 5\u00a0 metrics:\u00a0 - external:\u00a0 \u00a0 \u00a0 metric:\u00a0 \u00a0 \u00a0 \u00a0name: pubsub.googleapis.com|subscription|num_undelivered_messages\u00a0 \u00a0 \u00a0 \u00a0selector:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0matchLabels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0resource.labels.subscription_id: echo-read\u00a0 \u00a0 \u00a0 target:\u00a0 \u00a0 \u00a0 \u00a0 type: AverageValue\u00a0 \u00a0 \u00a0 \u00a0 averageValue: 2\u00a0 \u00a0 type: External\u00a0 scaleTargetRef:\u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 name: pubsub\n``` [  observability/custom-metrics-autoscaling/direct-to-sd/custom-metrics-sd-hpa.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/direct-to-sd/custom-metrics-sd-hpa.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/direct-to-sd/custom-metrics-sd-hpa.yaml) \n```\napiVersion: autoscaling/v2beta2kind: HorizontalPodAutoscalermetadata:\u00a0 name: custom-metric-sd\u00a0 namespace: defaultspec:\u00a0 scaleTargetRef:\u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 name: custom-metric-sd\u00a0 minReplicas: 1\u00a0 maxReplicas: 5\u00a0 metrics:\u00a0 - type: Pods\u00a0 \u00a0 pods:\u00a0 \u00a0 \u00a0 metric:\u00a0 \u00a0 \u00a0 \u00a0 name: custom-metric\u00a0 \u00a0 \u00a0 target:\u00a0 \u00a0 \u00a0 \u00a0 type: AverageValue\u00a0 \u00a0 \u00a0 \u00a0 averageValue: 20\n``` [  observability/custom-metrics-autoscaling/prometheus-to-sd/custom-metrics-prometheus-sd-hpa.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/prometheus-to-sd/custom-metrics-prometheus-sd-hpa.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/custom-metrics-autoscaling/prometheus-to-sd/custom-metrics-prometheus-sd-hpa.yaml) \n```\napiVersion: autoscaling/v2beta2kind: HorizontalPodAutoscalermetadata:\u00a0 name: custom-prometheus-hpa\u00a0 namespace: defaultspec:\u00a0 scaleTargetRef:\u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 name: custom-metric-prometheus-sd\u00a0 minReplicas: 1\u00a0 maxReplicas: 5\u00a0 metrics:\u00a0 - type: Pods\u00a0 \u00a0 pods:\u00a0 \u00a0 \u00a0 metric:\u00a0 \u00a0 \u00a0 \u00a0 name: custom_prometheus\u00a0 \u00a0 \u00a0 target:\u00a0 \u00a0 \u00a0 \u00a0 type: AverageValue\u00a0 \u00a0 \u00a0 \u00a0 averageValue: 20\n```\nDeploy the `HorizontalPodAutoscaler` to your cluster:\n```\nkubectl apply -f manifests/helloweb-hpa.yaml\n```\n```\nkubectl apply -f deployment/pubsub-hpa.yaml\n```\n```\nkubectl apply -f custom-metrics-sd-hpa.yaml\n```\n```\nkubectl apply -f custom-metrics-prometheus-sd-hpa.yaml\n```## Generating loadFor some metrics, you might need to generate load to watch the autoscaling:\nSimulate 10,000 requests to the `helloweb` server:\n```\n\u00a0kubectl exec -it deployments/helloweb -- /bin/sh -c \\\u00a0 \u00a0 \u00a0\"for i in $(seq -s' ' 1 10000); do wget -q -O- localhost:8080; done\"\n```\nPublish 200 messages to the Pub/Sub topic:\n```\nfor i in {1..200}; do gcloud pubsub topics publish echo --message=\"Autoscaling #${i}\"; done\n```\nNot Applicable: The code used in this sample exports a constant value of `40` for the custom metric. The HorizontalPodAutoscaler is set with a target value of `20` , so it attempts to scale up the Deployment automatically.\nNot Applicable: The code used in this sample exports a constant value of `40` for the custom metric. The HorizontalPodAutoscaler is set with a target value of `20` , so it attempts to scale up the Deployment automatically.\n **Note:** You might need to wait a couple minutes for the HorizontalPodAutoscaler to respond to the metric changes.## Observing HorizontalPodAutoscaler scaling upYou can check the current number of replicas of your Deployment by running:\n```\nkubectl get deployments\n```\nAfter giving some time for the metric to propagate, the Deployment creates five Pods to handle the backlog.\nYou can also inspect the state and recent activity of the HorizontalPodAutoscaler by running:\n```\nkubectl describe hpa\n```## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\nDelete your GKE cluster:\n```\n\u00a0gcloud container clusters delete metrics-autoscaling\n```- Clean up the Pub/Sub subscription and topic:```\ngcloud pubsub subscriptions delete echo-readgcloud pubsub topics delete echo\n```\n- Delete your GKE cluster:```\ngcloud container clusters delete metrics-autoscaling\n```\nDelete your GKE cluster:\n```\n\u00a0gcloud container clusters delete metrics-autoscaling\n```\nDelete your GKE cluster:\n```\n\u00a0gcloud container clusters delete metrics-autoscaling\n```## What's next\n- Learn more about [custom and external metrics for scaling workloads](/kubernetes-engine/docs/concepts/custom-and-external-metrics) .\n- Explore other [Kubernetes Engine tutorials](/kubernetes-engine/docs/tutorials) .", "guide": "Google Kubernetes Engine (GKE)"}