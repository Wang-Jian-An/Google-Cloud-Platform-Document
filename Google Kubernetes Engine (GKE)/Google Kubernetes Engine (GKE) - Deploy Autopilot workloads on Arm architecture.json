{"title": "Google Kubernetes Engine (GKE) - Deploy Autopilot workloads on Arm architecture", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/autopilot-arm-workloads", "abstract": "# Google Kubernetes Engine (GKE) - Deploy Autopilot workloads on Arm architecture\nThis page shows you how to configure your Google Kubernetes Engine (GKE) Autopilot deployments to request nodes that are backed by Arm architecture.\n", "content": "## About Arm architecture in Autopilot\nAutopilot clusters offer [compute classes](/kubernetes-engine/docs/concepts/autopilot-compute-classes) for workloads that have specific hardware requirements. Some of these compute classes support multiple CPU architectures, such as `amd64` and `arm64` .\n## Use cases for Arm nodes\nNodes with Arm architecture offer more cost-efficient performance than similar x86 nodes. You should select Arm for your Autopilot workloads in situations such as the following:\n- Your environment relies on Arm architecture for building and testing.\n- You're developing applications for Android devices that run on Arm CPUs.\n- You use multi-arch images and want to optimize costs while running your workloads.## How to request Arm nodes in Autopilot\nTo request Arm nodes for your Pods, you must request nodes with the Arm architecture and request a compute class that supports Arm nodes. The following sections show you how to request the compute class and Arm architecture using a node selector or a node affinity rule in your Pod specification.\nFor a list of compute classes that support Arm architecture, refer to [Compute classes in Autopilot](/kubernetes-engine/docs/concepts/autopilot-compute-classes) .\n## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n- [Ensure that you have a GKE Autopilot cluster](/kubernetes-engine/docs/how-to/creating-an-autopilot-cluster) running GKE version 1.24.1-gke.1400 or later. To set the version, use the`--cluster-version`flag in your [create](/sdk/gcloud/reference/container/clusters/create-auto#--cluster-version) or [upgrade](/sdk/gcloud/reference/container/clusters/upgrade#--cluster-version) command.\n- Ensure that you have quota for the`T2A`Compute Engine machine type.\n- Ensure that you have a Pod with a container image that's built for Arm architecture.## Request a compute class and Arm architecture\nTo tell Autopilot to place your Pods on a compute class that supports Arm architecture, specify **both** of the following labels in a [nodeSelector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector) or [node affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity) rule:\n```\ncloud.google.com/compute-class: COMPUTE_CLASS\nkubernetes.io/arch: arm64\n```\nReplace `` with the name of a compute class that supports the Arm architecture, such as `Scale-Out` .\nWhen you deploy your workload, Autopilot does the following:\n- Automatically provisions Arm nodes to run your Pods.\n- Automatically taints the new nodes to prevent non-Arm Pods from being scheduled on those nodes.\n- Automatically adds a toleration to your Arm Pods to allow scheduling on the new nodes.\nYou can also request Arm architecture for Spot Pods.\n## Example request for Arm architecture\nThe following example specifications show you how to use a node selector or a node affinity rule to request Arm architecture in Autopilot.\nThe following example manifest shows you how to request Arm nodes in a nodeSelector:\n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: nginx-armspec:\u00a0 replicas: 3\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: nginx-arm\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: nginx-arm\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/compute-class: Scale-Out\u00a0 \u00a0 \u00a0 \u00a0 kubernetes.io/arch: arm64\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: nginx-arm\u00a0 \u00a0 \u00a0 \u00a0 image: nginx\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 2000m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 2Gi\n```\nYou can use [node affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity) to request Arm nodes. You can also specify the type of node affinity to use:- `requiredDuringSchedulingIgnoredDuringExecution`: Must use the specified compute class and architecture.\n- `preferredDuringSchedulingIgnoredDuringExecution`: Use the specified compute class and architecture on a best-effort basis. For example, if an existing x86 node is allocatable, GKE places your Pod on the x86 node instead of provisioning a new Arm node. Unless you're using a multi-arch image manifest, your Pod will crash. We strongly recommend that you explicitly request the specific architecture that you want.\nThe following example manifest the `Scale-Out` class and Arm nodes:\n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: nginx-armspec:\u00a0 replicas: 3\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: nginx-arm\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: nginx-arm\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 terminationGracePeriodSeconds: 25\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: nginx-arm\u00a0 \u00a0 \u00a0 \u00a0 image: nginx\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 2000m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 2Gi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 1Gi\u00a0 \u00a0 \u00a0 affinity:\u00a0 \u00a0 \u00a0 \u00a0 nodeAffinity:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requiredDuringSchedulingIgnoredDuringExecution:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nodeSelectorTerms:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - matchExpressions:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - key: cloud.google.com/compute-class\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operator: In\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - Scale-Out\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - key: kubernetes.io/arch\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operator: In\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - arm64\n```\n## Recommendations\n- [Build and use multi-arch images](/kubernetes-engine/docs/how-to/build-multi-arch-for-arm) as part of your pipeline. Multi-arch images ensure that your Pods run even if they're placed on x86 nodes.\n- Explicitly request architecture and compute classes in your workload manifests. If you don't, Autopilot uses the default architecture of the selected compute class, which might not be Arm.## Availability\nYou can deploy Autopilot workloads on Arm architecture in the following Google Cloud regions:\n- us-central1\n- europe-west4\n- asia-southeast1## Troubleshooting\nFor common errors and troubleshooting information, refer to [Troubleshooting Arm workloads](/kubernetes-engine/docs/troubleshooting/troubleshooting-arm-workloads) .\n## What's next\n- [Learn more about Autopilot cluster architecture](/kubernetes-engine/docs/concepts/autopilot-architecture) .\n- [Learn about the lifecycle of Pods](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/) .\n- [Learn about the available Autopilot compute classes](/kubernetes-engine/docs/concepts/autopilot-compute-classes) .\n- [Read about the default, minimum, and maximum resource requests for eachplatform](/kubernetes-engine/docs/concepts/autopilot-resource-requests) .", "guide": "Google Kubernetes Engine (GKE)"}