{"title": "Google Kubernetes Engine (GKE) - Overview of deploying workloads", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/deploying-workloads-overview", "abstract": "# Google Kubernetes Engine (GKE) - Overview of deploying workloads\nYou can create these controller objects using the Kubernetes API or by using `kubectl` , a command-line interface to Kubernetes installed by [gcloud](/sdk/docs/overview) . Typically, you build a representation of your desired Kubernetes controller object as a YAML configuration file, and then use that file with the Kubernetes API or the `kubectl` command-line interface.\n", "content": "## Types of workloads\nKubernetes provides different kinds of controller objects that correspond to different kinds of workloads you can run. Certain controller objects are better suited to representing specific types of workloads. The following sections describe some common types of workloads and the Kubernetes controller objects you can create to run them on your cluster, including:\n- Stateless applications\n- Stateful applications\n- Batch jobs\n- Daemons\n### Stateless applications\nA [stateless application](/kubernetes-engine/docs/how-to/stateless-apps) does not preserve its state and saves no data to persistent storage \u2014 all user and session data stays with the client.\nSome examples of stateless applications include web frontends like [Nginx](https://www.nginx.com/resources/wiki/) , web servers like [Apache Tomcat](http://tomcat.apache.org/) , and other web applications.\nYou can create a Kubernetes [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) to deploy a stateless application on your cluster. Pods created by Deployments are not unique and do not preserve their state, which makes scaling and updating stateless applications easier.\n### Stateful applications\nA [stateful application](/kubernetes-engine/docs/how-to/stateful-apps) requires that its state be saved or persistent. Stateful applications use persistent storage, such as [persistent volumes](/kubernetes-engine/docs/concepts/persistent-volumes) , to save data for use by the server or by other users.\nExamples of stateful applications include databases like [MongoDB](https://www.mongodb.com/) and message queues like [Apache ZooKeeper](https://zookeeper.apache.org/) .\nYou can create a Kubernetes [StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) to deploy a stateful application. Pods created by StatefulSets have unique identifiers and can be updated in an ordered, safe way.\n### Batch jobs\nrepresent finite, independent, and often parallel tasks which run to their completion. Some examples of batch jobs include automatic or scheduled tasks like sending emails, rendering video, and performing expensive computations.\nYou can create a Kubernetes [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) to execute and manage a batch task on your cluster. You can specify the number of Pods that should complete their tasks before the Job is complete, as well as the maximum number of Pods that should run in parallel.\n### Daemons\nperform ongoing background tasks in their assigned nodes without the need for user intervention. Examples of daemons include log collectors like [Fluentd](https://www.fluentd.org/) and monitoring services.\nYou can create a Kubernetes [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) to deploy a daemon on your cluster. DaemonSets create one Pod per node, and you can choose a specific node to which the DaemonSet should deploy.\nGKE administers nodes in clusters that you create using the [Autopilot mode of operation](/kubernetes-engine/docs/concepts/autopilot-overview) . You cannot manually add, remove, or modify the nodes or the underlying Compute Engine virtual machines (VMs). However, the Kubernetes node object is still visible, and Autopilot supports DaemonSets as your workloads.\nGKE Autopilot limits some administrative functions that affect all workload Pods, including Pods managed by DaemonSets. DaemonSets that perform administrative functions on nodes using elevated privileges, such as the `privileged` security context, won't run on Autopilot clusters unless explicitly allowed by GKE.\nFor more information on the limits enforced by Autopilot, see [Workload limitations and restrictions](/kubernetes-engine/docs/concepts/autopilot-resource-requests) . You can use DaemonSets with workloads that meet the restrictions set by Autopilot, as well as DaemonSets from some Google Cloud [partners](/kubernetes-engine/docs/resources/autopilot-partners) .\nGKE uses the total size of your deployed workloads to determine the size of the nodes that Autopilot provisions for the cluster. If you add or resize a DaemonSet after Autopilot provisions a node, GKE won't resize existing nodes to accommodate the new total workload size. DaemonSets with resource requests larger than the allocatable capacity of existing nodes, after accounting for system pods, also won't get scheduled on those nodes.\nStarting in GKE version 1.27.6-gke.1248000, clusters in Autopilot mode detect nodes that can't fit all DaemonSets and, over time, migrate workloads to larger nodes that can fit all DaemonSets. This process takes some time, especially if the nodes run system Pods, which need extra time to gracefully terminate so that there's no disruption to core cluster capabilities.\nIn GKE version 1.27.5-gke.200 or earlier, we recommend [cordoning](https://kubernetes.io/docs/concepts/architecture/nodes/#manual-node-administration) and [draining](https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/) nodes that can't accommodate DaemonSet Pods.\nFor all GKE versions, we recommend the following best practices when deploying DaemonSets on Autopilot:\n- Deploy DaemonSets before any other workloads.\n- Set a higher [PriorityClass](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/) on DaemonSets than regular Pods. The higher PriorityClass lets GKE evict lower-priority Pods to accommodate DaemonSet pods if the node can accommodate those pods. This helps to ensure that the DaemonSet is present on each node without triggering node recreation.## Managing workload objects\nYou can create, manage, and delete objects using and methods. The following sections describe these methods as well as the following tools you can use to employ them:\n- [kubectl](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands) , the Kubernetes command-line tool installed with [gcloud CLI](/sdk/docs/overview) \n- [GKE Workloads menu](https://console.cloud.google.com/kubernetes/workload) in the Google Cloud console\n- The [GKE REST API](/kubernetes-engine/reference/rest) and the [Kubernetes API](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/) .\n### Imperative commands\n[Imperative commands](https://kubernetes.io/docs/tutorials/object-management-kubectl/imperative-object-management-command/) allow you to quickly create, view, update, and delete objects with `kubectl` . These commands are useful for one-off tasks or for making changes to active objects in a cluster. Imperative commands are commonly used to operate on live, deployed objects on your cluster.\n`kubectl` features several verb-driven commands for creating and editing Kubernetes objects. For example:\n- [run](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#run) : Generate a new object in the cluster. Unless otherwise specified,`run`creates a Deployment object.`run`also supports [several other generators](https://kubernetes.io/docs/user-guide/kubectl-conventions/#generators) .\n- [expose](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#expose) : Create a new Service object to load balance traffic across a set of labelled Pods.\n- [autoscale](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#autoscale) : Create a new Autoscaler object to automatically horizontally scale a controller object, such as a Deployment.\nImperative commands do not require strong understanding of object schema and do not require configuration files.\n### Imperative object configuration\n[Imperative object configuration](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/imperative-config/) creates, updates, and deletes objects using configuration files containing fully-defined object definitions. You can store object configuration files in source control systems and audit changes more easily than with imperative commands.\nYou can run [kubectl apply](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#apply) , [delete](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete) , and [replace](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#replace) operations with configuration files or directories containing configuration files.\n### Declarative object configuration\n[Declarative object configuration](https://kubernetes.io/docs/tutorials/object-management-kubectl/declarative-object-management-configuration/) operates on locally-stored configuration files but does not require explicit definition of the operations to be executed. Instead, operations are automatically detected per-object by `kubectl` . This is useful if you are working with a directory of configuration files with many different operations. Declarative object management requires a strong understanding of object schemas and configuration files.\nYou can run [kubectl apply](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#apply) to create and updates objects declaratively. `apply` updates objects by reading the whole live object, calculating the differences, then merging those differences by sending patch requests to the API server.\n### Public Docker Hub images\nWhen you deploy a public container image from Docker Hub, GKE automatically checks the caching proxy `mirror.gcr.io` for a cached copy of the container image. If a cached copy is unavailable, GKE pulls your requested image from Docker Hub and the caching proxy might cache the image for future use. For more information, see [Pulling cached images](/container-registry/docs/pulling-cached-images) .\n### Console\nAfter you have deployed a workload using `kubectl` or the API, you can use the [GKE Workloads menu](https://console.cloud.google.com/kubernetes/workload) in the Google Cloud console to inspect, manage, and edit workloads running on your clusters.\nThe menu offers the following features:\n- You can use the YAML-based text editor to edit live objects from your web browser\n- You can view detailed information about objects, including revision history, recent events and activities, and its managed Pods\n- You can easily scale Deployments, Jobs, and StatefulSets\n- You can autoscale, trigger rolling updates, and manually scale Deployments from the **Actions** menu.\n- You can use [Cloud Shell](/shell/docs) to inspect, edit, and delete any object.\n### API\nYou can use the [GKE REST API](/kubernetes-engine/reference/rest) and [Kubernetes API](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/) alongside the [Google Cloud Client Libraries](/apis/docs/cloud-client-libraries) to programmatically create and manage workloads.\n## Configuration files\nWhen you deploy a workload using any of the methods previously described, GKE adds a configuration file to your cluster that represents the object.\nAn object's might differ from its local file. [YAML](https://en.wikipedia.org/wiki/YAML) is most commonly used to create and represent Kubernetes objects. You can also use [JSON](https://en.wikipedia.org/wiki/JSON) .\nTo learn more about Kubernetes object specifications, statuses, and the Kubernetes API, refer to [Understanding Kubernetes Objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/) and [the Kubernetes API reference](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/) .\n### Inspecting live configurations\nTo inspect the live configuration of a deployed object, perform the following steps:- Go to the **Workloads** page in the Google Cloud console. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload) \n- Select the desired workload.\n- Click **YAML** .\nTo inspect the live configuration of a deployed object, run the following command:\n```\nkubectl get [OBJECT_TYPE] [OBJECT_NAME] -o yaml\n```\n might be `deployment` , `statefulset` , `job` , or other object type. For example:\n```\nkubectl get deployment my-stateless-app -o yaml\n```\n## Managing resource usage with quotas\nWhen many users or teams share the resources in your cluster, there's a concern that some could use more than their fair share. You can use the [KubernetesResourceQuota object](https://kubernetes.io/docs/concepts/policy/resource-quotas/) to limit resource consumption within specific namespaces.\nGKE also applies a default immutable [gke-resource-quotasobject](/kubernetes-engine/quotas#resource_quotas) to namespaces on clusters with 100 nodes or fewer to prevent instability.\n## What's next\n- [Learn more about deploying stateless applications](/kubernetes-engine/docs/how-to/stateless-apps) .\n- [Learn more about deploying stateful applications](/kubernetes-engine/docs/how-to/stateful-apps) .\n- [Learn about scaling applications](/kubernetes-engine/docs/how-to/scaling-apps) .\n- [Read about the cluster architecture](/kubernetes-engine/docs/concepts/cluster-architecture) .\n- [Learn more about managed continuous delivery using Cloud Deploy](/deploy/docs/overview) .", "guide": "Google Kubernetes Engine (GKE)"}