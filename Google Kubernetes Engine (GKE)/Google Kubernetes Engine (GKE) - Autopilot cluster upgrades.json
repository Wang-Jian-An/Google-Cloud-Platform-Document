{"title": "Google Kubernetes Engine (GKE) - Autopilot cluster upgrades", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-upgrades-autopilot", "abstract": "# Google Kubernetes Engine (GKE) - Autopilot cluster upgrades\nThis page discusses how automatic upgrades work on Google Kubernetes Engine (GKE) Autopilot clusters, including links to more information about related tasks and settings. You can use this information to keep your clusters updated for stability and security with minimal disruptions to your workloads.\n", "content": "## Automatic control plane and node upgrades\nAutomatic upgrades are enabled on all Autopilot clusters. GKE initiates automatic upgrades when GKE versions are [selected for auto-upgrade](#auto-upgrade-version-selection) , observes automatic upgrades across all clusters, and intervenes if problems such as unhealthy nodes occur.\nTo upgrade a cluster, GKE updates the version the control plane and nodes are running. Clusters are upgraded to either a newer minor version (for example, 1.24 to 1.25) or newer patch version (for example, 1.24.2-gke.100 to 1.24.5-gke.200). For more information, see [GKE versioning and support](/kubernetes-engine/versioning) .\nAll Autopilot clusters are enrolled in a [release channel](/kubernetes-engine/docs/concepts/release-channels) , so GKE automatically upgrades the control plane and nodes to run the same GKE version.\nGKE upgrades a cluster's [control plane](#cluster_upgrades) before upgrading [nodes](#node_pool_upgrades) .\n### Automatic control plane upgrades\nAll Autopilot clusters are [regional](/kubernetes-engine/docs/concepts/types-of-clusters#regional_clusters) clusters. Regional clusters have multiple replicas of the control plane, and only one replica is upgraded at a time, in an undefined order. This ensures that the cluster remains highly available during automatic upgrades. Each control plane replica is only unavailable while the upgrade is in progress.\nIf you configure a [maintenance window or exclusion](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) , GKE honors the configuration if possible.\nGKE can't create new nodes when a control plane upgrade is in progress in both Autopilot and Standard. If you deploy Autopilot Pods that require new node types while a control plane upgrade is in progress, you might experience delays until the control plane upgrade completes.\n### Automatic node upgrades\nAfter GKE upgrades your Autopilot cluster control plane, GKE upgrades the nodes to the same GKE version.\nIn Autopilot, GKE groups nodes that share similar characteristics together. GKE uses [surge upgrades](#surge) for Autopilot nodes, upgrading up to 20 nodes in a group at the same time. The precise number of nodes that are upgraded at the same time varies to ensure continued high availability of nodes and workloads.\nNode upgrades might take several hours depending on the number of nodes and the configuration of workloads running in the nodes. For example, the following configurations could contribute to longer upgrades:\n- A high value of [terminationGracePeriodSeconds](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#podtemplatespec-v1-core) in a Pod's configuration.\n- A conservative [PodDisruptionBudget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#how-disruption-budgets-work) .\n- [Node affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity) interactions.\n- Attached [PersistentVolumes](/kubernetes-engine/docs/concepts/persistent-volumes) .\nIf you configure a [maintenance window or exclusion](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) , GKE honors the configuration if possible.\nWhen GKE upgrades a node, the following steps happen:\n- GKE creates a newwith the new GKE version and waits for the surge node to register with the control plane.\n- GKE selects an existing node, the, to upgrade.\n- GKEthe target node, preventing new Pods from being placed on the target node.\n- GKEthe target node, evicting existing Pods from the target node.- [PodDisruptionBudget](https://kubernetes.io/docs/tasks/run-application/configure-pdb/) is respected for 1 hour.\n- [terminationGracePeriodSeconds](https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods) is limited to 1 hour.\n- GKE reschedules Pods that are managed by a [workload controller](https://kubernetes.io/docs/concepts/workloads/controllers/) onto other available nodes. Pods that can't be rescheduled remain in `PENDING` state until GKE can reschedule them. **Note:** If your target node has static Pods, those Pods aren't rescheduled and will be deleted with the target node.\n- GKE deletes the target node.\nIf a significant number of automatic upgrades to a specific GKE version result in unhealthy nodes across the GKE fleet, GKE stops upgrades to that version while we investigate the issue.\n### How versions are selected for auto-upgrade\nGKE releases new minor versions regularly, but a released version isn't immediately selected for automatic upgrades. To qualify as an auto-upgrade target, the GKE version must accumulate enough usage to prove stability over time.\nGoogle Cloud then selects that version as an auto-upgrade target for clusters that run a specific subset of older GKE versions. For example, soon after a new minor version becomes available, the oldest available minor version [typically becomes unsupported](/kubernetes-engine/versioning#lifecycle) . GKE upgrades clusters that run unsupported minor versions to the auto-upgrade target version.\nGKE announces new auto-upgrade target versions in the [release notes](/kubernetes-engine/docs/release-notes) . Occasionally, a version is selected for control plane auto-upgrades and node auto-upgrades during different weeks. GKE automatically upgrades to new patch releases within a minor version (such as v1.21.x).\nFor information about the version lifecycle and versioning scheme, refer to [GKE versioning and support](/kubernetes-engine/versioning) .\nTo ensure the stability and reliability of clusters on new versions, GKE follows certain practices during version rollouts.\nThese practices include, but are not limited to:\n- GKE gradually rolls out changes across Google Cloud regions and zones.\n- GKE gradually rolls out [patch versions](/kubernetes-engine/versioning#versioning_scheme) across [release channels](/kubernetes-engine/docs/concepts/release-channels) . A patch is given soak time in the Rapid release channel, then the Regular release channel, before being promoted to the Stable release channel once it has accumulated usage and continued to demonstrate stability. If an issue is found with a patch version during the soaking time on a release channel, that version is not promoted to the next channel and the issue is fixed on a newer patch version.\n- GKE gradually rolls out [minor versions](/kubernetes-engine/versioning#versioning_scheme) , following a similar soaking process to patch versions. Minor versions have longer soaking periods as they introduce more significant changes.\n- GKE may delay automatic upgrades when a new version impacts a group of clusters. For example, [GKE pausesautomatic upgrades](/kubernetes-engine/docs/deprecations#auto-upgrade-pause) for clusters that it detects are exposed to a deprecated API or feature that will be removed in the next minor version.\n- GKE might delay the rollout of new versions during peak times (for example, major holidays) to ensure business continuity.\n### Configuring when auto-upgrades can occur\nBy default, auto-upgrades can occur at any time. Auto-upgrades are minimally disruptive, especially for Autopilot clusters. However, some workloads might require finer-grained control. You can configure [maintenance windows and exclusions](/kubernetes-engine/docs/how-to/maintenance-windows-and-exclusions) to manage when auto-upgrades can and must not occur.\nIf you configure [maintenance windows and exclusions](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) , the upgrade does not occur until the current time is within a maintenance window. If a maintenance window expires before the upgrade completes, GKE attempts to pause the upgrade. GKE resumes the upgrade during the next available maintenance window.\n## Manually upgrade an Autopilot cluster\nYou can manually upgrade the GKE version of your Autopilot cluster control plane. GKE automatically upgrades your nodes to match the control plane version as soon as possible, subject to [maintenanceavailability](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) . For instructions, refer to [Manually upgrading the controlplane](/kubernetes-engine/docs/how-to/upgrading-a-cluster#upgrade_cp) . You can't manually manage the node version for Autopilot clusters.\nYou can upgrade the control plane version to a supported minor or patch version in the same release channel, or to a patch version of the same minor version as your cluster in a different release channel.\nFor example, consider an Autopilot cluster running GKE version 1.22.8-gke.202 in the Regular release channel. The following behavior applies:\n- You can upgrade to any version in Regular.\n- You can upgrade to any patch version of 1.22 in the Rapid channel.\nFor more information about upgrading outside your channel, refer to [Running patch versions from a newer channel](/kubernetes-engine/docs/concepts/release-channels#newer-patch-versions) .\n## Surge upgrades\nAutopilot clusters use to upgrade multiple nodes at the same time. Surge upgrades let GKE reduce how disruptive version upgrades are to your running workloads by maintaining enough compute capacity for your running workloads. Autopilot manages the number of that are added to the cluster during the upgrade. This number varies based on the total size of the cluster. GKE also manages the total number of that can be simultaneously unavailable during the upgrade.\nThe number of new surge nodes and unavailable target nodes varies to ensure that your cluster always has enough compute capacity for all running workloads. You might experience minor disruptions as GKE migrates workloads from target nodes to surge nodes during the upgrade.\nFor a description of how surge upgrades occur, refer to [Automatic node upgrades](#node_pool_upgrades) .\n### Quota requirements for surge upgrades\nUnlike node recreation, surge upgrades require additional Compute Engine resources. Resource allocation depends on your available [Compute Engine quota](/compute/quotas) . Depending on your configuration, this quota can limit the number of parallel upgrades or even cause the upgrade to fail. As a good practice to avoid scaling issues and for more predictable upgrades, ensure that your Compute Engine instance quota doesn't exceed 90%.\nFor more information about quota, refer to [Ensure resources for node upgrades](/kubernetes-engine/docs/how-to/node-upgrades-quota) .\n## Receive upgrade notifications\nGKE publishes upgrade notifications to [Pub/Sub](/pubsub/docs/overview) , providing you with a channel to receive information from GKE about your clusters.\nFor more information, see [Receiving cluster notifications](/kubernetes-engine/docs/how-to/cluster-notifications) .\n## Component upgrades\nGKE runs system workloads on worker nodes to support specific capabilities for clusters. For example, the `gke-metadata-server` system workload supports [workload identity federation for GKE](/kubernetes-engine/docs/how-to/workload-identity) . GKE is [responsible](/kubernetes-engine/docs/concepts/shared-responsibility#googles_responsibilities) for the health of these workloads. To learn more about these components, refer to the documentation for the associated capabilities.\nWhen new features or fixes become available for a component, GKE indicates the patch version in which they are included. To obtain the latest version of a component, refer to the associated documentation or [releasenotes](/kubernetes-engine/docs/release-notes) for instructions on upgrading your control plane or nodes to the appropriate version.\n## What's next\n- Configure [maintenance windows and exclusions](/kubernetes-engine/docs/how-to/maintenance-windows-and-exclusions) .\n- Learn about managing automatic cluster upgrades across environments with [rollout sequencing](/kubernetes-engine/docs/concepts/about-rollout-sequencing) .\n- Watch [GKE cluster upgrades: Best practices for GKE cluster stability, security, and performance](https://www.youtube.com/watch?v=RFp61C3YEXw)", "guide": "Google Kubernetes Engine (GKE)"}