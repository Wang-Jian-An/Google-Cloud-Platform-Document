{"title": "Google Kubernetes Engine (GKE) - Ensuring compatibility of webhook certificates before upgrading to v1.23", "url": "https://cloud.google.com/kubernetes-engine/docs/deprecations/webhookcompatibility", "abstract": "# Google Kubernetes Engine (GKE) - Ensuring compatibility of webhook certificates before upgrading to v1.23\nStarting from **version 1.23** , Kubernetes no longer supports server identity validation using the X.509 Common Name (CN) field in certificates. Instead, Kubernetes will only rely on information in the X.509 Subject Alternative Name (SAN) fields.\nTo prevent impact to your clusters, you must replace incompatible certificates without SANs for backends of webhooks and aggregated API servers before upgrading your clusters to Kubernetes **version 1.23** .\n**Note:** GKE only upgrades clusters on **version 1.22.6-gke.1000** or later if the clusters are not using webhook backends with incompatible certificates. Affected clusters will only be upgraded once the certificate(s) are replaced or when Kubernetes **version 1.22** reaches its [end of life](/kubernetes-engine/docs/release-schedule) date. If your cluster has an earlier version than **1.22.6-gke.1000** , you can temporarily prevent automatic minor upgrades by configuring a [maintenance exclusion](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#exclusions) .\n**Warning:** If you do not ensure compatibility of your certificates for Kubernetes **version 1.23** , cluster functionality might be impaired. GKE webhook and aggregated API server backends reliant on the CN field for server identity validation will fail due to authentication failure. The Kubernetes control plane will be unable to communicate with your webhooks. Depending on your configuration\u2014especially if you use Admission webhooks\u2014failure to contact a webhook might block resource (i.e. Pod) creation.\n", "content": "## Why Kubernetes no longer supports backend certificates without SANs\nGKE operates open-source Kubernetes, which uses the [kube-apiserver component](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/) to contact your webhook and aggregated API server backends using Transport Layer Security (TLS). The kube-apiserver component is written in the Go programming language.\nBefore Go 1.15, TLS clients validated the identity of the servers they connected to using a two-step process:\n- Check if the DNS name (or IP address) of the server is present as one of the SANs on the server's certificate.\n- As a fallback, check if the DNS name (or IP address) of the server is equal to the CN on the server's certificate.\n[RFC 6125](https://datatracker.ietf.org/doc/html/rfc6125) fully deprecated server identity validation based on the CN field in 2011. Browsers and other security-critical applications no longer use the field.\nTo align with the wider TLS ecosystem, [Go 1.15 removed Step 2](https://golang.org/doc/go1.15#commonname) from its validation process, but left a debug switch ( `x509ignoreCN=0` ) to enable the old behavior to ease the migration process. Kubernetes **version1.19** was the first version built using Go 1.15. GKE clusters on versions from 1.19 to 1.22 enabled the debug switch by default to provide customers with more time to replace the certificates for the affected webhook and aggregated API server backends.\nKubernetes **version 1.23** is built with Go 1.17, which [removes the debug switch](https://tip.golang.org/doc/go1.17#crypto/x509) . Once GKE upgrades your clusters to **version 1.23** , calls will fail to connect from your cluster's control plane to webhooks or aggregated API services that do not provide a valid X.509 certificate with appropriate SAN.\n## Identifying affected clusters\n### For clusters running patch versions at least 1.21.9 or 1.22.3\nFor clusters on patch versions 1.21.9 and 1.22.3 or later with Cloud Logging [enabled](/stackdriver/docs/solutions/gke/installing#installing) , GKE provides a [Cloud Audit Logs log](/kubernetes-engine/docs/how-to/audit-logging#viewing_your_projects_admin_activity_log) to identify calls to affected backends from your cluster. You can use the following filter to search for the logs:\n```\nlogName =~ \"projects/.*/logs/cloudaudit.googleapis.com%2Factivity\"\nresource.type = \"k8s_cluster\"\noperation.producer = \"k8s.io\"\n\"invalid-cert.webhook.gke.io\"\n```\nIf your clusters have not called backends with affected certificates, you won't see any logs. If you do see such an audit log, it will include the hostname of the affected backend.\nThe following is an example of the log entry, for a webhook backend hosted by a service named **example-webhook** in the **default** namespace:\n```\n{\u00a0 ...\u00a0 resource {\u00a0 \u00a0 type: \"k8s_cluster\",\u00a0 \u00a0 \"labels\": {\u00a0 \u00a0 \u00a0 \"location\": \"us-central1-c\",\u00a0 \u00a0 \u00a0 \"cluster_name\": \"example-cluster\",\u00a0 \u00a0 \u00a0 \"project_id\": \"example-project\"\u00a0 \u00a0 }\u00a0 },\u00a0 labels: {\u00a0 \u00a0 invalid-cert.webhook.gke.io/example-webhook.default.svc: \"No subjectAltNames returned from example-webhook.default.svc:8443\",\u00a0 \u00a0 ...\u00a0 },\u00a0 logName: \"projects/example-project/logs/cloudaudit.googleapis.com%2Factivity\",\u00a0 operation: {\u00a0 \u00a0 ...\u00a0 \u00a0 producer: \"k8s.io\",\u00a0 \u00a0 ...\u00a0 },\u00a0 ...}\n```\nThe hostnames of the affected services (e.g. `example-webhook.default.svc` ) are included as suffixes in the label names that start with `invalid-cert.webhook.gke.io/` . You can also get the name of the cluster that made the call from the `resource.labels.cluster_name` label, which has `example-cluster` value in this example.\n**Deprecation insights**\nYou can learn which clusters use incompatible certificates from [deprecation insights](/kubernetes-engine/docs/deprecations/viewing-deprecation-insights-and-recommendations) . Insights are available for clusters running version 1.22.6-gke.1000 or later.\n### Other cluster versions\nIf you have a cluster on a patch version earlier than 1.22.3 on the 1.22 minor version, or any patch version earlier than 1.21.9, you have two options for determining whether your cluster is affected by this deprecation:\n**Option 1** : [Upgrade](/kubernetes-engine/docs/how-to/upgrading-a-cluster) your cluster to a patch version that supports [identifying affected certificates with logs](#identifying-certificates-with-logs) . Make sure that Cloud Logging is [enabled](/stackdriver/docs/solutions/gke/installing#installing) for your cluster. After your cluster has been upgraded, the identifying Cloud Audit Logs logs will be produced each time the cluster attempts to call a Service that does not provide a certificate with an appropriate SAN. As the logs will only be produced on a call attempt, we recommend waiting for 30 days after an upgrade to make enough time for all call paths to be invoked.\nUsing logs to identify impacted services is recommended because this approach minimizes manual effort by automatically producing logs to show the affected services.\n**Option 2** : Inspect the certificates used by Webhooks or Aggregated API Servers in your clusters to determine whether they are affected because of not having SANs:\n- [Get the list](#identifying-services-to-inspect) of Webhooks and Aggregated API Servers in your cluster and identify their backends (Services or URLs).\n- [Inspect the certificates](#inspecting-certificate-of-service) used by the backend services.\nGiven the manual effort required to inspect all certificates in this way, this method should only be followed if you need to assess the impact of the deprecations in Kubernetes **version 1.23** before upgrading your cluster to **version 1.21** . If you can upgrade your cluster to 1.21, you should upgrade it first and then follow the instructions in Option 1 to avoid the manual effort.\n## Identifying backend services to inspect\nTo identify backends that might be affected by the deprecation, get the list of Webhooks and Aggregated API Services and their associated backends in the cluster.\nTo list all relevant webhooks in the cluster, use the following `kubectl` commands:\n```\nkubectl get mutatingwebhookconfigurations -A \u00a0 # mutating admission webhookskubectl get validatingwebhookconfigurations -A # validating admission webhooks\n```\nYou can get an associated backend Service or URL for a given Webhook by examining `clientConfig.service` [field](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#service-reference) or `webhooks.clientConfig.url` [field](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#url) in the Webhook's configuration:\n```\nkubectl get mutatingwebhookconfigurations example-webhook -o yaml\n```\nThe output of this command is similar to the following:\n```\napiVersion: admissionregistration.k8s.io/v1kind: MutatingWebhookConfigurationwebhooks:- admissionReviewVersions:\u00a0 clientConfig:\u00a0 \u00a0 service:\u00a0 \u00a0 \u00a0 \u00a0 name: example-service\u00a0 \u00a0 \u00a0 \u00a0 namespace: default\u00a0 \u00a0 \u00a0 \u00a0 port: 443\n```\nNote that clientConfig can specify its backend as a Kubernetes Service ( `clientConfig.service` ), or as a URL ( `clientConfig.url` ).\nTo list all relevant Aggregated API Services in the cluster, use the following `kubectl` command:\n```\nkubectl get apiservices -A |grep -v Local \u00a0 \u00a0 \u00a0# aggregated API services\n```\nThe output of this command is similar to the following:\n```\nNAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 SERVICE \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0AVAILABLE \u00a0 AGEv1beta1.metrics.k8s.io \u00a0 kube-system/metrics-server \u00a0 True \u00a0 \u00a0 \u00a0 \u00a0237d\n```\nThis example returns `metric-server` Service from the `kube-system` namespace.\nYou can get an associated Service for a given Aggregated API by examining `spec.service` field:\n```\nkubectl get apiservices v1beta1.metrics.k8s.io -o yaml\n```\nThe output of this command is similar to the following:\n```\n...apiVersion: apiregistration.k8s.io/v1kind: APIServicespec:\u00a0 service:\u00a0 \u00a0 name: metrics-server\u00a0 \u00a0 namespace: kube-system\u00a0 \u00a0 port: 443\n```\n### Inspecting the certificate of a Service\nOnce you have [identified](#identifying-services-to-inspect) relevant backend Services to inspect, you can inspect the certificate of each specific Service, such as `example-service` :\n- Find the selector and target port of the service:```\nkubectl describe service example-service\n```The output of this command is similar to the following:```\nName: example-serviceNamespace: defaultLabels: run=nginxSelector: run=nginxType: ClusterIPIP: 172.21.xxx.xxxPort: 443TargetPort: 444\n```In this example, `example-service` has the selector `run=nginx` and the target port `444` . **Note:** When absent, `TargetPort` is the same value as the `Port` field.\n- Find a pod matching the selector:```\nkubectl get pods --selector=run=nginx\n```The output of the command is similar to the following:```\nNAME \u00a0 \u00a0 \u00a0 \u00a0 \u00a0READY \u00a0 STATUS \u00a0 \u00a0RESTARTS \u00a0 AGEexample-pod \u00a0 1/1 \u00a0 \u00a0 Running \u00a0 0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a021m\n```\n- Set up a [port forward](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward) from your `kubectl` localhost to the pod.```\nkubectl port-forward pods/example-pod LOCALHOST_PORT:TARGET_PORT # port forwarding in background\n```Replace the following in the command:- ``: the address to listen on.\n- ``the`TargetPort`from Step 1.\n- Use `openssl` to print the certificate used by the Service:```\nopenssl s_client -connect localhost:LOCALHOST_PORT </dev/null | openssl x509 -noout -text\n```This example output shows a valid certificate (with SAN entries):```\nSubject: CN = example-service.default.svcX509v3 extensions:\u00a0 X509v3 Subject Alternative Name:\u00a0 \u00a0 DNS:example-service.default.svc\n```This example output shows a certificate with a missing SAN:```\nSubject: CN = example-service.default.svc\u00a0 X509v3 extensions:\u00a0 \u00a0 \u00a0 X509v3 Key Usage: critical\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Digital Signature, Key Encipherment\u00a0 \u00a0 \u00a0 X509v3 Extended Key Usage:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 TLS Web Server Authentication\u00a0 \u00a0 \u00a0 X509v3 Authority Key Identifier:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 keyid:1A:5F:29:D8:E9:3C:54:3C:35:CC:D8:AB:D1:21:FD:C3:56:25:C0:74\n```\n- Remove the port forward from running in the background with the following commands:```\n$ jobs\n[1]+ Running     kubectl port-forward pods/example-pod 8888:444 &\n$ kill %1\n[1]+ Terminated    kubectl port-forward pods/example 8888:444\n```\n### Inspecting the certificate of a URL backend\nIf the webhook uses a `url` [backend](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#url) , directly connect to the hostname specified in the URL. For example, if the URL is `https://example.com:123/foo/bar` , use the following `openssl` command to print the certificate used by the backend:\n```\n\u00a0 openssl s_client -connect example.com:123 </dev/null | openssl x509 -noout -text\n```\n## Mitigating the risk of 1.23 upgrade\nOnce you have [identified](#identifying-affected-clusters) affected clusters and their backend services using certificates without SANs, you must update the webhooks and aggregated API server backends to use certificates with appropriate SANs prior to upgrading the clusters to **version 1.23** .\nGKE will not automatically upgrade clusters on versions 1.22.6-gke.1000 or later with backends using incompatible certificates until you replace the certificates or until **version 1.22** reaches [end of life](/kubernetes-engine/docs/release-schedule) .\nIf your cluster is on a GKE version earlier than **1.22.6-gke.1000** , you can temporarily prevent automatic upgrades by configuring a [maintenance exclusion](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#x27;) to prevent minor upgrades.\n## Resources\nSee the following resources for additional information on this change:\n- [Kubernetes 1.23 release notes](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.23.md#urgent-upgrade-notes) - Kubernetes is built using Go 1.17. This version of Go removes the ability to use a`GODEBUG=x509ignoreCN=0`environment setting to re-enable deprecated legacy behavior of treating the CN of X.509 serving certificates as a host name.\n- [Kubernetes 1.19](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.19.md#api-change-5) and [Kubernetes 1.20](https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#api-change-10) release notes- The deprecated, legacy behavior of treating the CN field on X.509 serving certificates as a host name when no SANs are present is now disabled by default.\n- [Go 1.17 release notes](https://go.dev/doc/go1.17#crypto/x509) - The temporary`GODEBUG=x509ignoreCN=0`flag has been removed.\n- [Go 1.15 release notes](https://go.dev/doc/go1.15#commonname) - The deprecated, legacy behavior of treating the CN field on X.509 certificates as a host when no SANs are present is now disabled by default.\n- [RFC 6125](https://datatracker.ietf.org/doc/html/rfc6125#page-46) (page 46)- Although the use of the CN value is existing practice, it is deprecated, and Certificate Authorities are encouraged to provide`subjectAltName`values instead.\n- [Admission webhooks](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#contacting-the-webhook)", "guide": "Google Kubernetes Engine (GKE)"}