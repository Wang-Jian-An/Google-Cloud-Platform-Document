{"title": "Google Kubernetes Engine (GKE) - Deploy a batch system using Kueue", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/kueue-intro", "abstract": "# Google Kubernetes Engine (GKE) - Deploy a batch system using Kueue\nThis tutorial shows you how to deploy a batch system using\n [Kueue](https://kueue.sigs.k8s.io) \nto perform\n [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) \nqueueing on Google Kubernetes Engine (GKE). Complete this tutorial to learn how to set up GKE and Kueue to run Jobs in a first-in-first-out (FIFO) model.\n", "content": "## BackgroundJobs are applications that run to completion, such as machine learning, rendering, simulation, analytics, CI/CD, and similar workloads.\nKueue is a Cloud Native Job scheduler that works with the default Kubernetes scheduler, the Job controller, and the cluster autoscaler to provide an end-to-end batch system. Kueue implements Job queueing, deciding when Jobs should wait and when they should start, based on quotas and a hierarchy for sharing resources fairly among teams.\nKueue has the following characteristics:- It is optimized for cloud architectures, where resources are heterogeneous, interchangeable, and scalable.\n- It provides a set of APIs to manage elastic quotas and manage Job queueing.\n- It does not re-implement existing functionality such as autoscaling, pod scheduling, or Job lifecycle management.\n- Kueue has built-in support for the Kubernetes`batch/v1.Job`API.\n- It can integrate with other job APIs.\nKueue refers to jobs defined with any API as Workloads, to avoid the confusion with the specific Kubernetes Job API.## ObjectivesThis tutorial is for cluster operators and other users that want to implement a batch system on Kubernetes. In this tutorial, you set up a shared cluster for two tenant teams. Each team has their own namespace where they create Jobs and share the same global resources that are controlled with the corresponding quotas.\nThis tutorial covers the following steps:- Create a GKE cluster\n- Create the [ResourceFlavor](https://kueue.sigs.k8s.io/docs/concepts/resource_flavor/) \n- Create the [ClusterQueue](https://kueue.sigs.k8s.io/docs/concepts/cluster_queue/) \n- Create the [LocalQueue](https://kueue.sigs.k8s.io/docs/concepts/local_queue/) \n- Create Jobs and observe the admitted workloads\n## Costs\nThis tutorial uses the following billable components of Google Cloud:\n- [GKE](/kubernetes-engine/pricing) \nUse the [Pricing Calculator](/products/calculator) to generate a cost estimate based on your projected usage.\nWhen you finish this tutorial, avoid continued billing by deleting the resources you created. For more information, see [Clean up](#clean-up) .## Before you begin\n### Set up your project### Set defaults for the Google Cloud CLI\n- In the Google Cloud console, start a Cloud Shell instance:  [Open Cloud Shell](https://console.cloud.google.com/?cloudshell=true) \n- Download the source code for this sample app:```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samplescd kubernetes-engine-samples/batch/kueue-intro\n```\n- Set the default environment variables:```\ngcloud config set project PROJECT_IDgcloud config set compute/region COMPUTE_REGION\n```Replace the following values:- : your Google Cloud [project ID](/resource-manager/docs/creating-managing-projects#identifying_projects) .\n- : the [Compute Engine region](/compute/docs/regions-zones#available) .## Create a GKE cluster\n- Create a GKE Autopilot cluster named `kueue-autopilot` :```\ngcloud container clusters create-auto kueue-autopilot \\\u00a0 --release-channel \"rapid\" --region COMPUTE_REGION\n```Autopilot clusters are fully managed, and have built-in autoscaling. Learn more about [GKE Autopilot](/kubernetes-engine/docs/concepts/autopilot-overview) .Kueue also supports Standard GKE with Node Auto-provisioning and regular autoscaled node pools. **Note:** Autopilot cluster creation can take up to five minutes to complete.The outcome is similar to the following once the cluster is created:```\n NAME: kueue-autopilot\n LOCATION: us-central1\n MASTER_VERSION: 1.26.2-gke.1000\n MASTER_IP: 35.193.173.228\n MACHINE_TYPE: e2-medium\n NODE_VERSION: 1.26.2-gke.1000\n NUM_NODES: 3\n STATUS: RUNNING\n```Where the `STATUS` is `RUNNING` for the `kueue-autopilot` .\n- Get authentication credentials for the cluster:```\ngcloud container clusters get-credentials kueue-autopilot\n```\n- Install Kueue on the cluster:```\nVERSION=VERSIONkubectl apply --server-side -f \\\u00a0 https://github.com/kubernetes-sigs/kueue/releases/download/$VERSION/manifests.yaml\n```Replace with the latest version of Kueue. For more information about Kueue versions, see [Kueue releases](https://github.com/kubernetes-sigs/kueue/releases) .\n- Wait until the Kueue Pods are ready:```\nwatch kubectl -n kueue-system get pods\n```The output should be similar to the following before you can continue:```\nNAME          READY STATUS RESTARTS AGE\nkueue-controller-manager-66d8bb946b-wr2l2 2/2  Running 0   3m36s\n``` **Note:** This step may take up to three minutes.\n- Create two new namespaces called `team-a` and `team-b` :```\nkubectl create namespace team-akubectl create namespace team-b\n```\n## Create the ResourceFlavorA ResourceFlavor is an object that represents the variations in the nodes available in your cluster by associating them with node labels and taints. For example, you can use ResourceFlavors to represent VMs with different provisioning guarantees (for example, spot versus on-demand), architectures (for example, x86 versus ARM CPUs), brands and models (for example, Nvidia A100 versus T4 GPUs).\nIn this tutorial, the `kueue-autopilot` cluster has homogeneous resources. As a result, create a single ResourceFlavor for CPU, memory, ephemeral-storage, and GPUs, with no labels or taints.\n [  batch/kueue-intro/flavors.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/flavors.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/flavors.yaml) \n```\napiVersion: kueue.x-k8s.io/v1beta1kind: ResourceFlavormetadata:\u00a0 name: default-flavor # This ResourceFlavor will be used for all the resources\n```\nDeploy the ResourceFlavor:\n```\nkubectl apply -f flavors.yaml\n```## Create the ClusterQueueA ClusterQueue is a cluster-scoped object that manages a pool of resources such as CPU, memory, GPU. It manages the ResourceFlavors, and limits the usage and dictates the order in which workloads are admitted.\n [  batch/kueue-intro/cluster-queue.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/cluster-queue.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/cluster-queue.yaml) \n```\napiVersion: kueue.x-k8s.io/v1beta1kind: ClusterQueuemetadata:\u00a0 name: cluster-queuespec:\u00a0 namespaceSelector: {} # Available to all namespaces\u00a0 queueingStrategy: BestEffortFIFO # Default queueing strategy\u00a0 resourceGroups:\u00a0 - coveredResources: [\"cpu\", \"memory\", \"nvidia.com/gpu\", \"ephemeral-storage\"]\u00a0 \u00a0 flavors:\u00a0 \u00a0 - name: \"default-flavor\"\u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 - name: \"cpu\"\u00a0 \u00a0 \u00a0 \u00a0 nominalQuota: 10\u00a0 \u00a0 \u00a0 - name: \"memory\"\u00a0 \u00a0 \u00a0 \u00a0 nominalQuota: 10Gi\u00a0 \u00a0 \u00a0 - name: \"nvidia.com/gpu\"\u00a0 \u00a0 \u00a0 \u00a0 nominalQuota: 10\u00a0 \u00a0 \u00a0 - name: \"ephemeral-storage\"\u00a0 \u00a0 \u00a0 \u00a0 nominalQuota: 10Gi\n```\nDeploy the ClusterQueue:\n```\nkubectl apply -f cluster-queue.yaml\n```\nThe order of consumption is determined by `.spec.queueingStrategy` , where there are two configurations:- BestEffortFIFO- The default queueing strategy configuration.\n- The workload admission follows the first in first out (FIFO) rule, but if there is not enough quota to admit the workload at the head of the queue, the next one in line is tried.\n- StrictFIFO- Guarantees FIFO semantics.\n- Workload at the head of the queue can block queueing until the workload can be admitted.\nIn `cluster-queue.yaml` , you create a new ClusterQueue called `cluster-queue` . This ClusterQueue manages four resources, `cpu` , `memory` , `nvidia.com/gpu` and `ephemeral-storage` with the flavor created in `flavors.yaml` . The quota is consumed by the requests in the workload Pod specs.\nEach flavor includes usage limits represented as `.spec.resourceGroups[].flavors[].resources[].nominalQuota` . In this case, the ClusterQueue admits workloads if and only if:- The sum of the CPU requests is less than or equal to 10\n- The sum of the memory requests is less than or equal to 10Gi\n- The sum of GPU requests is less than or equal to 10\n- The sum of the storage used is less than or equal to 10Gi\n## Create the LocalQueueA LocalQueue is a namespaced object that accepts workloads from users in the namespace. LocalQueues from different namespaces can point to the same ClusterQueue where they can share the resources' quota. In this case, LocalQueue from namespace `team-a` and `team-b` points to the same ClusterQueue `cluster-queue` under `.spec.clusterQueue` .\n [  batch/kueue-intro/local-queue.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/local-queue.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/local-queue.yaml) \n```\napiVersion: kueue.x-k8s.io/v1beta1kind: LocalQueuemetadata:\u00a0 namespace: team-a # LocalQueue under team-a namespace\u00a0 name: lq-team-aspec:\u00a0 clusterQueue: cluster-queue # Point to the ClusterQueue---apiVersion: kueue.x-k8s.io/v1beta1kind: LocalQueuemetadata:\u00a0 namespace: team-b # LocalQueue under team-b namespace\u00a0 name: lq-team-bspec:\u00a0 clusterQueue: cluster-queue # Point to the ClusterQueue\n```\nEach team sends their workloads to the LocalQueue in their own namespace. Which are then allocated resources by the ClusterQueue.\nDeploy the LocalQueues:\n```\nkubectl apply -f local-queue.yaml\n```## Create Jobs and observe the admitted workloads [  batch/kueue-intro/job-team-a.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/job-team-a.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/job-team-a.yaml) \n```\napiVersion: batch/v1kind: Jobmetadata:\u00a0 namespace: team-a # Job under team-a namespace\u00a0 generateName: sample-job-team-a-\u00a0 annotations:\u00a0 \u00a0 kueue.x-k8s.io/queue-name: lq-team-a # Point to the LocalQueuespec:\u00a0 ttlSecondsAfterFinished: 60 # Job will be deleted after 60 seconds\u00a0 parallelism: 3 # This Job will have 3 replicas running at the same time\u00a0 completions: 3 # This Job requires 3 completions\u00a0 suspend: true # Set to true to allow Kueue to control the Job when it starts\u00a0 template:\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-accelerator: \"nvidia-tesla-t4\" # Specify the GPU hardware\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: dummy-job\u00a0 \u00a0 \u00a0 \u00a0 image: gcr.io/k8s-staging-perf-tests/sleep:latest\u00a0 \u00a0 \u00a0 \u00a0 args: [\"10s\"] # Sleep for 10 seconds\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"500m\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: \"1\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"500m\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: \"1\"\u00a0 \u00a0 \u00a0 restartPolicy: Never\n```\nJobs are created under the namespace `team-a` . This Job points to the LocalQueue `lq-team-a` . To request GPU resources, `nodeSelector` is set to `nvidia-tesla-t4` .\nThe Job is composed of three Pods that sleep for 10 seconds in parallel. Jobs are cleaned up after 60 seconds according to `ttlSecondsAfterFinished` .\nThis Job requires 1500 milliCPU, 1536 Mi of memory, 1536 Mi of ephemeral storage, and three GPUs since there are three Pods.\nJobs are also created under the file [job-team-b.yaml](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/batch/kueue-intro/job-team-b.yaml) where its namespace belongs to `team-b` , with requests to represent different teams with different needs.\nTo learn more, see [deploying GPU workloads in Autopilot](https://cloud.google.com/kubernetes-engine/docs/how-to/autopilot-gpus) .- In a new terminal, observe the status of the ClusterQueue that refreshes every two seconds:```\nwatch -n 2 kubectl get clusterqueue cluster-queue -o wide\n```\n- In a new terminal, observe the status of the nodes:```\nwatch -n 2 kubectl get nodes -o wide\n```\n- In a new terminal, create Jobs to LocalQueue from namespace `team-a` and `team-b` every 10 seconds:```\n./create_jobs.sh job-team-a.yaml job-team-b.yaml 10\n```\n- Observe the Jobs being queued up, admitted in the ClusterQueue, and nodes being brought up with GKE Autopilot. **Note:** It is normal to see a warning for the Pods with message `Unschedulable` while Nodes are scaling up.\n- Obtain a Job from namespace `team-a` :```\nkubectl -n team-a get jobs\n```The outcome is similar to the following:```\nNAME      COMPLETIONS DURATION AGE\nsample-job-team-b-t6jnr 3/3   21s  3m27s\nsample-job-team-a-tm7kc 0/3      2m27s\nsample-job-team-a-vjtnw 3/3   30s  3m50s\nsample-job-team-b-vn6rp 0/3      40s\nsample-job-team-a-z86h2 0/3      2m15s\nsample-job-team-b-zfwj8 0/3      28s\nsample-job-team-a-zjkbj 0/3      4s\nsample-job-team-a-zzvjg 3/3   83s  4m50s\n```\n- Copy a Job name from the previous step and observe the admission status and events for a Job through the Workloads API:```\nkubectl -n team-a describe workload JOB_NAME\n```\n- When the pending Jobs start increasing from the ClusterQueue, end the script by pressing `CTRL + C` on the running script.\n- Once all Jobs are completed, notice the nodes being scaled down. **Note:** The scale down process can take up to two minutes.\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n### Delete the individual resource\n- Delete the Kueue quota system:```\nkubectl delete -n team-a localqueue lq-team-akubectl delete -n team-b localqueue lq-team-bkubectl delete clusterqueue cluster-queuekubectl delete resourceflavor default-flavor\n```\n- Delete the Kueue manifest:```\nVERSION=VERSIONkubectl delete -f \\\u00a0 https://github.com/kubernetes-sigs/kueue/releases/download/$VERSION/manifests.yaml\n```\n- Delete the cluster:```\ngcloud container clusters delete kueue-autopilot --region=COMPUTE_REGION\n```\n## What's next\n- Check out the [GKE documentation](/kubernetes-engine/docs/concepts/kubernetes-engine-overview) .\n- Learn more about [Jobs](https://kubernetes.io/docs/concepts/workloads/controllers/job/) .\n- [Learn more about Kueue](https://kueue.sigs.k8s.io/) \n- Learn how to [Setup Kueue for quota sharing between namespaces](/kubernetes-engine/docs/tutorials/kueue-cohort)", "guide": "Google Kubernetes Engine (GKE)"}