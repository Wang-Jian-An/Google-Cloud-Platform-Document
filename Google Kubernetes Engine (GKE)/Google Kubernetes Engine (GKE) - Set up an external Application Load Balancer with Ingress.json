{"title": "Google Kubernetes Engine (GKE) - Set up an external Application Load Balancer with Ingress", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/http-balancer", "abstract": "# Google Kubernetes Engine (GKE) - Set up an external Application Load Balancer with Ingress\nThis tutorial shows how to run a web application behind an [external Application Load Balancer](/load-balancing/docs/https) by configuring the [Ingress](/kubernetes-engine/docs/concepts/ingress) resource.\n **Note:** This process does not apply to an [NGINX Ingress controller](https://github.com/kubernetes/ingress-nginx) .", "content": "## BackgroundGoogle Kubernetes Engine (GKE) offers integrated support for two types of Cloud Load Balancing for a publicly accessible application:- [Ingress](/kubernetes-engine/docs/concepts/ingress) \n- [External passthrough Network Load Balancer](/load-balancing/docs/network) \nIn this tutorial, you use [Ingresses](/kubernetes-engine/docs/concepts/ingress) .\n### IngressWhen you specify `kind: Ingress` in a resource manifest, you instruct GKE to create an [Ingress](/kubernetes-engine/docs/concepts/ingress) resource. By including annotations and supporting workloads and Services, you can create a custom Ingress controller. Otherwise, GKE makes appropriate Google Cloud API calls to create an [external Application Load Balancer](/load-balancing/docs/https) . The load balancer's URL map's host rules and path matchers reference one or more backend services, where each backend service corresponds to a GKE [Service](https://kubernetes.io/docs/concepts/services-networking/service/) of type `NodePort` , as referenced in the `Ingress` . The backends for each backend service are either instance groups or network endpoint groups (NEGs). NEGs are created when you configure [container-native loadbalancing](/kubernetes-engine/docs/how-to/container-native-load-balancing) as part of the configuration for your Ingress. For each backend service, GKE creates a Google Cloud health check, based on the readiness probe settings of the workload referenced by the corresponding GKE [Service](https://kubernetes.io/docs/concepts/services-networking/service/) .\nIf you are exposing an HTTP(S) service hosted on GKE, [HTTP(S)load balancing](/compute/docs/load-balancing/http) is the recommended method for load balancing.\n **Note:** The load balancers created by GKE are billed according to the regular [Cloud Load Balancing pricing](/vpc/network-pricing#lb) .\n **Note:** To use Ingress, you must have the external Application Load Balancer add-on enabled. GKE clusters have external Application Load Balancers enabled by default; you must not disable it.\n **Note:** Google Kubernetes Engine relies on a health check mechanism to determine the health status of the backend service. This mechanism cannot be used to perform Blackbox monitoring. To perform Blackbox monitoring, create an uptime check. For more information, see [(Optional) Monitoring the availability and latency of your service](#monitor) .## Objectives\n- Create a GKE cluster.\n- Deploy the sample web application to the cluster.\n- Expose the sample app to the internet behind an external Application Load Balancer.\n## CostsIn this document, you use the following billable components of Google Cloud:- [GKE](/kubernetes-engine/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin\nTake the following steps to enable the Kubernetes Engine API:\n- Visit the [ Kubernetes Engine page](https://console.cloud.google.com/projectselector/kubernetes) in the Google Cloud console.\n- Create or select a project.\n- Wait for the API and related services to be enabled.  This can take several minutes.\n- [Make sure that billing is enabled for your Google Cloud project](/billing/docs/how-to/verify-billing-enabled#console) .\nInstall the following command-line tools used in this tutorial:- `gcloud`is used to create and delete Kubernetes Engine clusters.`gcloud`is included in the [gcloud CLI](/sdk/docs/install) .\n- `kubectl`is used to manage Kubernetes, the cluster orchestration system used by  Kubernetes Engine. You can install`kubectl`using`gcloud`:```\ngcloud components install kubectl\n```\nClone the sample code from GitHub:\n```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples\ncd kubernetes-engine-samples/networking/load-balancing\n```\n### Set defaults for the gcloud command-line tool\nTo save time typing your\n [project ID](https://support.google.com/cloud/answer/6158840) \nand\n [Compute Engine zone](/compute/docs/zones#available) \noptions in the\n`gcloud`\ncommand-line tool, you can set the defaults:\n```\ngcloud config set project project-id\ngcloud config set compute/zone compute-zone\n```\n### Create a GKE clusterCreate a GKE Autopilot cluster:\n```\ngcloud container clusters create-auto loadbalancedcluster\n```## Deploying a web applicationThe following manifest describes a [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) that runs the sample web application container image on an HTTP server on port 8080:\n [  networking/load-balancing/web-deployment.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-deployment.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-deployment.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: web\u00a0 namespace: defaultspec:\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 run: web\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 run: web\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\u00a0 \u00a0 \u00a0 \u00a0 imagePullPolicy: IfNotPresent\u00a0 \u00a0 \u00a0 \u00a0 name: web\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8080\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 protocol: TCP\n```\nApply the resource to the cluster:\n```\nkubectl apply -f web-deployment.yaml\n```## Exposing your Deployment inside your clusterThe following manifest describes a [Service](https://kubernetes.io/docs/concepts/services-networking/service/) that makes the `web` deployment accessible within your container cluster:\n [  networking/load-balancing/web-service.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-service.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-service.yaml) \n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: web\u00a0 namespace: defaultspec:\u00a0 ports:\u00a0 - port: 8080\u00a0 \u00a0 protocol: TCP\u00a0 \u00a0 targetPort: 8080\u00a0 selector:\u00a0 \u00a0 run: web\u00a0 type: NodePort\n```- Apply the resource to the cluster:```\nkubectl apply -f web-service.yaml\n```When you create a Service of type [NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#nodeport) with this command, GKE makes your Service available on a randomly selected high port number (e.g. 32640) on all the nodes in your cluster.\n- Verify that the Service is created and a node port is allocated:```\nkubectl get service web\n```Output:```\nNAME  TYPE  CLUSTER-IP  EXTERNAL-IP PORT(S)   AGE\nweb  NodePort 10.35.245.219 <none>  8080:32640/TCP 5m\n```In the sample output, the node port for the `web` Service is `32640` . Also, note that there is no external IP allocated for this Service. Since the GKE nodes are not externally accessible by default, creating this Service does not make your application accessible from the internet.\nTo make your HTTP(S) web server application publicly accessible, you must create an Ingress resource.## Creating an Ingress resource [Ingress](/kubernetes-engine/docs/concepts/ingress) is a Kubernetes resource that encapsulates a collection of rules and configuration for routing external HTTP(S) traffic to internal services.\nOn GKE, Ingress is implemented using [Cloud Load Balancing](/load-balancing) . When you create an Ingress in your cluster, GKE creates an [HTTP(S) load balancer](/compute/docs/load-balancing/http) and configures it to route traffic to your application.\nThe following manifest describes an Ingress resource that directs traffic to your `web` Service:\n [  networking/load-balancing/basic-ingress.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/basic-ingress.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/basic-ingress.yaml) \n```\napiVersion: networking.k8s.io/v1kind: Ingressmetadata:\u00a0 name: basic-ingressspec:\u00a0 defaultBackend:\u00a0 \u00a0 service:\u00a0 \u00a0 \u00a0 name: web\u00a0 \u00a0 \u00a0 port:\u00a0 \u00a0 \u00a0 \u00a0 number: 8080\n```\nApply the resource to the cluster:\n```\nkubectl apply -f basic-ingress.yaml\n```\nAfter you deploy this manifest, Kubernetes creates an Ingress resource on your cluster. The GKE Ingress controller creates and configures an [HTTP(S) Load Balancer](/compute/docs/load-balancing/http) according to the information in the Ingress, routing all external HTTP traffic (on port 80) to the `web` NodePort Service you exposed.\n **Note:** To use Ingress, you must have the external Application Load Balancer add-on enabled. GKE clusters have external Application Load Balancers enabled by default; you must not disable it.## Visiting your applicationFind out the external IP address of the load balancer serving your application by running:\n```\nkubectl get ingress basic-ingress\n```\nOutput:\n```\nNAME   HOSTS  ADDRESS   PORTS  AGE\nbasic-ingress *   203.0.113.12 80  2m\n```\n **Note:** It might take a few minutes for GKE to allocate an external IP address and set up forwarding rules before the load balancer is ready to serve your application. You might get errors such as HTTP 404 or HTTP 500 until the load balancer configuration is propagated across the globe.\nOpen the external IP address of your application in a browser and see a plain text HTTP response like the following:\n```\nHello, world!\nVersion: 1.0.0\nHostname: web-6498765b79-fq5q5\n```\nYou can visit [Load Balancing](https://console.cloud.google.com/networking/loadbalancing) on the Google Cloud console and inspect the networking resources created by the GKE Ingress controller.## (Optional) Configuring a static IP addressWhen you expose a web server on a domain name, you need the external IP address of an application to be a static IP that does not change.\nBy default, GKE allocates [ephemeral external IPaddresses](/compute/docs/ip-addresses#ephemeraladdress) for HTTP applications exposed through an Ingress. Ephemeral addresses are subject to change. If you are planning to run your application for a long time, you must use a [static external IPaddress](/compute/docs/ip-addresses/reserve-static-external-ip-address) .\nNote that after you configure a static IP for the Ingress resource, deleting the Ingress does not delete the static IP address associated with it. Make sure to clean up the static IP addresses you configured when you no longer plan to use them again.\n **Warning:** The following instructions create a static IP address and then reference the IP address in an Ingress manifest. If you modify an existing Ingress to use a static IP address instead of an ephemeral IP address, GKE might change the IP address of the load balancer when GKE re-creates the forwarding rule of the load balancer.\nTo configure a static IP address, complete the following steps:- Reserve a [static external IP address](/compute/docs/ip-addresses/reserve-static-external-ip-address) named `web-static-ip` :\n```\ngcloud compute addresses create web-static-ip --global\n```\n **Note:** This step requires [Config Connector](https://cloud.google.com/config-connector/docs/overview) . Follow the [installation instructions](https://cloud.google.com/config-connector/docs/how-to/install-upgrade-uninstall) to install Config Connector on your cluster.\n [View on GitHub](https://github.com/GoogleCloudPlatform/k8s-config-connector/blob/HEAD/config/samples/tutorials/http-balancer/compute-address.yaml) \n```\napiVersion: compute.cnrm.cloud.google.com/v1beta1kind: ComputeAddressmetadata:\u00a0 name: web-static-ipspec:\u00a0 location: global\n```\nTo deploy this manifest, download it to your machine as compute-address.yaml, and run:\n```\nkubectl apply -f compute-address.yaml\n```\n- The `basic-ingress-static.yaml` manifest adds an annotation on Ingress to use the static IP resource named `web-static-ip` : [  networking/load-balancing/basic-ingress-static.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/basic-ingress-static.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/basic-ingress-static.yaml) ```\napiVersion: networking.k8s.io/v1kind: Ingressmetadata:\u00a0 name: basic-ingress\u00a0 annotations:\u00a0 \u00a0 kubernetes.io/ingress.global-static-ip-name: \"web-static-ip\"spec:\u00a0 defaultBackend:\u00a0 \u00a0 service:\u00a0 \u00a0 \u00a0 name: web\u00a0 \u00a0 \u00a0 port:\u00a0 \u00a0 \u00a0 \u00a0 number: 8080\n```View the manifest:```\ncat basic-ingress-static.yaml\n```\n- Apply the resource to the cluster:```\nkubectl apply -f basic-ingress-static.yaml\n```\n- Check the external IP address:```\nkubectl get ingress basic-ingress\n```Wait until the IP address of your application changes to use the reserved IP address of the `web-static-ip` resource.It might take a few minutes to update the existing Ingress resource, re-configure the load balancer, and propagate the load balancing rules across the globe. After this operation completes, GKE releases the ephemeral IP address previously allocated to your application. **Note:** Unused static external IP address are billed according to the regular [IPaddress billing](/compute/pricing#ipaddress) .## (Optional) Serving multiple applications on a load balancerYou can run multiple services on a single load balancer and public IP by configuring routing rules on the Ingress. By hosting multiple services on the same Ingress, you can avoid creating additional load balancers (which are billable resources) for every Service that you expose to the internet.\nThe following manifest describes a Deployment with version `2.0` of the same web application:\n [  networking/load-balancing/web-deployment-v2.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-deployment-v2.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-deployment-v2.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: web2\u00a0 namespace: defaultspec:\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 run: web2\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 run: web2\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:2.0\u00a0 \u00a0 \u00a0 \u00a0 imagePullPolicy: IfNotPresent\u00a0 \u00a0 \u00a0 \u00a0 name: web2\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 8080\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 protocol: TCP\n```\nApply the resource to the cluster:\n```\nkubectl apply -f web-deployment-v2.yaml\n```\nThe following manifest describes a Service that exposes `web2` internally to the cluster on a NodePort Service called `web2` :\n [  networking/load-balancing/web-service-v2.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-service-v2.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/web-service-v2.yaml) \n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: web2\u00a0 namespace: defaultspec:\u00a0 ports:\u00a0 - port: 8080\u00a0 \u00a0 protocol: TCP\u00a0 \u00a0 targetPort: 8080\u00a0 selector:\u00a0 \u00a0 run: web2\u00a0 type: NodePort\n```\nApply the resource to the cluster:\n```\nkubectl apply -f web-service-v2.yaml\n```\nThe following manifest describes an Ingress resource that:- routes the requests with path starting with`/v2/`to the`web2`Service\n- routes all other requests to the`web`Service\n [  networking/load-balancing/fanout-ingress.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/fanout-ingress.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/networking/load-balancing/fanout-ingress.yaml) \n```\napiVersion: networking.k8s.io/v1kind: Ingressmetadata:\u00a0 name: fanout-ingressspec:\u00a0 rules:\u00a0 - http:\u00a0 \u00a0 \u00a0 paths:\u00a0 \u00a0 \u00a0 - path: /*\u00a0 \u00a0 \u00a0 \u00a0 pathType: ImplementationSpecific\u00a0 \u00a0 \u00a0 \u00a0 backend:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 service:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: web\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 number: 8080\u00a0 \u00a0 \u00a0 - path: /v2/*\u00a0 \u00a0 \u00a0 \u00a0 pathType: ImplementationSpecific\u00a0 \u00a0 \u00a0 \u00a0 backend:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 service:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: web2\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 port:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 number: 8080\n```\nApply the resource to the cluster:\n```\nkubectl create -f fanout-ingress.yaml\n```\nAfter the Ingress is deployed, run `kubectl get ingress fanout-ingress` to find out the public IP address of the cluster.\n **Note:** It might take a few minutes for GKE to allocate an external IP address and prepare the load balancer. You might get errors like HTTP 404 and HTTP 500 until the load balancer is ready to serve the traffic.\nThen visit the IP address to see that both applications are reachable on the same load balancer:- Visit`http://<IP_ADDRESS>/`and note that the response contains`Version: 1.0.0`(as the request is routed to the`web`Service)\n- Visit`http://<IP_ADDRESS>/v2/`and note that the response contains`Version: 2.0.0`(as the request is routed to the`web2`Service)\nThe only supported wildcard character for the `path` field of an Ingress is the `*` character. The `*` character must follow a forward slash ( `/` ) and must be the last character in the pattern. For example, `/*` , `/foo/*` , and `/foo/bar/*` are valid patterns, but `*` , `/foo/bar*` , and `/foo/*/bar` are not.\nA more specific pattern takes precedence over a less specific pattern. If you have both `/foo/*` and `/foo/bar/*` , then `/foo/bar/bat` is taken to match `/foo/bar/*` .\nFor more information about path limitations and pattern matching, see the [URL Maps documentation](/load-balancing/docs/url-map) .## (Optional) Monitoring the availability and latency of your serviceGoogle Cloud [Uptime checks](/monitoring/uptime-checks) perform blackbox monitoring of applications from the viewpoint of the user, determining latency and availability from multiple external IPs to the IP address of the load balancer. In comparison, Google Cloud health checks perform an internal check against the Pod IPs, determining availability at the instance level. The checks are complementary and provide a holistic picture of application health.\nYou can create an uptime check by using the Google Cloud console, the Cloud Monitoring API, or by using the Cloud Monitoring client libraries. For information, see [Managing uptime checks](/monitoring/uptime-checks) . If you want to create an uptime check by using the Google Cloud console, do the following:- Go to the **Services & Ingress** page in the Google Cloud console. [Go to Services & Ingress](https://console.cloud.google.com/kubernetes/discovery) \n- Click the name of the Service you want to create an uptime check for.\n- Click **Create Uptime Check** .\n- In the **Create Uptime Check** pane, enter a title for the uptime check and then click **Next** to advance to the **Target** settings.The **Target** fields of the uptime check are automatically filled in using the information from the Service load balancer.For complete documentation on all the fields in an uptime check, see [Creating an uptime check](/monitoring/uptime-checks#create) .\n- Click **Next** to advance to the **Response Validation** settings.\n- Click **Next** to advance to the **Alert and Notification** section.To monitor an uptime check, you can create an alerting policy or view the uptime check dashboard. An alerting policy can notify you by email or through a different channel if your uptime check fails. For general information about alerting policies, see [Introduction to alerting](/monitoring/alerts) . **Note:** You can create an alerting policy for an uptime check as part of the process of creating the uptime check. Creating an alerting policy is optional, but it is recommended. For information on how to create an alerting policy as an independent action, see [Alerting on uptime checks](/monitoring/uptime-checks/uptime-alerting-policies) \n- Click **Create** .\n## RemarksBy default, Ingress performs a periodic health check by making a `GET` request on the `/` path to determine the health of the application, and expects a HTTP 200 response. If you want to check a different path or to expect a different response code, you can use a [custom health check path](/kubernetes-engine/docs/concepts/ingress#health_checks) .\nIngress supports more advanced use cases, such as:- **Name-based virtual hosting:** You can use Ingress to reuse the load balancer for multiple domain names, subdomains, and to expose multiple Services on a single IP address and load balancer. Check out the [simplefanout](https://kubernetes.io/docs/concepts/services-networking/ingress/#simple-fanout) and [name-based virtualhosting](https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting) examples to learn how to configure Ingress for these tasks.\n- [HTTPS termination](/compute/docs/load-balancing/http#tls_support) : You can [configure theIngress](https://kubernetes.io/docs/concepts/services-networking/ingress/#tls) to terminate the HTTPS traffic using the Cloud Load Balancer.\n **Note:** Always modify the properties of the Load Balancer using the Ingress object. Making changes directly on the load balancing resources might get lost or overridden by the GKE Ingress controller.\nWhen an Ingress is deleted, the GKE Ingress controller cleans up the associated resources (except reserved static IP addresses) automatically.## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.- **Delete any manually created forwarding rules and target proxies that reference the Ingress:** **Note:** This step is needed only if the load balancer associated with the Ingress is updated manually using the Google Kubernetes Engine API or the Google Cloud console.A dangling target proxy that is referencing a GKE Ingress controller managed URL map will cause the deletion of the Ingress to fail in GKE versions 1.15.4-gke.22+. Inspect the Ingress resource to find an event with an error message similar to the following:```\n Error during GC: error running load balancer garbage collection routine: googleapi: Error 400: The url_map resource 'projects/project-id/global/urlMaps/k8s2-um-tlw9rhgp-default-my-ingress-9ifnni82' is already being used by 'projects/project-id/global/targetHttpsProxies/k8s2-um-tlw9rhgp-default-my82-target-proxy', resourceInUseByAnotherResource\n \n```In the preceding error message, `k8s2-um-tlw9rhgp-default-my82-target-proxy` is a manually created target https proxy that is still referencing the URL map `k8s2-um-tlw9rhgp-default-my-ingress-9ifnni82` which was created and managed by an Ingress controller.These manually created frontend resources (both forwarding rule and target proxy) must be deleted before proceeding with the deletion of the Ingress.\n- **Delete the Ingress:** This step deallocates the ephemeral external IP address and the load balancing resources associated with your application:```\nkubectl delete ingress basic-ingress\n```If you followed the optional step to create an Ingress to route requests by path, then delete the Ingress:```\nkubectl delete ingress fanout-ingress\n```\n- **Delete the static IP address:** Complete this step only if you followed the optional step to create a static IP address.- If you followed \"Option 1\" to convert an existing ephemeral IP address to static IP, then visit the [Google Cloud console](https://console.cloud.google.com/networking/addresses/list) to delete the static IP address.\n- If you followed \"Option 2\" to create a new static IP address, then run the following command to delete the static IP address:```\ngcloud compute addresses delete web-static-ip --global\n```\n- **Delete the cluster:** This step deletes the [compute nodes](/compute) of your container cluster and other resources such as the Deployments in the cluster:```\ngcloud container clusters delete loadbalancedcluster\n```\n## What's next\n- Check out the [Ingress user guide](https://kubernetes.io/docs/concepts/services-networking/ingress/) for details about Ingress features.\n- Configure [static IP and a domain name](/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip) for your Ingress application using Ingress.\n- Configure [SSL certificates](/kubernetes-engine/docs/how-to/ingress-multi-ssl) for your Ingress load balancer.\n- Learn about [using Google-managed SSL certificates with Ingress](/kubernetes-engine/docs/how-to/managed-certs) .\n- If you have an application running on multiple Kubernetes Engine clusters in different regions, set up a [multi-cluster Ingress](/kubernetes-engine/docs/how-to/multi-cluster-ingress) to route traffic to a cluster in the region closest to the user.\n- Explore other [Kubernetes Engine tutorials](/kubernetes-engine/docs/tutorials) .\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Google Kubernetes Engine (GKE)"}