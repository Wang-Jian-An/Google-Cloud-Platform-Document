{"title": "Google Kubernetes Engine (GKE) - About cluster autoscaling", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler", "abstract": "# Google Kubernetes Engine (GKE) - About cluster autoscaling\nThis page explains how Google Kubernetes Engine (GKE) automatically resizes your Standard cluster's node pools based on the demands of your workloads. When demand is high, the cluster autoscaler adds nodes to the node pool. To learn how to configure cluster autoscaler, see [Autoscaling a cluster](/kubernetes-engine/docs/how-to/cluster-autoscaler) .\nWith Autopilot clusters, you don't need to worry about provisioning nodes or managing node pools because node pools are provisioned through [node auto-provisioning](/kubernetes-engine/docs/how-to/node-auto-provisioning) , and are automatically scaled to meet the requirements of your workloads.\n", "content": "## Why use cluster autoscaler\nGKE's automatically resizes the number of nodes in a given node pool, based on the demands of your workloads. When demand is low, the cluster autoscaler scales back down to a minimum size that you designate. This can increase the availability of your workloads when you need it, while controlling costs. You don't need to manually add or remove nodes or over-provision your node pools. Instead, you specify a minimum and maximum size for the node pool, and the rest is automatic.\nIf resources are deleted or moved when autoscaling your cluster, your workloads might experience transient disruption. For example, if your workload consists of a controller with a single replica, that replica's Pod might be rescheduled onto a different node if its current node is deleted. Before enabling cluster autoscaler, design your workloads to tolerate potential disruption or ensure that critical Pods are not interrupted.\n**Note:** To increase your workload's tolerance to interruption, consider deploying your workload using a controller with multiple replicas, such as a Deployment.\nYou can increase the cluster autoscaler performance with [Image streaming](/kubernetes-engine/docs/how-to/image-streaming) , which remotely streams required image data from eligible container images while simultaneously caching the image locally to allow workloads on new nodes to start faster.\n## How cluster autoscaler works\nCluster autoscaler works on a per-node pool basis. When you configure a node pool with cluster autoscaler, you specify a minimum and maximum size for the node pool.\nCluster autoscaler increases or decreases the size of the node pool automatically by adding or removing virtual machine (VM) instances in the underlying Compute Engine [Managed Instance Group (MIG)](/compute/docs/instance-groups#managed_instance_groups) for the node pool. Cluster autoscaler makes these scaling decisions based on the resource requests (rather than actual resource utilization) of Pods running on that node pool's nodes. It periodically checks the status of Pods and nodes, and takes action:\n- If Pods are unschedulable because there are not enough nodes in the node pool, cluster autoscaler adds nodes, up to the maximum size of the node pool.\n- If nodes are under-utilized, and all Pods could be scheduled even with fewer nodes in the node pool, Cluster autoscaler removes nodes, down to the minimum size of the node pool. If there are Pods on a node that cannot move to other nodes in the cluster, cluster autoscaler does not attempt to scale down that node. If Pods can be moved to other nodes, but the node cannot be drained gracefully after a timeout period (currently 10 minutes), the node is forcibly terminated. The grace period is not configurable for GKE clusters. For more information about how scale down works, see the [cluster autoscaler documentation](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-does-scale-down-work) .\nIf your Pods have requested too few resources (or haven't changed the defaults, which might be insufficient) and your nodes are experiencing shortages, cluster autoscaler does not correct the situation. You can help ensure cluster autoscaler works as accurately as possible by making explicit resource requests for all of your workloads.\n**Caution:** Do not enable Compute Engine [autoscaling for managed instancegroups](/compute/docs/autoscaler) for your cluster nodes. GKE's cluster autoscaler is separate from Compute Engine autoscaling. This can lead to node pools failing to scale up or scale down as the Compute Engine autoscaler will be in conflict with GKE's cluster autoscaler.\n### Operating criteria\nCluster autoscaler makes the following assumptions when resizing a node pool:\n- All replicated Pods can be restarted on some other node, possibly causing a brief disruption. If your services are not disruption-tolerant, using cluster autoscaler is not recommended.\n- Users or administrators are not manually managing nodes; it can override any manual node management operations you perform.\n- All nodes in a single node pool have the same set of labels.\n- Cluster autoscaler considers the relative cost of the instance types in the various pools, and attempts to expand the least expensive possible node pool. The reduced cost of node pools containing [Spot VMs](/kubernetes-engine/docs/concepts/spot-vms) is taken into account.\n- Cluster autoscaler considers the init container requests before scheduling Pods. Init container requests can use any unallocated resources available on the nodes which might prevent Pods from being scheduled. Cluster autoscaler follows the same request calculation rules that Kubernetes uses. To learn more, see [Using init containers](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#resources) .\n- Labels manually added after initial cluster or node pool creation are not tracked. Nodes created by cluster autoscaler are assigned labels specified with`--node-labels`at the time of node pool creation.\n- In GKE version 1.21 or earlier, cluster autoscaler considers the taint information of the existing nodes from a node pool to represent the whole node pool. Starting in GKE version 1.22, cluster autoscaler combines information from existing nodes in the cluster and the node pool. Cluster autoscaler detects manual node and node pool changes to scale up.\n### Balancing across zones\nIf your node pool contains multiple managed instance groups with the same instance type, cluster autoscaler attempts to keep these managed instance group sizes balanced . This helps prevent an uneven distribution of nodes among managed instance groups in multiple zones of a node pool. GKE does not consider the autoscaling policy when scaling down.\n**Note:** Cluster autoscaler only balances across zones during a scale-up event. Cluster autoscaler scales down underutilized nodes regardless of the relative sizes of underlying managed instance groups in a node pool which can cause the nodes to be distributed unevenly across zones.\nStarting in GKE version 1.24.1-gke.800, you can change the location policy of the GKE cluster autoscaler. You can control the cluster autoscaler distribution policy by specifying the `location_policy` flag with any of the following values:\n- `BALANCED`: the autoscaler considers Pod requirements and the availability of resources in each zone. This does not guarantee similar node groups will have exactly the same sizes, as the autoscaler considers many factors, including available capacity in a given zone and zone affinities of Pods that triggered scale up.\n- `ANY`: the autoscaler prioritizes utilization of unused reservations and accounts for current constraints of available resources. This policy is recommended if you are using Spot VMs or if you want to use VM reservations that are not equal between zones.Starting in GKE version 1.27, cluster autoscaler always considers [reservations](/compute/docs/instances/reservations-overview) when making the scale-up decisions. The node pools with matching unused reservations are prioritized when choosing the node pool to scale up, even when the node pool is not the most efficient one. Additionally, unused reservations are always prioritized when balancing multi-zonal scale-ups.\nFor [Spot VMs](/kubernetes-engine/docs/concepts/spot-vms) node pools, the default cluster autoscaler distribution policy is `ANY` . In this policy, Spot VMs have a lower risk of being preempted.\nFor non-preemptible [node pools](/kubernetes-engine/docs/concepts/node-pools) , the default cluster autoscaler distribution policy is `BALANCED` .\n### Minimum and maximum node pool size\nWhen creating a new node pool, you can specify the minimum and maximum size for each node pool in your cluster, and the cluster autoscaler makes rescaling decisions within these scaling constraints. To update the minimum size, manually resize the cluster to a size within the new constraints after specifying the new minimum value. The cluster autoscaler then makes rescaling decisions based on the new constraints.\n| Current node pool size       | Cluster autoscaler action                   | Scaling constraints            |\n|:--------------------------------------------------|:--------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------|\n| Lower than the minimum you specified    | Cluster autoscaler scales up to provision pending pods. Scaling down is disabled.     | The node pool does not scale down below the value you specified. |\n| Within the minimum and maximum size you specified | Cluster autoscaler scales up or down according to demand.           | The node pool stays within the size limits you specified.  |\n| Greater than the maximum you specified   | Cluster autoscaler scales down only the nodes that can be safely removed. Scaling up is disabled. | The node pool does not scale above the value you specified.  |\nOn Standard clusters, the cluster autoscaler never scales down a cluster to zero nodes. One or more nodes must always be available in the cluster to run system Pods. Additionally, if the current number of nodes is zero due to removal of nodes, cluster autoscaler and node auto-provisioning can scale up from zero node clusters.\nTo learn more about autoscaler decisions, see [cluster autoscaler limitations](#limitations) .\n### Autoscaling limits\nYou can set the minimum and maximum number of nodes for the cluster autoscaler to use when scaling a node pool. Use the `--min-nodes` and `--max-nodes` flags to set the minimum and maximum number of nodes per zone\nStarting in GKE version 1.24, you can use the `--total-min-nodes` and `--total-max-nodes` flags for new clusters. These flags set the minimum and maximum number of the total number of nodes in the node pool across all zones.\n**Min and max nodes example**\nThe following command creates an autoscaling [multi-zonal cluster](/kubernetes-engine/docs/concepts/types-of-clusters#multi-zonal_clusters) with six nodes across three zones initially, with a minimum of one node per zone and a maximum of four nodes per zone:\n```\ngcloud container clusters create example-cluster \\\n --num-nodes=2 \\\n --zone=us-central1-a \\\n --node-locations=us-central1-a,us-central1-b,us-central1-f \\\n --enable-autoscaling --min-nodes=1 --max-nodes=4\n```\nIn this example, the total size of the cluster can be between three and twelve nodes, spread across the three zones. If one of the zones fails, the total size of the cluster can be between two and eight nodes.\n**Total nodes example**\nThe following command, available in GKE version 1.24 or later, creates an autoscaling [multi-zonal cluster](/kubernetes-engine/docs/concepts/types-of-clusters#multi-zonal_clusters) with six nodes across three zones initially, with a minimum of three nodes and a maximum of twelve nodes in the node pool across all zones:\n```\ngcloud container clusters create example-cluster \\\n --num-nodes=2 \\\n --zone=us-central1-a \\\n --node-locations=us-central1-a,us-central1-b,us-central1-f \\\n --enable-autoscaling --total-min-nodes=3 --total-max-nodes=12\n```\nIn this example, the total size of the cluster can be between three and twelve nodes, regardless of spreading between zones.\n### Autoscaling profiles\nThe decision of when to remove a node is a trade-off between optimizing for utilization or the availability of resources. Removing underutilized nodes improves cluster utilization, but new workloads might have to wait for resources to be provisioned again before they can run.\nYou can specify which autoscaling profile to use when making such decisions. The available profiles are:\n- `balanced`: The default profile for Standard clusters. The`balanced`profile isn't available for Autopilot clusters.\n- `optimize-utilization`: Prioritize optimizing utilization over keeping spare resources in the cluster. When you enable this profile, the cluster autoscaler scales down the cluster more aggressively. GKE can remove more nodes, and remove nodes faster. GKE prefers to schedule Pods in nodes that already have high allocation of CPU, memory, or GPUs. However, other factors [influence scheduling](https://kubernetes.io/docs/reference/scheduling/config/#scheduling-plugins) , such as spread of Pods belonging to the same Deployment, StatefulSet or Service, across nodes.\nThe `optimize-utilization` autoscaling profile helps the cluster autoscaler to identify and remove underutilized nodes. To achieve this optimization, GKE sets the scheduler name in the Pod spec to `gke.io/optimize-utilization-scheduler` . Pods that specify a custom scheduler are not affected.\nThe following command enables `optimize-utilization` autoscaling profile in an existing cluster:\n```\ngcloud container clusters update CLUSTER_NAME \\\u00a0 \u00a0 --autoscaling-profile optimize-utilization\n```\n### Considering Pod scheduling and disruption\nWhen scaling down, the cluster autoscaler respects scheduling and eviction rules set on Pods. These restrictions can prevent a node from being deleted by the autoscaler. A node's deletion could be prevented if it contains a Pod with any of these conditions:\n- The Pod's [affinity or anti-affinity](https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity) rules prevent rescheduling.\n- The Pod is not managed by a [Controller](https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/#pods-and-controllers) such as a Deployment, StatefulSet, Job or ReplicaSet.\n- The Pod has local storage and the GKE control plane version is lower than 1.22. In GKE clusters with control plane version 1.22 or later, Pods with local storage no longer block scaling down.\n- The Pod has the`\"cluster-autoscaler.kubernetes.io/safe-to-evict\": \"false\"`annotation.\n- The node's deletion would exceed the configured [PodDisruptionBudget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#how-disruption-budgets-work) .\nFor more information about cluster autoscaler and preventing disruptions, see the following questions in the [Cluster autoscaler FAQ](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md) :\n- [How does scale-down work?](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-does-scale-down-work) \n- [Does Cluster autoscaler work with PodDisruptionBudget in scale-down?](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#does-ca-work-with-poddisruptionbudget-in-scale-down) \n- [What types of Pods can prevent Cluster autoscaler from removing a node?](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#what-types-of-pods-can-prevent-ca-from-removing-a-node) \n### Autoscaling TPUs in GKE\nGKE supports Tensor Processing Units (TPUs) to accelerate machine learning workloads. Both [single-host TPU slice node pool](/kubernetes-engine/docs/concepts/tpus#node_pool) and [multi-host TPU slice node pool](/kubernetes-engine/docs/concepts/tpus#node_pool) support autoscaling and auto-provisioning.\nWith the [--enable-autoprovisioning](/sdk/gcloud/reference/container/clusters/update#--enable-autoprovisioning) flag on a GKE cluster, GKE creates or deletes single-host or multi-host TPU slice node pools with a TPU version and topology that meets the requirements of pending workloads.\nWhen you use [--enable-autoscaling](/sdk/gcloud/reference/container/node-pools/create#--enable-autoscaling) , GKE scales the node pool based on its type, as follows:\n- TPU slice node pool: GKE adds or removes TPU nodes in the existing node pool. The node pool may contain any number of TPU nodes between zero and the maximum size of the node pool as determined by the [--max-nodes](/sdk/gcloud/reference/container/node-pools/create#--max-nodes) and the [--total-max-nodes](/sdk/gcloud/reference/container/node-pools/create#--total-max-nodes) flags. When the node pool scales, all the TPU nodes in the node pool have the same machine type and topology. To learn more how to create a single-host TPU slice node pool, see [Create a nodepool](/kubernetes-engine/docs/how-to/tpus#single-host) .\n- TPU slice node pool: GKE atomically scales up the node pool from zero to the number of nodes required to satisfy the TPU topology. For example, with a TPU node pool with a machine type `ct5lp-hightpu-4t` and a topology of `16x16` , the node pool contains 64 nodes. The GKE autoscaler ensures that this node pool has exactly 0 or 64 nodes. When scaling back down, GKE evicts all scheduled pods, and drains the entire node pool to zero. To learn more how to create a multi-host TPU slice node pool, see [Create a node pool](/kubernetes-engine/docs/how-to/tpus#multi-host) .\n### Additional information\nYou can find more information about cluster autoscaler in the [Autoscaling FAQin the open-source Kubernetes project](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md) .\n## Limitations\nCluster autoscaler has the following limitations:\n- [Local PersistentVolumes](/kubernetes-engine/docs/how-to/persistent-volumes/local-ssd) are currently not supported by cluster autoscaler.\n- In GKE control plane version earlier than 1.24.5-gke.600, when pods request ephemeral storage, cluster autoscaler does not support scaling up a node pool with zero nodes that uses [Local SSDs as ephemeral storage](/kubernetes-engine/docs/how-to/persistent-volumes/local-ssd#creating_a_node_pool_using_ephemeral_storage_on_local_ssds) .\n- Cluster size limitations: up to 15,000 nodes. Please account for other [cluster limits](/kubernetes-engine/quotas#limits_per_cluster) and our [best practices](/kubernetes-engine/docs/best-practices/scalability) when running clusters of this size.\n- When scaling down, the cluster autoscaler honors a graceful termination period of 10 minutes for rescheduling the node's Pods onto a different node before forcibly terminating the node.\n- Occasionally, the cluster autoscaler cannot scale down completely and an extra node exists after scaling down. This can occur when required system Pods are scheduled onto different nodes, because there is no trigger for any of those Pods to be moved to a different node. See [I have a couple of nodes with low utilization, but they are not scaled down. Why?](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#i-have-a-couple-of-nodes-with-low-utilization-but-they-are-not-scaled-down-why) . To work around this limitation, you can configure a [Pod disruption budget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/) .\n- Custom scheduling with altered [Filters](https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/#filter) is not supported.\n- Nodes will not scale up if Pods have a [PriorityClass](https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#priorityclass) value below`-10`. Learn more in [How does Cluster Autoscaler work with Pod Priority and Preemption?](https://github.com/kubernetes/autoscaler/blob/master/cluster-autoscaler/FAQ.md#how-does-cluster-autoscaler-work-with-pod-priority-and-preemption) \n- Cluster autoscaler might not have enough unallocated IP address space to use to add new nodes or Pods, resulting in scale-up failures, which are indicated by [eventResult events](/kubernetes-engine/docs/how-to/cluster-autoscaler-visibility#eventresult-event) with the reason`scale.up.error.ip.space.exhausted`. You can add more IP addresses for nodes by [expanding the primary subnet](/vpc/docs/create-modify-vpc-networks#expand-subnet) , or add new IP addresses for Pods using [discontiguous multi-Pod CIDR](/kubernetes-engine/docs/how-to/multi-pod-cidr) . For more information, see [Not enough free IP space for Pods](/kubernetes-engine/docs/how-to/alias-ips#not_enough_space) .## Known issues\n- In GKE control plane version prior to 1.22, GKE cluster autoscaler stops scaling up all node pools on empty (zero node) clusters. This behavior doesn't occur in GKE version 1.22 and later.## What's next\n- [Learn how to autoscale your nodes](/kubernetes-engine/docs/how-to/cluster-autoscaler) .\n- [Learn how to auto-upgrade your nodes](/kubernetes-engine/docs/how-to/node-auto-upgrades) .\n- [Learn how to auto-repair your nodes](/kubernetes-engine/docs/how-to/node-auto-repair) .\n- [Learn how to reduce image pull times on new nodes](/kubernetes-engine/docs/how-to/image-streaming) .", "guide": "Google Kubernetes Engine (GKE)"}