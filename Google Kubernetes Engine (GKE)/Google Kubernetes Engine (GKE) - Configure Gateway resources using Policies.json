{"title": "Google Kubernetes Engine (GKE) - Configure Gateway resources using Policies", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/configure-gateway-resources", "abstract": "# Google Kubernetes Engine (GKE) - Configure Gateway resources using Policies\nThis page shows you how to configure the load balancer that Google Kubernetes Engine (GKE) creates when you deploy a Gateway in a GKE cluster.\nWhen you deploy a Gateway, the GatewayClass configuration determines which load balancer GKE creates. This managed load balancer is pre-configured with default settings that you can modify using a .\nYou can customize Gateway resources to fit with your infrastructure or application requirements by attaching Policies to Gateways, Services or ServiceImports. After you apply or modify a Policy, you don't need to delete or recreate your Gateway, Route, or Service resources, the Policy is processed by the Gateway controller and the underlying load balancer resource is (re)configured according to the (new) Policy.\n", "content": "## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n### GKE Gateway controller requirements\n- For Standard, GKE version 1.24 or later.\n- For Autopilot, GKE version 1.26 or later.\n- Google Cloud CLI version 407.0.0 or later.\n- The Gateway API is supported on [VPC-native](/kubernetes-engine/docs/concepts/alias-ips) clusters only.\n- If you are using the internal GatewayClasses, you must enable a [proxy-only subnet](/load-balancing/docs/proxy-only-subnets) .\n- Your cluster must have the`HttpLoadBalancing`add-on enabled.\n- If you are using Istio, you must upgrade Istio to one of the following versions:- 1.15.2 or later\n- 1.14.5 or later\n- 1.13.9 or later.\n- If you are using Shared VPC, then in the host project, you need to assign the`Compute Network User`role to the GKE Service account for the service project.\n### Restrictions and Limitations\nIn addition to the GKE Gateway controller [restrictions and limitations](/kubernetes-engine/docs/how-to/deploying-gateways#limitations) , the following limitations apply specifically to Policies applied on the Gateway resources:\n- `GCPGatewayPolicy` resources can only be attached to a `gateway.networking.k8s.io` `Gateway` .\n- `GCPGatewayPolicy` resources must exist in the same namespace as the target `Gateway` .\n- When using a single cluster Gateway, `GCPBackendPolicy` , and `HealthCheckPolicy` resources must refer to a `Service` resource.\n- When using a multi-cluster Gateway,`GCPBackendPolicy`, and`HealthCheckPolicy`, resources must refer to a`ServiceImport`resource.\n- Only one `GCPGatewayPolicy` can be attached to a Service at any given time. When two `GCPGatewayPolicy` policies are created and target the same `Service` or `ServiceImport` , the oldest policy will take precedence and the second one will fail to be attached.\n- Hierarchical policies are not supported with GKE Gateway.\n- `HealthCheckPolicy` , and `GCPBackendPolicy` resources must exist in the same namespace as the target `Service` or `ServiceImport` resource.\n- `GCPBackendPolicy` and `HealthCheckPolicy` resources are structured in a way that they can reference only one backend service.## Configure global access for your regional internal Gateway\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\nTo enable global access with your internal Gateway, attach a policy to the Gateway resource.\nThe following `GCPGatewayPolicy` manifest enables regional internal Gateway for global access:\n```\napiVersion: networking.gke.io/v1kind: GCPGatewayPolicymetadata:\u00a0 name: my-gateway-policy\u00a0 namespace: defaultspec:\u00a0 default:\u00a0 \u00a0 allowGlobalAccess: true\u00a0 targetRef:\u00a0 \u00a0 group: gateway.networking.k8s.io\u00a0 \u00a0 kind: Gateway\u00a0 \u00a0 name: my-gateway\n```\n**Note:** Upgrading an existing internal Gateway by adding global access recreates the forwarding rule of your regional internal load balancer. **This upgradedeletes and then re-creates Google Cloud load balancers which resultsin up to 15 minutes of unavailability.** We recommend performing this operation during a maintenance window to avoid any application downtime.\n## Configure SSL Policies to secure client-to-load-balancer traffic\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\nTo secure your client-to-load-balancer traffic, configure the SSL policy by adding the name of your policy to the `GCPGatewayPolicy` . By default, the Gateway does not have any SSL Policy defined and attached.\nMake sure that you [create an SSL policy](/load-balancing/docs/use-ssl-policies#create_ssl_policies) prior to referencing the policy in your `GCPGatewayPolicy` .\n**Note:** If you use a regional Gateway, make sure you create a regional SSL policy.\nThe following `GCPGatewayPolicy` manifest specifies a security policy named `gke-gateway-ssl-policy` :\n```\napiVersion: networking.gke.io/v1kind: GCPGatewayPolicymetadata:\u00a0 name: my-gateway-policy\u00a0 namespace: team1spec:\u00a0 default:\u00a0 \u00a0 sslPolicy: gke-gateway-ssl-policy\u00a0 targetRef:\u00a0 \u00a0 group: gateway.networking.k8s.io\u00a0 \u00a0 kind: Gateway\u00a0 \u00a0 name: my-gateway\n```\n## Configure health checks\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\nYou can use a `HealthCheckPolicy` to control the load balancer health check settings. Each type of health check ( `http` , `https` , `grpc` , and `http2` ) has a parameters that you can define. Google Cloud creates a unique health check for each backend service for each GKE Service.\nThe following `HealthCheckPolicy` manifest shows all the fields available when configuring a health check policy:\n```\napiVersion: networking.gke.io/v1kind: HealthCheckPolicymetadata:\u00a0 name: lb-healthcheck\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 checkIntervalSec: INTERVAL\u00a0 \u00a0 timeoutSec: TIMEOUT\u00a0 \u00a0 healthyThreshold: HEALTHY_THRESHOLD\u00a0 \u00a0 unhealthyThreshold: UNHEALTHY_THRESHOLD\u00a0 \u00a0 logConfig:\u00a0 \u00a0 \u00a0 enabled: ENABLED\u00a0 \u00a0 config:\u00a0 \u00a0 \u00a0 type: PROTOCOL\u00a0 \u00a0 \u00a0 httpHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 \u00a0 host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: REQUEST_PATH\u00a0 \u00a0 \u00a0 \u00a0 response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 proxyHeader: PROXY_HEADER\u00a0 \u00a0 \u00a0 httpsHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 \u00a0 host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: REQUEST_PATH\u00a0 \u00a0 \u00a0 \u00a0 response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 proxyHeader: PROXY_HEADER\u00a0 \u00a0 \u00a0 grpcHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 grpcServiceName: GRPC_SERVICE_NAME\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 http2HealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 \u00a0 host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: REQUEST_PATH\u00a0 \u00a0 \u00a0 \u00a0 response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 proxyHeader: PROXY_HEADER\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: HealthCheckPolicymetadata:\u00a0 name: lb-healthcheck\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 checkIntervalSec: INTERVAL\u00a0 \u00a0 timeoutSec: TIMEOUT\u00a0 \u00a0 healthyThreshold: HEALTHY_THRESHOLD\u00a0 \u00a0 unhealthyThreshold: UNHEALTHY_THRESHOLD\u00a0 \u00a0 logConfig:\u00a0 \u00a0 \u00a0 enabled: ENABLED\u00a0 \u00a0 config:\u00a0 \u00a0 \u00a0 type: PROTOCOL\u00a0 \u00a0 \u00a0 httpHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 \u00a0 host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: REQUEST_PATH\u00a0 \u00a0 \u00a0 \u00a0 response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 proxyHeader: PROXY_HEADER\u00a0 \u00a0 \u00a0 httpsHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 \u00a0 host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: REQUEST_PATH\u00a0 \u00a0 \u00a0 \u00a0 response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 proxyHeader: PROXY_HEADER\u00a0 \u00a0 \u00a0 grpcHealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 grpcServiceName: GRPC_SERVICE_NAME\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 http2HealthCheck:\u00a0 \u00a0 \u00a0 \u00a0 portSpecification: PORT_SPECIFICATION\u00a0 \u00a0 \u00a0 \u00a0 port: PORT\u00a0 \u00a0 \u00a0 \u00a0 portName: PORT_NAME\u00a0 \u00a0 \u00a0 \u00a0 host: HOST\u00a0 \u00a0 \u00a0 \u00a0 requestPath: REQUEST_PATH\u00a0 \u00a0 \u00a0 \u00a0 response: RESPONSE\u00a0 \u00a0 \u00a0 \u00a0 proxyHeader: PROXY_HEADER\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\nReplace the following:\n- ``: specifies the [check-interval](/load-balancing/docs/health-check-concepts#probes) , in seconds, for each health check prober. This is the time from the start of one prober's check to the start of its next check. If you omit this parameter, the Google Cloud default is 5 seconds. For more information, see [Multiple probes and frequency](/load-balancing/docs/health-check-concepts#multiple-probers) .\n- ``: specifies the amount of time that Google Cloud waits for a response to a probe. The value of``must be less than or equal to the``. Units are seconds. Each probe requires an HTTP 200 (OK) response code to be delivered before the probe timeout.\n- ``and``: specifies the number of sequential connection attempts that must succeed or fail, for at least one prober, to change the [health state](/load-balancing/docs/health-check-concepts#health_state) from healthy to unhealthy or unhealthy to healthy. If you omit one of these parameters, the Google Cloud default is 2.\n- ``: specifies a [protocol](/load-balancing/docs/health-check-concepts#category_and_protocol) used by probe systems for health checking. For more information, see [Success criteria for HTTP, HTTPS, and HTTP/2](/load-balancing/docs/health-check-concepts#criteria-protocol-http) and [Success criteria for gRPC](/load-balancing/docs/health-check-concepts#criteria-protocol-grpc) . This parameter is required.\n- ``: specifies if logging is enabled or disabled.\n- ``: specifies if the health check uses a fixed port (`USE_FIXED_PORT`), named port (`USE_NAMED_PORT`) or serving port (`USE_SERVING_PORT`). If not specified, the health check follows the behavior specified in the`port`and`portName`fields. If neither`port`or`portName`are specified, this field defaults to`USE_SERVING_PORT`.\n- ``: specifies the [request-path](/load-balancing/docs/health-check-concepts#criteria-protocol-http) to which the probe system should connect for HTTP, HTTPS, or HTTP2 health checks. If you omit this parameter, the Google Cloud default is`/`.\n- ``: A HealthCheckPolicy only supports specifying [the load balancer health check port by using a port number](/load-balancing/docs/health-check-concepts#category_and_port_specification) . If you omit this parameter, the Google Cloud default is 80. Because the load balancer sends probes to the Pod's IP address directly, you should select a port matching a`containerPort`of a serving Pods, even if the`containerPort`is referenced by a`targetPort`of the Service. You are not limited to`containerPorts`referenced by a Service's`targetPort`.\n- ``: specifies the port name as defined in [InstanceGroup.NamedPort.name](/compute/docs/reference/rest/v1/instanceGroups) . If both`port`and`portName`are defined, Google Cloud considers the`port`value first.\n- ``: the value of the host header in the health check request. This value uses the [RFC 1123](https://www.rfc-editor.org/rfc/rfc1123#page-13) definition of a hostname except numeric IP addresses are not allowed. If not specified or left empty, this value defaults to the IP address of the health check.\n- ``: specifies the request path of the health check request. If not specified or left empty, defaults to`/`.\n- ``: specifies the bytes to match against the beginning of the response data. If not specified or left empty, GKE interprets any response as healthy. The response data can only be ASCII.\n- ``: specifies the proxy header type. You can use`NONE`or`PROXY_V1`. Defaults to`NONE`.\n- ``: an optional name of the gRPC Service. Omit this field to specify all Services.\nFor more information about HealthCheckPolicy fields, see the `healthChecks` [reference](/compute/docs/reference/rest/v1/healthChecks) .\n## Configure Google Cloud Armor backend security policy to secure your backend services\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\n**Note:** Google Cloud has replaced the `LbPolicy` policy with the `GCPBackendPolicy` policy. The `LbPolicy` is still supported, but with no additional attributes.\nConfigure the Google Cloud Armor backend security policy by adding the name of your security policy to the `GCPBackendPolicy` to secure your backend services. By default, the Gateway does not have any Google Cloud Armor backend security policy defined and attached.\nMake sure that you [create a Google Cloud Armor backend security policy](/armor/docs/configure-security-policies) prior to referencing the policy in your `GCPBackendPolicy` .\nThe following `GCPBackendPolicy` manifest specifies a backend security policy named `example-security-policy` :\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 securityPolicy: example-security-policy\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 securityPolicy: example-security-policy\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\n## Configure IAP\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\nIdentity-Aware Proxy (IAP) enforces access control policies on backend services associated with an HTTPRoute. With this enforcement, only authenticated users or applications with the correct Identity and Access Management (IAM) role assigned can access these backend services.\nBy default, there is no IAP applied to your backend services, you need to explicitly configure IAP in a `GCPBackendPolicy` .\nTo configure IAP with Gateway, do the following:\n- [Enable IAP for GKE](/iap/docs/enabling-kubernetes-howto#enabling_iap) Do not configure the backend ( [Configuring BackendConfig](/iap/docs/enabling-kubernetes-howto#kubernetes-configure) ) because `BackendConfig` is only valid in the case of an Ingress deployment.\n- Create a secret for your IAP:- Go to the Credentials page. Button: Go to the Credentials page.\n- Click the name of the client and download the OAuth client file.\n- From the OAuth client file, copy the OAuth secret on the clipboard.\n- Create a file called `iap-secret.txt` .\n- Paste the OAuth secret in the `iap-secret.txt` file using the following command:```\necho -n CLIENT_SECRET > iap-secret.txtkubectl create secret generic SECRET_NAME --from-file=key=iap-secret.txt\n```\n- To specify IAP policy referencing a secret:- Create the following `GCPBackendPolicy` manifest, replace the `SECRET_NAME` and `CLIENT_ID` respectively. Save the manifest as `backend-policy.yaml` :\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: backend-policyspec:\u00a0 default:\u00a0 \u00a0 iap:\u00a0 \u00a0 \u00a0 enabled: true\u00a0 \u00a0 \u00a0 oauth2ClientSecret:\u00a0 \u00a0 \u00a0 \u00a0 name: SECRET_NAME\u00a0 \u00a0 \u00a0 clientID: CLIENT_ID\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n```\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: backend-policyspec:\u00a0 default:\u00a0 \u00a0 iap:\u00a0 \u00a0 \u00a0 enabled: true\u00a0 \u00a0 \u00a0 oauth2ClientSecret:\u00a0 \u00a0 \u00a0 \u00a0 name: SECRET_NAME\u00a0 \u00a0 \u00a0 clientID: CLIENT_ID\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\n- Apply the `backend-policy.yaml` manifest:```\nkubectl apply -f backend-policy.yaml\n```\n- Verify your configuration:- Confirm that the policy was applied after creating your `GCPBackendPolicy` with IAP:```\nkubectl get gcpbackendpolicy\n```The output is similar to the following:```\nNAME    AGE\nbackend-policy 45m\n```\n- To get more details, use the describe command:```\nkubectl describe gcpbackendpolicy\n```The output is similar to the following:```\nName:   backend-policy\nNamespace: default\nLabels:  <none>\nAnnotations: <none>\nAPI Version: networking.gke.io/v1\nKind:   GCPBackendPolicy\nMetadata:\n Creation Timestamp: 2023-05-27T06:45:32Z\n Generation:   2\n Resource Version: 19780077\n UID:     f4f60a3b-4bb2-4e12-8748-d3b310d9c8e5\nSpec:\n Default:\n Iap:\n  Client ID: 441323991697-luotsrnpboij65ebfr13hlcpm5a4heke.apps.googleusercontent.com\n  Enabled: true\n  oauth2ClientSecret:\n  Name: my-iap-secret\n Target Ref:\n Group:\n Kind: Service\n Name: lb-service\nStatus:\n Conditions:\n Last Transition Time: 2023-05-27T06:48:25Z\n Message:\n Reason:    Attached\n Status:    True\n Type:     Attached\nEvents:\n Type  Reason Age     From     Message\n ----  ------ ----    ----     ------ Normal ADD  46m     sc-gateway-controller default/backend-policy\n Normal SYNC 44s (x15 over 43m) sc-gateway-controller Application of GCPGatewayPolicy \"default/backend-policy\" was a success\n```\n## Configure backend service timeout\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\n**Note:** Google Cloud has replaced the `LbPolicy` policy with the `GCPBackendPolicy` policy. The `LbPolicy` is still supported, but with no additional attributes.\nThe following `GCPBackendPolicy` manifest specifies a [backend service timeout](/load-balancing/docs/backend-service#timeout-setting) period of 40 seconds. The `timeoutSec` field defaults to 30 seconds.\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 timeoutSec: 40\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 timeoutSec: 40\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\n## Configure session affinity\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\n**Note:** Google Cloud has replaced the `LbPolicy` policy with the `GCPBackendPolicy` policy. The `LbPolicy` is still supported, but with no additional attributes.\nYou can configure [session affinity](/load-balancing/docs/backend-service#session_affinity) based on the following criteria:\n- Client IP address\n- Generated cookie\nWhen you configure [session affinity](/load-balancing/docs/backend-service#session_affinity) for your Service, the Gateway's `localityLbPolicy` setting is set to `MAGLEV` .\nWhen you remove a session affinity configuration from the `GCPBackendPolicy` , the Gateway reverts the `localityLbPolicy` setting to the default value, `ROUND_ROBIN` . This value is silently set on the GKE-managed backend service (attached to the load balancer) and is not reflected in the output of a gcloud CLI command, in the UI, or with Terraform.\nThe following `GCPBackendPolicy` manifest specifies a session affinity based on the [client IP address](/load-balancing/docs/backend-service#client_ip_affinity) :\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 sessionAffinity:\u00a0 \u00a0 \u00a0 type: CLIENT_IP\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 sessionAffinity:\u00a0 \u00a0 \u00a0 type: CLIENT_IP\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\nThe following `GCPBackendPolicy` manifest specifies a session affinity based on a [generated cookie](/load-balancing/docs/backend-service#generated_cookie_affinity) and configures the cookies TTL to 50 seconds:\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 sessionAffinity:\u00a0 \u00a0 \u00a0 type: GENERATED_COOKIE\u00a0 \u00a0 \u00a0 cookieTtlSec: 50\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 sessionAffinity:\u00a0 \u00a0 \u00a0 type: GENERATED_COOKIE\u00a0 \u00a0 \u00a0 cookieTtlSec: 50\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\nYou can use the following options for `sessionAffinity.type` : `CLIENT_IP` , `CLIENT_IP_PROTO` , `CLIENT_IP_PORT_PROTO` , `GENERATED_COOKIE` , `HEADER_FIELD` , `HTTP_COOKIE` , `NONE` .\n## Configure connection draining timeout\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\n**Note:** Google Cloud has replaced the `LbPolicy` policy with the `GCPBackendPolicy` policy. The `LbPolicy` is still supported, but with no additional attributes.\nYou can configure [connection draining timeout](/load-balancing/docs/enabling-connection-draining) using `GCPBackendPolicy` . Connection draining timeout is the time, in seconds, to wait for connections to drain. The timeout duration can be from 0 to 3600 seconds. The default value is 0, which also disables connection draining.\nThe following `GCPBackendPolicy` manifest specifies a connection draining timeout of 60 seconds:\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 connectionDraining:\u00a0 \u00a0 \u00a0 drainingTimeoutSec: 60\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 connectionDraining:\u00a0 \u00a0 \u00a0 drainingTimeoutSec: 60\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\nFor the specified duration of the timeout, GKE waits for existing requests to the removed backend to complete. The load balancer does not send new requests to the removed backend. After the timeout duration is reached, GKE closes all remaining connections to the backend.\n## HTTP access logging\nThis section describes a functionality that is available on GKE clusters running version 1.24 or later.\n**Note:** Google Cloud has replaced the `LbPolicy` policy with the `GCPBackendPolicy` policy. The `LbPolicy` is still supported, but with no additional attributes.\nBy default:\n- The Gateway controller logs all HTTP requests from clients to [Cloud Logging](/logging/docs) .\n- The sampling rate is 1,000,000, which means all requests are logged.\nYou can disable [access logging](/load-balancing/docs/https/https-logging-monitoring) on your Gateway using a `GCPBackendPolicy` in three ways:\n- You can leave the`GCPBackendPolicy`with no`logging`section\n- You can set`logging.enabled`to`false`\n- You can set`logging.enabled`to`true`and set`logging.sampleRate`to`0`\nYou can also configure the access logging sampling rate.\nThe following `GCPBackendPolicy` manifest modifies access logging's default sample rate and sets it to 50% of the HTTP requests for a given Service resource:\n```\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 logging:\u00a0 \u00a0 \u00a0 enabled: true\u00a0 \u00a0 \u00a0 sampleRate: 500000\u00a0 targetRef:\u00a0 \u00a0 group: \"\"\u00a0 \u00a0 kind: Service\u00a0 \u00a0 name: lb-service\n``````\napiVersion: networking.gke.io/v1kind: GCPBackendPolicymetadata:\u00a0 name: my-backend-policy\u00a0 namespace: lb-service-namespacespec:\u00a0 default:\u00a0 \u00a0 logging:\u00a0 \u00a0 \u00a0 enabled: true\u00a0 \u00a0 \u00a0 sampleRate: 500000\u00a0 targetRef:\u00a0 \u00a0 group: net.gke.io\u00a0 \u00a0 kind: ServiceImport\u00a0 \u00a0 name: lb-service\n```\nThis manifest has the following fields:\n- `enable: true`: explicitly enables access logging. Logs are available in Logging.\n- `sampleRate: 500000`: specifies that 50% of packets are logged. You can use a value between 0 and 1,000,000. GKE converts this value to a floating point value in the range [0, 1] by dividing by 1,000,000. This field is only relevant if`enable`is set to`true`.`sampleRate`is an optional field, but if it's configured then`enable: true`must also be set. If`enable`is set to`true`and`sampleRate`is not provided then GKE sets`enable`to`false`.## Troubleshooting\n### Multiple GCPBackendPolicy attached to the same Service\n**Symptom:**\nThe following status condition might occur when you attach a `GCPBackendPolicy` to a `Service` or a `ServiceImport` :\n```\nstatus:\n conditions:\n - lastTransitionTime: \"2023-09-26T20:18:03Z\"\n  message: conflicted with GCPBackendPolicy \"[POLICY_NAME]\" of higher precedence, hence not applied\n  reason: Conflicted\n  status: \"False\"\n  type: Attached\n```\n**Reason:**\nThis status condition indicates that you are trying to apply a second `GCPBackendPolicy` to a `Service` or `ServiceImport` that already has a `GCPBackendPolicy` attached.\nMultiple `GCPBackendPolicy` attached to the same `Service` or `ServiceImport` is not supported with GKE Gateway. See [Restrictions and Limitations](/kubernetes-engine/docs/how-to/configure-gateway-resources#restrictions_and_limitations) for more details.\n**Workaround:**\nConfigure a single `GCPBackendPolicy` that includes all custom configurations and attach it to your `Service` or `ServiceImport` .\n## What's next\n- Learn more about the [Gateway controller](/kubernetes-engine/docs/concepts/gateway-api) .\n- Learn how to [reference a Gateway from a resource](https://gateway-api.sigs.k8s.io/references/policy-attachment/#policy-attachment-for-ingress) .", "guide": "Google Kubernetes Engine (GKE)"}