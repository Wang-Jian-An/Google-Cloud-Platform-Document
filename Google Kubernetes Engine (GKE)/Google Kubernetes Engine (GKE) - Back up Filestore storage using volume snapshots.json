{"title": "Google Kubernetes Engine (GKE) - Back up Filestore storage using volume snapshots", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/backup-filestore-volume-snapshots", "abstract": "# Google Kubernetes Engine (GKE) - Back up Filestore storage using volume snapshots\nThis page shows you how to back up and restore Filestore storage using Kubernetes volume snapshots.\nCreating a [Kubernetes volume snapshot](/kubernetes-engine/docs/how-to/persistent-volumes/volume-snapshots) is equivalent to creating a [Filestore backup](/filestore/docs/backups) . For more information, see [About Kubernetes volume snapshots](/kubernetes-engine/docs/how-to/persistent-volumes/volume-snapshots) .\n", "content": "## Requirements\nTo use volume snapshots on GKE, you must meet the following requirements:\n- You must deploy the [Filestore CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver) , which supports the following Filestore [service tiers](/filestore/docs/service-tiers) :- Basic HDD with GKE version 1.21 or later\n- Basic SSD with GKE version 1.21 or later\n- Enterprise with GKE version 1.25 or later\n- Use control plane [versions](/kubernetes-engine/versioning-and-upgrades) 1.17 or later. To use the [Filestore CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver) in a `VolumeSnapshot` , use GKE versions 1.21 or later.\n- Have an existing`PersistentVolumeClaim`to use for a snapshot. The`PersistentVolume`you use for a snapshot source must be managed by a CSI driver. You can verify that you're using a CSI driver by checking that the`PersistentVolume`spec has a`csi`section with`driver: pd.csi.storage.gke.io`or`filestore.csi.storage.gke.io`. If the`PersistentVolume`is [dynamically provisioned](/kubernetes-engine/docs/concepts/persistent-volumes#dynamic_provisioning) by the CSI driver as described in the following sections, it's managed by the CSI driver.## Limitations\n- Snapshot volumes have the same size restrictions as regular volumes. For example, Filestore snapshots must be greater than or equal to 1\u00a0TiB in size for the basic HDD tier.\n- The Filestore CSI driver does not support dynamic provisioning or backup workflows for the following Filestore service tiers:- Zonal with higher capacity band (previously high scale ssd)\n- Zonal with lower capacity band\n- You can only back up one share per instance at a time. With regard to storage pools, backup requests issued from two different shares from two Filestore instances will execute simultaneously.\n- Singleshare backups can only be restored to singleshare volumes. Using the Filestore CSI driver, you can only restore a singleshare volume to a new Filestore instance.- The new instance must use the same service tier as the backup.\n- The new instance must match the same minimum capacity as the backup.\n- Filestore `backup restore` operations to the source or to an existing Filestore instance are not supported. For a complete list of feature limitations, see [Filestore backup feature limitations](/filestore/docs/backups#feature_limitations) .\n- Multishare backups are not supported.## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.## Creating and using a volume snapshot\nThe examples in this document show you how to do the following tasks:\n- [Create a PersistentVolumeClaim and Deployment](#create-deployment) .\n- [Add a file to the PersistentVolume that the Deployment uses](#add-file) .\n- [Create a VolumeSnapshotClass to configure the snapshot](#create-snapshotclass) .\n- [Create a volume snapshot of the PersistentVolume](#create-snapshot) .\n- [Delete the test file](#delete-file) .\n- [Restore the PersistentVolume to the snapshot you created](#restore-snapshot) .\n- [Verify that the restoration worked](#verify-restore) .\nTo use a volume snapshot, you must complete the following steps:\n- Create a`VolumeSnapshotClass`object to specify the CSI driver and deletion policy for your snapshot.\n- Create a`VolumeSnapshot`object to request a snapshot of an existing`PersistentVolumeClaim`.\n- Reference the`VolumeSnapshot`in a`PersistentVolumeClaim`to restore a volume to that snapshot or create a new volume using the snapshot.\n### Create a PersistentVolumeClaim and a Deployment\n- To create the `PersistentVolumeClaim` object, save the following manifest as `my-pvc.yaml` :\n```\n\u00a0apiVersion: v1\u00a0kind: PersistentVolumeClaim\u00a0metadata:\u00a0 \u00a0name: my-pvc\u00a0spec:\u00a0 \u00a0storageClassName: enterprise-rwx\u00a0 \u00a0accessModes:\u00a0 \u00a0- ReadWriteMany\u00a0 \u00a0resources:\u00a0 \u00a0 \u00a0requests:\u00a0 \u00a0 \u00a0 \u00a0storage: 1Ti\n```\nThis example creates an enterprise tier Filestore PVC. To learn more, see [Access Filestore instances with the Filestore CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver) .\nFor `spec.storageClassName` , you can specify any storage class that uses a supported CSI driver.\n- Apply the manifest:```\nkubectl apply -f my-pvc.yaml\n```\n- To create a `Deployment` , save the following manifest as `my-deployment.yaml` :```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: hello-appspec:\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: hello-app\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: hello-app\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: hello-app\u00a0 \u00a0 \u00a0 \u00a0 image: google/cloud-sdk:slim\u00a0 \u00a0 \u00a0 \u00a0 args: [ \"sleep\", \"3600\" ]\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - name: sdk-volume\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mountPath: /usr/share/hello/\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 - name: sdk-volume\u00a0 \u00a0 \u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 claimName: my-pvc\n```\n- Apply the manifest:```\nkubectl apply -f my-deployment.yaml\n```\n- Check the status of the `Deployment` :```\nkubectl get deployment hello-app\n```It might take some time for the `Deployment` to become ready. You can run the preceding command until you see an output similar to the following:```\nNAME  READY UP-TO-DATE AVAILABLE AGE\nhello-app 1/1  1   1   2m55s\n```\n### Add a test file to the volume\n- List the `Pods` in the `Deployment` :```\nkubectl get pods -l app=hello-app\n```The output is similar to the following:```\nNAME       READY STATUS RESTARTS AGE\nhello-app-6d7b457c7d-vl4jr 1/1  Running 0   2m56s\n```\n- Create a test file in a `Pod` :```\nkubectl exec POD_NAME \\\u00a0 \u00a0 -- sh -c 'echo \"Hello World!\" > /usr/share/hello/hello.txt'\n```Replace `` with the name of the `Pod` .\n- Verify that the file exists:```\nkubectl exec POD_NAME \\\u00a0 \u00a0 -- sh -c 'cat /usr/share/hello/hello.txt'\n```The output is similar to the following:```\nHello World!\n```\n### Create a VolumeSnapshotClass object\nCreate a `VolumeSnapshotClass` object to specify the CSI driver and `deletionPolicy` for your volume snapshot. You can reference `VolumeSnapshotClass` objects when you create `VolumeSnapshot` objects.\n- Save the following manifest as `volumesnapshotclass.yaml` .\n```\napiVersion: snapshot.storage.k8s.io/v1kind: VolumeSnapshotClassmetadata:\u00a0 name: my-snapshotclassdriver: filestore.csi.storage.gke.ioparameters:\u00a0 type: backupdeletionPolicy: Delete\n```\nIn this example:- The`driver`field is used by the CSI driver to provision the snapshot. In this example,`filestore.csi.storage.gke.io`uses the [Filestore CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver) .\n- The`deletionPolicy`field tells GKE what to do with the`VolumeSnapshotContent`object and the underlying snapshot when the bound`VolumeSnapshot`object is deleted. Specify`Delete`to delete the`VolumeSnapshotContent`object and the underlying snapshot. Specify`Retain`if you want to keep the`VolumeSnapshotContent`and the underlying snapshot.- Apply the manifest:```\nkubectl apply -f volumesnapshotclass.yaml\n```\n### Create a VolumeSnapshot\nA `VolumeSnapshot` object is a request for a snapshot of an existing `PersistentVolumeClaim` object. When you create a `VolumeSnapshot` object, GKE automatically creates and binds it with a `VolumeSnapshotContent` object, which is a resource in your cluster like a `PersistentVolume` object.\n- Save the following manifest as `volumesnapshot.yaml` .```\napiVersion: snapshot.storage.k8s.io/v1kind: VolumeSnapshotmetadata:\u00a0 name: my-snapshotspec:\u00a0 volumeSnapshotClassName: my-snapshotclass\u00a0 source:\u00a0 \u00a0 persistentVolumeClaimName: my-pvc\n```\n- Apply the manifest:```\nkubectl apply -f volumesnapshot.yaml\n```After you create a `Volume` snapshot, GKE creates a corresponding `VolumeSnapshotContent` object in the cluster. This object stores the snapshot and bindings of `VolumeSnapshot` objects. You don't interact with `VolumeSnapshotContents` objects directly.\n- Confirm that GKE created the `VolumeSnapshotContents` object:```\nkubectl get volumesnapshotcontents\n```The output is similar to the following:```\nNAME            AGE\nsnapcontent-cee5fb1f-5427-11ea-a53c-42010a1000da 55s\n```\nAfter the `Volume` snapshot content is created, the CSI driver you specified in the `VolumeSnapshotClass` creates a snapshot on the corresponding storage system. After GKE creates a snapshot on the storage system and binds it to a `VolumeSnapshot` object on the cluster, the snapshot is ready to use. You can check the status by running the following command:\n```\nkubectl get volumesnapshot \\\u00a0 -o custom-columns='NAME:.metadata.name,READY:.status.readyToUse'\n```\nIf the snapshot is ready to use, the output is similar to the following:\n```\nNAME    READY\nmy-snapshot  true\n```\n### Delete the test file\n- Delete the test file that you created:```\nkubectl exec POD_NAME \\\u00a0 \u00a0 -- sh -c 'rm /usr/share/hello/hello.txt'\n```\n- Verify that the file no longer exists:```\nkubectl exec POD_NAME \\\u00a0 \u00a0 -- sh -c 'cat /usr/share/hello/hello.txt'\n```The output is similar to the following:```\ncat: /usr/share/hello/hello.txt: No such file or directory\n```\n### Restore the volume snapshot\nYou can reference a `VolumeSnapshot` in a `PersistentVolumeClaim` to provision a new volume with data from an existing volume.\nTo reference a `VolumeSnapshot` in a `PersistentVolumeClaim` , add the `dataSource` field to your `PersistentVolumeClaim` .\nIn this example, you reference the `VolumeSnapshot` that you created in a new `PersistentVolumeClaim` and update the `Deployment` to use the new claim.\n- Save the following manifest as `pvc-restore.yaml` :\n```\napiVersion: v1kind: PersistentVolumeClaimmetadata:\u00a0 name: pvc-restorespec:\u00a0 dataSource:\u00a0 \u00a0 name: my-snapshot\u00a0 \u00a0 kind: VolumeSnapshot\u00a0 \u00a0 apiGroup: snapshot.storage.k8s.io\u00a0 storageClassName: enterprise-rwx\u00a0 accessModes:\u00a0 - ReadWriteMany\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: 1Ti\n```\n **Note:** The namespace of the `PersistentVolumeClaim` must be the same as the namespace of the `VolumeSnapshot` .\n- Apply the manifest:```\nkubectl apply -f pvc-restore.yaml\n```\n- Update the `my-deployment.yaml` file to use the new `PersistentVolumeClaim` :```\n...volumes:- name: my-volume\u00a0 persistentVolumeClaim:\u00a0 \u00a0 claimName: pvc-restore\n```\n- Apply the updated manifest:```\nkubectl apply -f my-deployment.yaml\n```\n### Check that the snapshot restored successfully\n- Get the name of the new `Pod` that GKE creates for the updated `Deployment` :```\n\u00a0kubectl get pods -l app=hello-app\n```\nVerify that the test file exists:\n```\n\u00a0 \u00a0kubectl exec NEW_POD_NAME \\\u00a0 \u00a0 \u00a0 \u00a0-- sh -c 'cat /usr/share/hello/hello.txt'\n```\nReplace `` with the name of the new `Pod` that GKE created.\nThe output is similar to the following:\n```\n Hello World!\n```\n## Clean up\nTo avoid incurring charges to your Google Cloud account for the resources used on this page, follow these steps.\n- Delete the `VolumeSnapshot` :```\nkubectl delete volumesnapshot my-snapshot\n``` **Note:** If a volume snapshot's `VolumeSnapshotClass` has `deletionPolicy:Delete` , the corresponding `VolumeSnapshotContent` and the physical snapshot on the storage system are also deleted. If it has a `deletionPolicy:Retain` , GKE retains the underlying snapshot.\n- Delete the `VolumeSnapshotClass` :```\nkubectl delete volumesnapshotclass my-snapshotclass\n```\n- Delete the `Deployment` :```\nkubectl delete deployments hello-app\n```\n- Delete the `PersistentVolumeClaim` objects:```\nkubectl delete pvc my-pvc pvc-restore\n```## What's next\n- Read the [Kubernetes Volume Snapshot](https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-cis-volume-snapshot-beta/) documentation.\n- Learn about [volume expansion](/kubernetes-engine/docs/how-to/volume-expansion) .\n- Learn how to [manually install a CSI driver](/kubernetes-engine/docs/how-to/install-csi-driver) .\n- Learn about [file storage (Filestore) for GKE](/kubernetes-engine/docs/concepts/storage-overview#filestore) .", "guide": "Google Kubernetes Engine (GKE)"}