{"title": "Google Kubernetes Engine (GKE) - Private clusters in GKE", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/private-cluster-concept", "abstract": "# Google Kubernetes Engine (GKE) - Private clusters in GKE\nThis page explains how private clusters work in Google Kubernetes Engine (GKE). You can also learn how to [create and manage private clusters](/kubernetes-engine/docs/how-to/private-clusters) .\nA is a type of [VPC-native cluster](/kubernetes-engine/docs/concepts/alias-ips) that only depends on [internal IP addresses](/vpc/docs/ip-addresses) . Nodes, Pods, and Services in a private cluster require [unique subnet IP address ranges](/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing) .\nYou can create and configure private clusters in Standard or Autopilot.\nIf you want to provide outbound internet access for certain private nodes, you can use [Cloud NAT](/nat/docs/overview#NATwithGKE) .\n", "content": "## Architecture of private clusters\nPrivate clusters use [nodes](/kubernetes-engine/docs/concepts/cluster-architecture#nodes) that do not have external IP addresses. This means that clients on the internet cannot connect to the IP addresses of the nodes. For example, a Service of type `NodePort` hosted in a private cluster is inaccessible to external clients because the node does not have an internet-routable public IP address.\nUnlike a public cluster, a private cluster has both a control plane private endpoint and a control plane public endpoint. You must specify a unique `/28` IP address range for the control plane's private endpoint, and you can choose to disable the control plane's public endpoint.\nThe following diagram provides an overview of the architecture for a private cluster:\nEven though the nodes use internal IP addresses, external clients can connect to [Services](/kubernetes-engine/docs/concepts/service) in your cluster. For example:\n- An external client with a source IP address on the internet can connect to an external Service of type `LoadBalancer` if you omit `spec.loadBalancerSourceRanges` from the Service manifest.\n- You can create a Service of type `NodePort` or `ClusterIP` and [expose the Service to external clients using an external Ingress](/kubernetes-engine/docs/concepts/ingress-xlb) .## Using Private Google Access in private clusters\nFor private clusters using VPC networks in the same project as the cluster, GKE ensures [Private Google Access](/vpc/docs/private-google-access) is enabled on the subnet used by the private cluster when you create the cluster. A network admin, project owner, or project editor for a Shared VPC host project must manually enable Private Google Access on subnets used by private clusters if the private clusters are created in Shared VPC service projects.\n[Private Google Access](/vpc/docs/private-google-access) is enabled by default in private clusters, except for Shared VPC clusters. You must enable Private Google Access manually for Shared VPC clusters.\nPrivate Google Access provides private nodes and their workloads access to Google Cloud APIs and services over Google's private network. For example, Private Google Access is required for private clusters to access container images from [Artifact Registry](/artifact-registry/docs) , and to send logs to [Cloud Logging](/logging/docs) .\n## The control plane in private clusters\nEvery GKE cluster has a Kubernetes API server that is managed by the [controlplane](/kubernetes-engine/docs/concepts/cluster-architecture#control_plane) .\nThe control plane runs on a virtual machine (VM) that is in a VPC network in a Google-managed project. A regional cluster has multiple replicas of the control plane, each of which runs on its own VM.\nIn private clusters, the control plane's VPC network is connected to your cluster's VPC network with [VPC Network Peering](/vpc/docs/vpc-peering) . Your VPC network contains the cluster nodes, and the Google-managed Google Cloud VPC network contains your cluster's control plane.\nTraffic between nodes and the control plane is routed entirely using internal IP addresses. If you use VPC Network Peering to connect your cluster's VPC network to a third network, the third network cannot reach resources in the control plane's VPC network. This is because VPC Network Peering only supports communication between directly peered networks, and the third network cannot be peered with the control plane network. For more information, see [VPC Network Peering restrictions](/vpc/docs/vpc-peering#restrictions) .\n**Note:** The [Restrict VPC Network Peering usage](/resource-manager/docs/organization-policy/org-policy-constraints) organization policy constraint prevents you from creating a private cluster when there is no existing VPC Network Peering connection to the control plane's VPC network (that is, this is the first zonal or regional private cluster). Work with your Organization Policy Administrator to adjust the constraint, as needed.\n## VPC Network Peering reuse\nPrivate clusters created after January 15, 2020 use a common VPC Network Peering connection if the clusters are in the same location and use the same VPC network. In this context, exclusively refers to a Google Cloud region or a Google Cloud zone.\n- For zonal clusters: the first private cluster you create in a zone generates a new VPC Network Peering connection to the cluster's VPC network. Additional private clusters that you create in the same zone and VPC network use the same peering connection.\n- For regional clusters: The first private cluster you create in a region generates a new VPC Network Peering connection to the cluster's VPC network. Additional private clusters that you create in the same region and VPC network use the same peering connection.\n- GKE does not use a common peering for zonal clusters and regional clusters, even when the zonal clusters belong to the same region as the regional clusters.\nThe following examples clarify this behavior. Each example uses one VPC Network Peering connection:\n- Two or more zonal private clusters in the `us-east1-b` zone using the same VPC network.\n- Two or more private clusters in the `us-east1` region using the same VPC network.\nHowever, one or more zonal private clusters in `us-east1-b` and one or more regional clusters in `us-east1` using the same VPC network require two VPC Network Peering connections.\nFor more information about private clusters and connections, see [VPC Network Peering reuse](/kubernetes-engine/docs/how-to/private-clusters#vpc_peering_reuse)\n**Note:** All private clusters created prior to January 15, 2020 created a unique VPC Network Peering connection. To enable VPC Network Peering reuse on these clusters, you can delete a cluster and recreate it. Upgrading a cluster does not cause it to reuse an existing VPC Network Peering connection.\n## Endpoints in private clusters\nThe control plane for a private cluster has a private endpoint in addition to a public endpoint. The control plane for a non-private cluster only has a public endpoint.### Access to cluster endpoints\nYou can control access to the endpoints using one of the following configurations:\n- **Public endpoint access disabled** : This is the most secure option as it prevents all internet access to the control plane. This is a good choice if you have configured your on-premises network to connect to Google Cloud using [Cloud Interconnect](/network-connectivity/docs/interconnect/concepts/overview) or [Cloud VPN](/network-connectivity/docs/vpn/concepts/overview) .If you disable public endpoint access, then you must configure authorized networks for the private endpoint. If you don't do this, you can only connect to the private endpoint from cluster nodes or VMs in the same subnet as the cluster. With this setting, authorized networks must be [internal IP addresses](/vpc/docs/ip-addresses) . **Important:** Even if you disable access to the public endpoint, Google can use the control plane's public endpoint for cluster management purposes, such as [scheduled maintenance](/kubernetes-engine/docs/scheduled-maintenance) and [automatic control plane upgrades](/kubernetes-engine/versioning-and-upgrades#automatic_cp_upgrades) .\n- **Public endpoint access enabled, authorized networks enabled** : In this configuration, the authorized networks apply to the control plane's public endpoint. This is a good choice if you need to administer the cluster from source networks that are not connected to your cluster's VPC network using Cloud Interconnect or Cloud VPN.\n- **Public endpoint access enabled, authorized networks disabled** : This is the default and it is also the least restrictive option. Since authorized networks are not enabled, you can administer your cluster from any source IP address as long as you authenticate.\nThe following table summarizes the different ways you can access the endpoints:\n| Unnamed: 0           | Public endpoint access disabled                                                                                                                                                                 | Public endpoint access enabled, authorized networks enabled                                                                                                                                                                                                                            | Public endpoint access enabled, authorized networks disabled                                                                                                                                                |\n|:---------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Security           | Highest level of restricted access to the control plane. Client access to the control plane's public endpoint is blocked. Access to the control plane must be from internal IP addresses.                                                                                                                          | Restricted access to the control plane from both internal and external IP addresses that you define.                                                                                                                                                                                                                 | Access to the control plane from any IP address.                                                                                                                                                   |\n| Detailed configuration steps      | Creating a private cluster with no client access to the public endpoint.                                                                                                                                                      | Creating a private cluster with limited access to the public endpoint.                                                                                                                                                                                                                         | Creating a private cluster with unrestricted access to the public endpoint.                                                                                                                                            |\n| Google Cloud console configuration options   | Select Enable VPC-native. Select Private cluster. Clear Access control plane using its external IP address. Enable control plane authorized networks is automatically enabled.                                                                                                                             | Select Enable VPC-native. Select Private cluster. Select Access control plane using its external IP address. Select Enable control plane authorized networks.                                                                                                                                                                                                   | Select Enable VPC-native. Select Private cluster. Select Access control plane using its external IP address. Clear Enable control plane authorized networks.                                                                                                                        |\n| gcloud cluster creation flags      | --enable-ip-alias --enable-private-nodes --enable-private-endpoint --enable-master-authorized-networks                                                                                                                                               | --enable-ip-alias --enable-private-nodes --enable-master-authorized-networks                                                                                                                                                                                                                        | --enable-ip-alias --enable-private-nodes --no-enable-master-authorized-networks                                                                                                                                           |\n| Communication between nodes and control plane  | Nodes always contact the control plane using the private endpoint.                                                                                                                                                        | Nodes always contact the control plane using the private endpoint.                                                                                                                                                                                                                          | Nodes always contact the control plane using the private endpoint.                                                                                                                                              |\n| Webhook communication between nodes and API server | Webhooks that use a service with a targetPort other than 443 require a firewall rule to permit this. See Adding firewall rules for specific use cases for more information.                                                                                                                              | Webhooks that use a service with a targetPort other than 443 require a firewall rule to permit this. See Adding firewall rules for specific use cases for more information.                                                                                                                                                                                                | Webhooks that use a service with a targetPort other than 443 require a firewall rule to permit this. See Adding firewall rules for specific use cases for more information.                                                                                                                    |\n| Control plane authorized networks     | Required for access to the control plane from internal IP addresses other than nodes and Pods. You do not need to explicitly authorize the internal IP address range of nodes. Addresses in the primary IP address range of the cluster's subnet are always authorized to communicate with the private endpoint. Use --master-authorized-networks to specify additional internal IP addresses that can access the control plane. You cannot include external IP addresses in the list of authorized networks, because access to the public endpoint is disabled.                               | Required for access to the control plane from external IP addresses, and from internal IP addresses other than nodes and Pods. Use --master-authorized-networks to specify external and internal IP addresses, other than nodes and Pods, that can access the control plane.                                                                                                                                                                       | Not used. If you enable access to the control plane's public endpoint without enabling authorized networks, access to the control plane's public endpoint is not restricted.                                                                                                                   |\n| Access using kubectl        | From nodes: Always uses the private endpoint. kubectl must be configured to use the private endpoint. From other VMs in the cluster's VPC network: Other VMs can use kubectl to communicate with the private endpoint only if either their internal IP addresses are included in the list of authorized networks or they are located in the same subnet as the cluster's nodes. By default only VMs on the same region can reach the private endpoint. If you need to reach the private endpoint outside the cluster region consider configuring control plane private endpoint global access. kubectl must be configured to use the private endpoint. From public IP addresses: Never. | From nodes: Always uses the private endpoint. kubectl must be configured to use the private endpoint. From other VMs in the cluster's VPC network: Other VMs can use kubectl to communicate with the private endpoint only if either their internal IP addresses are included in the list of authorized networks or they are located in the same subnet as the cluster's nodes. By default only VMs on the same region can reach the private endpoint. If you need to reach the private endpoint outside the cluster region consider configuring control plane private endpoint global access. kubectl must be configured to use the private endpoint. From public IP addresses: Machines with public IP addresses can use kubectl to communicate with the public endpoint only if their public IP addresses are included in the list of authorized networks. This includes machines outside of Google Cloud and Google Cloud VMs with external IP addresses. | From nodes: Always uses the private endpoint. kubectl must be configured to use the private endpoint. From other VMs in the cluster's VPC network: By default only VMs on the same region can reach the private endpoint. If you need to reach the private endpoint outside the cluster region consider configuring control plane private endpoint global access. kubectl must be configured to use the private endpoint. From public IP addresses: Any machine with a public IP address can use kubectl to communicate with the public endpoint. This includes machines outside of Google Cloud and Google Cloud VMs with external IP addresses. |\n## What's next\n- [Read the GKE network overview](/kubernetes-engine/docs/concepts/network-overview) .\n- [Learn how to create a private cluster](/kubernetes-engine/docs/how-to/private-clusters) .\n- [Learn how to create VPC-native clusters](/kubernetes-engine/docs/how-to/alias-ips) .\n- [Learn how to deploy a Windows application to a private cluster](/kubernetes-engine/docs/how-to/deploying-windows-app#deploying_a_windows_server_application_to_a_private_cluster) .\n- [Learn more about VPC peering](/vpc/docs/vpc-peering) .", "guide": "Google Kubernetes Engine (GKE)"}