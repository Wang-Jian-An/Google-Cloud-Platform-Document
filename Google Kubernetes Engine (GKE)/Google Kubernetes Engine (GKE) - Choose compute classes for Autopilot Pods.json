{"title": "Google Kubernetes Engine (GKE) - Choose compute classes for Autopilot Pods", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/autopilot-compute-classes", "abstract": "# Google Kubernetes Engine (GKE) - Choose compute classes for Autopilot Pods\nThis page shows you how to select specific compute classes to run workloads that have unique hardware requirements in your Google Kubernetes Engine (GKE) Autopilot clusters. Before you start, become familiar with the concept of [compute classes in GKE Autopilot](/kubernetes-engine/docs/concepts/autopilot-compute-classes) .\n", "content": "## Overview of Autopilot compute classes\nAutopilot offers that are designed to run workloads that have specific hardware requirements. These compute classes are useful for workloads such as machine learning and AI tasks, or running real-time high traffic databases.\nThese compute classes are a subset of the Compute Engine [machine series](/compute/docs/machine-types#machine_type_comparison) , and offer flexibility beyond the default Autopilot general-purpose compute class. For example, the `Scale-Out` class turns off simultaneous multi-threading so that each vCPU is one physical core.\nBased on your individual Pod needs, you can configure your regular Autopilot Pods or your Spot Pods to request nodes backed by these compute classes. You can also request specific CPU architecture, such as [Arm](https://www.arm.com/architecture) , in compute classes that support that architecture.\n## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n- [Ensure that you have a GKE Autopilot cluster](/kubernetes-engine/docs/how-to/creating-an-autopilot-cluster) running GKE version 1.24.1-gke.1400 or later.## Request a compute class in your Autopilot Pod\n`cloud.google.com/compute-class`\n[nodeSelector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)\n[node affinity rule](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity)\n```\n\u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 name: hello-app\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 replicas: 3\u00a0 \u00a0 \u00a0 selector:\u00a0 \u00a0 \u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app: hello-app\u00a0 \u00a0 \u00a0 template:\u00a0 \u00a0 \u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app: hello-app\u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/compute-class: \"COMPUTE_CLASS\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: hello-app\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"2000m\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"2Gi\"\u00a0 \u00a0 \n```\nReplace `` with the name of the [compute class](/kubernetes-engine/docs/concepts/autopilot-compute-classes#when-to-use) based on your use case, such as `Scale-Out` .  If you select `Accelerator` , you must also specify a compatible GPU. For instructions,  see [Deploy GPU workloads in Autopilot](/kubernetes-engine/docs/how-to/autopilot-gpus) . If you select `Performance` ,  you must also select a Compute Engine machine series in the node selector. For instructions,  see [Run CPU-intensive workloads with optimal performance](/kubernetes-engine/docs/how-to/performance-pods) .```\n\u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 name: hello-app\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 replicas: 3\u00a0 \u00a0 \u00a0 selector:\u00a0 \u00a0 \u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app: hello-app\u00a0 \u00a0 \u00a0 template:\u00a0 \u00a0 \u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app: hello-app\u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 terminationGracePeriodSeconds: 25\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: hello-app\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"2000m\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"2Gi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: \"1Gi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 affinity:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nodeAffinity:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requiredDuringSchedulingIgnoredDuringExecution:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nodeSelectorTerms:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - matchExpressions:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - key: cloud.google.com/compute-class\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operator: In\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - \"COMPUTE_CLASS\"\u00a0 \u00a0 \u00a0 \n```\nReplace `` with the name of the [compute class](/kubernetes-engine/docs/concepts/autopilot-compute-classes#when-to-use) based on your use case, such as `Scale-Out` . If you select `Accelerator` , you must also specify a compatible GPU. For instructions,   see [Deploy GPU workloads in Autopilot](/kubernetes-engine/docs/how-to/autopilot-gpus) . If you select `Performance` ,   you must also select a Compute Engine machine series in the node selector. For instructions,   see [Run CPU-intensive workloads with optimal performance](/kubernetes-engine/docs/how-to/cpu-intensive-performance) .\nYou can also request specific compute classes for your Spot Pods.\n### Specify resource requests\nWhen you choose a compute class, make sure that you specify resource requests for your Pods based on the [Minimum and maximum resource requests](/kubernetes-engine/docs/concepts/autopilot-resource-requests#min-max-requests) for your selected class. If your requests are less than the minimum, Autopilot automatically scales your requests up. However, if your requests are greater than the maximum, Autopilot does not deploy your Pods and displays an error message.\n## Choose a CPU architecture\nSome compute classes support multiple CPU architectures. For example, the `Scale-Out` class supports both Arm and x86 architectures. If you don't request a specific architecture, Autopilot provisions nodes that have the default architecture of the specified compute class. If your Pods need to use a different architecture, request that architecture in your node selector or node affinity rule, alongside your compute class request. The compute class that you request must support the CPU architecture you specify.\nFor instructions, refer to [Deploy Autopilot Pods on Arm architecture](/kubernetes-engine/docs/how-to/autopilot-arm-workloads) .\n## What's next\n- [Learn more about Autopilot cluster architecture](/kubernetes-engine/docs/concepts/autopilot-architecture) .\n- [Learn about the lifecycle of Pods](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/) .\n- [Learn about the available Autopilot compute classes](/kubernetes-engine/docs/concepts/autopilot-compute-classes) .\n- [Read about the default, minimum, and maximum resource requests for eachplatform](/kubernetes-engine/docs/concepts/autopilot-resource-requests) .", "guide": "Google Kubernetes Engine (GKE)"}