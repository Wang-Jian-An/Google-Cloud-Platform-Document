{"title": "Google Kubernetes Engine (GKE) - Explore your cluster and workload", "url": "https://cloud.google.com/kubernetes-engine/docs/quickstarts/tour-cluster", "abstract": "# Google Kubernetes Engine (GKE) - Explore your cluster and workload\n# Explore your cluster and workloadView and learn about the some of the key workload settings and resources that you deployed in [Create a cluster and deploy a workload](/kubernetes-engine/docs/quickstarts/create-cluster) .To follow step-by-step guidance for this task directly in the Google Cloud console, click **Guide me** :\n [Guide me](https://console.cloud.google.com/kubernetes/list/overview?walkthrough_id=kubernetes--tour-cluster) ", "content": "## Before you beginFollow the steps in [Create a cluster and deploy a workload](/kubernetes-engine/docs/quickstarts/create-cluster) .## View the Deployment specification for your appAll Kubernetes resources describe their desired state in specification files. Following Infrastructure as Code (IaC) practices, you can store these files in a source-code control system and use the files to recreate environments as needed.\nTo view the specification file for the app you deployed:- In the Google Cloud console, go to the **Deployment details** page for **hello-world-app** :- Go to the GKE **Workloads** page. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload/overview) \n- In the **Name** column, click the name of the app you deployed, **hello-world-app** .\n- Click the tab.\n- Notice that the second line is `kind: Deployment` , which means that this is a specification for a deployed app. Other types of Kubernetes resources use different values in the `kind:` line.\n- Find the line that starts with `spec:` in column 1 (no preceding white space).All of the subsequent lines in this Deployment specification define the desired state for the app, including `replicas:` , which specifies the initial number of Pod replicas that the app needs and `resources:` , which specifies the amount of computing resources that are available to each Pod.If the load on your app surpasses the configured compute resources, the horizontal autoscaling Service automatically replicates Pods to handle the increased load. Autopilot mode enables this autoscaling Service by default.\n- You can edit the YAML directly by clicking .Alternatively, any change you make in the **Deployment details** page will update the YAML.\n- To download this specification as a file and use it as the basis for other Deployments, click .\n## View Pods\n- If you aren't already on the **Deployment details** page:- In the Google Cloud console, go to the GKE **Workloads** page. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload/overview) \n- In the **Name** column, click the name of the app you deployed, **hello-world-app** .\n- On the **Overview** tab, the chart shows the CPU usage from all Pods in the current workload.\n- In the section:- **Replicas** : Summarizes the number of Pod replicas that are currently running in your workload.\n- **Pod specification** : Lists the version of the Deployment (which you assign in the Deployment specification), and the containers that are running in the workload.\n- The table links to configuration data and performance metrics for each Pod replica that is currently running for the workload.\n## View ServicesWhen you deployed your workload, you chose to create a load balancing Service that directs external traffic to your workload.\nTo view your workload's Service:- If you aren't already on the **Deployment details** page:- In the Google Cloud console, go to the GKE **Workloads** page. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload/overview) \n- In the **Name** column, click the name of the app you deployed, **hello-world-app** .\n- The table links to the load balancing Service you configured for the workload.\n- In the **Name** column of the **Exposing services** table, click the name of the Service.\n- On the **Service details** page, click the **YAML** tab.\n- Notice the second line is `kind: Service` , which defines this file as a specification for a Kubernetes Service resource.\n- Find the line that starts with `spec:` (ignore the line that starts with `f:spec:` ).All of the subsequent lines in a Service specification configure the load balancer.- The cluster IP addresses are the internal addresses that the load balancer sends traffic to. These IP addresses are automatically managed by GKE.\n- The ingress IP address is the external IP address on which the load balancer listens for requests.\n- As with the Deployment specification, you can edit the Service YAML directly by clicking .To download this specification as a file and use it as the basis for other Services, click .\nThis is the end of the cluster tour.## What's next\n- Learn the basics of [configuring a cluster for staging andtesting your web app](/kubernetes-engine/docs/tutorials/admin-workflow) \n- [Update and deploy from an IDE](/kubernetes-engine/docs/tutorials/developer-workflow) \n- [Clean up to avoid billing charges](/kubernetes-engine/docs/quickstarts/learning-path-cleanup) . If you plan to take additional tutorials, wait until you finish those tutorials before you clean up. You can use the sample Kubernetes cluster in most GKE tutorials.", "guide": "Google Kubernetes Engine (GKE)"}