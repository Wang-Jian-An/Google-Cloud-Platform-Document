{"title": "Google Kubernetes Engine (GKE) - Provisioning regional persistent disks", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/regional-pd", "abstract": "# Google Kubernetes Engine (GKE) - Provisioning regional persistent disks\nThis page explains how to enable dynamic provisioning of [regional persistentdisks](/kubernetes-engine/docs/concepts/persistent-volumes#regional_persistent_disks) and how to provision them manually in Google Kubernetes Engine (GKE).\nFor creating end-to-end solutions for high-availability applications with regional persistent disks, see [Increase stateful app availability with Stateful HA Operator](/kubernetes-engine/docs/how-to/stateful-ha) .\n", "content": "## Regional persistent disks\n**Note:** To use regional persistent disks of type `pd-balanced` , set the `PersistentVolumeClaim.storage` attribute to `200Gi` or higher. If you need a smaller volume, use `pd-ssd` instead of `pd-balanced` .\nAs with zonal persistent disks, regional persistent disks can be dynamically provisioned as needed or manually provisioned in advance by the cluster administrator, although dynamic provisioning is recommended.\n**Note:** This example uses the [Compute Engine persistent disk CSI driver](/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver) . CSI volumes use `topology.gke.io/zone` labels on persistent volumes and in the `CSINode` resources. The Kubernetes in-tree provisioner, `kubernetes.io/gce-pd` , uses beta labels on persistent volumes and the node, like `failure-domain.beta.kubernetes.io/zone` . These have been [deprecated in GKE 1.17 and later](/kubernetes-engine/docs/release-notes#1.17-changes) , In-tree volumes from 1.21 are updated to use the new labels (for example, `topology.kubernetes.io/zone` ). Because of this complication using the CSI driver is recommended.\nTo enable dynamic provisioning of regional persistent disks, create a `StorageClass` with the `replication-type` parameter, and specify zone constraints in `allowedTopologies` .\nFor example, the following manifest describes a `StorageClass` named `regionalpd-storageclass` that uses standard persistent disks and that replicates data to the `europe-west1-b` and `europe-west1-c` zones:\n```\nkind: StorageClassapiVersion: storage.k8s.io/v1metadata:\u00a0 name: regionalpd-storageclassprovisioner: pd.csi.storage.gke.ioparameters:\u00a0 type: pd-balanced\u00a0 replication-type: regional-pdvolumeBindingMode: WaitForFirstConsumerallowedTopologies:- matchLabelExpressions:\u00a0 - key: topology.gke.io/zone\u00a0 \u00a0 values:\u00a0 \u00a0 - europe-west1-b\u00a0 \u00a0 - europe-west1-c\n```\nIf using a regional cluster, you can leave `allowedTopologies` unspecified. If you do this, when you create a Pod that consumes a `PersistentVolumeClaim` which uses this `StorageClass` a regional persistent disk is provisioned with two zones. One zone is the same as the zone that the Pod is scheduled in. The other zone is randomly picked from the zones available to the cluster.\nWhen using a zonal cluster, `allowedTopologies` must be set.\nOnce the `StorageClass` is created, next create a `PersistentVolumeClaim` object, using the `storageClassName` field to refer to the `StorageClass` . For example, the following manifest creates a `PersistentVolumeClaim` named `regional-pvc` and references the `regionalpd-storageclass` :\n```\napiVersion: v1kind: PersistentVolumeClaimmetadata:\u00a0 name: regional-pvcspec:\u00a0 accessModes:\u00a0 \u00a0 - ReadWriteOnce\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: 500Gi\u00a0 storageClassName: regionalpd-storageclass\n```\nSince the `StorageClass` is configured with `volumeBindingMode: WaitForFirstConsumer` , the `PersistentVolume` is not provisioned until a Pod using the `PersistentVolumeClaim` has been created.\nThe following manifest is an example Pod using the previously created `PersistentVolumeClaim` :\n```\nkind: PodapiVersion: v1metadata:\u00a0 name: task-pv-podspec:\u00a0 volumes:\u00a0 \u00a0 - name: task-pv-storage\u00a0 \u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0 claimName: regional-pvc\u00a0 containers:\u00a0 \u00a0 - name: task-pv-container\u00a0 \u00a0 \u00a0 image: nginx\u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 80\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: \"http-server\"\u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - mountPath: \"/usr/share/nginx/html\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: task-pv-storage\n```\nFirst, create a regional persistent disk using the [gcloud compute disks create](/sdk/gcloud/reference/compute/disks/create) command. The following example creates a disk named `gce-disk-1` replicated to the `europe-west1-b` and `europe-west1-c` zones:\n```\ngcloud compute disks create gce-disk-1 \\\u00a0 \u00a0--size 500Gi \\\u00a0 \u00a0--region europe-west1 \\\u00a0 \u00a0--replica-zones europe-west1-b,europe-west1-c\n```\nYou can then create a `PersistentVolume` that references the regional persistent disk you just created. In addition to objects in [Using preexisting Persistent Disks as PersistentVolumes](/kubernetes-engine/docs/how-to/persistent-volumes/preexisting-pd) , the `PersistentVolume` for a regional persistent disk should also specify a [node-affinity](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#node-affinity) . If you use a `StorageClass` , it should specify the persistent disk CSI driver.\nHere's an example of a `StorageClass` manifest that uses standard persistent disks and that replicates data to the `europe-west1-b` and `europe-west1-c` zones:\n```\nkind: StorageClassapiVersion: storage.k8s.io/v1metadata:\u00a0 name: regionalpd-storageclassprovisioner: pd.csi.storage.gke.ioparameters:\u00a0 type: pd-balanced\u00a0 replication-type: regional-pdvolumeBindingMode: WaitForFirstConsumerallowedTopologies:- matchLabelExpressions:\u00a0 - key: topology.gke.io/zone\u00a0 \u00a0 values:\u00a0 \u00a0 - europe-west1-b\u00a0 \u00a0 - europe-west1-c\n```\nHere's an example manifest that creates a `PersistentVolume` named `pv-demo` and references the `regionalpd-storageclass` :\n```\napiVersion: v1kind: PersistentVolumemetadata:\u00a0 name: pv-demospec:\u00a0 storageClassName: \"regionalpd-storageclass\"\u00a0 capacity:\u00a0 \u00a0 \u00a0storage: 500Gi\u00a0 accessModes:\u00a0 \u00a0 \u00a0- ReadWriteOnce\u00a0 claimRef:\u00a0 \u00a0 namespace: default\u00a0 \u00a0 name: pv-claim-demo\u00a0 csi:\u00a0 \u00a0 driver: pd.csi.storage.gke.io\u00a0 \u00a0 volumeHandle: projects/PROJECT_ID/regions/europe-west1/disks/gce-disk-1\u00a0 nodeAffinity:\u00a0 \u00a0 required:\u00a0 \u00a0 \u00a0 nodeSelectorTerms:\u00a0 \u00a0 \u00a0 \u00a0 - matchExpressions:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - key: topology.gke.io/zone\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 operator: In\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 values:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- europe-west1-b\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0- europe-west1-c\n```\nNote the following for the `PersistentVolume` example:- The`volumeHandle`field contains details from the`gcloud compute disks create`call, including your``.\n- The`claimRef.namespace`field must be specified even when it is set to`default`.## Naming persistent disks\nKubernetes cannot distinguish between zonal and regional persistent disks with the same name. As a workaround, ensure that persistent disks have unique names. This issue does not occur when using dynamically provisioned persistent disks.\n## What's next\n- Take a tutorial to learn about [Deploying WordPress on GKE with Persistent Disks and Cloud SQL](/kubernetes-engine/docs/tutorials/persistent-disk) .", "guide": "Google Kubernetes Engine (GKE)"}