{"title": "Google Kubernetes Engine (GKE) - About Hyperdisk for GKE", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/hyperdisk", "abstract": "# Google Kubernetes Engine (GKE) - About Hyperdisk for GKE\nGoogle Cloud Hyperdisk is a network block storage option offered on GKE. You can use this storage option in your GKE clusters in a similar way as with other Compute Engine Persistent Disk volumes with added flexibility to tune performance for your workload. Compared to Persistent Disk storage, Hyperdisk provides substantially higher maximum input/output operations per second (IOPS) and throughput. Unlike Persistent Disk volumes where performance is shared across all volumes attached to a node, with Hyperdisk, you can specify and tune the level of performance for each Hyperdisk volume.\n**Note:** Google Cloud Hyperdisk support is subject to the disks and machine type of your node. Refer to the [Compute Engine documentation](/compute/docs/disks/hyperdisks) for the latest supported machine types, performance limits, and capacity limits per VM.\nYou can choose from the following Hyperdisk options on GKE:\n| Storage option  | GKE operation mode | Description                                              |\n|:---------------------|:---------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Hyperdisk Balanced | Autopilot Standard | The best fit for most workloads. This is a good option for deploying most enterprise and line-of-business apps, as well as databases and web servers.            |\n| Hyperdisk Throughput | Autopilot Standard | Optimized for cost-efficient high-throughput. This is a good option if your use case targets scale-out analytics (for example, Hadoop or Kafka) and throughput-oriented cost-sensitive workloads. |\n| Hyperdisk Extreme | Autopilot Standard | Optimized for IOPS performance. This is a good option if you are deploying high-performance workloads, such as database management systems.              |\n", "content": "## Benefits\n- With Hyperdisk, you have more predictable performance on stateful workloads that you deploy.\n- With Hyperdisk, you can easily provision, manage, and scale your stateful workloads on GKE without the cost and complexity of managing a on-premises storage area network (SAN).\n- Hyperdisk storage capacity is partitioned and made available to GKE nodes as individual volumes. Hyperdisk volumes are decoupled from nodes enabling you to attach, detach, and move volumes between nodes. Data stored in Hyperdisk volumes persist over node reboots and deletions. You can also add multiple Hyperdisk volumes to a single GKE node.## Pricing\nYou are billed for the total provisioned capacity of your Hyperdisk volumes until you delete them. You are charged per GiB per month. Additionally, you are billed for the following:\n- Hyperdisk Balanced charges a monthly rate for the provisioned IOPS and provisioned throughput (in MiBps) in excess of the baseline values of 3,000\u00a0IOPS and 140\u00a0MiBps throughput.\n- Hyperdisk Extreme charges a monthly rate based on the provisioned IOPS.\n- Hyperdisk Throughput charges a monthly rate based on the provisioned throughput (in MiBps).\nFor pricing information, refer to [Disk pricing](/compute/disks-image-pricing#disk) in the Compute Engine documentation.\n## Limitations\n- After volume creation, you can only modify the following settings through the Compute Engine API:- Throughput: Hyperdisk Throughput and Hyperdisk Balanced volumes\n- IOPS: Hyperdisk Extreme and Hyperdisk Balanced volumes\n- You can only attach Hyperdisk volumes to [specific instancetypes](/compute/docs/machine-resource#machine_type_comparison) ; Read-Only attachments are not supported.\n- See the [Restrictions and Limitations](/compute/docs/disks/hyperdisks#hyperdisk_limits) section in the Compute Engine documentation for additional information.## Hyperdisk and Autopilot Compute Classes\nIf you want to use Hyperdisk on Autopilot clusters that use [Compute Classes](/kubernetes-engine/docs/concepts/autopilot-compute-classes) , make sure your node's machine type is both [supported by Hyperdisk](/compute/docs/disks/hyperdisks#machine-type-support) and [supported by the Compute Class](/kubernetes-engine/docs/concepts/autopilot-compute-classes#when-to-use) .\nThe following example shows how you can specify the `nodeSelector` property to control Pod scheduling on Autopilot clusters with the **Performance** Compute Class, when using Hyperdisk Balanced.\n```\ncloud.google.com/compute-class: \"Performance\"cloud.google.com/machine-famility: \"c3\"\n```\nFor more information, see [Choose Compute Classes for Autopilot Pods](/kubernetes-engine/docs/how-to/autopilot-compute-classes#request-compute-class) .\n## Plan the performance level for your Hyperdisk volumes\nUse the following considerations to plan the right level of performance for your Hyperdisk volumes.\nWith Hyperdisk Balanced, you can provision capacity separately from throughput and IOPS. To provision throughput or IOPS, you select the level for a given volume. Individual volumes have full throughput isolation\u2014each volume can use all the specified throughput or IOPS capacity for that volume. However, the throughput or IOPS is ultimately limited by per-instance limits on the VM instance to which your volumes are attached. To learn more about these limits, see [About Google Cloud Hyperdisk](/compute/docs/disks/hyperdisks) in the Compute Engine documentation.\nBoth read and write operations count against the throughput and IOPS limit provisioned for a Hyperdisk Balanced volume. The throughput or IOPS provisioned and the maximum limits apply to the combined total of read and write operations.\nIf the total throughput or IOPS provisioned for one or more Hyperdisk volumes exceeds the total throughput or IOPS available at the VM instance level, the performance is limited to the instance performance level.\nWith Hyperdisk Throughput, you can provision capacity separately from throughput. To provision throughput, you select the level for a given volume. Individual volumes have full throughput isolation\u2014each gets the throughput provisioned to it. However, the throughput is ultimately capped by per-instance limits on the VM instance to which your volumes are attached. To learn more about these limits, see [About Google Cloud Hyperdisk](/compute/docs/disks/hyperdisks) in the Compute Engine documentation.\nBoth read and write operations count against the throughput limit provisioned for a Hyperdisk Throughput volume. The throughput provisioned and the maximum limits apply to the combined total of read and write throughput.\nWhen defining a StorageClass, throughput provisioned for Hyperdisk Throughput volumes must follow these rules:- At least 10\u00a0MiBps per TiB of capacity, and no more than 90\u00a0MiBps per TiB of capacity, depending on the machine type.\n- At most 600\u00a0MiBps per volume, depending on the machine type.\nIf the total throughput provisioned for one or more Hyperdisk Throughput volumes exceeds the total throughput available at the VM instance level, the throughput is limited to the instance throughput level.\nWith Hyperdisk Extreme, you can provision capacity separately from the IOPS level. To provision the IOPS level, you select the desired level for a given volume. Individual volumes have full IOPS level isolation\u2014each gets the IOPS level provisioned to it. However, the IOPS is ultimately capped by per-instance limits on the VM instance to which your volumes are attached. To learn more about these limits, see [About Google Cloud Hyperdisk](/compute/docs/disks/hyperdisks) in the Compute Engine documentation.\nBoth read and write operations count against the IOPS limit provisioned for a Hyperdisk Extreme volume. The IOPS provisioned, and the maximum limits listed in this document, apply to the total of read and write IOPS.\nWhen defining a StorageClass, IOPS provisioned for Hyperdisk Extreme volumes must be no more than 350,000 IOPS, depending on the machine type.\nIf the total IOPS provisioned for one or more Hyperdisk Extreme volumes exceeds the total IOPS available at the VM instance level, the performance is limited to the instance IOPS level. If there are multiple Hyperdisk and Persistent Disk volumes attached to the same VM requesting IOPS at the same time, and the VM limits are reached, then each volume has an IOPS level proportional to their share in the total IOPS provisioned across all attached Hyperdisk Extreme volumes.\n## What's next\n- [Create a storage class for Hyperdisk Balanced, Throughput, or Extreme](/kubernetes-engine/docs/how-to/persistent-volumes/hyperdisk#create-storageclass) .\n- [Learn how to migrate Persistent Disk volumes to Hyperdisk](/compute/docs/disks/migrate-to-hyperdisk#gcloud) .\n- [Scale your storage performance using Hyperdisk on GKE](/kubernetes-engine/docs/how-to/persistent-volumes/hyperdisk) .", "guide": "Google Kubernetes Engine (GKE)"}