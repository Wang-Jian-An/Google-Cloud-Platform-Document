{"title": "Google Kubernetes Engine (GKE) - Set up Elastic Stack on GKE", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/elk-stack", "abstract": "# Google Kubernetes Engine (GKE) - Set up Elastic Stack on GKE\nThis tutorial shows you how to run [Elastic Stack](https://www.elastic.co/elastic-stack) on GKE using the Elastic Cloud on Kubernetes (ECK) operator.\nElastic Stack is a popular open source solution used for logging, monitoring, and analyzing data in real-time. Using Elastic Stack on GKE, you can benefit from the scalability and reliability provided by GKE Autopilot and the powerful Elastic Stack features.\nThis tutorial is intended for Kubernetes administrators or site reliability engineers.", "content": "## Objectives\n- Create a GKE cluster.\n- Deploy the ECK operator.\n- Configure Elasticsearch clusters and Kibana using the ECK operator.\n- Deploy a complete Elastic Stack using the ECK operator.\n- Autoscale Elasticsearch clusters and upgrade the Elastic Stack deployment.\n- Use Elastic Stack to monitor Kubernetes environments.\n## Costs\nIn this document, you use the following billable components of Google Cloud:- [GKE](/kubernetes-engine/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin- Grant roles to your Google Account. Run the following command once for each of the following   IAM roles: `roles/container.clusterAdmin` ```\ngcloud projects add-iam-policy-binding PROJECT_ID --member=\"user:EMAIL_ADDRESS\" --role=ROLE\n```- Replace``with your project ID.\n- Replace``with your email address.\n- Replace``with each individual role.- You must own a domain name. The domain name must be no longer than 63 characters. You can use [Cloud Domains](/domains/docs) or another registrar.\n## Prepare the environmentIn this tutorial, you use [Cloud Shell](/shell) to manage resources hosted on Google Cloud. Cloud Shell is preinstalled with the software you need for this tutorial, including [kubectl](https://kubernetes.io/docs/reference/kubectl/) , [Helm](https://helm.sh/) , and the [gcloud CLI](/sdk/gcloud) .\nTo set up your environment with Cloud Shell, follow these steps:- Launch a Cloud Shell session from the Google Cloud console, by clicking **Activate Cloud Shell** in the [Google Cloud console](https://console.cloud.google.com/) . This launches a session in the bottom pane of the Google Cloud console.\n- Add a Helm chart repository and update it:```\nhelm repo add elastic https://helm.elastic.cohelm repo update\n```\n- Clone the GitHub repository:```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples.git\n```\n- Change to the working directory:```\ncd kubernetes-engine-samples/observability/elastic-stack-tutorial\n```\n## Create a GKE clusterCreate a GKE cluster with control plane metrics collection enabled:\n```\ngcloud container clusters create-auto elk-stack \\\u00a0 \u00a0 --location=\"us-central1\" \\\u00a0 \u00a0 --monitoring=\"SYSTEM,WORKLOAD,API_SERVER,SCHEDULER,CONTROLLER_MANAGER\"\n```## Deploy the ECK operatorElastic Cloud on Kubernetes (ECK) is a platform for deploying and managing the Elastic Stack on Kubernetes clusters.\nECK automates the deployment and management of Elastic Stack clusters, simplifying the process of setting up and maintaining Elastic Stack on Kubernetes. It provides a set of Kubernetes custom resources that you can use to create and configure Elasticsearch, Kibana, Application Performance Management Server, and other Elastic Stack components in Kubernetes. This lets developers and DevOps teams configure and manage Elastic Stack clusters at scale.\nECK supports multiple Elasticsearch nodes, automatic application failover, seamless upgrades, and SSL encryption. ECK also includes features that let you monitor and troubleshoot Elasticsearch performance.\n **Note** : This tutorial provides instructions for working with this app: ECK version 2.8.0. The instructions might not represent newer versions of the app. For more information, see the documentation: [ECK](https://www.elastic.co/downloads/elastic-cloud-kubernetes) .- Install the ECK Helm chart:```\nhelm upgrade --install \"elastic-operator\" \"elastic/eck-operator\" \\\u00a0 \u00a0 --version=\"2.8.0\" \\\u00a0 \u00a0 --create-namespace \\\u00a0 \u00a0 --namespace=\"elastic-system\" \\\u00a0 \u00a0 --set=\"resources.limits.cpu=250m\" \\\u00a0 \u00a0 --set=\"resources.limits.memory=512Mi\" \\\u00a0 \u00a0 --set=\"resources.limits.ephemeral-storage=1Gi\" \\\u00a0 \u00a0 --set=\"resources.requests.cpu=250m\" \\\u00a0 \u00a0 --set=\"resources.requests.memory=512Mi\" \\\u00a0 \u00a0 --set=\"resources.requests.ephemeral-storage=1Gi\"\n```\n- Wait for the operator to be ready:```\nwatch kubectl get pods -n elastic-system\n```The output is similar to the following:```\nNAME     READY STATUS RESTARTS AGE\nelastic-operator-0 1/1  Running 0   31s \n```When the operator `STATUS` is `Running` , return to the command line by pressing `Ctrl+C` .\n## Configure Elastic Stack with ECKBy using Elastic Stack with Elasticsearch, Kibana, and Elastic Agent working in Fleet mode, you can set up a powerful, scalable, and fully-managed solution for managing and visualizing data using Kibana.\nKibana is an open source data analytics and visualization tool that lets you search, analyze and visualize data in Elasticsearch.\nElastic Agent is a lightweight data shipper that collects data from different sources, such as logs or metrics, and automatically sends it to Elasticsearch.\nElastic Fleet is a mode of operation in which Elastic agents report to a central fleet server, which handles their configuration and management. The fleet server simplifies the deployment, configuration, and scaling of Elastic agents, making it easier to manage large and complex deployments.\nElasticsearch autoscaling is a self-monitoring feature that can report when additional resources are needed based on an operator-defined policy. For example, a policy might specify that a certain tier should scale based on available disk space. Elasticsearch can monitor the disk space and suggest scaling if it predicts a shortage, although it is still up to the operator to add the necessary resources. For more information about Elasticsearch autoscaling see [Autoscaling](https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-autoscaling.html) in the Elasticsearch documentation.\n### Configure an Elasticsearch clusterElasticsearch provides a distributed, RESTful search and analytics engine designed to store and search large volumes of data quickly and efficiently.\nWhen deploying Elastic Stack on Kubernetes, you should manage the VM settings, specifically the `vm.max_map_count setting` , which is required by Elasticsearch. `vm.max_map_count` specifies the number of memory areas that a process can allocate to a file. Elasticsearch must have this value set to at least `262144` to run optimally. For more information, see [Virtual memory](https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-virtual-memory.html#k8s-virtual-memory) in the ECK documentation.\n **Note** : This tutorial provides instructions for working with this app: Elastic version 8.9.0. The instructions might not represent newer versions of the app. For more information, see the documentation: [Elastic](https://www.elastic.co/downloads/elasticsearch) .- Review the following manifest: [  observability/elastic-stack-tutorial/max-map-count-setter-ds.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/max-map-count-setter-ds.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/max-map-count-setter-ds.yaml) ```\napiVersion: scheduling.k8s.io/v1kind: PriorityClassmetadata:\u00a0 name: user-daemonset-priorityvalue: 999999999preemptionPolicy: PreemptLowerPriorityglobalDefault: falsedescription: \"User DaemonSet priority\"\n```This manifest describes a DaemonSet that configures the kernel setting on the host directly. This manifest is on an allowlist to run on Autopilot. Don't modify this manifest, including the container images.\n- Apply this manifest to your cluster:```\nkubectl apply -f max-map-count-setter-ds.yaml\n```\n- Review the following manifest: [  observability/elastic-stack-tutorial/elasticsearch.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/elasticsearch.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/elasticsearch.yaml) ```\napiVersion: elasticsearch.k8s.elastic.co/v1kind: Elasticsearchmetadata:\u00a0 name: elasticsearch\u00a0 namespace: elastic-systemspec:\u00a0 version: \"8.9.0\"\u00a0 volumeClaimDeletePolicy: DeleteOnScaledownOnly\u00a0 podDisruptionBudget:\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 minAvailable: 2\u00a0 \u00a0 \u00a0 selector:\u00a0 \u00a0 \u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 elasticsearch.k8s.elastic.co/cluster-name: elasticsearch\u00a0 nodeSets:\u00a0 \u00a0 - name: default\u00a0 \u00a0 \u00a0 config:\u00a0 \u00a0 \u00a0 \u00a0 node.roles: [\"master\", \"data\", \"ingest\", \"ml\", \"remote_cluster_client\"]\u00a0 \u00a0 \u00a0 podTemplate:\u00a0 \u00a0 \u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/name: elasticsearch\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/version: \"8.9.0\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/component: \"elasticsearch\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/part-of: \"elk\"\u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/compute-class: \"Balanced\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 initContainers:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: max-map-count-check\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 command:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - sh\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - -c\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - while true; do mmc=$(cat /proc/sys/vm/max_map_count); if test ${mmc} -eq 262144; then exit 0; fi; sleep 1; done\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 10m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 16Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 16Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 10m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 16Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 16Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: elasticsearch\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 990m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 4080Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 1008Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 1000m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 4080Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 1008Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: ES_JAVA_OPTS\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"-Xms2g -Xmx2g\"\u00a0 \u00a0 \u00a0 count: 3\u00a0 \u00a0 \u00a0 volumeClaimTemplates:\u00a0 \u00a0 \u00a0 \u00a0 - metadata:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: elasticsearch-data # Do not change this name unless you set up a volume mount for the data path.\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 accessModes:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - ReadWriteOnce\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storage: 2Gi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storageClassName: standard-rwo\n```This manifest defines an Elasticsearch cluster with the following fields:- `initContainers`: waits for the virtual memory host's kernel settings to change.\n- `podDisruptionBudget`: specifies that the cluster won't be destroyed during the Pods' defragmentation process.\n- `config.node.roles`: Elasticsearch node roles configuration. For more information about node roles, see [Node](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html) in the Elasticsearch documentation.\n- Apply this manifest to your cluster:```\nkubectl apply -f elasticsearch.yaml\n```\n- Wait for the Elasticsearch cluster to be ready:```\nwatch kubectl --namespace elastic-system get elasticsearches.elasticsearch.k8s.elastic.co\n```The output is similar to the following:```\nNAME   HEALTH NODES VERSION PHASE AGE\nelasticsearch green 3  8.8.0  Ready 5m3s\n```When the Elasticsearch cluster `HEALTH` is `green` and `PHASE` is `Ready` , return to the command line by pressing `Ctrl+C` .\n## Configure Kibana **Note** : This tutorial provides instructions for working with this app: Elastic version 8.9.0. The instructions might not represent newer versions of the app. For more information, see the documentation: [Elastic](https://www.elastic.co/downloads/elasticsearch) .- Review the following manifest: [  observability/elastic-stack-tutorial/kibana.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/kibana.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/kibana.yaml) ```\napiVersion: kibana.k8s.elastic.co/v1kind: Kibanametadata:\u00a0 name: kibana\u00a0 namespace: elastic-systemspec:\u00a0 version: \"8.9.0\"\u00a0 count: 1\u00a0 elasticsearchRef:\u00a0 \u00a0 name: elasticsearch\u00a0 \u00a0 namespace: elastic-system\u00a0 http:\u00a0 \u00a0 tls:\u00a0 \u00a0 \u00a0 selfSignedCertificate:\u00a0 \u00a0 \u00a0 \u00a0 disabled: true\u00a0 config:\u00a0 \u00a0 server.publicBaseUrl: https://elk.BASE_DOMAIN\u00a0 \u00a0 xpack.reporting.kibanaServer.port: 5601\u00a0 \u00a0 xpack.reporting.kibanaServer.protocol: http\u00a0 \u00a0 xpack.reporting.kibanaServer.hostname: kibana-kb-http.elastic-system.svc\u00a0 \u00a0 xpack.fleet.agents.elasticsearch.hosts: [\"https://elasticsearch-es-http.elastic-system.svc:9200\"]\u00a0 \u00a0 xpack.fleet.agents.fleet_server.hosts: [\"https://fleet-server-agent-http.elastic-system.svc:8220\"]\u00a0 \u00a0 xpack.fleet.packages:\u00a0 \u00a0 - name: system\u00a0 \u00a0 \u00a0 version: latest\u00a0 \u00a0 - name: elastic_agent\u00a0 \u00a0 \u00a0 version: latest\u00a0 \u00a0 - name: fleet_server\u00a0 \u00a0 \u00a0 version: latest\u00a0 \u00a0 - name: kubernetes\u00a0 \u00a0 \u00a0 version: latest\u00a0 \u00a0 xpack.fleet.agentPolicies:\u00a0 \u00a0 - name: Fleet Server on ECK policy\u00a0 \u00a0 \u00a0 id: eck-fleet-server\u00a0 \u00a0 \u00a0 namespace: default\u00a0 \u00a0 \u00a0 monitoring_enabled:\u00a0 \u00a0 \u00a0 - logs\u00a0 \u00a0 \u00a0 - metrics\u00a0 \u00a0 \u00a0 unenroll_timeout: 900\u00a0 \u00a0 \u00a0 package_policies:\u00a0 \u00a0 \u00a0 - name: fleet_server-1\u00a0 \u00a0 \u00a0 \u00a0 id: fleet_server-1\u00a0 \u00a0 \u00a0 \u00a0 package:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: fleet_server\u00a0 \u00a0 - name: Elastic Agent on ECK policy\u00a0 \u00a0 \u00a0 id: eck-agent\u00a0 \u00a0 \u00a0 namespace: default\u00a0 \u00a0 \u00a0 monitoring_enabled:\u00a0 \u00a0 \u00a0 - logs\u00a0 \u00a0 \u00a0 - metrics\u00a0 \u00a0 \u00a0 unenroll_timeout: 900\u00a0 \u00a0 \u00a0 package_policies:\u00a0 \u00a0 \u00a0 - package:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: system\u00a0 \u00a0 \u00a0 \u00a0 name: system-1\u00a0 \u00a0 \u00a0 - package:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: kubernetes\u00a0 \u00a0 \u00a0 \u00a0 name: kubernetes-1\u00a0 podTemplate:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/name: kibana\u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/version: \"8.9.0\"\u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/component: \"ui\"\u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/part-of: \"elk\"\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: kibana\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 1Gi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 500m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 1Gi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 1Gi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 500m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 1Gi\n```This manifest describes a Kibana custom resource that configures agent policies for the fleet server and agents.\n- Apply this manifest to your cluster:```\nkubectl apply -f kibana.yaml\n```\n- Wait for the Pods to be ready:```\nwatch kubectl --namespace elastic-system get kibanas.kibana.k8s.elastic.co\n```The output is similar to the following:```\nNAME  HEALTH NODES VERSION AGE\nkibana green 1  8.8.0  6m47s\n```When the Pods `HEALTH` is `green` , return to the command line by pressing `Ctrl+C` .\n## Configure a load balancer to access KibanaTo access Kibana, create a Kubernetes Ingress object, a Google-managed certificate, a global IP address, and a DNS Zone.- Create global external IP address:```\ngcloud compute addresses create \"elastic-stack\" --global\n```\n- Create a managed zone and record set in Cloud DNS:```\ngcloud dns managed-zones create \"elk\" \\\u00a0 \u00a0 --description=\"DNS Zone for Airflow\" \\\u00a0 \u00a0 --dns-name=\"elk.BASE_DOMAIN\" \\\u00a0 \u00a0 --visibility=\"public\"gcloud dns record-sets create \"elk.BASE_DOMAIN\" \\\u00a0 \u00a0 --rrdatas=\"$(gcloud compute addresses describe \"elastic-stack\" --global --format=\"value(address)\")\" \\\u00a0 \u00a0 --ttl=\"300\" \\\u00a0 \u00a0 --type=\"A\" \\\u00a0 \u00a0 --zone=\"elk\"\n```\n- Delegate the DNS zone as a subdomain of the base domain by creating an NS record set with a name servers list. You can get a list of name servers using the following command:```\ngcloud dns record-sets describe elk.BASE_DOMAIN \\\u00a0 \u00a0 --type=\"NS\" \\\u00a0 \u00a0 --zone=\"elk\" \\\u00a0 \u00a0 --format=\"value(DATA)\"\n```\n- Review the following manifest: [  observability/elastic-stack-tutorial/ingress.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/ingress.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/ingress.yaml) ```\napiVersion: networking.gke.io/v1kind: ManagedCertificatemetadata:\u00a0 name: elastic-stack\u00a0 namespace: elastic-systemspec:\u00a0 domains:\u00a0 \u00a0 - elk.BASE_DOMAIN\n```This manifest describes a ManagedCertificate that provisions an SSL certificate to establish the TLS connection.\n- Apply the manifest to your cluster:```\nkubectl apply -f ingress.yaml\n```\n## Configure Elastic Agents **Note** : This tutorial provides instructions for working with this app: Elastic version 8.9.0. The instructions might not represent newer versions of the app. For more information, see the documentation: [Elastic](https://www.elastic.co/downloads/elasticsearch) .- Review the following manifest: [  observability/elastic-stack-tutorial/fleet-server-and-agents.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/fleet-server-and-agents.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/observability/elastic-stack-tutorial/fleet-server-and-agents.yaml) ```\napiVersion: agent.k8s.elastic.co/v1alpha1kind: Agentmetadata:\u00a0 name: fleet-server\u00a0 namespace: elastic-systemspec:\u00a0 version: 8.9.0\u00a0 kibanaRef:\u00a0 \u00a0 name: kibana\u00a0 \u00a0 namespace: elastic-system\u00a0 elasticsearchRefs:\u00a0 \u00a0 - name: elasticsearch\u00a0 \u00a0 \u00a0 namespace: elastic-system\u00a0 mode: fleet\u00a0 fleetServerEnabled: true\u00a0 policyID: eck-fleet-server\u00a0 deployment:\u00a0 \u00a0 replicas: 1\u00a0 \u00a0 podTemplate:\u00a0 \u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/name: fleet-server\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/version: \"8.9.0\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/component: \"agent\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 app.kubernetes.io/part-of: \"elk\"\u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: agent\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 512Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 250m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 10Gi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: 512Mi\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: 250m\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 10Gi\u00a0 \u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - name: \"agent-data\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 volumeClaimTemplate:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 accessModes: [\"ReadWriteOnce\"]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storageClassName: \"standard-rwo\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storage: 10Gi\u00a0 \u00a0 \u00a0 \u00a0 serviceAccountName: fleet-server\u00a0 \u00a0 \u00a0 \u00a0 automountServiceAccountToken: true\u00a0 \u00a0 \u00a0 \u00a0 securityContext:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 runAsUser: 0\n```This manifest describes an Elastic Agent that configures a fleet server with ECK.\n- Apply this manifest to your cluster:```\nkubectl apply -f fleet-server-and-agents.yaml\n```\n- Wait for the Pods to be ready:```\nwatch kubectl --namespace elastic-system get agents.agent.k8s.elastic.co\n```The output is similar to the following:```\nNAME   HEALTH AVAILABLE EXPECTED VERSION AGE\nelastic-agent green 5   5   8.8.0  14m\nfleet-server green 1   1   8.8.0  16m\n```When the Pods `HEALTH` is `green` , return to the command line by pressing `Ctrl+C` .\n## Configure logging and monitoringElastic Stack can use the kube-state-metrics exporter to collect cluster-level metrics.- Install kube-state-metrics:```\nhelm repo add prometheus-community https://prometheus-community.github.io/helm-chartshelm repo updatehelm install kube-state-metrics prometheus-community/kube-state-metrics --namespace elastic-system\n```\n- Get the default Kibana `elastic` user credentials:```\nkubectl get secret elasticsearch-es-elastic-user -o yaml -n elastic-system -o jsonpath='{.data.elastic}' | base64 -d\n```\n- Open `https://elk.` `` in your browser and login to Kibana with the credentials.\n- From the menu, select **Analytics** , then **Dashboards** .\n- In the search text field, enter **Kubernetes overview** and select **Overview dashboard** to see base metrics.Some of the dashboard panels might show no data or error messages because GKE limits access to some of the control plane endpoints that Kibana uses to get cluster metrics.\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- Delete a Google Cloud project:\n- ```\ngcloud projects delete PROJECT_ID\n```\n### Delete the individual resourcesIf you used an existing project and you don't want to delete it, delete the individual resources.- Delete the Elastic Stack components, ECK operator, and kube-state-metrics:```\nkubectl --namespace elastic-system delete ingresses.networking.k8s.io elastic-stackkubectl --namespace elastic-system delete managedcertificates.networking.gke.io elastic-stackkubectl --namespace elastic-system delete frontendconfigs.networking.gke.io elastic-stackkubectl --namespace elastic-system delete agents.agent.k8s.elastic.co elastic-agentkubectl --namespace elastic-system delete agents.agent.k8s.elastic.co fleet-serverkubectl --namespace elastic-system delete kibanas.kibana.k8s.elastic.co kibanakubectl --namespace elastic-system delete elasticsearches.elasticsearch.k8s.elastic.co elasticsearchkubectl --namespace elastic-system delete daemonsets.apps max-map-count-setterkubectl --namespace elastic-system delete pvc --selector='elasticsearch.k8s.elastic.co/cluster-name=elasticsearch'helm --namespace elastic-system uninstall kube-state-metricshelm --namespace elastic-system uninstall elastic-operator\n```\n- Delete the DNS record set, IP address, DNS managed zone, and GKE cluster:```\ngcloud dns record-sets delete \"elk.BASE_DOMAIN\" \\\u00a0 \u00a0 --type=\"A\" \\\u00a0 \u00a0 --zone=\"elk\" \\\u00a0 \u00a0 --quietgcloud compute addresses delete \"elastic-stack\" \\\u00a0 \u00a0 --global \\\u00a0 \u00a0 --quietgcloud dns managed-zones delete \"elk\" --quietgcloud container clusters delete \"elk-stack\" \\\u00a0 \u00a0 --location=\"us-central1\" \\\u00a0 \u00a0 --quiet\n```\n## What's next\n- Explore reference architectures, diagrams, and best practices about Google Cloud. Take a look at our [Cloud Architecture Center](/architecture) .", "guide": "Google Kubernetes Engine (GKE)"}