{"title": "Google Kubernetes Engine (GKE) - Using the Compute Engine persistent disk CSI Driver", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver", "abstract": "# Google Kubernetes Engine (GKE) - Using the Compute Engine persistent disk CSI Driver\nGoogle Kubernetes Engine (GKE) provides a simple way for you to automatically deploy and manage the [Compute Engine persistent disk Container Storage Interface (CSI) Driver](https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver) in your clusters. The Compute Engine persistent disk CSI Driver is always enabled in Autopilot clusters and can't be disabled or edited. In Standard clusters, you must enable the Compute Engine persistent disk CSI Driver.\nThe Compute Engine persistent disk CSI Driver version is tied to GKE version numbers. The Compute Engine persistent disk CSI Driver version is typically the latest driver available at the time that the GKE version is released. The drivers update automatically when the cluster is upgraded to the latest GKE patch.\n**Note:** Because the Compute Engine persistent disk CSI Driver and some of the other associated CSI components are deployed as separate containers, they incur resource usage (VM CPU, memory, and boot disk) on Kubernetes nodes. VM CPU usage is typically tens of millicores and memory usage is typically tens of MB. Boot disk usage is mostly incurred by the logs of the CSI driver and other system containers in the Deployment.\n", "content": "## Benefits\nUsing the Compute Engine persistent disk CSI Driver provides the following benefits:\n- It enables the automatic deployment and management of the persistent disk driver without having to manually set it up.\n- You can use customer-managed encryption keys (CMEKs). These keys are used to encrypt the data encryption keys that encrypt your data. To learn more about CMEK on GKE, see [Using CMEK](/kubernetes-engine/docs/how-to/using-cmek) .\n- You can use [volume snapshots](/kubernetes-engine/docs/how-to/persistent-volumes/volume-snapshots) with the Compute Engine persistent disk CSI Driver. Volume snapshots let you create a copy of your volume at a specific point in time. You can use this copy to bring a volume back to a prior state or to provision a new volume.\n- You can use [volume cloning](/kubernetes-engine/docs/how-to/persistent-volumes/volume-cloning) with the Compute Engine persistent disk CSI Driver in clusters running GKE version 1.22 and later. Volume cloning lets you create a duplicate of your volume at a specific point in time, provisioned with all of the data of from the source volume.\n- Bug fixes and feature updates are rolled out independently from minor Kubernetes releases. This release schedule typically results in a faster release cadence.## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n### Requirements\nTo use the Compute Engine persistent disk CSI Driver, your clusters must be using the following versions:\n- Linux clusters: GKE version 1.14 or later.\n- Windows clusters: GKE version 1.18 or later.\nIn version 1.22 and later, [CSI Migration is enabled](https://kubernetes.io/blog/2019/12/09/kubernetes-1-17-feature-csi-migration-beta/) . Existing volumes that use the `gce-pd` provider are migrated to communicate through CSI drivers instead. No changes are required to any StorageClass. The `gce-pd` provider continues to not support features such as CMEK or volume snapshots. You must use the `pd.csi.storage.gke.io` provider in the StorageClass to enable these features.\nTo use the Compute Engine persistent disk CSI Driver with [workload identity federation for GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity) , your Standard clusters must use the following versions:\n- Linux clusters: GKE version 1.16 or later.\n- Windows clusters: GKE version 1.20.8-gke.900 or later.\n**Note:** For [Autopilot](/kubernetes-engine/docs/concepts/autopilot-overview) , the Compute Engine persistent disk CSI Driver is enabled by default and cannot be disabled or edited. To use the driver, skip to [Use the Compute Engine persistent disk CSI Driver for Linux clusters](#using_the_for_linux_clusters) .\n## Enabling the Compute Engine persistent disk CSI Driver on a new cluster\n**Note:** The Compute Engine persistent disk CSI Driver is enabled by default on newly created clusters for the following versions: **Linux clusters** : GKE version 1.18.10-gke.2100 or  later, or 1.19.3-gke.2100 or later. **Windows clusters** : GKE version 1.22.6-gke.300 or later,  or 1.23.2-gke.300 or later.For Autopilot clusters, the Compute Engine persistent disk CSI Driver is enabled by default  and cannot be disabled or edited.\nTo create a Standard cluster with a version where the Compute Engine persistent disk CSI Driver is not automatically enabled, you can use the Google Cloud CLI or the Google Cloud console.\nTo enable the driver on cluster creation, complete the following steps:\n```\ngcloud container clusters create CLUSTER-NAME \\\u00a0 \u00a0 --addons=GcePersistentDiskCsiDriver \\\u00a0 \u00a0 --cluster-version=VERSION\n```\nReplace the following:- ``: the name of your cluster.\n- ``: the GKE version number. **You\nmust select a version of 1.14 or higher to use this feature.** \nFor the full list of flags, see the [gcloud container clusters create](/sdk/gcloud/reference/container/clusters/create) documentation.- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Click **Create** .\n- In the **Standard** section, click **Configure** .\n- Configure the cluster as desired.\n- From the navigation pane, under **Cluster** , click **Features** .\n- Select the **Enable Compute Engine persistent disk CSI Driver** checkbox.\n- Click **Create** .\nAfter you have enabled the Compute Engine persistent disk CSI Driver, you can use the driver in Kubernetes volumes using the driver and provisioner name: `pd.csi.storage.gke.io` .\n## Enabling the Compute Engine persistent disk CSI Driver on an existing cluster\nTo enable the Compute Engine persistent disk CSI Driver in existing Standard clusters, use the Google Cloud CLI or the Google Cloud console.\nTo enable the driver on an existing cluster, complete the following steps:\n```\ngcloud container clusters update CLUSTER-NAME \\\u00a0 \u00a0--update-addons=GcePersistentDiskCsiDriver=ENABLED\n```\nReplace `` with the name of the existing cluster.- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- In the cluster list, click the name of the cluster you want to modify.\n- Under **Features** , next to the **Compute Engine persistent disk CSIDriver** field, click **Edit ComputeEngine CSI driver** .\n- Select the **Enable Compute Engine Persistent Disk CSI Driver** checkbox.\n- Click **Save Changes** .## Disabling the Compute Engine persistent disk CSI Driver\nYou can disable the Compute Engine persistent disk CSI Driver for Standard clusters by using Google Cloud CLI or the Google Cloud console.\nIf you disable the driver, then any Pods currently using PersistentVolumes owned by the driver do not terminate. Any new Pods that try to use those PersistentVolumes also fail to start.\n**Note:** As the `gcePersistentDisk` volume type is migrated to the Compute Engine persistent disk CSI Driver in version 1.22 and later, if you disable the persistent disk CSI driver, the `gcePersistentDisk` volume type also stops working.\n**Warning:** There is a known issue in GKE 1.21 and earlier if you are using the in-tree persistent disk driver and want to delete regional disks. A Compute Engine regional disk can leak when its related `PersistentVolume` resource is deleted. This problem can be detected when your API call to delete the regional disk fails and returns an error code other than `NotFound` . For more information, see this [GitHub issue](https://github.com/kubernetes/kubernetes/issues/109328) .\nTo disable the driver on an existing Standard cluster, complete the following steps:\n```\ngcloud container clusters update CLUSTER-NAME \\\u00a0 \u00a0 --update-addons=GcePersistentDiskCsiDriver=DISABLED\n```\nReplace `` with the name of the existing cluster.- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- In the cluster list, click the name of the cluster you want to modify.\n- Under **Features** , next to the **Compute Engine persistent disk CSIDriver** field, click **Edit ComputeEngine CSI driver** .\n- Clear the **Enable Compute Engine Persistent Disk CSI Driver** checkbox.\n- Click **Save Changes** .## Using the Compute Engine persistent disk CSI Driver for Linux clusters\nThe following sections describe the typical process for using a Kubernetes volume backed by a CSI driver in GKE. These sections are specific to clusters using Linux.\n### Create a StorageClass\nAfter you enable the Compute Engine persistent disk CSI Driver, GKE automatically installs the following [StorageClasses](/kubernetes-engine/docs/concepts/persistent-volumes#storageclasses) :\n- `standard-rwo`, using balanced persistent disk\n- `premium-rwo`, using SSD persistent disk\nFor Autopilot clusters, the default StorageClass is `standard-rwo` , which uses the Compute Engine persistent disk CSI Driver. For Standard clusters, the default StorageClass uses the Kubernetes in-tree `gcePersistentDisk` volume plugin.\nYou can find the name of your installed StorageClasses by running the following command:\n```\nkubectl get sc\n```\nYou can also install a different StorageClass that uses the Compute Engine persistent disk CSI Driver by adding `pd.csi.storage.gke.io` in the provisioner field.\nFor example, you could create a StorageClass using the following file named `pd-example-class.yaml` :\n```\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:\u00a0 name: pd-exampleprovisioner: pd.csi.storage.gke.iovolumeBindingMode: WaitForFirstConsumerallowVolumeExpansion: trueparameters:\u00a0 type: pd-balanced\n```\nYou can specify the following [persistent disk types](/compute/docs/disks#disk-types) in the `type` parameter:\n- `pd-balanced`\n- `pd-ssd`\n- `pd-standard`\n- `pd-extreme`(supported on GKE version 1.26 and later)\nIf using `pd-standard` or `pd-extreme` , see [Unsupported machine types](#unsupported_machine_types) for additional usage restrictions.\nWhen you use the `pd-extreme` option, you must also add the `provisioned-iops-on-create` field to your manifest. This field must be set to the same value as the [provisionedIOPS value](/compute/docs/disks/extreme-persistent-disk#provisioning_iops) that you specified when you created your persistent disk.\n```\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:\u00a0 name: pd-extreme-exampleprovisioner: pd.csi.storage.gke.iovolumeBindingMode: WaitForFirstConsumerallowVolumeExpansion: trueparameters:\u00a0 type: pd-extreme\u00a0 provisioned-iops-on-create: '10000'\n```\nAfter creating the `pd-example-class.yaml` file, run the following command:\n```\nkubectl create -f pd-example-class.yaml\n```\n### Create a PersistentVolumeClaim\nYou can create a PersistentVolumeClaim that references the Compute Engine persistent disk CSI Driver's StorageClass.\nThe following file, named `pvc-example.yaml` , uses the pre-installed storage class `standard-rwo` :\n```\nkind: PersistentVolumeClaimapiVersion: v1metadata:\u00a0 name: podpvcspec:\u00a0 accessModes:\u00a0 - ReadWriteOnce\u00a0 storageClassName: standard-rwo\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: 6Gi\n```\nAfter creating the PersistentVolumeClaim manifest, run the following command:\n```\nkubectl create -f pvc-example.yaml\n```\nIn the pre-installed StorageClass ( `standard-rwo` ), `volumeBindingMode` is set to `WaitForFirstConsumer` . When `volumeBindingMode` is set to `WaitForFirstConsumer` , the PersistentVolume is not provisioned until a Pod referencing the PersistentVolumeClaim is scheduled. If `volumeBindingMode` in the StorageClass is set to `Immediate` (or it's omitted), a persistent-disk-backed PersistentVolume is provisioned after the PersistentVolumeClaim is created.\n### Create a Pod that consumes the volume\nWhen using Pods with PersistentVolumes, we recommend that you use a workload controller (such as a Deployment or StatefulSet). While you would not typically use a standalone Pod, the following example uses one for simplicity.\nThe following example consumes the volume that you created in the previous section:\n```\napiVersion: v1kind: Podmetadata:\u00a0 name: web-serverspec:\u00a0 containers:\u00a0 \u00a0- name: web-server\u00a0 \u00a0 \u00a0image: nginx\u00a0 \u00a0 \u00a0volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0- mountPath: /var/lib/www/html\u00a0 \u00a0 \u00a0 \u00a0 \u00a0name: mypvc\u00a0 volumes:\u00a0 \u00a0- name: mypvc\u00a0 \u00a0 \u00a0persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0claimName: podpvc\u00a0 \u00a0 \u00a0 \u00a0readOnly: false\n```\n## Using the Compute Engine persistent disk CSI Driver for Windows clusters\nThe following sections describe the typical process for using a Kubernetes volume backed by a CSI driver in GKE. These sections are specific to clusters using Windows.\nEnsure that the:\n- Cluster version is 1.19.7-gke.2000, 1.20.2-gke.2000, or later.\n- Node versions is 1.18.12-gke.1203, 1.19.6-gke.800, or later.\n### Create a StorageClass\nCreating a StorageClass for Windows is very similar to Linux. You should be aware that the StorageClass installed by default will not work for Windows because the file system type is different. Compute Engine persistent disk CSI Driver for Windows requires `NTFS` as the file system type.\nFor example, you could create a StorageClass using the following file named `pd- windows-class.yaml` . Make sure to add `csi.storage.k8s.io/fstype: NTFS` to the parameters list:\n```\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:\u00a0 name: pd-sc-windowsprovisioner: pd.csi.storage.gke.iovolumeBindingMode: WaitForFirstConsumerallowVolumeExpansion: trueparameters:\u00a0 type: pd-balanced\u00a0 csi.storage.k8s.io/fstype: NTFS\n```\n### Create a PersistentVolumeClaim\nAfter creating a StorageClass for Windows, you can now create a PersistentVolumeClaim that references that StorageClass:\n```\nkind: PersistentVolumeClaimapiVersion: v1metadata:\u00a0 name: podpvc-windowsspec:\u00a0 accessModes:\u00a0 - ReadWriteOnce\u00a0 storageClassName: pd-sc-windows\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: 6Gi\n```\n### Create a Pod that consumes the volume\nThe following example consumes the volume that you created in the previous task:\n```\napiVersion: v1kind: Podmetadata:\u00a0 name: web-serverspec:\u00a0 nodeSelector:\u00a0 \u00a0 kubernetes.io/os: windows\u00a0 containers:\u00a0 \u00a0 - name: iis-server\u00a0 \u00a0 \u00a0 image: mcr.microsoft.com/windows/servercore/iis\u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 - containerPort: 80\u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 - mountPath: /var/lib/www/html\u00a0 \u00a0 \u00a0 \u00a0 name: mypvc\u00a0 volumes:\u00a0 \u00a0 - name: mypvc\u00a0 \u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0 claimName: podpvc-windows\u00a0 \u00a0 \u00a0 \u00a0 readOnly: false\n```\n## Using the Compute Engine persistent disk CSI Driver with non-default filesystem types\nThe default filesystem type for Compute Engine persistent disks in GKE is `ext4` . You can also use the `xfs` storage type as long as your node image supports it. See [Storage driver support](/kubernetes-engine/docs/concepts/node-images#storage_driver_support) for a list of supported drivers by node image.\nThe following example shows you how to use `xfs` as the default filesystem type instead of `ext4` with the Compute Engine persistent disk CSI Driver.\n### Create a StorageClass\n- Save the following manifest as a YAML file named `pd-xfs-class.yaml` :```\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:\u00a0 name: xfs-classprovisioner: pd.csi.storage.gke.ioparameters:\u00a0 type: pd-balanced\u00a0 csi.storage.k8s.io/fstype: xfsvolumeBindingMode: WaitForFirstConsumer\n```\n- Apply the manifest:```\nkubectl apply -f pd-xfs-class.yaml\n```\n### Create a PersistentVolumeClaim\n- Save the following manifest as `pd-xfs-pvc.yaml` :```\napiVersion: v1kind: PersistentVolumeClaimmetadata:\u00a0 name: xfs-pvcspec:\u00a0 storageClassName: xfs-class\u00a0 accessModes:\u00a0 \u00a0 - ReadWriteOnce\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: 10Gi\n```\n- Apply the manifest:```\nkubectl apply -f pd-xfs-pvc.yaml\n```\n### Create a Pod that consumes the volume\n- Save the following manifest as `pd-xfs-pod.yaml` :```\napiVersion: v1kind: Podmetadata:\u00a0 name: pd-xfs-podspec:\u00a0 containers:\u00a0 - name: cloud-sdk\u00a0 \u00a0 image: google/cloud-sdk:slim\u00a0 \u00a0 args: [\"sleep\",\"3600\"]\u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 - mountPath: /xfs\u00a0 \u00a0 \u00a0 name: xfs-volume\u00a0 volumes:\u00a0 - name: xfs-volume\u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 claimName: xfs-pvc\n```\n- Apply the manifest:```\nkubectl apply -f pd-xfs-pod.yaml\n```\n### Verify that the volume was mounted correctly\n- Open a shell session in the Pod:```\nkubectl exec -it pd-xfs-pod -- /bin/bash\n```\n- Look for `xfs` partitions:```\ndf -aTh --type=xfs\n```The output should be similar to the following:```\nFilesystem  Type Size Used Avail Use% Mounted on\n/dev/sdb  xfs 30G 63M 30G 1% /xfs\n```## View logs for Compute Engine persistent disk CSI Driver\nYou can use Cloud Logging to view events that relate to the Compute Engine persistent disk CSI Driver. Logs can help you troubleshoot issues.\nFor more information about Cloud Logging, see [Viewing your GKE logs](/stackdriver/docs/solutions/gke/using-logs) .\nTo view logs for the Compute Engine persistent disk CSI Driver, complete the following steps:\n- Go to the **Cloud Logging** page in the Google Cloud console. [Go to Cloud Logging](https://console.cloud.google.com/logs) \n- Run the following query:```\n\u00a0resource.type=\"k8s_container\"\u00a0resource.labels.project_id=\"PROJECT_ID\"\u00a0resource.labels.location=\"LOCATION\"\u00a0resource.labels.cluster_name=\"CLUSTER_NAME\"\u00a0resource.labels.namespace_name=\"kube-system\"\u00a0resource.labels.container_name=\"gce-pd-driver\"\n```Replace the following:- ``: the name of your project.\n- ``: the Compute Engine region or zone of the cluster.\n- ``: the name of your cluster.\n## Known issues\n### Unsupported machine types\nIf you are using the C3 series machine family, the `pd-standard` persistent disk type is not supported.\nIf you attempt to run a Pod on a machine, and the Pod uses an unsupported persistent disk type, you will see a warning message like the following emitted on the Pod:\n```\nAttachVolume.Attach failed for volume \"pvc-d7397693-5097-4a70-9df0-b10204611053\" : rpc error: code = Internal desc = unknown Attach error: failed when waiting for zonal op: operation operation-1681408439910-5f93b68c8803d-6606e4ed-b96be2e7 failed (UNSUPPORTED_OPERATION): [pd-standard] features are not compatible for creating instance.\n```\nIf your cluster has multiple node pools with different machine families, you can use [node taints](/kubernetes-engine/docs/how-to/node-taints#create_a_cluster_with_node_taints) and [node affinity](/kubernetes-engine/docs/how-to/node-taints#configure_pods_to_tolerate_a_taint) to limit where workloads can be scheduled. For example, you can use this approach to restrict a workload using `pd-standard` from running on an unsupported machine family.\nIf you are using the `pd-extreme` persistent disk type, you need to ensure that your disk is attached to a VM instance with a suitable machine shape. To learn more, refer to [Machine shape support](/compute/docs/disks/extreme-persistent-disk#machine_shape_support) .\n## What's next\n- [Learn how to use volume expansion](/kubernetes-engine/docs/how-to/persistent-volumes/volume-expansion) .\n- [Learn how to use volume snapshots](/kubernetes-engine/docs/how-to/persistent-volumes/volume-snapshots) .\n- [Learn how to use volume cloning](/kubernetes-engine/docs/how-to/persistent-volumes/volume-cloning) .\n- [Read more about the driver on GitHub](https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver) .", "guide": "Google Kubernetes Engine (GKE)"}