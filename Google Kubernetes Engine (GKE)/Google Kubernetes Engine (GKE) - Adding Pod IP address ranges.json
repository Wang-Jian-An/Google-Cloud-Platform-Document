{"title": "Google Kubernetes Engine (GKE) - Adding Pod IP address ranges", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/multi-pod-cidr", "abstract": "# Google Kubernetes Engine (GKE) - Adding Pod IP address ranges\nThis page shows you how to add new or existing secondary Pod IP address ranges to GKE clusters with discontiguous multi-Pod CIDR.\n", "content": "## Why add more Pod IPv4 ranges\nAs a platform administrator, you can add more Pod IPv4 ranges by creating additional secondary ranges. This can be useful in the following scenarios:\n- When your cluster is running out of Pod IP addresses.\n- When you want to efficiently allocate IP addresses anticipating the future.\n- When you can use fragmented IP address spaces for your clusters.\n- When you can reallocate IP addresses in response to changing business needs.## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n- Review the [Add more Pod IPv4 ranges for specific use cases](/kubernetes-engine/docs/how-to/multi-pod-cidr#add_more_pod_ipv4_ranges_for_specific_use_cases) section.\n- Use [VPC-native clusters](/kubernetes-engine/docs/how-to/alias-ips) only.## Add more Pod IPv4 ranges with GKE Autopilot\nFor GKE Autopilot clusters on version 1.26 or later, you can add more Pod IPv4 ranges by creating additional secondary ranges and assigning them to the cluster.\n**Note:** For Standard clusters, you can also use the following configuration when you don't need to control the secondary Pod IP address assignment to node pools. With this configuration, GKE assigns the additional IP ranges at the cluster level, instead of assigning them at node pool level.\n### Create an additional secondary range for a subnet\n- Go to the **VPC networks** page in the Google Cloud console. [Go to VPC networks](https://console.cloud.google.com/networking/networks/list) \n- In the **VPC networks** list, select the network that you want to expand.\n- In the **Subnets** list, select the subnet that you want.\n- Click **Edit** .\n- Click **Add IP range** .\n- For **Subnet range name** , enter the additional Pod range name. For example, `pod-range-2` .\n- For **Secondary IP range** , enter the IP range. For example, `10.2.204.0/22` .\n- Click **Save** .\n```\ngcloud compute networks subnets update SUBNET_NAME \\\u00a0 \u00a0 --add-secondary-ranges ADDITIONAL_RANGE=RANGE \\\u00a0 \u00a0 --location=COMPUTE_LOCATION\n```\nReplace the following:- ``: The name of the subnet you want to add a range to (needs to be the subnet assigned to the cluster).\n- ``: The name of the Pod range to add to the cluster. For example,`pod-range-2`. To specify multiple ranges, separate the range names by a comma. For example,`pod-range-1`,`pod-range-2`.\n- ``: The IP address range to add to the cluster.\n- ``: The [Compute Engine location](/compute/docs/regions-zones/viewing-regions-zones) of the subnet.\n### Assign additional secondary ranges to the cluster\nCreate additional secondary ranges and assign them to the cluster. You can use the Google Cloud console or the Google Cloud CLI:\n- Go to the **Google Kubernetes Engine** page in the Google Cloud console. [Go to Google Kubernetes Engine](https://console.cloud.google.com/kubernetes/list) \n- Next to the cluster you want to edit, click **Actions** , then click **Edit** .\n- In the **Networking** section, next to **Cluster Pod IPv4 ranges(additional)** , click **Edit** .\n- In the **Edit additional Cluster Pod IPv4 ranges** dialog, select the **Pod secondary CIDR ranges** that you want to add to the cluster. Use the same Pod range name you created in the subnet as additional secondary ranges to the cluster.\n- Click **Save Changes** .\n- Update your cluster to use an additional IP address range:```\ngcloud container clusters update CLUSTER_NAME \\\u00a0 \u00a0 --additional-pod-ipv4-ranges=ADDITIONAL_RANGE \\\u00a0 \u00a0 --location=COMPUTE_LOCATION\n```Replace the following:- ``: The name of the cluster. Your cluster must be running version 1.26.0 or later.\n- ``: The name of the Pod range to add to the cluster. Use the same Pod range name you created in the subnet as additional secondary ranges to the cluster.\n- ``: The [Compute Engine location](/compute/docs/regions-zones/viewing-regions-zones) of the subnet.\n- Verify the new IP address is assigned to the cluster:```\ngcloud container clusters describe CLUSTER_NAME\n```The output is similar to the following:```\nipAllocationPolicy:additionalPodRangesConfig:\u00a0 podRangeNames:\u00a0 - pod-range-1\u00a0 - pod-range-2clusterIpv4Cidr: 10.10.0.0/23clusterIpv4CidrBlock: 10.10.0.0/23clusterSecondaryRangeName: cluster-pods\n```## Add more Pod IPv4 ranges with GKE Standard\nFor GKE Standard clusters, you can add more Pod IPv4 ranges by using any of the following methods:\n- Create and assign additional secondary ranges to the cluster: recommended for users that don't need to control the Pod IP address ranges at a node pool level. This method is available on GKE version 1.26.0 or later. For more information, see how to [Add more Pod IPv4 ranges with GKE Autopilot](#assign_additional_secondary_ranges_to_the_cluster) .\n- Create a node pool with a new secondary Pod IP address range: recommended for users that need to fully control the Pod IP address ranges of your node pools. This method is available on GKE version 1.20.4-gke.500 or later.\n- Create a node pool using an existing secondary Pod IP address: recommended for users that need to fully control the existing Pod IP address ranges of node pools. This method is available on GKE version 1.20.4-gke.500 or later.\n### Create a node pool with a new secondary Pod IP range\nBy default, GKE associates one Pod range to the node pool. This can be the cluster's default Pod IP address range or one of the additional Pod ranges (if any) associated with the cluster. With additional secondary ranges, you can specify a Pod IPv4 address range during node pool creation and the node pool uses that range instead of the cluster's default secondary Pod IP address range.\nIn this section, you create a node pool with a secondary Pod IP address range.\nYou can use the Google Cloud CLI or the GKE API.\n```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --cluster CLUSTER_NAME \\\u00a0 \u00a0 --create-pod-ipv4-range name=RANGE_NAME,range=RANGE\n```\nReplace the following:- ``: the name of the new node pool.\n- ``: the name of the cluster.\n- ``: an optional name of the new secondary Pod IP address range.\n- ``: an optional Pod IP address range provided as either a netmask (`/20`) or CIDR range (`10.12.4.0/20`). If you provide a netmask, GKE allocates a range from the available ranges in the cluster network. If you don't provide a value for the`range`, GKE automatically allocates a`/14`netmask, the default size for the subnet's [secondary IP range for Pods](/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing_secondary_range_pods) .\n **Note:** If you want to leave the `--create-pod-ipv4-range` flag empty, specify `\"\"` to make GKE use the default value instead. See the [gcloud beta container node-pools create documentation](/sdk/gcloud/reference/beta/container/node-pools/create#--create-pod-ipv4-range) for a full description of allowed values.\n```\n\"nodePool\": {\u00a0 \"name\": \"POOL_NAME\",\u00a0 ...\u00a0 \"networkConfig\": {\u00a0 \u00a0 \"createPodRange\": true,\u00a0 \u00a0 \"podRange\": \"RANGE_NAME\",\u00a0 \u00a0 \"podIpv4CidrBlock\": \"RANGE\"\u00a0 }}\n```\nReplace the following:- ``: the name of the new node pool.\n- ``: an optional name of the new secondary Pod IP address range.\n- ``: an optional Pod IP address range provided as either a netmask (`/20`) or CIDR range (`10.12.0.0/20`). If a netmask is specified, the IP range is automatically allocated from the free space in the cluster's network. If no value is provided, GKE automatically allocates a`/14`netmask, the default size for the subnet's [secondary IP range for Pods](/kubernetes-engine/docs/concepts/alias-ips#cluster_sizing_secondary_range_pods) .\n### Create a node pool using an existing secondary Pod IP range\nIn this section, you create a node pool with an existing secondary Pod IP address range.\nYou can use the gcloud CLI or the GKE API.\n```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --cluster CLUSTER_NAME \\\u00a0 \u00a0 --pod-ipv4-range RANGE_NAME\n```\nReplace the following:- ``: the name of the new node pool.\n- ``: the name of the cluster.\n- ``: the name of an existing secondary Pod IP address range in the cluster's subnetwork.\n```\n\"nodePool\": {\u00a0 \"name\": \"POOL_NAME\",\u00a0 ...\u00a0 \"networkConfig\": {\u00a0 \u00a0 \"podRange\": \"RANGE_NAME\"\u00a0 }}\n```\nReplace the following:- ``: the name of the new node pool.\n- ``: the name of an existing secondary Pod IP address range in the cluster's subnetwork.\n### Verify the Pod CIDR block for a node pool\nTo determine which Pod CIDR block is used for Pods in a given node pool, use the following command:\n```\ngcloud container node-pools describe POOL_NAME \\\u00a0 \u00a0 --cluster CLUSTER_NAME\n```\nThe output is similar to the following:\n```\n...\nnetworkConfig:\n podIpv4CidrBlock: 192.168.0.0/18\n podRange: podrange\n...\n```\nIf the node pool is using discontiguous multi-Pod CIDR, `podRange` and `podIpv4CidrBlock` display the configured values for this node pool.\nIf the node pool is not using discontiguous multi-Pod CIDR, `podRange` and `podIpv4CidrBlock` display the cluster's default values, `clusterSecondaryRangeName` and `clusterIpv4CidrBlock` from [IPAllocationPolicy](/kubernetes-engine/docs/reference/rest/v1/projects.locations.clusters#Cluster.IPAllocationPolicy) .\n## Add more Pod IPv4 ranges for specific use cases\n- If you use [ip-masq-agent](/kubernetes-engine/docs/how-to/ip-masquerade-agent) configured with the`nonMasqueradeCIDRs`parameter, you must update the`nonMasqueradeCIDRs`to include all additional secondary ranges.\n- If you use [NetworkPolicy](https://kubernetes.io/docs/concepts/services-networking/network-policies/) configured with an`ipBlock`to specify traffic, you must update the CIDR value to include all Pod CIDR ranges.\n- For Shared VPC, you need to [pre-set another Service Account](/compute/docs/access/service-accounts#user-managed) .\n- To add a secondary Pod IP address range to the cluster or to create a node pool with a new secondary Pod IP address range, you must have the [Network Admin role](/vpc/docs/shared-vpc#net_and_security_admins) . A user role can only use these resources if they are created by the Network Admin.\n- If your project has more than one cluster, ensure you [create and add a secondary Pod IP address range](#add_more_pod_ranges_standard) on each cluster.## How discontiguous multi-Pod CIDR works\nWhen you create a new node pool, by default the node pool uses the cluster's default Pod IP address range, also known as the cluster CIDR. With this feature, you can specify a Pod IP address range during node pool creation and the node pool uses that range instead of the cluster's default Pod IP address range.\nThe following diagram shows a [user-managed](/kubernetes-engine/docs/concepts/alias-ips#user-managed) cluster with a /24 CIDR block as a secondary Pod IP address range (256 IP addresses) and two nodes that use /25 CIDR blocks for Pod IP addresses (128 IP addresses each). The secondary Pod IP address range is exhausted and you cannot add another node to the cluster. Instead of deleting and re-creating the cluster you can use discontiguous multi-Pod CIDR to expand the Pod IP addresses with /20 CIDR blocks. The cluster expands to include a third node that uses /25 CIDR block for Pod IP addresses that come from the /20 block.### Modified firewall rule\nWhen GKE creates a cluster, it creates a [firewall rule](/kubernetes-engine/docs/concepts/firewall-rules) to enable Pod-to-Pod communication, `gke-[cluster-name]-[cluster-hash]-all` .\nWhen you create or delete a node pool with discontiguous multi-Pod CIDR enabled, GKE updates the source value of this firewall rule to all CIDRs used by the cluster for Pod IPs.\n## Troubleshooting\nYou can enable [VPC Flow Logs](/vpc/docs/using-flow-logs) to determine if packets are being sent to nodes correctly.\n## What's next\n- Learn more about [VPC-native clusters](/kubernetes-engine/docs/how-to/alias-ips) .\n- Read the [GKE network overview](/kubernetes-engine/docs/concepts/network-overview) .\n- Learn more about [Optimizing IP address allocation](/kubernetes-engine/docs/how-to/flexible-pod-cidr) .\n- [Learn about GKE IP address utilization insights](/network-intelligence-center/docs/network-analyzer/insights/kubernetes-engine/gke-ip-utilization) .", "guide": "Google Kubernetes Engine (GKE)"}