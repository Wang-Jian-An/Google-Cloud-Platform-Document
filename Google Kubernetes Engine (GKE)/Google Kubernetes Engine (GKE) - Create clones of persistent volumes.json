{"title": "Google Kubernetes Engine (GKE) - Create clones of persistent volumes", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/volume-cloning", "abstract": "# Google Kubernetes Engine (GKE) - Create clones of persistent volumes\nThis document shows you how to use Kubernetes volume cloning to clone [persistent volumes](/kubernetes-engine/docs/concepts/persistent-volumes) in your Google Kubernetes Engine (GKE) clusters.\n", "content": "## Overview\nA clone is a new independent volume that is a duplicate of an existing Kubernetes volume. A clone is similar to a [volume snapshot](/kubernetes-engine/docs/how-to/persistent-volumes/volume-snapshots) in that it's a copy of a volume at a specific point in time. However, rather than creating a snapshot object from the source volume, volume cloning provisions the clone with all the data from the source volume.\n## Requirements\nTo use volume cloning on GKE, you must meet the following requirements:\n- The source PersistentVolumeClaim must be in the same namespace as the destination PersistentVolumeClaim.\n- Use a CSI driver that supports volume cloning. The in-tree persistent disk driver does not support volume cloning.- The [Compute Engine persistent disk CSI Driver](https://github.com/kubernetes-sigs/gcp-compute-persistent-disk-csi-driver) version 1.4.0 and later supports volume cloning, and is installed by default on new Linux clusters running GKE version 1.22 or later. You can also [enable the Compute Engine persistent disk CSI Driver on an existing cluster](/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver#enabling_the_on_an_existing_cluster) .To verify the Compute Engine persistent disk CSI Driver version, run the following command in the gcloud CLI:\n```\nkubectl describe daemonsets pdcsi-node --namespace=kube-system | grep \"gke.gcr.io/gcp-compute-persistent-disk-csi-driver\"\n```\nIf the output shows a version earlier than `1.4.0` , [manually upgrade your control plane](/kubernetes-engine/docs/how-to/upgrading-a-cluster#upgrade_cp) to get the latest version.\n## Limitations\n- Both volumes must use the same [volume mode](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#volume-mode) . By default, GKE sets the VolumeMode to`ext4`.\n- All [restrictions for creating a disk clone from an existing disk](/compute/docs/disks/create-disk-from-source#restrictions) on Compute Engine also apply to GKE.\n- You can create a regional disk clone from a zonal disk, but you should be aware of the [restrictions of this approach](/compute/docs/disks/create-disk-from-source#restrictions_2) .- TODO(b/271605275): Remove once zonal mismatch fix is rolled out\n- Cloning must be done in a compatible zone. Use [allowedTopologies](https://kubernetes.io/docs/concepts/storage/storage-classes/#allowed-topologies) to restrict the topology of provisioned volumes to specific zones. Alternatively, [nodeSelectors](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector) or [Affinity and anti-affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity) can be used to constrain a Pod so that it is restricted to run on particular node that runs in a compatible zone.- For zonal to zonal cloning, the clone zone must match the source disk zone.\n- For zonal to regional cloning, one of the replica zones of the clone must match the zone of the source disk.\n## Using volume cloning\nTo provision a volume clone, you add a reference to an existing PersistentVolumeClaim in the same namespace to the `dataSource` field of a new PersistentVolumeClaim. The following exercise shows you how to provision a source volume with data, create a volume clone, and consume the clone.\n### Create a source volume\nTo create a source volume, follow the instructions in [Using the Compute Engine persistent disk CSI Driver for Linux clusters](/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver#using_the_for_linux_clusters) to create a StorageClass, a PersistentVolumeClaim, and a Pod to consume the new volume. You'll use the PersistentVolumeClaim that you create as the source for the volume clone.\n### Add a test file to the source volume\nAdd a test file to the source volume. You can look for this test file in the volume clone to verify that cloning was successful.\n- Create a test file in a Pod:```\nkubectl exec POD_NAME \\\u00a0 \u00a0 -- sh -c 'echo \"Hello World!\" > /var/lib/www/html/hello.txt'\n```Replace `` with the name of a Pod that consumes the source volume. For example, if you followed the instructions in [Using the Compute Engine persistent disk CSI Driver for Linux clusters](/kubernetes-engine/docs/how-to/persistent-volumes/gce-pd-csi-driver#using_the_for_linux_clusters) , replace `` with `web-server` .\n- Verify that the file exists:```\nkubectl exec POD_NAME \\\u00a0 \u00a0 -- sh -c 'cat /var/lib/www/html/hello.txt'\n```The output is similar to the following:```\nHello World!\n```\n### Clone the source volume\n- Save the following manifest as `podpvc-clone.yaml` :```\nkind: PersistentVolumeClaimapiVersion: v1metadata:\u00a0 name: podpvc-clonespec:\u00a0 dataSource:\u00a0 \u00a0 name: PVC_NAME\u00a0 \u00a0 kind: PersistentVolumeClaim\u00a0 accessModes:\u00a0 - ReadWriteOnce\u00a0 storageClassName: STORAGE_CLASS_NAME\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: STORAGE\n```Replace the following:- ``: the name of the source PersistentVolumeClaim that you created in [Create a source volume](#create-source) .\n- ``: the name of the StorageClass to use, which must be the same as the StorageClass of the source PersistentVolumeClaim.\n- ``: the amount of storage to request, which must be at least the size of the source PersistentVolumeClaim.\n- Apply the manifest:```\nkubectl apply -f podpvc-clone.yaml\n```\n### Create a Pod that consumes the cloned volume\nThe following example creates a Pod that consumes the volume clone that you created.\n- Save the following manifest as `web-server-clone.yaml` :```\napiVersion: v1kind: Podmetadata:\u00a0 name: web-server-clonespec:\u00a0 containers:\u00a0 \u00a0- name: web-server-clone\u00a0 \u00a0 \u00a0image: nginx\u00a0 \u00a0 \u00a0volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0- mountPath: /var/lib/www/html\u00a0 \u00a0 \u00a0 \u00a0 \u00a0name: mypvc\u00a0 volumes:\u00a0 \u00a0- name: mypvc\u00a0 \u00a0 \u00a0persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0claimName: podpvc-clone\u00a0 \u00a0 \u00a0 \u00a0readOnly: false\n```\n- Apply the manifest:```\nkubectl apply -f web-server-clone.yaml\n```\n- Verify that the test file exists:```\nkubectl exec web-server-clone \\\u00a0 \u00a0 -- sh -c 'cat /var/lib/www/html/hello.txt'\n```The output is similar to the following:```\nHello World!\n```## Clean up\nTo avoid incurring charges to your Google Cloud account for the resources used on this page, follow these steps.\n- Delete the `Pod` objects:```\nkubectl delete pod POD_NAME web-server-clone\n```\n- Delete the `PersistentVolumeClaim` objects:```\nkubectl delete pvc podpvc podpvc-clone\n```", "guide": "Google Kubernetes Engine (GKE)"}