{"title": "Google Kubernetes Engine (GKE) - Services", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/service", "abstract": "# Google Kubernetes Engine (GKE) - Services\nThis page describes Kubernetes [Services](https://kubernetes.io/docs/concepts/services-networking/service/) and their use in Google Kubernetes Engine (GKE). There are different types of Services, which you can use to group a set of [Pod](https://kubernetes.io/docs/concepts/workloads/pods/) endpoints into a single resource. To learn how to create a Service, see [Exposing applications using services](/kubernetes-engine/docs/how-to/exposing-apps) .\n", "content": "## What is a Kubernetes Service?\nThe idea of a Service is to group a set of Pod endpoints into a single resource. You can configure various ways to access the grouping. By default, you get a stable cluster IP address that clients inside the cluster can use to contact Pods in the Service. A client sends a request to the stable IP address, and the request is routed to one of the Pods in the Service.\nA Service identifies its member Pods with a selector. For a Pod to be a member of the Service, the Pod must have all of the labels specified in the selector. A [label](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/) is an arbitrary key/value pair that is attached to an object.\nThe following Service manifest has a selector that specifies two labels. The `selector` field says any Pod that has both the `app: metrics` label and the `department:engineering` label is a member of this Service.\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: my-servicespec:\u00a0 selector:\u00a0 \u00a0 app: metrics\u00a0 \u00a0 department: engineering\u00a0 ports:\u00a0 ...\n```\n## Why use a Kubernetes Service?\nIn a Kubernetes cluster, each Pod has an internal IP address. But the Pods in a Deployment come and go, and their IP addresses change. So it doesn't make sense to use Pod IP addresses directly. With a Service, you get a stable IP address that lasts for the life of the Service, even as the IP addresses of the member Pods change.\nA Service also provides load balancing. Clients call a single, stable IP address, and their requests are balanced across the Pods that are members of the Service.\n## Types of Kubernetes Services\nThere are five types of Services:\n- **ClusterIP (default):** Internal clients send requests to a stable internal IP address.\n- **NodePort:** Clients send requests to the IP address of a node on one or more `nodePort` values that are specified by the Service.\n- **LoadBalancer:** Clients send requests to the IP address of a network load balancer.\n- **ExternalName:** Internal clients use the DNS name of a Service as an alias for an external DNS name.\n- **Headless:** You can use a [headless service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) when you want a Pod grouping, but don't need a stable IP address.\nThe `NodePort` type is an extension of the `ClusterIP` type. So a Service of type `NodePort` has a cluster IP address.\nThe `LoadBalancer` type is an extension of the `NodePort` type. So a Service of type `LoadBalancer` has a cluster IP address and one or more `nodePort` values.\n## Services of type ClusterIP\nWhen you create a Service of type `ClusterIP` , Kubernetes creates a stable IP address that is accessible from nodes in the cluster.\nHere is a manifest for a Service of type ClusterIP:\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: my-cip-servicespec:\u00a0 selector:\u00a0 \u00a0 app: metrics\u00a0 \u00a0 department: sales\u00a0 type: ClusterIP\u00a0 ports:\u00a0 - protocol: TCP\u00a0 \u00a0 port: 80\u00a0 \u00a0 targetPort: 8080\n```\nYou can [create the Service](/kubernetes-engine/docs/how-to/exposing-apps) by using `kubectl apply -f [MANIFEST_FILE]` . After you create the Service, you can use `kubectl get service` to see the stable IP address:\n```\nNAME    TYPE  CLUSTER-IP  EXTERNAL-IP PORT(S)\nmy-cip-service ClusterIP 10.11.247.213 none   80/TCP\n```\nClients in the cluster call the Service by using the cluster IP address and the TCP port specified in the `port` field of the Service manifest. The request is forwarded to one of the member Pods on the TCP port specified in the `targetPort` field. For the preceding example, a client calls the Service at `10.11.247.213` on TCP port 80. The request is forwarded to one of the member Pods on TCP port 8080. The member Pod must have a container that is listening on TCP port 8080. If there is no container listening on port 8080, clients will see a message like \"Failed to connect\" or \"This site can't be reached\".\n## Service of type NodePort\nWhen you create a Service of type `NodePort` , Kubernetes gives you a `nodePort` value. Then the Service is accessible by using the IP address of any node along with the `nodePort` value.\nHere is a manifest for a Service of type `NodePort` :\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: my-np-servicespec:\u00a0 selector:\u00a0 \u00a0 app: products\u00a0 \u00a0 department: sales\u00a0 type: NodePort\u00a0 ports:\u00a0 - protocol: TCP\u00a0 \u00a0 port: 80\u00a0 \u00a0 targetPort: 8080\n```\nAfter you create the Service, you can use `kubectl get service -o yaml` to view its specification and see the `nodePort` value.\n```\nspec:\n clusterIP: 10.11.254.114\n externalTrafficPolicy: Cluster\n ports:\n - nodePort: 32675\n port: 80\n protocol: TCP\n targetPort: 8080\n```\nExternal clients call the Service by using the external IP address of a node along with the TCP port specified by `nodePort` . The request is forwarded to one of the member Pods on the TCP port specified by the `targetPort` field.\nFor example, suppose the external IP address of one of the cluster nodes is `203.0.113.2` . Then for the preceding example, the external client calls the Service at `203.0.113.2` on TCP port 32675. The request is forwarded to one of the member Pods on TCP port 8080. The member Pod must have a container listening on TCP port 8080.\nThe `NodePort` Service type is an extension of the `ClusterIP` Service type. So internal clients have two ways to call the Service:\n- Use`clusterIP`and`port`.\n- Use a node's IP address and`nodePort`.\nFor some cluster configurations, the [external Application Load Balancer](/load-balancing/docs/https) uses a Service of type `NodePort` .\n[Set up an external Application Load Balancer with Ingress](/kubernetes-engine/docs/tutorials/http-balancer)\nAn external Application Load Balancer is a proxy server, and is fundamentally different from the [external passthrough Network Load Balancer](/load-balancing/docs/network) described in this topic under [Service of type LoadBalancer](#services_of_type_loadbalancer) .\n**Note:** You can specify your own `nodePort` value in the 30000--32767 range. However, it's best to omit the field and let Kubernetes allocate a `nodePort` for you. This avoids collisions between Services.\n## Services of type LoadBalancer\nTo learn more about Services of type LoadBalancer, see [LoadBalancer Service concepts](/kubernetes-engine/docs/concepts/service-load-balancer) .\n## Service of type ExternalName\nA Service of type `ExternalName` provides an internal alias for an external DNS name. Internal clients make requests using the internal DNS name, and the requests are redirected to the external name.\nHere is a manifest for a Service of type `ExternalName` :\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: my-xn-servicespec:\u00a0 type: ExternalName\u00a0 externalName: example.com\n```\nWhen you create a Service, Kubernetes creates a DNS name that internal clients can use to call the Service. For the preceding example, the DNS name is my-xn-service.default.svc.cluster.local. When an internal client makes a request to my-xn-service.default.svc.cluster.local, the request gets redirected to example.com.\nThe `ExternalName` Service type is fundamentally different from the other Service types. In fact, a Service of type `ExternalName` does not fit the definition of Service given at the beginning of this topic. A Service of type `ExternalName` is not associated with a set of Pods, and it does not have a stable IP address. Instead, a Service of type `ExternalName` is a mapping from an internal DNS name to an external DNS name.\n## Headless Service\nA headless Service is a type of Kubernetes Service that does not allocate a cluster IP address. Instead, a headless Service uses DNS to expose the IP addresses of the Pods that are associated with the Service. This allows you to connect directly to the Pods, instead of going through a proxy.\nHeadless Services are useful for a variety of scenarios, including:\n- **Load balancing across pods** : You can use headless Services to load balance across Pods. To implement this, create a Service with a selector that matches the Pods that you want to load balance. The Service will then distribute traffic evenly across all of the Pods that match the selector.\n- **Service discovery** : You can use a headless Service to implement Service discovery. To implement this, create a Service with a name and a selector. DNS record for the headless service contains all the IPs of the Pods behind the Service that match the selector. Clients can use these DNS records to find the IP addresses of the Pods that are associated with the Service.\n- **Direct Pod access** : Clients can connect directly to the Pods that are associated with a headless Service, which can be useful for Services that require direct access to the underlying Pods, such as load balancers and DNS servers.\n- **Flexibility** : Headless services can be used to create a variety of different topologies, such as load balancers, DNS servers, and distributed databases.\nIf you have special network requirements for your workloads that can not be solved using headless Services with selectors, there is also the possibility of using headless Services without selectors. Headless Services are a useful tool for accessing Services that are not located within the Kubernetes cluster itself, as the control plane does not create EndpointSlice objects, you can read more about it in [Service without selectors](https://kubernetes.io/docs/concepts/services-networking/service/#without-selectors)\nThe following example is a manifest for a Headless Service:\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: nginxspec:\u00a0 clusterIP: None\u00a0 selector:\u00a0 \u00a0 app: nginx\u00a0 ports:\u00a0 - name: http\u00a0 \u00a0 port: 80\u00a0 \u00a0 targetPort: 80\n```\nOnce you have created a headless Service, you can find the IP addresses of the Pods that are associated with the Service by querying the DNS. For example, the following command lists the IP addresses of the Pods that are associated with the nginx Service:\n**Note:** This example assumes that the Pods created are tagged with the `nginx` label.\n```\ndig +short nginx.default.svc.cluster.local\n```\nAnother example which uses Kubernetes query expansion::\n```\ndig +short +search nginx\n```\nYou can create a headless Service with a single command, and headless Services are easy to update and scale.\n```\nkubectl create service clusterip my-svc --clusterip=\"None\" --dry-run=client -o yaml > [file.yaml]\n```\n## Service abstraction\nA Service is an abstraction in the sense that it is not a process that listens on some network interface. Part of the abstraction is implemented in the [iptables](https://linux.die.net/man/8/iptables) rules of the cluster nodes. Depending on the type of the Service, other parts of the abstraction are implemented by either an [external passthrough Network Load Balancer](/load-balancing/docs/network) or an [external Application Load Balancer](/load-balancing/docs/https) .\n## Arbitrary Service ports\nThe value of the `port` field in a Service manifest is arbitrary. However, the value of `targetPort` is not arbitrary. Each member Pod must have a container listening on `targetPort` .\nHere's a Service, of type `LoadBalancer` , that has a `port` value of 50000:\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: my-ap-servicespec:\u00a0 clusterIP: 10.11.241.93\u00a0 externalTrafficPolicy: Cluster\u00a0 ports:\u00a0 - nodePort: 30641\u00a0 \u00a0 port: 50000\u00a0 \u00a0 protocol: TCP\u00a0 \u00a0 targetPort: 8080\u00a0 selector:\u00a0 \u00a0 app: parts\u00a0 \u00a0 department: engineering\u00a0 sessionAffinity: None\u00a0 type: LoadBalancerstatus:\u00a0 loadBalancer:\u00a0 \u00a0 ingress:\u00a0 \u00a0 - ip: 203.0.113.200\n```\nA client calls the Service at `203.0.113.200` on TCP port 50000. The request is forwarded to one of the member Pods on TCP port 8080.\n## Multiple ports\nThe `ports` field of a Service is an array of [ServicePort](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#serviceport-v1-core) objects. The ServicePort object has these fields:\n- `name`\n- `protocol`\n- `port`\n- `targetPort`\n- `nodePort`\nIf you have more than one ServicePort, each ServicePort must have a unique name.\nHere is a Service, of type `LoadBalancer` , that has two `ServicePort` objects:\n```\napiVersion: v1kind: Servicemetadata:\u00a0 name: my-tp-servicespec:\u00a0 clusterIP: 10.11.242.196\u00a0 externalTrafficPolicy: Cluster\u00a0 ports:\u00a0 - name: my-first-service-port\u00a0 \u00a0 nodePort: 31233\u00a0 \u00a0 port: 60000\u00a0 \u00a0 protocol: TCP\u00a0 \u00a0 targetPort: 50000\u00a0 - name: my-second-service-port\u00a0 \u00a0 nodePort: 31081\u00a0 \u00a0 port: 60001\u00a0 \u00a0 protocol: TCP\u00a0 \u00a0 targetPort: 8080\u00a0 selector:\u00a0 \u00a0 app: tests\u00a0 \u00a0 department: engineering\u00a0 sessionAffinity: None\u00a0 type: LoadBalancerstatus:\u00a0 loadBalancer:\u00a0 \u00a0 ingress:\u00a0 \u00a0 - ip: 203.0.113.201\n```\n**Note:** You can specify a maximum of five ports for a LoadBalancer service.\nIn the preceding example, if a client calls the Service at `203.0.113.201` on TCP port 60000, the request is forwarded to a member Pod on TCP port 50000. But if a client calls the Service at `203.0.113.201` on TCP port 60001, the request is forwarded to a member Pod on TCP port 8080.\nEach member Pod must have a container listening on TCP port 50000 and a container listening on TCP port 8080. This could be a single container with two threads, or two containers running in the same Pod.\n## Service endpoints\nWhen you create a Service, Kubernetes creates an [Endpoints](https://v1-25.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#endpoints-v1-core) object that has the same name as your Service. Kubernetes uses the Endpoints object to keep track of which Pods are members of the Service.\n## Single-stack and dual-stack Services\nYou can create an IPv6 Service of type [ClusterIP](/kubernetes-engine/docs/concepts/service#services_of_type_clusterip) or [NodePort](/kubernetes-engine/docs/concepts/service#service_of_type_nodeport) . GKE supports dual-stack Services of type [LoadBalancer](/kubernetes-engine/docs/concepts/service-load-balancer) during [Preview](/products#product-launch-stages) which carries no SLA or technical support.\nFor each of these Service types, you can define `ipFamilies` and `ipFamilyPolicy` fields as either IPv4, IPv6, or a [dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/#services) Service.\n## What's next\n- Learn more about [Kubernetes Services](https://kubernetes.io/docs/concepts/services-networking/service/) \n- [Expose Applications using Services](/kubernetes-engine/docs/how-to/exposing-apps) \n- Learn more about [StatefulSets](/kubernetes-engine/docs/concepts/statefulset) \n- Learn more about [Ingress](/kubernetes-engine/docs/concepts/ingress) \n- Complete the [Set up an external Application Load Balancer with Ingress](/kubernetes-engine/docs/tutorials/http-balancer) tutorial", "guide": "Google Kubernetes Engine (GKE)"}