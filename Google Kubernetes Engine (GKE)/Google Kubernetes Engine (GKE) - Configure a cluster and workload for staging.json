{"title": "Google Kubernetes Engine (GKE) - Configure a cluster and workload for staging", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/admin-workflow", "abstract": "# Google Kubernetes Engine (GKE) - Configure a cluster and workload for staging\nWhile GKE clusters in Autopilot mode provide reasonable defaults for most settings, it's likely that you'll need different settings in your development, staging, and production environments.\n", "content": "## Objectives\nLearn some basic tasks for configuring a staging and testing cluster:\n- Limit access to the cluster's administrative service, which is called the . This prevents unauthorized users from viewing or changing cluster and workload settings.\n- Specify that your app needs computing resources that efficiently scale up and down to meet demand.\n- Test autoscaling, which automatically replicates Pods when demand increases beyond a threshold you specify.\n- Adjust log retention so you only keep the logs you need.\n- Enable the GKE security posture dashboard.\nThese are just some of the tasks for promoting a cluster from development to staging. Read the [GKE documentation](/kubernetes-engine/docs) for the full list of tasks to consider.To follow step-by-step guidance for this task directly in the Google Cloud console, click **Guide me** :\n [Guide me](https://console.cloud.google.com/kubernetes/list/overview?journey_id=kubernetes--admin-workflow--intro) ## CostsIn this document, you use the following billable components of Google Cloud:- [GKE](/kubernetes-engine/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you beginCreate a Kubernetes cluster and deploy a workload. [Create a cluster and deploy a workload](/kubernetes-engine/docs/quickstarts/create-cluster) shows you how.## Limit access to the control planeTo improve your security posture, allow only an authorized network and Google Cloud console and Cloud Shell to access your cluster's control plane.\n### Configure an authorized network\n- In the Google Cloud console, go to the GKE **Clusters** page. [Go to Clusters](https://console.cloud.google.com/kubernetes/list/overview) \n- In the **Name** column, click the name of your cluster, **hello-world-cluster** .\n- In the row of the Networking table, click edit **Edit** .\n- In the Edit control plane authorized networks dialog, select **Enable control plane authorized networks** .\n- Select **Allow access through Google Cloud public IP addresses** .This lets you to manage the cluster from Google Cloud console and Cloud Shell\n- Click **Add authorized network** .\n- Enter a name, such as **My example on-prem network** .\n- In **Network** , enter the range of IP addresses that you want to grant access to your cluster's control plane. Use CIDR notation.For example, enter the following range:```\n198.51.100.0/24\n```\n- Click **Done** .\n- Click **Save changes** .This operation takes a few minutes to complete.\n- Click the button and wait until you see a green check mark next to **Update control plane authorized networks setting in Kubernetes Engine cluster \"hello-world-cluster\"** .\nYou have configured a cluster control plane that is accessible only from your authorized network and from Google Cloud public IP addresses (which lets you to manage the cluster from Google Cloud console and Cloud Shell).\nTo see the IP address of your cluster's control plane and confirm the addresses of the authorized network, click **Next** .\n### View IP addresses\n- Go to the GKE **Clusters** page. [Go to Clusters](https://console.cloud.google.com/kubernetes/list/overview) \n- In the **Name** column, click the name of your cluster, **hello-world-cluster** .\n- In the **Cluster basics** table, the **External endpoint** row shows the IP address of the cluster's control plane.\n- In the **Networking** table, the **Control plane authorized networks** row shows the IP addresses of your authorized network.\nYour cluster's control plane can now only be accessed from an authorized network, Google Cloud console, and Cloud Shell.## Specify a compute classBy default, GKE Autopilot Pods use compute resources that are optimized for general-purpose workloads. For workloads that need to scale optimally or that have other unique requirements, you can specify a different compute class.\n### Update the Deployment specification\n- In the Google Cloud console, go to the GKE **Workloads** page. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload/overview) \n- In the **Name** column, click the name of the app you deployed, **hello-world-app** .\n- Click to edit the deployment specification.\n- In the **YAML** tab, find the line that starts with `containers:`\n- Just above this line, add the following lines:```\nnodeSelector:\n cloud.google.com/compute-class: \"Scale-Out\"\n```Make sure your file matches the indentation in the following example:```\napiVersion: apps/v1\n kind: Deployment\n ...\n spec:\n ...\n template:\n ...\n  spec:\n  nodeSelector:\n   cloud.google.com/compute-class: \"Scale-Out\"\n  containers:\n  - name: hello-app\n   image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:1.0\n```\n- To download this file and use it as the basis for other workload configurations, click .\n- Click **Save** .\nAny Pod replicas that are created to run your workload will use the compute class you specified.## Test autoscalingNow that you have a workload that can scale efficiently, update autoscaling settings to more easily cause your workload to scale up. Then generate load to trigger autoscaling.\n### Update Pod autoscaling settings\n- Go to the GKE **Workloads** page. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload/overview) \n- In the **Name** column, click the name of your deployment, **hello-world-app** .\n- Click .\n- Select **Autoscale** and click **Horizontal pod autoscaling** .\n- In the **Configure Horizontal Pod Autoscaler** dialog, under **Autoscaling metrics** , click **CPU** .\n- Change the value of **Target** to 2, which automatically scales up your Pods when they use at least 2% of their configured CPU resources. This low target value ensures that you can easily trigger autoscaling in the next step.\n- Click **Save** .\nTo trigger autoscaling, click **Next** .\n### Generate load to trigger autoscaling\n- Open Cloud Shell by clicking .\n- Paste the following command into Cloud Shell:```\n for i in $(seq -s' ' 1 10000); do wget -q -O- <var>external-IP-address</var>; done\n```Replace with the IP address that appears in the column.\n- Press Enter to run the command and send 10,000 requests to hello-world-app.\n- Wait for the `wget` command to finish running and the command-line prompt to reappear.\n- You can close Cloud Shell when the `wget` command finishes.\nTo watch your workload scale to accommodate the increased traffic, click **Next** .\n### Watch your workload scale\n- On the **Deployment details** page for your workload, look in the chart for a spike in CPU usage.You might need to wait up to 5 minutes to see the spike.\n- Click refresh to make sure the **Deployment details** page shows the latest data.\n- Look in the **Managed Pods** table to see that three replicas of your workload are now running.You might initially see errors about unschedulable Pods, but these messages are transient as the replicas start up.\n- You can wait for about 10 minutes, click refresh **Refresh** , and see that CPU usage has dropped and so the number of Pods in **Managed Pods** returns to one.\nYou have tested autoscaling and watched your workload scale.## Adjust logs retentionBy default, Cloud Logging ingests all logs from your GKE clusters. Ingesting large amounts of logs data could result in a fee. To ensure that you're only ingesting the logs data that you need for the staging environment, adjust logs retention.\n### Create a logs filter\n- In the navigation panel of the Google Cloud console, select **Logging** , and then select **Logs Explorer** : [Go to Logs Explorer](https://console.cloud.google.com/logs/query) Notice that the pane shows logs from all resources in your project.\n- Above the query results:- Click .\n- Search for **Kubernetes cluster** , then click it.\n- Click **us-central-1** .\n- Click **hello-world-cluster** .\n- Click **Apply** .\n- Click and select **Info** (which changes to **Info and higher** on hover).\n- Click .\n- Note that **Query results** now only contains INFO messages from your staging cluster.\n- Copy the query from the query editor. You'll paste this query when you create a filter for your log sink.\nTo create a log sink and storage bucket, click **Next** .\n### Create a log sink and storage bucket\n- Go to the Logging **Log router** page. [Go to Log router](https://console.cloud.google.com/logs/router) \n- Click .\n- In **Name** , enter the following name:```\nhello-world-cluster-sink\n```\n- Click **Next** .\n- In **Select sink service** , select **Logging bucket** .\n- In **Select a log bucket** , select **Create new log bucket** .\n- In **Bucket details** , enter a unique name, such as:```\nhello-world-bucket-<var>user-id</var>\n```\n- Click **Create bucket** .\n- Under **Sink destination** , click **Next** .\n- In **Build inclusion filter** , paste the query you created in the Logs Explorer.\n- Click **Create sink** .\nTo view the logs in your cluster's bucket, click **Next** .\n### View your cluster's logs\n- In the navigation panel of the Google Cloud console, select **Logging** , and then select **Logs Explorer** : [Go to Logs Explorer](https://console.cloud.google.com/logs/query) \n- Click .\n- Select **Scope by storage** .\n- Select **/bucket-name** .\n- Click **Apply** . **Query results** shows only the logs that are stored in your cluster's bucket.\nYou have adjusted the logs retention so your staging cluster doesn't store DEBUG messages. You can [set permissions](/logging/docs/logs-views) so that only certain users can view the logs in your cluster's bucket.## Enable the security posture dashboardThe security posture dashboard scans your GKE clusters and workloads to provide you with opinionated, actionable recommendations to improve your security posture.\n### Explore any concerns\n- Go to the GKE **Security posture** page. [Go to Security posture](https://console.cloud.google.com/kubernetes/security/dashboard) \n- If you are asked to enable the Container Security API, click **Enable** .\n- The **Dashboards** tab summarizes concerns for your project's clusters and workloads.\n- Click the **Concerns** tab.\n- If any concerns appear on the tab, click the concern for more information.\nYou have completed some of the basic tasks for configuring a cluster for staging and testing your app.## What's next\n- [Guidelines for creating scalable clusters](/kubernetes-engine/docs/best-practices/scalability) \n- [Set up a CI/CD pipeline](https://console.cloud.google.com/welcome?walkthroughId=deploy--cloud-deploy-e2e-gke) \n- [Clean up to avoid billing charges](/kubernetes-engine/docs/quickstarts/learning-path-cleanup) . If you plan to take additional tutorials, wait until you finish those tutorials before you clean up. You can use the sample Kubernetes cluster in most GKE tutorials.", "guide": "Google Kubernetes Engine (GKE)"}