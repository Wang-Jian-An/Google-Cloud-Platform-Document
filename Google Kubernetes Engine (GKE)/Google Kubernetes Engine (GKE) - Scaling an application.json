{"title": "Google Kubernetes Engine (GKE) - Scaling an application", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/scaling-apps", "abstract": "# Google Kubernetes Engine (GKE) - Scaling an application\nThis page explains how to scale a deployed application in Google Kubernetes Engine (GKE).\n", "content": "## Overview\nWhen you [deploy an application](/kubernetes-engine/docs/how-to/deploying-workloads-overview) in GKE, you define how many of the application you'd like to run. When you an application, you increase or decrease the number of replicas.\nEach replica of your application represents a Kubernetes Pod that encapsulates your application's container(s).\n## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.## Inspecting an application\nBefore scaling your application, you should inspect the application and ensure that it is healthy.\nTo see all applications deployed to your cluster, run the following command:\n```\nkubectl get CONTROLLER\n```\nSubstitute `` for `deployments` , `statefulsets` , or another controller object type.\nFor example, if you run `kubectl get deployments` and you have created only one Deployment, the command's output should look similar to the following:\n```\nNAME     DESIRED CURRENT UP-TO-DATE AVAILABLE AGE\nmy-app    1   1   1   1   10m\n```\nThe output of this command is similar for all objects, but may appear slightly different. For Deployments, the output has six columns:\n- `NAME`lists the names of the Deployments in the cluster.\n- `DESIRED`displays the desired number of, or the, of the application, which you define when you create the Deployment.\n- `CURRENT`displays how many replicas are currently running.\n- `UP-TO-DATE`displays the number of replicas that have been updated to achieve the desired state.\n- `AVAILABLE`displays how many replicas of the application are available to your users.\n- `AGE`displays the amount of time that the application has been running in the cluster.\nIn this example, there is only one Deployment, `my-app` , which has only one replica because its desired state is one replica. You define the desired state at the time of creation, and you can change it at any time by scaling the application.\n## Inspecting StatefulSets\nBefore scaling a StatefulSet, you should inspect it by running the following command:\n```\nkubectl describe statefulset my-app\n```\nIn the output of this command, check the **Pods Status** field. If the `Failed` value is greater than `0` , scaling might fail.\nIf a StatefulSet appears to be unhealthy, perform the following:\n- Get a list of pods, and see which pods are unhealthy:```\nkubectl get pods\n```\n- Remove the unhealthy pod:```\nkubectl delete POD_NAME\n```\nAttempting to scale a StatefulSet while it is unhealthy may cause it to become unavailable.\n## Scaling an application\nThe following sections describe each method you can use to scale an application. The `kubectl scale` method is the fastest way to scale. However, you may prefer another method in some situations, like when updating configuration files or when performing in-place modifications.\nThe [kubectl scale](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#scale) command lets your instantaneously change the number of replicas you want to run your application.\nTo use `kubectl scale` , you specify the new number of replicas by setting the `--replicas` flag. For example, to scale `my-app` to four replicas, run the following command, substituting `` for `deployment` , `statefulset` , or another controller object type:\n```\nkubectl scale CONTROLLER my-app --replicas 4\n```\nIf successful, this command's output should be similar to `deployment \"my-app\" scaled` .\nNext, run:\n```\nkubectl get CONTROLLER my-app\n```\nThe output should look similar to the following:\n```\nNAME     DESIRED CURRENT UP-TO-DATE AVAILABLE AGE\nmy-app    4   4   4   4   15m\n```\n **Note:** It may take several minutes for scaling to complete.\nYou can use [kubectl apply](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#apply) to apply a new configuration file to an existing controller object. `kubectl apply` is useful for making multiple changes to a resource, and may be useful for users who prefer to manage their resources in configuration files.\nTo scale using `kubectl apply` , the configuration file you supply should include a new number of replicas in the `replicas` field of the object's specification.\nThe following is an updated version of the configuration file for the example `my-app` object. The example shows a Deployment, so if you use another type of controller, such as a StatefulSet, change the `kind` accordingly. This example works best on a cluster with at least three Nodes.\n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: my-appspec:\u00a0 replicas: 3\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: app\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: app\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: my-container\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/hello-app:2.0\n```\nIn this file, the value of the `replicas` field is `3` . When this configuration file is applied, the object `my-app` scales to three replicas.\nTo apply an updated configuration file, run the following command:\n```\nkubectl apply -f config.yaml\n```\nNext, run:\n```\nkubectl get CONTROLLER my-app\n```\nThe output should look similar to the following:\n```\nNAME     DESIRED CURRENT UP-TO-DATE AVAILABLE AGE\nmy-app    3   3   3   3   15m\n```\nTo scale a workload in the Google Cloud console, perform the following steps:- Go to the **Workloads** page in the Google Cloud console. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload) \n- In the workloads list, click the name of the workload you want to scale.\n- Click **Actions > Scale > Edit replicas** .\n- Enter the new number of **Replicas** for the workload.\n- Click **Scale** .## Autoscaling Deployments\nYou can autoscale Deployments based on CPU utilization of Pods using `kubectl autoscale` or from the GKE Workloads menu in the Google Cloud console.\n[kubectl autoscale](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#autoscale) creates a `HorizontalPodAutoscaler` (or HPA) object that targets a specified resource (called the ) and scales it as needed. The HPA periodically adjusts the number of replicas of the scale target to match the average CPU utilization that you specify.\n **Note:** Your object's Pod template can include a `resources` field that specifies a CPU utilization request for each Pod. To learn more about making resource requests for Pods and containers, refer to [Managing resources for containers](https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/) .\nWhen you use `kubectl autoscale` , you specify a maximum and minimum number of replicas for your application, as well as a CPU utilization target. For example, to set the maximum number of replicas to six and the minimum to four, with a CPU utilization target of 50% utilization, run the following command:\n```\nkubectl autoscale deployment my-app --max 6 --min 4 --cpu-percent 50\n```\nIn this command, the `--max` flag is required. The `--cpu-percent` flag is the target CPU utilization over all the Pods. This command immediately scale the Deployment to six replicas, unless there is already a systemic demand.\nAfter running `kubectl autoscale` , the `HorizontalPodAutoscaler` object is created and targets the application. When there is a change in load, the object increases or decreases the application's replicas.\n **Note:** The maximum number of replicas is limited by the cluster's resources. If the cluster has a static number of available nodes, the cluster might run out of resources and prevent some replicated Pods from running. To learn about scaling your cluster, refer to [Resizing a cluster](/kubernetes-engine/docs/how-to/resizing-a-container-cluster) and [Cluster autoscaling](/kubernetes-engine/docs/concepts/cluster-autoscaler) .\nTo get a list of the `HorizontalPodAutoscaler` objects in your cluster, run:\n```\nkubectl get hpa\n```\nTo see a specific `HorizontalPodAutoscaler` object in your cluster, run:\n```\nkubectl get hpa HPA_NAME\n```\nReplace `` with the name of your `HorizontalPodAutoscaler` object.\nTo see the `HorizontalPodAutoscaler` configuration:\n```\nkubectl get hpa HPA_NAME -o yaml\n```\nThe output of this command is similar to the following:\n```\napiVersion: v1items:- apiVersion: autoscaling/v1\u00a0 kind: HorizontalPodAutoscaler\u00a0 metadata:\u00a0 \u00a0 creationTimestamp: ...\u00a0 \u00a0 name: HPA_NAME\u00a0 \u00a0 namespace: default\u00a0 \u00a0 resourceVersion: \"664\"\u00a0 \u00a0 selfLink: ...\u00a0 \u00a0 uid: ...\u00a0 spec:\u00a0 \u00a0 maxReplicas: 10\u00a0 \u00a0 minReplicas: 1\u00a0 \u00a0 scaleTargetRef:\u00a0 \u00a0 \u00a0 apiVersion: apps/v1\u00a0 \u00a0 \u00a0 kind: Deployment\u00a0 \u00a0 \u00a0 name: HPA_NAME\u00a0 \u00a0 targetCPUUtilizationPercentage: 50\u00a0 status:\u00a0 \u00a0 currentReplicas: 0\u00a0 \u00a0 desiredReplicas: 0kind: Listmetadata: {}resourceVersion: \"\"selfLink: \"\"\n```\nIn this example output, the `targetCPUUtilizationPercentage` field holds the `50` percentage value passed in from the `kubectl autoscale` example.\nTo see a detailed description of a specific `HorizontalPodAutoscaler` object in the cluster:\n```\nkubectl describe hpa HPA_NAME\n```\nYou can modify the `HorizontalPodAutoscaler` by applying a new configuration file with `kubectl apply` , using `kubectl edit` , or using `kubectl patch` .\nTo delete a `HorizontalPodAutoscaler` object:\n```\nkubectl delete hpa HPA_NAME\n```\nTo autoscale a Deployment, perform the following steps:- Go to the **Workloads** page in the Google Cloud console. [Go to Workloads](https://console.cloud.google.com/kubernetes/workload) \n- In the workloads list, click the name of the Deployment you want to autoscale.\n- Click **Actions > Autoscale** .\n- Enter the **Maximum number of replicas** and, optionally, the **Minimumnumber of replicas** for the Deployment.\n- Under **Autoscaling metrics** , select and configure metrics as desired.\n- Click **Autoscale** .\n### Autoscaling with custom metrics\nYou can scale your Deployments based on [custom metrics](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#support-for-custom-metrics) exported from [Cloud Monitoring](/stackdriver/docs/solutions/gke) .\nTo learn how to use custom metrics to autoscale deployments, refer to the [Autoscaling deployments with custom metrics](/kubernetes-engine/docs/tutorials/custom-metrics-autoscaling) tutorial.\n**Note:** Cloud Monitoring is a Google Cloud service separate from GKE. To use scaling based on custom metrics, you need to associate a paid Google Cloud Observability service account with your Google Cloud console project. For more information, refer to the [Google Cloud Observability for GKE documentation](/stackdriver/docs/solutions/gke) .\n## What's next\n- [Learn about exposing your application externally](/kubernetes-engine/docs/how-to/exposing-apps) .", "guide": "Google Kubernetes Engine (GKE)"}