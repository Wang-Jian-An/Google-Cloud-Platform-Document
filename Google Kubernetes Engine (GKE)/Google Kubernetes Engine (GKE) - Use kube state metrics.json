{"title": "Google Kubernetes Engine (GKE) - Use kube state metrics", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics", "abstract": "# Google Kubernetes Engine (GKE) - Use kube state metrics\nYou can configure a Google Kubernetes Engine (GKE) cluster to send a curated set of kube state metrics, including metrics for Pods, Deployments, and more. to [Cloud Monitoring](/monitoring) using [Google Cloud Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) . This document describes how these metrics are formatted when they are written to Cloud Monitoring and how to query them. This document also provides tables that list the metrics in each set and provides information about how you can use these metrics.\nBefore you can use kube state metrics, you must [enable their collection](/kubernetes-engine/docs/how-to/configure-metrics#ksm-package) .\n", "content": "## Metric format\nAll Kubernetes kube state metrics written to Cloud Monitoring use the resource type [prometheus_target](/monitoring/api/resources#tag_prometheus_target) . Each metric name is prefixed with `prometheus.googleapis.com/` and has a suffix indicating the Prometheus metric type, such as `/gauge` , `/histogram` , or `/counter` . Otherwise, each metric name is identical to the metric name exposed by open source Kubernetes.\n## Exporting from Cloud Monitoring\nThe kube state metrics can be exported from Cloud Monitoring by using the [Cloud Monitoring API](/monitoring/api/v3) . Because all kube state metrics are ingested by using [Google Cloud Managed Service for Prometheus](/stackdriver/docs/managed-prometheus) , kube state metrics can be queried [by using Prometheus Query Language (PromQL)](/monitoring/promql) . They can also be queried by using [by using Monitoring Query Language (MQL)](/monitoring/mql) .\n## Querying metrics\nWhen you query kube state metrics, the name you use depends on whether you are using PromQL or Cloud Monitoring-based features like MQL or the Metrics Explorer [menu-driven interface](/monitoring/charts/metrics-explorer#menu-driven-interface) .\nThe following tables of kube state metrics show two versions of each metric name:\n- **PromQL metric name** : When [using PromQL](/monitoring/promql) in Cloud Monitoring pages  of the Google Cloud console or in PromQL fields of the [Cloud Monitoring API](/monitoring/api/v3) ,  use the PromQL metric name.\n- **Cloud Monitoring metric name** When using other  Cloud Monitoring features, use the Cloud Monitoring metric name  in the tables below. This name must be prefixed with`prometheus.googleapis.com/`, which has been omitted from the  entries in the table.\n## Storage metrics\nThe Cloud Monitoring metric names in this table must be prefixed with `prometheus.googleapis.com/` . That prefix has been omitted from the entries in the table.\n| ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Kind,\\xa0Type,\\xa0Unit Monitored\\xa0resources Required\\xa0GKE\\xa0version') | ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Description Labels')                                      |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| kube_persistentvolume_capacity_bytes kube_persistentvolume_capacity_bytes/gauge                  | kube_persistentvolume_capacity_bytes kube_persistentvolume_capacity_bytes/gauge                                        |\n| GAUGE,\u00a0DOUBLE,\u00a0By prometheus_target 1.27.2-gke.1200                         | Persistentvolume capacity in bytes. Sampled every 30 seconds. persistentvolume: persistentvolume.                                   |\n| kube_persistentvolume_claim_ref kube_persistentvolume_claim_ref/gauge                    | kube_persistentvolume_claim_ref kube_persistentvolume_claim_ref/gauge                                           |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Information about the Persistent Volume Claim Reference. Sampled every 30 seconds. claim_name: claim_name. name: name. persistentvolume: persistentvolume.                     |\n| kube_persistentvolume_info kube_persistentvolume_info/gauge                       | kube_persistentvolume_info kube_persistentvolume_info/gauge                                             |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Information about persistentvolume. Sampled every 30 seconds. csi_driver: csi_driver. csi_volume_handle: csi_volume_handle. local_fs: local_fs. local_path: local_path. persistentvolume: persistentvolume. storageclass: storageclass. |\n| kube_persistentvolume_status_phase kube_persistentvolume_status_phase/gauge                   | kube_persistentvolume_status_phase kube_persistentvolume_status_phase/gauge                                         |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The phase indicates if a volume is available, bound to a claim, or released by a claim. Sampled every 30 seconds. persistentvolume: persistentvolume. phase: phase.                  |\n| kube_persistentvolumeclaim_info kube_persistentvolumeclaim_info/gauge                    | kube_persistentvolumeclaim_info kube_persistentvolumeclaim_info/gauge                                           |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Information about persistent volume claim. Sampled every 30 seconds. persistentvolumeclaim: persistentvolumeclaim. storageclass: storageclass. volumename: volumename.                  |\n| kube_persistentvolumeclaim_resource_requests_storage_bytes kube_persistentvolumeclaim_resource_requests_storage_bytes/gauge       | kube_persistentvolumeclaim_resource_requests_storage_bytes kube_persistentvolumeclaim_resource_requests_storage_bytes/gauge                             |\n| GAUGE,\u00a0DOUBLE,\u00a0By prometheus_target 1.27.2-gke.1200                         | The capacity of storage requested by the persistent volume claim. Sampled every 30 seconds. persistentvolumeclaim: persistentvolumeclaim.                         |\n| kube_persistentvolumeclaim_status_phase kube_persistentvolumeclaim_status_phase/gauge                | kube_persistentvolumeclaim_status_phase kube_persistentvolumeclaim_status_phase/gauge                                       |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The phase the persistent volume claim is currently in. Sampled every 30 seconds. persistentvolumeclaim: persistentvolumeclaim. phase: phase.                        |\nFor more information, see [PersistentVolume Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/persistentvolume-metrics.md) and [PersistentVolumeClaim Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/persistentvolumeclaim-metrics.md) .\n## Pod metrics\nA Pod is a group of one or more containers with a specification for how to run the containers, which share storage and network resources.\n### Table of Pod metrics\nThe Pod metrics let you monitor and alert on the behavior of your Pods. The following table shows the metrics available in the kube state metrics package:\nThe Cloud Monitoring metric names in this table must be prefixed with `prometheus.googleapis.com/` . That prefix has been omitted from the entries in the table.\n| ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Kind,\\xa0Type,\\xa0Unit Monitored\\xa0resources Required\\xa0GKE\\xa0version') | ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Description Labels')                 |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------|\n| kube_pod_container_status_ready kube_pod_container_status_ready/gauge                    | kube_pod_container_status_ready kube_pod_container_status_ready/gauge                      |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Describes whether the containers readiness check succeeded. Sampled every 30 seconds. container: container. pod: pod. uid: uid.      |\n| kube_pod_container_status_waiting_reason kube_pod_status_container_status_waiting_reason/gauge              | kube_pod_container_status_waiting_reason kube_pod_status_container_status_waiting_reason/gauge               |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Describes the reason the container is currently in waiting state. Sampled every 30 seconds. container: container. pod: pod. reason: reason. uid: uid. |\n| kube_pod_status_phase kube_pod_status_phase/gauge                         | kube_pod_status_phase kube_pod_status_phase/gauge                           |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The pods current phase. Sampled every 30 seconds. phase: phase. pod: pod. uid: uid.                  |\n| kube_pod_status_unschedulable kube_pod_status_unschedulable/gauge                     | kube_pod_status_unschedulable kube_pod_status_unschedulable/gauge                       |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Describes the unschedulable status for the pod. Sampled every 30 seconds. pod: pod. uid: uid.               |\nFor more information, see [Pod Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/pod-metrics.md) .\n### Sample queries for Pod metrics\nTo determine if you have unschedulable Pods, use the following PromQL expression:\n```\nsum(kube_pod_status_unschedulable{cluster=\"CLUSTER\", namespace=\"NAMESPACE\"})\n```\nTo alert on a number of unschedulable pods in a namespace, you can use the following PromQL expression:\n```\nsum(kube_pod_status_unschedulable{cluster=\"CLUSTER\", namespace=\"NAMESPACE\"}) > LIMIT\n```\nYou can use the `kube_pod_container_status_waiting_reason` metric to create an alert for a container stuck in a specific waiting state by using a PromQL expression like the following:\n```\nmax_over_time(kube_pod_container_status_waiting_reason{reason=\"REASON\", cluster=\"CLUSTER\", namespace=\"NAMESPACE\"}[5m]) >= 1\n```\nThe value of specifies the container's waiting state, for example:\n- `CrashLoopBackOff`\n- `ImagePullBackOff`\n- `ContainerCreating`\nTo create an alert for a container stuck in any of the waiting states, use the following PromQL expression:\n```\nmax_over_time(kube_pod_container_status_waiting_reason{cluster=\"CLUSTER\", namespace=\"NAMESPACE\"}[5m]) >= 1\n```\nTo determine how many containers are failing readiness checks, use the following PromQL expression\n```\nsum(kube_pod_container_status_ready) by (pod, container) == 0\n```\nSome of the query and alert expressions in this section were adapted from the [kubernetes-apps.yaml file](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml) in the Prometheus community Kubernetes Helm Charts repository on GitHub.### Interactive playbooks\nKube state metrics are also used in the GKE interactive playbooks for troubleshooting unschedulable or crashlooping Pods. For more information about these failure modes, see the following troubleshooting documents:\n- [Crashlooping Pods](/kubernetes-engine/docs/troubleshooting#CrashLoopBackOff) \n- [Unschedulable Pods](/kubernetes-engine/docs/troubleshooting#PodUnschedulable) \nWithout the kube state metrics package enabled, the primary way to detect pod-scheduling issues is to query \"Failed Scheduling\" log events. After you enable the kube state metrics package, you can use the `kube_pod_status_unschedulable` metric, which serves the same purpose but is easier to aggregate and chart. By using the metric, you can see how many Pods are unschedulable and when the problem started.\nSimilarly, the GKE system metric [kubernetes.io/container/restart_count](/monitoring/api/metrics_kubernetes#kubernetes/container/restart_count) can help you detect crashlooping Pods. The `kube_pod_container_status_waiting_reason` metric also enumerates crashlooping Pods, and it also lets you determine if Pods are stuck in waiting states other than `CrashLookBackOff` , like `ImagePullBackOff` and `ContainerCreating` .\nTo explore the interactive playbooks, do the following:\n- In the navigation panel of the Google Cloud console, select **Monitoring** , and then select **Dashboards** : [Go to Dashboards](https://console.cloud.google.com/monitoring/dashboards) \n- Filter the dashboard list by clicking the **G\u200bC\u200bP** category.\n- Click the name of a \"GKE Interactive Playbook\" dashboard in the list.## Deployment metrics\nA Deployment is a controller that updates the state of resources like Pods, to manage events like rollouts and turndowns.\n### Table of Deployment metrics\nThe Deployment metrics let you monitor and alert on the behavior of the controller. The following table shows the metrics available in the kube state metrics package:\nThe Cloud Monitoring metric names in this table must be prefixed with `prometheus.googleapis.com/` . That prefix has been omitted from the entries in the table.\n| ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Kind,\\xa0Type,\\xa0Unit Monitored\\xa0resources Required\\xa0GKE\\xa0version') | ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Description Labels')   |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------|\n| kube_deployment_spec_replicas kube_deployment_spec_replicas/gauge                     | kube_deployment_spec_replicas kube_deployment_spec_replicas/gauge         |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Number of desired pods for a deployment. Sampled every 30 seconds. deployment: deployment.   |\n| kube_deployment_status_replicas_available kube_deployment_status_replicas_available/gauge               | kube_deployment_status_replicas_available kube_deployment_status_replicas_available/gauge   |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of available replicas per deployment. Sampled every 30 seconds. deployment: deployment. |\n| kube_deployment_status_replicas_updated kube_deployment_status_replicas_updated/gauge                | kube_deployment_status_replicas_updated kube_deployment_status_replicas_updated/gauge    |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of updated replicas per deployment. Sampled every 30 seconds. deployment: deployment. |\nFor more information, see [Deployment Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/deployment-metrics.md) .\n### Sample queries for Deployment metrics\nYou can create charts and alerting policies for individual Deployments by filtering Deployment metrics by cluster, namespace, and the name of the Deployment.\nFor example, to compare the number of available replicas to the expected number of replicas in a single Deployment, you can use the following PromQL queries to plot both metrics on a single chart:\n```\nkube_deployment_spec_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", deployment=DEPLOYMENT\"}\n```\n```\nkube_deployment_status_replicas_available{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", deployment=DEPLOYMENT\"}\n```\nTo alert on a failed or stalled Deployment, you can use the following PromQL expression:\n```\n(\n kube_deployment_spec_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", deployment=\"DEPLOYMENT\"}\n >\n kube_deployment_status_replicas_available{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", deployment=\"DEPLOYMENT\"}\n) and (\n changes(kube_deployment_status_replicas_updated{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", deployment=\"DEPLOYMENT\"}[10m])\n ==\n 0\n)\n```\nSome of the query and alert expressions in this section were adapted from the [kubernetes-apps.yaml file](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml) in the Prometheus community Kubernetes Helm Charts repository on GitHub.\n## StatefulSet metrics\nA StatefulSet is a controller that manages the deployment and scaling of a set of Pods for stateful applications. This controller manages the the ordering and uniqueness of Pods.\n### Table of StatefulSet metrics\nThe StatefulSet metrics let you monitor and alert on the behavior of the controller. The following table shows the metrics available in the kube state metrics package:\nThe Cloud Monitoring metric names in this table must be prefixed with `prometheus.googleapis.com/` . That prefix has been omitted from the entries in the table.\n| ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Kind,\\xa0Type,\\xa0Unit Monitored\\xa0resources Required\\xa0GKE\\xa0version') | ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Description Labels')   |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------|\n| kube_statefulset_replicas kube_statefulset_replicas/gauge                       | kube_statefulset_replicas kube_statefulset_replicas/gauge           |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Number of desired pods for a StatefulSet. Sampled every 30 seconds. statefulset: statefulset.  |\n| kube_statefulset_status_replicas_ready kube_statefulset_status_replicas_ready/gauge                 | kube_statefulset_status_replicas_ready kube_statefulset_status_replicas_ready/gauge     |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of ready replicas per StatefulSet. Sampled every 30 seconds. statefulset: statefulset. |\n| kube_statefulset_status_replicas_updated kube_statefulset_status_replicas_updated/gauge                | kube_statefulset_status_replicas_updated kube_statefulset_status_replicas_updated/gauge    |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of updated replicas per StatefulSet. Sampled every 30 seconds. statefulset: statefulset. |\nFor more information, see [StatefulSet Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/statefulset-metrics.md) .\n### Sample queries for StatefulSet metrics\nYou can create charts and alerting policies for individual StatefulSets by filtering statefulset metrics by cluster, namespace, and the name of the StatefulSet.\nFor example, to compare the number of available replicas to the expected number of replicas in a single StatefulSet, you can use the following PromQL queries to plot both metrics on a single chart:\n```\nkube_statefulset_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", statefulset=\"STATEFULSET\"}\n```\n```\nkube_statefulset_status_replicas_ready{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", statefulset=\"STATEFULSET\"}\n```\nTo alert on a failed or stalled StatefulSet rollout, you can use the following PromQL expression:\n```\n(\n kube_statefulset_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", statefulset=\"STATEFULSET\"}\n >\n kube_statefulset_status_replicas_ready{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", statefulset=\"STATEFULSET\"}\n) and (\n changes(kube_statefulset_status_replicas_updated{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", statefulset=\"STATEFULSET\"}[10m])\n ==\n 0\n)\n```\nSome of the query and alert expressions in this section were adapted from the [kubernetes-apps.yaml file](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml) in the Prometheus community Kubernetes Helm Charts repository on GitHub.\n## DaemonSet metrics\nA DaemonSet is a controller that ensures that some set of Nodes runs a copy of a Pod. For example, as Nodes are added to a cluster, the DaemonSet adds Pods to the Nodes. This controller is useful for ensuring that certain processes run on every node.\n### Table of DaemonSet metrics\nThe DaemonSet metrics let you monitor and alert on the behavior of the controller. The following table shows the metrics available in the kube state metrics package:\nThe Cloud Monitoring metric names in this table must be prefixed with `prometheus.googleapis.com/` . That prefix has been omitted from the entries in the table.\n| ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Kind,\\xa0Type,\\xa0Unit Monitored\\xa0resources Required\\xa0GKE\\xa0version') | ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Description Labels')                   |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| kube_daemonset_status_desired_number_scheduled kube_daemonset_status_desired_number_scheduled/gauge             | kube_daemonset_status_desired_number_scheduled kube_daemonset_status_desired_number_scheduled/gauge                 |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of nodes that should be running the daemon pod. Sampled every 30 seconds. daemonset: daemonset.               |\n| kube_daemonset_status_number_misscheduled kube_daemonset_status_number_misscheduled/gauge               | kube_daemonset_status_number_misscheduled kube_daemonset_status_number_misscheduled/gauge                   |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of nodes running a daemon pod but are not supposed to. Sampled every 30 seconds. daemonset: daemonset.             |\n| kube_daemonset_status_number_ready kube_daemonset_status_number_ready/gauge                   | kube_daemonset_status_number_ready kube_daemonset_status_number_ready/gauge                       |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of nodes that should be running the daemon pod and have one or more of the daemon pod running and ready. Sampled every 30 seconds. daemonset: daemonset. |\n| kube_daemonset_status_updated_number_scheduled kube_daemonset_status_updated_number_scheduled/gauge             | kube_daemonset_status_updated_number_scheduled kube_daemonset_status_updated_number_scheduled/gauge                 |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The number of nodes that are running updated daemon pod. Sampled every 30 seconds. daemonset: daemonset.               |\nFor more information, see [DaemonSet Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/daemonset-metrics.md) .\n### Sample queries for DaemonSet metrics\nYou can create charts and alerting policies for individual DaemonSets by filtering daemonset metrics by cluster, namespace, and the name of the DaemonSet.\nFor example, to compare the number of available replicas to the expected number of replicas in a single DaemonSet, you can use the following PromQL queries to plot both metrics on a single chart:\n```\nkube_daemonset_status_updated_number_scheduled{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", daemonsetset=DAEMONSET\"}\n```\n```\nkube_daemonset_status_desired_number_scheduled{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", daemonset=DAEMONSET\"}\n```\nTo alert on a failed or stalled DaemonSet rollout, you can use the following PromQL expression:\n```\n(\n (\n kube_daemonset_status_number_misscheduled{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", daemonset=\"DAEMONSET\"}\n  !=\n 0\n ) or (\n kube_daemonset_status_updated_number_scheduled{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", daemonset=\"DAEMONSET\"}\n  !=\n kube_daemonset_status_desired_number_scheduled{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", daemonset=\"DAEMONSET\"}\n )\n) and (\n changes(kube_daemonset_status_updated_number_scheduled{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", daemonset=\"DAEMONSET\"}[5m])\n ==\n 0\n)\n```\nSome of the query and alert expressions in this section were adapted from the [kubernetes-apps.yaml file](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml) in the Prometheus community Kubernetes Helm Charts repository on GitHub.\n## HorizontalPodAutoscaler metrics\nA HorizontalPodAutoscaler (HPA) is a controller that periodically changes the number of pods in a workload, such as a Deployment or StatefulSet, in response to some metric like CPU or memory utilization. Changing the number of pods available to a workload keeps the workload responsive but efficient.\nFor more information about HPAs, see [Viewing details about a Horizontal PodAutoscaler](/kubernetes-engine/docs/how-to/horizontal-pod-autoscaling#viewing) .\n### Table of HPA metrics\nThe HorizontalPodAutoscaler metrics let you monitor and alert on the behavior of the controller. The following table shows the metrics available in the kube state metrics package:\nThe Cloud Monitoring metric names in this table must be prefixed with `prometheus.googleapis.com/` . That prefix has been omitted from the entries in the table.\n| ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Kind,\\xa0Type,\\xa0Unit Monitored\\xa0resources Required\\xa0GKE\\xa0version') | ('PromQL\\xa0metric\\xa0name Cloud\\xa0Monitoring\\xa0metric\\xa0name', 'Description Labels')                                      |\n|:----------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| kube_horizontalpodautoscaler_spec_max_replicas kube_horizontalpodautoscaler_spec_max_replicas/gauge             | kube_horizontalpodautoscaler_spec_max_replicas kube_horizontalpodautoscaler_spec_max_replicas/gauge                                    |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Upper limit for the number of pods that can be set by the autoscaler, cannot be smaller than MinReplicas. Sampled every 30 seconds. horizontalpodautoscaler: horizontalpodautoscaler.               |\n| kube_horizontalpodautoscaler_spec_min_replicas kube_horizontalpodautoscaler_spec_min_replicas/gauge             | kube_horizontalpodautoscaler_spec_min_replicas kube_horizontalpodautoscaler_spec_min_replicas/gauge                                    |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Lower limit for the number of pods that can be set by the autoscaler, default 1. Sampled every 30 seconds. horizontalpodautoscaler: horizontalpodautoscaler.                     |\n| kube_horizontalpodautoscaler_spec_target_metric kube_horizontalpodautoscaler_spec_target_metric/gauge            | kube_horizontalpodautoscaler_spec_target_metric kube_horizontalpodautoscaler_spec_target_metric/gauge                                   |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The metric specifications used by this autoscaler when calculating the desired replica count. Sampled every 30 seconds. horizontalpodautoscaler: horizontalpodautoscaler. metric_name: metric_name. metric_target_type: metric_target_type. |\n| kube_horizontalpodautoscaler_status_condition kube_horizontalpodautoscaler_status_condition/gauge             | kube_horizontalpodautoscaler_status_condition kube_horizontalpodautoscaler_status_condition/gauge                                    |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | The condition of this autoscaler. Sampled every 30 seconds. condition: condition. horizontalpodautoscaler: horizontalpodautoscaler. namespace: namespace. status: status.                 |\n| kube_horizontalpodautoscaler_status_current_replicas kube_horizontalpodautoscaler_status_status_current_replicas/gauge        | kube_horizontalpodautoscaler_status_current_replicas kube_horizontalpodautoscaler_status_status_current_replicas/gauge                               |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Current number of replicas of pods managed by this autoscaler. Sampled every 30 seconds. horizontalpodautoscaler: horizontalpodautoscaler.                          |\n| kube_horizontalpodautoscaler_status_desired_replicas kube_horizontalpodautoscaler_status_desired_replicas/gauge          | kube_horizontalpodautoscaler_status_desired_replicas kube_horizontalpodautoscaler_status_desired_replicas/gauge                                 |\n| GAUGE,\u00a0DOUBLE,\u00a01 prometheus_target 1.27.2-gke.1200                         | Desired number of replicas of pods managed by this autoscaler. Sampled every 30 seconds. horizontalpodautoscaler: horizontalpodautoscaler.                          |\nFor more information, see [Horizontal Pod Autoscaler Metrics](https://github.com/kubernetes/kube-state-metrics/blob/main/docs/horizontalpodautoscaler-metrics.md) .\n### Sample queries for HPA metrics\nFor example, to determine if the HPA is approaching the maximum number of replicas, you can plot the following ratio:\n```\nkube_horizontalpodautoscaler_status_current_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", horizontalpodautoscaler=\"HPA\"} /\nkube_horizontalpodautoscaler_spec_max_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", horizontalpodautoscaler=\"HPA\"}\n```\nWhen the HPA is running with the maximum number of replicas, you might want to increase the spec for maximum number of pods. You can use the following PromQL expression to create an alert to notify you of this case:\n```\nkube_horizontalpodautoscaler_status_current_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", horizontalpodautoscaler=\"HPA\"}\n ==\nkube_horizontalpodautoscaler_spec_max_replicas{cluster=\"CLUSTER\", namespace=\"NAMESPACE\", horizontalpodautoscaler=\"HPA\"}\n```\nYou can also compare the values of the `kube_horizontalpodautoscaler_status_current_replicas` and the `kube_horizontalpodautoscaler_status_desired_replicas` metrics to determine if there is a difference between the current and needed number of replicas. A difference might may indicate a resource constraint in the cluster. The following PromQL expression looks for differences between the current number of replicas and the needed, minimum, and maximum numbers of replicas, as well as changes in the current number of replicas:\n```\n(kube_horizontalpodautoscaler_status_desired_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"}\n !=\nkube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"})\n and\n(kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"}\n >\nkube_horizontalpodautoscaler_spec_min_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"})\n and\n(kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"}\n <\nkube_horizontalpodautoscaler_spec_max_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"})\n and\nchanges(kube_horizontalpodautoscaler_status_current_replicas{job=\"kube-state-metrics\", namespace=~\"NAMESPACE\"}[15m]) == 0\n```\nThe `condition` and `status` labels on the `kube_horizontalpodautoscaler_status_condition` metric can also help you detect when HPAs run into various failure modes. For example:\n- The condition`ScalingLimited`and status of`true`indicates that the HPA is bound by either its minimum or maximum replica count:```\nkube_horizontalpodautoscaler_status_condition{status=\"true\", condition=\"ScalingLimited\"} == 1\n```\n- The condition `AbleToScale` and a status of `false` indicates that the HPA is encountering issues fetching or updating scales:```\nkube_horizontalpodautoscaler_status_condition{status=\"false\", condition=\"AbleToScale\"} == 1\n```\n- The condition `ScalingActive` and a status of `false` indicates that the HPA is disabled or is unable to calculate a new scale:```\nkube_horizontalpodautoscaler_status_condition{status=\"false\", condition=\"ScalingActive\"} == 1\n```Some of the query and alert expressions in this section were adapted from the [kubernetes-apps.yaml file](https://github.com/prometheus-community/helm-charts/blob/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14/kubernetes-apps.yaml) in the Prometheus community Kubernetes Helm Charts repository on GitHub.", "guide": "Google Kubernetes Engine (GKE)"}