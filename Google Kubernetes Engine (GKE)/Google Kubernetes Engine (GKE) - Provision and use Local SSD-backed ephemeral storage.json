{"title": "Google Kubernetes Engine (GKE) - Provision and use Local SSD-backed ephemeral storage", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/persistent-volumes/local-ssd", "abstract": "# Google Kubernetes Engine (GKE) - Provision and use Local SSD-backed ephemeral storage\nThis page explains how to provision Local SSD storage on Google Kubernetes Engine (GKE) clusters, and how to configure workloads to consume data from Local SSD-backed ephemeral storage attached to nodes in your cluster.\n**Note:** Local SSD volumes require machine type `n1-standard-1` or larger; the default machine type, `e2-medium` is not supported. You can learn more about [machine types](/compute/docs/machine-types) in the Compute Engine documentation.\nTo learn more about Local SSD support on GKE, see [About Local SSD storage](/kubernetes-engine/docs/concepts/local-ssd#emptydir-volume) .\n", "content": "## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.## Create a cluster or node pool with Local SSD-backed ephemeral storage\nUse the Google Cloud CLI to create a cluster or node pool with Local SSD-backed ephemeral storage.\nUse the `--ephemeral-storage-local-ssd` option to attach fully-managed [localephemeral storage](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#local-ephemeral-storage) backed by Local SSD volumes. This storage is tied to the lifecycle of your Pods. When your Pods request ephemeral storage, GKE schedules them to run on nodes that have Local SSD volumes configured as ephemeral storage.\nIf you have [cluster autoscaling](/kubernetes-engine/docs/how-to/cluster-autoscaler) enabled, GKE autoscales your nodes when the cluster needs more ephemeral storage space. Your Pods can access data on Local SSD volumes through the [emptyDir](https://kubernetes.io/docs/concepts/storage/volumes/#emptydir) volume.\n**Note:** If you were using the `--local-ssd-count` option during the Preview, we strongly encourage switching to the `--ephemeral-storage-local-ssd` option instead to take advantage of more performant storage backed by NVMe.\nThe gcloud CLI command you run to create the cluster or node pool depends on which [machine series generation](/kubernetes-engine/docs/concepts/local-ssd#machine) of your selected machine type. For example, N1 and N2 machine types belong to a first and second generation machine series respectively, while C3 machine types belong to a third generation machine series.\n### Create a cluster with Local SSD\nIf you are using a machine type from a first or second generation machine series, create your cluster by specifying the `--ephemeral-storage-local-ssd count=` `` option. This option specifies the number of [Local SSD volumes](/compute/docs/disks/local-ssd) to attach to each node. The maximum number [varies by machine type and region](/compute/docs/disks#local_ssd_machine_type_restrictions) .\nThese settings apply to the default node pool only. If subsequent node pools need Local SSD, specify that during [node pool creation](#node-pool) .\nTo create a cluster running on GKE version 1.25.3-gke.1800 or later in which the default pool uses Local SSD volumes, run the following command:\n```\ngcloud container clusters create CLUSTER_NAME \\\u00a0 \u00a0 --ephemeral-storage-local-ssd count=NUMBER_OF_DISKS \\\u00a0 \u00a0 --machine-type=MACHINE_TYPE \\\u00a0 \u00a0 --release-channel CHANNEL_NAME\n```\nReplace the following:- ``: the name of the cluster.\n- ``: the number of Local SSD volumes to provision on each node. These volumes are combined into a single logical volume during node setup. The maximum number of volumes [varies by machine type and region](/compute/docs/disks#local_ssd_machine_type_restrictions) . Note that some Local SSD capacity is [reserved for system use](/kubernetes-engine/docs/concepts/plan-node-sizes#local_ephemeral_storage_reservation) .\n- ``: the machine type to use. This field is required, as Local SSD cannot be used with the default`e2-medium`type.\n- ``: a [release channel](/kubernetes-engine/docs/concepts/release-channels) that includes GKE versions later than 1.25.3-gke.1800. If you prefer not to use a release channel, you can also use the`--cluster-version`flag instead of`--release-channel`, specifying a valid version later than 1.25.3-gke.1800. To determine the valid versions, use the`gcloud container get-server-config`command.\nIf you use a machine type from a third generation machine series, you do not need to specify any Local SSD options when creating a cluster. The [number of disks](/compute/docs/disks/local-ssd#choose_number_local_ssds) attached to each node depends on the machine type.\nTo create a cluster, run the following command:\n```\ngcloud container clusters create CLUSTER_NAME \\\u00a0 --machine-type=MACHINE_TYPE \\\u00a0 --cluster-version CLUSTER_VERSION\n```\nReplace the following:- ``: the name of the cluster.\n- ``: the machine type to use from a third generation machine series.\n- ``: a [GKE cluster version](/kubernetes-engine/docs/concepts/local-ssd#3gen) that supports Local SSD on machines types from a third generation machine series.\n### Create a node pool with Local SSD\nTo create a node pool running on GKE version 1.25.3-gke.1800 or later that uses Local SSD volumes, run the following command:\n```\ngcloud container node-pools create POOL_NAME \\\u00a0 \u00a0 --cluster=CLUSTER_NAME \\\u00a0 \u00a0 --ephemeral-storage-local-ssd count=NUMBER_OF_DISKS \\\u00a0 \u00a0 --machine-type=MACHINE_TYPE\n```\nReplace the following:- ``: the name of your new node pool.\n- ``: the name of the cluster.\n- ``: the number of Local SSD volumes to provision on each node. These volumes are combined into a single logical volume during node setup. The maximum number of volumes [varies by machine type and region](/compute/docs/disks#local_ssd_machine_type_restrictions) . Note that some Local SSD capacity is [reserved for system use](/kubernetes-engine/docs/concepts/plan-node-sizes#local_ephemeral_storage_reservation) .\n- ``: the machine type to use. This field is required, as Local SSD cannot be used with the default`e2-medium`type.\nIf you use a machine type from a third generation machine series, you do not need to specify any Local SSD options when creating a node pool. The number of volumes attached to each node depends on the machine type.\nTo create a node pool, run the following command:\n```\ngcloud container node-pools create POOL_NAME \\\u00a0 --cluster=CLUSTER_NAME \\\u00a0 --machine-type=MACHINE_TYPE \\\u00a0 --node-version NODE_VERSION\n```\nReplace the following:- ``: the name of the new node pool.\n- ``: the name of the cluster.\n- ``: the machine type to use from a third generation machine series.\n- ``: a [GKE node pool version](/kubernetes-engine/docs/concepts/local-ssd#3gen) that supports Local SSD on machines types from a third generation machine series.\nNodes in the node pool are created with a `cloud.google.com/gke-ephemeral-storage-local-ssd=true` label. You can verify the labels by running the following command:\n```\nkubectl describe node NODE_NAME\n```\n## Use Local SSD-backed ephemeral storage with Autopilot clusters\nYou can use Local SSD in the following Autopilot compute classes:\n- `Performance`\n- `Accelerator`\nFor the `Performance` class, follow the instructions to [use Local SSDs inPerformance classPods](/kubernetes-engine/docs/how-to/performance-pods#local-ssds-performance-class) .\nFor the `Accelerator` compute class, you can use Local SSD for ephemeral storage if using NVIDIA L4 GPUs, and running GKE patch version 1.28.6-gke.1369000 and later or 1.29.1-gke.1575000 and later. NVIDIA H100 (80GB) GPUs and NVIDIA A100 (80GB) GPUs always use Local SSDs for ephemeral storage, and you can't specify the following node selector for those GPUs.\nTo use Local SSD for ephemeral storage, add the `cloud.google.com/gke-ephemeral-storage-local-ssd: \"true\"` nodeSelector to your workload manifest. Your Pod specification should look similar to the following example:\n```\napiVersion: v1kind: Podmetadata:\u00a0 name: l4-localssd-podspec:\u00a0 containers:\u00a0 - name: my-gpu-container\u00a0 \u00a0 image: nvidia/cuda:11.0.3-runtime-ubuntu20.04\u00a0 \u00a0 command: [\"/bin/bash\", \"-c\", \"--\"]\u00a0 \u00a0 args: [\"while true; do sleep 600; done;\"]\u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 cpu: 16\u00a0 \u00a0 \u00a0 \u00a0 memory: 64Gi\u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: 800Gi\u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0cpu: 16\u00a0 \u00a0 \u00a0 \u00a0memory: 64Gi\u00a0 \u00a0 \u00a0 \u00a0ephemeral-storage: 800Gi\u00a0 \u00a0 \u00a0 \u00a0nvidia.com/gpu: 8\u00a0 nodeSelector:\u00a0 \u00a0 cloud.google.com/gke-accelerator: nvidia-l4\u00a0 \u00a0 cloud.google.com/compute-class: Accelerator\u00a0 \u00a0 cloud.google.com/gke-ephemeral-storage-local-ssd: \"true\"\n```\n## Using the legacy API parameter\nThe `--local-ssd-count` option is a legacy API parameter that supports SCSI Local SSD. The Compute Engine third generation machine series does not support SCSI and only supports NVMe. You should only use this option with Windows Server clusters. If you are currently using the legacy API parameter on Linux clusters, we recommend that you use the `--ephemeral-storage-local-ssd` option instead.\n### Local SSD on Windows Server clusters\n**Note:** Local SSD support for Windows Server is only available via the Local SSD count parameter ( `gcloud container clusters create --local-ssd-count` ).\nWhen you use Local SSD with your [clusters running Windows Server node pools](/kubernetes-engine/docs/how-to/creating-a-cluster-windows) , you need to log in to the node and format the volume before using it. In the following example, the Local SSD volume is formatted with the NTFS file system. You can also create directories under the volume. In this example, the directories are under disk D.\n```\nPS C:\\> Get-Disk | Where partitionstyle -eq 'raw' | Initialize-Disk -PartitionStyle MBR -PassThru | New-Partition -AssignDriveLetter -UseMaximumSize | Format-Volume -FileSystem ntfs -Confirm:$falsePS C:\\> mkdir D:\\test-ssd\n```\n## Access Local SSD volumes\nThe following example shows how you can access Local SSD-backed ephemeral storage.\n### Ephemeral storage as an emptyDir volume\nA GKE node pool can be configured to use Local SSD for ephemeral storage, including `emptyDir` volumes.\nThe following Pod manifest uses an `emptyDir` and a node selector of `cloud.google.com/gke-ephemeral-storage-local-ssd` . You can apply a similar technique for Deployment manifests or StatefulSet manifests.\nWhen choosing the ephemeral storage resource request, take into account the Local SSD capacity [reserved for system use](/kubernetes-engine/docs/concepts/plan-node-sizes#local_ephemeral_storage_reservation) .\n```\napiVersion: v1kind: Podmetadata:\u00a0 name: POD_NAMEspec:\u00a0 containers:\u00a0 \u00a0 - name: CONTAINER_NAME\u00a0 \u00a0 \u00a0 image: \"registry.k8s.io/pause\"\u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral-storage: \"200Gi\"\u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - mountPath: /cache\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: scratch-volume\u00a0 nodeSelector:\u00a0 \u00a0 cloud.google.com/gke-ephemeral-storage-local-ssd: \"true\"\u00a0 volumes:\u00a0 \u00a0 - name: scratch-volume\u00a0 \u00a0 \u00a0 emptyDir: {}\n```\n## Troubleshooting\nFor troubleshooting instructions, refer to [Troubleshooting storage in GKE](/kubernetes-engine/docs/troubleshooting/troubleshooting-gke-storage#local-ssds) .\n## What's next\n- [Learn more about node pools](/kubernetes-engine/docs/concepts/node-pools) .", "guide": "Google Kubernetes Engine (GKE)"}