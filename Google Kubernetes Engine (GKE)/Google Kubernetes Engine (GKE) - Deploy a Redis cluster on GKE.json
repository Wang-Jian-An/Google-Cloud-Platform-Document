{"title": "Google Kubernetes Engine (GKE) - Deploy a Redis cluster on GKE", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/upgrading-stateful-workload", "abstract": "# Google Kubernetes Engine (GKE) - Deploy a Redis cluster on GKE\nThis tutorial provides recommended practices for creating a [stateful](/kubernetes-engine/docs/concepts/statefulset) application and upgrading the Google Kubernetes Engine (GKE) cluster that's running the application. This tutorial uses [Redis](https://redis.io/) as an example for deploying a stateful application, but the same concepts are applicable to other types of stateful applications deployed on GKE.", "content": "## ObjectivesThis tutorial covers the following steps:- Create a GKE cluster enrolled in a release channel.\n- Create a [Redis Cluster](https://redis.io/topics/cluster-spec) on GKE.\n- Deploy the Redis client application to GKE.\n- Perform these best practices for node pool upgrades:- Set up the [Pod Disruption Budget (PDB)](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/) .\n- Set up the [maintenance window and exclusions](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) .\n- Set up the [node upgrade strategy](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies) to either [surge upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#surge) or [blue-green upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy) .\n- Test the application.\n- Upgrade the cluster.\n- Test workload disruption.\nThe following diagram shows you a high-level view of the cluster architecture for this tutorial:## CostsIn this document, you use the following billable components of Google Cloud:- [GKE](/kubernetes-engine/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . \nWhen you finish the tasks that are described in this document, you can avoid continued billing by deleting the resources that you created. For more information, see [Clean up](#clean-up) .## Before you begin\n### Set up your project### Set defaults for the Google Cloud CLI\n- In the Google Cloud console, start a Cloud Shell instance:  [Open Cloud Shell](https://console.cloud.google.com/?cloudshell=true) \n- Download the source code for this sample app:```\n\u00a0git clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samples\u00a0cd kubernetes-engine-samples/quickstarts/hello-app-redis/manifests\n```\n- Set the default environment variables:```\n\u00a0gcloud config set project PROJECT-ID\u00a0gcloud config set compute/zone COMPUTE-ZONE\n```Replace the following values:- : your Google Cloud [project ID](/resource-manager/docs/creating-managing-projects#identifying_projects) .\n- : the [Compute Engine zone](/compute/docs/regions-zones#available) .## Create a GKE cluster enrolled in a release channelTo create your GKE cluster, complete the following steps:- Create a cluster named `redis-test` with three nodes:```\ngcloud container clusters create redis-test \\\u00a0 \u00a0 --num-nodes=3 \\\u00a0 \u00a0 --release-channel regular\n```Once the cluster is created, you should see output similar to the following example:```\n NAME: redis-test\n LOCATION: us-central1-c\n MASTER_VERSION: 1.22.10-gke.600\n MASTER_IP: 34.69.67.7\n MACHINE_TYPE: e2-medium\n NODE_VERSION: 1.22.10-gke.600\n NUM_NODES: 3\n STATUS: RUNNING\n```\n- Configure `kubectl` to communicate with the cluster:```\ngcloud container clusters get-credentials redis-test\n```\n## Create a Redis Cluster on GKEIn this section, you add a Redis Cluster on top of the GKE cluster you previously created by deploying a [ConfigMap](https://kubernetes.io/docs/concepts/configuration/configmap/) , [StatefulSet](/kubernetes-engine/docs/concepts/statefulset) , and [headless Service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) .\nTo create a Redis cluster, complete these steps:- Refer to the ConfigMap file ( `redis-configmap.yaml` ) which stores the Redis configuration. The snippet below shows the Readiness probe and the Liveness probe scripts. [  quickstarts/hello-app-redis/manifests/redis-configmap.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/redis-configmap.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/redis-configmap.yaml) ```\nreadiness.sh: |-\u00a0 #!/bin/sh\u00a0 pingResponse=\"$(redis-cli -h localhost ping)\"\u00a0 if [ \"$?\" -eq \"124\" ]; then\u00a0 \u00a0 echo \"PING timed out\"\u00a0 \u00a0 exit 1\u00a0 fi\u00a0 if [ \"$pingResponse\" != \"PONG\"]; then\u00a0 \u00a0 echo \"$pingResponse\"\u00a0 \u00a0 exit 1\u00a0 filiveness.sh: |-\u00a0 #!/bin/sh\u00a0 pingResponse=\"$(redis-cli -h localhost ping | head -n1 | awk '{print $1;}')\"\u00a0 if [ \"$?\" -eq \"124\" ]; then\u00a0 \u00a0 echo \"PING timed out\"\u00a0 \u00a0 exit 1\u00a0 fi\u00a0 if [ \"$pingResponse\" != \"PONG\"] && [ \"$pingResponse\" != \"LOADING\" ] && [ \"$pingResponse\" != \"MASTERDOWN\" ]; then\u00a0 \u00a0 echo \"$pingResponse\"\u00a0 \u00a0 exit 1\u00a0 fi\n```The `readiness.sh` and `liveness.sh` scripts use [redis-cli ping](https://redis.io/commands/ping/) to check if the redis server is running or not. If it returns `PONG` , the Redis server is up and running. These scripts will be used in the `redis-cluster.yaml` .To learn more about the Redis parameters in this ConfigMap, see the Redis Cluster configuration parameters section in the [Redis Cluster tutorial](https://redis.io/docs/manual/scaling/#redis-cluster-configuration-parameters) .\n- Deploy the ConfigMap:```\nkubectl apply -f redis-configmap.yaml\n```\n- Refer to the StatefulSet ( `redis-cluster.yaml` ) snippet below which shows the usage of the Readiness probe and the Liveness probe.To learn about how to configure probes in Kubernetes, see [Configure Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes) . [  quickstarts/hello-app-redis/manifests/redis-cluster.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/redis-cluster.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/redis-cluster.yaml) ```\nstartupProbe:\u00a0 periodSeconds: 5\u00a0 timeoutSeconds: 5\u00a0 successThreshold: 1\u00a0 failureThreshold: 20\u00a0 tcpSocket:\u00a0 \u00a0 port: redislivenessProbe:\u00a0 periodSeconds: 5\u00a0 timeoutSeconds: 5\u00a0 successThreshold: 1\u00a0 failureThreshold: 5\u00a0 exec:\u00a0 \u00a0 command: [\"sh\", \"-c\", \"/probes/liveness.sh\"]readinessProbe:\u00a0 periodSeconds: 5\u00a0 timeoutSeconds: 1\u00a0 successThreshold: 1\u00a0 failureThreshold: 5\u00a0 exec:\u00a0 \u00a0 command: [\"sh\", \"-c\", \"/probes/readiness.sh\"]\n```We strongly recommend that you use Readiness and Liveness probes when upgrading node pools; this ensures that your Pods are ready during an upgrade.\n- Deploy the StatefulSet:```\nkubectl apply -f redis-cluster.yaml\n```\n- The headless Service named [redis-service.yaml](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/quickstarts/hello-app-redis/manifests/redis-service.yaml) is for the Redis nodes' connection. The `clusterIP` field is set to `None` in order to create a headless Service.Deploy the Service:```\nkubectl apply -f redis-service.yaml\n```\n- Wait approximately two minutes and verify all the Pods are running by using the following command:```\nkubectl get pods\n```You should see output similar to the following example:```\nNAME  READY STATUS    RESTARTS AGE\nredis-0 1/1  Running    0   2m29s\nredis-1 1/1  Running    0   2m8s\nredis-2 1/1  Running    0   107s\nredis-3 1/1  Running    0   85s\nredis-4 1/1  Running    0   54s\nredis-5 1/1  Running    0   23s\n```\n- Verify the persistent volumes were created by running the following command:```\nkubectl get pv\n```You should see output similar to the following example:```\nNAME  CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM     STORAGECLASS REASON AGE\npvc-HASH 1Gi  RWO   Delete   Bound default/data-redis-5 standard    75s\npvc-HASH 1Gi  RWO   Delete   Bound default/data-redis-1 standard    2m59s\npvc-HASH 1Gi  RWO   Delete   Bound default/data-redis-3 standard    2m16s\npvc-HASH 1Gi  RWO   Delete   Bound default/data-redis-2 standard    2m38s\npvc-HASH 1Gi  RWO   Delete   Bound default/data-redis-0 standard    3m20s\npvc-HASH 1Gi  RWO   Delete   Bound default/data-redis-4 standard    104s\n```In this output, represents a hash which is attached to each persistent volume name.\n### Assign roles to your Redis ClusterOnce the configuration is complete, assign roles to the Redis Cluster.\nThe following script obtains the Pod IP addresses, then assigns the leader and follower roles by passing each of the Pod IP addresses into the command:\n [  quickstarts/hello-app-redis/manifests/roles.sh ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/roles.sh) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/roles.sh) \n```\n#!/bin/bash# Usage: ./roles.shurls=$(kubectl get pods -l app=redis -o jsonpath='{range.items[*]}{.status.podIP} ')command=\"kubectl exec -it redis-0 -- redis-cli --cluster create --cluster-replicas 1 \"for url in $urlsdo\u00a0 \u00a0 command+=$url\":6379 \"doneecho \"Executing command: \" $command$command\n```\nTo assign roles to your Redis cluster, complete these steps:- Run the script:```\nchmod +x ./roles.sh./roles.sh\n```\n- Type `yes` when prompted.\n- Log in to a Redis node to check its role. For example, to verify that that `redis-0` has a leader role, run the following command:```\nkubectl exec -it redis-0 -- redis-cli role\n```You should see output similar to the following example:```\n1) \"master\"\n2) (integer) 574\n3) 1) 1) \"10.28.2.3\"\n  2) \"6379\"\n  3) \"574\"\n```\n## Deploy the Redis client applicationTo deploy your application to the GKE cluster you created, define a Deployment for your application. The file named [app-deployment.yaml](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/quickstarts/hello-app-redis/manifests/app-deployment.yaml) contains the deployment definition for the application.\nTo learn more about the probes and Pod affinity rules used in this Deployment, see [GKE best practices: Designing and building highly available clusters](https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-creating-a-highly-available-gke-cluster) .\nTo create the Deployment, complete the following steps:- Apply the Deployment:```\nkubectl apply -f app-deployment.yaml\n```\n- Expose the application through a load balancer:```\nkubectl expose deployment hello-web \\\u00a0 \u00a0 --type=LoadBalancer \\\u00a0 \u00a0 --port 80 \\\u00a0 \u00a0 --target-port 8080\n```\n- Wait approximately one minute and retrieve the application's external IP address by running the following command:```\nkubectl get service\n```From the output, copy the value listed in `hello-web's` `EXTERNAL-IP` column:```\nNAME    TYPE   CLUSTER-IP EXTERNAL-IP PORT(S)    AGE\nhello-web  LoadBalancer 10.13.10.55 EXTERNAL_IP 80:30703/TCP   166m\n```\n- Verify the application is working by pasting the into your web browser. You should see output similar to the following example:```\nI have been hit [1] times since deployment!\n```Take note of the visit number. You need to use it in the [Testing the application's disruption](#test) section.\n- Set a variable for the you just copied. You use this value when you [create scripts to test your application](#scripts) in the next section:```\nexport IP=EXTERNAL_IP\n```\n## Configure best practices for node pool upgradesPerform these best practices for stateful applications to optimize for better availability during node pool upgrades.\n### Set up the Pod Disruption Budget (PDB)Create a [Pod Disruption Budget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/) to limit the number of replicated Pods that are down simultaneously during a voluntary disruption. This is useful for stateful application where there needs to be a quorum for the number of replicas to be available during an upgrade.\n [  quickstarts/hello-app-redis/manifests/pdb-minavailable.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/pdb-minavailable.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/manifests/pdb-minavailable.yaml) \n```\napiVersion: policy/v1kind: PodDisruptionBudgetmetadata:\u00a0 name: redis-pdbspec:\u00a0 minAvailable: 3\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: redis\n```\nIn a PDB definition:- `app`specifies which application this PDB applies to.\n- `minAvailable`sets the minimum number of Pods to be available during a disruption. It can be a value or a percentage (e.g. 30%).\n- `maxUnavailable`sets the maximum number of Pods that can be unavailable during a disruption. It can be a value or a percentage as well.\n **Note:** Based on the quorum or preference of the application, choose one of `minAvailable` or `maxUnavailable` for the PDB.\n **Note:** Once the `PodDisruptionBudget` is set, GKE will not shut down Pods in your application [if the number of pods is equal to or less than a configured limit](https://kubernetes.io/docs/tasks/run-application/configure-pdb/#specifying-a-poddisruptionbudget) for up to 60 minutes.\nTo set up the PDB, complete these steps:- Deploy the PDB:```\nkubectl apply -f pdb-minavailable.yaml\n```\n- Verify that the PDB has been created:```\nkubectl get pdb\n```\n### Set up the maintenance windows and exclusionsNode auto-upgrades streamline the upgrade process and keep the nodes in the cluster up-to-date when the control plane is upgraded on your behalf. This feature is enabled by default. To learn more, see [Auto-upgrading nodes](/kubernetes-engine/docs/how-to/node-auto-upgrades) .\nUse [maintenance windows and maintenance exclusions](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions) to set up time frames and control when maintenance can and cannot occur on GKE clusters:- Set up a maintenance window that starts at 2:00 AM UTC on August 19, 2022, and finishes four hours later. This maintenance window runs daily. During this time, automatic maintenance is permitted.```\ngcloud container clusters update redis-test \\\u00a0 \u00a0--maintenance-window-start 2022-08-19T02:00:00Z \\\u00a0 \u00a0--maintenance-window-end 2022-08-19T06:00:00Z \\\u00a0 \u00a0--maintenance-window-recurrence FREQ=DAILY\n```\n- Set up an exclusion window that prevents maintenance during the New Year holiday. This maintenance exclusion uses the `no_upgrades` scope. During this time, no automatic maintenance of any kind is permitted. To learn more, see [Scope of maintenance to exclude](/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#scope_of_maintenance_to_exclude) .```\ngcloud container clusters update redis-test \\\u00a0 \u00a0--add-maintenance-exclusion-name new-year \\\u00a0 \u00a0--add-maintenance-exclusion-start 2022-12-26T00:00:00Z \\\u00a0 \u00a0--add-maintenance-exclusion-end 2023-01-02T02:00:00Z \\\u00a0 \u00a0--add-maintenance-exclusion-scope no_upgrades\n```\n- Verify the maintenance window and exclusions are applied. Look under `maintenancePolicy:````\ngcloud container clusters describe redis-test\n```\nTo learn more, see [Configure maintenance windows and exclusions](/kubernetes-engine/docs/how-to/maintenance-windows-and-exclusions) .\n### Configure a node upgrade strategyThere are two node upgrade strategies you can use for the node pools in your GKE cluster: **Blue-green upgrades** and **surge upgrades** . To learn more, see [Node upgrade strategies](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#choose-surge-upgrades) .\nChoose blue-green upgrades if the workloads are less tolerant of disruptions, and a temporary cost increase due to higher resource usage is acceptable.\nRun the following command to change the current node pools to [blue-green upgrade](/kubernetes-engine/docs/concepts/node-pool-upgrade-strategies#blue-green-upgrade-strategy) strategy.\n```\ngcloud container node-pools update default-pool \\--cluster=redis-test \\--enable-blue-green-upgrade \\--zone COMPUTE-ZONE \\--node-pool-soak-duration=120s\n```\nNode pool soak duration is set to two minutes to save time during the soak node pool phase for the purpose of this tutorial. This phase is used to verify the workload's health after the blue pool nodes have been drained. We recommend setting the node pool soak duration to one hour (3600 seconds) or a duration that best suits the application.\nFor more information about managing pod allocation, see [Deploy a Pod to a specific node pool](/kubernetes-engine/docs/how-to/node-pools#deploy) and [Deploying Services to specific node pools](/kubernetes-engine/docs/concepts/node-pools#deploying_services_to_specific_node_pools) .\nFor more information about configuring blue-green upgrades, see [Configure blue-green upgrades](/kubernetes-engine/docs/how-to/node-pool-upgrade-strategies#configure-blue-green-upgrades) .\nChoose surge upgrades if cost optimization is important and if workloads can tolerate a graceful shutdown in less than 60 minutes (GKE respects PDB up to 60 minutes).\nRun the following command to change the current node pools to [surge upgrade](/kubernetes-engine/docs/how-to/node-pool-upgrade-strategies#surge) strategy.\n```\ngcloud container node-pools update default-pool \\--max-surge-upgrade=1 \\--max-unavailable-upgrade=0 \\--cluster=redis-test\n```\nWith this configuration ( `maxSurge=1` and `maxUnavailable=0` ), only one surge node can be added to the node pool during an upgrade, so only one node can be upgraded at a time. This setting speeds up Pod restarts during upgrades while progressing conservatively.\nFor more information about configuring surge upgrades, see [Configure surge upgrades](/kubernetes-engine/docs/how-to/node-pool-upgrade-strategies#surge) .Check the current node pool configuration:\n```\n\u00a0 \u00a0gcloud container node-pools describe default-pool \\\u00a0 \u00a0--cluster redis-test \\\u00a0 \u00a0--zone COMPUTE-ZONE\n```\nFor more information on viewing node pools, see [View node pools in a cluster](/kubernetes-engine/docs/how-to/node-pools#viewing_node_pools_in_a_cluster) .## Test the applicationIn this section you use two scripts, one that sends requests to your application, and one that measures the success rate of the requests. You use these scripts to measure what happens when you upgrade your cluster.\nTo create the scripts:- Change to the directory containing the scripts:```\ncdcd kubernetes-engine-samples/quickstarts/hello-app-redis/scripts\n```\n- Refer to the script named `generate_load.sh` which sends a queries-per-second (QPS) request to your application. The script saves the HTTP response code into the current directory to a file named `output` . The value of `output` is used in the script you create in the next step. [  quickstarts/hello-app-redis/scripts/generate_load.sh ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/scripts/generate_load.sh) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/scripts/generate_load.sh) ```\n#!/bin/bash# Usage: ./generate_load.sh <IP> <QPS>IP=$1QPS=$2while true\u00a0 do for N in $(seq 1 $QPS)\u00a0 \u00a0 do curl -I -m 5 -s -w \"%{http_code}\\n\" -o /dev/null http://${IP}/ >> output &\u00a0 \u00a0 done\u00a0 sleep 1done\n```\n- Refer to the script named `print_error_rate.sh` which calculates the success rate based on the output generated by `generate_load.sh` . [  quickstarts/hello-app-redis/scripts/print_error_rate.sh ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/scripts/print_error_rate.sh) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/quickstarts/hello-app-redis/scripts/print_error_rate.sh) ```\n#!/bin/bash# Usage: watch ./print_error_rate.shTOTAL=$(cat output | wc -l);SUCCESS=$(grep \"200\" output | \u00a0wc -l);ERROR1=$(grep \"000\" output | \u00a0wc -l)ERROR2=$(grep \"503\" output | \u00a0wc -l)ERROR3=$(grep \"500\" output | \u00a0wc -l)SUCCESS_RATE=$(($SUCCESS * 100 / TOTAL))ERROR_RATE=$(($ERROR1 * 100 / TOTAL))ERROR_RATE_2=$(($ERROR2 * 100 / TOTAL))ERROR_RATE_3=$(($ERROR3 * 100 / TOTAL))echo \"Success rate: $SUCCESS/$TOTAL (${SUCCESS_RATE}%)\"echo \"App network Error rate: $ERROR1/$TOTAL (${ERROR_RATE}%)\"echo \"Resource Error rate: $ERROR2/$TOTAL (${ERROR_RATE_2}%)\"echo \"Redis Error rate: $ERROR3/$TOTAL (${ERROR_RATE_3}%)\"\n```\n- Give yourself permission to run the scripts:```\nchmod u+x generate_load.sh print_error_rate.sh\n```\n- Set a variable for the number of QPS. This value is used in the `generate_load.sh` script as is the variable you set for the . We recommend you set a value of 40.```\nexport QPS=40\n```\n- Run the `generate_load.sh` script to start sending QPS:```\n./generate_load.sh $IP $QPS 2>&1\n```\n- Leave the `generate_load.sh` script running and open a new terminal. In the new terminal, run the `print_error_rate.sh` script to check the error rate:```\ncdcd kubernetes-engine-samples/quickstarts/hello-app-redis/scriptswatch ./print_error_rate.sh\n```You should see a 100% success rate and 0% error rates as the QPS are made.\n- Leave both scripts running and open a third terminal in preparation for the next section.\n## Upgrade the clusterTo upgrade the cluster, complete these steps:- Determine which GKE version the `redis-test` cluster is using:```\nV=$(gcloud container clusters describe redis-test | grep \"version:\" | sed \"s/version: //\")echo $V\n```You should see output similar to the following example: `1.22.9-gke.2000` .\n- Retrieve a list of available Kubernetes versions:```\ngcloud container get-server-config\n```\n- In the list of versions, locate the `validMasterVersions:` section and look for the `redis-cluster` version you retrieved in the previous step. To avoid [version skew](https://kubernetes.io/docs/setup/release/version-skew-policy/) , copy the version from the list that is immediately above the `redis-cluster` version.\n- Upgrade the cluster's control plane to the version you selected and type `y` when prompted:```\ngcloud container clusters upgrade redis-test \\\u00a0 \u00a0 --master \\\u00a0 \u00a0 --cluster-version VERSION\n```Replace with the version you selected from the list in the previous step.The control plane upgrade takes several minutes.\n- Upgrade the cluster's nodes to the version you selected and type `y` when prompted:```\ngcloud container clusters upgrade redis-test \\\u00a0 \u00a0 --cluster-version=VERSION \\\u00a0 \u00a0 --node-pool=default-pool\n```Replace with the version you selected from the list.\n## Test workload disruptionIn this section, you test your application's status and observe workload disruption.- Return to the terminal window running `./print_error_rate.sh` and observe how the success rate changed during the upgrade. You should notice a slight decrease in the success rate and a slight increase in the app network error rate as the nodes are taken down to be upgraded.In the `Success rate` field, you'll see how many visits were successfully made to the website. Take a note of this value.\n- Stop both scripts from running by entering `CTRL+C` in the relevant terminals.\n- Return to the website for your application by entering its IP address (this is the you copied during the [Deploy the Redis client application](#deploy-gke) section) into your browser.\n- Observe the visit number for your application. The number you see should equal:`` `+` ``where is the number you recorded in the final step of [Deploy the Redis client application](#deploy-gke) and is the value you recorded in the first step of this section.\n## Clean up\nAfter you finish the tutorial, you can clean up the resources that you created so that they stop using quota and incurring charges. The following sections describe how to delete or turn off these resources.\n### Delete the project\nThe easiest way to eliminate billing is to delete the project that you created for the tutorial.\nTo delete the project:\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\nIf you plan to explore multiple architectures, tutorials, or quickstarts, reusing projects  can help you avoid exceeding project quota limits.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.### Delete the clusterTo delete the cluster you created for this tutorial, run the following command:\n```\ngcloud container clusters delete redis-test\n```## What's next\n- [Best practices for upgrading clusters](/kubernetes-engine/docs/best-practices/upgrading-clusters) \n- [How to set Cluster notifications](/kubernetes-engine/docs/concepts/cluster-notifications) \n- [GKE Best Practices: Day 2 Operations](/blog/products/containers-kubernetes/ensuring-reliability-and-uptime-for-your-gke-cluster) \n- [Set up Health checks with Probes](/blog/products/containers-kubernetes/kubernetes-best-practices-setting-up-health-checks-with-readiness-and-liveness-probes)", "guide": "Google Kubernetes Engine (GKE)"}