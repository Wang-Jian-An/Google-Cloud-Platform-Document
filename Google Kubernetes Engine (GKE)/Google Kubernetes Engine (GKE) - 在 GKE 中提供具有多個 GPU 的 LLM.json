{"title": "Google Kubernetes Engine (GKE) - \u5728 GKE \u4e2d\u63d0\u4f9b\u5177\u6709\u591a\u500b GPU \u7684 LLM", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/serve-multiple-gpu?hl=zh-cn", "abstract": "# Google Kubernetes Engine (GKE) - \u5728 GKE \u4e2d\u63d0\u4f9b\u5177\u6709\u591a\u500b GPU \u7684 LLM\n\u672c\u6559\u7a0b\u4ecb\u7d39\u5982\u4f55\u5728 Google Kubernetes Engine (GKE) \u6a21\u5f0f\u4e0b\u63d0\u4f9b\u5e36\u6709 GPU \u7684\u5927\u578b\u8a9e\u8a00\u6a21\u578b (LLM)\u3002\u672c\u6559\u7a0b\u6703\u5275\u5efa\u4e00\u500b\u4f7f\u7528\u591a\u500b L4 GPU \u7684 GKE Standard \u96c6\u7fa3\uff0c\u4e26\u6e96\u5099 GKE \u57fa\u790e\u67b6\u69cb\u4ee5\u8655\u7406\u4ee5\u4e0b\u4efb\u4f55\u6a21\u578b\uff1a- [Falcon 40b](https://falconllm.tii.ae/falcon-40b.html) \u3002\n- [Llama 2 70b](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf) \n\u6839\u64da\u6a21\u578b\u7684\u6578\u64da\u683c\u5f0f\uff0cGPU \u7684\u6578\u91cf\u6703\u6709\u6240\u4e0d\u540c\u3002\u5728\u672c\u6559\u7a0b\u4e2d\uff0c\u6bcf\u500b\u6a21\u578b\u90fd\u4f7f\u7528\u5169\u500b L4 GPU\u3002\u5982\u9700\u77ad\u89e3\u8a73\u60c5\uff0c\u8acb\u53c3\u95b1 [\u8a08\u7b97 GPU \u7684\u6578\u91cf](#calculate-gpus) \u3002\n\u5728\u5b8c\u6210 GKE \u4e2d\u7684\u672c\u6559\u7a0b\u4e4b\u524d\uff0c\u6211\u5011\u5efa\u8b70\u60a8\u77ad\u89e3 [GKE \u4e2d\u7684 GPU \u7c21\u4ecb](https://cloud.google.com/kubernetes-engine/docs/concepts/gpus?hl=zh-cn) \u3002", "content": "## \u76ee\u6a19\u672c\u6559\u7a0b\u9069\u7528\u65bc\u5e0c\u671b\u4f7f\u7528 GKE \u7de8\u6392\u529f\u80fd\u4f86\u63d0\u4f9b LLM \u7684 MLOps \u6216 DevOps \u5de5\u7a0b\u5e2b\u6216\u5e73\u81fa\u7ba1\u7406\u54e1\u3002\n\u672c\u6559\u7a0b\u4ecb\u7d39\u4ee5\u4e0b\u6b65\u9a5f\uff1a- \u5275\u5efa\u96c6\u7fa3\u548c\u7bc0\u9ede\u6c60\u3002\n- \u6e96\u5099\u5de5\u4f5c\u8ca0\u8f09\u3002\n- \u90e8\u7f72\u5de5\u4f5c\u8ca0\u8f09\u3002\n- \u8207 LLM \u63a5\u53e3\u4ea4\u4e92\u3002\n## \u6e96\u5099\u5de5\u4f5c\n\u5728\u958b\u59cb\u4e4b\u524d\uff0c\u8acb\u78ba\u4fdd\u60a8\u5df2\u57f7\u884c\u4ee5\u4e0b\u4efb\u52d9\uff1a- \u5553\u7528 Google Kubernetes Engine API\u3002\n- [  \u5553\u7528 Google Kubernetes Engine API ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com&hl=zh-cn) \n- \u5982\u679c\u60a8\u8981\u4f7f\u7528 Google Cloud CLI \u57f7\u884c\u6b64\u4efb\u52d9\uff0c\u8acb [\u5b89\u88dd](https://cloud.google.com/sdk/docs/install?hl=zh-cn) \u4e26 [\u521d\u59cb\u5316](https://cloud.google.com/sdk/docs/initializing?hl=zh-cn) gcloud CLI\u3002 \u5982\u679c\u60a8\u4e4b\u524d\u5b89\u88dd\u4e86 gcloud CLI\uff0c\u8acb\u904b\u884c`gcloud components update`\u4ee5\u7372\u53d6\u6700\u65b0\u7248\u672c\u3002 **\u6ce8\u610f** \uff1a\u5c0d\u65bc\u73fe\u6709 gcloud CLI \u5b89\u88dd\uff0c\u8acb\u52d9\u5fc5\u8a2d\u7f6e`compute/region`\u548c`compute/zone` [\u5c6c\u6027](https://cloud.google.com/sdk/docs/properties?hl=zh-cn#setting_properties) \u3002\u901a\u904e\u8a2d\u7f6e\u9ed8\u8a8d\u4f4d\u7f6e\uff0c\u60a8\u53ef\u4ee5\u907f\u514d gcloud CLI \u4e2d\u51fa\u73fe\u4ee5\u4e0b\u932f\u8aa4\uff1a`One of [--zone, --region] must be supplied: Please specify location`\u3002\n- \u5982\u679c\u60a8\u60f3\u4f7f\u7528 Llama 2 70b \u6a21\u578b\uff0c\u8acb\u78ba\u4fdd\uff1a- \u64c1\u6709 [Meta Llama \u578b\u865f](https://huggingface.co/meta-llama/Llama-2-7b-hf) \u7684\u8a2a\u554f\u6b0a\u9650\u548c\u6709\u6548\u7684\u8a31\u53ef\u3002\n- [HuggingFace \u4ee4\u724c](https://huggingface.co/docs/hub/security-tokens) \u3002\n **\u8b66\u544a** \uff1a\u7372\u53d6 Llama \u6a21\u578b\u7684\u8a2a\u554f\u6b0a\u9650\u548c\u6279\u51c6\u6700\u591a\u53ef\u80fd\u9700\u8981\u4e09\u5929\u7684\u6642\u9593\u3002\n## \u6e96\u5099\u74b0\u5883\n- \u5728 Google Cloud \u63a7\u5236\u6aaf\u4e2d\uff0c\u5553\u52d5 Cloud Shell \u5be6\u4f8b\uff1a  [\u6253\u958b Cloud Shell](https://console.cloud.google.com/?cloudshell=true&hl=zh-cn) \n- \u8a2d\u7f6e\u9ed8\u8a8d\u74b0\u5883\u8b8a\u91cf\uff1a```\ngcloud config set project PROJECT_IDexport PROJECT_ID=$(gcloud config get project)export REGION=us-central1\n```\u5c07 \u66ff\u63db\u7232\u60a8\u7684 Google Cloud [\u9805\u76ee ID](https://cloud.google.com/resource-manager/docs/creating-managing-projects?hl=zh-cn#identifying_projects) \u3002 **\u6ce8\u610f** \uff1a\u5982\u679c\u60a8\u7684 Cloud Shell \u5be6\u4f8b\u5728\u6574\u500b\u6559\u7a0b\u57f7\u884c\u671f\u9593\u65b7\u958b\u9023\u63a5\uff0c\u8acb\u91cd\u8907\u4e0a\u8ff0\u6b65\u9a5f\u3002\n### \u5275\u5efa GKE Standard \u96c6\u7fa3\u548c GPU \u7bc0\u9ede\u6c60\u4f7f\u7528 Cloud Shell \u57f7\u884c\u4ee5\u4e0b\u64cd\u4f5c\uff1a- \u5275\u5efa\u4f7f\u7528 [\u9069\u7528\u65bc GKE \u7684\u5de5\u4f5c\u8ca0\u8f09\u8eab\u4efd\u806f\u5408](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity?hl=zh-cn) \u7684 Standard \u96c6\u7fa3\uff1a```\ngcloud container clusters create l4-demo --location ${REGION} \\\u00a0 --workload-pool ${PROJECT_ID}.svc.id.goog \\\u00a0 --enable-image-streaming \\\u00a0 --node-locations=$REGION-a \\\u00a0 --workload-pool=${PROJECT_ID}.svc.id.goog \\\u00a0 --addons GcsFuseCsiDriver \u00a0 \\\u00a0 --machine-type n2d-standard-4 \\\u00a0 --num-nodes 1 --min-nodes 1 --max-nodes 5 \\\u00a0 --ephemeral-storage-local-ssd=count=2\n``` **\u6ce8\u610f\uff1a** \u53ef\u80fd\u5fc5\u9808\u6839\u64da\u60a8\u9078\u64c7\u7684\u5340\u57df\u8abf\u6574 `--node-locations` \u6a19\u8a8c\u3002\u5982\u679c\u60a8\u66f4\u6539 `us-central1` \u5340\u57df\uff0c\u8acb\u6aa2\u67e5 [L4 GPU \u7684\u53ef\u7528\u5340](https://cloud.google.com/compute/docs/gpus?hl=zh-cn#nvidia_l4_vws_gpus) \u53ef\u7528\u3002\n- \u5275\u5efa GPU \u7bc0\u9ede\u6c60\uff1a```\ngcloud container node-pools create g2-standard-24 --cluster l4-demo \\\u00a0 --accelerator type=nvidia-l4,count=2,gpu-driver-version=latest \\\u00a0 --machine-type g2-standard-24 \\\u00a0 --ephemeral-storage-local-ssd=count=2 \\\u00a0 --enable-autoscaling --enable-image-streaming \\\u00a0 --num-nodes=0 --min-nodes=0 --max-nodes=3 \\\u00a0 --node-locations $REGION-a,$REGION-c --region $REGION --spot\n```GKE \u6703\u7232 LLM \u5275\u5efa\u4ee5\u4e0b\u8cc7\u6e90\uff1a- \u516c\u5171 Google Kubernetes Engine (GKE) \u6a19\u6e96\u7248\u96c6\u7fa3\u3002\n- \u5169\u500b\u904b\u884c`g2-standard-24`\u6a5f\u5668\u7684\u7bc0\u9ede\u3002\n- \u7e2e\u6e1b\u7232 0 \u500b\u7bc0\u9ede\u7684\u7bc0\u9ede\u6c60\u3002\u5728\u958b\u59cb\u767c\u4f48\u8acb\u6c42 GPU \u7684 Kubernetes Pod \u4e4b\u524d\uff0c\u60a8\u7121\u9700\u7232\u4efb\u4f55 GPU \u4ed8\u8cbb\u3002\u6b64\u7bc0\u9ede\u6c60\u9810\u914d [Spot \u865b\u64ec\u6a5f](https://cloud.google.com/kubernetes-engine/docs/how-to/spot-vms?hl=zh-cn) \uff0c\u5176\u50f9\u683c\u4f4e\u65bc\u9ed8\u8a8d\u6a19\u6e96 Compute Engine \u865b\u64ec\u6a5f\uff0c\u4f46\u4e0d\u4fdd\u8b49\u53ef\u7528\u6027\u3002\u60a8\u53ef\u4ee5\u5f9e\u6b64\u547d\u4ee4\u4e2d\u79fb\u9664`--spot`\u6a19\u8a8c\uff0c\u4e26\u79fb\u9664`text-generation-inference.yaml`\u914d\u7f6e\u4e2d\u7684`cloud.google.com/gke-spot`\u7bc0\u9ede\u9078\u64c7\u5668\uff0c\u4ee5\u4f7f\u7528\u6309\u9700\u865b\u64ec\u6a5f\u3002\n- \u914d\u7f6e `kubectl` \u4ee5\u8207\u60a8\u7684\u96c6\u7fa3\u901a\u4fe1\uff1a```\ngcloud container clusters get-credentials l4-demo --region=${REGION}\n```\n## \u6e96\u5099\u5de5\u4f5c\u8ca0\u8f09\u4ee5\u4e0b\u90e8\u5206\u4ecb\u7d39\u5982\u4f55\u6839\u64da\u8981\u4f7f\u7528\u7684\u6a21\u578b\u8a2d\u7f6e\u5de5\u4f5c\u8ca0\u8f09\uff1a\n- \u5275\u5efa\u4ee5\u4e0b`text-generation-inference.yaml`\u6e05\u55ae\uff1a\n [  ai-ml/llm-multiple-gpus/falcon-40b/text-generation-inference.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/falcon-40b/text-generation-inference.yaml) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/falcon-40b/text-generation-inference.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: llmspec:\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: llm\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: llm\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: llm\u00a0 \u00a0 \u00a0 \u00a0 image: ghcr.io/huggingface/text-generation-inference:1.4.3\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"10\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"60Gi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: \"2\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"10\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"60Gi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: \"2\"\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: MODEL_ID\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: tiiuae/falcon-40b-instruct\u00a0 \u00a0 \u00a0 \u00a0 - name: NUM_SHARD\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"2\"\u00a0 \u00a0 \u00a0 \u00a0 - name: PORT\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"8080\"\u00a0 \u00a0 \u00a0 \u00a0 - name: QUANTIZE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: bitsandbytes-nf4\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - mountPath: /dev/shm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: dshm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - mountPath: /data\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: ephemeral-volume\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 \u00a0 - name: dshm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 emptyDir:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 medium: Memory\u00a0 \u00a0 \u00a0 \u00a0 - name: ephemeral-volume\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 volumeClaimTemplate:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type: ephemeral\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 accessModes: [\"ReadWriteOnce\"]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storageClassName: \"premium-rwo\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storage: 175Gi\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-accelerator: \"nvidia-l4\"\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-spot: \"true\"\n```\n\u5728\u6b64\u6e05\u55ae\u4e2d\uff1a- `NUM_SHARD`\u5fc5\u9808\u7232`2`\uff0c\u56e0\u7232\u8a72\u6a21\u578b\u9700\u8981\u5169\u500b NVIDIA L4 GPU\u3002\u5426\u5247\uff0cGKE \u50c5\u9810\u914d\u4e00\u500b GPU\u3002\n- `QUANTIZE`\u8a2d\u7f6e\u7232`bitsandbytes-nf4`\uff0c\u8868\u793a\u6a21\u578b\u4ee5 4 \u4f4d\uff08\u800c\u975e 32 \u4f4d\uff09\u5f62\u5f0f\u52a0\u8f09\u3002\u9019\u4f7f GKE \u53ef\u4ee5\u6e1b\u5c11\u6240\u9700\u7684 GPU \u5167\u5b58\u91cf\uff0c\u4e26\u63d0\u9ad8\u63a8\u65b7\u901f\u5ea6\u3002\u4f46\u662f\uff0c\u6a21\u578b\u6e96\u78ba\u7387\u53ef\u80fd\u6703\u964d\u4f4e\u3002\u5982\u9700\u77ad\u89e3\u5982\u4f55\u8a08\u7b97\u8981\u8acb\u6c42\u7684 GPU\uff0c\u8acb\u53c3\u95b1 [\u8a08\u7b97 GPU \u6578\u91cf](#calculate-gpus) \u3002\n- \u61c9\u7528\u6e05\u55ae\uff1a```\nkubectl apply -f text-generation-inference.yaml\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\ndeployment.apps/llm created\n```\n- \u9a57\u8b49\u6a21\u578b\u7684\u72c0\u614b\uff1a```\nwatch kubectl get deploy\n```\u90e8\u7f72\u6e96\u5099\u5c31\u7dd2\u5f8c\uff0c\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\u3002\u5982\u9700\u9000\u51fa\u76e3\u63a7\uff0c\u8acb\u6309 `CTRL + C` \u3002```\nNAME   READY UP-TO-DATE AVAILABLE AGE\nllm   1/1  1   1   10m\n```\n- \u67e5\u770b\u6b63\u5728\u904b\u884c\u7684\u90e8\u7f72\u4e2d\u7684\u65e5\u8a8c\uff1a```\nkubectl logs -l app=llm\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n{\"timestamp\":\"2023-10-19T00:10:22.206703Z\",\"level\":\"INFO\",\"fields\":{\"message\":\"Waiting\nfor shard to be\nready...\"},\"target\":\"text_generation_launcher\",\"span\":{\"rank\":0,\"name\":\"shard-manager\"},\"spans\":[{\"rank\":0,\"name\":\"shard-manager\"}]}\n{\"timestamp\":\"2023-10-19T00:10:22.206725Z\",\"level\":\"INFO\",\"fields\":{\"message\":\"Waiting\nfor shard to be\nready...\"},\"target\":\"text_generation_launcher\",\"span\":{\"rank\":1,\"name\":\"shard-manager\"},\"spans\":[{\"rank\":1,\"name\":\"shard-manager\"}]}\n```\n- \u8a2d\u7f6e\u9ed8\u8a8d\u74b0\u5883\u8b8a\u91cf\uff1a```\nexport HF_TOKEN=HUGGING_FACE_TOKEN\n```\u5c07 `` \u66ff\u63db\u7232\u60a8\u7684 HuggingFace \u4ee4\u724c\u3002\n- \u7232 HuggingFace \u4ee4\u724c\u5275\u5efa [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/) \uff1a```\nkubectl create secret generic l4-demo \\\u00a0 \u00a0 --from-literal=HUGGING_FACE_TOKEN=${HF_TOKEN} \\\u00a0 \u00a0 --dry-run=client -o yaml > hf-secret.yaml\n```\n- \u61c9\u7528\u6e05\u55ae\uff1a```\nkubectl apply -f hf-secret.yaml\n```\n- \u5275\u5efa\u4ee5\u4e0b `text-generation-inference.yaml` \u6e05\u55ae\uff1a [  ai-ml/llm-multiple-gpus/llama2-70b/text-generation-inference.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/llama2-70b/text-generation-inference.yaml) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/llama2-70b/text-generation-inference.yaml) ```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: llmspec:\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: llm\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: llm\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: llm\u00a0 \u00a0 \u00a0 \u00a0 image: ghcr.io/huggingface/text-generation-inference:1.4.3\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"10\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"60Gi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: \"2\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"10\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"60Gi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 nvidia.com/gpu: \"2\"\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: MODEL_ID\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: meta-llama/Llama-2-70b-chat-hf\u00a0 \u00a0 \u00a0 \u00a0 - name: NUM_SHARD\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"2\"\u00a0 \u00a0 \u00a0 \u00a0 - name: PORT\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"8080\"\u00a0 \u00a0 \u00a0 \u00a0 - name: QUANTIZE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: bitsandbytes-nf4\u00a0 \u00a0 \u00a0 \u00a0 - name: HUGGING_FACE_HUB_TOKEN\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 valueFrom:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 secretKeyRef:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: l4-demo\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 key: HUGGING_FACE_TOKEN\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - mountPath: /dev/shm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: dshm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 - mountPath: /data\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name: ephemeral-volume\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 \u00a0 - name: dshm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 emptyDir:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 medium: Memory\u00a0 \u00a0 \u00a0 \u00a0 - name: ephemeral-volume\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ephemeral:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 volumeClaimTemplate:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 type: ephemeral\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 accessModes: [\"ReadWriteOnce\"]\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storageClassName: \"premium-rwo\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 storage: 150Gi\u00a0 \u00a0 \u00a0 nodeSelector:\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-accelerator: \"nvidia-l4\"\u00a0 \u00a0 \u00a0 \u00a0 cloud.google.com/gke-spot: \"true\"\n```\u5728\u6b64\u6e05\u55ae\u4e2d\uff1a- `NUM_SHARD`\u5fc5\u9808\u7232`2`\uff0c\u56e0\u7232\u8a72\u6a21\u578b\u9700\u8981\u5169\u500b NVIDIA L4 GPU\u3002\u5426\u5247\uff0cGKE \u50c5\u9810\u914d\u4e00\u500b GPU\u3002\n- `QUANTIZE`\u8a2d\u7f6e\u7232`bitsandbytes-nf4`\uff0c\u8868\u793a\u6a21\u578b\u4ee5 4 \u4f4d\uff08\u800c\u975e 32 \u4f4d\uff09\u5f62\u5f0f\u52a0\u8f09\u3002\u9019\u4f7f GKE \u53ef\u4ee5\u6e1b\u5c11\u6240\u9700\u7684 GPU \u5167\u5b58\u91cf\uff0c\u4e26\u63d0\u9ad8\u63a8\u65b7\u901f\u5ea6\u3002\u4f46\u662f\uff0c\u6a21\u578b\u6e96\u78ba\u7387\u53ef\u80fd\u6703\u964d\u4f4e\u3002\u5982\u9700\u77ad\u89e3\u5982\u4f55\u8a08\u7b97\u8981\u8acb\u6c42\u7684 GPU\uff0c\u8acb\u53c3\u95b1 [\u8a08\u7b97 GPU \u7684\u6578\u91cf](#calculate-gpus) \u3002\n- \u61c9\u7528\u6e05\u55ae\uff1a```\nkubectl apply -f text-generation-inference.yaml\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\ndeployment.apps/llm created\n```\n- \u9a57\u8b49\u6a21\u578b\u7684\u72c0\u614b\uff1a```\nkubectl get deploy\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\nNAME   READY UP-TO-DATE AVAILABLE AGE\nllm   1/1  1   1   20m\n```\n- \u67e5\u770b\u6b63\u5728\u904b\u884c\u7684\u90e8\u7f72\u4e2d\u7684\u65e5\u8a8c\uff1a```\nkubectl logs -l app=llm\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\n{\"timestamp\":\"2023-10-19T00:10:22.206703Z\",\"level\":\"INFO\",\"fields\":{\"message\":\"Waiting for shard to be ready...\"},\"target\":\"text_generation_launcher\",\"span\":{\"rank\":0,\"name\":\"shard-manager\"},\"spans\":[{\"rank\":0,\"name\":\"shard-manager\"}]}\n{\"timestamp\":\"2023-10-19T00:10:22.206725Z\",\"level\":\"INFO\",\"fields\":{\"message\":\"Waiting for shard to be ready...\"},\"target\":\"text_generation_launcher\",\"span\":{\"rank\":1,\"name\":\"shard-manager\"},\"spans\":[{\"rank\":1,\"name\":\"shard-manager\"}]}\n```### \u5275\u5efa ClusterIP \u985e\u578b\u7684 Service\n- \u5275\u5efa\u4ee5\u4e0b `llm-service.yaml` \u6e05\u55ae\uff1a```\napiVersion: v1kind: Servicemetadata:\u00a0 name: llm-servicespec:\u00a0 selector:\u00a0 \u00a0 app: llm\u00a0 type: ClusterIP\u00a0 ports:\u00a0 \u00a0 - protocol: TCP\u00a0 \u00a0 \u00a0 port: 80\u00a0 \u00a0 \u00a0 targetPort: 8080\n```\n- \u61c9\u7528\u6e05\u55ae\uff1a```\nkubectl apply -f llm-service.yaml\n```\n### \u90e8\u7f72\u804a\u5929\u754c\u9762\u4f7f\u7528 [G \u55ae\u9078\u6309\u9215](https://www.gradio.app/docs/interface) \u69cb\u5efa\u4e00\u500b Web \u61c9\u7528\uff0c\u4ee5\u4fbf\u60a8\u8207\u6a21\u578b\u9032\u884c\u4ea4\u4e92\u3002G \u55ae\u9078\u6309\u9215\u662f\u4e00\u500b Python \u5eab\uff0c\u5b83\u6709\u4e00\u500b ChatInterface \u5c01\u88dd\u5bb9\u5668\uff0c\u7528\u65bc\u7232\u804a\u5929\u6a5f\u5668\u4eba\u5275\u5efa\u754c\u9762\u3002\n- \u5275\u5efa\u4e00\u500b\u540d\u7232 `gradio.yaml` \u7684\u6587\u4ef6\uff1a [  ai-ml/llm-multiple-gpus/falcon-40b/gradio.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/falcon-40b/gradio.yaml) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/falcon-40b/gradio.yaml) ```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: gradio\u00a0 labels:\u00a0 \u00a0 app: gradiospec:\u00a0 strategy:\u00a0 \u00a0 type: Recreate\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: gradio\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: gradio\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: gradio\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/gradio-app:v1.0.0\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"512m\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"1\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: CONTEXT_PATH\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"/generate\"\u00a0 \u00a0 \u00a0 \u00a0 - name: HOST\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"http://llm-service\"\u00a0 \u00a0 \u00a0 \u00a0 - name: LLM_ENGINE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"tgi\"\u00a0 \u00a0 \u00a0 \u00a0 - name: MODEL_ID\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"falcon-40b-instruct\"\u00a0 \u00a0 \u00a0 \u00a0 - name: USER_PROMPT\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"User: prompt\"\u00a0 \u00a0 \u00a0 \u00a0 - name: SYSTEM_PROMPT\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"Assistant: prompt\"\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 7860---apiVersion: v1kind: Servicemetadata:\u00a0 name: gradio-servicespec:\u00a0 type: LoadBalancer\u00a0 selector:\u00a0 \u00a0 app: gradio\u00a0 ports:\u00a0 - port: 80\u00a0 \u00a0 targetPort: 7860\n```\n- \u61c9\u7528\u6e05\u55ae\uff1a```\nkubectl apply -f gradio.yaml\n```\n- \u627e\u5230 Service \u7684\u5916\u90e8 IP \u5730\u5740\uff1a```\nkubectl get svc\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\nNAME    TYPE   CLUSTER-IP  EXTERNAL-IP  PORT(S)  AGE\ngradio-service LoadBalancer 10.24.29.197 34.172.115.35 80:30952/TCP 125m\n```\n- \u5f9e `EXTERNAL-IP` \u5217\u4e2d\u8907\u88fd\u5916\u90e8 IP \u5730\u5740\u3002\n- \u5728\u60a8\u7684\u7db2\u7d61\u700f\u89bd\u5668\u4e2d\u4f7f\u7528\u5916\u90e8 IP \u5730\u5740\u53ca\u516c\u958b\u7684\u7aef\u53e3\u67e5\u770b\u6a21\u578b\u754c\u9762\uff1a```\nhttp://EXTERNAL_IP\n```\n- \u5275\u5efa\u4e00\u500b\u540d\u7232 `gradio.yaml` \u7684\u6587\u4ef6\uff1a [  ai-ml/llm-multiple-gpus/llama2-70b/gradio.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/llama2-70b/gradio.yaml) [\u5728 GitHub \u4e0a\u67e5\u770b](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/ai-ml/llm-multiple-gpus/llama2-70b/gradio.yaml) ```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: gradio\u00a0 labels:\u00a0 \u00a0 app: gradiospec:\u00a0 strategy:\u00a0 \u00a0 type: Recreate\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: gradio\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: gradio\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: gradio\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/gradio-app:v1.0.0\u00a0 \u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"512m\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 limits:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 cpu: \"1\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 memory: \"512Mi\"\u00a0 \u00a0 \u00a0 \u00a0 env:\u00a0 \u00a0 \u00a0 \u00a0 - name: CONTEXT_PATH\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"/generate\"\u00a0 \u00a0 \u00a0 \u00a0 - name: HOST\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"http://llm-service\"\u00a0 \u00a0 \u00a0 \u00a0 - name: LLM_ENGINE\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"tgi\"\u00a0 \u00a0 \u00a0 \u00a0 - name: MODEL_ID\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"llama-2-70b\"\u00a0 \u00a0 \u00a0 \u00a0 - name: USER_PROMPT\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"[INST] prompt [/INST]\"\u00a0 \u00a0 \u00a0 \u00a0 - name: SYSTEM_PROMPT\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 value: \"prompt\"\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 7860---apiVersion: v1kind: Servicemetadata:\u00a0 name: gradio-servicespec:\u00a0 type: LoadBalancer\u00a0 selector:\u00a0 \u00a0 app: gradio\u00a0 ports:\u00a0 - port: 80\u00a0 \u00a0 targetPort: 7860\n```\n- \u61c9\u7528\u6e05\u55ae\uff1a```\nkubectl apply -f gradio.yaml\n```\n- \u627e\u5230 Service \u7684\u5916\u90e8 IP \u5730\u5740\uff1a```\nkubectl get svc\n```\u8f38\u51fa\u985e\u4f3c\u65bc\u4ee5\u4e0b\u5167\u5bb9\uff1a```\nNAME    TYPE   CLUSTER-IP  EXTERNAL-IP  PORT(S)  AGE\ngradio-service LoadBalancer 10.24.29.197 34.172.115.35 80:30952/TCP 125m\n```\n- \u5f9e `EXTERNAL-IP` \u5217\u4e2d\u8907\u88fd\u5916\u90e8 IP \u5730\u5740\u3002\n- \u5728\u60a8\u7684\u7db2\u7d61\u700f\u89bd\u5668\u4e2d\u4f7f\u7528\u5916\u90e8 IP \u5730\u5740\u53ca\u516c\u958b\u7684\u7aef\u53e3\u67e5\u770b\u6a21\u578b\u754c\u9762\uff1a```\nhttp://EXTERNAL_IP\n``` **\u6210\u529f** \uff1a\u6b64\u6642\uff0c\u60a8\u5df2\u5728 GKE \u4e2d\u4f7f\u7528 L4 GPU \u90e8\u7f72\u4e86 LLM\u3002## \u8a08\u7b97 GPU \u7684\u6578\u91cfGPU \u7684\u6578\u91cf\u53d6\u6c7a\u65bc `QUANTIZE` \u6a19\u8a8c\u7684\u503c\u3002\u5728\u672c\u6559\u7a0b\u4e2d\uff0c `QUANTIZE` \u8a2d\u7f6e\u7232 `bitsandbytes-nf4` \uff0c\u9019\u610f\u5473\u7740\u6a21\u578b\u4ee5 4 \u4f4d\u7232\u55ae\u4f4d\u52a0\u8f09\u3002\n700 \u5104\u500b\u53c3\u6578\u6a21\u578b\u9700\u8981\u81f3\u5c11 40 GB \u7684 GPU \u5167\u5b58\uff0c\u7b49\u65bc 700 \u5104\u6b21 4 \u4f4d\uff08700 x 4 \u4f4d= 35 GB\uff09\u4e14\u6703\u88ab\u8996\u7232 5 GB \u7684\u958b\u92b7\u3002\u5728\u9019\u7a2e\u60c5\u6cc1\u4e0b\uff0c\u55ae\u500b L4 GPU \u6c92\u6709\u8db3\u5920\u7684\u5167\u5b58\u3002\u56e0\u6b64\uff0c\u672c\u6559\u7a0b\u4e2d\u7684\u793a\u4f8b\u4f7f\u7528\u5169\u500b L4 GPU \u5167\u5b58 (2 x 24 = 48 GB)\u3002\u6b64\u914d\u7f6e\u8db3\u4ee5\u5728 L4 GPU \u4e2d\u904b\u884c Falcon 40b \u6216 Llama 2 70b\u3002## \u6e05\u7406\u7232\u907f\u514d\u56e0\u672c\u6559\u7a0b\u4e2d\u4f7f\u7528\u7684\u8cc7\u6e90\u5c0e\u81f4\u60a8\u7684 Google Cloud \u8cec\u865f\u7522\u751f\u8cbb\u7528\uff0c\u8acb\u522a\u9664\u5305\u542b\u9019\u4e9b\u8cc7\u6e90\u7684\u9805\u76ee\uff0c\u6216\u8005\u4fdd\u7559\u9805\u76ee\u4f46\u522a\u9664\u5404\u500b\u8cc7\u6e90\u3002\n### \u522a\u9664\u96c6\u7fa3\u7232\u907f\u514d\u7cfb\u7d71\u56e0\u672c\u6307\u5357\u4e2d\u5275\u5efa\u7684\u8cc7\u6e90\u5411\u60a8\u7684 Google Cloud \u8cec\u865f\u6536\u53d6\u8cbb\u7528\uff0c\u8acb\u522a\u9664 GKE \u96c6\u7fa3\uff1a\n```\ngcloud container clusters delete l4-demo --region ${REGION}\n```## \u5f8c\u7e8c\u6b65\u9a5f\n- [\u8a73\u7d30\u77ad\u89e3\u914d\u5099 NVIDIA L4 GPU \u7684 G2 \u865b\u64ec\u6a5f](https://cloud.google.com/blog/products/compute/introducing-g2-vms-with-nvidia-l4-gpus?hl=zh-cn) \n- [\u5728 GKE Standard \u6a21\u5f0f\u4e0b\u4f7f\u7528 GPU \u8a13\u7df4\u6a21\u578b](https://cloud.google.com/kubernetes-engine/docs/quickstarts/train-model-gpus-standard?hl=zh-cn)", "guide": "Google Kubernetes Engine (GKE)"}