{"title": "Google Kubernetes Engine (GKE) - Migrating containers to Google Cloud: Migrating to a multi-cluster GKE environment with Multi Cluster Ingress and Multi-Cluster Service Discovery", "url": "https://cloud.google.com/kubernetes-engine/docs/archive/migrating-containers-multi-cluster-gke-ingress-services?hl=zh-cn", "abstract": "# Google Kubernetes Engine (GKE) - Migrating containers to Google Cloud: Migrating to a multi-cluster GKE environment with Multi Cluster Ingress and Multi-Cluster Service Discovery\nLast reviewed 2021-08-12 UTC\n**Warning:** This page is **archived** and is not actively maintained. The commands on this page might not work and could cause disruptions to your cluster.\nThis document describes how to migrate from a single-cluster [Google Kubernetes Engine (GKE)](/kubernetes-engine) environment to a multi-cluster GKE environment with minimal downtime. The multi-cluster GKE environment uses the following:- [Multi Cluster Ingress](/kubernetes-engine/docs/concepts/multi-cluster-ingress) to expose workloads outside clusters.\n- [Multi-Cluster Service Discovery](/kubernetes-engine/docs/concepts/multi-cluster-services) to expose workloads across clusters.\n **Note:** This document describes a migration approach that uses Multi Cluster Ingress. For new migration projects, we recommend that you use multi-cluster Gateways and Multi-Cluster Service Discovery to [migrate to multi-cluster networking with Google Kubernetes Engine Autopilot and Standard](/kubernetes-engine/docs/how-to/migrate-gke-multi-cluster) .\nThis document is useful if you're planning to migrate from a single-cluster environment to a multi-cluster environment with minimal downtime. This document is also useful if you're evaluating the opportunity to migrate and want to explore what it might look like.\nA multi-cluster environment can help to mitigate scalability issues and service disruptions that are caused by single points of failure. When you use Multi Cluster Ingress and Multi-Cluster Service Discovery, you can deploy multiple instances of your workloads and transparently expose them to clients that are outside the cluster or that are running in other clusters in the multi-cluster environment.\nThis tutorial assumes that you're familiar with the following:- [Kubernetes](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/) \n- GKE\n- Multi Cluster Ingress\n- Multi-Cluster Service Discovery\nIn this tutorial, you use the following software:- [Terraform](https://www.terraform.io/) : a tool to provision resources in cloud environments.\nYou perform most of the steps for this tutorial in [Cloud Shell](/shell) .", "content": "## Objectives\n- Provision a GKE cluster to simulate the source environment.\n- Provision multiple GKE clusters to simulate the target environment.\n- Deploy the example workloads that are provided in this tutorial.\n- Configure Multi-Cluster Service Discovery and Multi Cluster Ingress.\n- Expose the example workloads with Multi Cluster Ingress.\n- Deploy and use Multi-Cluster Service Discovery.\n- Switch traffic to the target environment.\n- Decommission the source environment.\n## CostsIn this document, you use the following billable components of Google Cloud:- [GKE](/kubernetes-engine/pricing) \n- [Compute Engine](/compute/all-pricing) for [GKE worker nodes](/kubernetes-engine/docs/concepts/cluster-architecture#nodes) \n- [Cloud Load Balancing](/vpc/network-pricing#lb) \n- [Virtual Private Cloud external static IP addresses](/vpc/network-pricing#ipaddress) \n- [Multi Cluster Ingress](/kubernetes-engine/docs/concepts/multi-cluster-ingress#pricing_and_trials) \n- [Cloud DNS](/vpc/network-pricing#dns-pricing) \n- [Cloud Storage](/storage/pricing) \nTo generate a cost estimate based on your projected usage,  use the [pricing calculator](/products/calculator) . ## Before you beginTo complete the steps in this tutorial, you need the following:- A Google Cloud [organization](/resource-manager/docs/cloud-platform-resource-hierarchy#organizations) in which you have the following Identity and Access Management (IAM) roles:- [Project Creator role](/iam/docs/understanding-roles#resource-manager-roles) (`roles/resourcemanager.projectCreator`)\n- [Billing Account Administrator role](/iam/docs/understanding-roles#billing-roles) (`roles/billing.admin`).\n- An active [billing account](/billing/docs/how-to/manage-billing-account) .\nYou can create a new organization and a new billing account, or you can use an existing organization and billing account. In this tutorial, you run scripts to create two [Google Cloud projects](/resource-manager/docs/cloud-platform-resource-hierarchy#projects) .## Preparing your environment\n- In the Google Cloud console, activate Cloud Shell. [Activate Cloud Shell](https://console.cloud.google.com/?cloudshell=true) At the bottom of the Google Cloud console, a [Cloud Shell](/shell/docs/how-cloud-shell-works) session starts and displays a command-line prompt. Cloud Shell is a shell environment  with the Google Cloud CLI  already installed and with values already set for  your current project. It can take a few seconds for the session to initialize.\n- Change the working directory to the home directory:```\ncd \"${HOME}\"\n```\n- Clone the GitHub repository:```\ngit clone https://github.com/GoogleCloudPlatform/solutions-multicluster-gke-migration.git\n```The repository contains the scripts and the manifest files to deploy and configure the demo workloads.\n- Authenticate your user account with [Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials) :```\ngcloud auth application-default login\n```The output is similar to the following, which shows the path to the Application Default Credentials file:```\nCredentials saved to file:\n[/tmp/tmp.T5Qae7XwAO/application_default_credentials.json]\nThese credentials will be used by any library that requests Application Default Credentials (ADC).\n```Make a note of the path to the Application Default Credentials file. You use it in the next step.\n- Set the following environment variables:```\nAPPLICATION_DEFAULT_CREDENTIALS_PATH=ADC_PATHBILLING_ACCOUNT_ID=BILLING_ACCOUNT_IDDEFAULT_PROJECT=DEFAULT_PROJECTDEFAULT_REGION=DEFAULT_REGIONDEFAULT_ZONE=DEFAULT_ZONEGOOGLE_APPLICATION_CREDENTIALS=\"${APPLICATION_DEFAULT_CREDENTIALS_PATH}\"MCI_MCS_TUTORIAL_DIRECTORY_PATH=\"$(pwd)\"/solutions-multicluster-gke-migrationORGANIZATION_ID=ORGANIZATION_IDTERRAFORM_STATE_PROJECT=TERRAFORM_STATE_PROJECTexport GOOGLE_APPLICATION_CREDENTIALS\n```Replace the following:- ``: the path to the Application Default Credentials file that you noted in the previous step.\n- `` : the ID of the billing account that you want to use. To get a list of billing account IDs, run the following:```\ngcloud beta billing accounts list --filter=open=true\n```\n- `` : the [Google Cloud project ID](/resource-manager/docs/creating-managing-projects#before_you_begin) that you want to use to provision the resources for this tutorial. You run a Terraform script later to create this project.\n- `` : the default [region](/compute/docs/regions-zones) in which to provision resources.\n- `` : the default [zone](/compute/docs/regions-zones) in which to provision resources.\n- `` : the ID of your Google Cloud organization. To find your organization ID, run the following:```\ngcloud organizations list\n```\n- `` : the Google Cloud project ID that you want to use to store the [Terraform state](https://www.terraform.io/docs/language/state/index.html) information. You run an initialization script later to create this project. For this tutorial, the project `TERRAFORM_STATE_PROJECT` must be different from the project `DEFAULT_PROJECT` , but both projects must be in the same organization.## The example workloadIn this tutorial, you use the [Bookinfo](https://istio.io/docs/examples/bookinfo/) app, which is a 4-tier, [polyglot](https://wikipedia.org/wiki/Polyglot_(computing)) microservices app that shows information about books. Although this example workload is already containerized, the approach described in this document series also applies to non-containerized services. In such cases, you can add a during which you containerize the services that you intend to migrate.\nThe Bookinfo app has the following microservice components:- `productpage`: Calls the`details`,`ratings`, and`reviews`microservices to populate the book information page.\n- `details`: Serves information about books.\n- `reviews`: Contains book reviews.\n- `ratings`: Returns book ranking information to accompany a book review.\n **Note:** To demonstrate Istio and its features, the authors and maintainers of the Bookinfo app implemented multiple versions of some of these components. In this tutorial, you deploy only one version of each component.## Provisioning the source and target environmentsIn this section, you use Terraform to automatically provision the source and target environments. By using Terraform to apply the proposed changes, you automate the following tasks:- [Create a Google Cloud project](/resource-manager/docs/creating-managing-projects#creating_a_project) in your Google Cloud organization.\n- [Enable the necessary Cloud APIs](/endpoints/docs/openapi/enable-api) .\n- [Provision three regional GKE clusters](/kubernetes-engine/docs/how-to/creating-a-regional-cluster) to simulate source and target environments. To provision the GKE clusters, Terraform uses the [kubernetes-engine Terraform module](https://registry.terraform.io/modules/terraform-google-modules/kubernetes-engine) .\n- [Configure Workload Identity](/kubernetes-engine/docs/how-to/workload-identity) for the GKE clusters.\n- [Register the GKE clusters as part of the multi-cluster fleet](/anthos/multicluster-management/connect/registering-a-cluster) .\nTo apply the proposed changes, do the following:- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Initialize the Terraform backend configuration:```\nscripts/init-terraform.sh \\\u00a0 --application-credentials \"${APPLICATION_DEFAULT_CREDENTIALS_PATH}\" \\\u00a0 --billing-account-id \"${BILLING_ACCOUNT_ID}\" \\\u00a0 --default-project \"${DEFAULT_PROJECT}\" \\\u00a0 --default-region \"${DEFAULT_REGION}\" \\\u00a0 --default-zone \"${DEFAULT_ZONE}\" \\\u00a0 --organization-id \"${ORGANIZATION_ID}\" \\\u00a0 --terraform-state-project \"${TERRAFORM_STATE_PROJECT}\"\n```The `init-terraform.sh` script does the following:- Creates a project and a [Cloud Storage bucket](/storage/docs/buckets) to store the Terraform state information.\n- Generates the descriptors to configure Terraform to use that bucket as a [remote backend](https://www.terraform.io/docs/language/settings/backends/index.html) .\n- Initializes the Terraform working directory.\n- Change the working directory to the `terraform` directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"/terraform\n```\n- Use Terraform to apply the changes:```\nterraform apply\n```When prompted, review the proposed changes. To confirm, enter `yes` .The output is similar to the following, which shows details about the resource that Terraform created:```\nApply complete! Resources: 60 added, 0 changed, 0 destroyed\n```\nThe following diagram shows the target architecture of the system for this section, with `DEFAULT_REGION` set to `us-central1` : \nThe preceding diagram shows the following GKE clusters in the default region:- `source-cluster-1`: the source environment\n- `target-cluster-1`and`target-cluster-2`: the target environment.\nThe GKE clusters don't host any workload, and they are ready for the deployment of the workload to be migrated.## Deploying the example workload in the source environmentIn this section, you deploy the example workload in the source environment. The example workload simulates a workload that you migrate to the target environment.- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Deploy the example workload in the source environment and use [GKE Ingress](/kubernetes-engine/docs/concepts/ingress) to expose the workload outside the cluster:```\nscripts/workloads.sh \\\u00a0 --cluster-name source-cluster-1 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --expose-with GKE_INGRESS\n```\n- Confirm that the [Pods](https://kubernetes.io/docs/concepts/workloads/pods/) of the example workload are ready:```\nkubectl get pods --namespace bookinfo\n```The output is similar to the following. When all Pods are ready, the `STATUS` field shows `RUNNING` :```\nNAME        READY STATUS RESTARTS AGE\ndetails-v1-79f774bdb9-95khd  1/1  Running 0   43h\nproductpage-v1-7b8d9dcc69-95lc6 1/1  Running 0   23h\nratings-v1-b6994bb9-gt94b   1/1  Running 0   43h\nreviews-v3-674d9bff46-4gl2v  1/1  Running 0   23h\n```\n- Confirm that the Ingress object of the example workloads is ready:```\nkubectl get ingress --namespace bookinfo\n```The output is similar to the following, in which the `IP` column shows the IP address for the `bookinfo` Ingress object:```\nNAME  CLASS HOSTS ADDRESS  PORTS AGE\nbookinfo <none> *  34.117.181.7 80  45h\n```\n- In your browser, go to the following URL, where `` is the IP address from the previous step:```\nhttp://EXTERNAL_IP/productpage\n```The page that loads displays information about books and relevant ratings.\nThe environment is now provisioned and configured to simulate the source environment.\nThe following diagram shows the target architecture of the system for this section:The preceding diagram shows the example workload running in the GKE cluster `source-cluster-1` , and a load balancer that exposes that workload. You configured Cloud Load Balancing using a GKE Ingress object. The target GKE clusters, `target-cluster-1` and `target-cluster-2` , don't host any workload. A client accesses the workload through the load balancer that's configured with the GKE Ingress object.## Deploying the example workload in the target environmentIn this section, you start the migration by deploying the example workload in the target environment. Having the target workload ready in the target environment ensures that the target environment is ready to fulfill requests coming from clients. If you expose workloads before they are ready in the target environment, you may expose clients to issues due to service disruption.- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Deploy the example workload in the cluster `target-cluster-1` to the target environment:```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-1 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\"\n```\n- Confirm that the Pods of the example workload are ready:```\nkubectl get pods --namespace bookinfo\n```The output is similar to the following. When all Pods are ready, the value shown in the `STATUS` field is `RUNNING` :```\nNAME        READY STATUS RESTARTS AGE\ndetails-v1-79f774bdb9-95khd  1/1  Running 0   43h\nproductpage-v1-7b8d9dcc69-95lc6 1/1  Running 0   23h\nratings-v1-b6994bb9-gt94b   1/1  Running 0   43h\nreviews-v3-674d9bff46-4gl2v  1/1  Running 0   23h\n```\n- Deploy the example workload in the `target-cluster-2` cluster in the target environment:```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-2 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\"\n```\n- Confirm that the Pods of the example workload are ready:```\nkubectl get pods --namespace bookinfo\n```The output is similar to the following. When all Pods are ready, the value shown in the `STATUS` field is `RUNNING` :```\nNAME        READY STATUS RESTARTS AGE\ndetails-v1-79f774bdb9-95khd  1/1  Running 0   43h\nproductpage-v1-7b8d9dcc69-95lc6 1/1  Running 0   23h\nratings-v1-b6994bb9-gt94b   1/1  Running 0   43h\nreviews-v3-674d9bff46-4gl2v  1/1  Running 0   23h\n```\nThe following diagram shows the target architecture of the system for this section:The preceding diagram shows the example workload running in the GKE cluster `source-cluster-1` , and a load balancer that exposes that workload. The architecture in the diagram matches the configuration that you set up, in which the load balancer uses a GKE Ingress object. The target GKE clusters, `target-cluster-1` and `target-cluster-2` , host instances of the example workload that aren't exposed to clients or to workloads running in other GKE clusters. A client accesses the workload through the load balancer that's configured with the GKE Ingress object.## Configuring Multi Cluster Ingress and Multi-Cluster Service DiscoveryIn this section, you provision and configure Multi Cluster Ingress and Multi-Cluster Service Discovery. Multi Cluster Ingress lets you expose workloads multiple clusters, and Multi-Cluster Service Discovery lets you expose workloads multiple clusters.- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Provision and configure Multi Cluster Ingress and Multi-Cluster Service Discovery:```\nscripts/mci-mcs.sh \\\u00a0 --config-cluster-membership-name \"${DEFAULT_REGION}-target-cluster-1\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\"\n```The `mci-mcs.sh` script does the following:- Designates a [Config Cluster](/kubernetes-engine/docs/concepts/multi-cluster-ingress#config_cluster_design) . To simplify the migration process, we recommend that you designate a Config Cluster in the target environment so that you don't have to [migrate the Config Cluster](/kubernetes-engine/docs/how-to/troubleshooting-and-ops#config_cluster_migration) before decommissioning the source environment.\n- [Enables Multi-Cluster Service Discovery](/kubernetes-engine/docs/how-to/multi-cluster-services#enabling) .\n- Confirm that Multi Cluster Ingress is set up correctly:```\ngcloud alpha container hub ingress describe\n```The output is similar to the following, in which the `featureState.details.code` fields show `OK` :```\nfeatureState:\n details:\n code: OK\n description: Ready to use\n updateTime: '2021-05-10T12:39:28.378476653Z'\n detailsByMembership:\n projects/324979197388/locations/global/memberships/us-central1-source-cluster-1:\n  code: OK\n  updateTime: '2021-05-12T09:22:39.420038966Z'\n projects/324979197388/locations/global/memberships/us-central1-target-cluster-1:\n  code: OK\n  updateTime: '2021-05-12T09:22:39.420038676Z'\n projects/324979197388/locations/global/memberships/us-central1-target-cluster-2:\n  code: OK\n  updateTime: '2021-05-12T09:22:39.420039116Z'\n hasResources: true\n lifecycleState: ENABLED\n```\n- Confirm that Multi-Cluster Service Discovery is set up correctly:```\ngcloud alpha container hub multi-cluster-services describe\n```It might take a few minutes for Multi-Cluster Service Discovery to be ready. When it's ready, the output is similar to the following, in which the value shown in the `featureState` `code` fields is `OK` :```\nfeatureState:\ndetailsByMembership:\n projects/PROJECT/locations/global/memberships/CLUSTER1:\n code: OK\n description: Firewall successfully created.\n updateTime: '2020-09-24T05:16:27.675313587Z'\n projects/PROJECT/locations/global/memberships/CLUSTER2:\n code: OK\n description: Firewall successfully created.\n updateTime: '2020-09-24T05:15:26.665213577Z'\nlifecycleState: ENABLED\n```\nMulti Cluster Ingress and Multi-Cluster Service Discovery are now provisioned and configured.\n### Exposing workloads using Multi Cluster IngressIn this section, you deploy Multi Cluster Ingress to expose the example workload.- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Use Multi Cluster Ingress to expose the example workload outside the cluster:```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-1 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --expose-with MCI\n```The `workloads.sh` script deploys Multi Cluster Ingress descriptors in the Config Cluster. System workloads in the Config Cluster handle the provisioning and configuring of Multi Cluster Ingress.\n- Confirm that Multi Cluster Ingress is set up correctly:```\nkubectl describe mci productpage --namespace bookinfo\n```It might take a couple of minutes for Multi-Cluster Service Discovery to be ready. When it's ready, the output shows a `Status` message similar to the following:```\nStatus:\n Cloud Resources:\n Backend Services:\n  gkemci-24ipb2-9080-bookinfo-productpage\n Firewalls:\n  gkemci-24ipb2-mcs-mci-tutorial-2-workloads-vpc-l7\n Forwarding Rules:\n  gkemci-24ipb2-fw-bookinfo-bookinfo-mci\n Health Checks:\n  gkemci-24ipb2-9080-bookinfo-productpage\n Network Endpoint Groups:\n  zones/us-central1-a/networkEndpointGroups/k8s1-2f4b7c0c-bookinf-mci-productpage-svc-ohon2ru3-908-d8e31dbd\n  zones/us-central1-a/networkEndpointGroups/k8s1-c05699ee-bookinf-mci-productpage-svc-ohon2ru3-908-a9236573\n  zones/us-central1-a/networkEndpointGroups/k8s1-fa6c2f9b-bookinf-mci-productpage-svc-ohon2ru3-908-8f28ea70\n  zones/us-central1-b/networkEndpointGroups/k8s1-2f4b7c0c-bookinf-mci-productpage-svc-ohon2ru3-908-d8e31dbd\n  zones/us-central1-b/networkEndpointGroups/k8s1-c05699ee-bookinf-mci-productpage-svc-ohon2ru3-908-a9236573\n  zones/us-central1-c/networkEndpointGroups/k8s1-fa6c2f9b-bookinf-mci-productpage-svc-ohon2ru3-908-8f28ea70\n  zones/us-central1-f/networkEndpointGroups/k8s1-2f4b7c0c-bookinf-mci-productpage-svc-ohon2ru3-908-d8e31dbd\n  zones/us-central1-f/networkEndpointGroups/k8s1-c05699ee-bookinf-mci-productpage-svc-ohon2ru3-908-a9236573\n  zones/us-central1-f/networkEndpointGroups/k8s1-fa6c2f9b-bookinf-mci-productpage-svc-ohon2ru3-908-8f28ea70\n Target Proxies:\n  gkemci-24ipb2-bookinfo-bookinfo-mci\n URL Map: gkemci-24ipb2-bookinfo-bookinfo-mci\n VIP:  34.117.121.178\n```Make a note of the IP address in the `VIP` field. You use it throughout this tutorial.\n- Open a browser and go to the following URL, where `` is the IP address in the `VIP` field from the previous step:```\nhttp://MCI_IP/productpage\n```It might take a couple of minutes for the page to be ready. When it's ready, the page displays information about books and relevant ratings.\nThe following diagram shows the target architecture of the system for this section:The preceding diagram shows the example workload running in the following GKE clusters: `source-cluster-1` , `target-cluster-1` , and `target-cluster-2` . Cloud Load Balancing exposes the workload running in each GKE cluster. The architecture in the diagram matches the configuration that you set up as follows:- The workload that is running in the GKE cluster`source-cluster-1`is exposed by a load balancer using a GKE Ingress object and exposed by a load balancer using Multi Cluster Ingress.\n- The workloads that are running in the GKE clusters`target-cluster-1`and`target-cluster-2`are exposed by a load balancer using Multi Cluster Ingress.\nA client accesses the workload through the load balancer that's configured with the GKE Ingress object.\n### Exposing workloads using Multi-Cluster Service DiscoveryIn this section, you configure Multi-Cluster Service Discovery to expose the example workload.- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Use Multi-Cluster Service Discovery to expose the example workload across the cluster `target-cluster-1` :```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-1 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --expose-with MCI \\\u00a0 --deploy-mcs\n```The `workloads.sh` script deploys the Kubernetes resources to configure Multi-Cluster Service Discovery in the Config Cluster. System workloads in the Config Cluster handle provisioning and configuring Multi-Cluster Service Discovery. The first [provisioning and configuration of Multi-Cluster Service Discovery](/kubernetes-engine/docs/how-to/multi-cluster-services#registering_a_service_for_export) takes about five minutes.\n- Confirm that Multi-Cluster Service Discovery is set up correctly:```\nkubectl get serviceimport --namespace bookinfo\n```The output is similar to the following, in which the `IP` column shows the IP address for three ServiceImports resources:```\nNAME   TYPE   IP     AGE\ndetails  ClusterSetIP [\"192.168.115.96\"] 41h\nratings  ClusterSetIP [\"192.168.107.46\"] 41h\nreviews  ClusterSetIP [\"192.168.167.69\"] 41h\n```When Multi-Cluster Service Discovery setup is complete, the output includes three ServiceImport resources. The resources appear gradually, and it might take a few minutes for all of them to be available. If the output displays the following error message, wait a minute and then run the command again : `No resources found in bookinfo namespace` .\n- Use Multi-Cluster Service Discovery to expose the example workload across the cluster `target-cluster-2` :```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-1 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --expose-with MCI \\\u00a0 --deploy-mcs\n```The `workloads.sh` script automatically updates the [kubectl context](/kubernetes-engine/docs/how-to/cluster-access-for-kubectl#kubeconfig) to point to the correct GKE cluster.\n- Confirm that Multi-Cluster Service Discovery is set up correctly:```\nkubectl get serviceimport --namespace bookinfo\n```The output is similar to the following, in which the `IP` column shows the IP address for three ServiceImports resources:```\nNAME   TYPE   IP     AGE\ndetails  ClusterSetIP [\"192.168.115.96\"] 41h\nratings  ClusterSetIP [\"192.168.107.46\"] 41h\nreviews  ClusterSetIP [\"192.168.167.69\"] 41h\n```When Multi-Cluster Service Discovery setup is complete, the output includes three ServiceImport resources. Each service in the output is now mapped to two DNS A records, where each `[SERVICE_NAME]` value is the name one of the ServiceImports resources in the output:- The`[SERVICE_NAME].bookinfo.svc.cluster.local`resource resolves to the [ClusterIP](https://kubernetes.io/docs/concepts/services-networking/service/#proxy-mode-userspace) that is local to the cluster where the Service is located.\n- The`[SERVICE_NAME].bookinfo.svc.clusterset.local`resource resolves to the [ClusterSetIP](/kubernetes-engine/docs/how-to/multi-cluster-services#consuming_cross-cluster_services) that points to Multi-Cluster Service Discovery.\n- Update and restart the example workload Pods that are running in the cluster `target-cluster-1` so that they use Multi-Cluster Service Discovery:```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-1 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --consume-mcs\n```\n- Confirm that the Pods of the example workload are ready:```\nkubectl get pods --namespace bookinfo\n```The output is similar to the following. When all Pods are ready, the value shown in the `STATUS` field is `RUNNING` :```\nNAME        READY STATUS RESTARTS AGE\ndetails-v1-79f774bdb9-95khd  1/1  Running 0   43h\nproductpage-v1-7b8d9dcc69-95lc6 1/1  Running 0   23h\nratings-v1-b6994bb9-gt94b   1/1  Running 0   43h\nreviews-v3-674d9bff46-4gl2v  1/1  Running 0\n```\n- Update the example workload Pods that are running in the `target-cluster-2` cluster so that they use Multi-Cluster Service Discovery:```\nscripts/workloads.sh \\\u00a0 --cluster-name target-cluster-2 \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --consume-mcs\n```\n- Confirm that the Pods of the example workload are ready:```\nkubectl get pods --namespace bookinfo\n```The output is similar to the following. When all Pods are ready, the value shown in the `STATUS` field is `RUNNING` :```\nNAME        READY STATUS RESTARTS AGE\ndetails-v1-79f774bdb9-95khd  1/1  Running 0   43h\nproductpage-v1-7b8d9dcc69-95lc6 1/1  Running 0   23h\nratings-v1-b6994bb9-gt94b   1/1  Running 0   43h\nreviews-v3-674d9bff46-4gl2v  1/1  Running 0\n```\n- Open a browser and go to the following URL, where `` is the VIP address that you noted when you [exposed workloads using Multi Cluster Ingress](#exposing-workloads-using-mci) earlier in this tutorial:```\nhttp://MCI_IP/productpage\n```A page is displayed with information about books and relevant ratings.\nYou deploy Multi-Cluster Service Discovery and Pods that use Multi-Cluster Service Discovery in the target environment only. This approach ensures that you don't apply changes to the source environment until you validate the target environment. It also ensures that you don't impact your clients during the migration, which reduces downtime to the minimum.\nThe following diagram shows the target architecture of the system for this section:The preceding diagram shows the example workload running in the following GKE clusters: `source-cluster-1` , `target-cluster-1` , and `target-cluster-2` . Cloud Load Balancing exposes the workload running in each GKE cluster. The architecture in the diagram matches the configuration that you set up as follows:- The workload that is running in the GKE cluster`source-cluster-1`is exposed by a load balancer using a GKE Ingress object and exposed by a load balancer using Multi Cluster Ingress.\n- The workloads that are running in the GKE clusters`target-cluster-1`and`target-cluster-2`are exposed by a load balancer using Multi Cluster Ingress.\n- Multi-Cluster Service Discovery is configured to expose the workload running in the GKE cluster`target-cluster-1`to the GKE cluster`target-cluster-2`, and the other way around.\nA client accesses the workload through the load balancer that's configured with the GKE Ingress object.## Switching traffic to the target environmentAt this point, clients can reach the example workload in the following ways:- Using a GKE Ingress object that exposes the example workload from the source environment.\n- Using Multi Cluster Ingress, which exposes the example workload from multiple clusters in the target environment.\nIn a typical production environment, clients can use a DNS record to resolve the IP address of the [HTTP Load Balancer](/kubernetes-engine/docs/concepts/ingress#overview) that the `bookinfo` GKE Ingress object created. For example, clients can use the `bookinfo.example.com` [DNS A record](https://wikipedia.org/wiki/List_of_DNS_record_types) to resolve the IP address of the load balancer that you created using GKE Ingress.\nAfter you validate that the target environment meets your requirements, you can update the `bookinfo.example.com` DNS A record to point to the Multi Cluster Ingress VIP address. This update causes clients to start pointing to the workloads in the target environment. Before you implement this DNS-based migration strategy, ensure that your DNS clients honor the [time to live (TTL) of DNS records](https://wikipedia.org/wiki/Time_to_live#DNS_records) . Misbehaving DNS clients might ignore updates to DNS records and use stale cache values instead. This DNS-based migration strategy doesn't support advanced traffic-management features to implement gradual migration strategies, such as partial traffic shifting or traffic mirroring. For information about alternatives that support traffic management features, see [Evaluate your runtime platform and environments](/architecture/migrating-containers-multi-cluster-gke#evaluate-runtime-platform-environments) .\nTo implement this DNS-based migration strategy, you can use [Cloud DNS](/dns) to manage your DNS records. If you want to provision Cloud DNS resources with Terraform, refer to [google_dns_managed_zone](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/dns_managed_zone) and [google_dns_record_set](https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/dns_record_set) .\nIn this document, GKE Ingress and Multi Cluster Ingress use two different static IP addresses. If your workloads can afford a minimal downtime due to a cutover window, you can delete the GKE Ingress first, and then [configure Multi Cluster Ingress to use the static IP address](/kubernetes-engine/docs/how-to/multi-cluster-ingress#static) that the GKE Ingress object used. Although reusing the GKE Ingress static IP address for Multi Cluster Ingress adds a minimal downtime, you avoid changing DNS records.\nThe following diagram shows the target architecture of the system for this section:The preceding diagram shows the example workload running in the following GKE clusters: `source-cluster-1` , `target-cluster-1` , and `target-cluster-2` . Cloud Load Balancing exposes the workload running in each GKE cluster. The architecture in the diagram matches the configuration that you set up as follows:- The workload that is running in the GKE cluster`source-cluster-1`is exposed by a load balancer using a GKE Ingress object and exposed by a load balancer using Multi Cluster Ingress.\n- The workloads that are running in the GKE clusters`target-cluster-1`and`target-cluster-2`are exposed by a load balancer using Multi Cluster Ingress.\n- Multi-Cluster Service Discovery exposes the workload running in the GKE cluster`target-cluster-1`to the GKE cluster`target-cluster-2`, and the other way around.\nA client accesses the workload through the load balancer that's configured with Multi Cluster Ingress.## Decommissioning the source environmentIn this section, you decommission the source environment. Before you proceed, ensure that the source environment is no longer serving client requests. To do so, you can use [Network Telemetry](/network-telemetry) to [access logs for clusters in the source environment](/vpc/docs/using-flow-logs#access-logs-gke-cluster) . When you're sure that all clients have switched to the target environment, follow these steps:- In Cloud Shell, change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Delete the resources from the cluster `source-cluster-1` :```\ngcloud container clusters get-credentials source-cluster-1 --region=\"${DEFAULT_REGION}\" \\&& kubectl delete namespace bookinfo --wait\n```\n- Change the working directory to the `terraform` directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"/terraform\n```\n- Deregister the clusters in the source environment from the fleet and delete them:```\nterraform destroy -target module.gke-and-hub-source\n```\nThe following diagram shows the target architecture of the system for this section:The preceding diagram shows the architecture that you configured, in which the example workload is running in the GKE clusters `target-cluster-1` and `target-cluster-2` . The cluster `source-cluster-1` is decommissioned. A client accesses the workload through the load balancer that's configured with Multi Cluster Ingress.## Cleaning upTo avoid incurring charges to your Google Cloud account for the resources used in this tutorial, delete the resources and the projects that you created.\n### Delete the resources and projectsIn Cloud Shell:- Change the working directory to the repository directory:```\ncd \"${MCI_MCS_TUTORIAL_DIRECTORY_PATH}\"\n```\n- Delete the resources that you provisioned:```\nscripts/cleanup.sh \\\u00a0 --google-cloud-project \"${DEFAULT_PROJECT}\" \\\u00a0 --cluster-region \"${DEFAULT_REGION}\" \\\u00a0 --terraform-state-project \"${TERRAFORM_STATE_PROJECT}\"\n```\n## What's next\n- Read about the other [migration strategies from a single cluster environment to a multi-cluster environment](/architecture/migrating-containers-multi-cluster-gke) .\n- Learn how [Multi-Cluster Service Discovery](/kubernetes-engine/docs/concepts/multi-cluster-services) and [Multi Cluster Ingress](/kubernetes-engine/docs/concepts/multi-cluster-ingress) work.\n- For more reference architectures, diagrams, and best practices, explore the [Cloud Architecture Center](/architecture) .", "guide": "Google Kubernetes Engine (GKE)"}