{"title": "Google Kubernetes Engine (GKE) - Best practices for continuous integration and delivery to Google Kubernetes Engine", "url": "https://cloud.google.com/kubernetes-engine/docs/concepts/best-practices-continuous-integration-delivery-kubernetes", "abstract": "# Google Kubernetes Engine (GKE) - Best practices for continuous integration and delivery to Google Kubernetes Engine\nThis guide describes a set of best practices for continuous integration and continuous delivery (CI/CD) to Google Kubernetes Engine (GKE). These practices cover a wide range of topics, from source control to deployment strategies. These best practices are specific to GKE and general CI/CD best practices still apply. For more information, see [DevOps tech: Continuous integration](/solutions/devops/devops-tech-continuous-integration) and [DevOps tech: Continuous delivery](/solutions/devops/devops-tech-continuous-delivery) .\n**Note:** For a summarized checklist of all the GKE best practices, see the [Checklist summary](#checklist) at the bottom of this guide.\n", "content": "## Continuous integration\n[Continuous integration (CI)](/solutions/devops/devops-tech-continuous-integration) is a practice in which developers integrate all their code changes back into a main branch as often as possible. It's meant to allow for faster failures by exposing issues as early as possible in the process. CI pipelines are usually triggered by developers pushing code changes. The pipeline involves steps to validate those changes such as linting, testing, and building. A CI pipeline typically produces an artifact that you can deploy in later stages of the deployment process.\n**Best practices** : [Create pipelines that enable rapid iteration](#rapid-iteration) . [Follow best practices for building containers](#container-best-practices) . [Test your container images](#test-images) . [Establish security early](#early-security) .\n### Create pipelines that enable rapid iteration\nThe time between when a developer makes a code change and when you have a running version of the application should be as short as possible. This speed is especially important during development on feature branches that involve fast iteration by developers. Ideally, your CI pipelines should run in less than 10 minutes. If that isn't possible, then create two types of CI pipelines:\n- **Rapid pipelines** : These pipelines typically run in 10 minutes or less. These pipelines are for feature branches and are not meant to be comprehensive. Rapid pipelines can potentially result in unstable artifacts.\n- **Full pipelines** : These pipelines can take longer than 10 minutes to run, and they run more comprehensive tests and checks. Full pipelines run on merge or pull requests, and commits to the main branch.\n### Follow best practices for building containers\nTo create smaller, more resilient images, and to make your containers easier to build and run, make sure you follow the [best practices for building containers](/solutions/best-practices-for-building-containers) .\n### Test your container images\nAs part of your CI pipelines, ensure that you run all the required tests on your code and build artifacts. These tests should include unit, functional, integration, and load or performance testing.\nIt's also important to test the structure of your built container images. Testing the structure ensures that all commands run as you expect them to inside of your container. Testing also lets you check that specific files are in the correct location and have the correct content.\nTo test your container images, you can use the [Container Structure Tests](https://github.com/GoogleContainerTools/container-structure-test) framework.\n### Establish security early in pipelines\nHave security checks and balances as early as possible in the development life cycle. By finding security risks before you build artifacts or deploy, you can reduce the time and cost spent to address these risks.\nTo help achieve early detection, you can implement the following security measures in your pipelines:\n- **Require that subject matter experts review any code integrated into your production repository** .\n- **Implement linting and static code analysis early in your pipeline** . This testing helps you find weaknesses such as not escaping inputs, accepting raw input data for SQL queries, or vulnerabilities in your code.\n- **Scan your built container image for vulnerabilities withvulnerability scanning** .\n- **Prevent images that contain vulnerabilities from being deployed to yourclusters, by using Binary Authorization** . Binary Authorization requires an [GKE Enterprise subscription](/binary-authorization/pricing) . To provide you with higher confidence in the produced images, Binary Authorization also lets you require [attestations](/binary-authorization/docs/key-concepts#attestations) by different entities or systems. For example, these attestations could include the following:- Passed vulnerability scan\n- Passed QA testing\n- Sign off from product owner\n## Continuous delivery\n[Continuous delivery (CD)](/solutions/devops/devops-tech-deployment-automation) lets you release code at any time. CD operates on the artifact produced by CI pipelines. CD pipelines can run for much longer than CI pipelines, especially if you're using more elaborate deployment strategies such as [blue-green deployments](https://wikipedia.org/wiki/Blue-green_deployment) .\n**Best practices** : [Use GitOps methodology](#gitops) . [Promote, rather than rebuild containers](#promote-containers) . [Consider using more advanced deployment options](#advanced-deployment-testing) . [Separate clusters for different environments](#separate-clusters) . [Keep your pre-production environments as close as possible to production](#pre-production-close-to-production) . [Prepare for failures in production](#prepare-failures) .\n### Use GitOps methodology\nGitOps is the concept of declarative infrastructure stored in Git repositories and the CI/CD tools to deploy that infrastructure to your environment. When you use a GitOps methodology, you ensure that all changes to your applications and clusters are stored in source repositories and are always accessible.\nUsing GitOps methodologies provides you with the following advantages:\n- You can review changes before they are deployed through merge or pull requests.\n- You have a single location that you can use to refer back to the state of your applications and clusters at any point in time.\n- Snapshots of your clusters and applications make it easier to recover when there are failures.\nTo learn more about the GitOps methodology and the different patterns that you can use in your source repositories, see [GitOps concepts](/solutions/addressing-continuous-delivery-challenges-in-a-kubernetes-world#gitops_concepts) .\nSome common tools used for declarative infrastructure are [Terraform](/docs/terraform) by Hashicorp and [Config Connector](/config-connector/docs/overview) by Google Cloud. For hands-on practice managing infrastructure with GitOps and other tools, try the [Managing infrastructure as code with Terraform, Cloud Build, and GitOps](/solutions/managing-infrastructure-as-code) tutorial. To learn how to manage applications in GitOps style, try the [GitOps-style continuous delivery with Cloud Build](/kubernetes-engine/docs/tutorials/gitops-cloud-build) .\n### Promote, rather than rebuild container images\nContainer images shouldn't be rebuilt as they pass through the different stages of a CI/CD pipeline. Rebuilding can introduce minor differences across code branches. These differences can cause your application to fail in production or cause the accidental addition of untested code in the production container image. To ensure that the container image you tested is the container image you deploy, it's best to build once and promote along your environments. This advice assumes that you are keeping environment-specific configuration separate from packages as advised in the [best practices for building containers](/solutions/best-practices-for-building-containers) .\n### Consider using more advanced deployment and testing patterns\nGKE offers you the flexibility to deploy and test your applications using several patterns. The deployment pattern you choose largely depends on your business goals. For example, you might need to deploy changes without any downtime or deploy changes to an environment or a subset of users before you make a feature generally available.\nSome of the different deployment patterns available for you include the following:\n- **Recreating a deployment** : You fully scale down the existing application version before you scale up the new application version.\n- **Rolling update deployment** : You update a subset of running application instances instead of updating all the running application instances at one time. Then you progressively update more of the running application instances until they are all updated.\n- **Blue-green deployment** : You deploy an additional parallel set of instances to your existing production instances with an upgraded version of your application. You switch over traffic to the new instances when you are ready to deploy.\nTo learn more about these strategies, see [Application deployment and testing strategies](/solutions/application-deployment-and-testing-strategies) .\n**Important:** Many of these deployment and testing patterns require significant work to use with GitOps. To learn how to use GitOps with these patterns, see [Kubernetes and the challenges of continuous software delivery](/solutions/addressing-continuous-delivery-challenges-in-a-kubernetes-world#pattern_1_only_nominal_states_in_the_git_repository) .\n### Separate clusters for different environments\nSeparation of environments is an important consideration for any deployment target. Ideally, you should have separate clusters for each of the following environments:\n- **Development environment** : This environment is where your developers deploy applications for testing and experimentation. These deployments require integration with other parts of the application or system (for example, a database). The clusters for this environment typically have fewer gates, and developers have greater control over their cluster configuration.\n- **Pre-production environments (Staging or QA)** : These environments should resemble the production environment as closely as possible. They're used to perform large-scale tests of changes like integration, load, performance, or regression tests.\n- **Production environment** : This environment is where your production workloads and user-facing applications and services run.\nTo learn more about these environments, see the [Environments section in Kubernetes and the challenges of continuous software delivery](/solutions/addressing-continuous-delivery-challenges-in-a-kubernetes-world#environments) .\n### Keep pre-production environments close to production\nIdeally, pre-production clusters are identical to production clusters, but for cost purposes pre-production clusters can be scaled down replicas. Keeping the clusters similar ensures that any testing is done on the same or similar conditions to what's in production. Parity between pre-production and production clusters also reduces the probability of unexpected failures due to environmental differences when you deploy to production.\nDeclarative infrastructure and GitOps help you to achieve a closer parity of your environments because you can more easily duplicate the configuration of your underlying cluster. To ensure your environments have similar conditions for policies and configurations, you can also use tools like [Config Sync](/anthos-config-management/docs/config-sync-overview) .\n### Prepare for failures in production\nNo amount of testing can guarantee the proper behavior of your application in production. Failures can be caused by edge cases with data that weren't considered or access patterns by your users that weren't tested. It's important to monitor your application in production and have automated rollback and deployment mechanisms so you can quickly react to and fix bugs or outages. Using more robust deployment strategies allows you to reduce the impact of issues and affect fewer of your end users when issues arise in production.\n## Checklist summary\nThe following table summarizes the tasks that we recommend when you use a CI/CD pipeline in GKE:\n| Area     | Tasks                                                                   |\n|:-----------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Continuous integration | Create pipelines that enable rapid iteration. Follow the best practices for building containers. Test your container images. Establish security early in pipelines.                          |\n| Continuous delivery | Use GitOps methodology. Promote, rather than rebuild containers. Consider using more advanced deployment and testing patterns. Separate clusters for different environments. Keep pre-production environments close to production. Prepare for failures in production. |\n## What's next\n- Learn about [Best practices for operating containers](/solutions/best-practices-for-operating-containers) .\n- Learn about [Best practices for enterprise multi-tenancy](/kubernetes-engine/docs/best-practices/enterprise-multitenancy) .\n- Learn more about [CI/CD on Google Cloud](/docs/ci-cd) .", "guide": "Google Kubernetes Engine (GKE)"}