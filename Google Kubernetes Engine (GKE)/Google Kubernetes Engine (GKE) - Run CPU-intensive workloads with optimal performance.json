{"title": "Google Kubernetes Engine (GKE) - Run CPU-intensive workloads with optimal performance", "url": "https://cloud.google.com/kubernetes-engine/docs/how-to/performance-pods", "abstract": "# Google Kubernetes Engine (GKE) - Run CPU-intensive workloads with optimal performance\nThis page shows you how to optimize CPU-intensive workloads for performance by telling Google Kubernetes Engine (GKE) to place each Pod on its own node, with full access to all of the node's resources. To use this Pod placement model, request the Performance [compute class](/kubernetes-engine/docs/concepts/autopilot-compute-classes) in your Autopilot workloads.\n", "content": "## Benefits of the Performance compute class\nDedicated nodes per Pod are ideal when you run large-scale CPU-intensive workloads that might need access to capabilities on the underlying virtual machine (VM). For example, CPU-intensive AI/ML training workloads or high performance computing (HPC) batch workloads.\nPods on these dedicated nodes have the following benefits:\n- **Predictable performance** : Access all of the node resources at any time.\n- **Burstable workloads** : If you don't set resource limits in your manifests, your Performance class Pods can burst into all of the unused capacity on the node with minimal risk of Kubernetes node-pressure eviction.## How Performance class Pods work\nYou deploy a Pod that has the following characteristics:\n- Selects the Performance class and a Compute Engine machine series\n- Specifies resource requests and, ideally, doesn't specify resource limits\nGKE does the following:\n- Ensures that the deployed Pod requests at least the [minimum resources for the compute class](/kubernetes-engine/docs/concepts/autopilot-resource-requests#compute-class-min-max) \n- Calculates the total resource requests of the deployed Pod and any DaemonSets in the cluster\n- Provisions a node that's backed by the selected machine series\n- Modifies the Pod manifest with a combination of node selectors and tolerations to ensure that the Pod runs on its own node\n### Compatibility with other GKE features\nYou can use Performance class Pods with the following GKE capabilities and features:\n- [Spot Pods](/kubernetes-engine/docs/how-to/autopilot-spot-pods) \n- [Extended run time Pods](/kubernetes-engine/docs/how-to/extended-duration-pods) \n- [Workload separation](/kubernetes-engine/docs/how-to/workload-separation) \n- [Capacity reservations](/kubernetes-engine/docs/how-to/consuming-reservations) \n- [Committed-use discounts](/kubernetes-engine/cud) \nSpot Pods and extended run time Pods are mutually exclusive. GKE doesn't enforce higher minimum resource requests for Performance class Pods that use workload separation.\n## Pricing\nYour Pod can use the entire underlying VM and any attached hardware at any time, and you're billed for this hardware by Compute Engine, with a premium for Autopilot node management and scalability. For details, see [GKE pricing](/kubernetes-engine/pricing#autopilot_mode) .\n## Before you begin\nBefore you start, make sure you have performed the following tasks:\n- Enable    the Google Kubernetes Engine API.\n- [    Enable Google Kubernetes Engine API   ](https://console.cloud.google.com/flows/enableapi?apiid=container.googleapis.com) \n- If you want to use the Google Cloud CLI for this task, [install](/sdk/docs/install) and then [initialize](/sdk/docs/initializing) the  gcloud CLI. If you previously installed the gcloud CLI, get the latest  version by running`gcloud components update`. **Note:** For existing gcloud CLI  installations, make sure to set the`compute/region`and`compute/zone` [properties](/sdk/docs/properties#setting_properties) . By setting default locations,  you can avoid errors in gcloud CLI like the following:`One of [--zone, --region] must be supplied: Please specify location`.\n- Ensure that you're familiar with the following:- [Compute Engine machine series and use cases](/compute/docs/machine-resource#machine_type_comparison) \n- Kernel-level requirements for your applications\n- Ensure that you have an existing Autopilot cluster running version 1.28.6-gke.1369000 and later or version 1.29.1-gke.1575000 and later. To create a cluster, see [Create an Autopilot cluster](/kubernetes-engine/docs/how-to/creating-an-autopilot-cluster#set-version) .## Connect to your cluster\nUse the Google Cloud CLI to connect to your Autopilot cluster:\n```\ngcloud container clusters get-credentials CLUSTER_NAME \\\u00a0 \u00a0 --location=LOCATION\n```\nReplace the following:\n- ``: the name of your cluster.\n- ``: the Compute Engine [location](/compute/docs/regions-zones/viewing-regions-zones) of the cluster.## Deploy a Performance class Pod\n- Save the following manifest as `perf-class-pod.yaml` :```\napiVersion: v1kind: Podmetadata:\u00a0 name: performance-podspec:\u00a0 nodeSelector:\u00a0 \u00a0 cloud.google.com/compute-class: Performance\u00a0 \u00a0 cloud.google.com/machine-family: MACHINE_SERIES\u00a0 containers:\u00a0 - name: my-container\u00a0 \u00a0 image: \"k8s.gcr.io/pause\"\u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 cpu: 20\u00a0 \u00a0 \u00a0 \u00a0 memory: \"100Gi\"\n```Replace `` with the Compute Engine machine series for your Pod, like `c3` . For supported values, see [Supported machine series](#supported-machine-series) in this document.\n- Deploy the Pod:```\nkubectl apply -f perf-class-pod.yaml\n```\n### Use Local SSDs in Performance class Pods\nPerformance class Pods can use Local SSDs for ephemeral storage if you select a machine series that includes a Local SSD. GKE considers ephemeral storage requests when provisioning a node for the Performance class Pod.\n- Save the following manifest as `perf-class-ssd-pod.yaml` :```\napiVersion: v1kind: Podmetadata:\u00a0 name: performance-podspec:\u00a0 nodeSelector:\u00a0 \u00a0 cloud.google.com/compute-class: Performance\u00a0 \u00a0 cloud.google.com/machine-family: MACHINE_SERIES\u00a0 \u00a0 cloud.google.com/gke-ephemeral-storage-local-ssd: \"true\"\u00a0 containers:\u00a0 - name: my-container\u00a0 \u00a0 image: \"k8s.gcr.io/pause\"\u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 \u00a0 cpu: 12\u00a0 \u00a0 \u00a0 \u00a0 memory: \"50Gi\"\u00a0 \u00a0 \u00a0 \u00a0 ephemeral: \"200Gi\"\n```Replace `` with a [supported machine series](#supported-machine-series) that also supports Local SSDs. If your specified machine series doesn't support Local SSDs, the deployment fails with an error.\n- Deploy the Pod:```\nkubectl apply -f perf-class-pod.yaml\n```## Supported machine series\nThe Performance compute class supports the following machine series:\n| Machine series   | Local SSD selection in Autopilot |\n|:-------------------------|-----------------------------------:|\n| C3 machine series (c3) |        nan |\n| C3D machine series (c3d) |        nan |\n| H3 machine series (h3) |        nan |\n| C2 machine series (c2) |        nan |\n| C2D machine series (c2d) |        nan |\n| T2D machine series (t2d) |        nan |\n| T2A machine series (t2a) |        nan |\nTo compare these machine series and their use cases, see [Machine series comparison](/compute/docs/machine-resource#machine_type_comparison) in the Compute Engine documentation.\n## How GKE selects a machine size\nTo select a machine size in the specified machine series, GKE calculates the total CPU, total memory, and total ephemeral storage requests of the Performance class Pod and any DaemonSets that will run on the new node. GKE rounds these values up to the nearest available Compute Engine machine type that supports all of these totals.\n- Example 1: Consider a Performance class Pod that selects the `C3` machine series. The total resource requests including DaemonSets are as follows:- 70\u00a0vCPU\n- 200\u00a0GiB of memory\nGKE places the Pod on a node that's backed by the `c3-standard-88` machine type, which has 88\u00a0vCPUs and 352\u00a0GB of memory.\n- Example 2: Consider a Performance class Pod that selects the `C3D` machine series and Local SSDs for ephemeral storage. The total resource requests including DaemonSets are as follows:- 12\u00a0vCPU\n- 50\u00a0GiB of memory\n- 200\u00a0GiB of ephemeral storage\nGKE places the Pod on a node that uses the `c3d-standard-16-lssd` machine type, which has 16\u00a0vCPUs, 64\u00a0GiB of memory, and 365\u00a0GiB of Local SSD capacity.## What's next\n- [Learn about the other Autopilot compute classes](/kubernetes-engine/docs/concepts/autopilot-compute-classes) \n- [Deploy GPU-based workloads in Autopilot](/kubernetes-engine/docs/how-to/autopilot-gpus)", "guide": "Google Kubernetes Engine (GKE)"}