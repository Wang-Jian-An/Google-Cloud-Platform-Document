{"title": "Google Kubernetes Engine (GKE) - Deploy a stateful workload with Filestore", "url": "https://cloud.google.com/kubernetes-engine/docs/tutorials/stateful-workload", "abstract": "# Google Kubernetes Engine (GKE) - Deploy a stateful workload with Filestore\nThis tutorial shows how to deploy a simple reader/writer stateful workload using a\n [Persistent Volume (PV)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistent-volumes) \nand a\n [Persistent Volume Claim (PVC)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#persistentvolumeclaims) \non Google Kubernetes Engine (GKE). Follow this tutorial to learn how to design for scalability using\n [Filestore](/filestore/docs) \n, Google Cloud's managed network filesystem.\n", "content": "## BackgroundBy nature, Pods are ephemeral. This means that GKE destroys the state and value stored in a Pod when it is deleted, evicted, or rescheduled.\nAs an application operator, you may want to maintain stateful workloads. Examples of such workloads include applications that process WordPress articles, messaging apps, and apps that process machine learning operations.\nBy using Filestore on GKE, you can perform the following operations:- Deploy stateful workloads that are scalable.\n- Enable multiple Pods to have`ReadWriteMany`as its`accessMode`, so that multiple Pods can read and write at the same time to the same storage.\n- Set up GKE to mount volumes into multiple Pods simultaneously.\n- Persist storage when Pods are removed.\n- Enable Pods to share data and easily scale.\n## Objectives\nThis tutorial is for application operators and other users that want to set up a scalable stateful workload on GKE using PVC and NFS.\nThis tutorial covers the following steps:- Create a GKE cluster.\n- Configure the managed file storage with Filestore using CSI.\n- Create a reader and a writer Pod.\n- Expose and access the reader Pod to a Service Load Balancer.\n- Scale up the writer.\n- Access data from the writer Pod.## Costs\nThis tutorial uses the following billable components of Google Cloud:\n- [Filestore](/filestore/pricing) \n- [GKE](/kubernetes-engine/pricing) \nUse the [Pricing Calculator](/products/calculator) to generate a cost estimate based on your projected usage.\nWhen you finish this tutorial, you can avoid continued billing by deleting the resources you created. For more information, see [Clean up](#clean-up) .To follow step-by-step guidance for this task directly in the Google Cloud console, click **Guide me** :\n [Guide me](https://console.cloud.google.com/?walkthrough_id=kubernetes--stateful) ## Before you begin\n### Set up your project### Set defaults for the Google Cloud CLI\n- In the Google Cloud console, start a Cloud Shell instance:  [Open Cloud Shell](https://console.cloud.google.com/?cloudshell=true) \n- Download the source code for this sample app:```\ngit clone https://github.com/GoogleCloudPlatform/kubernetes-engine-samplescd kubernetes-engine-samples/databases/stateful-workload-filestore\n```\n- Set the default environment variables:```\ngcloud config set project PROJECT_IDgcloud config set compute/region COMPUTE_REGIONgcloud config set compute/zone COMPUTE_ZONEgcloud config set filestore/zone COMPUTE_ZONEgcloud config set filestore/region COMPUTE_REGION\n```Replace the following values:- : your Google Cloud [project ID](/resource-manager/docs/creating-managing-projects#identifying_projects) .\n- : the [Compute Engine region](/compute/docs/regions-zones#available) .\n- : the [Compute Engine zone](/compute/docs/regions-zones#available) .## Create a GKE cluster\n- Create a GKE cluster named `stateful-cluster` :```\ngcloud container clusters create-auto stateful-cluster --region COMPUTE_REGION\n``` **Note:** This step can take up to five minutes to complete.The outcome is similar to the following once the cluster is created:```\n gcloud container clusters describe stateful-cluster\n NAME: stateful-cluster\n LOCATION: northamerica-northeast2\n MASTER_VERSION: 1.21.11-gke.1100\n MASTER_IP: 34.130.255.70\n MACHINE_TYPE: e2-medium\n NODE_VERSION: 1.21.11-gke.1100\n NUM_NODES: 3\n STATUS: RUNNING\n```Where the `STATUS` is `RUNNING` for the `stateful-cluster` .\n## Configure the managed file storage with Filestore using CSIGKE provides a way to automatically deploy and manage the [Kubernetes Filestore CSI driver](https://github.com/kubernetes-sigs/gcp-filestore-csi-driver) in your clusters. Using Filestore CSI allows you to dynamically create or delete Filestore instances and use them in Kubernetes workloads with a `StorageClass` or a `Deployment` .\nYou can create a new Filestore instance by creating a PVC that dynamically provisions a Filestore instance and the PV, or access pre-provisioned Filestore instances in Kubernetes workloads.\n **Note:** To use the Filestore CSI driver, your clusters must use GKE version 1.21 or later. [  databases/stateful-workload-filestore/filestore-storageclass.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/filestore-storageclass.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/filestore-storageclass.yaml) \n```\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:\u00a0 name: filestore-scprovisioner: filestore.csi.storage.gke.iovolumeBindingMode: ImmediateallowVolumeExpansion: trueparameters:\u00a0 tier: standard\u00a0 network: default\n```- `volumeBindingMode`is set to`Immediate`, which allows the provisioning of the volume to begin immediately.\n- `tier`is set to`standard`for faster Filestore instance creation time. If you need higher available NFS storage, snapshots for data backup, data replication over multiple zones and other enterprise level features, set`tier`to`enterprise`instead. Note: The reclaim policy for dynamically created PV defaults to`Delete`if the`reclaimPolicy`in the`StorageClass`is not set.\n- Create the `StorageClass` resource:```\nkubectl create -f filestore-storageclass.yaml\n```\n- Verify that the Storage Class is created:```\nkubectl get sc\n```The output is similar to the following:```\nNAME      PROVISIONER     RECLAIMPOLICY VOLUMEBINDINGMODE  ALLOWVOLUMEEXPANSION AGE\nfilestore-sc    filestore.csi.storage.gke.io Delete   Immediate    true     94m\n```\n [  databases/stateful-workload-filestore/preprov-storageclass.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/preprov-storageclass.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/preprov-storageclass.yaml) \n```\napiVersion: storage.k8s.io/v1kind: StorageClassmetadata:\u00a0 name: filestore-scprovisioner: filestore.csi.storage.gke.iovolumeBindingMode: ImmediateallowVolumeExpansion: true\n```\nWhen `volumeBindingMode` is set to `Immediate` , it allows the provisioning of the volume to begin immediately.- Create the `StorageClass` resource:```\n\u00a0 kubectl create -f preprov-storageclass.yaml\n```\n- Verify that the Storage Class is created:```\n\u00a0 kubectl get sc\n```The output is similar to the following:```\n NAME      PROVISIONER     RECLAIMPOLICY VOLUMEBINDINGMODE  ALLOWVOLUMEEXPANSION AGE\n filestore-sc    filestore.csi.storage.gke.io Delete   Immediate    true     94m\n```\n [  databases/stateful-workload-filestore/preprov-pv.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/preprov-pv.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/preprov-pv.yaml) \n```\napiVersion: v1kind: PersistentVolumemetadata:\u00a0 name: fileserver\u00a0 annotations:\u00a0 \u00a0 pv.kubernetes.io/provisioned-by: filestore.csi.storage.gke.iospec:\u00a0 storageClassName: filestore-sc\u00a0 capacity:\u00a0 \u00a0 storage: 1Ti\u00a0 accessModes:\u00a0 \u00a0 - ReadWriteMany\u00a0 persistentVolumeReclaimPolicy: Delete\u00a0 volumeMode: Filesystem\u00a0 csi:\u00a0 \u00a0 driver: filestore.csi.storage.gke.io\u00a0 \u00a0 # Modify this to use the zone, filestore instance and share name.\u00a0 \u00a0 volumeHandle: \"modeInstance/<FILESTORE_ZONE>/<INSTANCE_NAME>/<FILESTORE_SHARE_NAME>\"\u00a0 \u00a0 volumeAttributes:\u00a0 \u00a0 \u00a0 ip: <IP_ADDRESS> # Modify this to Pre-provisioned Filestore instance IP\u00a0 \u00a0 \u00a0 volume: <FILESTORE_SHARE_NAME> # Modify this to Pre-provisioned Filestore instance share name\n```- Verify that the pre-existing Filestore instance is ready:```\n\u00a0 gcloud filestore instances list\n```The output is similar to the following, where the `STATE` value is `READY` :```\n INSTANCE_NAME: stateful-filestore\n LOCATION: us-central1-a\n TIER: ENTERPRISE\n CAPACITY_GB: 1024\n FILE_SHARE_NAME: statefulpath\n IP_ADDRESS: 10.109.38.98\n STATE: READY\n CREATE_TIME: 2022-04-05T18:58:28\n```Note the `INSTANCE_NAME` , `LOCATION` , `FILE_SHARE_NAME` , and `IP_ADDRESS` of the Filestore instance.\n- Populate the Filestore instance console variables:```\n\u00a0 INSTANCE_NAME=INSTANCE_NAME\u00a0 LOCATION=LOCATION\u00a0 FILE_SHARE_NAME=FILE_SHARE_NAME\u00a0 IP_ADDRESS=IP_ADDRESS\n```\n- Replace the placeholder variables with the console variables obtained above to the file `preprov-pv.yaml` :```\n\u00a0 sed \"s/<INSTANCE_NAME>/$INSTANCE_NAME/\" preprov-pv.yaml > changed.yaml && mv changed.yaml preprov-pv.yaml\u00a0 sed \"s/<LOCATION>/$LOCATION/\" preprov-pv.yaml > changed.yaml && mv changed.yaml preprov-pv.yaml\u00a0 sed \"s/<FILE_SHARE_NAME>/$FILE_SHARE_NAME/\" preprov-pv.yaml > changed.yaml && mv changed.yaml preprov-pv.yaml\u00a0 sed \"s/<IP_ADDRESS>/$IP_ADDRESS/\" preprov-pv.yaml > changed.yaml && mv changed.yaml preprov-pv.yaml\n```\n- Create the PV```\n\u00a0 kubectl apply -f preprov-pv.yaml\n```\n- Verify that the PV's `STATUS` is set to `Bound` :```\n\u00a0 kubectl get pv\n```The output is similar to the following:```\n NAME  CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM    STORAGECLASS REASON AGE\n fileserver 1Ti  RWX   Delete   Bound default/fileserver filestore-sc    46m\n```### Use a PersistentVolumeClaim to access the volumeThe following `pvc.yaml` manifest references the Filestore CSI driver's `StorageClass` named `filestore-sc` .\nIn order to have multiple Pods reading and writing to the volume, the `accessMode` is set to `ReadWriteMany` .\n [  databases/stateful-workload-filestore/pvc.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/pvc.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/pvc.yaml) \n```\nkind: PersistentVolumeClaimapiVersion: v1metadata:\u00a0 name: fileserverspec:\u00a0 accessModes:\u00a0 - ReadWriteMany\u00a0 storageClassName: filestore-sc\u00a0 resources:\u00a0 \u00a0 requests:\u00a0 \u00a0 \u00a0 storage: 1Ti\n```- Deploy the PVC:```\nkubectl create -f pvc.yaml\n```\n- Verify that the PVC is created:```\nkubectl get pvc\n```The output is similar to the following:```\nNAME   STATUS VOLUME          CAPACITY ACCESS MODES STORAGECLASS  AGE\nfileserver Bound pvc-aadc7546-78dd-4f12-a909-7f02aaedf0c3 1Ti  RWX   filestore-sc  92m\n```\n- Verify that the newly created Filestore instance is ready:```\ngcloud filestore instances list\n```The output is similar to the following:```\nINSTANCE_NAME: pvc-5bc55493-9e58-4ca5-8cd2-0739e0a7b68c\nLOCATION: northamerica-northeast2-a\nTIER: STANDARD\nCAPACITY_GB: 1024\nFILE_SHARE_NAME: vol1\nIP_ADDRESS: 10.29.174.90\nSTATE: READY\nCREATE_TIME: 2022-06-24T18:29:19\n```\n **Note:** The Filestore instance can take 5 minutes to create. Proceed to the next step while waiting.## Create a reader and a writer Pod\n### Create the reader PodThe reader Pod will read the file that is being written by the writers Pods. The reader Pods will see what time and which writer Pod replica wrote to the file.\n [  databases/stateful-workload-filestore/reader-fs.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/reader-fs.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/reader-fs.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: readerspec:\u00a0 replicas: 1\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: reader\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: reader\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: nginx\u00a0 \u00a0 \u00a0 \u00a0 image: nginx:stable-alpine\u00a0 \u00a0 \u00a0 \u00a0 ports:\u00a0 \u00a0 \u00a0 \u00a0 - containerPort: 80\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - name: fileserver\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mountPath: /usr/share/nginx/html # the shared directory \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 readOnly: true\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 - name: fileserver\u00a0 \u00a0 \u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 claimName: fileserver\n```\nThe reader Pod will read from the path `/usr/share/nginx/html` which is shared between all the Pods.- Deploy the reader Pod:```\nkubectl apply -f reader-fs.yaml\n```\n- Verify that the reader replicas are running by querying the list of Pods:```\nkubectl get pods\n```The output is similar to the following:```\nNAME      READY STATUS RESTARTS AGE\nreader-66b8fff8fd-jb9p4 1/1  Running 0   3m30s\n```\n **Note:** While the reader Pod is creating, proceed to the next step.\n### Create the writer PodThe writer Pod will periodically write to a shared file that other writer and reader Pods can access. The writer Pod records its presence by writing its host name to the shared file.\nThe image used for the writer Pod is a custom image of Alpine Linux, which is used for utilities and production applications. It includes a script `indexInfo.html` that will obtain the metadata of the most recent writer, and keep count of all the unique writers and total writes.\n [  databases/stateful-workload-filestore/writer-fs.yaml ](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/writer-fs.yaml) [View on GitHub](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/HEAD/databases/stateful-workload-filestore/writer-fs.yaml) \n```\napiVersion: apps/v1kind: Deploymentmetadata:\u00a0 name: writerspec:\u00a0 replicas: 2 # start with 2 replicas\u00a0 selector:\u00a0 \u00a0 matchLabels:\u00a0 \u00a0 \u00a0 app: writer\u00a0 template:\u00a0 \u00a0 metadata:\u00a0 \u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 \u00a0 app: writer\u00a0 \u00a0 spec:\u00a0 \u00a0 \u00a0 containers:\u00a0 \u00a0 \u00a0 - name: content\u00a0 \u00a0 \u00a0 \u00a0 image: us-docker.pkg.dev/google-samples/containers/gke/stateful-workload:latest\u00a0 \u00a0 \u00a0 \u00a0 volumeMounts:\u00a0 \u00a0 \u00a0 \u00a0 - name: fileserver\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 mountPath: /html # the shared directory\u00a0 \u00a0 \u00a0 \u00a0 command: [\"/bin/sh\", \"-c\"]\u00a0 \u00a0 \u00a0 \u00a0 args:\u00a0 \u00a0 \u00a0 \u00a0 - cp /htmlTemp/indexInfo.html /html/index.html;\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 while true; do\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 echo \"<b> Date :</b> <text>$(date)</text> <b> Writer :</b> <text2> ${HOSTNAME} </text2> <br> \u00a0\" >> /html/indexData.html;\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 sleep 30; \u00a0\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 done\u00a0 \u00a0 \u00a0 volumes:\u00a0 \u00a0 \u00a0 - name: fileserver\u00a0 \u00a0 \u00a0 \u00a0 persistentVolumeClaim:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 claimName: fileserver\n```\nFor this tutorial, the writer Pod writes every 30 seconds to the path `/html/index.html` . Modify the `sleep` number value to have a different write frequency.- Deploy the writer Pod:```\nkubectl apply -f writer-fs.yaml\n```\n- Verify that the writer Pods are running by querying the list of Pods:```\nkubectl get pods\n```The output is similar to the following:```\nNAME      READY STATUS RESTARTS AGE\nreader-66b8fff8fd-jb9p4 1/1  Running 0   3m30s\nwriter-855565fbc6-8gh2k 1/1  Running 0   2m31s\nwriter-855565fbc6-lls4r 1/1  Running 0   2m31s\n``` **Note:** Pod creation might take up to five minutes.\n## Expose and access the reader workload to a Service Load BalancerTo expose a workload outside the cluster, create a Service of type `LoadBalancer` . This type of Service creates an external load balancer with an IP address reachable through the internet.- Create a Service of type `LoadBalancer` named `reader-lb` :```\nkubectl create -f loadbalancer.yaml\n```\n- Watch the deployment to see that GKE assigns an `EXTERNAL-IP` for `reader-lb` Service:```\nkubectl get svc --watch\n```When the `Service` is ready, the `EXTERNAL-IP` column displays the public IP address of the load balancer:```\n NAME   TYPE   CLUSTER-IP EXTERNAL-IP  PORT(S)  AGE\n kubernetes ClusterIP  10.8.128.1 <none>   443/TCP  2d21h\n reader-lb LoadBalancer 10.8.131.79 34.71.232.122 80:32672/TCP 2d20h\n```\n- Press **Ctrl+C** to terminate the watch process.\n- Use a web browser to navigate to the `EXTERNAL-IP` assigned to the load balancer. The page refreshes every 30 seconds. The more writers Pods and shorter the frequency, the more entries it will show.\nTo see more details about the load balancer service, see [loadbalancer.yaml](https://github.com/GoogleCloudPlatform/kubernetes-engine-samples/blob/main/databases/stateful-workload-filestore/loadbalancer.yaml) .## Scale up the writerBecause the PV `accessMode` was set to `ReadWriteMany` , GKE can scale up the number of Pods so that more writer Pods can write to this shared volume (or more readers can read to read them).- Scale up the `writer` to five replicas:```\nkubectl scale deployment writer --replicas=5\n```The output is similar to the following:```\ndeployment.extensions/writer scaled\n``` **Note:** Scaling might take a few minutes while the cluster is allocating more resources.\n- Verify the number of running replicas:```\nkubectl get pods\n```The output is similar to the following:```\nNAME      READY STATUS RESTARTS AGE\nreader-66b8fff8fd-jb9p4 1/1  Running 0   11m\nwriter-855565fbc6-8dfkj 1/1  Running 0   4m\nwriter-855565fbc6-8gh2k 1/1  Running 0   10m\nwriter-855565fbc6-gv5rs 1/1  Running 0   4m\nwriter-855565fbc6-lls4r 1/1  Running 0   10m\nwriter-855565fbc6-tqwxc 1/1  Running 0   4m\n```\n- Use a web browser to navigate again to the `EXTERNAL-IP` assigned to the load balancer.\nAt this point, you configured and scaled your cluster to support five stateful writer Pods. Where multiple writer Pods are writing to the same file simultaneously. The reader Pods can also be easily scaled up.## Optional: Access data from the writer PodThis section demonstrates how to use a command-line interface to access a reader or writer Pod. You can see the shared component that the writer is writing to and the reader is reading from.- Obtain the writer Pod name:```\nkubectl get pods\n```The output is similar to the following:```\nNAME      READY STATUS RESTARTS AGE\nwriter-5465d65b46-7hxv4 1/1  Running 0   20d\n```Note the hostname of a writer Pod (Example: `writer-5465d65b46-7hxv4` ).\n- Run the following command to access the writer Pod:```\nkubectl exec -it WRITER_HOSTNAME -- /bin/sh\n```\n- See the shared component in the file `indexData.html` :```\ncd /htmlcat indexData.html\n```\n- Clear the `indexData.html` file:```\necho '' > indexData.html\n```Refresh the web browser hosting the `EXTERNAL-IP` address to see the change.\n- Exit the environment:```\nexit\n```\n## Clean upTo avoid incurring charges to your Google Cloud account for the resources used in this   tutorial, either delete the project that contains the resources, or keep the project and   delete the individual resources.\n### Delete the project\n- **Caution** : Deleting a project has the following effects:- **Everything in the project is deleted.** If you used an existing project for  the tasks in this document, when you delete it, you also delete any other work you've  done in the project.\n- **Custom project IDs are lost.** When you created this project, you might have created a custom project ID that you want to use in  the future. To preserve the URLs that use the project ID, such as an`appspot.com`URL, delete selected resources inside the project instead of deleting the whole project.\n- In the Google Cloud console, go to the **Manage resources** page. [Go to Manage resources](https://console.cloud.google.com/iam-admin/projects) \n- In the project list, select the project that you  want to delete, and then click **Delete** .\n- In the dialog, type the project ID, and then click **Shut down** to delete the project.\n### Delete the individual resources\n- Delete the load balancer Service:```\nkubectl delete service reader-lb\n```Wait until the load balancer provisioned for the reader service is deleted\n- Verify the list returns `Listed 0 items` :```\ngcloud compute forwarding-rules list\n```\n- Delete the Deployments```\nkubectl delete deployment writerkubectl delete deployment reader\n```\n- Verify the Pods are deleted and returns `No resources found in default namespace.````\nkubectl get pods\n```\n- Delete the PVC. This will also delete the PV and the Filestore instance due to the retention policy set to `delete````\nkubectl delete pvc fileserver\n```\n- Delete the GKE cluster:```\ngcloud container clusters delete stateful-cluster --zone=COMPUTE_ZONE\n```This deletes the resources that make up the GKE cluster, including the reader and writer Pods.\n## What's next\n- Learn how to deploy [Cloud SQL with GKE](/sql/docs/mysql/connect-instance-kubernetes#gcloud_3) \n- [Access Modes](/kubernetes-engine/docs/concepts/persistent-volumes#access_modes) for PV and PVC\n- Learn more about [GKE and Filestore](/filestore/docs/csi-driver) \n- Learn more about [Filestore CSI Driver](/kubernetes-engine/docs/how-to/persistent-volumes/filestore-csi-driver#console) \n- How to create a [Filestore instance](/filestore/docs/creating-instances) \n- [See how to access Filestore instances from GKE clusters](/filestore/docs/csi-driver) \n- Explore other [Kubernetes Engine tutorials](/kubernetes-engine/docs/tutorials) .\n- Learn more about exposing apps using Services in GKE [Exposing applications using services](/kubernetes-engine/docs/how-to/exposing-apps)", "guide": "Google Kubernetes Engine (GKE)"}