{"title": "Vertex AI - Run training job with experiment tracking", "url": "https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform", "abstract": "# Vertex AI - Run training job with experiment tracking\nVertex AI provides a [managed training service](/vertex-ai/docs/training/overview) that enables you to operationalize large scale model training. You can enable experiment tracking using Vertex AI SDK for Python to capture parameters and performance metrics when submitting the custom training job.\nThis feature isn't available when you:\n- submit a training job through Google Cloud console or Google Cloud CLI,\n- use TPU in the training job,\n- use distributed training in the training job.\nBoth [prebuilt training containers](/vertex-ai/docs/training/pre-built-containers) and [custom containers are supported](/vertex-ai/docs/training/create-custom-container) are supported. Required: A version of the Vertex AI SDK for Python higher than 1.24.1 for google-cloud-aiplatform is installed. If you are training with Tensorflow, ensure the protobuf version less than 4.0 is installed to avoid conflicts.\nThere are two options for logging data to Vertex AI Experiments, autologging and manual logging.\nAutologging is recommended if you are using one of these supported frameworks: Fastai, Gluon, Keras, LightGBM, Pytorch Lightning, Scikit-learn, Spark, Statsmodels, XGBoost. If your framework isn't supported, or there are custom metrics you want to log to your experiment run, you can manually adapt your training script to log parameters, metrics and artifacts.\n", "content": "## AutoLog data\nTo enable autologging, just set `enable_autolog=True` , see [from_local_script](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob#google_cloud_aiplatform_CustomJob_from_local_script) . You have the option to create an experiment run, or not. If an experiment name isn't specified, one is created for you.\nThe Vertex AI SDK for Python handles creating [ExperimentRun](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.ExperimentRun#google_cloud_aiplatform_ExperimentRun) resources for you.### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_custom_job_with_experiment_autologging_sample.py) \n```\ndef create_custom_job_with_experiment_autologging_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 staging_bucket: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 script_path: str,\u00a0 \u00a0 container_uri: str,\u00a0 \u00a0 service_account: str,\u00a0 \u00a0 experiment: str,\u00a0 \u00a0 experiment_run: Optional[str] = None,) -> None:\u00a0 \u00a0 aiplatform.init(project=project, location=location, staging_bucket=staging_bucket, experiment=experiment)\u00a0 \u00a0 job = aiplatform.CustomJob.from_local_script(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 script_path=script_path,\u00a0 \u00a0 \u00a0 \u00a0 container_uri=container_uri,\u00a0 \u00a0 \u00a0 \u00a0 enable_autolog=True,\u00a0 \u00a0 )\u00a0 \u00a0 job.run(\u00a0 \u00a0 \u00a0 \u00a0 service_account=service_account,\u00a0 \u00a0 \u00a0 \u00a0 experiment=experiment,\u00a0 \u00a0 \u00a0 \u00a0 experiment_run=experiment_run,\u00a0 \u00a0 )\n```\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these Project IDs in the   Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations.](/vertex-ai/docs/general/locations) \n- `staging_bucket`: The name you gave your bucket, for example,`my_bucket`.\n- `display_name`: The user-defined name of the [CustomJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob) .\n- `script_path`: The path, relative to the working directory on your local   file system, to the script that is the entry point for your training code.\n- `container_uri`: The URI of the training container image can be a   Vertex AI [prebuilt training container](/vertex-ai/docs/training/pre-built-containers) or a [custom container](/vertex-ai/docs/training/containers-overview) \n- `service_account`:   See [Create a service account with required permissions](/vertex-ai/docs/experiments/tensorboard-training#create_a_service_account_with_required_permissions) .\n- `experiment`: Provide a name for your experiment. The experiment must have a [TensorBoard instance](/vertex-ai/docs/experiments/tensorboard-setup#create-tensorboard-instance) .   You can find your list of experiments in the Google Cloud console by   selecting **Experiments** in the section nav.\n- `experiment_run`: (Optional) Specify a run name. If not specified, a run is   auto-created.## Manually log data\nUse the manually log data option to incorporate your training script.\nHere's how to change the training script:\n```\nimport osimport pickleimport pandas as pdfrom sklearn.linear_model import LinearRegression# To use manual logging APIs, import aiplatformfrom google.cloud import aiplatform# Create Datasetdata = {'A': [1.1,2.2,4.1,5.2],\u00a0 \u00a0 \u00a0 \u00a0 'B': [200, 212.12, 22, 123],\u00a0 \u00a0 \u00a0 \u00a0 'Y': [1,0,1,0]}df = pd.DataFrame(data)X = df[['A', 'B']]Y = df['Y']# Train modelmodel = LinearRegression().fit(X, Y)# Save the model to gcsmodel_dir = os.getenv('AIP_MODEL_DIR')model_gcs = model_dir.replace('gs://', '/gcs/')model_name = 'model.pkl'os.mkdir(model_gcs)f = open(os.path.join(model_gcs, model_name), 'wb')pickle.dump(model, f)f = open(os.path.join(model_gcs, model_name), 'wb')\u00a0 \u00a0 pickle.dump(model, f)# Call aiplatform's logging APIs to save data to Vertex AI Experiments.params = model.get_params()aiplatform.log_params(params)metrics = {\"training_accuracy\": model.score(X,Y)}aiplatform.log_metrics(metrics)\n```\nYou have the option to create an experiment run, or not. If an experiment name isn't specified, one is created for you.\nLearn more, see [Manually log data to an experiment run](/vertex-ai/docs/experiments/log-data) .### Python [View on GitHub](https://github.com/googleapis/python-aiplatform/blob/HEAD/samples/model-builder/create_custom_job_with_experiment_sample.py) \n```\ndef create_custom_job_with_experiment_sample(\u00a0 \u00a0 project: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 staging_bucket: str,\u00a0 \u00a0 display_name: str,\u00a0 \u00a0 script_path: str,\u00a0 \u00a0 container_uri: str,\u00a0 \u00a0 service_account: str,\u00a0 \u00a0 experiment: str,\u00a0 \u00a0 experiment_run: Optional[str] = None,) -> None:\u00a0 \u00a0 aiplatform.init(\u00a0 \u00a0 \u00a0 \u00a0 project=project,\u00a0 \u00a0 \u00a0 \u00a0 location=location,\u00a0 \u00a0 \u00a0 \u00a0 staging_bucket=staging_bucket,\u00a0 \u00a0 \u00a0 \u00a0 experiment=experiment\u00a0 \u00a0 )\u00a0 \u00a0 job = aiplatform.CustomJob.from_local_script(\u00a0 \u00a0 \u00a0 \u00a0 display_name=display_name,\u00a0 \u00a0 \u00a0 \u00a0 script_path=script_path,\u00a0 \u00a0 \u00a0 \u00a0 container_uri=container_uri,\u00a0 \u00a0 )\u00a0 \u00a0 job.run(\u00a0 \u00a0 \u00a0 \u00a0 service_account=service_account,\u00a0 \u00a0 \u00a0 \u00a0 experiment=experiment,\u00a0 \u00a0 \u00a0 \u00a0 experiment_run=experiment_run,\u00a0 \u00a0 )\n```\n- `project`: Your [project ID](/resource-manager/docs/creating-managing-projects#identifiers) . You can find these Project IDs in the   Google Cloud console [welcome](https://console.cloud.google.com/welcome) page.\n- `location`: See [List of available locations](/vertex-ai/docs/general/locations) \n- `staging_bucket`: The name you gave your bucket, for example,`my_bucket`.\n- `display_name`: The user-defined name of the [CustomJob](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomJob) .\n- `script_path`: The path, relative to the working directory on your local   file system, to the script that is the entry point for your training code.\n- `container_uri`: The URI of the training container image can be a   Vertex AI [prebuilt training container](/vertex-ai/docs/training/pre-built-containers) ,   or a [custom container](/vertex-ai/docs/training/containers-overview) . If you are using   a custom container, be sure [google-cloud-aiplatform>=1.24.0](/vertex-ai/docs/start/install-sdk#install-python-sdk) is installed.\n- `service_account`:   See [Create a service account with required permissions](/vertex-ai/docs/experiments/tensorboard-training#create_a_service_account_with_required_permissions) .\n- `experiment`: Provide a name for your experiment. You can find your   list of experiments in the Google Cloud console by selecting **Experiments** in the section nav.\n- `experiment_run`: Specify a run name. If not specified, a run is  be auto-created.\n## View autologged parameters and metricsUse the Vertex AI SDK for Python to [compare runs](/vertex-ai/docs/experiments/compare-analyze-runs#compare-runs) and get runs data. The [Google Cloud console](/vertex-ai/docs/experiments/compare-analyze-runs#console-compare-analyze-runs) provides an easy way to compare these runs.## What's next\n- [Log data to an experiment run](/vertex-ai/docs/experiments/log-data) \n## Relevant notebook sample\n- [Custom training autologging](/vertex-ai/docs/experiments/user-journey/uj-custom-training-autologging) \n-", "guide": "Vertex AI"}