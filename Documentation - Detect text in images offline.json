{"title": "Documentation - Detect text in images offline", "url": "https://cloud.google.com/distributed-cloud/hosted/docs/latest/gdch/overview", "abstract": "# Documentation - Detect text in images offline\n**In review:** This is a GA feature that has been identified as a Significant Change Request (SCR) feature and is going through further review. This feature has not received an Authority to Operate (ATO) within a regulated environment. For more information on features in review for accreditation, see the GDCH [feature stages](/distributed-cloud/hosted/docs/latest/gdch/resources/feature-stages) .\nAsynchronous image detection and annotation can be performed on a list of generic files, such as PDF files. The files might contain multiple pages and multiple images per page. The files to be processed must be stored in an Object storage bucket, and the detected text is written to an Object storage bucket in JSON format.\nYou can retrieve the progress and results of an asynchronous batch annotation request by using the `google.longrunning.Operations` interface. The `Operation.metadata` field contains `OperationMetadata` . The `Operation.response` field contains the `AsyncBatchAnnotateFilesResponse(Results)` .\n", "content": "## Prepare your environment\nBefore using an asynchronous OCR API to detect text offline, you must do the following:\n- [Create a project](/distributed-cloud/hosted/docs/latest/gdch/platform/pa-user/create-a-project) .\n- Create a [storage bucket](/distributed-cloud/hosted/docs/latest/gdch/platform/pa-user/create-storage-buckets#create_a_bucket) in the project.\n- Select the`Standard`class.\n- Grant`read`and`write`permissions on the bucket to the service account (`ai-ocr-system-sa`) used by the OCR service.\n- Enter the following sample code to create the project, storage bucket, role, and role binding:- Create the project.```\n\u00a0 apiVersion: resourcemanager.gdc.goog/v1\u00a0 kind: Project\u00a0 metadata:\u00a0 \u00a0 labels:\u00a0 \u00a0 \u00a0 atat.config.google.com/clin-number: <clin-number>\u00a0 \u00a0 \u00a0 atat.config.google.com/task-order-number: <task-order-number>\u00a0 \u00a0 name: ocr-async-project\u00a0 \u00a0 namespace: platform\n```\n- Create the storage bucket.```\n\u00a0 apiVersion: object.gdc.goog/v1\u00a0 kind: Bucket\u00a0 metadata:\u00a0 \u00a0 name: ocr-async-bucket\u00a0 \u00a0 namespace: ocr-async-project\u00a0 spec:\u00a0 \u00a0 description: bucket for async ocr\u00a0 \u00a0 storageClass: Standard\u00a0 \u00a0 bucketPolicy:\u00a0 \u00a0 \u00a0 lockingPolicy:\u00a0 \u00a0 \u00a0 \u00a0 defaultObjectRetentionDays: 90\n```\n- Create the role.```\n\u00a0 apiVersion: rbac.authorization.k8s.io/v1\u00a0 kind: Role\u00a0 metadata:\u00a0 \u00a0 name: ocr-async-reader-writer\u00a0 \u00a0 namespace: ocr-async-project\u00a0 rules:\u00a0 \u00a0 -\u00a0 \u00a0 \u00a0 apiGroups:\u00a0 \u00a0 \u00a0 \u00a0 - object.gdc.goog\u00a0 \u00a0 \u00a0 resources:\u00a0 \u00a0 \u00a0 \u00a0 - buckets\u00a0 \u00a0 \u00a0 verbs:\u00a0 \u00a0 \u00a0 \u00a0 - read-object\u00a0 \u00a0 \u00a0 \u00a0 - write-object\n```\n- Create the role binding.```\n\u00a0 apiVersion: rbac.authorization.k8s.io/v1\u00a0 kind: RoleBinding\u00a0 metadata:\u00a0 \u00a0 name: ocr-async-reader-writer-rolebinding\u00a0 \u00a0 namespace: ocr-async-project\u00a0 roleRef:\u00a0 \u00a0 apiGroup: rbac.authorization.k8s.io\u00a0 \u00a0 kind: Role\u00a0 \u00a0 name: ocr-async-reader-writer\u00a0 subjects:\u00a0 \u00a0 -\u00a0 \u00a0 \u00a0 kind: ServiceAccount\u00a0 \u00a0 \u00a0 name: ai-ocr-system-sa\u00a0 \u00a0 \u00a0 namespace: ai-ocr-system\n```\n## Upload files to the object storage bucket\nIn order for the OCR service to process the file, the files must be uploaded to the object storage bucket.\nFollow these steps:\n- To configure the gdcloud CLI storage, see [Install and configure the storage CLI for projects](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/install-configure-storage-cli#gdcloud-storage-configure) .\n- For the steps to upload objects to a storage bucket, see [Upload and download storage objects in projects](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/upload-download-storage-objects#upload_objects_to_storage_buckets) .## Trigger the AsyncBatchAnnotateFilesRequest request\n`AsyncBatchAnnotateFilesRequest` initiates the offline processing and returns the ID of the long-running process that performs text detection on the file. The returned ID can be used to track the status of the offline processing. If there are too many ongoing operations, the offline processing might not start immediately.\nBefore sending a request, you must ensure that the OCR service account has read permission to your input bucket and write permission to your output bucket, even though the input and output buckets can be different and in different project namespaces. We recommend using the same input and output buckets to prevent errors in case you provide the wrong name, and the results are written to buckets that don't belong to you.\nTo call the `AsyncBatchAnnotateFilesRequest` , you must specify the following:\n- **Input file:** The file that you want to annotate.\n- **Output destination:** The location where you want to store the annotated results.\n- **Project ID:** The ID of the project that you want to use.\n- **Endpoint:** The endpoint that you want to use.\n```\n\u00a0 \u00a0 echo '{\"parent\":PROJECT_ID,\"requests\": [{\"features\": [{\"type\": \"DOCUMENT_TEXT_DETECTION\"}],\"input_config\": {\"gcs_source\": {\"uri\": INPUT_FILE},\"mime_type\": \"application/pdf\"},\"output_config\": {\"gcs_destination\": {\"uri\": OUTPUT_DESTINATION}}}]}' | curl --data-binary \u00a0@- -H \"Content-Type: application/json\" -H \"Authorization: Bearer TOKEN\" ENDPOINT/v1/files:asyncBatchAnnotate\n```\n```\n\u00a0 cat <<- EOF > request.json\u00a0 {\u00a0 \u00a0 \"requests\": [{\u00a0 \u00a0 \u00a0 \"features\": [{\u00a0 \u00a0 \u00a0 \u00a0 \"type\": \"DOCUMENT_TEXT_DETECTION\"\u00a0 \u00a0 \u00a0 }],\u00a0 \u00a0 \u00a0 \"input_config\": {\u00a0 \u00a0 \u00a0 \u00a0 \"gcs_source\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"uri\": \"INPUT_FILE\"\u00a0 \u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \u00a0 \"mime_type\": \"application/pdf\"\u00a0 \u00a0 \u00a0 },\u00a0 \u00a0 \u00a0 \"output_config\": {\u00a0 \u00a0 \u00a0 \u00a0 \"gcs_destination\": {\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \"uri\": \"OUTPUT_DESTINATION\"\u00a0 \u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }],\u00a0 \u00a0 \"parent\": \"PROJECT_ID\"\u00a0 }\u00a0 EOF\u00a0 grpcurl -max-msg-sz 50000000 -d @ -plaintext ENDPOINT\u00a0 google.cloud.vision.v1.ImageAnnotator.AsyncBatchAnnotateFiles < request.json\n```\nThe `vc.async_batch_annotate_files()` function returns a Google API Core operation object. This object contains a long-running operation (LRO), which can be accessed by calling `operation.operation` . The operation name can be obtained from the LRO, and the user can use the name to query the status of the LRO. The `operation.result()` waits until the LRO is complete and then returns the result.\n```\n\u00a0 def vision_func_async(creds):\u00a0 \u00a0 vc = vision_client(creds)\u00a0 \u00a0 features = [{\"type_\": vision.Feature.Type.DOCUMENT_TEXT_DETECTION}]\u00a0 \u00a0 input_config = {\"gcs_source\":{\"uri\":INPUT_FILE},\"mime_type\": \"application/pdf\"}\u00a0 \u00a0 output_config = {\"gcs_destination\": {\"uri\": OUTPUT_DESTINATION}}\u00a0 \u00a0 req = {\"input_config\": input_config, \"output_config\": output_config, \"features\":features}\u00a0 \u00a0 reqs = {\"requests\":[req],\"parent\":PROJECT_ID}\u00a0 \u00a0 operation = vc.async_batch_annotate_files(request=reqs)\u00a0 \u00a0 lro = operation.operation\u00a0 \u00a0 resp = operation.result()\n```\n## Validate the jobs and check the status\nThe `` returned by the `AsyncBatchAnnotateFiles` function is required to check the status of the operation.\n## Get operation\nThe `get` method returns the latest state of a long-running operation. Use this method to poll the operation result generated by the OCR service. To call the `get` method, specify your `` and the `` .\n```\ncurl -X GET \"http://ENDPOINT/v1/OPERATION_NAME\"\n```\n```\ngrpcurl -plaintext -d '{\"name\": OPERATION_NAME}' ENDPOINT google.longrunning.Operations/get\n```\n## List Operation\nThe `list` method returns a list of the operations that match a specified filter in the request. The method can return operations from a specific project. To call the `list` method, specify your `` and the `` .\n```\ncurl -X GET \"http://ENDPOINT/v1/PROJECT_ID?page_size=10\"\n```\n```\ngrpcurl -plaintext -d '{\"name\": PROJECT_ID, \"page_size\": 10}' ENDPOINT google.longrunning.Operations/list\n```\n## Delete the bucket\nFor more information, see [Delete objects in storage buckets](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/delete-storage-objects#delete_objects_in_storage_buckets) .", "guide": "Documentation"}