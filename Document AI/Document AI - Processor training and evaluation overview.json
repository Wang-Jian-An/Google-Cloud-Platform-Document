{"title": "Document AI - Processor training and evaluation overview", "url": "https://cloud.google.com/document-ai/docs/workbench/training-overview?hl=zh-cn", "abstract": "# Document AI - Processor training and evaluation overview\n# Processor training and evaluation overview\nDocument AI lets you train new processor versions using your own training data and evaluate the quality of your processor version against your own test data.\nThis is useful when:\n- You want to use [Document AI Workbench](#cdw) to process a new type of document that Document AI does not yet provide built-in support for.\n- There exists a Document AI processor for your document type, but you'd like to [uptrain](#uptrain) a custom version of it to meet your needs.\nTraining and evaluation are typically performed in tandem to iterate towards a high quality, usable processor version.\n", "content": "## Document AI Workbench\n**Document AI Workbench** lets you build your own **Custom DocumentExtractor** , which extracts entities from documents of a particular type, for example, the items in a menu, or the name and contact information from a resume.\nUnlike other processors, custom processors do not come with any pretrained processor versions and thus, cannot process any documents until you train a version from scratch.\nTo get started with Document AI Workbench, see [Build your own custom processor](/document-ai/docs/workbench/build-custom-processor) .\n## Uptraining a processor\nYou can **uptrain** new processor versions to improve accuracy on your data, extract additional custom fields from your documents, and/or add support for new languages.\nUptraining works by applying on Google pretrained processor versions and generally requires less data than training from scratch.\nTo get started, see [Uptrain a specialized processor](/document-ai/docs/workbench/uptrain-processor) .\n### Supported Processors\nNot all specialized processors support uptraining. These are the processors that support uptraining.\n- [Pay Slip Parser](/document-ai/docs/processors-list#processor_pay-slip-parser) \n- [W2 Parser](/document-ai/docs/processors-list#processor_w2-parser) \n- [Expense Parser](/document-ai/docs/processors-list#processor_expense-parser) \n- [Invoice Parser](/document-ai/docs/processors-list#processor_invoice-processor) \n- [Purchase Order Parser](/document-ai/docs/processors-list#processor_PURCHASE_ORDER_PROCESSOR) ## Data considerations and recommendations\nThe quality and the amount of your data determines the quality of the training, uptraining, and evaluation.\nObtaining a set of representative, real-world documents and providing enough high-quality labels are often the most time-consuming and resource-intensive part of the process.\n### Number of documents\nIf your documents all have a similar format (for example, a fixed form with very low variation), then fewer documents are required to achieve accuracy. The higher the variation, the more documents are required.\nThe following charts provide a rough estimate of the number of documents that are required for a Custom Document Extractor to achieve a particular quality score.\n| Low variation | High variation |\n|----------------:|-----------------:|\n|    nan |    nan |\n### Data labeling\nConsider your [options for labeling documents](/document-ai/docs/workbench/label-documents#Labeling_options) and make sure you have enough resources to annotate the documents in your dataset.\n### Training models\nCustom Document Extractor processors can use different model types depending on the specific use case and available training data.\n- Custom model: model using labeled training data.- Template-based: documents with a fixed layout.\n- Model-based: documents with some layout variation.\n- Generative AI model: based on pretrained [foundation models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models) that require minimal additional training.\nThe following table illustrates which use cases correspond to each model type.\n| ('Unnamed: 0_level_0', 'Unnamed: 0_level_1')      | ('Custom model', 'Template-based') | ('Custom model', 'Model-based') | ('Generative AI', 'Generative AI') |\n|:-----------------------------------------------------------------|:-------------------------------------|:----------------------------------|:-------------------------------------|\n| Layout variation             | nan         | Low to medium      | High         |\n| Amount of free-form text (for example, paragraphs in a contract) | Low         | Low        | High         |\n| Amount of training data required         | Low         | High        | Low         |\n| Accuracy with limited training data        | Higher        | Lower        | Higher        |\n## When not to use Document AI Workbench\nDocument AI Workbench is not always the best choice for document processing. Here are some instances in which you might want to consider other options, or adapt your workflow.\n- Certain text-based input formats (.txt, .html, .docx, .md, and so forth) are currently not supported by Document AI Workbench. Consider other pre-built or custom language processing offerings in Google Cloud, such as the [Cloud Natural Language API](https://cloud.google.com/natural-language) .\n- The Custom Document Extractor schema supports up to 150 entity labels. If your business logic requires more than 150 entities in the schema definition, consider training multiple processors, each targeting a subset of entities.## What's next\n- [Create a dataset](/document-ai/docs/workbench/create-dataset) \n- [Label documents](/document-ai/docs/workbench/label-documents) \n- [Train processor](/document-ai/docs/workbench/train-processor) \n- [Evaluate processor performance](/document-ai/docs/workbench/evaluate)", "guide": "Document AI"}