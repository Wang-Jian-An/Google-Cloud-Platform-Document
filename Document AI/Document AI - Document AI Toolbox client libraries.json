{"title": "Document AI - Document AI Toolbox client libraries", "url": "https://cloud.google.com/document-ai/docs/toolbox?hl=zh-cn", "abstract": "# Document AI - Document AI Toolbox client libraries\nThis page shows how to get started with the Cloud Client Libraries for the Document AI Toolbox API. Client libraries make it easier to access Google Cloud APIs from a supported language. Although you can use Google Cloud APIs directly by making raw requests to the server, client libraries provide simplifications that significantly reduce the amount of code you need to write.\nRead more about the Cloud Client Libraries and the older Google API Client Libraries in [Client libraries explained](/apis/docs/client-libraries-explained) .\n**    Experimental     ** This library is subject to the \"Pre-GA Offerings Terms\" in the General Service Terms section   of the [Service Specific Terms](/terms/service-terms#1) .     Pre-GA libraries are available \"as is\" and might have limited support.    For more information, see the [launch stage descriptions](/products#product-launch-stages) .\n[](None)\n", "content": "## Install the client library\n```\npip install --upgrade google-cloud-documentai-toolbox\n```\nFor more information, see [Setting Up a Python Development Environment](/python/docs/setup) .\n[](None)\n## Set up authentication\n[Application Default Credentials (ADC)](/docs/authentication/application-default-credentials)\nFor production environments, the way you set up ADC depends on the service and context. For more information, see [Set up Application Default Credentials](/docs/authentication/provide-credentials-adc) .\nFor a local development environment, you can set up ADC with the credentials that are associated with your Google Account:\n- [Install and initialize the gcloud CLI](/sdk/docs/install) .When you initialize the gcloud CLI, be sure to specify a Google Cloud project in which you have permission to access the resources your application needs.\n- Create your credential file:```\ngcloud auth application-default login\n```A sign-in screen appears. After you sign in, your credentials are stored in the [local credential file used by ADC](/docs/authentication/application-default-credentials#personal) .\n## Use the client library\n[Document AI Toolbox](/document-ai/docs/toolbox) is an SDK for Python that provides utility functions for managing, manipulating, and extracting information from the document response. It creates a \"wrapped\" document object from a processed document response from JSON files in Cloud Storage, local JSON files, or output directly from the [process_document()](/document-ai/docs/reference/rest/v1/projects.locations.processors/process) method.\nIt can perform the following actions:\n- Combine fragmented [Document](/document-ai/docs/reference/rest/v1/Document) JSON files from Batch Processing into a single \"wrapped\" document.\n- Export shards as a unified [Document](/document-ai/docs/reference/rest/v1/Document) .\n- Get [Document](/document-ai/docs/reference/rest/v1/Document) output from:- [Cloud Storage](/storage) \n- [BatchProcessMetadata](/document-ai/docs/reference/rest/Shared.Types/BatchProcessMetadata) \n- [Operation name](/document-ai/docs/reference/rest/Shared.Types/ListOperationsResponse#Operation.FIELDS.name) \n- Access text from [Pages](/document-ai/docs/reference/rest/v1/Document#page) , [Lines](/document-ai/docs/reference/rest/v1/Document#line) , [Paragraphs](/document-ai/docs/reference/rest/v1/Document#paragraph) , [FormFields](/document-ai/docs/reference/rest/v1/Document#formfield) , and [Tables](/document-ai/docs/reference/rest/v1/Document#table) without handling [Layout](/document-ai/docs/reference/rest/v1/Document#Layout) information.\n- Search for a [Pages](/document-ai/docs/reference/rest/v1/Document#page) containing a target string or matching a regular expression.\n- Search for [FormFields](/document-ai/docs/reference/rest/v1/Document#formfield) by name.\n- Search for [Entities](/document-ai/docs/reference/rest/v1/Document#entity) by type.\n- Convert [Tables](/document-ai/docs/reference/rest/v1/Document#table) to a [Pandas](https://pandas.pydata.org/) Dataframe or CSV.\n- Insert [Entities](/document-ai/docs/reference/rest/v1/Document#entity) and [FormFields](/document-ai/docs/reference/rest/v1/Document#formfield) into a [BigQuery](/bigquery) table.\n- Split a PDF file based on [output from a Splitter/Classifier processor](#splitting) .\n- Extract image [Entities](/document-ai/docs/reference/rest/v1/Document#entity) from [Document](/document-ai/docs/reference/rest/v1/Document) [bounding boxes](/document-ai/docs/reference/rest/v1/Document#boundingpoly) .\n- Convert [Documents](/document-ai/docs/reference/rest/v1/Document) to and from commonly used formats:- [Cloud Vision API](/vision) [AnnotateFileResponse](/vision/docs/reference/rest/v1/BatchAnnotateFilesResponse#AnnotateFileResponse) \n- [hOCR](https://en.wikipedia.org/wiki/HOCR) \n- Third-party document processing formats\n- Create batches of documents for processing from a Cloud Storage folder.\n### Code Samples\nThe following code samples demonstrate how to use Document AI Toolbox.\n[View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/quickstart_sample.py) \n```\nfrom typing import Optionalfrom google.cloud import documentaifrom google.cloud.documentai_toolbox import documentfrom google.cloud.documentai_toolbox import gcs_utilities# TODO(developer): Uncomment these variables before running the sample.# Given a Document JSON or sharded Document JSON in path gs://bucket/path/to/folder# gcs_bucket_name = \"bucket\"# gcs_prefix = \"path/to/folder\"# Or, given a Document JSON in path gs://bucket/path/to/folder/document.json# gcs_uri = \"gs://bucket/path/to/folder/document.json\"# Or, given a Document JSON in path local/path/to/folder/document.json# document_path = \"local/path/to/folder/document.json\"# Or, given a Document object from Document AI# documentai_document = documentai.Document()# Or, given a BatchProcessMetadata object from Document AI# operation = client.batch_process_documents(request)# operation.result(timeout=timeout)# batch_process_metadata = documentai.BatchProcessMetadata(operation.metadata)# Or, given a BatchProcessOperation name from Document AI# batch_process_operation = \"projects/project_id/locations/location/operations/operation_id\"def quickstart_sample(\u00a0 \u00a0 gcs_bucket_name: Optional[str] = None,\u00a0 \u00a0 gcs_prefix: Optional[str] = None,\u00a0 \u00a0 gcs_uri: Optional[str] = None,\u00a0 \u00a0 document_path: Optional[str] = None,\u00a0 \u00a0 documentai_document: Optional[documentai.Document] = None,\u00a0 \u00a0 batch_process_metadata: Optional[documentai.BatchProcessMetadata] = None,\u00a0 \u00a0 batch_process_operation: Optional[str] = None,) -> document.Document:\u00a0 \u00a0 if gcs_bucket_name and gcs_prefix:\u00a0 \u00a0 \u00a0 \u00a0 # Load from Google Cloud Storage Directory\u00a0 \u00a0 \u00a0 \u00a0 print(\"Document structure in Cloud Storage\")\u00a0 \u00a0 \u00a0 \u00a0 gcs_utilities.print_gcs_document_tree(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 gcs_bucket_name=gcs_bucket_name, gcs_prefix=gcs_prefix\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document = document.Document.from_gcs(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 gcs_bucket_name=gcs_bucket_name, gcs_prefix=gcs_prefix\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 elif gcs_uri:\u00a0 \u00a0 \u00a0 \u00a0 # Load a single Document from a Google Cloud Storage URI\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document = document.Document.from_gcs_uri(gcs_uri=gcs_uri)\u00a0 \u00a0 elif document_path:\u00a0 \u00a0 \u00a0 \u00a0 # Load from local `Document` JSON file\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document = document.Document.from_document_path(document_path)\u00a0 \u00a0 elif documentai_document:\u00a0 \u00a0 \u00a0 \u00a0 # Load from `documentai.Document` object\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document = document.Document.from_documentai_document(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 documentai_document\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 elif batch_process_metadata:\u00a0 \u00a0 \u00a0 \u00a0 # Load Documents from `BatchProcessMetadata` object\u00a0 \u00a0 \u00a0 \u00a0 wrapped_documents = document.Document.from_batch_process_metadata(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 metadata=batch_process_metadata\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document = wrapped_documents[0]\u00a0 \u00a0 elif batch_process_operation:\u00a0 \u00a0 \u00a0 \u00a0 wrapped_documents = document.Document.from_batch_process_operation(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 location=\"us\", operation_name=batch_process_operation\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document = wrapped_documents[0]\u00a0 \u00a0 else:\u00a0 \u00a0 \u00a0 \u00a0 raise ValueError(\"No document source provided.\")\u00a0 \u00a0 # For all properties and methods, refer to:\u00a0 \u00a0 # https://cloud.google.com/python/docs/reference/documentai-toolbox/latest/google.cloud.documentai_toolbox.wrappers.document.Document\u00a0 \u00a0 print(\"Document Successfully Loaded!\")\u00a0 \u00a0 print(f\"\\t Number of Pages: {len(wrapped_document.pages)}\")\u00a0 \u00a0 print(f\"\\t Number of Entities: {len(wrapped_document.entities)}\")\u00a0 \u00a0 for page in wrapped_document.pages:\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Page {page.page_number}\")\u00a0 \u00a0 \u00a0 \u00a0 for block in page.blocks:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(block.text)\u00a0 \u00a0 \u00a0 \u00a0 for paragraph in page.paragraphs:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(paragraph.text)\u00a0 \u00a0 \u00a0 \u00a0 for line in page.lines:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(line.text)\u00a0 \u00a0 \u00a0 \u00a0 for token in page.tokens:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(token.text)\u00a0 \u00a0 \u00a0 \u00a0 # Only supported with Form Parser processor\u00a0 \u00a0 \u00a0 \u00a0 # https://cloud.google.com/document-ai/docs/form-parser\u00a0 \u00a0 \u00a0 \u00a0 for form_field in page.form_fields:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(f\"{form_field.field_name} : {form_field.field_value}\")\u00a0 \u00a0 \u00a0 \u00a0 # Only supported with Enterprise Document OCR version `pretrained-ocr-v2.0-2023-06-02`\u00a0 \u00a0 \u00a0 \u00a0 # https://cloud.google.com/document-ai/docs/process-documents-ocr#enable_symbols\u00a0 \u00a0 \u00a0 \u00a0 for symbol in page.symbols:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(symbol.text)\u00a0 \u00a0 \u00a0 \u00a0 # Only supported with Enterprise Document OCR version `pretrained-ocr-v2.0-2023-06-02`\u00a0 \u00a0 \u00a0 \u00a0 # https://cloud.google.com/document-ai/docs/process-documents-ocr#math_ocr\u00a0 \u00a0 \u00a0 \u00a0 for math_formula in page.math_formulas:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(math_formula.text)\u00a0 \u00a0 # Only supported with Entity Extraction processors\u00a0 \u00a0 # https://cloud.google.com/document-ai/docs/processors-list\u00a0 \u00a0 for entity in wrapped_document.entities:\u00a0 \u00a0 \u00a0 \u00a0 print(f\"{entity.type_} : {entity.mention_text}\")\u00a0 \u00a0 \u00a0 \u00a0 if entity.normalized_text:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(f\"\\tNormalized Text: {entity.normalized_text}\")\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/table_sample.py) \n```\nfrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a local document.proto or sharded document.proto in path# document_path = \"path/to/local/document.json\"# output_file_prefix = \"output/table\"def table_sample(document_path: str, output_file_prefix: str) -> None:\u00a0 \u00a0 wrapped_document = document.Document.from_document_path(document_path=document_path)\u00a0 \u00a0 print(\"Tables in Document\")\u00a0 \u00a0 for page in wrapped_document.pages:\u00a0 \u00a0 \u00a0 \u00a0 for table_index, table in enumerate(page.tables):\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Convert table to Pandas Dataframe\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Refer to https://pandas.pydata.org/docs/reference/frame.html for all supported methods\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 df = table.to_dataframe()\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print(df)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 output_filename = f\"{output_file_prefix}-{page.page_number}-{table_index}\"\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Write Dataframe to CSV file\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 df.to_csv(f\"{output_filename}.csv\", index=False)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Write Dataframe to HTML file\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 df.to_html(f\"{output_filename}.html\", index=False)\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # Write Dataframe to Markdown file\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 df.to_markdown(f\"{output_filename}.md\", index=False)\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/entities_to_bigquery_sample.py) \n```\nfrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a document.proto or sharded document.proto in path gs://bucket/path/to/folder# gcs_bucket_name = \"bucket\"# gcs_prefix = \"path/to/folder\"# dataset_name = \"test_dataset\"# table_name = \"test_table\"# project_id = \"YOUR_PROJECT_ID\"def entities_to_bigquery_sample(\u00a0 \u00a0 gcs_bucket_name: str,\u00a0 \u00a0 gcs_prefix: str,\u00a0 \u00a0 dataset_name: str,\u00a0 \u00a0 table_name: str,\u00a0 \u00a0 project_id: str,) -> None:\u00a0 \u00a0 wrapped_document = document.Document.from_gcs(\u00a0 \u00a0 \u00a0 \u00a0 gcs_bucket_name=gcs_bucket_name, gcs_prefix=gcs_prefix\u00a0 \u00a0 )\u00a0 \u00a0 job = wrapped_document.entities_to_bigquery(\u00a0 \u00a0 \u00a0 \u00a0 dataset_name=dataset_name, table_name=table_name, project_id=project_id\u00a0 \u00a0 )\u00a0 \u00a0 # Also supported:\u00a0 \u00a0 # job = wrapped_document.form_fields_to_bigquery(\u00a0 \u00a0 # \u00a0 \u00a0 dataset_name=dataset_name, table_name=table_name, project_id=project_id\u00a0 \u00a0 # )\u00a0 \u00a0 print(\"Document entities loaded into BigQuery\")\u00a0 \u00a0 print(f\"Job ID: {job.job_id}\")\u00a0 \u00a0 print(f\"Table: {job.destination.path}\")\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/split_pdf_sample.py) \n```\nfrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a local document.proto or sharded document.proto from a splitter/classifier in path# document_path = \"path/to/local/document.json\"# pdf_path = \"path/to/local/document.pdf\"# output_path = \"resources/output/\"def split_pdf_sample(document_path: str, pdf_path: str, output_path: str) -> None:\u00a0 \u00a0 wrapped_document = document.Document.from_document_path(document_path=document_path)\u00a0 \u00a0 output_files = wrapped_document.split_pdf(\u00a0 \u00a0 \u00a0 \u00a0 pdf_path=pdf_path, output_path=output_path\u00a0 \u00a0 )\u00a0 \u00a0 print(\"Document Successfully Split\")\u00a0 \u00a0 for output_file in output_files:\u00a0 \u00a0 \u00a0 \u00a0 print(output_file)\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/export_images_sample.py) \n```\nfrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a local document.proto or sharded document.proto from an identity processor in path# document_path = \"path/to/local/document.json\"# output_path = \"resources/output/\"# output_file_prefix = \"exported_photo\"# output_file_extension = \"png\"def export_images_sample(\u00a0 \u00a0 document_path: str,\u00a0 \u00a0 output_path: str,\u00a0 \u00a0 output_file_prefix: str,\u00a0 \u00a0 output_file_extension: str,) -> None:\u00a0 \u00a0 wrapped_document = document.Document.from_document_path(document_path=document_path)\u00a0 \u00a0 output_files = wrapped_document.export_images(\u00a0 \u00a0 \u00a0 \u00a0 output_path=output_path,\u00a0 \u00a0 \u00a0 \u00a0 output_file_prefix=output_file_prefix,\u00a0 \u00a0 \u00a0 \u00a0 output_file_extension=output_file_extension,\u00a0 \u00a0 )\u00a0 \u00a0 print(\"Images Successfully Exported\")\u00a0 \u00a0 for output_file in output_files:\u00a0 \u00a0 \u00a0 \u00a0 print(output_file)\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/convert_document_to_vision_sample.py) \n```\nfrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a document.proto or sharded document.proto in path gs://bucket/path/to/folder# gcs_bucket_name = \"bucket\"# gcs_prefix = \"path/to/folder\"def convert_document_to_vision_sample(\u00a0 \u00a0 gcs_bucket_name: str,\u00a0 \u00a0 gcs_prefix: str,) -> None:\u00a0 \u00a0 wrapped_document = document.Document.from_gcs(\u00a0 \u00a0 \u00a0 \u00a0 gcs_bucket_name=gcs_bucket_name, gcs_prefix=gcs_prefix\u00a0 \u00a0 )\u00a0 \u00a0 # Converting wrapped_document to vision AnnotateFileResponse\u00a0 \u00a0 annotate_file_response = (\u00a0 \u00a0 \u00a0 \u00a0 wrapped_document.convert_document_to_annotate_file_response()\u00a0 \u00a0 )\u00a0 \u00a0 print(\"Document converted to AnnotateFileResponse!\")\u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 f\"Number of Pages : {len(annotate_file_response.responses[0].full_text_annotation.pages)}\"\u00a0 \u00a0 )\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/convert_document_to_hocr_sample.py) \n```\nfrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a document.proto or sharded document.proto in path gs://bucket/path/to/folder# document_path = \"path/to/local/document.json\"# document_title = \"your-document-title\"def convert_document_to_hocr_sample(document_path: str, document_title: str) -> str:\u00a0 \u00a0 wrapped_document = document.Document.from_document_path(document_path=document_path)\u00a0 \u00a0 # Converting wrapped_document to hOCR format\u00a0 \u00a0 hocr_string = wrapped_document.export_hocr_str(title=document_title)\u00a0 \u00a0 print(\"Document converted to hOCR!\")\u00a0 \u00a0 return hocr_string\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/convert_external_annotations_sample.py) \n```\nfrom google.cloud.documentai_toolbox import converter# TODO(developer): Uncomment these variables before running the sample.# This sample will convert external annotations to the Document.json format used by Document AI Workbench for training.# To process this the external annotation must have these type of objects:# \u00a0 \u00a0 \u00a0 1) Type# \u00a0 \u00a0 \u00a0 2) Text# \u00a0 \u00a0 \u00a0 3) Bounding Box (bounding boxes must be 1 of the 3 optional types)\n## This is the bare minimum requirement to convert the annotations but for better accuracy you will need to also have:# \u00a0 \u00a0 \u00a0 1) Document width & height\n## Bounding Box Types:# \u00a0 Type 1:# \u00a0 \u00a0 \u00a0 bounding_box:[{\"x\":1,\"y\":2},{\"x\":2,\"y\":2},{\"x\":2,\"y\":3},{\"x\":1,\"y\":3}]# \u00a0 Type 2:# \u00a0 \u00a0 \u00a0 bounding_box:{ \"Width\": 1, \"Height\": 1, \"Left\": 1, \"Top\": 1}# \u00a0 Type 3:# \u00a0 \u00a0 \u00a0 bounding_box: [1,2,2,2,2,3,1,3]\n## \u00a0 Note: If these types are not sufficient you can propose a feature request or contribute the new type and conversion functionality.\n## Given a folders in gcs_input_path with the following structure :\n## gs://path/to/input/folder# \u00a0 \u251c\u2500\u2500test_annotations.json# \u00a0 \u251c\u2500\u2500test_config.json# \u00a0 \u2514\u2500\u2500test.pdf\n## An example of the config is in sample-converter-configs/Azure/form-config.json\n## location = \"us\",# processor_id = \"my_processor_id\"# gcs_input_path = \"gs://path/to/input/folder\"# gcs_output_path = \"gs://path/to/input/folder\"def convert_external_annotations_sample(\u00a0 \u00a0 location: str,\u00a0 \u00a0 processor_id: str,\u00a0 \u00a0 project_id: str,\u00a0 \u00a0 gcs_input_path: str,\u00a0 \u00a0 gcs_output_path: str,) -> None:\u00a0 \u00a0 converter.convert_from_config(\u00a0 \u00a0 \u00a0 \u00a0 project_id=project_id,\u00a0 \u00a0 \u00a0 \u00a0 location=location,\u00a0 \u00a0 \u00a0 \u00a0 processor_id=processor_id,\u00a0 \u00a0 \u00a0 \u00a0 gcs_input_path=gcs_input_path,\u00a0 \u00a0 \u00a0 \u00a0 gcs_output_path=gcs_output_path,\u00a0 \u00a0 )\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/create_batches_sample.py) \n```\nfrom google.cloud import documentaifrom google.cloud.documentai_toolbox import gcs_utilities# TODO(developer): Uncomment these variables before running the sample.# Given unprocessed documents in path gs://bucket/path/to/folder# gcs_bucket_name = \"bucket\"# gcs_prefix = \"path/to/folder\"# batch_size = 50def create_batches_sample(\u00a0 \u00a0 gcs_bucket_name: str,\u00a0 \u00a0 gcs_prefix: str,\u00a0 \u00a0 batch_size: int = 50,) -> None:\u00a0 \u00a0 # Creating batches of documents for processing\u00a0 \u00a0 batches = gcs_utilities.create_batches(\u00a0 \u00a0 \u00a0 \u00a0 gcs_bucket_name=gcs_bucket_name, gcs_prefix=gcs_prefix, batch_size=batch_size\u00a0 \u00a0 )\u00a0 \u00a0 print(f\"{len(batches)} batch(es) created.\")\u00a0 \u00a0 for batch in batches:\u00a0 \u00a0 \u00a0 \u00a0 print(f\"{len(batch.gcs_documents.documents)} files in batch.\")\u00a0 \u00a0 \u00a0 \u00a0 print(batch.gcs_documents.documents)\u00a0 \u00a0 \u00a0 \u00a0 # Use as input for batch_process_documents()\u00a0 \u00a0 \u00a0 \u00a0 # Refer to https://cloud.google.com/document-ai/docs/send-request\u00a0 \u00a0 \u00a0 \u00a0 # for how to send a batch processing request\u00a0 \u00a0 \u00a0 \u00a0 request = documentai.BatchProcessRequest(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 name=\"processor_name\", input_documents=batch\u00a0 \u00a0 \u00a0 \u00a0 )\n``` [View on GitHub](https://github.com/googleapis/python-documentai-toolbox/blob/HEAD/samples/snippets/merge_document_shards_sample.py) \n```\nfrom google.cloud import documentaifrom google.cloud.documentai_toolbox import document# TODO(developer): Uncomment these variables before running the sample.# Given a document.proto or sharded document.proto in path gs://bucket/path/to/folder# gcs_bucket_name = \"bucket\"# gcs_prefix = \"path/to/folder\"# output_file_name = \"path/to/folder/file.json\"def merge_document_shards_sample(\u00a0 \u00a0 gcs_bucket_name: str, gcs_prefix: str, output_file_name: str) -> None:\u00a0 \u00a0 wrapped_document = document.Document.from_gcs(\u00a0 \u00a0 \u00a0 \u00a0 gcs_bucket_name=gcs_bucket_name, gcs_prefix=gcs_prefix\u00a0 \u00a0 )\u00a0 \u00a0 merged_document = wrapped_document.to_merged_documentai_document()\u00a0 \u00a0 with open(output_file_name, \"w\") as f:\u00a0 \u00a0 \u00a0 \u00a0 f.write(documentai.Document.to_json(merged_document))\u00a0 \u00a0 print(f\"Document with {len(wrapped_document.shards)} shards successfully merged.\")\n```\n[](None)\n## Additional resources\nThe following list contains links to more resources related to the client library for Python:- [API reference](/python/docs/reference/documentai-toolbox/latest) \n- [Client libraries best practices](/apis/docs/client-libraries-best-practices) \n- [Issue tracker](https://github.com/googleapis/python-documentai-toolbox/issues) \n- [cloud-document-ai on Stack Overflow](https://stackoverflow.com/search?q=%5Bcloud-document-ai%5D+%5Bpython%5D) \n- [Source code](https://github.com/googleapis/python-documentai-toolbox)", "guide": "Document AI"}