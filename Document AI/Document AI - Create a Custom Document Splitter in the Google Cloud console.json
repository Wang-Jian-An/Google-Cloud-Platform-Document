{"title": "Document AI - Create a Custom Document Splitter in the Google Cloud console", "url": "https://cloud.google.com/document-ai/docs/workbench/build-custom-splitter-processor?hl=zh-cn", "abstract": "# Document AI - Create a Custom Document Splitter in the Google Cloud console\n# Create a Custom Document Splitter in the Google Cloud console\nYou can create Custom Document Splitters (CDS) that are specifically suited to your documents, and trained and evaluated with your data. This processor identifies classes of documents from a user-defined set of classes. You can then use this trained processor on additional documents. You typically would use a CDS on documents that are different types, then use the identification to pass the documents to an extraction processor to extract the entities.\nA typical workflow to create and use a CDS is as follows:- Create a Custom Document Splitter in Document AI Workbench.\n- Create a dataset using an empty Cloud Storage bucket.\n- Define and create the processor schema.\n- Import documents.\n- Assign documents to the Training and Test sets.\n- Annotate documents manually in Document AI Workbench or with Labeling Tasks.\n- Train the processor.\n- Evaluate the processor.\n- Deploy the processor.\n- Test the processor.\n- Use the processor on your documents.\nYou can make your own configuration choices that suit your workflow.\nThis guide describes how to use Document AI Workbench to create and train a Custom Document Splitter that splits and classifies procurement documents. Most of the document preparation work has been done so that you can focus on the other mechanics of creating a CDS.To follow step-by-step guidance for this task directly in the Google Cloud console, click **Guide me** :\n [Guide me](https://console.cloud.google.com/ai/document-ai?tutorial=document-ai--documentai-workbench_custom_splitter_console) ", "content": "## Before you begin\n## Create a processor\n- In the Google Cloud console, in the Document AI section, go to the **Workbench** page. [Workbench](https://console.cloud.google.com/ai/document-ai/workbench) \n- For **Custom Document Splitter** , click . \n- In the **Create processor** menu, enter a name for your processor, such as `my-custom-document-splitter` . \n- Select the region closest to you.\n- Click **Create** . The **Processor Details** tab appears.\n## Create a Cloud Storage bucket for the datasetIn order to train this new processor, you must create a dataset with training and testing data to help the processor identify the documents that you want to split and classify.\nThis dataset requires a new [Cloud Storage bucket](/storage) . Do not use the same bucket where your documents are currently stored.- Go to your processor's tab.\n- You have the option to let Google create a Cloud Storage bucket for you, or you can use your own. For this tutorial, select **Google-managed storage** under **Advanced Options** .\n- Click to create the dataset. Creating the dataset might take several minutes. \n## Define processor schemaYou can create the processor schema either before or after you import documents into your dataset. The schema provides labels that you will use to annotate documents.- On the **Train** tab, click in the lower left. The **Manage labels** page opens.\n- Click .\n- Enter the name for the label. Click **Create** . Refer to [Define processor schema](/document-ai/docs/workbench/label-documents#define_processor_schema) for detailed instructions on creating and editing a schema. **Note:** Labels cannot be deleted. Instead, you can disable any label you do not want to use.\n- Create each of the following labels for the processor schema.- `bank_statement`\n- `form_1040`\n- `form_w2`\n- `form_w9`\n- `paystub`\n- Click when the labels are complete. \n## Import an unlabeled document into a datasetNext, you import an unlabeled document into your dataset and label it.\nIf working on your own project, you determine how to label your data. Refer to [Labeling options](/document-ai/docs/workbench/label-documents#labeling_options) .\nDocument AI Custom Processors require a minimum of 10 documents in the training and test sets, along with 10 instances of each label in each set. We recommend at least 50 documents in each set, with 50 instances of each label for best performance. In general, more training data produces higher accuracy.- On the **Train** tab, click . \n- For this example, enter this path in . This contains one document PDF.```\ncloud-samples-data/documentai/Custom/Lending-Splitter/PDF-Unlabeled\n```\n- Set the as **None** .\n- Set the dropdown to **Unassigned** .The document in this folder is not given a label or assigned to the testing or training set by default.\n- Click . Document AI reads the documents from the bucket into the dataset. It does not modify the import bucket or read from the bucket after the import is complete.\nWhen you import documents, you can optionally assign the documents to the **Training** or **Test** set when imported, or wait to assign them later.\nIf you want to delete a document or documents that you have imported, select them on the **Train** tab, and click **Delete** .\nFor more information about preparing your data for import, refer to the [Data preparation guide](/document-ai/docs/workbench/create-dataset) .## Label a documentThe process of applying labels to a document is known as .- Return to the **Train** tab, and click to open the **Label management** console.\n- This document contains multiple page groups that need to be identified and labeled. First, you need to identify the split points. Move your mouse in between pages **1** and **2** in the image view and click on the . \n- Create split points before the following page numbers: **2** , **3** , **4** , **5** .Your console should look like this when finished. \n- In the , select the appropriate label for each page group.| Page(s) | Document type |\n|:----------|:----------------|\n| 1   | paystub   |\n| 2   | form_w9   |\n| 3   | bank_statement |\n| 4   | form_w2   |\n| 5 & 6  | form_1040  |The labeled document should look like this when complete: \n- Click when you have finished annotating the document.On the **Train** tab, the left-hand panel shows that 1 document has been labeled.\n## Assign annotated document to the training setNow that you have labeled this example document, you can assign it to the training set.- On the **Train** tab, select the checkbox.\n- From the list, select **Training** .\nIn the left-hand panel, you can find that 1 document has been assigned to the training set.## Import data with batch labelingNext, you import unlabeled PDF files that are sorted into different Cloud Storage folders by their type. Batch labeling helps save time on labeling by assigning a label at import time based on the file path.- On the **Train** tab, click .\n- Enter the following path in . This folder contains PDFs of bank statements.```\ncloud-samples-data/documentai/Custom/Lending-Splitter/PDF-CDS-BatchLabel/bank-statement\n```\n- Set the as `bank_statement` .\n- Set the dropdown to **Auto-split** . This automatically splits the documents to have 80% in the training set and 20% in the test set.\n- Click to add more folders.\n- Repeat the previous steps with the following paths and document labels:| Bucket path                  | Document label |\n|:---------------------------------------------------------------------------------|:-----------------|\n| cloud-samples-data/documentai/Custom/Lending-Splitter/PDF-CDS-BatchLabel/1040 | form_1040  |\n| cloud-samples-data/documentai/Custom/Lending-Splitter/PDF-CDS-BatchLabel/w2  | form_w2   |\n| cloud-samples-data/documentai/Custom/Lending-Splitter/PDF-CDS-BatchLabel/w9  | form_w9   |\n| cloud-samples-data/documentai/Custom/Lending-Splitter/PDF-CDS-BatchLabel/paystub | paystub   |The console should look like this when complete: \n- Click . The import takes several minutes.\nWhen the import is finished, find the documents on the **Train** tab.## Import prelabeled dataIn this guide, you are provided with prelabeled data in the [Document](/document-ai/docs/reference/rest/v1/Document) format as JSON files.\nThis is the same format that Document AI outputs when processing a document, labeling with Human-in-the-Loop, or [exporting a dataset](/document-ai/docs/workbench/label-documents#export_dataset) .- On the **Train** tab, click .\n- Enter the following path in .```\ncloud-samples-data/documentai/Custom/Lending-Splitter/JSON-Labeled\n```\n- Set the as **None** .\n- Set the dropdown to **Auto-split** .\n- Click .\nWhen the import is finished, find the documents on the **Train** tab.## Train the processorNow that you have imported the training and test data, you can train the processor. Because training might take several hours, make sure you have set up the processor with the appropriate data and labels before you begin training.- Click .\n- In the field, enter a name for this processor version, such as `my-cds-version-1` .\n- (Optional) Click **View Label Stats** to find information about the document labels. That can help determine your coverage. Click **Close** to return to the training setup.\n- Click You can check the status on the right-hand panel.\n## Deploy the processor version\n- After training is complete, navigate to the tab. You can view details about the version you just trained.\n- Click the on the right of the version you want to deploy, and select **Deploy version** .\n- Select from the popup window.Deployment takes a few minutes to complete.\n## Evaluate and test the processor\n- After deployment is complete, navigate to the tab.On this page, you can view evaluation metrics including the F1 score, Precision and Recall for the full document, and individual labels. For more information about evaluation and statistics, refer to [Evaluate processor](/document-ai/docs/workbench/evaluate) .\n- Download a document that has not been involved in previous training or testing so that you can use it to evaluate the processor version. If using your own data, you would use a document set aside for this purpose. [file_downloadDownload PDF](https://storage.googleapis.com/cloud-samples-data/documentai/Custom/Lending-Splitter/PDF-Inference/inference_cds.pdf) \n- Click and select the document you just downloaded.The **Custom Document Splitter analysis** page opens. The screen output will demonstrate how well the document was split and classified.The console should look like this when complete: You can also re-run the evaluation against a different test set or processor version.\n## (Optional) Import data with autolabelingAfter deploying a trained processor version, you can use [Auto-labeling](/document-ai/docs/workbench/label-documents#auto-label) to save time on labeling when importing new documents.- On the **Train** tab, click .\n- Enter the following path in . This folder contains unlabeled PDFs of multiple document types.```\ncloud-samples-data/documentai/Custom/Lending-Splitter/PDF-CDS-AutoLabel\n```\n- Set the as **Auto-label** .\n- Set the dropdown to **Auto-split** .\n- In the **Auto-labeling** section, set the as the version you previously trained.- For example:`2af620b2fd4d1fcf`\n- Click and wait for the documents to import.\n- You cannot use autolabeled documents for training or testing without marking them as labeled. Go to the section to view the autolabeled documents.\n- Select the first document to enter the labeling console.\n- Verify the label to ensure it's correct, and adjust if not.\n- Select when finished.\n- Repeat the label verification for each autolabeled document.\n- Return to the **Train** page and click **Train New Version** to use the data for training.\n## Use the processorYou have successfully created and trained a Custom Document Splitter processor.\nYou can manage your custom-trained processor versions just like any other processor version. For more information, refer to [Managing processor versions](/document-ai/docs/manage-processor-versions) .\nOnce deployed, you can [Send a processing request](/document-ai/docs/send-request) to your custom processor, and the [response can be handled the same as other splitter processors](/document-ai/docs/splitters) .## Clean upTo avoid incurring charges to your Google Cloud account for   the resources used on this page, follow these steps.\nTo avoid unnecessary Google Cloud charges, use the [Google Cloud console](https://console.cloud.google.com/) to delete your processor and project if you do not need them.\nIf you created a new project to learn about Document AI and you no longer need the project, [delete the project](https://console.cloud.google.com/cloud-resource-manager) .\nIf you used an existing Google Cloud project, delete the resources you created to avoid incurring charges to your account:- In the Google Cloud console navigation menu, click **Document AI** and select **My Processors** .\n- Click in the same row as the processor you want to delete.\n- Click **Delete processor** , type the processor name, then click **Delete** again to confirm.\n## What's next\n- [Creating and using a Custom Document Extractor](/document-ai/docs/workbench/build-custom-processor) \n- [Creating and using a Custom Document Classifier](/document-ai/docs/workbench/build-custom-classification-processor)", "guide": "Document AI"}