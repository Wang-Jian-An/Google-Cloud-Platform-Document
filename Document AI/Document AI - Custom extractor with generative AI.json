{"title": "Document AI - Custom extractor with generative AI", "url": "https://cloud.google.com/document-ai/docs/workbench/cde-with-genai?hl=zh-cn", "abstract": "# Document AI - Custom extractor with generative AI\n# Custom extractor with generative AI\nGenerative AI training and extraction allows you to:\n- Use zero-shot and few-shot technology to get a high performing model with little to no training data using the foundation model.\n- Use fine-tuning to further boost accuracy as you provide more and more training data.", "content": "## Generative AI training methods\nThe training method you choose depends on the amount of documents you have available and the amount of effort available to put into training your model. There are three ways to train a generative AI model:\n| Training method       | Zero-shot | Few-shot | Fine-tuning |\n|:-----------------------------------------|:------------|:------------|:--------------|\n| Accuracy         | Medium  | Medium-high | High   |\n| Effort         | Low   | Low   | Medium  |\n| Recommended number of training documents | 0   | 5 to 10  | 10 to 50+  |\n## Before getting started\nIf not done so already, enable billing and the [Document AI APIs](/document-ai/docs/setup) .\n**Note:** Takes some time for each training to complete.\n## Build and evaluate a generative AI model\n- [Create a processor](/document-ai/docs/workbench/build-custom-processor#create_a_processor) and [define fields](/document-ai/docs/workbench/build-custom-processor#define_processor_fields) you want to extract following [best practices](/document-ai/docs/workbench/label-documents#name-fields) , which is important because it impacts extraction quality.- Go to Workbench > Custom extractor > Create processor > Assign a name.\n- Go to Get started > Create new field.\n **Note:** The field names with the foundation model can greatly affect model accuracy and performance. A descriptive name is recommended.\n- Import documents- Import documents with [auto-labeling](#auto-labeling) and assign documents to the training and test set.\n- For zero-shot, only the schema is required. To evaluate the accuracy of the model, only a testing set is needed.\n- For few-shot, we recommend five training documents.\n- The number of needed testing documents depend on the use case. Generally, more testing documents is better.\n- Confirm or edit the [labels in the document](/document-ai/docs/workbench/build-custom-processor#label_a_document) .\n- Train model:- Select the **Build** tab and **Create new version** .\n- Enter a name and select **Create** .\n- Evaluation:- Go to **Evaluate & test** , select the version you just trained, then select **View full evaluation** .\n- You now see metrics such as [f1, precision, and recall](/document-ai/docs/workbench/evaluate#all-labels) for the entire document and each field.\n- Decide if performance meets your production goals. If it does not then reevaluate training and testing sets.\n- Set a new version as default:- Navigate to **Manage versions** .\n- Select to expand the options, and then select **Set as default** .\n **Note:** Ensure the **Status** of the version is deployed. If it is not, select the deploy version first. You can now set the new version as the default.Your model is now deployed. Documents sent to this processor use your custom version. You can evaluate the [model's performance](/document-ai/docs/workbench/evaluate) to check if it requires further training.## Evaluation reference\nThe evaluation engine can do both exact match or [fuzzy matching](/document-ai/docs/workbench/evaluate?_ga=2.20724541.-441119927.1706559262#fuzzy_matching) . For an exact match, the extracted value must exactly match the ground truth or is counted as a miss.\nFuzzy matching extractions that had slight differences such as capitalization differences still count as a match. This can be changed at the **Evaluation** screen.\n## Fine-tuning\nWith fine-tuning, you use hundreds or thousands of documents for your training.\n- Create a processor and define fields you want to extract following [best practices](/document-ai/docs/workbench/label-documents#name-fields) , which is important because it impacts extraction quality. **Note:** The field names with the foundation model can greatly affect model accuracy and performance. Be sure to give a descriptive name.\n- Import documents with auto-labeling, and assign documents to the training and test set.\n- Confirm or edit the [labels in the document](/document-ai/docs/workbench/build-custom-processor#label_a_document) .\n- Train model.- Select the **Build** tab and select **Create New Version** .\n- Try out the default training parameters or values provided. If the results are unsatisfactory, experiment with these advanced options:\n- Training steps (between 100 and 400): Controls how often the weights are optimized on a batch of data during the tuning.- Too low indicates a risk that the training ends before convergence (under-fitting).\n- Too high means the model might see the same batch of data multiple times during the training, which can lead to overfitting.\n- Fewer steps leads to faster training time. Higher counts can help for documents with little template variation (and lower ones for those with more variation).\n- Learning rate multiplier (between 0.1 and 10): Controls how quickly the model parameters are optimized on the training data. It roughly corresponds to the size of each training step.- Low rates mean small changes in the model weights at each training step. If too low, the model might not converge to a stable solution.\n- High rates indicate large changes, and too high can mean the model steps over the optimal solution and converges instead to a suboptimal solution.\n- Training time is not affected by the choice of learning rate.- Give a name and select **Create** .\n- Evaluation: Go to **Evaluate & test** , then select the version you just trained and select **View full evaluation** .- You now see metrics such as [f1, precision, and recall](/document-ai/docs/workbench/evaluate#all-labels) for the entire document and each field.\n- Decide if performance meets your production goals. If not, then further training documents might be required.\n- Set a new version as the default:- Navigate to **Manage versions** .\n- Select to expand the options, and select **Set as default** .\n **Note:** Ensure the status of the version is deployed. If it's not, then instead select **Deploy version** . You can now set the new version as the default when its status is changed to deployed.Your model is now deployed and documents sent to this processor now use your custom version. You want to evaluate the [model's performance](/document-ai/docs/workbench/evaluate) to check if it requires further training.## Auto-labeling with the foundation model\nThe foundation model can accurately extract fields for a variety of document types, but you can also provide additional training data to improve the accuracy of the model for specific document structures.\nDocument AI uses the label names you define and previous annotations to make it quicker and easier to label documents at scale with auto-labeling.\n- When you've created a custom processor, go to the **Get Started** tab.\n- Select **Create New Field** . **Note:** The label names with the foundation model can greatly affect model accuracy and performance. Be sure to give a descriptive name.\n- Navigate to the **Build** tab then select **Import Documents** .\n- Select the path of the documents and which set the documents should be imported into. Check the auto-labeling option and select the foundation model.\n- In the **Build** tab, select **Manage Dataset** .\n- When you see your imported documents, select one of them.\nThe predictions from the model are now shown highlighted in purple.\n- Review each label predicted by the model, and ensure it's correct.\n- If there are missing fields, add those as well. **Note:** It's important that all fields are as accurate as possible, or model performance will suffer. More details on [labeling](/document-ai/docs/workbench/label-documents) \n- When the document has been reviewed, select **Mark as Labeled** . The document is now ready to be used by the model.\n- Make sure the document is in either the testing or training set.## Three-level nesting\nCustom Extractor now provides three levels of nesting. This feature provides better extraction for complex tables.\n**Note:** Three levels of nesting is only supported if using generative AI (\"Foundation\") model types within the Custom Extractor. Extract, classify, and splitting models only support two levels of nesting.\nYou can determine the model type using the following API calls:\n- [processors.get](/document-ai/docs/reference/rest/v1beta3/projects.locations.processors/get) \n- [processorVersions.get](/document-ai/docs/reference/rest/v1beta3/projects.locations.processors.processorVersions/get) \nThe response of these is a [ProcessorVersion](/document-ai/docs/reference/rest/v1beta3/projects.locations.processors.processorVersions#resource:-processorversion) , which contains the `modelType` field in [v1beta3 preview](/document-ai/docs/reference/rest/v1beta3/projects.locations.processors.processorVersions#modeltype) .\n### Procedure and example\nWe are using this sample:- Select **Get Started** , and then create a field:- Create the top level.\n- In this sample, the`officer_appointments`is used.\n- Select **This is a parent label** .\n- Select **Occurrence** :`Optional multiple`.\n \n- Select **Add child field** . The second level label can now be created:- For this level label, create`officer`.\n- Select **This is a parent label** .\n- Select **Occurrence** :`Optional multiple`.\n \n- Select **Add child field** from second level `officer` . Create child labels for the third level of nesting. \n- When your schema is set, you can get predictions from documents with three levels of nesting using auto-labeling. ## Dataset configuration\nA document dataset is required to train, uptrain, or evaluate a processor version. Document AI processors learns from examples, just like humans. Dataset fuels processor stability in terms of performance.\n### Train dataset\nTrain a dataset to improve the model and accuracy on your documents. The model is made up of documents with ground-truth.\n- For fine-tuning, you need a minimum of 10 documents to train a new model.\n- For a few-shot, 5 documents is recommended.\n- For zero-shot, only a schema is required.\n**Note:** Ground-truth is the correctly labeled data, as determined by humans.\n### Test dataset\nThe test dataset is what the model uses to generate an F1 score (accuracy). It is made up of documents with ground-truth. To see how often the model is right, the ground truth is used to compare the model's predictions (extracted fields from the model) with the correct answers. The test dataset should have at least 10 documents for fine-tuning. An evaluation on your test set is automatically performed after training your first generative AI model and can be seen by checking the **Evaluate & Test** tab.\n## What's next\n[Uptrain a specialized processor](/document-ai/docs/workbench/uptrain-processor)", "guide": "Document AI"}