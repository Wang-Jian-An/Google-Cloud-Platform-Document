{"title": "Document AI - CDE template-based extraction user guide", "url": "https://cloud.google.com/document-ai/docs/workbench/cde-template-based-guide?hl=zh-cn", "abstract": "# Document AI - CDE template-based extraction user guide\n# CDE template-based extraction user guide\nThis page describes how to apply this Document AI Workbench custom document extractor.\n", "content": "## Overview\nTemplate-based training and extraction allows you to:\n- Train a high-performing model with as little as three training and three test documents for fixed-layout use cases.\n- Accelerate development and reduce time to production for templated document types like W9, 1040, ACORD, surveys, and questionnaires.\n- Choose a template-based or model-based training approach in one place.## Labeling best practices\n- Label all occurrences of each schema label.\n- Draw bounding boxes around the entire area you expect data to be in (per label) within a document, even if the label is empty in the training document you're labeling.\n- You may label empty fields for template-based training. Do not label empty fields for model-based training. It degrades model performance.\n- Label only child entities instead of parent entities, which are only containers without data required for labeling.\n- Select only the check box and not any associated text with the bounding box tool. Ensure that the check-box entity corresponds to what's in the document.\n**Good.** Labeling example for template-based training to extract the top section of a 1040.\n**Bad.** Labeling example for template-based training to extract the top section of a 1040. This is the labeling technique you should use for model-based training for documents with layout variation across documents.\n## Perform template-based extraction\n- Create a custom document extractor.- Navigate to Document AI Workbench to create your processor.\n- Scroll to the bottom and select **Custom Document Extractor** .\n- Give the CDE the name of the processor.\n- Set dataset location. Select the default option folder (Google-managed).\n- Import documents.- Select **Import documents** . The dataset has limitations:- 5,000 for document-import limit\n- 30,000 for dataset limit\n- Choose **Split type** . There are three options to use:- Training set, with a target of up to three documents\n- Test set, with at least three documents\n- Unassigned **Note:** Make sure documents have similar layout and template. If there's variation in the document layout, then use model-based training, not template-based.\n- Create schema.- Select **Edit Schema** and then select **Add new label** .\n- Select **Correct data type and occurrence** .\n- Save changes and go back to **Train UI** .\n **Note:** Use occurrence type for best results.\n- Determine split type. You can select a document and assign a split type to move it to a training or test set. There's a minimum of three documents in the training set and three in the test set. Adding more documents typically doesn't improve quality for template-based training. Rather than adding more documents, focus on labeling a small set of very accurately labeled docs. See the [labeling best practices](#labeling_best_practices) section later in this document.\n- Label training and test documents.- Click into document.\n- Use the bounding box tool to annotate all labels.\n- Are required at least three training documents, three test documents and three schema labels per set.\n **Note:** You can experiment by increasing the training set size if you observe template variations in your dataset. Try to include at least three training documents per variation: at least three training documents, three test documents, and three schema labels are required per set.\n- Train model.- Click on **Train new version** .\n- Name the processor version.\n- Go to **Show advanced options** and select the **template-based** model approach.\n- Deploy model.- Navigate to **Manage versions** .\n- View the F1 score, which is calculated based on your test dataset. If you want a more robust evaluation, add more documents to the test dataset.\n- Click to see the options and choose **Deploy version** .**Note:** The training time takes up to 30 minutes.\n- Import Documents with the auto-label feature.Import more documents using auto-label at import to take advantage of labeling efficiency. All you need to do is confirm or edit the model predictions within your dataset. This can help you build a larger dataset to more robustly evaluate model accuracy.## Supported features and limitations\n| Feature   | Description           | Supported |\n|:----------------|:-----------------------------------------------------|------------:|\n| Checkboxes  | Support for extract and convert data from checkboxes |   nan |\n| Nested entities | Entities nested into subcategories     |   nan |\n| Multipage  | Data when documents are similar      |   nan |\n| Auto-labeling | Auto-labeling feature supported for documents  |   nan |\n## Feedback\nTo submit feedback, bugs or feature requests, use [this form](https://docs.google.com/forms/d/e/1FAIpQLSeZdrsJ8c-8GpiAgZ1cjFVf2kEadIrN05ZjIQtaNygt8CEcNw/viewform?resourcekey=0-BqpBXS8UKpc3BiQwKNXm9A) .\n## What's next\n[Evaluate processor performance](/document-ai/docs/workbench/evaluate)", "guide": "Document AI"}