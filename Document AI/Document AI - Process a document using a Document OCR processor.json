{"title": "Document AI - Process a document using a Document OCR processor", "url": "https://cloud.google.com/document-ai/docs/samples/documentai-process-ocr-document?hl=zh-cn", "abstract": "# Document AI - Process a document using a Document OCR processor\nSends an online processing request to a Document OCR processor and parses the response. Extracts and prints full text, page dimensions, detected languages, paragraphs, blocks, lines, and tokens.", "content": "## Explore furtherFor detailed documentation that includes this code sample, see the following:- [Handling the processing response](/document-ai/docs/handle-response) \n- [Use Enterprise Document OCR to process documents](/document-ai/docs/process-documents-ocr) \n## Code sampleFor more information, see the [Document AI Java API reference documentation](/java/docs/reference/google-cloud-document-ai/latest/overview) .\nTo authenticate to Document AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/java-docs-samples/blob/HEAD/document-ai/src/main/java/documentai/v1beta3/ProcessOcrDocument.java) \n```\nimport com.google.cloud.documentai.v1beta3.Document;import com.google.cloud.documentai.v1beta3.DocumentProcessorServiceClient;import com.google.cloud.documentai.v1beta3.DocumentProcessorServiceSettings;import com.google.cloud.documentai.v1beta3.ProcessRequest;import com.google.cloud.documentai.v1beta3.ProcessResponse;import com.google.cloud.documentai.v1beta3.RawDocument;import com.google.protobuf.ByteString;import java.io.IOException;import java.nio.file.Files;import java.nio.file.Paths;import java.util.List;import java.util.concurrent.ExecutionException;import java.util.concurrent.TimeoutException;public class ProcessOcrDocument {\u00a0 public static void processOcrDocument()\u00a0 \u00a0 \u00a0 throws IOException, InterruptedException, ExecutionException, TimeoutException {\u00a0 \u00a0 // TODO(developer): Replace these variables before running the sample.\u00a0 \u00a0 String projectId = \"your-project-id\";\u00a0 \u00a0 String location = \"your-project-location\"; // Format is \"us\" or \"eu\".\u00a0 \u00a0 String processerId = \"your-processor-id\";\u00a0 \u00a0 String filePath = \"path/to/input/file.pdf\";\u00a0 \u00a0 processOcrDocument(projectId, location, processerId, filePath);\u00a0 }\u00a0 public static void processOcrDocument(\u00a0 \u00a0 \u00a0 String projectId, String location, String processorId, String filePath)\u00a0 \u00a0 \u00a0 throws IOException, InterruptedException, ExecutionException, TimeoutException {\u00a0 \u00a0 // Initialize client that will be used to send requests. This client only needs\u00a0 \u00a0 // to be created\u00a0 \u00a0 // once, and can be reused for multiple requests. After completing all of your\u00a0 \u00a0 // requests, call\u00a0 \u00a0 // the \"close\" method on the client to safely clean up any remaining background\u00a0 \u00a0 // resources.\u00a0 \u00a0 String endpoint = String.format(\"%s-documentai.googleapis.com:443\", location);\u00a0 \u00a0 DocumentProcessorServiceSettings settings =\u00a0 \u00a0 \u00a0 \u00a0 DocumentProcessorServiceSettings.newBuilder().setEndpoint(endpoint).build();\u00a0 \u00a0 try (DocumentProcessorServiceClient client = DocumentProcessorServiceClient.create(settings)) {\u00a0 \u00a0 \u00a0 // The full resource name of the processor, e.g.:\u00a0 \u00a0 \u00a0 // projects/project-id/locations/location/processor/processor-id\u00a0 \u00a0 \u00a0 // You must create new processors in the Cloud Console first\u00a0 \u00a0 \u00a0 String name =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 String.format(\"projects/%s/locations/%s/processors/%s\", projectId, location, processorId);\u00a0 \u00a0 \u00a0 // Read the file.\u00a0 \u00a0 \u00a0 byte[] imageFileData = Files.readAllBytes(Paths.get(filePath));\u00a0 \u00a0 \u00a0 // Convert the image data to a Buffer and base64 encode it.\u00a0 \u00a0 \u00a0 ByteString content = ByteString.copyFrom(imageFileData);\u00a0 \u00a0 \u00a0 RawDocument document =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 RawDocument.newBuilder().setContent(content).setMimeType(\"application/pdf\").build();\u00a0 \u00a0 \u00a0 // Configure the process request.\u00a0 \u00a0 \u00a0 ProcessRequest request =\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ProcessRequest.newBuilder().setName(name).setRawDocument(document).build();\u00a0 \u00a0 \u00a0 // Recognizes text entities in the PDF document\u00a0 \u00a0 \u00a0 ProcessResponse result = client.processDocument(request);\u00a0 \u00a0 \u00a0 Document documentResponse = result.getDocument();\u00a0 \u00a0 \u00a0 System.out.println(\"Document processing complete.\");\u00a0 \u00a0 \u00a0 // Read the text recognition output from the processor\u00a0 \u00a0 \u00a0 // For a full list of Document object attributes,\u00a0 \u00a0 \u00a0 // please reference this page:\u00a0 \u00a0 \u00a0 // https://googleapis.dev/java/google-cloud-document-ai/latest/index.html\u00a0 \u00a0 \u00a0 // Get all of the document text as one big string\u00a0 \u00a0 \u00a0 String text = documentResponse.getText();\u00a0 \u00a0 \u00a0 System.out.printf(\"Full document text: '%s'\\n\", escapeNewlines(text));\u00a0 \u00a0 \u00a0 // Read the text recognition output from the processor\u00a0 \u00a0 \u00a0 List<Document.Page> pages = documentResponse.getPagesList();\u00a0 \u00a0 \u00a0 System.out.printf(\"There are %s page(s) in this document.\\n\", pages.size());\u00a0 \u00a0 \u00a0 for (Document.Page page : pages) {\u00a0 \u00a0 \u00a0 \u00a0 System.out.printf(\"Page %d:\\n\", page.getPageNumber());\u00a0 \u00a0 \u00a0 \u00a0 printPageDimensions(page.getDimension());\u00a0 \u00a0 \u00a0 \u00a0 printDetectedLanguages(page.getDetectedLanguagesList());\u00a0 \u00a0 \u00a0 \u00a0 printParagraphs(page.getParagraphsList(), text);\u00a0 \u00a0 \u00a0 \u00a0 printBlocks(page.getBlocksList(), text);\u00a0 \u00a0 \u00a0 \u00a0 printLines(page.getLinesList(), text);\u00a0 \u00a0 \u00a0 \u00a0 printTokens(page.getTokensList(), text);\u00a0 \u00a0 \u00a0 }\u00a0 \u00a0 }\u00a0 }\u00a0 private static void printPageDimensions(Document.Page.Dimension dimension) {\u00a0 \u00a0 String unit = dimension.getUnit();\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0Width: %.1f %s\\n\", dimension.getWidth(), unit);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0Height: %.1f %s\\n\", dimension.getHeight(), unit);\u00a0 }\u00a0 private static void printDetectedLanguages(\u00a0 \u00a0 \u00a0 List<Document.Page.DetectedLanguage> detectedLangauges) {\u00a0 \u00a0 System.out.println(\" \u00a0 \u00a0Detected languages:\");\u00a0 \u00a0 for (Document.Page.DetectedLanguage detectedLanguage : detectedLangauges) {\u00a0 \u00a0 \u00a0 String languageCode = detectedLanguage.getLanguageCode();\u00a0 \u00a0 \u00a0 float confidence = detectedLanguage.getConfidence();\u00a0 \u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0%s (%.2f%%)\\n\", languageCode, confidence * 100.0);\u00a0 \u00a0 }\u00a0 }\u00a0 private static void printParagraphs(List<Document.Page.Paragraph> paragraphs, String text) {\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0%d paragraphs detected:\\n\", paragraphs.size());\u00a0 \u00a0 Document.Page.Paragraph firstParagraph = paragraphs.get(0);\u00a0 \u00a0 String firstParagraphText = getLayoutText(firstParagraph.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0First paragraph text: %s\\n\", escapeNewlines(firstParagraphText));\u00a0 \u00a0 Document.Page.Paragraph lastParagraph = paragraphs.get(paragraphs.size() - 1);\u00a0 \u00a0 String lastParagraphText = getLayoutText(lastParagraph.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0Last paragraph text: %s\\n\", escapeNewlines(lastParagraphText));\u00a0 }\u00a0 private static void printBlocks(List<Document.Page.Block> blocks, String text) {\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0%d blocks detected:\\n\", blocks.size());\u00a0 \u00a0 Document.Page.Block firstBlock = blocks.get(0);\u00a0 \u00a0 String firstBlockText = getLayoutText(firstBlock.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0First block text: %s\\n\", escapeNewlines(firstBlockText));\u00a0 \u00a0 Document.Page.Block lastBlock = blocks.get(blocks.size() - 1);\u00a0 \u00a0 String lastBlockText = getLayoutText(lastBlock.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0Last block text: %s\\n\", escapeNewlines(lastBlockText));\u00a0 }\u00a0 private static void printLines(List<Document.Page.Line> lines, String text) {\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0%d lines detected:\\n\", lines.size());\u00a0 \u00a0 Document.Page.Line firstLine = lines.get(0);\u00a0 \u00a0 String firstLineText = getLayoutText(firstLine.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0First line text: %s\\n\", escapeNewlines(firstLineText));\u00a0 \u00a0 Document.Page.Line lastLine = lines.get(lines.size() - 1);\u00a0 \u00a0 String lastLineText = getLayoutText(lastLine.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0Last line text: %s\\n\", escapeNewlines(lastLineText));\u00a0 }\u00a0 private static void printTokens(List<Document.Page.Token> tokens, String text) {\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0%d tokens detected:\\n\", tokens.size());\u00a0 \u00a0 Document.Page.Token firstToken = tokens.get(0);\u00a0 \u00a0 String firstTokenText = getLayoutText(firstToken.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0First token text: %s\\n\", escapeNewlines(firstTokenText));\u00a0 \u00a0 Document.Page.Token lastToken = tokens.get(tokens.size() - 1);\u00a0 \u00a0 String lastTokenText = getLayoutText(lastToken.getLayout().getTextAnchor(), text);\u00a0 \u00a0 System.out.printf(\" \u00a0 \u00a0 \u00a0 \u00a0Last token text: %s\\n\", escapeNewlines(lastTokenText));\u00a0 }\u00a0 // Extract shards from the text field\u00a0 private static String getLayoutText(Document.TextAnchor textAnchor, String text) {\u00a0 \u00a0 if (textAnchor.getTextSegmentsList().size() > 0) {\u00a0 \u00a0 \u00a0 int startIdx = (int) textAnchor.getTextSegments(0).getStartIndex();\u00a0 \u00a0 \u00a0 int endIdx = (int) textAnchor.getTextSegments(0).getEndIndex();\u00a0 \u00a0 \u00a0 return text.substring(startIdx, endIdx);\u00a0 \u00a0 }\u00a0 \u00a0 return \"[NO TEXT]\";\u00a0 }\u00a0 private static String escapeNewlines(String s) {\u00a0 \u00a0 return s.replace(\"\\n\", \"\\\\n\").replace(\"\\r\", \"\\\\r\");\u00a0 }}\n```For more information, see the [Document AI Node.js API reference documentation](/nodejs/docs/reference/documentai/latest) .\nTo authenticate to Document AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/nodejs-docs-samples/blob/HEAD/document-ai/process-document-ocr.js) \n```\n/**\u00a0* TODO(developer): Uncomment these variables before running the sample.\u00a0*/// const projectId = 'YOUR_PROJECT_ID';// const location = 'YOUR_PROJECT_LOCATION'; // Format is 'us' or 'eu'// const processorId = 'YOUR_PROCESSOR_ID'; // Create processor in Cloud Console// const filePath = '/path/to/local/pdf';const {DocumentProcessorServiceClient} =\u00a0 require('@google-cloud/documentai').v1beta3;// Instantiates a clientconst client = new DocumentProcessorServiceClient();async function processDocument() {\u00a0 // The full resource name of the processor, e.g.:\u00a0 // projects/project-id/locations/location/processor/processor-id\u00a0 // You must create new processors in the Cloud Console first\u00a0 const name = `projects/${projectId}/locations/${location}/processors/${processorId}`;\u00a0 // Read the file into memory.\u00a0 const fs = require('fs').promises;\u00a0 const imageFile = await fs.readFile(filePath);\u00a0 // Convert the image data to a Buffer and base64 encode it.\u00a0 const encodedImage = Buffer.from(imageFile).toString('base64');\u00a0 const request = {\u00a0 \u00a0 name,\u00a0 \u00a0 rawDocument: {\u00a0 \u00a0 \u00a0 content: encodedImage,\u00a0 \u00a0 \u00a0 mimeType: 'application/pdf',\u00a0 \u00a0 },\u00a0 };\u00a0 // Recognizes text entities in the PDF document\u00a0 const [result] = await client.processDocument(request);\u00a0 console.log('Document processing complete.');\u00a0 // Read the text recognition output from the processor\u00a0 // For a full list of Document object attributes,\u00a0 // please reference this page: https://googleapis.dev/nodejs/documentai/latest/index.html\u00a0 const {document} = result;\u00a0 const {text} = document;\u00a0 // Read the text recognition output from the processor\u00a0 console.log(`Full document text: ${JSON.stringify(text)}`);\u00a0 console.log(`There are ${document.pages.length} page(s) in this document.`);\u00a0 for (const page of document.pages) {\u00a0 \u00a0 console.log(`Page ${page.pageNumber}`);\u00a0 \u00a0 printPageDimensions(page.dimension);\u00a0 \u00a0 printDetectedLanguages(page.detectedLanguages);\u00a0 \u00a0 printParagraphs(page.paragraphs, text);\u00a0 \u00a0 printBlocks(page.blocks, text);\u00a0 \u00a0 printLines(page.lines, text);\u00a0 \u00a0 printTokens(page.tokens, text);\u00a0 }}const printPageDimensions = dimension => {\u00a0 console.log(` \u00a0 \u00a0Width: ${dimension.width}`);\u00a0 console.log(` \u00a0 \u00a0Height: ${dimension.height}`);};const printDetectedLanguages = detectedLanguages => {\u00a0 console.log(' \u00a0 \u00a0Detected languages:');\u00a0 for (const lang of detectedLanguages) {\u00a0 \u00a0 const code = lang.languageCode;\u00a0 \u00a0 const confPercent = lang.confidence * 100;\u00a0 \u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0${code} (${confPercent.toFixed(2)}% confidence)`);\u00a0 }};const printParagraphs = (paragraphs, text) => {\u00a0 console.log(` \u00a0 \u00a0${paragraphs.length} paragraphs detected:`);\u00a0 const firstParagraphText = getText(paragraphs[0].layout.textAnchor, text);\u00a0 console.log(\u00a0 \u00a0 ` \u00a0 \u00a0 \u00a0 \u00a0First paragraph text: ${JSON.stringify(firstParagraphText)}`\u00a0 );\u00a0 const lastParagraphText = getText(\u00a0 \u00a0 paragraphs[paragraphs.length - 1].layout.textAnchor,\u00a0 \u00a0 text\u00a0 );\u00a0 console.log(\u00a0 \u00a0 ` \u00a0 \u00a0 \u00a0 \u00a0Last paragraph text: ${JSON.stringify(lastParagraphText)}`\u00a0 );};const printBlocks = (blocks, text) => {\u00a0 console.log(` \u00a0 \u00a0${blocks.length} blocks detected:`);\u00a0 const firstBlockText = getText(blocks[0].layout.textAnchor, text);\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0First block text: ${JSON.stringify(firstBlockText)}`);\u00a0 const lastBlockText = getText(\u00a0 \u00a0 blocks[blocks.length - 1].layout.textAnchor,\u00a0 \u00a0 text\u00a0 );\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0Last block text: ${JSON.stringify(lastBlockText)}`);};const printLines = (lines, text) => {\u00a0 console.log(` \u00a0 \u00a0${lines.length} lines detected:`);\u00a0 const firstLineText = getText(lines[0].layout.textAnchor, text);\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0First line text: ${JSON.stringify(firstLineText)}`);\u00a0 const lastLineText = getText(\u00a0 \u00a0 lines[lines.length - 1].layout.textAnchor,\u00a0 \u00a0 text\u00a0 );\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0Last line text: ${JSON.stringify(lastLineText)}`);};const printTokens = (tokens, text) => {\u00a0 console.log(` \u00a0 \u00a0${tokens.length} tokens detected:`);\u00a0 const firstTokenText = getText(tokens[0].layout.textAnchor, text);\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0First token text: ${JSON.stringify(firstTokenText)}`);\u00a0 const firstTokenBreakType = tokens[0].detectedBreak.type;\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0First token break type: ${firstTokenBreakType}`);\u00a0 const lastTokenText = getText(\u00a0 \u00a0 tokens[tokens.length - 1].layout.textAnchor,\u00a0 \u00a0 text\u00a0 );\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0Last token text: ${JSON.stringify(lastTokenText)}`);\u00a0 const lastTokenBreakType = tokens[tokens.length - 1].detectedBreak.type;\u00a0 console.log(` \u00a0 \u00a0 \u00a0 \u00a0Last token break type: ${lastTokenBreakType}`);};// Extract shards from the text fieldconst getText = (textAnchor, text) => {\u00a0 if (!textAnchor.textSegments || textAnchor.textSegments.length === 0) {\u00a0 \u00a0 return '';\u00a0 }\u00a0 // First shard in document doesn't have startIndex property\u00a0 const startIndex = textAnchor.textSegments[0].startIndex || 0;\u00a0 const endIndex = textAnchor.textSegments[0].endIndex;\u00a0 return text.substring(startIndex, endIndex);};\n```For more information, see the [Document AI Python API reference documentation](/python/docs/reference/documentai/latest) .\nTo authenticate to Document AI, set up Application Default Credentials.  For more information, see [Set up authentication for a local development environment](/docs/authentication/provide-credentials-adc#local-dev) .\n [View on GitHub](https://github.com/GoogleCloudPlatform/python-docs-samples/blob/HEAD/documentai/snippets/handle_response_sample.py) \n```\nfrom typing import Optional, Sequencefrom google.api_core.client_options import ClientOptionsfrom google.cloud import documentai# TODO(developer): Uncomment these variables before running the sample.# project_id = \"YOUR_PROJECT_ID\"# location = \"YOUR_PROCESSOR_LOCATION\" # Format is \"us\" or \"eu\"# processor_id = \"YOUR_PROCESSOR_ID\" # Create processor before running sample# processor_version = \"rc\" # Refer to https://cloud.google.com/document-ai/docs/manage-processor-versions for more information# file_path = \"/path/to/local/pdf\"# mime_type = \"application/pdf\" # Refer to https://cloud.google.com/document-ai/docs/file-types for supported file typesdef process_document_ocr_sample(\u00a0 \u00a0 project_id: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 processor_id: str,\u00a0 \u00a0 processor_version: str,\u00a0 \u00a0 file_path: str,\u00a0 \u00a0 mime_type: str,) -> None:\u00a0 \u00a0 # Optional: Additional configurations for Document OCR Processor.\u00a0 \u00a0 # For more information: https://cloud.google.com/document-ai/docs/enterprise-document-ocr\u00a0 \u00a0 process_options = documentai.ProcessOptions(\u00a0 \u00a0 \u00a0 \u00a0 ocr_config=documentai.OcrConfig(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 enable_native_pdf_parsing=True,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 enable_image_quality_scores=True,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 enable_symbol=True,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 # OCR Add Ons https://cloud.google.com/document-ai/docs/ocr-add-ons\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 premium_features=documentai.OcrConfig.PremiumFeatures(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 compute_style_info=True,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 enable_math_ocr=False, \u00a0# Enable to use Math OCR Model\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 enable_selection_mark_detection=True,\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 ),\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 )\u00a0 \u00a0 # Online processing request to Document AI\u00a0 \u00a0 document = process_document(\u00a0 \u00a0 \u00a0 \u00a0 project_id,\u00a0 \u00a0 \u00a0 \u00a0 location,\u00a0 \u00a0 \u00a0 \u00a0 processor_id,\u00a0 \u00a0 \u00a0 \u00a0 processor_version,\u00a0 \u00a0 \u00a0 \u00a0 file_path,\u00a0 \u00a0 \u00a0 \u00a0 mime_type,\u00a0 \u00a0 \u00a0 \u00a0 process_options=process_options,\u00a0 \u00a0 )\u00a0 \u00a0 text = document.text\u00a0 \u00a0 print(f\"Full document text: {text}\\n\")\u00a0 \u00a0 print(f\"There are {len(document.pages)} page(s) in this document.\\n\")\u00a0 \u00a0 for page in document.pages:\u00a0 \u00a0 \u00a0 \u00a0 print(f\"Page {page.page_number}:\")\u00a0 \u00a0 \u00a0 \u00a0 print_page_dimensions(page.dimension)\u00a0 \u00a0 \u00a0 \u00a0 print_detected_langauges(page.detected_languages)\u00a0 \u00a0 \u00a0 \u00a0 print_blocks(page.blocks, text)\u00a0 \u00a0 \u00a0 \u00a0 print_paragraphs(page.paragraphs, text)\u00a0 \u00a0 \u00a0 \u00a0 print_lines(page.lines, text)\u00a0 \u00a0 \u00a0 \u00a0 print_tokens(page.tokens, text)\u00a0 \u00a0 \u00a0 \u00a0 if page.symbols:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print_symbols(page.symbols, text)\u00a0 \u00a0 \u00a0 \u00a0 if page.image_quality_scores:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print_image_quality_scores(page.image_quality_scores)\u00a0 \u00a0 \u00a0 \u00a0 if page.visual_elements:\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 print_visual_elements(page.visual_elements, text)def print_page_dimensions(dimension: documentai.Document.Page.Dimension) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0Width: {str(dimension.width)}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0Height: {str(dimension.height)}\")def print_detected_langauges(\u00a0 \u00a0 detected_languages: Sequence[documentai.Document.Page.DetectedLanguage],) -> None:\u00a0 \u00a0 print(\" \u00a0 \u00a0Detected languages:\")\u00a0 \u00a0 for lang in detected_languages:\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0{lang.language_code} ({lang.confidence:.1%} confidence)\")def print_blocks(blocks: Sequence[documentai.Document.Page.Block], text: str) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(blocks)} blocks detected:\")\u00a0 \u00a0 first_block_text = layout_to_text(blocks[0].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First text block: {repr(first_block_text)}\")\u00a0 \u00a0 last_block_text = layout_to_text(blocks[-1].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last text block: {repr(last_block_text)}\")def print_paragraphs(\u00a0 \u00a0 paragraphs: Sequence[documentai.Document.Page.Paragraph], text: str) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(paragraphs)} paragraphs detected:\")\u00a0 \u00a0 first_paragraph_text = layout_to_text(paragraphs[0].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First paragraph text: {repr(first_paragraph_text)}\")\u00a0 \u00a0 last_paragraph_text = layout_to_text(paragraphs[-1].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last paragraph text: {repr(last_paragraph_text)}\")def print_lines(lines: Sequence[documentai.Document.Page.Line], text: str) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(lines)} lines detected:\")\u00a0 \u00a0 first_line_text = layout_to_text(lines[0].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First line text: {repr(first_line_text)}\")\u00a0 \u00a0 last_line_text = layout_to_text(lines[-1].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last line text: {repr(last_line_text)}\")def print_tokens(tokens: Sequence[documentai.Document.Page.Token], text: str) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(tokens)} tokens detected:\")\u00a0 \u00a0 first_token_text = layout_to_text(tokens[0].layout, text)\u00a0 \u00a0 first_token_break_type = tokens[0].detected_break.type_.name\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First token text: {repr(first_token_text)}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First token break type: {repr(first_token_break_type)}\")\u00a0 \u00a0 if tokens[0].style_info:\u00a0 \u00a0 \u00a0 \u00a0 print_style_info(tokens[0].style_info)\u00a0 \u00a0 last_token_text = layout_to_text(tokens[-1].layout, text)\u00a0 \u00a0 last_token_break_type = tokens[-1].detected_break.type_.name\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last token text: {repr(last_token_text)}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last token break type: {repr(last_token_break_type)}\")\u00a0 \u00a0 if tokens[-1].style_info:\u00a0 \u00a0 \u00a0 \u00a0 print_style_info(tokens[-1].style_info)def print_symbols(\u00a0 \u00a0 symbols: Sequence[documentai.Document.Page.Symbol], text: str) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(symbols)} symbols detected:\")\u00a0 \u00a0 first_symbol_text = layout_to_text(symbols[0].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First symbol text: {repr(first_symbol_text)}\")\u00a0 \u00a0 last_symbol_text = layout_to_text(symbols[-1].layout, text)\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last symbol text: {repr(last_symbol_text)}\")def print_image_quality_scores(\u00a0 \u00a0 image_quality_scores: documentai.Document.Page.ImageQualityScores,) -> None:\u00a0 \u00a0 print(f\" \u00a0 \u00a0Quality score: {image_quality_scores.quality_score:.1%}\")\u00a0 \u00a0 print(\" \u00a0 \u00a0Detected defects:\")\u00a0 \u00a0 for detected_defect in image_quality_scores.detected_defects:\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0{detected_defect.type_}: {detected_defect.confidence:.1%}\")def print_style_info(style_info: documentai.Document.Page.Token.StyleInfo) -> None:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Only supported in version `pretrained-ocr-v2.0-2023-06-02`\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Font Size: {style_info.font_size}pt\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Font Type: {style_info.font_type}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Bold: {style_info.bold}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Italic: {style_info.italic}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Underlined: {style_info.underlined}\")\u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Handwritten: {style_info.handwritten}\")\u00a0 \u00a0 print(\u00a0 \u00a0 \u00a0 \u00a0 f\" \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 Text Color (RGBa): {style_info.text_color.red}, {style_info.text_color.green}, {style_info.text_color.blue}, {style_info.text_color.alpha}\"\u00a0 \u00a0 )def print_visual_elements(\u00a0 \u00a0 visual_elements: Sequence[documentai.Document.Page.VisualElement], text: str) -> None:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Only supported in version `pretrained-ocr-v2.0-2023-06-02`\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 checkboxes = [x for x in visual_elements if \"checkbox\" in x.type]\u00a0 \u00a0 math_symbols = [x for x in visual_elements if x.type == \"math_formula\"]\u00a0 \u00a0 if checkboxes:\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(checkboxes)} checkboxes detected:\")\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First checkbox: {repr(checkboxes[0].type)}\")\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0Last checkbox: {repr(checkboxes[-1].type)}\")\u00a0 \u00a0 if math_symbols:\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0{len(math_symbols)} math symbols detected:\")\u00a0 \u00a0 \u00a0 \u00a0 first_math_symbol_text = layout_to_text(math_symbols[0].layout, text)\u00a0 \u00a0 \u00a0 \u00a0 print(f\" \u00a0 \u00a0 \u00a0 \u00a0First math symbol: {repr(first_math_symbol_text)}\")def process_document(\u00a0 \u00a0 project_id: str,\u00a0 \u00a0 location: str,\u00a0 \u00a0 processor_id: str,\u00a0 \u00a0 processor_version: str,\u00a0 \u00a0 file_path: str,\u00a0 \u00a0 mime_type: str,\u00a0 \u00a0 process_options: Optional[documentai.ProcessOptions] = None,) -> documentai.Document:\u00a0 \u00a0 # You must set the `api_endpoint` if you use a location other than \"us\".\u00a0 \u00a0 client = documentai.DocumentProcessorServiceClient(\u00a0 \u00a0 \u00a0 \u00a0 client_options=ClientOptions(\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 api_endpoint=f\"{location}-documentai.googleapis.com\"\u00a0 \u00a0 \u00a0 \u00a0 )\u00a0 \u00a0 )\u00a0 \u00a0 # The full resource name of the processor version, e.g.:\u00a0 \u00a0 # `projects/{project_id}/locations/{location}/processors/{processor_id}/processorVersions/{processor_version_id}`\u00a0 \u00a0 # You must create a processor before running this sample.\u00a0 \u00a0 name = client.processor_version_path(\u00a0 \u00a0 \u00a0 \u00a0 project_id, location, processor_id, processor_version\u00a0 \u00a0 )\u00a0 \u00a0 # Read the file into memory\u00a0 \u00a0 with open(file_path, \"rb\") as image:\u00a0 \u00a0 \u00a0 \u00a0 image_content = image.read()\u00a0 \u00a0 # Configure the process request\u00a0 \u00a0 request = documentai.ProcessRequest(\u00a0 \u00a0 \u00a0 \u00a0 name=name,\u00a0 \u00a0 \u00a0 \u00a0 raw_document=documentai.RawDocument(content=image_content, mime_type=mime_type),\u00a0 \u00a0 \u00a0 \u00a0 # Only supported for Document OCR processor\u00a0 \u00a0 \u00a0 \u00a0 process_options=process_options,\u00a0 \u00a0 )\u00a0 \u00a0 result = client.process_document(request=request)\u00a0 \u00a0 # For a full list of `Document` object attributes, reference this page:\u00a0 \u00a0 # https://cloud.google.com/document-ai/docs/reference/rest/v1/Document\u00a0 \u00a0 return result.documentdef layout_to_text(layout: documentai.Document.Page.Layout, text: str) -> str:\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 Document AI identifies text in different parts of the document by their\u00a0 \u00a0 offsets in the entirety of the document\"s text. This function converts\u00a0 \u00a0 offsets to a string.\u00a0 \u00a0 \"\"\"\u00a0 \u00a0 # If a text segment spans several lines, it will\u00a0 \u00a0 # be stored in different text segments.\u00a0 \u00a0 return \"\".join(\u00a0 \u00a0 \u00a0 \u00a0 text[int(segment.start_index) : int(segment.end_index)]\u00a0 \u00a0 \u00a0 \u00a0 for segment in layout.text_anchor.text_segments\u00a0 \u00a0 )\n```\n## What's nextTo search and filter code samples for other Google Cloud products, see the [Google Cloud sample browser](/docs/samples?product=documentai) .", "guide": "Document AI"}