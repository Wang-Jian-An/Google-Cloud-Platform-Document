{"title": "Documentation - Try Optical Character Recognition (OCR)", "url": "https://cloud.google.com/distributed-cloud/hosted/docs/latest/gdch/overview", "abstract": "# Documentation - Try Optical Character Recognition (OCR)\nThis quickstart guides the Application Operator (AO) through the process of using the Vertex AI Optical Character Recognition (OCR) pre-trained API.\n", "content": "## Before you begin\n- [Enable the OCR pre-trained API](/distributed-cloud/hosted/docs/latest/gdch/platform/pa-user/vertex-pre-trained-apis#enable-api) .\n- Download the [gdcloud command-line interface (CLI)](/distributed-cloud/hosted/docs/latest/gdch/resources/gdcloud-download) .## Set up your project\nSet up a project using the console to group the Vertex AI services. For information about creating and using projects, see [Creating a project](/distributed-cloud/hosted/docs/latest/gdch/platform/pa-user/create-a-project) .\n## Set up your service account\nSet up your service account with the name of your service account, project ID, and service key. Replace the `PROJECT_ID` with your [project](#set-up-your-project) .\n```\n\u00a0 ${HOME}/gdcloud init \u00a0# set URI and project\u00a0 ${HOME}/gdcloud auth login\u00a0 ${HOME}/gdcloud iam service-accounts create SERVICE_ACCOUNT \u00a0--project=PROJECT_ID\u00a0 ${HOME}/gdcloud iam service-accounts keys create \"SERVICE_KEY\".json --project=PROJECT_ID --iam-account=SERVICE_ACCOUNT\n```\n## Grant access to project resources\nGrant access to the Translation API service account by providing your project ID, name of your service account, and the role `ai-ocr-developer` .\n```\n\u00a0 ${HOME}/gdcloud iam service-accounts add-iam-policy-binding --project=PROJECT_ID --iam-account=SERVICE_ACCOUNT --role=role/ai-ocr-developer\n```\n## Set your environment variables\nBefore running the OCR pre-trained service, set your environment variable.\n```\n\u00a0 export GOOGLE_APPLICATION_CREDENTIALS=\"SERVICE_KEY\".json\n```\n## Authenticate the CLI\nYou must get a token to authenticate the CLI before sending requests to the OCR pre-trained service. Follow these steps:\n- Install the `google-auth` client library.```\npip install google-auth\n```\n- Save the following code to a Python script, and update the `ENDPOINT` to the OCR endpoint. Run the script to fetch the token. For more information, see [View service statuses and endpoints](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/vertex-ai-api-status) .```\nimport google.authfrom google.auth.transport import requestsapi_endpoint = \"https://ENDPOINT\"creds, project_id = google.auth.default()creds = creds.with_gdch_audience(api_endpoint)def test_get_token():\u00a0 req = requests.Request()\u00a0 creds.refresh(req)\u00a0 print(creds.token)if __name__==\"__main__\":\u00a0 test_get_token()\n```\n- Add the fetched token to the header of the `grpcurl` and `curl` requests:```\n-H \"Authorization: Bearer TOKEN\"\n```\nIf you don't have `grpcurl` installed, download and install it from a resource outside of GDCH ( [https://github.com/fullstorydev/grpcurl#from-source](https://github.com/fullstorydev/grpcurl#from-source) ).\n```\necho '{ \"requests\": [{\"features\": [{\"type\": \"TEXT_DETECTION\"}], \"image\": {\"content\": \"'iVBORw0KGgoAAAANSUhEUgAAAMgAAAArCAMAAAAKVjeAAAAAA3NCSVQICAjb4U/gAAAADFBMVEX///8AAABnZ2cMDAzMh6MLAAAAX3pUWHRSYXcgcHJvZmlsZSB0eXBlIEFQUDEAAAiZ40pPzUstykxWKCjKT8vMSeVSAANjEy4TSxNLo0QDAwMLAwgwNDAwNgSSRkC2OVQo0QAFmJibpQGhuVmymSmIzwUAT7oVaBst2IwAAAEjSURBVGiB7ZRBFsMgCEShvf+d+9o0VmAwxpCuZjZGkYGfaEQoiqIoiqIoiqKoG6Sqg6lbTqK1LfwWTpUjSJ0IMnIhyAXdDaL6mwSQPpg5hgeT9H7c5sG1FES/wiA2OgkSLUPfW7wSRNWUdSAuih19drTUFnCuiyBO+6ob7WBGTPJ5tZYDJ4NAJYgvEoesUgoC+8bntgikczALSXQGJLMcuj7nOfAduQbStkm3fQnkUQACP9EZkB3mCsgZ3QEiDkRQ0r9A4K55kHaswlUmyApIVsVH04oGxO1NSoDfbw2IujmI5hX7fNeeDkDaWAbSX/cIIjY4B+KTAoj5xaDelkAEWobooW2/xyZFkH0DTF4GsZ84HIejg4x7UWuAnlSzZIqiJvUCFxYEUadKypwAAAAASUVORK5CYII='\" } }] }' | grpcurl -vv --cacert ourcert.crt -authority ENDPOINT -H \"Authorization: Bearer TOKEN\" -max-msg-sz 50000000 -d @ ENDPOINT:443 google.cloud.vision.v1.ImageAnnotator.BatchAnnotateImages\n```\n```\necho '{\"requests\": [{\"image\": {\"content\": \"'iVBORw0KGgoAAAANSUhEUgAAAMgAAAArCAMAAAAKVjeAAAAAA3NCSVQICAjb4U/gAAAADFBMVEX///8AAABnZ2cMDAzMh6MLAAAAX3pUWHRSYXcgcHJvZmlsZSB0eXBlIEFQUDEAAAiZ40pPzUstykxWKCjKT8vMSeVSAANjEy4TSxNLo0QDAwMLAwgwNDAwNgSSRkC2OVQo0QAFmJibpQGhuVmymSmIzwUAT7oVaBst2IwAAAEjSURBVGiB7ZRBFsMgCEShvf+d+9o0VmAwxpCuZjZGkYGfaEQoiqIoiqIoiqKoG6Sqg6lbTqK1LfwWTpUjSJ0IMnIhyAXdDaL6mwSQPpg5hgeT9H7c5sG1FES/wiA2OgkSLUPfW7wSRNWUdSAuih19drTUFnCuiyBO+6ob7WBGTPJ5tZYDJ4NAJYgvEoesUgoC+8bntgikczALSXQGJLMcuj7nOfAduQbStkm3fQnkUQACP9EZkB3mCsgZ3QEiDkRQ0r9A4K55kHaswlUmyApIVsVH04oGxO1NSoDfbw2IujmI5hX7fNeeDkDaWAbSX/cIIjY4B+KTAoj5xaDelkAEWobooW2/xyZFkH0DTF4GsZ84HIejg4x7UWuAnlSzZIqiJvUCFxYEUadKypwAAAAASUVORK5CYII='\" }, \"features\": [ { \"type\": \"DOCUMENT_TEXT_DETECTION\" } ] }] }' | curl --cacert CERTIFICATE_NAME --data-binary @- -H \"Content-Type: application/json\" -H \"Authorization: Bearer TOKEN\" https://ENDPOINT/v1/images:annotate\n```## Run the OCR pre-trained API sample script\nThis example shows you how to interact with an OCR pre-trained API.\n- Check whether the client library for OCR is installed.```\n\u00a0 pip freeze | grep vision\u00a0 # output example: google-cloud-vision==3.0.0\n```If the existing version doesn't match the client library in `https://` `` `/.well-known/static/client-libraries` , uninstall the client library.```\n\u00a0 pip uninstall google-cloud-vision\n```\n- Specify the console endpoint and the [client library](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/vertex-ai-install-libraries#CLIENTLIB) for OCR (provided in the example).```\n\u00a0 \u00a0wget https://CONSOLE_ENDPOINT/.well-known/static/client-libraries/google-cloud-vision\n``` **Note:** If the error message, \"x509: certificate signed by unknown authority\", is displayed, your workstation doesn't trust the CA certificate used in GDCH. Follow your organization's procedure to check the trusted certification store for your workstation. **Warning:** Using `--login-config-cert` with an unverified certificate makes your workstation vulnerable to man-in-the-middle attacks. Ensure that you rely only on your workstation's trust store instead of trusting a CA certificate from unknown sources.\n- Extract the `tar` file, and install it using `pip` . If errors are generated because something isn't found, install any missing dependencies.```\ntar -xvzf CLIENT_LIBRARYpip install -r FOLDER/requirements.txt --no-index --find-links FOLDER\n```\n- Use the [OCR client library script](#ocr_sample_script) to generate the token, and make requests to the OCR service.\n- Set up your environment variable.```\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"\"SERVICE_KEY\".json\"\n```## Run the OCR sample\nReplace the `ENDPOINT` with the OCR endpoint that you use for your organization.\n```\nfrom google.cloud import visionimport google.authfrom google.auth.transport import requestsfrom google.api_core.client_options import ClientOptionsaudience = \"https://ENDPOINT\"api_endpoint=\"ENDPOINT:443\"def vision_client(creds):\u00a0 opts = ClientOptions(api_endpoint=api_endpoint)\u00a0 \"\"\"Create vision client.\"\"\"\u00a0 return vision.ImageAnnotatorClient(credentials=creds, client_options=opts)def main():\u00a0 creds = None\u00a0 try:\u00a0 \u00a0 creds, project_id = google.auth.default()\u00a0 \u00a0 creds = creds.with_gdch_audience(audience)\u00a0 \u00a0 req = requests.Request()\u00a0 \u00a0 creds.refresh(req)\u00a0 \u00a0 print(\"Got token: \")\u00a0 \u00a0 print(creds.token)\u00a0 except Exception as e:\u00a0 \u00a0 print(\"Caught exception\" + str(e))\u00a0 \u00a0 raise e\u00a0 return credsdef vision_func(creds):\u00a0 vc = vision_client(creds)\u00a0 image = {\"content\": \"iVBORw0KGgoAAAANSUhEUgAAAMgAAAArCAMAAAAKVjeAAAAAA3NCSVQICAjb4U/gAAAADFBMVEX///8AAABnZ2cMDAzMh6MLAAAAX3pUWHRSYXcgcHJvZmlsZSB0eXBlIEFQUDEAAAiZ40pPzUstykxWKCjKT8vMSeVSAANjEy4TSxNLo0QDAwMLAwgwNDAwNgSSRkC2OVQo0QAFmJibpQGhuVmymSmIzwUAT7oVaBst2IwAAAEjSURBVGiB7ZRBFsMgCEShvf+d+9o0VmAwxpCuZjZGkYGfaEQoiqIoiqIoiqKoG6Sqg6lbTqK1LfwWTpUjSJ0IMnIhyAXdDaL6mwSQPpg5hgeT9H7c5sG1FES/wiA2OgkSLUPfW7wSRNWUdSAuih19drTUFnCuiyBO+6ob7WBGTPJ5tZYDJ4NAJYgvEoesUgoC+8bntgikczALSXQGJLMcuj7nOfAduQbStkm3fQnkUQACP9EZkB3mCsgZ3QEiDkRQ0r9A4K55kHaswlUmyApIVsVH04oGxO1NSoDfbw2IujmI5hX7fNeeDkDaWAbSX/cIIjY4B+KTAoj5xaDelkAEWobooW2/xyZFkH0DTF4GsZ84HIejg4x7UWuAnlSzZIqiJvUCFxYEUadKypwAAAAASUVORK5CYII=\"}\u00a0 features = [{\"type_\": vision.Feature.Type.DOCUMENT_TEXT_DETECTION}]\u00a0 # Each requests element corresponds to a single image. \u00a0To annotate more\u00a0 # images, create a request element for each image and add it to\u00a0 # the array of requests\u00a0 req = {\"image\": image, \"features\": features}\u00a0 resp = vc.annotate_image(req)\u00a0 print(resp)if __name__==\"__main__\":\u00a0 creds = main()\u00a0 vision_func(creds)\n```\n## What's next\n- Learn more about how to [Detect text in images](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/vertex-ai-ocr) .\n- Learn more about how to [Detect text in images offline](/distributed-cloud/hosted/docs/latest/gdch/application/ao-user/vertex-ai-async-ocr) .", "guide": "Documentation"}